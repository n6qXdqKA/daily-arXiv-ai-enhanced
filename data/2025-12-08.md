[[toc]]

## cs.CV

### [1] [AREA3D: Active Reconstruction Agent with Unified Feed-Forward 3D Perception and Vision-Language Guidance](https://arxiv.org/abs/2512.05131)
*Tianling Xu,Shengzhe Gan,Leslie Gu,Yuelei Li,Fangneng Zhan,Hanspeter Pfister*

Main category: cs.CV

TL;DR: AREA3D：基于前馈3D重建模型和视觉语言引导的主动3D重建智能体，通过解耦视图不确定性建模和集成语义指导，在稀疏视图下实现最先进的重建精度。

- Motivation: 现有主动重建方法依赖手工几何启发式规则，可能导致冗余观测而无法显著提升重建质量。需要更智能的视角选择策略来高效获取准确完整的场景几何。
- Method: 1) 将视图不确定性建模与前馈重建器解耦，实现无需昂贵在线优化的精确不确定性估计；2) 集成视觉语言模型提供高层语义指导，鼓励超越纯几何线索的信息丰富且多样化的视角选择。
- Result: 在场景级和物体级基准测试中，AREA3D实现了最先进的重建精度，特别是在稀疏视图条件下表现优异。
- Conclusion: AREA3D通过结合前馈3D重建模型和视觉语言指导，解决了传统主动重建方法的局限性，实现了更高效、准确的3D场景重建。


### [2] [Breaking Scale Anchoring: Frequency Representation Learning for Accurate High-Resolution Inference from Low-Resolution Training](https://arxiv.org/abs/2512.05132)
*Wenshuo Wang,Fan Zhang*

Main category: cs.CV

TL;DR: 论文提出"尺度锚定"新问题：低分辨率训练的模型在高分辨率推理时误差被锚定在低分辨率水平，无法随分辨率提升而降低。提出频率表示学习(FRL)方法，通过分辨率对齐的频率表示和谱一致性训练解决该问题。

- Motivation: 现有零样本超分辨率时空预测研究认为在不同分辨率下保持相似误差即表示成功泛化，但作为数值求解器替代的深度学习模型应在分辨率增加时降低误差。低分辨率数据的奈奎斯特频率限制了其能表示的物理定律频率上限，导致模型难以处理高分辨率推理时包含的未见频率分量，造成误差被锚定在低分辨率水平。
- Method: 提出架构无关的频率表示学习(FRL)，通过分辨率对齐的频率表示和谱一致性训练缓解尺度锚定问题。在具有更高奈奎斯特频率的网格上，FRL增强变体在高频带的频率响应更稳定。
- Result: FRL方法允许误差随分辨率增加而降低，在任务和分辨率范围内显著优于基线方法，同时仅带来适度的计算开销。
- Conclusion: 定义了"尺度锚定"这一新问题，并提出频率表示学习作为解决方案。该方法通过改善模型对不同分辨率下频率分量的处理能力，实现了误差随分辨率提升而降低的理想性能。


### [3] [InvarDiff: Cross-Scale Invariance Caching for Accelerated Diffusion Models](https://arxiv.org/abs/2512.05134)
*Zihao Wu*

Main category: cs.CV

TL;DR: InvarDiff是一种无需训练的扩散模型加速方法，通过利用确定性采样中的特征不变性，实现2-3倍端到端加速，同时保持生成质量。

- Motivation: 扩散模型虽然能生成高质量结果，但由于需要迭代采样，推理速度较慢。作者观察到确定性采样中存在特征不变性，希望通过利用这种不变性来加速推理过程。
- Method: InvarDiff利用确定性采样中的相对时间不变性（跨时间步和层尺度）。通过少量确定性运行，计算每个时间步、每层、每个模块的二进制缓存计划矩阵，并使用重采样校正避免连续缓存时的漂移。基于分位数的变化度量决定哪些模块在哪些步骤可以重用而非重新计算。同样的不变性准则应用于步骤尺度，实现跨时间步缓存。
- Result: 在DiT和FLUX模型上的实验表明，InvarDiff实现了2-3倍的端到端加速，同时对标准质量指标影响最小。视觉质量几乎没有退化。
- Conclusion: InvarDiff通过利用扩散模型中的特征不变性，提供了一种无需训练的有效加速方法，在保持生成质量的同时显著提升推理速度。


### [4] [Fine-tuning an ECG Foundation Model to Predict Coronary CT Angiography Outcomes](https://arxiv.org/abs/2512.05136)
*Yujie Xiao,Gongzhen Tang,Deyun Zhang,Jun Li,Guangkun Nie,Haoyu Wang,Shun Huang,Tong Liu,Qinghao Zhao,Kangyin Chen,Shenda Hong*

Main category: cs.CV

TL;DR: 开发可解释AI-ECG模型，通过心电图预测冠状动脉严重或完全狭窄，在内外验证集上表现良好，性能稳定且可解释性强。

- Motivation: 冠状动脉疾病是全球主要健康负担，需要准确识别罪犯血管和评估狭窄程度。虽然冠脉CT血管造影是首选无创诊断方法，但其依赖高端设备、有辐射暴露且需要患者严格配合，限制了大规模应用。随着人工智能发展和心电图广泛可用，AI-ECG为CAD筛查提供了有前景的替代方案。
- Method: 开发可解释的AI-ECG模型，用于预测四大主要冠状动脉（RCA、LM、LAD、LCX）在CCTA上的严重或完全狭窄。模型在内部和外部验证集上进行评估，并在临床正常心电图亚组中测试稳定性，进行人口统计学和采集时间亚组分析，基于血管特异性发生率阈值进行风险分层，并进行可解释性分析。
- Result: 内部验证集上，模型对RCA、LM、LAD、LCX的AUC分别为0.794、0.818、0.744、0.755；外部验证集上AUC分别为0.749、0.971、0.667、0.727。在临床正常心电图亚组中性能保持稳定，表明模型超越明显心电图异常。亚组分析进一步确认模型稳定性。基于血管特异性发生率阈值的风险分层在校准和累积事件曲线上显示一致分离。可解释性分析揭示高低风险组间不同的波形差异，突出显示对模型决策贡献的关键电生理区域。
- Conclusion: 该研究开发的可解释AI-ECG模型能够有效预测冠状动脉严重狭窄，在内外验证集上表现良好且稳定，为CAD筛查提供了有前景的无创替代方案。可解释性分析提供了对冠状动脉狭窄心电图相关性的新见解。


### [5] [ChromouVQA: Benchmarking Vision-Language Models under Chromatic Camouflaged Images](https://arxiv.org/abs/2512.05137)
*Yunfei Zhang,Yizhuo He,Yuanxun Shao,Zhengtao Yao,Haoyan Xu,Junhao Dong,Zhen Yao,Zhikang Dong*

Main category: cs.CV

TL;DR: 提出了ChromouVQA基准测试，基于石原式色盲测试原理创建大规模多任务视觉问答数据集，用于评估视觉语言模型在复杂背景中目标识别能力

- Motivation: 当前视觉语言模型在多模态理解方面虽有进步，但在目标物体嵌入杂乱背景需要图形-背景分离时仍存在困难，需要专门的基准测试来评估和改进这种能力
- Method: 基于石原式色盲测试原理创建大规模数据集，扩展经典点阵设计，改变颜色分离、密度、大小、遮挡和旋转等参数，包含9种视觉问答任务，并提出模型无关的对比学习方法
- Result: 人类和VLM评估显示存在显著差距，特别是在细微颜色对比或破坏性几何填充条件下；提出的对比学习方法能改善全局形状恢复
- Conclusion: ChromouVQA提供了一个紧凑、可控的基准测试，用于可重复评估和扩展，有助于推动视觉语言模型在复杂背景中目标识别能力的发展


### [6] [Spatiotemporal Satellite Image Downscaling with Transfer Encoders and Autoregressive Generative Models](https://arxiv.org/abs/2512.05139)
*Yang Xiang,Jingwen Zhong,Yige Yan,Petros Koutrakis,Eric Garshick,Meredith Franklin*

Main category: cs.CV

TL;DR: 提出一种迁移学习生成式降尺度框架，结合轻量U-Net迁移编码器和扩散生成模型，从粗分辨率卫星图像重建细分辨率图像，在亚洲区域季节分割中表现优异。

- Motivation: 解决从粗分辨率卫星图像重建细分辨率图像的问题，特别是在训练数据有限的情况下。传统方法难以保持物理一致性，需要一种既能学习时空表征又能生成物理一致细分辨率图像的方法。
- Method: 结合轻量U-Net迁移编码器和扩散生成模型。首先在粗分辨率数据上预训练U-Net学习时空表征，然后冻结编码器并迁移到更大的降尺度模型中作为物理有意义的潜在特征。使用MERRA-2（50km）作为低分辨率源域，GEOS-5 Nature Run（7km）作为高分辨率目标域。
- Result: 在亚洲区域季节分割中表现优异（R2 = 0.65到0.94），优于确定性U-Net、变分自编码器和先前迁移学习基线。预测的降尺度图像保持了物理一致的空间变异性和时间自相关性，能够超越G5NR记录进行稳定的自回归重建。
- Conclusion: 迁移增强的扩散模型为有限训练期内的长时序粗分辨率图像降尺度提供了稳健且物理一致的解决方案，对改善环境暴露评估和长期环境监测有重要意义。


### [7] [FlowEO: Generative Unsupervised Domain Adaptation for Earth Observation](https://arxiv.org/abs/2512.05140)
*Georges Le Bellier,Nicolas Audebert*

Main category: cs.CV

TL;DR: FlowEO：基于流匹配的生成模型框架，用于地球观测图像的无监督域自适应，在分类和语义分割任务中优于现有图像翻译方法。

- Motivation: 地球观测数据存在传感器、地理区域、采集时间和大气条件等异质性，导致训练域和部署域之间的分布偏移严重限制了预训练模型的泛化能力，因此需要无监督域自适应（UDA）来解决实际应用中的挑战。
- Method: FlowEO利用流匹配学习语义保持的映射，将源域图像分布传输到目标域图像分布，通过生成模型实现图像空间的无监督域自适应，处理SAR到光学图像转换以及自然灾害引起的时空和语义偏移等复杂配置。
- Result: 在四个数据集上的广泛实验表明，FlowEO在域自适应任务中优于现有图像翻译方法，同时在感知图像质量方面达到相当或更好的水平。
- Conclusion: 基于流匹配的无监督域自适应方法在地球观测领域具有巨大潜力，能够有效处理遥感图像中的分布偏移问题，为大规模环境监测和分析提供可靠解决方案。


### [8] [Self-Improving VLM Judges Without Human Annotations](https://arxiv.org/abs/2512.05145)
*Inna Wanyin Lin,Yushi Hu,Shuyue Stella Li,Scott Geng,Pang Wei Koh,Luke Zettlemoyer,Tim Althoff,Marjan Ghazvininejad*

Main category: cs.CV

TL;DR: 提出无需人工标注、通过自合成数据训练VLM评估器的框架，在多个评测基准上超越大型模型

- Motivation: 当前训练VLM评估器依赖大规模人工偏好标注，成本高且标注容易过时，需要无需人工标注的自训练方法
- Method: 三阶段迭代框架：1)生成不同质量的多模态指令-响应对；2)生成推理轨迹和判断，过滤不符合质量要求的样本；3)基于正确判断及其推理轨迹进行训练
- Result: Llama-3.2-11B评估器在VL-RewardBench上的整体准确率从0.38提升至0.51，超越Llama-3.2-90B、GPT-4o和Claude 3.5 Sonnet等更大模型
- Conclusion: 无需人工标注的自训练方法展示了构建能够随VLM能力快速演进的自评估器的潜力


### [9] [TwinFlow: Realizing One-step Generation on Large Models with Self-adversarial Flows](https://arxiv.org/abs/2512.05150)
*Zhenglin Cheng,Peng Sun,Jianguo Li,Tao Lin*

Main category: cs.CV

TL;DR: TwinFlow：一种无需固定教师模型和对抗网络的简单高效1步生成模型训练框架，在文本到图像任务中实现100倍计算成本降低

- Motivation: 现有多模态生成模型通常基于多步框架（如扩散和流匹配），推理效率低（需要40-100 NFE）。现有的少步加速方法存在局限性：蒸馏方法需要迭代过程或在极少数步骤（<4-NFE）下性能显著下降；结合对抗训练的蒸馏方法则存在训练不稳定、复杂度高和GPU内存开销大的问题。
- Method: 提出TwinFlow框架，无需固定预训练教师模型，避免训练中使用标准对抗网络。通过全参数训练Qwen-Image-20B等大规模模型，将其转化为高效少步生成器。
- Result: 在文本到图像任务中，1-NFE下获得0.83的GenEval分数，优于SANA-Sprint和RCGM等基线方法。将Qwen-Image-20B转化为1-NFE生成器后，在GenEval和DPG-Bench基准测试中性能与原始100-NFE模型相当，计算成本降低100倍，质量下降很小。
- Conclusion: TwinFlow是一个简单有效的框架，能够训练1步生成模型，无需固定教师模型和对抗网络，适合构建大规模高效模型，显著提升推理效率。


### [10] [EFDiT: Efficient Fine-grained Image Generation Using Diffusion Transformer Models](https://arxiv.org/abs/2512.05152)
*Kun Wang,Donglin Di,Tonghua Su,Lei Fan*

Main category: cs.CV

TL;DR: 该论文提出了一种用于细粒度图像生成的分层嵌入器和超分辨率增强方法，结合ProAttention机制，解决了语义信息纠缠和细节不足的问题。

- Motivation: 基于扩散模型的类别条件生成方法通常关注常见类别，而在大规模细粒度图像生成中，存在语义信息纠缠和生成图像细节不足的问题。
- Method: 1. 引入分层嵌入器概念，整合超类和子类的语义信息；2. 在感知信息生成阶段引入超分辨率概念，通过增强和退化模型提升细节特征；3. 提出高效的ProAttention机制，可在扩散模型中有效实现。
- Result: 在公共基准测试上进行广泛实验，证明该方法在性能上优于其他最先进的微调方法。
- Conclusion: 提出的分层嵌入器、超分辨率增强和ProAttention机制有效解决了细粒度图像生成中的语义纠缠和细节不足问题，提升了生成质量。


### [11] [Semore: VLM-guided Enhanced Semantic Motion Representations for Visual Reinforcement Learning](https://arxiv.org/abs/2512.05172)
*Wentao Wang,Chunyang Liu,Kehua Sheng,Bo Zhang,Yan Wang*

Main category: cs.CV

TL;DR: Semore是一个基于视觉语言模型的强化学习框架，通过双路径骨干网络同时提取语义和运动表示，利用VLM的常识知识增强表征能力，在视觉RL任务中表现优于现有方法。

- Motivation: 现有基于LLM的强化学习方法主要关注控制策略的指导，但受限于骨干网络的表征能力不足。为了解决这个问题，作者提出利用视觉语言模型的常识知识来增强表征学习，从而提升视觉强化学习的性能。
- Method: 提出Semore框架：1）使用双路径骨干网络从RGB流中同时提取语义和运动表示；2）利用VLM的常识知识从观测中提取关键信息；3）使用预训练的CLIP实现文本-图像对齐，将真实表征嵌入骨干网络；4）采用分离监督方法同时指导语义和运动提取，并允许它们自发交互。
- Result: 大量实验表明，在特征层面使用VLM指导的方法相比现有最先进方法展现出高效和自适应的能力。代码已开源。
- Conclusion: Semore框架通过结合VLM的常识知识和双路径表征学习，有效解决了现有LLM-based RL方法的表征限制问题，在视觉强化学习中实现了更好的性能。


### [12] [Your Latent Mask is Wrong: Pixel-Equivalent Latent Compositing for Diffusion Models](https://arxiv.org/abs/2512.05198)
*Rowan Bradbury,Dazhi Zhong*

Main category: cs.CV

TL;DR: 提出像素等效潜在合成(PELC)原则，通过DecFormer实现扩散模型中与像素空间一致的潜在融合，解决传统线性插值导致的接缝伪影和颜色偏移问题。

- Motivation: 当前扩散模型中的潜在修复主要依赖在降采样掩码下对VAE潜在进行线性插值，这种方法无法实现像素等效的合成，导致掩码边缘出现大伪影、全局质量下降和颜色偏移。
- Method: 提出像素等效潜在合成(PELC)原则，开发DecFormer（7.7M参数transformer），预测每通道混合权重和离流形残差校正，实现掩码一致的潜在融合，确保解码后与像素空间alpha合成匹配。
- Result: 在FLUX.1系列上，DecFormer恢复全局颜色一致性、支持软掩码、保持锐利边界和高保真掩码，边缘误差指标比标准掩码插值降低达53%；作为修复先验，轻量LoRA达到与完全微调修复模型相当的质量。
- Conclusion: PELC为像素等效潜在编辑提供通用方案，DecFormer兼容现有扩散流程，无需主干微调，参数量仅增加0.07%，计算开销增加3.5%，显著提升潜在合成质量。


### [13] [DEAR: Dataset for Evaluating the Aesthetics of RenderingDEAR: Dataset for Evaluating the Aesthetics of Rendering](https://arxiv.org/abs/2512.05209)
*Vsevolod Plohotnuk,Artyom Panshin,Nikola Banić,Simone Bianco,Michael Freeman,Egor Ershov*

Main category: cs.CV

TL;DR: 提出了首个基于人类主观偏好的图像渲染美学评估数据集DEAR，用于超越传统失真评估的美学风格偏好建模

- Motivation: 传统图像质量评估主要关注噪声、模糊、压缩伪影等技术失真，而渲染美学评估（如摄影编辑、内容创作、AI生成图像）因缺乏反映主观风格偏好的数据集而研究不足
- Method: 基于MIT-Adobe FiveK数据集构建DEAR数据集，通过大规模众包收集成对图像的人类偏好评分，每对图像由25名评估者评分，总计13,648名参与者，共收集13,648个评估
- Result: 创建了首个系统性地基于人类主观偏好的图像渲染美学评估数据集，包含细粒度、上下文敏感的美学偏好标注，支持风格偏好预测、美学基准测试和个性化美学建模
- Conclusion: DEAR填补了图像渲染美学评估数据集的空白，为超越传统失真评估的美学风格偏好建模提供了基础，数据集子集已在HuggingFace发布


### [14] [IE2Video: Adapting Pretrained Diffusion Models for Event-Based Video Reconstruction](https://arxiv.org/abs/2512.05240)
*Dmitrii Torbunov,Onur Okuducu,Yi Huang,Odera Dim,Rebecca Coles,Yonggang Cui,Yihui Ren*

Main category: cs.CV

TL;DR: 提出混合捕获范式：结合稀疏RGB关键帧和连续事件流，离线重建完整RGB视频，降低功耗同时保持标准视频输出

- Motivation: 传统RGB摄像头功耗高，事件摄像头功耗低但输出异步事件流而非标准视频。需要一种既能降低功耗又能生成标准视频的解决方案
- Method: 提出IE2Video任务：从单个初始帧和后续事件数据重建RGB视频。研究两种架构：1）基于自回归模型（HyperE2VID）的RGB生成；2）通过学习编码器和低秩适配将事件表示注入预训练文本到视频扩散模型（LTX）
- Result: 基于扩散的方法比自回归基线感知质量提升33%（LPIPS 0.283 vs 0.422）。在三个事件摄像头数据集（BS-ERGB、HS-ERGB远/近）上验证，不同序列长度（32-128帧）下均表现良好，展示强大的跨数据集泛化能力
- Conclusion: 混合捕获范式能显著降低功耗，同时通过事件数据重建高质量RGB视频。基于扩散的方法在视频重建质量上优于自回归方法，具有良好的泛化性能


### [15] [Age-Inclusive 3D Human Mesh Recovery for Action-Preserving Data Anonymization](https://arxiv.org/abs/2512.05259)
*Georgios Chatzichristodoulou,Niki Efthymiou,Panagiotis Filntisis,Georgios Pavlakos,Petros Maragos*

Main category: cs.CV

TL;DR: AionHMR：首个能同时准确建模成人、儿童和婴儿的3D人体形状与姿态估计框架，通过引入SMPL-A身体模型和生成伪标注数据，实现了年龄包容的实时3D重建，并创建了隐私保护的3D-BabyRobot数据集。

- Motivation: 现有3D人体形状与姿态估计方法在成人数据上表现良好，但无法有效泛化到儿童和婴儿群体，存在明显的领域差距。需要开发能够同时准确建模不同年龄群体的方法。
- Method: 1. 提出基于优化的方法，扩展现有最佳模型，引入SMPL-A身体模型以同时建模成人、儿童和婴儿；2. 为公开的儿童和婴儿图像数据库生成伪地面真值标注；3. 基于新训练数据开发专门的基于transformer的深度学习模型，实现实时3D年龄包容人体重建。
- Result: 实验表明，该方法显著提高了儿童和婴儿的形状与姿态估计精度，同时不损害成人数据的准确性。重建的网格可作为原始图像的隐私保护替代品，保留动作、姿态和几何信息，支持匿名数据集发布。
- Conclusion: AionHMR填补了3D人体建模中的关键领域差距，为包容性、隐私保护和年龄多样化的3D人体建模奠定了基础，并展示了3D-BabyRobot数据集的实际应用价值。


### [16] [CARD: Correlation Aware Restoration with Diffusion](https://arxiv.org/abs/2512.05268)
*Niki Nezakati,Arnab Ghosh,Amit Roy-Chowdhury,Vishwanath Saragadam*

Main category: cs.CV

TL;DR: CARD提出了一种无需训练的方法来处理图像恢复中的空间相关噪声，通过噪声白化和改进的扩散更新步骤，在相关噪声数据集上优于现有方法。

- Motivation: 现有扩散模型通常假设噪声是独立同分布的高斯噪声，但真实传感器（如滚动快门传感器）会产生空间相关噪声，这限制了现有方法在实际应用中的效果。
- Method: CARD首先对噪声观测进行白化处理，将相关噪声转换为独立同分布形式，然后用噪声白化更新步骤替换扩散恢复步骤，继承了DDRM的闭式采样效率。
- Result: 在合成相关噪声的标准基准测试和新的CIN-D数据集上，CARD在去噪、去模糊和超分辨率任务中始终优于现有方法。
- Conclusion: CARD通过显式处理相关高斯噪声，扩展了扩散模型在图像恢复中的应用，并提供了CIN-D数据集填补了真实相关噪声评估的空白。


### [17] [Inferring Compositional 4D Scenes without Ever Seeing One](https://arxiv.org/abs/2512.05272)
*Ahmet Berke Gokmen,Ajad Chhatkuli,Luc Van Gool,Danda Pani Paudel*

Main category: cs.CV

TL;DR: COM4D是一种从单目视频重建完整4D场景的方法，能够同时预测多个静态和动态物体的结构和时空配置，无需4D组合训练数据。

- Motivation: 现实世界场景通常包含多个静态和动态物体，但现有方法往往只能处理单个物体，且依赖类别特定的参数化形状模型，导致场景配置不一致且受限于建模类别。
- Method: 通过精心设计的空间和时间注意力机制训练，将学习解耦为：从物体组合学习空间关系，以及从单物体动态学习时间关系。提出注意力混合机制，在推理时结合独立学习的注意力，无需4D组合示例。
- Result: 能够从单目视频重建完整且持久的4D场景，包含多个交互物体。在4D物体重建和组合3D重建等单独问题上也取得了最先进的结果。
- Conclusion: COM4D提供了一种数据驱动的方法，能够一致地联合预测4D/3D物体的结构和时空配置，避免了现有方法的局限性，实现了真实世界场景的4D重建。


### [18] [From Segments to Scenes: Temporal Understanding in Autonomous Driving via Vision-Language Model](https://arxiv.org/abs/2512.05277)
*Kevin Cannons,Saeed Ranjbar Alvar,Mohammad Asiful Hossain,Ahmad Rezaei,Mohsen Gholami,Alireza Heidarikhazaei,Zhou Weimin,Yong Zhang,Mohammad Akbari*

Main category: cs.CV

TL;DR: 本文提出了自动驾驶领域首个专注于时序理解的基准测试TAD，包含近6000个问答对，涵盖7个任务。现有SOTA模型在该基准上表现不佳，作者提出了两种无需训练的解决方案（Scene-CoT和TCogMap），将平均准确率提升高达17.72%。

- Motivation: 自动驾驶中的时序理解是一个重大挑战，现有VLMs在这方面表现不足。虽然已有一些时序推理的数据集和基准，但都侧重于体育、烹饪、电影等其他视频内容，缺乏专门针对自动驾驶第一视角视频独特挑战的基准测试。
- Method: 1. 创建TAD基准：包含近6000个问答对，涵盖7个人工设计的任务，专门评估VLMs在自动驾驶场景中捕捉动态动作关系的能力。
2. 评估9个开源和闭源通用模型以及SOTA自动驾驶专用模型。
3. 提出两种无需训练的解决方案：Scene-CoT（利用思维链）和TCogMap（融入第一视角时序认知地图）。
- Result: 1. 当前SOTA模型在TAD基准上表现不佳，主要原因是细粒度运动理解不完善。
2. 提出的Scene-CoT和TCogMap方法与现有VLMs集成后，在TAD上的平均准确率提升了高达17.72%。
- Conclusion: 通过引入TAD基准、评估多个SOTA模型并提出有效的增强方法，这项工作旨在推动自动驾驶时序理解的未来研究。基准测试和评估代码已开源。


### [19] [SpaceControl: Introducing Test-Time Spatial Control to 3D Generative Modeling](https://arxiv.org/abs/2512.05343)
*Elisabetta Fedele,Francis Engelmann,Ian Huang,Or Litany,Marc Pollefeys,Leonidas Guibas*

Main category: cs.CV

TL;DR: SpaceControl：无需训练的测试时方法，通过几何输入（从简单图元到精细网格）实现对3D生成的空间控制，在几何保真度和输出真实感之间提供可控权衡。

- Motivation: 当前3D生成方法主要依赖文本或图像提示，但存在几何特异性不足的问题：语言描述模糊，图像编辑繁琐。需要一种能够提供直观精确几何控制的方法。
- Method: SpaceControl是一种无需训练的测试时方法，接受广泛的几何输入（从粗略图元到详细网格），与预训练生成模型无缝集成，通过可控参数在几何保真度和输出真实感之间进行权衡。
- Result: 广泛的定量评估和用户研究表明，SpaceControl在几何忠实度方面优于基于训练和优化的基线方法，同时保持高视觉质量。提供了交互式用户界面，支持超二次曲面的在线编辑和直接转换为纹理3D资产。
- Conclusion: SpaceControl通过几何输入实现了对3D生成的精确空间控制，无需额外训练，在几何保真度和视觉质量之间取得了良好平衡，为创意工作流程提供了实用工具。


### [20] [SplatPainter: Interactive Authoring of 3D Gaussians from 2D Edits via Test-Time Training](https://arxiv.org/abs/2512.05354)
*Yang Zheng,Hao Tan,Kai Zhang,Peng Wang,Leonidas Guibas,Gordon Wetzstein,Wang Yifan*

Main category: cs.CV

TL;DR: 提出了一种用于3D高斯资产交互式编辑的快速前馈模型，支持从2D视图进行连续编辑，包括局部细节细化、局部绘制和全局重新着色等任务。

- Motivation: 3D高斯溅射技术虽然革新了3D资产创建，但缺乏交互式精修和编辑能力。现有基于扩散或优化的方法速度慢、会破坏原始资产特性，且缺乏细粒度控制精度。
- Method: 提出一种状态感知的前馈模型，直接预测紧凑、特征丰富的高斯表示属性的更新，并利用测试时训练创建状态感知的迭代工作流程。
- Result: 该方法能够以交互速度执行多种任务，包括高保真局部细节细化、局部绘制和一致的全局重新着色，为流畅直观的3D内容创作铺平道路。
- Conclusion: 该方法填补了3D高斯资产交互式编辑的空白，通过单一架构实现多样化的编辑任务，为3D内容创作提供了更直观高效的工具。


### [21] [Group Orthogonal Low-Rank Adaptation for RGB-T Tracking](https://arxiv.org/abs/2512.05359)
*Zekai Shao,Yufan Hu,Jingyuan Liu,Bin Fan,Hongmin Liu*

Main category: cs.CV

TL;DR: 提出GOLA框架，通过组正交低秩适应解决RGB-T跟踪中参数高效微调存在的秩空间冗余问题，提升特征表示能力

- Motivation: 现有参数高效微调方法在RGB-T跟踪中存在秩空间冗余问题，许多秩几乎不提供实用信息，限制了模型学习多样化知识应对各种挑战的能力
- Method: 提出组正交低秩适应(GOLA)框架：1) 使用奇异值分解量化秩重要性；2) 冻结关键秩保留预训练先验；3) 将冗余秩聚类分组；4) 设计组间正交约束策略，强制组间学习互补特征
- Result: 在四个基准数据集上显著优于现有最先进方法，有效减少参数冗余并增强特征表示能力
- Conclusion: GOLA框架通过结构化参数学习和正交约束，有效解决了RGB-T跟踪中低秩适应的冗余问题，提升了模型适应多样化挑战的能力


### [22] [PoolNet: Deep Learning for 2D to 3D Video Process Validation](https://arxiv.org/abs/2512.05362)
*Sanchit Kaul,Joseph Luna,Shray Arora*

Main category: cs.CV

TL;DR: PoolNet是一个深度学习框架，用于评估图像数据是否适合SfM处理，能快速区分可处理与不可处理的场景，显著减少传统SfM算法的时间消耗。

- Motivation: 传统SfM处理序列和非序列图像数据耗时且计算成本高，同时大量公开数据因相机姿态变化不足、场景元素遮挡和噪声数据等问题而不适合处理。
- Method: 提出PoolNet深度学习框架，支持帧级和场景级的野外数据验证，通过深度学习模型评估图像数据是否适合SfM处理。
- Result: 模型成功区分适合SfM处理的场景与不适合的场景，同时显著减少了获取SfM数据所需的时间，相比最先进算法大幅降低了处理时间。
- Conclusion: PoolNet为解决SfM数据处理中的效率和质量问题提供了有效的深度学习解决方案，能够快速筛选适合处理的图像数据，提高SfM处理的整体效率。


### [23] [ShaRP: SHAllow-LayeR Pruning for Video Large Language Models Acceleration](https://arxiv.org/abs/2512.05385)
*Yingjie Xia,Tao Liu,Jinglei Shi,Qingsong Xie,Heng Guo,Jian Yang,Xi Wang*

Main category: cs.CV

TL;DR: ShaRP是一个改进的基于注意力的剪枝框架，用于加速视频大语言模型的推理，通过在浅层解码器实现有效剪枝，同时保持高压缩率下的稳定性能。

- Motivation: 视频大语言模型在预填充阶段面临高计算负载问题，现有基于注意力的剪枝方法在浅层解码器尝试时会导致显著性能下降，特别是在高压缩率下。作者认为注意力剪枝本身具有识别最相关视觉令牌的潜力，但在浅层解码器的有效性受到位置编码偏差和信息交互不足等因素的限制。
- Method: 提出ShaRP框架，集成了三个关键技术：1) 段感知因果掩码，2) 位置去偏，3) 令牌去重。这些技术共同增强了令牌选择能力，使模型能够在浅层实现有效剪枝，且无需重新训练。
- Result: 在多个视频理解基准测试上的广泛实验表明，ShaRP实现了竞争性的性能表现，为加速VLLM推理建立了新的范式。
- Conclusion: ShaRP框架通过集成段感知因果掩码、位置去偏和令牌去重技术，成功解决了注意力剪枝在浅层解码器的局限性，能够在高压缩率下保持稳定性能，为视频大语言模型的高效推理提供了有效解决方案。


### [24] [LoC-Path: Learning to Compress for Pathology Multimodal Large Language Models](https://arxiv.org/abs/2512.05391)
*Qingqiao Hu,Weimin Lyu,Meilong Xu,Kehan Qi,Xiaoling Hu,Saumya Gupta,Jiawei Zhou,Chao Chen*

Main category: cs.CV

TL;DR: LoC-Path是一种高效的病理学全切片图像多模态大语言模型，通过减少冗余特征处理来降低计算成本，同时保持与现有方法相当的性能。

- Motivation: 现有的全切片图像多模态大语言模型采用暴力方式处理数千个图像块特征，计算成本过高，而实际上只有少量图像块与诊断任务真正相关，存在大量冗余特征。
- Method: 提出LoC-Path框架：1) 稀疏令牌合并器和MAE预训练重采样器去除局部冗余并压缩全局冗余令牌；2) 交叉注意力路由适配器和令牌重要性评分器以计算高效方式集成压缩视觉表示与语言模型。
- Result: 实验表明，该方法在性能上与现有最先进的全切片MLLMs相当，同时显著降低了计算和内存需求。
- Conclusion: 通过识别和减少全切片图像中的冗余特征，可以构建更高效的多模态大语言模型，在保持诊断准确性的同时大幅降低计算负担。


### [25] [Delving into Latent Spectral Biasing of Video VAEs for Superior Diffusability](https://arxiv.org/abs/2512.05394)
*Shizhan Liu,Xinran Deng,Zhuoyi Yang,Jiayan Teng,Xiaotao Gu,Jie Tang*

Main category: cs.CV

TL;DR: 提出SSVAE，通过分析视频VAE潜在空间的光谱特性，引入两种正则化方法改善扩散训练效率，实现3倍收敛加速和10%视频质量提升

- Motivation: 现有视频VAE主要关注重建保真度，忽视了潜在空间结构对扩散训练的重要性。研究发现潜在空间的光谱特性（时空频率谱偏向低频、通道特征谱由少数模式主导）对扩散训练效率有重要影响。
- Method: 提出光谱结构VAE（SSVAE），包含两种轻量级、与主干无关的正则化器：局部相关性正则化和潜在掩码重建，以诱导理想的潜在空间光谱特性。
- Result: SSVAE在文本到视频生成中实现3倍收敛加速和10%的视频奖励提升，优于现有的开源VAE模型。
- Conclusion: 通过优化VAE潜在空间的光谱结构，可以显著提升扩散模型的训练效率和生成质量，为视频生成模型设计提供了新思路。


### [26] [The Dynamic Prior: Understanding 3D Structures for Casual Dynamic Videos](https://arxiv.org/abs/2512.05398)
*Zhuoyuan Wu,Xurui Yang,Jiahui Huang,Yue Wang,Jun Gao*

Main category: cs.CV

TL;DR: 提出Dynamic Prior方法，利用视觉语言模型和SAM2分割能力，无需特定训练即可识别动态物体，提升相机位姿估计和3D重建精度

- Motivation: 传统SfM方法在动态物体场景中效果不佳，现有学习方法受限于运动分割数据集规模，导致分割不准确和3D理解能力有限
- Method: 结合视觉语言模型的推理能力和SAM2的细粒度空间分割能力，构建Dynamic Prior来识别动态物体，无需任务特定训练
- Result: 在合成和真实视频上实验表明，该方法在运动分割上达到SOTA，并显著提升相机位姿优化、深度重建和4D轨迹估计的准确性和鲁棒性
- Conclusion: Dynamic Prior通过利用先进视觉语言模型和分割技术，无需特定训练即可有效处理动态场景，为3D理解任务提供强大支持


### [27] [Genetic Algorithms For Parameter Optimization for Disparity Map Generation of Radiata Pine Branch Images](https://arxiv.org/abs/2512.05410)
*Yida Lin,Bing Xue,Mengjie Zhang,Sam Schofield,Richard Green*

Main category: cs.CV

TL;DR: 提出基于遗传算法的SGBM+WLS立体匹配参数优化框架，用于无人机林业应用，自动调参提升精度同时保持处理效率。

- Motivation: 传统SGBM+WLS立体匹配算法在无人机应用中速度快（约0.5秒/帧），但需要繁琐的手动参数调优。无人机林业应用需要精确测量树枝距离，现有方法参数调优困难，影响实际应用效果。
- Method: 提出遗传算法（GA）参数优化框架，系统搜索SGBM和WLS滤波器的最优参数配置。采用多图像质量指标综合评估方法，为资源受限的无人机系统提供实用解决方案。
- Result: 实验结果显示，GA优化方法相比基线配置：均方误差降低42.86%，峰值信噪比提升8.47%，结构相似性提升28.52%。在不同成像条件下表现出优异的泛化性能。
- Conclusion: GA参数优化框架有效解决了传统立体匹配算法的手动调参问题，显著提升了无人机林业应用中树枝距离测量的精度，同时保持了处理效率，具有实际应用价值。


### [28] [YOLO and SGBM Integration for Autonomous Tree Branch Detection and Depth Estimation in Radiata Pine Pruning Applications](https://arxiv.org/abs/2512.05412)
*Yida Lin,Bing Xue,Mengjie Zhang,Sam Schofield,Richard Green*

Main category: cs.CV

TL;DR: 基于YOLO目标检测与SGBM立体视觉的无人机自主修剪系统，无需昂贵LiDAR，实现精确树枝检测与定位

- Motivation: 人工修剪辐射松存在高空作业和复杂地形带来的安全风险，需要开发更安全、高效的自动化修剪方案
- Method: 集成YOLO目标检测与SGBM立体视觉的计算机视觉框架，仅使用立体相机输入进行树枝检测和深度估计
- Result: YOLO在树枝分割上达到82.0% mAPmask50-95，优于Mask R-CNN；系统在2米操作范围内准确定位树枝，单帧处理时间小于1秒
- Conclusion: 该系统证明了低成本自主修剪系统的可行性，能显著提高林业作业的安全性和操作效率


### [29] [Moving object detection from multi-depth images with an attention-enhanced CNN](https://arxiv.org/abs/2512.05415)
*Masato Shibukawa,Fumi Yoshida,Toshifumi Yanagisawa,Takashi Ito,Hirohisa Kurosaki,Makoto Yoshikawa,Kohki Kamiya,Ji-an Jiang,Wesley Fraser,JJ Kavelaars,Susan Benecchi,Anne Verbiscer,Akira Hatakeyama,Hosei O,Naoya Ozaki*

Main category: cs.CV

TL;DR: 提出一种结合卷积块注意力模块的多输入卷积神经网络，用于太阳系移动天体检测，减少人工验证工作量99%以上，准确率达99%

- Motivation: 太阳系移动天体检测面临信号真伪判断的挑战，传统人工验证成本高、效率低，需要减少对人工干预的依赖
- Method: 采用多输入卷积神经网络架构，同时处理多个堆叠图像，并集成卷积块注意力模块，使模型能聚焦空间和通道维度的关键特征
- Result: 在约2000张观测图像数据集上评估，准确率接近99%，AUC>0.99，通过调整检测阈值，人工工作量减少99%以上
- Conclusion: 该方法显著提升了移动天体检测的鲁棒性和效率，极大减少了人工验证需求，实现了优秀的分类性能


### [30] [Performance Evaluation of Deep Learning for Tree Branch Segmentation in Autonomous Forestry Systems](https://arxiv.org/abs/2512.05418)
*Yida Lin,Bing Xue,Mengjie Zhang,Sam Schofield,Richard Green*

Main category: cs.CV

TL;DR: 论文评估了多种深度学习模型在不同分辨率下对树木枝干分割的性能，为嵌入式林业系统提供了精度与效率权衡的基准。

- Motivation: 无人机林业作业需要快速精确的树木枝干分割以确保安全导航和自动化修剪，但现有方法在不同像素分辨率和操作条件下的性能差异尚未系统评估。
- Method: 使用Urban Street Tree数据集，在三种分辨率(256×256, 512×512, 1024×1024)下评估22种深度学习配置，采用标准指标(IoU, Dice)和专门指标(TS-IoU, CPR, Boundary-F1)。
- Result: U-Net+MiT-B4在256×256表现最佳；MiT-B4在512×512的IoU、Dice、TS-IoU和Boundary-F1领先；U-Net+MiT-B3在1024×1024的验证性能最优；PSPNet效率最高但精度有25.7/19.6/11.8个百分点的IoU下降。
- Conclusion: 研究建立了多分辨率基准，为嵌入式林业系统提供了精度与计算效率的权衡参考，PSPNet适合计算受限场景，而U-Net系列在精度要求高时表现更优。


### [31] [ParaUni: Enhance Generation in Unified Multimodal Model with Reinforcement-driven Hierarchical Parallel Information Interaction](https://arxiv.org/abs/2512.05422)
*Jiangtong Tan,Lin Liu,Jie Huanng,Xiaopeng Zhang,Qi Tian,Feng Zhao*

Main category: cs.CV

TL;DR: ParaUni提出了一种并行提取视觉语言模型多层特征的方法，通过层集成模块和层动态调整机制，在统一多模态模型中平衡充分交互与灵活实现，显著提升生成质量。

- Motivation: 现有统一多模态模型难以平衡充分交互与灵活实现，因为视觉语言模型和扩散模型之间存在巨大表示差异。视觉语言模型的多层特征包含从低层细节到高层语义的丰富层次信息，但现有方法未能充分利用这些信息。
- Method: 提出ParaUni方法：1）并行提取视觉语言模型所有层的特征，通过层集成模块（LIM）高效整合细粒度细节和语义抽象，为扩散模型提供融合表示条件；2）设计层动态调整机制（LDAM），利用强化学习中不同层对不同奖励的响应差异，通过RL对齐层的层次特性。
- Result: 实验表明ParaUni能够利用互补的多层特征显著提升生成质量，并在RL阶段展现出多奖励提升的强大潜力。
- Conclusion: ParaUni通过并行特征提取和层动态调整机制，有效解决了统一多模态模型中交互与实现的平衡问题，为视觉生成提供了更优的解决方案。


### [32] [TED-4DGS: Temporally Activated and Embedding-based Deformation for 4DGS Compression](https://arxiv.org/abs/2512.05446)
*Cheng-Yuan Ho,He-Bi Yang,Jui-Chiu Chiang,Yu-Lun Liu,Wen-Hsiao Peng*

Main category: cs.CV

TL;DR: TED-4DGS：一种基于时间激活和嵌入的变形方案，用于动态3D高斯泼溅的率失真优化压缩，在稀疏锚点表示上实现高效时空控制。

- Motivation: 现有动态3DGS方法存在缺陷：4DGS方法使用过参数化的短寿命高斯基元，而规范3DGS方法缺乏明确的时间控制。需要设计更紧凑高效的变形方案和率失真优化压缩策略。
- Method: 基于稀疏锚点的3DGS表示，每个规范锚点分配可学习的时间激活参数控制出现/消失，轻量级每锚点时间嵌入查询共享变形库生成锚点特定变形。采用INR超先验建模锚点属性分布，通道自回归模型捕获锚点内相关性。
- Result: 在多个真实世界数据集上实现了最先进的率失真性能，是首批追求动态3DGS表示率失真优化压缩框架的尝试之一。
- Conclusion: TED-4DGS统一了4DGS和规范3DGS的优势，通过时间激活和嵌入变形方案实现了高效的动态场景表示和压缩，为动态3DGS压缩开辟了新方向。


### [33] [University Building Recognition Dataset in Thailand for the mission-oriented IoT sensor system](https://arxiv.org/abs/2512.05468)
*Takara Taniguchi,Yudai Ueda,Atsuya Muramatsu,Kohki Hashimoto,Ryo Yagi,Hideya Ochiai,Chaodit Aswakul*

Main category: cs.CV

TL;DR: 该论文提出了专门针对朱拉隆功大学的建筑识别数据集CUBR，用于无线自组织联邦学习中的视觉Transformer训练，实验表明WAFL场景下的训练效果优于自训练场景。

- Motivation: 随着边缘设备性能提升，边缘训练成为趋势。无线自组织联邦学习（WAFL）特别是WAFL-ViT在图像识别任务中显示出潜力，但需要针对具体任务构建专用数据集。作者针对泰国朱拉隆功大学开发专门的建筑识别数据集。
- Method: 开发了朱拉隆功大学建筑识别数据集（CUBR），作为WAFL-ViT系统的专用数据集。使用无线自组织联邦学习框架进行视觉Transformer训练，并与自训练场景进行对比实验。
- Result: CUBR数据集已公开可用。实验结果表明，在WAFL场景下的训练比自训练场景获得更高的准确率，验证了WAFL-ViT在边缘设备协作学习中的优势。
- Conclusion: 针对特定任务构建专用数据集对于WAFL-ViT等任务导向型传感器系统至关重要。CUBR数据集为泰国朱拉隆功大学的建筑识别提供了专门资源，同时证明了WAFL在边缘设备协作学习中的有效性。


### [34] [EmoStyle: Emotion-Driven Image Stylization](https://arxiv.org/abs/2512.05478)
*Jingyuan Yang,Zihuan Bai,Hui Huang*

Main category: cs.CV

TL;DR: EmoStyle：一种情感驱动的图像风格化框架，通过构建数据集、情感内容推理器和风格量化器，实现艺术风格与特定情感的结合，同时保持内容一致性。

- Motivation: 现有图像风格化方法主要关注视觉外观转换，但忽略了艺术风格所承载的情感影响。为了填补这一空白，研究者提出了情感图像风格化任务，旨在应用艺术风格来唤起特定情感，同时保持内容完整性。
- Method: 1. 构建EmoStyleSet数据集：从ArtEmis中提取内容-情感-风格化图像三元组；2. 设计情感内容推理器：自适应整合情感线索与内容，学习连贯的风格查询；3. 开发风格量化器：将连续风格特征转换为与情感相关的码本条目。
- Result: 定性和定量评估（包括用户研究）表明，EmoStyle在保持内容一致性的同时增强了情感表达能力。学习到的情感感知风格字典可适应其他生成任务，显示出更广泛应用的潜力。
- Conclusion: 该研究为情感驱动的图像风格化奠定了基础，扩展了AI生成艺术的创作潜力，建立了艺术风格与情感表达之间的有效映射机制。


### [35] [UniFS: Unified Multi-Contrast MRI Reconstruction via Frequency-Spatial Fusion](https://arxiv.org/abs/2512.05481)
*Jialin Li,Yiwei Ren,Kai Pan,Dong Wei,Pujin Cheng,Xian Wu,Xiaoying Tang*

Main category: cs.CV

TL;DR: UniFS是一个统一频率-空间融合模型，用于多对比度MR重建，能够处理多种k空间欠采样模式而无需重新训练。

- Motivation: 现有多对比度MR重建方法通常需要为每种k空间欠采样模式单独训练模型，缺乏泛化能力；同时这些方法要么只关注空间信息而忽略频率特征，要么只提取浅层频率特征，未能充分利用跨模态频率互补信息。
- Method: 提出UniFS模型，包含三个关键模块：跨模态频率融合模块、基于自适应掩码的提示学习模块、双分支互补细化模块。通过自适应提示引导的频率融合进行k空间学习，提取域不变特征并动态适应不同欠采样模式。
- Result: 在BraTS和HCP数据集上，针对多种k空间欠采样模式和加速因子（包括未见过的模式）进行测试，UniFS在多种场景下均实现了最先进的性能。
- Conclusion: UniFS能够有效处理多种k空间欠采样模式而无需重新训练，通过频率-空间融合显著提升了模型的泛化能力，为多对比度MR重建提供了实用的解决方案。


### [36] [Concept-based Explainable Data Mining with VLM for 3D Detection](https://arxiv.org/abs/2512.05482)
*Mai Tsujimoto*

Main category: cs.CV

TL;DR: 提出跨模态框架，利用2D视觉语言模型从驾驶场景中挖掘稀有对象，提升3D物体检测性能，显著减少标注负担

- Motivation: 自动驾驶系统中基于点云数据的稀有物体检测具有挑战性，视觉语言模型在图像理解方面表现出色，但其通过智能数据挖掘增强3D物体检测的潜力尚未充分探索
- Method: 提出跨模态框架，结合物体检测、语义特征提取、降维和多方面异常检测技术，使用隔离森林和t-SNE异常检测方法配合基于概念的过滤，系统识别驾驶场景中的稀有关键物体
- Result: 在nuScenes数据集上的实验表明，该概念引导的数据挖掘策略提升了3D物体检测模型性能，仅使用少量训练数据，在拖车和自行车等挑战性类别上相比随机数据有显著改进
- Conclusion: 该方法能有效提取和标注目标稀有物体概念，大幅减少标注负担，仅关注最有价值的训练样本，对安全关键自动驾驶系统的数据集高效管理具有重要意义


### [37] [WaterWave: Bridging Underwater Image Enhancement into Video Streams via Wavelet-based Temporal Consistency Field](https://arxiv.org/abs/2512.05492)
*Qi Zhu,Jingyi Zhang,Naishan Zheng,Wei Yu,Jinghao Zhang,Deyi Ji,Feng Zhao*

Main category: cs.CV

TL;DR: 提出WaterWave方法，通过小波域时域一致性场增强水下视频，解决单帧增强方法缺乏时域一致性的问题

- Motivation: 水下视频对难以获取，现有方法通常将单帧增强模型逐帧应用，但缺乏时域一致性。从局部时域频率角度观察动态场景中的时域一致性先验
- Method: 基于小波的时域一致性场隐式表示方法，在时域一致性先验约束下渐进过滤不一致分量，保留运动细节。设计水下流校正模块修正估计的光流
- Result: 显著提升单帧水下增强方法生成的视频质量，在下游水下跟踪任务（UOSTrack和MAT）中表现优异，精度分别提升19.7%和9.7%
- Conclusion: WaterWave方法有效解决了水下视频增强中的时域一致性问题，通过时域频率分析和流校正实现了自然流畅的视频增强效果


### [38] [Decoding with Structured Awareness: Integrating Directional, Frequency-Spatial, and Structural Attention for Medical Image Segmentation](https://arxiv.org/abs/2512.05494)
*Fan Zhang,Zhiwei Gu,Hua Wang*

Main category: cs.CV

TL;DR: 提出新型医学图像分割解码器框架，包含三个核心模块：ACFA增强关键区域响应，TFFA融合多域特征，SMMM优化跳跃连接，显著提升分割精度和泛化能力。

- Motivation: 针对Transformer解码器在边缘细节捕捉、局部纹理识别和空间连续性建模方面的局限性，需要专门为医学图像分割设计更有效的解码器框架。
- Method: 提出包含三个核心模块的解码器框架：1) ACFA模块集成通道特征增强和空间注意力机制，引入可学习的平面、水平和垂直方向指导；2) TFFA模块融合空间、傅里叶和小波域特征，实现联合频率-空间表示；3) SMMM模块利用多尺度上下文和结构显著性过滤优化编码器-解码器跳跃连接。
- Result: 实验结果表明该框架有效解决了传统解码器的不足，在肿瘤分割和器官边界提取等高精度任务中显著提升了分割精度和模型泛化能力。
- Conclusion: 该框架为医学图像分割提供了高效实用的解决方案，通过三个协同工作的模块显著增强了边缘细节捕捉、局部纹理识别和空间连续性建模能力。


### [39] [Rethinking Infrared Small Target Detection: A Foundation-Driven Efficient Paradigm](https://arxiv.org/abs/2512.05511)
*Chuang Yu,Jinmiao Zhao,Yunpeng Liu,Yaokun Li,Xiujun Shu,Yuanhao Feng,Bo Wang,Yimian Dai,Xiangyu Yue*

Main category: cs.CV

TL;DR: 首次将视觉基础模型引入红外小目标检测，提出FDEP框架，通过语义对齐融合模块和协作优化蒸馏策略，在零额外推理开销下显著提升现有方法性能

- Motivation: 大规模视觉基础模型在多种视觉任务上展现强大泛化能力，但其在单帧红外小目标检测领域的潜力尚未被充分探索。现有方法面临语义信息不足和推理效率的平衡问题
- Method: 提出FDEP框架：1) SAMF模块实现视觉基础模型全局语义先验与任务特征的动态对齐和深度融合；2) CO-ISD策略通过参数共享和同步反向传播实现主分支与轻量分支间的隐式语义蒸馏；3) HSE指标提供像素级置信度和目标级鲁棒性的多阈值积分评估
- Result: 在多个公开数据集上，配备FDEP框架的SIRST检测网络达到最先进的性能，且不增加额外推理开销。代码已开源
- Conclusion: FDEP框架成功将视觉基础模型的知识迁移到红外小目标检测任务，通过语义对齐融合和协作优化蒸馏实现了精度提升与效率平衡，为领域提供了统一的评估标准


### [40] [Know-Show: Benchmarking Video-Language Models on Spatio-Temporal Grounded Reasoning](https://arxiv.org/abs/2512.05513)
*Chinthani Sugandhika,Chen Li,Deepu Rajan,Basura Fernando*

Main category: cs.CV

TL;DR: Know-Show是一个评估视频语言模型时空基础推理能力的新基准，包含五个场景和2500个人工编写的问题，揭示了当前模型与人类推理的显著差距，并提出了GRAM训练免费插件来增强细粒度基础能力。

- Motivation: 当前大型视频语言模型在多模态理解方面取得了显著进展，但其推理在空间和时间上的基础性仍然较弱。需要评估模型在推理动作及其语义的同时，能否将其推断基于视觉和时间证据的能力。
- Method: 提出了Know-Show基准，统一了推理和定位在单一评估框架中，包含空间（人物、物体、人物-物体、手-物体）和时间维度的五个互补场景。基于Charades、Action Genome和Ego4D数据集构建了2500个人工编写的问题。同时提出了GRAM训练免费插件，通过基于注意力的视频令牌选择和显式时间戳编码来增强视频语言模型的细粒度基础能力。
- Result: 实验表明，现有模型（包括Qwen、VideoLLaVA、GPT-4o和Gemini等）在"展示所知"方面存在困难，特别是在细粒度的手-物体交互中。Know-Show揭示了当前视频语言模型与人类推理之间的显著差距。
- Conclusion: Know-Show为评估视频语言理解中的基础推理建立了统一标准，并为开发可解释和可靠的多模态推理系统提供了见解。GRAM插件能够有效增强模型的细粒度基础能力，代码将公开发布。


### [41] [DashFusion: Dual-stream Alignment with Hierarchical Bottleneck Fusion for Multimodal Sentiment Analysis](https://arxiv.org/abs/2512.05515)
*Yuhua Wen,Qifei Li,Yingying Zhou,Yingming Gao,Zhengqi Wen,Jianhua Tao,Ya Li*

Main category: cs.CV

TL;DR: DashFusion提出了一种双流对齐与分层瓶颈融合框架，通过时间对齐、语义对齐和监督对比学习解决多模态情感分析中的对齐和融合问题，在多个数据集上达到SOTA性能。

- Motivation: 多模态情感分析面临对齐和融合两大挑战：对齐需要跨模态的时间与语义同步，融合需要将对齐特征整合为统一表示。现有方法往往单独处理对齐或融合，导致性能与效率受限。
- Method: 1. 双流对齐模块：时间对齐使用跨模态注意力建立帧级对应关系；语义对齐通过对比学习确保特征空间一致性。2. 监督对比学习：利用标签信息精炼模态特征。3. 分层瓶颈融合：通过压缩瓶颈token渐进式整合多模态信息，平衡性能与计算效率。
- Result: 在CMU-MOSI、CMU-MOSEI和CH-SIMS三个数据集上，DashFusion在各种指标上均达到最先进的性能，消融研究证实了对齐和融合技术的有效性。
- Conclusion: DashFusion通过统一处理对齐和融合问题，有效解决了多模态情感分析中的关键挑战，在保持计算效率的同时实现了卓越性能。


### [42] [VOST-SGG: VLM-Aided One-Stage Spatio-Temporal Scene Graph Generation](https://arxiv.org/abs/2512.05524)
*Chinthani Sugandhika,Chen Li,Deepu Rajan,Basura Fernando*

Main category: cs.CV

TL;DR: VOST-SGG：一种基于视觉语言模型的单阶段时空场景图生成框架，通过双源查询初始化和多模态特征库解决现有方法中查询语义信息不足和仅依赖视觉特征的问题，在Action Genome数据集上达到SOTA性能。

- Motivation: 现有DETR风格的单阶段ST-SGG模型存在两个主要问题：1）可学习查询是语义无信息和实例无关初始化的；2）仅依赖单模态视觉特征进行谓词分类。需要利用视觉语言模型的常识推理能力来增强ST-SGG的性能。
- Method: 提出VOST-SGG框架：1）双源查询初始化策略，将"关注什么"与"在哪里关注"解耦，实现语义基础化的what-where推理；2）多模态特征库，融合来自VLM的视觉、文本和空间线索，改进谓词分类。
- Result: 在Action Genome数据集上的大量实验表明，该方法实现了最先进的性能，验证了集成VLM辅助语义先验和多模态特征对ST-SGG的有效性。
- Conclusion: VOST-SGG成功地将VLM的常识推理能力整合到ST-SGG流程中，通过语义基础化的查询初始化和多模态特征融合，显著提升了时空场景图生成的性能。


### [43] [See in Depth: Training-Free Surgical Scene Segmentation with Monocular Depth Priors](https://arxiv.org/abs/2512.05529)
*Kunyi Yang,Qingyu Wang,Cheng Yuan,Yutong Ban*

Main category: cs.CV

TL;DR: 提出DepSeg框架，利用深度作为几何先验结合预训练视觉基础模型，实现免训练的手术场景分割，显著提升分割性能

- Motivation: 腹腔镜场景的像素级分割对计算机辅助手术至关重要，但由于密集标注成本高昂而难以扩展。需要一种标注高效的解决方案。
- Method: DepSeg框架：1) 使用预训练单目深度估计网络获取相对深度图；2) 提出深度引导的点提示，SAM2将其转换为类别无关掩码；3) 通过预训练视觉特征池化描述每个掩码；4) 通过模板匹配对模板库中的标注帧进行分类
- Result: 在CholecSeg8k数据集上，DepSeg显著优于直接SAM2自动分割基线（35.9% vs. 14.7% mIoU），即使仅使用10-20%的对象模板仍保持竞争力
- Conclusion: 深度引导提示和基于模板的分类提供了一种标注高效的分割方法，证明了深度作为几何先验与预训练视觉基础模型结合的有效性


### [44] [Ideal Observer for Segmentation of Dead Leaves Images](https://arxiv.org/abs/2512.05539)
*Swantje Mahncke,Malte Ott*

Main category: cs.CV

TL;DR: 提出基于"枯叶模型"的贝叶斯理想观察者方法，用于图像分割任务的理论框架

- Motivation: 人类视觉环境由空间分布的不同表面组成，物体间的遮挡关系决定了场景可见部分。需要建立能模拟这种遮挡关系的生成模型来研究图像分割问题。
- Method: 基于枯叶模型（物体位置、形状、颜色和纹理分布的生成模型），推导贝叶斯理想观察者方法，计算给定像素集分割的后验概率，并分析实际应用的可行性因素。
- Result: 建立了枯叶图像模型和相关理想观察者理论框架，可用于研究有限像素下的分割决策，为人类和视觉算法提供性能上限的基准。
- Conclusion: 枯叶模型和贝叶斯理想观察者方法为图像分割研究提供了理论基准，可用于比较人类视觉和计算机视觉算法的性能。


### [45] [Conscious Gaze: Adaptive Attention Mechanisms for Hallucination Mitigation in Vision-Language Models](https://arxiv.org/abs/2512.05546)
*Weijue Bu,Guan Yuan,Guixian Zhang*

Main category: cs.CV

TL;DR: CG-VLM是一个无需训练的推理时框架，通过博弈论可解释性实现解码控制，解决大视觉语言模型中的文本惯性问题，在多个基准测试中达到SOTA。

- Motivation: 大视觉语言模型存在文本惯性问题，注意力从视觉证据漂移到语言先验，导致物体幻觉。现有方法只在输出logits层面干预，无法纠正内部推理漂移，而基于启发式头部抑制或全局导向向量的内部控制方法缺乏理论基础。
- Method: 提出Conscious Gaze框架：1）基于Harsanyi交互的认知需求传感器估计瞬时视觉-文本协同作用，识别需要视觉接地的时刻；2）聚焦共识归纳模块在注意力崩溃到文本先验之前，选择性地将中间层注意力重新导向视觉token。
- Result: 在POPE和CHAIR基准测试上，CG-VLM在InstructBLIP、LLaVA、Qwen-VL和mPLUG等模型上达到最先进结果，同时保持通用能力。
- Conclusion: CG-VLM证明token级感知能够实现精确、上下文感知的干预，而不损害基础知识，为视觉语言模型的推理控制提供了理论基础。


### [46] [2K-Characters-10K-Stories: A Quality-Gated Stylized Narrative Dataset with Disentangled Control and Sequence Consistency](https://arxiv.org/abs/2512.05557)
*Xingxi Yin,Yicheng Li,Gong Yan,Chenglin Li,Jian Zhao,Cong Huang,Yue Deng,Yin Zhang*

Main category: cs.CV

TL;DR: 提出了2K-Characters-10K-Stories数据集，首个大规模分离控制信号的可视化叙事数据集，通过解耦控制方案实现序列身份一致性

- Motivation: 现有数据集缺乏足够的保真度，未能将稳定身份与瞬态属性分离，限制了姿势、表情和场景组合的结构化控制，从而制约了可靠的序列合成
- Method: 1) 构建2K-Characters-10K-Stories多模态风格化叙事数据集；2) 采用Human-in-the-Loop管道，结合专家验证的角色模板和LLM引导的叙事规划；3) 解耦控制方案分离持久身份与瞬态属性；4) 质量门控循环集成MMLM评估、自动提示调整和局部图像编辑
- Result: 在该数据集上微调的模型在生成视觉叙事方面达到与闭源模型相当的性能
- Conclusion: 提出的数据集和方法有效解决了序列身份一致性控制问题，为可控视觉叙事提供了高质量的结构化数据支持


### [47] [ProPhy: Progressive Physical Alignment for Dynamic World Simulation](https://arxiv.org/abs/2512.05564)
*Zijun Wang,Panwen Hu,Jing Wang,Terry Jingchen Zhang,Yuhao Cheng,Long Chen,Yiqiang Yan,Zutao Jiang,Hanhui Li,Xiaodan Liang*

Main category: cs.CV

TL;DR: ProPhy是一个渐进式物理对齐框架，通过两阶段物理专家混合机制实现物理感知的视频生成，解决了现有方法在物理一致性方面的不足。

- Motivation: 当前视频生成模型在处理大规模或复杂动态时难以产生物理一致的结果，主要因为现有方法对物理提示做出各向同性响应，忽视了生成内容与局部物理线索之间的细粒度对齐。
- Method: 提出ProPhy框架，采用两阶段物理专家混合机制：语义专家从文本描述推断语义级物理原理，精炼专家捕捉标记级物理动态。同时引入物理对齐策略，将视觉语言模型的物理推理能力转移到精炼专家中。
- Result: 在物理感知视频生成基准测试上的广泛实验表明，ProPhy比现有最先进方法产生更真实、动态和物理一致的结果。
- Conclusion: ProPhy通过显式的物理感知条件和各向异性生成，实现了更好的物理一致性视频生成，为构建世界模拟器提供了更可靠的解决方案。


### [48] [MedDIFT: Multi-Scale Diffusion-Based Correspondence in 3D Medical Imaging](https://arxiv.org/abs/2512.05571)
*Xingyu Zhang,Anna Reithmeir,Fryderyk Kögl,Rickmer Braren,Julia A. Schnabel,Daniel M. Lang*

Main category: cs.CV

TL;DR: MedDIFT：无需训练的3D医学图像配准框架，利用预训练扩散模型的多尺度特征作为体素描述符，在肺CT数据集上达到与SOTA学习模型相当的性能。

- Motivation: 传统医学图像配准方法依赖局部强度相似性度量，无法捕捉全局语义结构，在低对比度或解剖变异区域容易产生误匹配。需要一种能利用深层语义信息的配准方法。
- Method: MedDIFT利用预训练的潜在医学扩散模型的中间层多尺度特征作为体素描述符，通过余弦相似度进行匹配，可选局部搜索先验。无需任务特定训练。
- Result: 在公开肺CT数据集上，MedDIFT达到与SOTA学习模型UniGradICON相当的配准精度，优于传统B样条配准。消融实验证实多级特征融合和适度扩散噪声能提升性能。
- Conclusion: 扩散模型的中间表示编码了丰富的几何和语义信息，可用于构建有效的体素描述符。MedDIFT展示了预训练扩散模型在医学图像配准中的潜力，无需额外训练即可达到SOTA性能。


### [49] [Learning High-Fidelity Cloth Animation via Skinning-Free Image Transfer](https://arxiv.org/abs/2512.05593)
*Rong Wang,Wei Mao,Changsheng Lu,Hongdong Li*

Main category: cs.CV

TL;DR: 提出一种新的3D服装变形生成方法，通过分离低频形状和高频皱纹估计，利用图像转换和预训练模型提升动画质量

- Motivation: 现有方法依赖线性混合蒙皮处理低频服装形状并回归高频皱纹，但由于缺乏明确的蒙皮监督，在服装变形时经常产生错位形状，从而破坏高频信号并无法恢复高保真皱纹
- Method: 1) 提出无蒙皮方法，独立估计顶点位置（低频形状）和顶点法线（高频皱纹细节）；2) 将顶点属性编码为渲染纹理图像，通过2D图像转换实现3D服装变形；3) 利用预训练图像模型恢复皱纹细节；4) 提出多模态融合结合两种频率约束
- Result: 在各种服装类型上显著提升动画质量，比现有方法恢复更精细的皱纹细节
- Conclusion: 通过解耦频率模态、利用图像转换和预训练模型，实现了高质量、可扩展的3D服装变形生成，无需手动UV分割


### [50] [Fast SceneScript: Accurate and Efficient Structured Language Model via Multi-Token Prediction](https://arxiv.org/abs/2512.05597)
*Ruihong Yin,Xuepeng Shi,Oleksandr Bailo,Marco Manfredi,Theo Gevers*

Main category: cs.CV

TL;DR: Fast SceneScript：基于多令牌预测和置信度引导解码的高效3D场景布局估计结构化语言模型

- Motivation: 现有基于语言模型的感知通用方法在3D场景布局估计等任务上表现优异，但依赖自回归下一个令牌预测导致推理速度慢，需要提高效率
- Method: 采用多令牌预测减少自回归迭代次数，结合自推测解码和置信度引导解码过滤不可靠令牌，设计参数高效机制降低参数开销
- Result: 在ASE和Structured3D基准测试中，Fast SceneScript每次解码推理可生成最多9个令牌而不损失精度，仅增加约7.5%额外参数
- Conclusion: Fast SceneScript通过多令牌预测和置信度引导解码实现了准确且高效的3D场景布局估计，显著提升了推理速度


### [51] [NormalView: sensor-agnostic tree species classification from backpack and aerial lidar data using geometric projections](https://arxiv.org/abs/2512.05610)
*Juho Korkeala,Jesse Muhojoki,Josef Taher,Klaara Salolahti,Matti Hyyppä,Antero Kukko,Juha Hyyppä*

Main category: cs.CV

TL;DR: 提出NormalView方法，通过将点云几何信息投影为二维图像，结合YOLOv11进行树种分类，在MLS和ALS数据上取得高精度，并验证多光谱强度信息的有效性。

- Motivation: 移动激光扫描（MLS）和机载激光扫描（ALS）能提供高精度树木数据，但需要有效的树种分类方法。现有方法通常依赖特定传感器或复杂特征提取，需要一种传感器无关、基于几何信息的通用分类方法。
- Method: 提出NormalView方法：1）将点云局部几何信息（法向量估计）嵌入二维投影；2）使用图像分类网络YOLOv11处理投影图像；3）研究多光谱辐射强度信息对分类性能的影响；4）在高密度MLS（7树种）和ALS（9树种）数据上训练测试。
- Result: MLS数据上总体准确率95.5%（宏平均94.8%），ALS数据上91.8%（宏平均79.1%）。多光谱强度信息能提升分类性能，使用三通道强度信息的模型表现最佳。方法传感器无关，仅依赖几何信息。
- Conclusion: 投影方法结合几何信息和先进图像分类网络能取得优异结果，且传感器无关。多光谱强度信息对树种分类有益。公开了研究中使用的MLS数据集。


### [52] [DistillFSS: Synthesizing Few-Shot Knowledge into a Lightweight Segmentation Model](https://arxiv.org/abs/2512.05613)
*Pasquale De Marinis,Pieter M. Blok,Uzay Kaymak,Rogier Brussee,Gennaro Vessio,Giovanna Castellano*

Main category: cs.CV

TL;DR: DistillFSS：通过师生蒸馏将少样本分割知识嵌入模型参数，消除测试时对支持图像的需求，实现快速轻量推理

- Motivation: 跨域少样本语义分割面临三大挑战：源域和目标域分布差异大、标签空间不重叠、支持图像稀缺，导致传统episodic方法不可靠且计算成本高
- Method: 提出DistillFSS框架，通过师生蒸馏过程将支持集知识直接嵌入模型参数，在student网络中内化少样本推理到专用层，消除测试时对支持图像的需求
- Result: 在新构建的跨域少样本分割基准（医疗影像、工业检测、遥感）上，DistillFSS达到或超越SOTA基线，尤其在多类别和多样本场景表现优异，同时显著提升计算效率
- Conclusion: DistillFSS通过参数化少样本推理，实现了快速轻量推断，支持高效扩展到未见域的新类别，为实际应用提供了可行的解决方案


### [53] [Experts-Guided Unbalanced Optimal Transport for ISP Learning from Unpaired and/or Paired Data](https://arxiv.org/abs/2512.05635)
*Georgy Perevozchikov,Nancy Mehta,Egor Ershov,Radu Timofte*

Main category: cs.CV

TL;DR: 提出基于非平衡最优传输的无监督ISP训练框架，无需配对数据，通过专家判别器委员会提升图像质量

- Motivation: 传统学习型ISP管道依赖大规模配对raw-to-sRGB数据集，数据获取成本高，成为主要瓶颈
- Method: 基于非平衡最优传输的无监督训练框架，引入专家判别器委员会作为对抗正则化器，指导跨域映射
- Result: 配对模式下超越原有方法，非配对模式在定量和定性评估中达到甚至超过配对训练的性能
- Conclusion: 提出的UOT框架有效解决了ISP训练的数据依赖问题，为无监督图像信号处理提供了新途径


### [54] [Self-Supervised AI-Generated Image Detection: A Camera Metadata Perspective](https://arxiv.org/abs/2512.05651)
*Nan Zhong,Mian Zou,Yiran Xu,Zhenxing Qian,Xinpeng Zhang,Baoyuan Wu,Kede Ma*

Main category: cs.CV

TL;DR: 提出基于EXIF元数据的自监督方法检测AI生成图像，通过相机元数据学习摄影图像特征，实现跨模型泛化检测

- Motivation: 现有AI图像检测器依赖特定生成模型内部假设，跨模型适用性有限；AI生成图像泛滥给多媒体取证带来挑战
- Method: 自监督方法：利用EXIF元数据训练特征提取器，分类相机型号/场景类型，排序焦距/光圈值；基于EXIF特征进行单类检测（高斯混合模型）和二元检测（高频残差+空间打乱补丁）
- Result: 在多种生成模型上实验表明，EXIF诱导检测器显著提升SOTA性能，对真实样本有强泛化能力，对常见良性图像扰动具有鲁棒性
- Conclusion: 基于EXIF元数据的自监督方法有效检测AI生成图像，不依赖特定生成模型假设，具有强泛化能力和鲁棒性


### [55] [LeAD-M3D: Leveraging Asymmetric Distillation for Real-time Monocular 3D Detection](https://arxiv.org/abs/2512.05663)
*Johannes Meier,Jonathan Michel,Oussema Dhaouadi,Yung-Hsu Yang,Christoph Reich,Zuria Bauer,Stefan Roth,Marc Pollefeys,Jacques Kaiser,Daniel Cremers*

Main category: cs.CV

TL;DR: LeAD-M3D：一种实时单目3D目标检测方法，通过非对称增强去噪蒸馏、3D感知一致性匹配和置信度门控3D推理三个关键技术，在无需额外模态的情况下实现了SOTA精度和实时推理

- Motivation: 解决单目3D目标检测中的深度模糊、视角变化和3D推理计算成本高的问题。现有方法要么依赖LiDAR或几何先验来补偿缺失的深度信息，要么牺牲效率来获得竞争性精度
- Method: 1. 非对称增强去噪蒸馏(A2D2)：通过质量-重要性加权的深度特征损失，将几何知识从干净图像教师模型转移到混合噪声学生模型
2. 3D感知一致性匹配(CM3D)：将3D MGIoU集成到匹配分数中，改进预测到真实值的分配
3. 置信度门控3D推理(CGI3D)：通过将昂贵的3D回归限制在高置信度区域来加速检测
- Result: 在KITTI和Waymo上达到SOTA精度，在Rope3D上获得最佳报告的car AP，同时运行速度比先前高精度方法快3.6倍
- Conclusion: 高保真度和实时效率在单目3D检测中可以同时实现，无需LiDAR、立体视觉或几何假设，为单目3D检测设定了新的帕累托前沿


### [56] [Deep Learning-Based Real-Time Sequential Facial Expression Analysis Using Geometric Features](https://arxiv.org/abs/2512.05669)
*Talha Enes Koksal,Abdurrahman Gumus*

Main category: cs.CV

TL;DR: 提出了一种基于深度学习和几何特征的实时序列面部表情识别方法，使用MediaPipe FaceMesh进行面部关键点检测，提取几何特征，结合时间动态分析，采用ConvLSTM1D网络进行分类，在多个数据集上取得良好性能，处理速度达165帧/秒。

- Motivation: 面部表情识别对于增强人机交互和开发情感感知系统至关重要。实时检测和解释面部表情在用户体验个性化和智能监控等应用中变得越来越重要。
- Method: 使用MediaPipe FaceMesh进行快速准确的面部关键点检测，提取欧几里得距离和角度等几何特征，通过分析连续帧之间的特征差异来捕捉表情的起始、顶点和偏移阶段，采用ConvLSTM1D网络和多层感知机块进行分类。
- Result: 在CK+、Oulu-CASIA（VIS和NIR）、MMI数据集上分别达到93%、79%、77%、68%的准确率，在消费级硬件上处理速度约为165帧/秒，具备实时应用能力。
- Conclusion: 该方法为面部表情分析领域提供了一个快速、准确且适应性强的解决方案，推动了情感感知技术和个性化用户体验的进一步发展，为更复杂的人机交互系统铺平了道路。


### [57] [InverseCrafter: Efficient Video ReCapture as a Latent Domain Inverse Problem](https://arxiv.org/abs/2512.05672)
*Yeobin Hong,Suhyeon Lee,Hyungjin Chung,Jong Chul Ye*

Main category: cs.CV

TL;DR: InverseCrafter：一种高效的修复逆求解器，将4D生成任务重新定义为潜在空间中的修复问题，避免了昂贵的VAE操作和反向传播

- Motivation: 当前可控4D视频生成方法通常需要微调预训练的视频扩散模型，这种方法计算成本高，需要大规模数据集和架构修改，且容易导致模型原始生成先验的灾难性遗忘
- Method: 提出InverseCrafter修复逆求解器，将4D生成任务重新定义为潜在空间中的修复问题。核心方法是将像素空间退化算子编码为连续的多通道潜在掩码，从而绕过重复的VAE操作和反向传播的昂贵瓶颈
- Result: 在相机控制任务中实现了可比的新视角生成和更优的测量一致性，计算开销接近零；同时在通用视频修复和编辑方面表现出色
- Conclusion: InverseCrafter提供了一种高效且有效的4D视频生成方法，避免了传统微调方法的计算成本和灾难性遗忘问题，在保持生成质量的同时显著降低了计算开销


### [58] [Hyperspectral Unmixing with 3D Convolutional Sparse Coding and Projected Simplex Volume Maximization](https://arxiv.org/abs/2512.05674)
*Gargi Panda,Soumitra Kundu,Saumik Bhattacharya,Aurobinda Routray*

Main category: cs.CV

TL;DR: 提出基于算法展开的3D卷积稀疏编码网络（3D-CSCNet）用于高光谱解混，结合自编码器框架和投影单纯形体积最大化算法，在多个数据集上优于现有方法。

- Motivation: 现有基于算法展开的高光谱解混网络未能充分利用自编码器框架的优势，且需要更好地联合学习高光谱数据的三维空间-光谱关系。
- Method: 提出3D-CSCNet：1）基于3D卷积稀疏编码模型构建算法展开网络；2）采用自编码器框架，编码器为3D-CSC块估计丰度矩阵，解码器权重作为端元矩阵；3）提出PSVM算法初始化端元；4）联合学习三维高光谱数据的空间和光谱关系。
- Result: 在三个真实数据集和一个模拟数据集（三种不同信噪比水平）上的实验表明，3D-CSCNet优于现有最先进方法。
- Conclusion: 3D-CSCNet通过算法展开和自编码器框架有效解决了高光谱解混问题，能够联合学习空间-光谱特征，并在多个数据集上取得了优越性能。


### [59] [Physics-Informed Graph Neural Network with Frequency-Aware Learning for Optical Aberration Correction](https://arxiv.org/abs/2512.05683)
*Yong En Kok,Bowen Deng,Alexander Bentley,Andrew J. Parkes,Michael G. Somekh,Amanda J. Wright,Michael P. Pound*

Main category: cs.CV

TL;DR: ZRNet：一种物理信息框架，通过Zernike图模块和频域对齐损失，联合预测Zernike系数并进行光学图像恢复，在复杂大像差显微镜图像处理中达到SOTA性能。

- Motivation: 光学像差（特别是深层成像时）显著降低显微镜图像质量。现有方法通常只处理轻度像差，且将问题视为黑盒映射，没有利用波前畸变的光学物理原理。
- Method: 提出ZRNet框架，包含：1）Zernike图模块，基于方位角建模Zernike多项式间的物理关系；2）频域感知对齐损失，在傅里叶域对齐Zernike系数预测和图像特征；3）联合执行Zernike系数预测和光学图像恢复。
- Result: 在CytoImageNet数据集上的实验表明，该方法在图像恢复和Zernike系数预测方面均达到最先进性能，适用于多种显微镜模态和具有复杂大像差的生物样本。
- Conclusion: ZRNet通过显式建模光学物理原理，实现了对复杂大像差的有效校正，为显微镜图像恢复提供了物理一致且性能优越的解决方案。


### [60] [OWL: Unsupervised 3D Object Detection by Occupancy Guided Warm-up and Large Model Priors Reasoning](https://arxiv.org/abs/2512.05698)
*Xusheng Guo,Wanfa Zhang,Shijia Zhao,Qiming Xia,Xiaolong Xie,Mingming Wang,Hai Wu,Chenglu Wen*

Main category: cs.CV

TL;DR: OWL提出了一种无监督3D目标检测方法，通过占用引导预热和大模型先验推理来改进伪标签质量，在Waymo和KITTI数据集上超越现有方法超过15% mAP。

- Motivation: 现有无监督3D目标检测方法依赖伪标签自训练，但初始伪标签往往错误，会误导优化过程。如何有效过滤和精炼伪标签是关键挑战。
- Method: 1. 占用引导预热策略：初始化骨干网络权重，赋予空间感知能力，减少错误伪标签对收敛的干扰。2. 实例提示推理模块：利用大模型先验知识评估伪标签质量，实现精确过滤和精炼。3. 权重自适应自训练策略：动态重新加权伪标签，通过自训练提升性能。
- Result: 在Waymo Open Dataset和KITTI数据集上的大量实验表明，OWL超越最先进的无监督方法超过15.0% mAP，证明了方法的有效性。
- Conclusion: OWL通过占用引导预热、大模型先验推理和权重自适应自训练，有效解决了无监督3D目标检测中伪标签质量差的问题，显著提升了检测性能。


### [61] [Manifold-Aware Point Cloud Completion via Geodesic-Attentive Hierarchical Feature Learning](https://arxiv.org/abs/2512.05710)
*Jianan Sun,Dongzhihan Wang,Mingyu Fan*

Main category: cs.CV

TL;DR: 提出了一种基于流形感知的点云补全框架，通过引入测地线距离近似器和流形感知特征提取器，显式地利用非线性几何信息，提升点云补全的几何一致性和语义连贯性。

- Motivation: 现有点云补全方法主要依赖欧氏距离，忽略了点云内在的非线性几何结构，导致几何一致性不足和语义模糊。需要显式地利用流形几何信息来改善这些问题。
- Method: 提出流形感知点云补全框架，包含两个核心模块：1) 测地线距离近似器(GDA)，估计点之间的测地线距离以捕捉潜在流形拓扑；2) 流形感知特征提取器(MAFE)，利用基于测地线的k-NN分组和测地线关系注意力机制指导层次特征提取。
- Result: 在基准数据集上的大量实验表明，该方法在重建质量方面持续优于现有最先进方法。
- Conclusion: 通过显式地整合测地线感知的关系注意力，该方法能够促进重建点云的语义连贯性和结构保真度，有效解决了传统方法忽略非线性几何结构的问题。


### [62] [Distilling Expert Surgical Knowledge: How to train local surgical VLMs for anatomy explanation in Complete Mesocolic Excision](https://arxiv.org/abs/2512.05740)
*Lennart Maack,Julia-Kristin Graß,Lisa-Marie Toscha,Nathaniel Melling,Alexander Schlaefer*

Main category: cs.CV

TL;DR: 提出隐私保护框架，将大型通用LLM知识蒸馏到本地可部署的VLM中，用于手术场景理解

- Motivation: 当前VLM在特定手术领域理解（如全结肠系膜切除术中的解剖标志识别）存在不足，且需要本地可部署模型以避免患者数据泄露到外部大型VLM
- Method: 通过专家监督生成数据集：仅使用文本上下文和二进制分割掩码（无敏感图像）提示教师LLM，然后对本地VLM进行监督微调（SFT）和直接偏好优化（DPO）
- Result: 使用生成数据集微调的VLM在手术领域知识方面相比基础VLM有大幅提升
- Conclusion: 验证了数据高效且符合隐私要求的方法，可训练手术领域优化的本地可部署VLM用于手术场景理解


### [63] [HQ-DM: Single Hadamard Transformation-Based Quantization-Aware Training for Low-Bit Diffusion Models](https://arxiv.org/abs/2512.05746)
*Shizhuo Mao,Hongtao Zou,Qihu Xie,Song Chen,Yi Kang*

Main category: cs.CV

TL;DR: HQ-DM提出了一种用于扩散模型的量化感知训练框架，通过单哈达玛变换减少激活矩阵中的异常值，在低比特量化下保持模型性能。

- Motivation: 扩散模型在图像生成领域应用广泛，但计算和内存成本高，部署困难。现有量化方法在低比特量化时难以处理激活矩阵中的异常值，导致性能显著下降。
- Method: 提出HQ-DM量化感知训练框架，对激活矩阵应用单哈达玛变换，有效减少激活异常值，同时支持INT卷积操作并防止权重异常值放大。
- Result: 在ImageNet 256x256数据集上使用LDM-4模型，W4A4和W4A4量化方案相比现有最优方法分别将Inception Score提高了12.8%和467.73%。
- Conclusion: HQ-DM框架通过单哈达玛变换有效解决了扩散模型量化中的激活异常值问题，在低比特量化下显著提升了模型性能。


### [64] [USV: Unified Sparsification for Accelerating Video Diffusion Models](https://arxiv.org/abs/2512.05754)
*Xinjian Wu,Hongmei Wang,Yuan Zhou,Qinglin Lu*

Main category: cs.CV

TL;DR: USV提出统一稀疏化框架，通过联合优化注意力稀疏化、token合并和去噪步数减少，实现视频扩散模型的高效加速。

- Motivation: 现有视频扩散模型面临两个主要冗余问题：全局时空注意力的二次复杂度和长迭代去噪轨迹的计算开销。现有加速方法通常只针对单一维度，容易遇到收益递减问题。
- Method: USV是一个端到端可训练框架，学习动态的、数据和时间步相关的稀疏化策略，联合协调注意力连接剪枝、语义相似token自适应合并和去噪步数减少。
- Result: 在大规模视频生成基准测试中，USV实现了去噪过程83.3%的加速和端到端22.7%的加速，同时保持高视觉保真度。
- Conclusion: 统一动态稀疏化为实现高效高质量视频生成提供了实用路径，多维度协同设计使先前独立的加速策略能够相互增强。


### [65] [Label-Efficient Point Cloud Segmentation with Active Learning](https://arxiv.org/abs/2512.05759)
*Johannes Meyer,Jasper Hoffmann,Felix Schulz,Dominik Merkle,Daniel Buescher,Alexander Reiterer,Joschka Boedecker,Wolfram Burgard*

Main category: cs.CV

TL;DR: 提出一种基于2D网格分割点云和网络集成不确定度估计的主动学习方法，在多个数据集上达到或超越复杂SOTA方法性能，并发现标注面积比标注点数更适合作为点云主动学习的评估指标。

- Motivation: 3D点云语义分割标注成本高昂，现有主动学习方法通常依赖复杂启发式策略进行区域分割和样本选择。需要一种简单易实现且有效的主动学习策略来降低标注成本。
- Method: 1) 使用2D网格将点云分割为柱状区域；2) 采用网络集成方法估计网络输出的不确定性；3) 基于不确定性选择最有价值的区域进行标注。
- Result: 在S3DIS、Toronto-3D和Freiburg城市点云数据集上评估，性能达到或超越复杂SOTA方法。发现标注面积比标注点数更适合作为点云主动学习的评估指标。
- Conclusion: 提出的简单易实现主动学习策略在多个数据集上表现优异，同时发现标注面积是比标注点数更有意义的点云主动学习评估指标。


### [66] [FNOPT: Resolution-Agnostic, Self-Supervised Cloth Simulation using Meta-Optimization with Fourier Neural Operators](https://arxiv.org/abs/2512.05762)
*Ruochen Chen,Thuy Tran,Shaifali Parashar*

Main category: cs.CV

TL;DR: FNOpt是一个自监督布料模拟框架，将时间积分作为优化问题，通过傅里叶神经算子参数化的神经优化器进行训练，能够在不同网格分辨率和运动模式上实现稳定准确的模拟，无需重新训练。

- Motivation: 现有神经模拟器通常依赖大量地面真实数据或牺牲细节，在不同分辨率和运动模式上泛化能力差。需要一种能够跨分辨率可靠模拟、捕捉细节且不依赖大量标注数据的方法。
- Method: 将时间积分公式化为优化问题，训练一个由傅里叶神经算子参数化的分辨率无关神经优化器。仅使用粗网格上的物理损失进行训练，无需地面真实数据。
- Result: FNOpt在布料模拟基准测试中优于现有学习方法，在分布外设置下在准确性和鲁棒性方面表现更好。能够泛化到更细分辨率，捕捉细尺度皱纹并保持模拟稳定性。
- Conclusion: 基于FNO的元优化是先前布料神经模拟器的有吸引力的替代方案，减少了对策划数据的需求，提高了跨分辨率可靠性，为自监督物理模拟提供了新方向。


### [67] [Active Video Perception: Iterative Evidence Seeking for Agentic Long Video Understanding](https://arxiv.org/abs/2512.05774)
*Ziyang Wang,Honglu Zhou,Shijie Wang,Junnan Li,Caiming Xiong,Silvio Savarese,Mohit Bansal,Michael S. Ryoo,Juan Carlos Niebles*

Main category: cs.CV

TL;DR: AVP提出了一种主动视频感知框架，通过迭代的规划-观察-反思过程，让MLLM代理主动决定观察视频的哪些部分，从而高效地从长视频中提取查询相关的证据。

- Motivation: 现有长视频理解方法依赖查询无关的标注器，会浪费计算资源在无关内容上，并模糊细粒度时空信息。受主动感知理论启发，作者认为LVU代理应该主动决定观察什么、何时观察、何处观察，并持续评估当前观察是否足以回答问题。
- Method: AVP采用证据寻找框架，将视频视为交互环境，直接从像素获取紧凑的查询相关证据。具体采用迭代的规划-观察-反思过程：规划器提出有针对性的视频交互，观察器执行交互提取带时间戳的证据，反射器评估证据是否足以回答查询，决定停止回答或触发进一步观察。
- Result: 在五个LVU基准测试中，AVP实现了最高性能且显著提升。特别地，AVP在平均准确率上比最佳代理方法高出5.7%，同时仅需18.4%的推理时间和12.4%的输入token。
- Conclusion: AVP通过主动感知框架有效解决了长视频理解中的稀疏线索问题，实现了高效且准确的视频理解，为LVU任务提供了新的解决方案。


### [68] [Curvature-Regularized Variational Autoencoder for 3D Scene Reconstruction from Sparse Depth](https://arxiv.org/abs/2512.05783)
*Maryam Yousefi,Soodeh Bakhshandeh*

Main category: cs.CV

TL;DR: 提出基于离散拉普拉斯算子的曲率正则化方法，在深度传感器仅提供5%测量数据时，实现比标准变分自编码器高18.1%的3D场景重建精度。

- Motivation: 当深度传感器只能提供所需测量的5%时，重建完整的3D场景变得困难。自动驾驶车辆和机器人无法容忍稀疏重建引入的几何误差。
- Method: 通过离散拉普拉斯算子进行曲率正则化，该方法提供稳定的梯度和噪声抑制，仅增加15%的训练开销且零推理成本。
- Result: 重建精度比标准变分自编码器提高18.1%，挑战了几何深度学习中"组合多个几何约束能提高性能"的隐含假设。
- Conclusion: 单个精心设计的正则化项不仅能匹配甚至超越复杂多项公式的效果，为稀疏3D重建提供了高效解决方案。


### [69] [Bring Your Dreams to Life: Continual Text-to-Video Customization](https://arxiv.org/abs/2512.05802)
*Jiahua Dong,Xudong Wang,Wenqi Liang,Zongyan Han,Meng Cao,Duzhen Zhang,Hanbin Zhao,Zhi Han,Salman Khan,Fahad Shahbaz Khan*

Main category: cs.CV

TL;DR: 提出CCVD模型解决定制化文本到视频生成中的持续学习问题，通过概念特定属性保留和任务感知概念聚合来缓解灾难性遗忘，使用可控条件合成解决概念忽视问题。

- Motivation: 现有定制化文本到视频生成方法假设个性化概念是静态的，无法处理随时间递增的新概念学习，且在持续学习新概念时存在遗忘和概念忽视问题。
- Method: 提出持续定制化视频扩散模型(CCVD)，包含概念特定属性保留模块和任务感知概念聚合策略来应对灾难性遗忘，以及可控条件合成方法通过层特定区域注意力引导的噪声估计来增强区域特征和对齐视频上下文。
- Result: 大量实验比较表明，CCVD在定制化文本到视频生成任务上优于现有模型。
- Conclusion: CCVD能够持续学习新概念，有效解决灾难性遗忘和概念忽视问题，在定制化视频生成任务中表现出色。


### [70] [Probing the effectiveness of World Models for Spatial Reasoning through Test-time Scaling](https://arxiv.org/abs/2512.05809)
*Saurav Jha,M. Jehanzeb Mirza,Wei Lin,Shiqi Yang,Sarath Chandar*

Main category: cs.CV

TL;DR: 本文系统分析了基于世界模型的测试时验证器在空间推理任务中的表现，揭示了其局限性并提出了改进框架ViSA，但发现当前世界模型仍是信息瓶颈。

- Motivation: 当前视觉语言模型在需要多视角理解和具身视角转换的空间推理任务中存在局限。MindJourney等近期方法通过测试时缩放（让世界模型想象动作条件轨迹，并通过启发式验证器选择有用视角）来弥补这一差距，但这些验证器的实际效果尚未得到系统评估。
- Method: 1) 系统分析MindJourney验证器在不同基准测试中的行为，发现其校准能力有限且存在系统性动作偏差；2) 提出ViSA（Verification through Spatial Assertions）框架，将测试时奖励基于可验证的、帧锚定的微观主张；3) 在SAT-Real和MMSI-Bench基准上评估不同验证器的表现。
- Result: 1) MindJourney验证器提供很少有意义的校准，随机评分通常同样能降低答案熵；2) ViSA框架在SAT-Real基准上持续改善空间推理，并通过更平衡的探索行为纠正轨迹选择偏差；3) 在挑战性的MMSI-Bench上，包括ViSA在内的所有验证器都无法实现一致的缩放，表明当前世界模型形成了信息瓶颈，想象的视角无法丰富细粒度推理。
- Conclusion: 本文揭示了基于世界模型的测试时验证在空间推理中的好坏两方面：ViSA框架能有效改善某些任务，但当前世界模型的想象能力限制了细粒度推理的提升。研究为基于世界模型的推理测试时验证提供了全面的评估框架。


### [71] [UG-FedDA: Uncertainty-Guided Federated Domain Adaptation for Multi-Center Alzheimer's Disease Detection](https://arxiv.org/abs/2512.05814)
*Fubao Zhu,Zhanyuan Jia,Zhiguo Wang,Huan Huang,Danyang Sun,Chuang Han,Yanting Li,Jiaofen Nan,Chen Zhao,Weihua Zhou*

Main category: cs.CV

TL;DR: 提出UG-FedDA框架，结合不确定性量化与联邦域适应，解决多中心阿尔茨海默病MRI分类中的站点异质性和隐私保护问题。

- Motivation: 现有AD分类框架在多中心研究中面临挑战：忽略站点间异质性、缺乏不确定性量化机制，限制了鲁棒性和临床适用性。
- Method: UG-FedDA框架整合不确定性量化与联邦域适应，使用自注意力transformer提取多模板ROI特征，通过不确定性引导特征对齐，降低不确定样本权重。
- Result: 在ADNI、AIBL、OASIS三个数据集上，UG-FedDA在AD vs NC、MCI vs AD、NC vs MCI三个分类任务中均取得显著性能提升，同时保护隐私。
- Conclusion: UG-FedDA能有效适应多中心数据，处理站点异质性，提供不确定性量化，在保护隐私的同时提升AD分类性能。


### [72] [Phase-OTDR Event Detection Using Image-Based Data Transformation and Deep Learning](https://arxiv.org/abs/2512.05830)
*Muhammet Cagri Yeke,Samil Sirin,Kivilcim Yuksel,Abdurrahman Gumus*

Main category: cs.CV

TL;DR: 该研究提出了一种将Phase-OTDR一维数据转换为灰度图像（使用GADF、GASF和RP技术）并组合成多通道RGB表示的方法，用于光纤事件检测，在EfficientNetB0和DenseNet121模型上分别达到98.84%和98.24%的分类准确率。

- Motivation: 传统Phase-OTDR数据分析方法在处理复杂光纤传感数据时存在局限性，需要更鲁棒和高效的事件检测方法。通过将一维数据转换为图像表示，可以利用先进的计算机视觉技术和迁移学习模型来提高分析效率和准确性。
- Method: 提出将Phase-OTDR一维数据转换为灰度图像的方法，使用Gramian Angular Difference Field (GADF)、Gramian Angular Summation Field (GASF)和Recurrence Plot (RP)三种技术。将这些灰度图像组合成多通道RGB表示，然后使用迁移学习模型（EfficientNetB0和DenseNet121）进行分类。采用5折交叉验证评估模型性能。
- Result: 在六类光纤事件检测任务中，EfficientNetB0模型达到98.84%的准确率，DenseNet121模型达到98.24%的准确率。5折交叉验证的测试准确率分别为99.07%和98.68%。该方法在公开的Phase-OTDR数据集上验证了有效性，同时减少了数据集大小并提高了分析效率。
- Conclusion: 基于图像的分析方法在解释复杂光纤传感数据方面具有变革潜力，显著提高了光纤监测系统的准确性和可靠性。该方法为光纤事件检测提供了高效解决方案，相关代码和图像数据集已在GitHub上公开以支持进一步研究。


### [73] [VRSA: Jailbreaking Multimodal Large Language Models through Visual Reasoning Sequential Attack](https://arxiv.org/abs/2512.05853)
*Shiji Zhao,Shukun Xiong,Yao Huang,Yan Jin,Zhenyu Wu,Jiyang Guan,Ranjie Duan,Jialing Tao,Hui Xue,Xingxing Wei*

Main category: cs.CV

TL;DR: 提出视觉推理序列攻击（VRSA），通过将有害文本分解为多个相关子图像，诱导多模态大语言模型逐步外化并聚合完整有害意图，评估视觉推理任务中的安全风险。

- Motivation: 多模态大语言模型（MLLMs）虽然具有强大的跨模态理解和生成能力，但更多模态也带来了更多被用于越狱攻击的漏洞。以往研究主要关注文本模态的推理安全风险，而视觉模态中的类似威胁在很大程度上被忽视了。
- Method: 提出视觉推理序列攻击（VRSA）：1）将原始有害文本分解为多个顺序相关的子图像；2）自适应场景优化（Adaptive Scene Refinement）优化与原始有害查询最相关的场景；3）语义连贯补全（Semantic Coherent Completion）结合上下文信息迭代重写每个子文本；4）文本-图像一致性对齐（Text-Image Consistency Alignment）保持语义一致性。
- Result: 实验表明，VRSA在开源和闭源MLLMs（如GPT-4o和Claude-4.5-Sonnet）上相比最先进的越狱攻击方法实现了更高的攻击成功率。
- Conclusion: VRSA方法有效揭示了多模态大语言模型在视觉推理任务中的安全风险，表明视觉模态同样存在严重的越狱攻击威胁，需要加强多模态安全防护。


### [74] [Edit-aware RAW Reconstruction](https://arxiv.org/abs/2512.05859)
*Abhijith Punnappurath,Luxi Zhao,Ke Zhao,Hue Nguyen,Radek Grzeszczuk,Michael S. Brown*

Main category: cs.CV

TL;DR: 提出一种可插拔的编辑感知损失函数，通过可微分ISP模拟真实照片处理流程，提升RAW重建方法对不同渲染风格和编辑操作的鲁棒性。

- Motivation: 用户通常在相机显示参考输出（如sRGB JPEG）上进行编辑，而非RAW格式。现有RAW重建方法主要优化像素级重建保真度，但在不同渲染风格和编辑操作下性能会下降。摄影编辑是消费级成像中RAW重建的主要动机，因此需要提升重建RAW对编辑的鲁棒性。
- Method: 提出可插拔的编辑感知损失函数，包含模块化可微分图像信号处理器（ISP），模拟真实照片处理流程。训练时，每个ISP模块的参数从精心设计的分布中随机采样，模拟实际相机处理的变化。损失在sRGB空间中计算，通过可微分ISP渲染真实和重建的RAW图像。
- Result: 该方法在各种编辑条件下将sRGB重建质量提升1.5-2 dB PSNR。应用于元数据辅助的RAW重建方法时，能够针对目标编辑进行微调，获得进一步增益。
- Conclusion: 该简单而有效的损失函数为增强现有方法的编辑保真度和渲染灵活性提供了通用机制，特别适用于消费级成像中RAW重建的主要应用场景——摄影编辑。


### [75] [Underwater Image Reconstruction Using a Swin Transformer-Based Generator and PatchGAN Discriminator](https://arxiv.org/abs/2512.05866)
*Md. Mahbub Hasan Akash,Aria Tasnim Mridula,Sheekar Banerjee,Ishtiak Al Mamoon*

Main category: cs.CV

TL;DR: 本文提出了一种结合Swin Transformer和GAN的新型深度学习框架，用于水下图像重建，在EUVP数据集上取得了PSNR 24.76 dB和SSIM 0.89的SOTA性能。

- Motivation: 水下成像对海洋探索、环境监测和基础设施检查至关重要，但水会导致波长相关的吸收和散射，造成颜色失真、低对比度和雾霾效应。传统方法和基于CNN的方法由于感受野有限且无法建模全局依赖关系，难以有效解决这些问题。
- Method: 提出了一种新颖的深度学习框架，将Swin Transformer架构集成到生成对抗网络(GAN)中。生成器采用带有Swin Transformer块的U-Net结构，以捕获局部特征和长距离依赖关系，这对整个图像的颜色校正至关重要。使用PatchGAN判别器进行对抗训练，确保高频细节的保留。
- Result: 在EUVP数据集上训练和评估模型，定量结果显示PSNR达到24.76 dB，SSIM达到0.89，显著优于现有方法。视觉结果显示了有效的色彩平衡恢复、对比度提升和雾霾减少。消融研究证实了Swin Transformer设计相对于卷积替代方案的优越性。
- Conclusion: 所提出的方法为各种海洋应用提供了稳健的水下图像重建解决方案，通过结合Swin Transformer的全局建模能力和GAN的对抗训练，有效解决了水下图像退化问题。


### [76] [SCAIL: Towards Studio-Grade Character Animation via In-Context Learning of 3D-Consistent Pose Representations](https://arxiv.org/abs/2512.05905)
*Wenhao Yan,Sheng Ye,Zhuoyi Yang,Jiayan Teng,ZhenHui Dong,Kairui Wen,Xiaotao Gu,Yong-Jin Liu,Jie Tang*

Main category: cs.CV

TL;DR: SCAIL是一个通过上下文学习实现工作室级角色动画的框架，采用创新的3D姿态表示和全上下文姿态注入机制，在复杂运动和跨身份动画中保持结构保真度和时间一致性。

- Motivation: 现有方法在将驱动视频的运动转移到参考图像时，在复杂运动和跨身份动画等野外场景中往往无法保持结构保真度和时间一致性，难以达到工作室级的生产标准。
- Method: 1. 提出新颖的3D姿态表示，提供更鲁棒和灵活的运动信号；2. 在扩散变换器架构中引入全上下文姿态注入机制，实现对完整运动序列的有效时空推理；3. 开发确保多样性和质量的精选数据管道。
- Result: SCAIL实现了最先进的性能，在复杂运动和跨身份动画场景中表现出色，推动了角色动画向工作室级可靠性和真实感的发展。
- Conclusion: SCAIL通过创新的3D姿态表示和全上下文姿态注入机制，解决了现有方法在复杂动画场景中的局限性，为工作室级角色动画提供了有效的解决方案。


### [77] [NICE: Neural Implicit Craniofacial Model for Orthognathic Surgery Prediction](https://arxiv.org/abs/2512.05920)
*Jiawen Yang,Yihui Cao,Xuanyu Tian,Yuyao Zhang,Hongjiang Wei*

Main category: cs.CV

TL;DR: 提出NICE模型，使用隐式神经表示进行颅面解剖重建和正颌手术结果预测，在唇部和下巴等关键区域显著提高预测精度。

- Motivation: 正颌手术对于矫正牙颌面骨骼畸形至关重要，但术后面部外观预测困难，现有方法要么计算效率低，要么无法充分捕捉骨骼运动与面部软组织之间的复杂非线性相互作用。
- Method: 提出神经隐式颅面模型(NICE)，包含形状模块和手术模块。形状模块使用区域特定的隐式符号距离函数解码器重建面部表面、上颌骨和下颌骨；手术模块使用区域特定的变形解码器，由共享的手术潜在代码驱动，输出逐点位移场来模拟手术结果。
- Result: NICE在广泛实验中优于当前最先进方法，显著提高了唇部和下巴等关键面部区域的预测精度，同时稳健地保持了解剖完整性。
- Conclusion: 该工作为增强正颌手术规划和患者咨询提供了临床可行的工具。


### [78] [LPD: Learnable Prototypes with Diversity Regularization for Weakly Supervised Histopathology Segmentation](https://arxiv.org/abs/2512.05922)
*Khang Le,Anh Mai Vu,Thi Kim Trang Vo,Ha Thach,Ngoc Bui Lam Quang,Thanh-Huy Nguyen,Minh H. N. Le,Zhu Han,Chandra Mohan,Hien Van Nguyen*

Main category: cs.CV

TL;DR: 提出一种无需聚类的单阶段可学习原型框架，通过多样性正则化增强形态学类内异质性覆盖，在病理图像弱监督语义分割中实现SOTA性能

- Motivation: 病理图像弱监督语义分割面临类间同质性、类内异质性以及CAM导致的区域收缩问题。现有两阶段方法（构建聚类原型库+精炼掩码）成本高、对超参数敏感，且原型发现与分割学习解耦，限制了效果和效率。
- Method: 提出聚类无关的单阶段可学习原型框架，通过多样性正则化增强形态学类内异质性覆盖，避免两阶段流程的缺陷。
- Result: 在BCSS-WSSS数据集上实现SOTA性能，mIoU和mDice指标优于先前方法。定性分割图显示更清晰的边界和更少的误标，激活热图表明可学习原型覆盖了每个类别内更多样化和互补的区域。
- Conclusion: 提出的单阶段可学习原型框架有效解决了病理图像弱监督语义分割中的关键挑战，相比聚类方法能更好地覆盖类内异质性，在性能和效率上均有优势。


### [79] [World Models That Know When They Don't Know: Controllable Video Generation with Calibrated Uncertainty](https://arxiv.org/abs/2512.05927)
*Zhiting Mei,Tenny Yin,Micah Baker,Ola Shorinwa,Anirudha Majumdar*

Main category: cs.CV

TL;DR: 提出C3方法，通过不确定性量化训练可控视频模型，实现亚像素级置信度估计，精确定位生成视频帧中的不确定区域

- Motivation: 当前可控视频模型存在幻觉问题（生成与物理现实不符的视频帧），但缺乏评估和表达置信度的能力，这阻碍了幻觉缓解，特别是在机器人策略评估和规划等任务中
- Method: 提出C3不确定性量化方法：1）通过严格适当评分规则训练视频模型实现正确性和校准；2）在潜在空间估计不确定性，避免像素空间方法的训练不稳定和高成本；3）将密集潜在空间不确定性映射到可解释的像素级RGB空间不确定性，提供高分辨率不确定性热图
- Result: 在大规模机器人学习数据集（Bridge和DROID）和真实世界评估中，该方法不仅能在训练分布内提供校准的不确定性估计，还能有效进行分布外检测
- Conclusion: C3方法通过不确定性量化使可控视频模型能够评估和表达置信度，精确定位生成视频中的不确定区域，为幻觉缓解提供了有效工具


### [80] [A Comparative Study on Synthetic Facial Data Generation Techniques for Face Recognition](https://arxiv.org/abs/2512.05928)
*Pedro Vidal,Bernardo Biesseck,Luiz E. L. Coelho,Roger Granada,David Menotti*

Main category: cs.CV

TL;DR: 该研究比较了不同合成面部数据生成技术在面部识别任务中的效果，评估了8个主流数据集上的准确率、Rank-1、Rank-5等指标，发现合成数据能捕捉真实变化但仍存在性能差距。

- Motivation: 面部识别面临可解释性、人口统计偏差、隐私保护、对抗老化、姿态变化、光照变化、遮挡和表情等挑战。隐私法规导致多个数据集质量下降，引发法律、伦理和隐私问题。合成面部数据生成被认为是有前景的解决方案。
- Method: 比较不同技术生成的合成面部数据集在面部识别任务中的效果，评估包括扩散模型、GANs和3D模型等多种生成技术。在8个主流数据集上评估准确率、Rank-1、Rank-5以及FPR=0.01%时的TPR等指标。
- Result: 结果表明合成数据能够捕捉真实的面部变化，但性能仍与真实数据存在差距。扩散模型、GANs和3D模型等技术取得了显著进展，但仍面临挑战。
- Conclusion: 合成面部数据在缓解隐私问题、控制面部属性、减轻人口统计偏差和补充训练数据方面具有潜力，但需要进一步研究来缩小与真实数据的性能差距。


### [81] [Synset Signset Germany: a Synthetic Dataset for German Traffic Sign Recognition](https://arxiv.org/abs/2512.05936)
*Anne Sielemann,Lena Loercher,Max-Lion Schumacher,Stefan Wolf,Masoud Roschani,Jens Ziehn*

Main category: cs.CV

TL;DR: 提出结合数据驱动和解析建模优势的交通标志识别合成数据集生成方法，创建包含105500张德国交通标志图像的Synset Signset Germany数据集

- Motivation: 现有交通标志识别数据集在真实性和参数可控性方面存在局限，需要既能生成逼真图像又能支持可解释AI和鲁棒性测试的合成数据集
- Method: 结合GAN纹理生成实现数据驱动的污损效果，使用解析场景建模实现物理正确的光照效果，提供详细的参数化控制
- Result: 创建了包含211个德国交通标志类别、105500张图像的Synset Signset Germany数据集，包含掩码、分割图像和丰富元数据，在GTSRB基准测试中验证了真实性
- Conclusion: 提出的合成管道成功结合了数据驱动和解析建模的优势，生成的交通标志数据集既具有高真实性，又支持可解释AI和鲁棒性测试应用


### [82] [Measuring the Effect of Background on Classification and Feature Importance in Deep Learning for AV Perception](https://arxiv.org/abs/2512.05937)
*Anne Sielemann,Valentin Barner,Stefan Wolf,Masoud Roschani,Jens Ziehn,Juergen Beyerer*

Main category: cs.CV

TL;DR: 该研究通过生成六个合成数据集，系统分析了背景相关性对交通标志识别中深度神经网络特征重要性的影响，量化了背景特征在分类任务中的作用程度。

- Motivation: 当前可解释AI方法（如SHAP和GradCAM）虽然能显示输入特征的重要性，但难以定量测试其解释的合理性。特别是在真实数据中，难以区分合法相关性和虚假相关性，而合成数据可以精确控制相关性但缺乏真实感。因此需要系统研究背景相关性对分类器行为的影响。
- Method: 生成了六个合成交通标志识别数据集，这些数据集仅在相机变化程度和背景相关性方面有所不同。通过控制变量方法，量化了背景相关性、相机变化水平和交通标志形状对分类性能和背景特征重要性的独立影响。
- Result: 研究量化了背景特征在何时以及多大程度上获得重要性以支持分类任务，基于训练域的变化。具体分析了背景相关性对分类器特征选择行为的影响程度。
- Conclusion: 通过系统化的合成数据实验，该研究为可解释AI提供了更可靠的定量评估框架，能够更准确地理解背景相关性如何影响深度神经网络的分类决策过程。


### [83] [Zoom in, Click out: Unlocking and Evaluating the Potential of Zooming for GUI Grounding](https://arxiv.org/abs/2512.05941)
*Zhiyuan Jiang,Shenghao Xie,Wenyi Li,Wenqiang Zu,Peihang Li,Jiahao Qiu,Siqi Pei,Lei Ma,Tiejun Huang,Mengdi Wang,Shilong Liu*

Main category: cs.CV

TL;DR: ZoomClick：一种无需训练的方法，利用缩放作为GUI元素定位的先验，通过动态空间聚焦和自适应上下文切换显著提升GUI grounding性能。

- Motivation: 现有GUI grounding方法依赖大规模边界框监督，但仍面临跨平台泛化、复杂布局分析和细粒度元素定位等挑战。缩放作为一种强大但未被充分探索的先验，具有解决这些问题的潜力。
- Method: 提出ZoomClick方法，通过表征缩放的四个关键属性（预缩放、深度、收缩尺寸、最小裁剪尺寸），解锁其动态空间聚焦和自适应上下文切换的能力，实现无需训练的GUI grounding增强。
- Result: 方法显著提升通用视觉语言模型和专用GUI grounding模型的性能，在多个主流基准上达到SOTA；UI-Venus-72B在ScreenSpot-Pro上达到73.1%成功率。同时提出了GUIZoom-Bench基准用于评估模型对缩放的适应性。
- Conclusion: 缩放是GUI grounding的强大先验，ZoomClick方法有效利用缩放特性提升定位性能，未来研究可进一步改进缩放策略以增强训练和测试时的扩展能力。


### [84] [AQUA-Net: Adaptive Frequency Fusion and Illumination Aware Network for Underwater Image Enhancement](https://arxiv.org/abs/2512.05960)
*Munsif Ali,Najmul Hassan,Lucia Ventura,Davide Di Bari,Simonepietro Canese*

Main category: cs.CV

TL;DR: 提出AQUA-Net模型，通过频率融合和光照感知分支，在保持低参数量的同时实现水下图像增强，效果与SOTA相当

- Motivation: 水下图像常因波长依赖的光吸收和散射而出现严重颜色失真、低对比度和雾状外观，同时现有深度学习模型计算复杂度高，限制了实时水下应用部署
- Method: 提出AQUA-Net模型，集成残差编码解码器与双辅助分支（频率域和光照域）。频率融合编码器从傅里叶域提取频率线索，光照感知解码器通过学习的照明图进行自适应曝光校正
- Result: 在多个基准数据集上的实验表明，AQUA-Net在定性和定量评估中与SOTA相当，同时使用更少参数。消融研究证实频率和光照分支提供互补贡献，改善可见性和颜色表示
- Conclusion: AQUA-Net展示了强大的泛化能力和鲁棒性，为真实世界水下成像应用提供了有效解决方案，同时提出了地中海高分辨率真实水下视频数据集


### [85] [EditThinker: Unlocking Iterative Reasoning for Any Image Editor](https://arxiv.org/abs/2512.05965)
*Hongyu Li,Manyuan Zhang,Dian Zheng,Ziyu Guo,Yimeng Jia,Kaituo Feng,Hao Yu,Yexin Liu,Yan Feng,Peng Pei,Xunliang Cai,Linjiang Huang,Hongsheng Li,Si Liu*

Main category: cs.CV

TL;DR: 提出EditThinker框架，通过"思考-编辑"循环提升图像编辑模型的指令跟随能力，使用强化学习对齐思考与编辑过程

- Motivation: 现有基于指令的图像编辑方法虽然能生成高质量图像，但指令跟随能力有限，主要因为随机性和缺乏深思熟虑的过程。单次编辑成功率受限于模型的内在随机性。
- Method: 提出深思熟虑的编辑框架，模拟人类认知循环：迭代执行"思考-编辑"循环（批判结果、优化指令、重复生成）。训练单一MLLM模型EditThinker作为推理引擎，联合生成批判分数、推理过程和优化指令，并使用强化学习对齐思考与编辑过程。
- Result: 在四个基准测试上的广泛实验表明，该方法显著提升了任何图像编辑模型的指令跟随能力，取得了大幅度的改进。
- Conclusion: EditThinker框架通过引入深思熟虑的编辑过程，有效解决了图像编辑中指令跟随能力不足的问题，将发布数据构建框架、数据集和模型以促进社区发展。
## eess.AS

### [86] [SyncVoice: Towards Video Dubbing with Vision-Augmented Pretrained TTS Model](https://arxiv.org/abs/2512.05126)
*Kaidi Wang,Yi He,Wenhao Guan,Weijie Wu,Hongwu Ding,Xiong Zhang,Di Wu,Meng Meng,Jian Luan,Lin Li,Qingyang Hong*

Main category: eess.AS

TL;DR: SyncVoice：基于预训练TTS模型的视觉增强视频配音框架，通过音频-视觉数据微调实现强视听一致性，使用双说话人编码器缓解跨语言干扰，在视频翻译场景中应用。

- Motivation: 现有视频配音方法在语音自然度和音视频同步方面存在局限，且仅限于单语设置。需要解决这些问题以实现高质量、多语言的视频配音。
- Method: 基于预训练TTS模型构建视觉增强视频配音框架，在音频-视觉数据上微调TTS模型以实现强视听一致性，提出双说话人编码器缓解跨语言干扰，探索视频翻译场景应用。
- Result: 实验结果显示SyncVoice实现了高保真语音生成和强同步性能，展示了在视频配音任务中的潜力。
- Conclusion: SyncVoice框架通过视觉增强和跨语言处理，有效解决了视频配音中的自然度和同步问题，为视频翻译等应用提供了可行方案。
## cs.HC

### [87] [EXR: An Interactive Immersive EHR Visualization in Extended Reality](https://arxiv.org/abs/2512.05438)
*Benoit Marteau,Shaun Q. Y. Tan,Jieru Li,Andrew Hornback,Yishan Zhong,Shaunna Wang,Christian Lowson,Jason Woloff,Joshua M. Pahys,Steven W. Hwang,Coleman Hilton,May D. Wang*

Main category: cs.HC

TL;DR: 开发了一个用于电子健康记录沉浸式可视化的扩展现实平台，将结构化与非结构化患者数据整合到共享3D环境中，支持实时协作与直观探索。

- Motivation: 传统2D界面在电子健康记录可视化方面存在局限，需要更直观、沉浸式的交互方式来探索复杂的患者数据，并为下一代临床决策支持工具奠定基础。
- Method: 构建模块化XR平台，集成FHIR标准的EHR数据、容积医学影像和AI生成的分割结果，使用合成EHR数据集和CT衍生的脊柱模型，通过AI分割流程处理进行演示验证。
- Result: 成功实现了将结构化与非结构化患者数据可视化到共享3D环境中的平台，能够支持实时协作和直观探索，展示了与现代化医疗系统的互操作性。
- Conclusion: 这种集成的XR解决方案可以作为下一代临床决策支持工具的基础，让先进的数据基础设施在交互式、空间丰富的环境中直接可访问。
## cs.AI

### [88] [Multimodal Oncology Agent for IDH1 Mutation Prediction in Low-Grade Glioma](https://arxiv.org/abs/2512.05824)
*Hafsa Akebli,Adam Shephard,Vincenzo Della Mea,Nasir Rajpoot*

Main category: cs.AI

TL;DR: MOA整合TITAN基础模型的组织学工具和临床基因组数据推理，用于低级别胶质瘤IDH1突变预测，在TCGA-LGG队列中达到0.912 F1分数。

- Motivation: 低级别胶质瘤中的IDH1突变具有重要的临床意义，但现有预测方法可能无法充分利用多模态信息。需要开发能整合组织学特征、临床数据和外部生物医学知识的综合预测系统。
- Method: 提出多模态肿瘤智能体(MOA)，整合基于TITAN基础模型的组织学工具进行IDH1突变预测，同时通过PubMed、Google搜索和OncoKB对结构化临床和基因组输入进行推理。
- Result: 在TCGA-LGG队列的488名患者中评估：MOA无组织学工具时F1分数0.826优于临床基线0.798；融合组织学特征后达到最高性能0.912，超过组织学基线0.894和融合基线0.897。
- Conclusion: MOA通过整合外部生物医学资源捕获了互补的突变相关信息，能够准确预测IDH1突变，展示了多模态方法在肿瘤基因组预测中的优势。
## eess.SY

### [89] [ARCAS: An Augmented Reality Collision Avoidance System with SLAM-Based Tracking for Enhancing VRU Safety](https://arxiv.org/abs/2512.05299)
*Ahmad Yehia,Jiseop Byeon,Tianyi Wang,Huihai Wang,Yiming Xu,Junfeng Jiao,Christian Claudel*

Main category: eess.SY

TL;DR: ARCAS是一个实时增强现实碰撞避免系统，通过可穿戴AR头显为弱势道路使用者提供个性化空间警报，融合路边3D LiDAR和SLAM头显跟踪，在真实世界测试中显著提高了行人安全反应时间。

- Motivation: 弱势道路使用者在混合交通中面临高碰撞风险，现有安全系统大多优先考虑驾驶员或车辆辅助，缺乏对弱势道路使用者的直接支持。
- Method: 系统融合路边360度3D LiDAR与基于SLAM的头显跟踪，采用自动3D校准程序，在用户透视视图中准确叠加世界锁定的3D边界框和方向箭头，并通过共享世界锚定实现多头显协调。
- Result: 在真实世界行人-电动滑板车/车辆交互测试中（180次试验），ARCAS几乎使行人的碰撞时间翻倍，并将对应方的反应余量提高了4倍。
- Conclusion: 结果验证了LiDAR驱动的AR引导的可行性和有效性，突显了可穿戴AR作为下一代城市移动安全工具的巨大潜力。
## cs.CL

### [90] [Interleaved Latent Visual Reasoning with Selective Perceptual Modeling](https://arxiv.org/abs/2512.05665)
*Shuai Dong,Siyuan Wang,Xingyu Liu,Zhongyu Wei*

Main category: cs.CL

TL;DR: ILVR框架通过交错潜在视觉表示解决MLLMs中视觉推理的计算瓶颈，在保持精确感知的同时实现动态状态演化

- Motivation: 现有交错推理范式因重复编码像素密集图像而计算成本过高，而潜在视觉推理方法要么牺牲感知精度，要么无法处理动态问题
- Method: 提出交错潜在视觉推理(ILVR)框架，将文本生成与作为后续推理线索的潜在视觉表示交错；使用动量教师模型从辅助图像中选择性蒸馏相关特征作为稀疏监督目标
- Result: 在多模态推理基准测试中，ILVR显著优于现有方法，有效弥合细粒度感知与顺序多模态推理之间的差距
- Conclusion: ILVR统一了动态状态演化与精确感知建模，通过自适应选择机制实现上下文感知的视觉信号生成


### [91] [M4-RAG: A Massive-Scale Multilingual Multi-Cultural Multimodal RAG](https://arxiv.org/abs/2512.05959)
*David Anugraha,Patrick Amadeus Irawan,Anshul Singh,En-Shiun Annie Lee,Genta Indra Winata*

Main category: cs.CL

TL;DR: M4-RAG是一个大规模多语言多模态检索增强生成基准，覆盖42种语言和56种方言，包含8万多个文化多样性图像-问题对，用于评估跨语言和跨模态的检索增强视觉问答。

- Motivation: 视觉语言模型在视觉问答中表现良好，但受限于静态训练数据。检索增强生成能够访问最新、文化相关和多语言信息，但多语言多模态RAG研究不足，需要系统评估框架。
- Method: 构建M4-RAG基准，包含42种语言和56种方言的8万多个文化多样性图像-问题对。创建受控检索环境，包含数百万精心策划的多语言文档，模拟真实检索条件同时确保实验一致性。
- Result: 系统评估显示，RAG对小规模VLMs有持续益处，但对大规模模型效果不佳甚至降低性能，揭示了模型规模与当前检索效果之间的关键不匹配。
- Conclusion: M4-RAG为推进下一代RAG系统奠定了基础，这些系统能够跨语言、模态和文化语境进行无缝推理，解决当前模型规模与检索效果不匹配的问题。
## cs.RO

### [92] [Toward Efficient and Robust Behavior Models for Multi-Agent Driving Simulation](https://arxiv.org/abs/2512.05812)
*Fabian Konstantinidis,Moritz Sackmann,Ulrich Hofmann,Christoph Stiller*

Main category: cs.RO

TL;DR: 提出一种基于实例中心场景表示的多智能体驾驶模拟方法，通过局部坐标系表示交通参与者和地图元素，实现高效、视角不变的场景编码，并采用对抗逆强化学习优化行为模型。

- Motivation: 可扩展的多智能体驾驶模拟需要既真实又计算高效的行为模型。现有方法在计算效率和真实性之间存在权衡，特别是在处理大量交通参与者时。
- Method: 1. 采用实例中心场景表示：每个交通参与者和地图元素在各自的局部坐标系中建模，实现高效、视角不变的场景编码，允许静态地图标记在模拟步骤间重用。
2. 使用查询中心对称上下文编码器：通过局部框架间的相对位置编码来建模交互。
3. 采用对抗逆强化学习训练行为模型，并提出自适应奖励变换，在训练过程中自动平衡鲁棒性和真实性。
- Result: 实验表明，该方法能够随着标记数量的增加而高效扩展，显著减少训练和推理时间，同时在位置精度和鲁棒性方面优于多个智能体中心基线方法。
- Conclusion: 提出的实例中心场景表示和对抗逆强化学习方法为可扩展的多智能体驾驶模拟提供了高效且真实的解决方案，在计算效率和性能之间取得了良好平衡。


### [93] [Physically-Based Simulation of Automotive LiDAR](https://arxiv.org/abs/2512.05932)
*L. Dudzik,M. Roschani,A. Sielemann,K. Trampert,J. Ziehn,J. Beyerer,C. Neumann*

Main category: cs.RO

TL;DR: 提出用于汽车ToF激光雷达的物理渲染模型，包含光晕、回波脉冲宽度和环境光等效应，通过实验室测量系统确定参数，并在两种不同激光雷达系统上验证。

- Motivation: 现有激光雷达仿真模型通常简化物理效应，缺乏对光晕、回波脉冲宽度和环境光等关键因素的准确建模，需要更精确的物理基础仿真方法。
- Method: 基于物理渲染(PBR)的近红外域模型，包含单次反射和逆向反射，使用光栅化或光线追踪渲染图像。通过高精度测角仪(0.01°分辨率)的实验室测量确定系统特定参数。
- Result: 成功在Valeo Scala Gen. 2和Blickfeld Cube 1两种不同汽车激光雷达系统上提取相关模型参数并验证，模型能够处理系统特性和环境参数。
- Conclusion: 提出的分析模型能够系统地表征汽车ToF激光雷达性能，通过实验室测量确定参数的方法具有普适性，适用于不同系统特性的激光雷达仿真。


### [94] [SIMPACT: Simulation-Enabled Action Planning using Vision-Language Models](https://arxiv.org/abs/2512.05955)
*Haowen Liu,Shaoxiong Yao,Haonan Chen,Jiawei Gao,Jiayuan Mao,Jia-Bin Huang,Yilun Du*

Main category: cs.RO

TL;DR: SIMPACT：一个无需额外训练、通过模拟循环世界建模为视觉语言模型赋予物理推理能力的测试时动作规划框架

- Motivation: 视觉语言模型在常识和语义推理方面表现出色，但缺乏对物理动态的接地理解。这是因为VLMs在静态的互联网规模视觉语言数据上训练，这些数据不包含因果交互或动作条件变化。因此，难以利用VLMs进行需要物理理解、推理和相应动作规划的细粒度机器人操作任务。
- Method: 提出SIMPACT框架，在测试时通过模拟循环世界建模为VLMs提供物理推理能力。从单个RGB-D观测开始，高效构建物理模拟，使VLM能够提出知情动作、观察模拟推演并迭代优化其推理。通过将语言推理与物理预测相结合，使模拟增强的VLM能够以物理接地的方式理解接触动态和动作结果。
- Result: 在五个需要细粒度物理推理的挑战性真实世界刚体和可变形物体操作任务上展示了最先进的性能，优于现有的通用机器人操作模型。
- Conclusion: 在测试时通过高效模拟将物理理解嵌入VLM推理，为实现通用化具身智能提供了一条有前景的路径。
