[[toc]]

## cs.CV

### [1] [Future Optical Flow Prediction Improves Robot Control & Video Generation](https://arxiv.org/abs/2601.10781)
*Kanchana Ranasinghe,Honglu Zhou,Yu Fang,Luyu Yang,Le Xue,Ran Xu,Caiming Xiong,Silvio Savarese,Michael S Ryoo,Juan Carlos Niebles*

Main category: cs.CV

TL;DR: FOFPred是一个语言条件化的光流预测模型，结合视觉语言模型和扩散架构，从网络规模的人类活动数据中学习，用于控制和生成任务。

- Motivation: 光流等未来运动表示对控制和生成任务很有价值，但预测通用化的密集运动表示仍具挑战性，且从噪声真实数据中学习此类预测相对未被探索。
- Method: 提出FOFPred模型，采用统一的视觉语言模型和扩散架构，结合数据预处理技术和强图像预训练，从网络规模的人类活动视频-字幕数据中学习。
- Result: 模型在机器人操纵和视频生成的语言驱动设置下进行评估，展示了跨领域通用性，验证了统一VLM-扩散架构和从多样化网络数据中可扩展学习的价值。
- Conclusion: 统一的VLM-扩散架构结合网络规模数据学习，为未来光流预测提供了有效的解决方案，具有跨领域应用潜力。


### [2] [ICONIC-444: A 3.1-Million-Image Dataset for OOD Detection Research](https://arxiv.org/abs/2601.10802)
*Gerhard Krumpl,Henning Avenhaus,Horst Possegger*

Main category: cs.CV

TL;DR: ICONIC-444是一个专门用于OOD检测研究的大规模工业图像数据集，包含310万张RGB图像和444个类别，旨在解决现有数据集在规模和任务复杂度上的不足。

- Motivation: 当前OOD检测研究缺乏大规模、高质量的数据集，这些数据集需要明确定义的OOD类别（从近OOD到远OOD），并支持细粒度和粗粒度的计算机视觉任务。
- Method: 通过原型工业分拣机采集数据，构建了包含310万张RGB图像、444个类别的ICONIC-444数据集，定义了四个参考任务来评估OOD检测方法。
- Result: 提供了22种最先进的post-hoc OOD检测方法的基准结果，为OOD检测研究提供了结构化和多样化的评估平台。
- Conclusion: ICONIC-444填补了OOD检测研究的数据集空白，通过模拟真实工业任务，为评估和推进OOD检测方法提供了重要资源。


### [3] [A Unified 3D Object Perception Framework for Real-Time Outside-In Multi-Camera Systems](https://arxiv.org/abs/2601.10819)
*Yizhou Wang,Sameer Pusegaonkar,Yuxing Wang,Anqi Li,Vishal Kumar,Chetan Sethi,Ganapathy Aiyer,Yun He,Kartikay Thakkar,Swapnil Rathi,Bhushan Rupde,Zheng Tang,Sujit Biswas*

Main category: cs.CV

TL;DR: 本文提出了一种针对大规模基础设施环境的优化Sparse4D框架，通过绝对世界坐标几何先验和遮挡感知ReID模块提升多相机多目标跟踪性能，并采用生成式数据增强解决Sim2Real问题，在AI City Challenge 2025基准测试中达到SOTA性能。

- Motivation: 工业基础设施数字化需要准确的3D物体感知和多目标多相机跟踪，但将自动驾驶的"由内向外"模型迁移到静态相机网络的"由外向内"场景面临重大挑战，包括异构相机布置和极端遮挡问题。
- Method: 1) 采用优化的Sparse4D框架；2) 利用绝对世界坐标几何先验；3) 引入遮挡感知ReID嵌入模块保持身份稳定性；4) 使用NVIDIA COSMOS框架进行生成式数据增强，解决Sim2Real域差距；5) 开发TensorRT插件优化多尺度可变形聚合(MSDA)实现硬件加速。
- Result: 1) 在AI City Challenge 2025基准测试中达到SOTA的HOTA分数45.22；2) 硬件加速实现2.15倍速度提升；3) 单个Blackwell级GPU可支持超过64个并发相机流。
- Conclusion: 本文提出的优化框架成功解决了基础设施环境中多相机多目标跟踪的挑战，通过几何先验、遮挡感知ReID和生成式数据增强实现了高性能，并通过硬件加速满足了实时部署需求。


### [4] [Can Vision-Language Models Understand Construction Workers? An Exploratory Study](https://arxiv.org/abs/2601.10835)
*Hieu Bui,Nathaniel E. Chodosh,Arash Tavakoli*

Main category: cs.CV

TL;DR: 评估GPT-4o、Florence 2和LLaVa-1.5三种视觉语言模型在建筑工地图像中识别工人行为和情绪的性能，GPT-4o表现最佳

- Motivation: 随着机器人在建筑工作流程中的集成增加，理解人类行为对安全有效协作至关重要。视觉语言模型（VLMs）在视觉理解任务中表现出潜力，能在缺乏领域特定训练的情况下识别人类行为，这在标注数据稀缺的建筑领域尤其有价值，监测工人行为和情绪对安全和生产力至关重要。
- Method: 使用包含1,000张图像的数据集，标注了10个行为类别和10个情绪类别，评估三种领先的VLM模型（GPT-4o、Florence 2、LLaVa-1.5）的性能。通过标准化推理流程和多种评估指标（F1分数、准确率）进行分析，并使用混淆矩阵识别模型在语义相近类别上的混淆情况。
- Result: GPT-4o在两个任务中都表现最佳：行为识别平均F1分数0.756，准确率0.799；情绪识别F1分数0.712，准确率0.773。Florence 2表现中等（行为F1 0.497，情绪F1 0.414），LLaVa-1.5表现最差（行为F1 0.466，情绪F1 0.461）。所有模型在区分语义相近类别（如团队协作与主管沟通）时都存在困难。
- Conclusion: 通用视觉语言模型在建筑环境中的人类行为识别方面提供了基础能力，但需要领域适应、时序建模或多模态传感等改进才能达到实际应用的可靠性要求。


### [5] [One Model, Many Behaviors: Training-Induced Effects on Out-of-Distribution Detection](https://arxiv.org/abs/2601.10836)
*Gerhard Krumpl,Henning Avenhaus,Horst Possegger*

Main category: cs.CV

TL;DR: 研究发现ID准确率与OOD检测性能存在非单调关系，训练策略、检测器选择和OOD性能之间存在强相互依赖，没有单一方法普遍最优

- Motivation: 尽管OOD检测技术稳步发展，但其与最大化ID准确率和泛化能力的现代训练流程之间的相互作用尚未充分探索。研究旨在探究ID准确率与OOD检测性能之间的关系
- Method: 采用ResNet-50架构，对56个通过不同训练策略获得的ImageNet训练模型，在8个OOD测试集上评估21种后处理、最先进的OOD检测方法
- Result: 发现ID准确率与OOD检测性能存在非单调关系：OOD性能随准确率提高而改善，但当高级训练方法将准确率推至基线以上时反而下降。训练策略、检测器选择和OOD性能之间存在强相互依赖
- Conclusion: 没有单一的OOD检测方法在所有训练策略下都是最优的，ID准确率与OOD检测性能之间的关系比通常假设的更为复杂


### [6] [Effects of Different Attention Mechanisms Applied on 3D Models in Video Classification](https://arxiv.org/abs/2601.10854)
*Mohammad Rasras,Iuliana Marin,Serban Radu,Irina Mocanu*

Main category: cs.CV

TL;DR: 研究通过降低时间特征提取、提高帧分辨率，并在3D ResNet架构中加入不同注意力机制，探索时间特征缺失对动作识别性能的影响。

- Motivation: 研究时间特征减少（同时提高帧分辨率）对3D CNN动作识别性能的影响，探索注意力机制能否补偿时间信息的缺失。
- Method: 基于MC3、R3D、R(2+1)D三种3D ResNet架构，创建减少时间特征提取、提高帧分辨率的变体，并加入dropout层。进一步开发10个新版本，分别集成CBAM、TCN、多头注意力、通道注意力等机制。
- Result: 在UCF101数据集上测试，改进的R(2+1)D+多头注意力变体达到88.98%准确率。不同注意力变体在类别级准确率上表现各异，尽管整体性能提升相似。
- Conclusion: 时间特征的缺失对提高分辨率的新模型性能有显著影响，注意力机制能在一定程度上补偿时间信息损失，但不同注意力模块对各类别的影响存在差异。


### [7] [Medical SAM3: A Foundation Model for Universal Prompt-Driven Medical Image Segmentation](https://arxiv.org/abs/2601.10880)
*Chongcong Jiang,Tianxingjian Ding,Chuhan Song,Jiachen Tu,Ziyang Yan,Yihua Shao,Zhenyi Wang,Yuzhang Shang,Tianyu Han,Yu Tian*

Main category: cs.CV

TL;DR: Medical SAM3是基于SAM3进行全参数微调的医学图像分割基础模型，通过在33个医学影像数据集上训练，显著提升了医学图像分割性能，特别是在语义模糊、复杂形态和3D长程上下文等挑战性场景中。

- Motivation: 现有通用分割基础模型（如SAM3）在医学图像分割中存在严重领域偏移问题，缺乏空间提示，且需要处理复杂的解剖和体积结构。虽然SAM3在自然图像上表现良好，但在医学数据上性能显著下降，其竞争力主要依赖于强几何先验（如真实边界框）。
- Method: 通过在全参数微调SAM3的基础上，使用33个医学影像数据集（涵盖10种成像模态）进行训练，这些数据集包含配对的2D和3D医学图像分割掩码和文本提示，使模型获得领域特定表示同时保持提示驱动的灵活性。
- Result: 在跨器官、成像模态和维度的广泛实验中，Medical SAM3表现出一致且显著的性能提升，特别是在语义模糊、复杂形态和长程3D上下文等挑战性场景中。相比原始SAM3，在医学图像分割任务上取得了更好的效果。
- Conclusion: Medical SAM3成为医学影像的通用文本引导分割基础模型，证明了在严重领域偏移下，整体模型适应（而非仅提示工程）对于实现稳健的提示驱动分割至关重要。代码和模型将开源。


### [8] [FrankenMotion: Part-level Human Motion Generation and Composition](https://arxiv.org/abs/2601.10909)
*Chuqiao Li,Xianghui Xie,Yong Cao,Andreas Geiger,Gerard Pons-Moll*

Main category: cs.CV

TL;DR: 提出FrankenMotion：首个具有原子级、时序感知的部位级文本标注的运动数据集，以及基于扩散的部位感知运动生成框架，实现空间（身体部位）和时间（原子动作）的细粒度控制。

- Motivation: 现有文本到运动生成方法主要依赖序列级或动作级描述，缺乏细粒度的部位级运动标注，限制了其对单个身体部位的可控性。需要构建高质量的部位级标注数据集来解决这一问题。
- Method: 1. 利用大语言模型的推理能力构建具有原子级、时序感知的部位级文本标注的运动数据集；2. 提出基于扩散的部位感知运动生成框架FrankenMotion，每个身体部位由其自身的时序结构化文本提示引导。
- Result: FrankenMotion在实验设置中优于所有先前经过调整和重新训练的基线模型，并且能够组合训练中未见过的运动。该模型实现了空间（身体部位）和时间（原子动作）的双重控制。
- Conclusion: 这是首个提供原子级、时序感知的部位级运动标注的工作，并提出了能够实现空间和时间细粒度控制的运动生成模型，显著提升了文本到运动生成的可控性和组合能力。


### [9] [Classification of Chest XRay Diseases through image processing and analysis techniques](https://arxiv.org/abs/2601.10913)
*Santiago Martínez Novoa,María Catalina Ibáñez,Lina Gómez Mesa,Jeremias Kramer*

Main category: cs.CV

TL;DR: 该论文综述了多分类胸部X光图像分析方法，比较了包括DenseNet121在内的多种方法，并部署了一个开源Web应用进行测试和评估。

- Motivation: 胸部X光图像是诊断胸部疾病最常用的放射学检查方法之一，但现有方法需要系统性的比较和评估，以确定最佳实践并改进现有技术。
- Method: 采用多种方法（包括DenseNet121）进行多分类胸部X光图像分析，部署开源Web应用程序进行测试，并对不同方法进行系统性比较。
- Result: 通过测试比较了不同方法的性能，识别了所提出方法的弱点，并提出了改进建议。
- Conclusion: 该研究为多分类胸部X光图像分析提供了方法比较框架，指出了现有方法的局限性，并为未来改进提供了方向，相关代码已开源。


### [10] [Self-learned representation-guided latent diffusion model for breast cancer classification in deep ultraviolet whole surface images](https://arxiv.org/abs/2601.10917)
*Pouya Afshin,David Helminiak,Tianling Niu,Julie M. Jorns,Tina Yen,Bing Yu,Dong Hye Ye*

Main category: cs.CV

TL;DR: 提出基于自监督学习引导的潜在扩散模型，生成高质量合成DUV-FSM图像补丁，结合真实数据增强ViT模型，显著提升乳腺癌保乳手术边缘评估的准确性。

- Motivation: 乳腺癌保乳手术需要精确的术中边缘评估，但深度紫外荧光扫描显微镜数据标注稀缺，限制了深度学习模型的训练效果。
- Method: 使用自监督学习引导的潜在扩散模型生成合成训练补丁，通过微调的DINO教师模型嵌入注入细胞结构语义细节，结合真实与合成数据微调视觉Transformer，采用补丁预测聚合进行全切片图像分类。
- Result: 5折交叉验证显示，该方法达到96.47%的准确率，FID分数降至45.72，显著优于类别条件基线方法。
- Conclusion: 提出的SSL引导LDM方法能有效解决DUV-FSM数据稀缺问题，生成高质量合成数据，显著提升乳腺癌边缘评估模型的性能。


### [11] [RobuMTL: Enhancing Multi-Task Learning Robustness Against Weather Conditions](https://arxiv.org/abs/2601.10921)
*Tasneem Shaffee,Sherief Reda*

Main category: cs.CV

TL;DR: RobuMTL：一种通过动态选择任务特定的分层LoRA模块和LoRA专家小组来应对恶劣天气条件影响的多任务学习鲁棒架构。

- Motivation: 现实世界中恶劣天气条件会严重降低自动驾驶系统模型的性能和可靠性，需要鲁棒的多任务学习方法来应对视觉退化问题。
- Method: 提出RobuMTL架构，采用混合专家方式，根据输入扰动动态选择任务特定的分层低秩适应（LoRA）模块和LoRA专家小组，实现基于输入特征的自适应专业化。
- Result: 在PASCAL数据集上，相比MTL基线，单扰动下平均相对提升+2.8%，混合天气条件下提升达+44.4%；在NYUD-v2数据集上，跨任务平均相对提升+9.7%。
- Conclusion: RobuMTL通过自适应选择LoRA模块和专家小组，有效提升了多任务学习在恶劣天气条件下的鲁棒性，在多个基准测试中显著优于现有方法。


### [12] [Sparse Data Tree Canopy Segmentation: Fine-Tuning Leading Pretrained Models on Only 150 Images](https://arxiv.org/abs/2601.10931)
*David Szczecina,Hudson Sun,Anthony Bertnyk,Niloofar Azad,Kyle Gao,Lincoln Linlin Xu*

Main category: cs.CV

TL;DR: 该研究评估了五种深度学习模型在仅有150张标注图像的小数据集上进行树冠检测的性能，发现基于CNN的YOLOv11和Mask R-CNN表现优于基于Transformer的模型。

- Motivation: 树冠检测对环境监测、城市规划和生态系统分析很重要，但实际应用中常面临数据标注稀缺的问题。Solafune树冠检测竞赛提供的小规模不平衡数据集（仅150张标注图像）为训练深度模型带来了严重过拟合的挑战。
- Method: 评估了五种代表性架构：YOLOv11、Mask R-CNN、DeepLabv3、Swin-UNET和DINOv2，在极端数据稀缺条件下进行树冠分割。分析了训练策略、数据增强策略和模型在小数据约束下的行为。
- Result: 预训练的基于卷积的模型（特别是YOLOv11和Mask R-CNN）比预训练的基于Transformer的模型泛化能力显著更好。DeepLabv3、Swin-UNET和DINOv2表现不佳，可能由于语义分割与实例分割任务的差异、Vision Transformers的高数据需求以及缺乏强归纳偏置。
- Conclusion: Transformer架构在低数据环境下表现不佳，除非有大量预训练或数据增强；语义分割与实例分割的差异进一步影响模型性能；轻量级CNN方法在有限图像数据上进行树冠检测仍然是最可靠的。


### [13] [PatientVLM Meets DocVLM: Pre-Consultation Dialogue Between Vision-Language Models for Efficient Diagnosis](https://arxiv.org/abs/2601.10945)
*K Lokesh,Abhirama Subramanyam Penamakuri,Uday Agarwal,Apoorva Challa,Shreya K Gowda,Somesh Gupta,Anand Mishra*

Main category: cs.CV

TL;DR: 提出预咨询对话框架(PCDF)，通过两个视觉语言模型模拟真实诊断对话，显著提升医疗诊断准确性

- Motivation: 传统AI医疗诊断主要依赖图像分析，但缺乏患者自述症状信息限制了诊断准确性。需要模拟真实医生诊断过程，通过对话获取症状信息。
- Method: 设计预咨询对话框架：DocVLM基于图像和对话历史生成追问问题，PatientVLM根据真实诊断的症状档案进行回答。通过小规模临床验证合成症状的临床相关性，并用对话数据微调DocVLM。
- Result: 临床医生确认合成症状具有临床相关性、症状覆盖度和真实感。基于对话的监督训练相比仅图像训练取得显著提升，证明症状询问对诊断的价值。
- Conclusion: 预咨询对话框架能生成真实的多轮医疗咨询对话，结合图像和症状信息显著提高诊断准确性，为AI医疗诊断提供了新的有效方法。


### [14] [MMedExpert-R1: Strengthening Multimodal Medical Reasoning via Domain-Specific Adaptation and Clinical Guideline Reinforcement](https://arxiv.org/abs/2601.10949)
*Meidan Ding,Jipeng Zhang,Wenxuan Wang,Haiqin Zhong,Xiaoling Luo,Wenting Chen,Linlin Shen*

Main category: cs.CV

TL;DR: MMedExpert-R1是一个新颖的医学视觉语言模型，通过领域特定适应和临床指南强化来解决现有MedVLMs在复杂临床推理中的不足，在多个医学基准测试中达到最先进性能。

- Motivation: 现有的医学视觉语言模型擅长感知任务，但在真实世界场景所需的复杂临床推理方面表现不佳。虽然强化学习被探索用于增强推理能力，但现有方法面临关键不匹配：深度推理数据稀缺、冷启动限制多专科对齐，以及标准RL算法无法建模临床推理多样性。
- Method: 1. 构建MMedExpert数据集：包含10K样本，涵盖四个专科，带有逐步推理轨迹；2. 领域特定适应：创建专科特定的LoRA模块提供多样化初始化；3. 基于指南的优势：明确建模不同临床推理视角以对齐真实世界诊断策略；4. 冲突感知能力集成：将这些专科专家合并为统一代理，确保稳健的多专科对齐。
- Result: 在全面实验中展示了最先进的性能：7B模型在MedXpert-MM上达到27.50分，在OmniMedVQA上达到83.03分，为可靠的医学多模态推理系统建立了坚实基础。
- Conclusion: MMedExpert-R1通过领域特定适应和临床指南强化，成功解决了医学视觉语言模型在复杂临床推理中的关键挑战，实现了多专科对齐和稳健的推理能力，为可靠的医学多模态推理系统提供了有效解决方案。


### [15] [IDDR-NGP: Incorporating Detectors for Distractor Removal with Instant Neural Radiance Field](https://arxiv.org/abs/2601.11030)
*Xianliang Huang,Jiajie Gou,Shuhang Chen,Zhizhou Zhong,Jihong Guan,Shuigeng Zhou*

Main category: cs.CV

TL;DR: IDDR-NGP是首个统一的3D场景干扰物去除方法，基于Instant-NGP，能处理多种干扰物（雪花、彩纸、落叶等），通过结合隐式3D表示和2D检测器，从多张受损图像中高效恢复3D场景。

- Motivation: 现有方法通常只针对特定类型的干扰物，缺乏统一的3D场景干扰物去除方法。需要一种能处理多种干扰物类型的方法，以应对真实世界中复杂的干扰场景。
- Method: 基于Instant-NGP，结合隐式3D表示和2D检测器，设计LPIPS损失和多视角补偿损失(MVCL)联合优化渲染结果，端到端训练合成高质量3D场景。构建包含合成和真实干扰物的新基准数据集。
- Result: IDDR-NGP能有效去除多种类型干扰物，在去雪任务上达到SOTA水平，能准确去除真实和合成干扰物，实验证明了方法的有效性和鲁棒性。
- Conclusion: IDDR-NGP是首个统一的3D场景干扰物去除方法，能处理多种干扰物类型，通过结合隐式3D表示和2D检测器，从多视角受损图像中高效恢复高质量3D场景。


### [16] [Your One-Stop Solution for AI-Generated Video Detection](https://arxiv.org/abs/2601.11035)
*Long Ma,Zihao Xue,Yan Wang,Zhiyuan Yan,Jin Xu,Xiaorui Jiang,Haiyang Yu,Yong Liao,Zhen Bi*

Main category: cs.CV

TL;DR: AIGVDBench：一个全面的AI生成视频检测基准，涵盖31个最新生成模型和44万+视频，对33个检测器进行1500+次评估，提供8项深度分析和4个新发现。

- Motivation: 当前AI生成视频检测领域存在两个关键限制：1）数据集方面：现有数据集规模有限，使用过时或范围狭窄的生成模型，难以捕捉现代生成技术的多样性和快速演变；2）基准方面：当前基准主要停留在数据集创建阶段，缺乏系统性的深入分析。
- Method: 提出AIGVDBench基准，涵盖31个最先进的生成模型和超过44万个视频，对属于四个不同类别的33个现有检测器执行超过1500次评估。
- Result: 从多个角度提出了8项深度分析，并识别出4个新颖发现，为未来研究提供有价值的见解。
- Conclusion: AIGVDBench为推进AI生成视频检测领域提供了坚实基础，该基准已在GitHub上开源。


### [17] [M3DDM+: An improved video outpainting by a modified masking strategy](https://arxiv.org/abs/2601.11048)
*Takuya Murakawa,Takumi Fukuzawa,Ning Ding,Toru Tamaki*

Main category: cs.CV

TL;DR: M3DDM+改进M3DDM视频外绘框架，通过统一训练时的掩码方向解决训练-推理不匹配问题，提升信息有限场景下的视觉质量和时间一致性

- Motivation: M3DDM在相机运动有限或外绘区域较大的挑战性场景中，会出现空间模糊和时间不一致的质量下降问题。研究发现这是由于训练时随机掩码方向与推理时需要一致方向外绘之间的不匹配造成的。
- Method: 提出M3DDM+，在训练时对所有帧应用统一的掩码方向和宽度，然后对预训练的M3DDM模型进行微调，以解决训练-推理不匹配问题。
- Result: 实验表明M3DDM+在信息有限场景下显著提高了视觉保真度和时间一致性，同时保持了计算效率。
- Conclusion: 通过统一训练时的掩码策略，M3DDM+有效解决了M3DDM在挑战性场景中的质量下降问题，为视频外绘提供了更可靠的解决方案。


### [18] [PhysRVG: Physics-Aware Unified Reinforcement Learning for Video Generative Models](https://arxiv.org/abs/2601.11087)
*Qiyuan Zhang,Biao Gong,Shuai Tan,Zheng Zhang,Yujun Shen,Xing Zhu,Yuyuan Li,Kelu Yao,Chunhua Shen,Changqing Zou*

Main category: cs.CV

TL;DR: 提出首个物理感知的强化学习范式用于视频生成模型，通过Mimicry-Discovery Cycle框架在保持模型能力的同时强制执行物理碰撞规则

- Motivation: 当前基于Transformer的视频生成模型缺乏物理原理的建模，特别是在刚体运动方面。虽然计算机图形学和物理模拟器可以轻松使用牛顿公式建模碰撞，但现代预训练-微调范式在像素级全局去噪过程中丢弃了物体刚性的概念，限制了生成视频的物理真实感
- Method: 提出物理感知的强化学习范式，直接在视频生成模型中强制执行物理碰撞规则；进一步扩展为Mimicry-Discovery Cycle统一框架，允许大幅微调同时完全保留模型利用物理基础反馈的能力
- Result: 构建了新的基准测试PhysRVGBench，并通过广泛的定性和定量实验验证了方法的有效性
- Conclusion: 首次将物理感知强化学习范式引入视频生成，通过MDcycle框架在保持模型能力的同时强制执行物理规则，显著提升了生成视频的物理真实感


### [19] [CoDance: An Unbind-Rebind Paradigm for Robust Multi-Subject Animation](https://arxiv.org/abs/2601.11096)
*Shuai Tan,Biao Gong,Ke Ma,Yutong Feng,Qiyuan Zhang,Yan Wang,Yujun Shen,Hengshuang Zhao*

Main category: cs.CV

TL;DR: CoDance提出Unbind-Rebind框架，通过解绑姿势与参考图像间的刚性空间对齐，再结合语义和空间引导重新绑定，实现任意数量、类型和空间配置的多主体角色动画。

- Motivation: 现有方法在单角色动画上表现良好，但难以处理任意主体数量、多样角色类型以及参考图像与驱动姿势间的空间错位问题。这些限制源于过于刚性的空间绑定和无法将运动准确重绑定到目标主体。
- Method: 提出Unbind-Rebind框架：1) Unbind模块使用姿势偏移编码器，通过对姿势及其潜在特征引入随机扰动，打破姿势与参考间的刚性空间绑定，学习位置无关的运动表示；2) Rebind模块利用文本提示的语义引导和主体掩码的空间引导，将学习到的运动重定向到目标角色。
- Result: 在新建的CoDanceBench和现有数据集上的实验表明，CoDance达到SOTA性能，在多样主体和空间布局上展现出卓越的泛化能力。
- Conclusion: CoDance通过创新的Unbind-Rebind框架解决了多主体角色动画的关键挑战，实现了对任意数量、类型和空间配置角色的灵活动画生成，并建立了新的评估基准。


### [20] [Graph Smoothing for Enhanced Local Geometry Learning in Point Cloud Analysis](https://arxiv.org/abs/2601.11102)
*Shangbo Yuan,Jie Xu,Ping Hu,Xiaofeng Zhu,Na Zhao*

Main category: cs.CV

TL;DR: 提出一种结合图平滑模块和增强局部几何学习模块的新方法，解决3D点云分析中边界点稀疏连接和交叉区域噪声连接的问题

- Motivation: 现有的基于图的方法在3D点云分析中虽然有效，但存在图结构不理想的问题，特别是在边界点处连接稀疏，在交叉区域存在噪声连接，这影响了方法的性能
- Method: 1. 提出图平滑模块来优化图结构，减少不可靠稀疏连接和噪声连接的负面影响；2. 基于优化后的图结构，通过局部几何信息改进特征提取函数，包括基于特征向量的自适应几何描述符提取形状特征，以及通过圆柱坐标变换获取分布特征
- Result: 在真实世界数据集上的实验结果表明，该方法在多种点云学习任务（分类、部件分割、语义分割）中均表现出有效性
- Conclusion: 通过集成图平滑和增强局部几何学习，能够有效解决传统图结构在边界点和交叉区域的局限性，提升3D点云分析性能


### [21] [Vision-as-Inverse-Graphics Agent via Interleaved Multimodal Reasoning](https://arxiv.org/abs/2601.11109)
*Shaofeng Yin,Jiaxin Ge,Zora Zhiruo Wang,Xiuyu Li,Michael J. Black,Trevor Darrell,Angjoo Kanazawa,Haiwen Feng*

Main category: cs.CV

TL;DR: VIGA是一个视觉逆向图形智能体，通过迭代执行和验证的闭环过程，将图像重建为可编辑的图形程序，在多个基准测试中显著优于单次基线方法。

- Motivation: 当前强大的视觉语言模型缺乏细粒度的空间和物理基础能力，无法一次性实现视觉逆向图形（将图像重建为可编辑图形程序）的目标。需要解决多模态推理的迭代执行和验证问题。
- Method: VIGA采用闭环的"编写-运行-渲染-比较-修订"过程，从空世界开始重建或编辑场景。结合技能库（交替生成器和验证器角色）和演进上下文记忆（包含计划、代码差异和渲染历史），支持长程推理。
- Result: 在BlenderGym上提升35.32%，SlideBench上提升117.17%，新提出的BlenderBench上提升124.70%。VIGA是任务无关的，无需辅助模块，覆盖3D重建、多步场景编辑、4D物理交互和2D文档编辑等任务。
- Conclusion: VIGA通过迭代多模态推理解决了视觉逆向图形的挑战，实现了任务无关和模型无关的解决方案，显著提升了现有方法的性能，并为评估异构基础视觉语言模型提供了统一协议。


### [22] [SoLA-Vision: Fine-grained Layer-wise Linear Softmax Hybrid Attention](https://arxiv.org/abs/2601.11164)
*Ruibang Li,Guan Luo,Yiwei Zhang,Jin Gao,Bing Li,Weiming Hu*

Main category: cs.CV

TL;DR: SoLA-Vision提出了一种层级的软注意力与线性注意力混合架构，通过精细控制软注意力层插入策略，在保持高性能的同时显著降低计算复杂度。

- Motivation: 标准软注意力在视觉任务中表现出色但计算复杂度为O(N²)，限制了高分辨率应用；线性注意力复杂度为O(N)但建模能力受限。需要找到平衡计算效率和性能的解决方案。
- Method: 通过分析研究和系统实验对比线性与软注意力，提出SoLA-Vision：一种灵活的层级混合注意力骨干网络，通过精细控制软注意力层插入策略实现计算优化。
- Result: 在ImageNet-1K上优于纯线性和其他混合注意力模型；在密集预测任务中显著超越强基线；通过少量全局软注意力层实现精度与计算成本的强权衡。
- Conclusion: 层级混合注意力设计比刚性块内混合更有效，SoLA-Vision通过精细的软注意力层插入策略，在保持高性能的同时显著降低计算复杂度，为高分辨率视觉任务提供实用解决方案。


### [23] [Democratizing planetary-scale analysis: An ultra-lightweight Earth embedding database for accurate and flexible global land monitoring](https://arxiv.org/abs/2601.11183)
*Shuang Chen,Jie Wang,Shuai Yuan,Jiayang Li,Yu Xia,Yuanhong Liao,Junbo Wei,Jincheng Yuan,Xiaoqing Xu,Xiaolin Zhu,Peng Zhu,Hongsheng Zhang,Yuyu Zhou,Haohuan Fu,Huabing Huang,Bin Chen,Fan Dai,Peng Gong*

Main category: cs.CV

TL;DR: ESD是一个超轻量级的30米全球地球嵌入数据库，将2000-2024年25年的多传感器卫星观测数据压缩为信息密集的量化潜在向量，实现340倍数据压缩，使全球陆地表面单年数据仅需2.4TB，可在标准工作站上进行十年尺度全球分析。

- Motivation: 卫星地球观测系统产生了PB级数据，但巨大的计算和存储需求阻碍了全球尺度分析的广泛应用，限制了行星尺度研究。需要解决这些障碍来促进全球研究。
- Method: 使用ESDNet架构和有限标量量化(FSQ)，将Landsat系列(5,7,8,9)和MODIS Terra的高维多传感器观测转换为信息密集的量化潜在向量，将年度物候周期压缩为12个时间步长。
- Result: 实现了约340倍的数据压缩比，全球陆地表面单年数据仅需2.4TB；重建保真度高(MAE:0.0130, RMSE:0.0179, CC:0.8543)；土地覆盖分类准确率达79.74%，优于原始反射率融合的76.92%；具有强大的少样本学习能力和纵向一致性。
- Conclusion: ESD为民主化行星尺度研究和推进下一代地理空间人工智能提供了多功能基础，使全球尺度分析能够在标准本地工作站上进行，解决了大规模卫星数据分析的存储和计算瓶颈。


### [24] [ATATA: One Algorithm to Align Them All](https://arxiv.org/abs/2601.11194)
*Boyi Pang,Savva Ignatyev,Vladimir Ippolitov,Ramil Khafizov,Yurii Melnik,Oleg Voynov,Maksim Nakhodnov,Aibek Alanov,Xiaopeng Fan,Peter Wonka,Evgeny Burnaev*

Main category: cs.CV

TL;DR: 提出基于Rectified Flow的多模态联合推理算法，用于结构对齐的样本对生成，相比现有方法更快且质量更高

- Motivation: 现有方法在联合生成时未从结构对齐角度考虑问题，而基于Score Distillation Sampling的方法存在计算耗时、模式崩溃和卡通化结果等问题
- Method: 基于Rectified Flow模型，在结构化潜在空间中进行联合传输，利用样本空间的片段联合运输实现快速推理
- Result: 在图像、视频和3D形状生成任务中表现出优异的结构对齐性和视觉质量，图像和视频生成达到SOTA，3D生成质量相当但速度快数个数量级
- Conclusion: 提出的方法在保持高质量的同时显著提升了推理速度，为多模态联合生成提供了有效的结构对齐解决方案


### [25] [Bio-inspired fine-tuning for selective transfer learning in image classification](https://arxiv.org/abs/2601.11235)
*Ana Davila,Jacinto Colan,Yasuhisa Hasegawa*

Main category: cs.CV

TL;DR: BioTune是一种基于进化优化的自适应微调技术，通过智能选择冻结层和调整学习率来提升迁移学习效果，在多个图像分类数据集上优于现有方法。

- Motivation: 深度学习依赖大量标注数据，迁移学习虽能缓解此问题，但源域和目标域之间的差异会阻碍有效迁移。需要一种能自适应调整微调策略的方法来提升迁移学习效果。
- Method: BioTune采用进化优化技术，智能选择哪些层需要冻结，并为未冻结层调整学习率。该方法通过优化层冻结策略和学习率配置来适应不同的数据特性和分布变化。
- Result: 在9个图像分类数据集（包括自然图像和医学影像）上，BioTune在准确性和效率方面均优于AutoRGN、LoRA等最先进的微调方法。在4种不同CNN架构上均表现出色，展现了良好的适应性。
- Conclusion: BioTune通过进化优化实现自适应微调，有效解决了迁移学习中源域和目标域不匹配的问题，在多种任务和架构上表现出优越的性能和灵活性。


### [26] [Image-Text Knowledge Modeling for Unsupervised Multi-Scenario Person Re-Identification](https://arxiv.org/abs/2601.11243)
*Zhiqi Pang,Lingling Zhao,Yang Liu,Chunyu Wang,Gaurav Sharma*

Main category: cs.CV

TL;DR: 提出无监督多场景行人重识别新任务，通过图像-文本知识建模三阶段框架，利用视觉语言模型跨多个场景（跨分辨率、换装等）提升性能

- Motivation: 现有行人重识别方法通常针对特定场景设计，缺乏统一框架处理多场景问题。需要开发能够跨不同场景（如分辨率变化、服装更换等）统一处理的无监督方法
- Method: 提出图像-文本知识建模三阶段框架：1) 在图像编码器中引入场景嵌入并微调；2) 优化文本嵌入与伪标签关联，引入多场景分离损失；3) 通过异构匹配模块获取可靠正样本对，采用动态文本表示更新策略保持一致性
- Result: 在多个场景实验中表现出优越性和泛化能力，不仅超越现有场景特定方法，还能通过整合多场景知识提升整体性能
- Conclusion: 提出的无监督多场景行人重识别框架ITKM有效利用视觉语言模型表示能力，为跨场景行人重识别提供了统一解决方案，具有良好泛化性能


### [27] [Language-Agnostic Visual Embeddings for Cross-Script Handwriting Retrieval](https://arxiv.org/abs/2601.11248)
*Fangke Chen,Tianhao Dong,Sirry Chen,Guobin Zhang,Yishu Zhang,Yining Chen*

Main category: cs.CV

TL;DR: 提出轻量级非对称双编码器框架，用于跨语言手写词检索，通过联合优化实例级对齐和类级语义一致性，学习统一、风格不变的视觉嵌入，在保持高精度的同时大幅减少参数数量。

- Motivation: 手写词检索对于数字档案至关重要，但由于手写变异性大和跨语言语义鸿沟而具有挑战性。现有的大型视觉语言模型计算成本过高，难以在实际边缘设备上部署。
- Method: 提出轻量级非对称双编码器框架，学习统一、风格不变的视觉嵌入。通过联合优化实例级对齐和类级语义一致性，将视觉嵌入锚定到语言无关的语义原型，强制跨文字和书写风格的不变性。
- Result: 在28个基线方法中表现最佳，在语言内检索基准上达到最先进精度。在显式跨语言检索（查询语言与目标语言不同）中验证了学习到的跨语言表示的有效性。仅需现有模型参数的一小部分即可实现强大性能。
- Conclusion: 该框架实现了准确且资源高效的跨文字手写检索，为实际边缘部署提供了可行的解决方案，解决了手写词检索中的计算成本和跨语言语义鸿沟问题。


### [28] [FTDMamba: Frequency-Assisted Temporal Dilation Mamba for Unmanned Aerial Vehicle Video Anomaly Detection](https://arxiv.org/abs/2601.11254)
*Cheng-Zhuang Liu,Si-Bao Chen,Qing-Ling Shu,Chris Ding,Jin Tang,Bin Luo*

Main category: cs.CV

TL;DR: 提出FTDMamba网络用于无人机视频异常检测，通过频率解耦时空相关模块和时序扩张Mamba模块处理动态背景，并构建了新的MUVAD数据集。

- Motivation: 现有视频异常检测方法主要针对静态背景，对无人机动态背景视频研究有限。动态背景中物体运动与无人机全局运动耦合，现有方法容易误判正常无人机运动为异常，或无法检测动态背景中隐藏的真实异常。
- Method: 提出FTDMamba网络，包含两个核心组件：1) 频率解耦时空相关模块，通过频率分析解耦耦合运动模式并建模全局时空依赖；2) 时序扩张Mamba模块，利用Mamba序列建模能力联合学习多时间感受野下的细粒度时序动态和局部空间结构。
- Result: 在两个公开静态基准测试和新构建的MUVAD数据集上，FTDMamba都达到了最先进的性能。MUVAD数据集包含222,736帧、240个异常事件、12种异常类型。
- Conclusion: FTDMamba网络有效解决了无人机动态背景视频异常检测的挑战，通过频率分析和Mamba序列建模实现了更好的性能，新构建的MUVAD数据集填补了该领域数据空白。


### [29] [X-Distill: Cross-Architecture Vision Distillation for Visuomotor Learning](https://arxiv.org/abs/2601.11269)
*Maanping Shao,Feihong Zhang,Gu Zhang,Baiye Cheng,Zhengrong Xue,Huazhe Xu*

Main category: cs.CV

TL;DR: X-Distill通过跨架构知识蒸馏，将大型DINOv2 ViT的视觉表示转移到小型ResNet-18上，再结合扩散策略头进行微调，在数据稀缺的机器人操作任务中实现最先进性能。

- Motivation: 视觉运动策略通常使用大型预训练ViT以获得强大泛化能力，但在数据稀缺的机器人学习环境中，其大量数据需求成为主要挑战，而紧凑CNN具有更强的归纳偏置且更容易优化。需要解决这种权衡问题。
- Method: 提出X-Distill方法：1) 在通用ImageNet数据集上进行离线跨架构知识蒸馏，将大型冻结DINOv2教师的丰富视觉表示转移到紧凑ResNet-18学生；2) 将蒸馏后的编码器与扩散策略头在目标操作任务上联合微调。
- Result: 在34个模拟基准和5个具有挑战性的真实世界任务上的广泛实验表明，该方法始终优于使用从头训练ResNet或微调DINOv2编码器的策略，甚至超过使用特权点云观测或更大视觉语言模型的3D编码器。
- Conclusion: 这项工作展示了简单、理论基础扎实的蒸馏策略在数据高效机器人操作中实现最先进性能的有效性，为数据稀缺环境下的机器人学习提供了实用解决方案。


### [30] [Efficient On-Board Processing of Oblique UAV Video for Rapid Flood Extent Mapping](https://arxiv.org/abs/2601.11290)
*Vishisht Sharma,Sam Leroux,Lisa Landuyt,Nick Witvrouwen,Pieter Simoens*

Main category: cs.CV

TL;DR: TTR框架通过动态识别静态区域并传播预计算特征，在边缘设备上加速视频分割，实现30%延迟降低且精度损失可忽略

- Motivation: 无人机灾害响应中，倾斜航拍视频处理面临严格的SWaP约束，标准边缘硬件无法满足高分辨率宽视场视频流的低延迟推理需求
- Method: 提出Temporal Token Reuse框架：将图像块表示为token，使用轻量相似度度量动态识别静态区域，传播预计算深度特征，避免冗余主干计算
- Result: 在边缘级硬件上，TTR实现30%推理延迟降低，分割精度损失可忽略（<0.5% mIoU），验证了在标准基准和新构建的倾斜洪水数据集上的有效性
- Conclusion: TTR有效移动了操作帕累托边界，为时间关键的遥感任务实现了高保真、实时的倾斜视频理解能力


### [31] [SAMannot: A Memory-Efficient, Local, Open-source Framework for Interactive Video Instance Segmentation based on SAM2](https://arxiv.org/abs/2601.11301)
*Gergely Dinya,András Gelencsér,Krisztina Kupán,Clemens Küpper,Kristóf Karacs,Anna Gelencsér-Horváth*

Main category: cs.CV

TL;DR: SAMannot是一个开源本地视频实例分割框架，集成SAM2模型，通过人机协作工作流解决研究中的视频标注瓶颈问题。

- Motivation: 当前视频分割研究面临手动标注耗时、商业平台昂贵、云服务隐私风险等问题，需要高保真视频实例分割但受限于标注瓶颈和隐私担忧。
- Method: 开发开源本地框架，集成SAM2模型，优化计算资源使用，实现持久实例身份管理、"锁定-精炼"工作流、基于掩码骨架化的自动提示机制。
- Result: 通过动物行为追踪案例和LVOS、DAVIS基准数据集验证，工具能生成YOLO和PNG格式的研究就绪数据集，提供可扩展、私密、经济高效的视频标注方案。
- Conclusion: SAMannot为复杂视频标注任务提供了可扩展、私密、经济高效的商业平台替代方案，解决了研究中的视频分割标注瓶颈问题。


### [32] [Context-Aware Semantic Segmentation via Stage-Wise Attention](https://arxiv.org/abs/2601.11310)
*Antoine Carreaud,Elias Naha,Arthur Chansel,Nina Lahellec,Jan Skaloud,Adrien Gressin*

Main category: cs.CV

TL;DR: CASWiT是一种用于超高分辨率遥感图像分割的双分支Transformer架构，通过上下文编码器和高分辨率编码器结合跨尺度融合模块，解决了传统Transformer内存爆炸问题，并在IGN FLAIR-HUB和URUR数据集上取得了SOTA性能。

- Motivation: 超高分辨率遥感图像分割在航空测绘和环境监测中至关重要。传统Transformer模型在处理此类图像时面临内存爆炸问题（token数量平方增长），限制了上下文范围或空间分辨率。
- Method: 提出CASWiT双分支Swin-based架构：1) 上下文编码器处理下采样邻域捕获长距离依赖；2) 高分辨率编码器提取UHR补丁的细粒度特征；3) 跨尺度融合模块结合交叉注意力和门控特征注入，用上下文丰富高分辨率token。此外提出SimMIM风格预训练，掩码75%高分辨率图像token和对应低分辨率中心区域，用小型解码器重建原始图像。
- Result: 在IGN FLAIR-HUB数据集上达到65.83% mIoU，比RGB基线提升1.78个百分点。在URUR数据集上达到49.1% mIoU，比当前SOTA提升0.9%。
- Conclusion: CASWiT通过双分支架构和跨尺度融合有效解决了Transformer在超高分辨率图像分割中的内存限制问题，结合SimMIM风格预训练进一步提升了性能，在多个遥感数据集上实现了新的SOTA。


### [33] [Enhancing Vision Language Models with Logic Reasoning for Situational Awareness](https://arxiv.org/abs/2601.11322)
*Pavana Pradeep,Krishna Kant,Suya Yu*

Main category: cs.CV

TL;DR: 提出结合视觉语言模型与传统计算机视觉的显式逻辑推理方法，通过智能微调策略提升情境感知的准确性和可靠性

- Motivation: 在情境感知应用中，需要可靠识别低频但重要的事件，同时提取细粒度细节并评估识别质量。当前视觉语言模型虽然能生成可解释描述，但在准确性和可靠性方面仍需改进
- Method: 整合视觉语言模型与传统计算机视觉方法，通过显式逻辑推理增强情境感知，包括：(a)提取细粒度事件细节，(b)采用智能微调策略提升准确性，(c)在推理过程中为VLM输出生成解释
- Result: 智能微调机制显著提高了准确性，并在推理过程中提供验证VLM输出有效性或指出其问题的方法
- Conclusion: 通过显式逻辑推理结合VLM与传统CV方法，能够有效提升情境感知系统的可靠性和准确性，特别是在低频重要事件识别和细粒度细节提取方面


### [34] [Beer-Lambert Autoencoder for Unsupervised Stain Representation Learning and Deconvolution in Multi-immunohistochemical Brightfield Histology Images](https://arxiv.org/abs/2601.11336)
*Mark Eastwood,Thomas McKee,Zedong Hu,Sabine Tejpar,Fayyaz Minhas*

Main category: cs.CV

TL;DR: 提出一种基于编码器-解码器架构的数据驱动方法，用于从RGB组织切片图像中分离多个染色剂的贡献，解决了传统Beer-Lambert方法在多重免疫组化中不稳定的问题。

- Motivation: 在多重免疫组化（mIHC）中，当染色剂数量超过3个时，传统的Beer-Lambert颜色去卷积方法变得欠定和不稳定，需要一种能够准确分离多个染色剂贡献的方法。
- Method: 采用简单的数据驱动编码器-解码器架构：编码器是紧凑的U-Net，预测K个非负浓度通道；解码器是可微分的Beer-Lambert前向模型，带有可学习的染色矩阵，初始化为典型染色剂色调。训练是无监督的，使用感知重建目标，并加入防止不必要染色混合的损失项。
- Result: 在包含5种染色剂（H, CDX2, MUC2, MUC5, CD8）的结直肠mIHC面板上，展示了优异的RGB重建效果，与基于矩阵的去卷积方法相比，显著减少了通道间渗漏。
- Conclusion: 该方法能够学习队列特定的染色特征，产生清晰、分离良好的每染色浓度图，为多重免疫组化分析提供了有效的解决方案，代码和模型已开源。


### [35] [Assessing Building Heat Resilience Using UAV and Street-View Imagery with Coupled Global Context Vision Transformer](https://arxiv.org/abs/2601.11357)
*Steffen Knoblauch,Ram Kumar Muthusamy,Hao Li,Iddy Chazua,Benedcto Adamu,Innocent Maholi,Alexander Zipf*

Main category: cs.CV

TL;DR: 提出融合无人机和街景影像的机器学习框架，通过双模态跨视角学习评估建筑热相关属性，识别热暴露不平等现象

- Motivation: 气候变化加剧了全球南方城市中心的热暴露风险，但缺乏可扩展的方法评估建筑热相关属性，特别是低收入社区的建筑材料选择会加剧热健康风险
- Method: 提出耦合全局上下文视觉变换器（CGCViT）框架，融合无人机和街景影像进行双模态跨视角学习，利用HotSat-1热红外数据量化建筑属性与热健康风险的关系
- Result: 双模态方法比最佳单模态模型性能提升9.3%；植被环绕、较亮屋顶、混凝土/粘土/木材屋顶材料与较低热红外值显著相关；在坦桑尼亚达累斯萨拉姆成功识别家庭层面的热暴露不平等
- Conclusion: 无人机和街景影像提供互补的城市结构视角，机器学习框架能识别与建筑材料相关的热暴露不平等，为制定公平的气候适应策略提供数据驱动的风险评估方法


### [36] [Think-Clip-Sample: Slow-Fast Frame Selection for Video Understanding](https://arxiv.org/abs/2601.11359)
*Wenhui Tan,Ruihua Song,Jiaze Li,Jianzhong Ju,Zhenbo Luo*

Main category: cs.CV

TL;DR: TCS是一个无需训练的长视频理解框架，通过多查询推理和片段级慢快采样提升MLLMs性能，在减少50%推理时间的同时达到可比精度。

- Motivation: 当前多模态大语言模型在长视频理解上存在计算限制和帧选择不佳的问题，需要更高效的解决方案。
- Method: TCS包含两个核心组件：1) 多查询推理 - 生成多个查询以捕捉问题和视频的互补方面；2) 片段级慢快采样 - 自适应平衡密集局部细节和稀疏全局上下文。
- Result: 在MLVU、LongVideoBench和VideoMME数据集上的实验表明，TCS能持续提升不同MLLMs的性能，最高提升6.9%准确率，且能以50%更少的推理时间达到可比精度。
- Conclusion: TCS框架在长视频理解上同时展现了高效性和有效性，为MLLMs的长视频处理提供了实用的训练免费解决方案。


### [37] [Heterogeneous Uncertainty-Guided Composed Image Retrieval with Fine-Grained Probabilistic Learning](https://arxiv.org/abs/2601.11393)
*Haomiao Tang,Jinpeng Wang,Minyi Zhao,Guanghao Meng,Ruisheng Luo,Long Chen,Shu-Tao Xia*

Main category: cs.CV

TL;DR: HUG提出了一种异构不确定性引导的组成图像检索范式，通过细粒度概率学习框架和异构不确定性估计，解决了现有方法在实例级整体建模和查询-目标同质处理方面的不足。

- Motivation: 组成图像检索（CIR）中的三元组存在固有噪声，导致内在不确定性并威胁模型鲁棒性。现有的概率学习方法虽然有望解决这些问题，但由于其实例级整体建模和对查询与目标的同质处理，在CIR任务中表现不足。
- Method: 提出异构不确定性引导（HUG）范式：1）使用高斯嵌入表示查询和目标，捕获细粒度概念和不确定性；2）为多模态查询和单模态目标定制异构不确定性估计；3）设计不确定性引导的目标函数，包括查询-目标整体对比和细粒度对比，配合全面的负采样策略。
- Result: 在基准测试中，HUG超越了最先进的基线方法，实验证明了其有效性，并通过可靠分析验证了技术贡献。
- Conclusion: HUG通过细粒度概率学习框架和异构不确定性估计，有效解决了CIR中的噪声和不确定性问题，提升了模型的鲁棒性和检索性能。


### [38] [SUG-Occ: An Explicit Semantics and Uncertainty Guided Sparse Learning Framework for Real-Time 3D Occupancy Prediction](https://arxiv.org/abs/2601.11396)
*Hanlin Wu,Pengfei Lin,Ehsan Javanmardi,Nanren Bao,Bo Qian,Hao Si,Manabu Tsukada*

Main category: cs.CV

TL;DR: SUG-Occ是一个基于语义和不确定性引导的稀疏学习3D占据预测框架，通过利用3D场景的固有稀疏性减少冗余计算，在保持几何和语义完整性的同时实现高效实时部署。

- Motivation: 3D语义占据预测作为自动驾驶场景理解的关键任务，虽然提供体素级语义信息，但计算和内存开销巨大，阻碍了实际实时部署。需要解决计算效率问题。
- Method: 1) 利用语义和不确定性先验抑制自由空间投影，采用无符号距离编码增强几何一致性，生成结构一致的稀疏3D表示；2) 设计级联稀疏补全模块，通过超交叉稀疏卷积和生成上采样实现粗到细推理；3) 提出基于对象上下文表示(OCR)的掩码解码器，聚合稀疏特征的全局语义上下文，通过轻量级查询-上下文交互细化体素预测。
- Result: 在SemanticKITTI基准测试中，该方法优于基线，准确率提升7.34%，效率提升57.8%。
- Conclusion: SUG-Occ通过语义和不确定性引导的稀疏学习，有效解决了3D语义占据预测的计算效率问题，在保持精度的同时显著提升了推理速度，为实际实时部署提供了可行方案。


### [39] [Wetland mapping from sparse annotations with satellite image time series and temporal-aware segment anything model](https://arxiv.org/abs/2601.11400)
*Shuai Yuan,Tianwu Lin,Shuang Chen,Yu Xia,Peng Qin,Xiangyu Liu,Xiaoqing Xu,Nan Xu,Hongsheng Zhang,Jie Wang,Peng Gong*

Main category: cs.CV

TL;DR: WetSAM：基于SAM的框架，通过双分支设计整合卫星图像时间序列，从稀疏点监督中进行湿地制图，显著优于现有方法。

- Motivation: 湿地制图对生态系统监测至关重要，但密集像素级标注成本高昂，实际应用通常依赖稀疏点标签，现有深度学习模型在此条件下表现不佳；同时强烈的季节性和年际湿地动态使单日期图像不足，导致显著制图误差；虽然SAM等基础模型在点提示下表现出良好泛化能力，但它们本质上是为静态图像设计，无法建模时间信息，导致在异质湿地中产生碎片化掩码。
- Method: 提出WetSAM框架，采用双分支设计：1）时间提示分支通过分层适配器和动态时间聚合扩展SAM，从物候变化中解耦湿地特征；2）空间分支采用时间约束的区域增长策略生成可靠的密集伪标签；3）通过双向一致性正则化联合优化两个分支。
- Result: 在八个全球区域（每个约5000平方公里）的广泛实验中，WetSAM显著优于最先进方法，平均F1分数达到85.58%，能够以最小标注工作量提供准确且结构一致的湿地分割。
- Conclusion: WetSAM展示了强大的泛化能力和可扩展、低成本、高分辨率湿地制图的潜力，为从稀疏点监督中进行湿地制图提供了有效解决方案。


### [40] [SME-YOLO: A Real-Time Detector for Tiny Defect Detection on PCB Surfaces](https://arxiv.org/abs/2601.11402)
*Meng Han*

Main category: cs.CV

TL;DR: SME-YOLO：基于YOLOv11n改进的PCB微小缺陷检测框架，通过NWDLoss、EUCB上采样和MSFA注意力模块提升小目标检测性能

- Motivation: PCB表面缺陷直接影响产品可靠性和安全性，但检测面临挑战：缺陷尺寸微小、纹理相似度高、尺度分布不均匀，传统方法难以实现高精度检测
- Method: 提出SME-YOLO框架：1) 使用NWDLoss替代IoU，降低微小目标位置偏差敏感性；2) 用EUCB替换原上采样模块，通过多尺度卷积恢复空间分辨率并增强边缘纹理细节；3) 提出MSFA模块，针对PCB缺陷空间分布自适应增强关键尺度区间感知，实现局部细粒度特征与全局上下文信息高效融合
- Result: 在PKU-PCB数据集上达到SOTA性能，相比基线YOLOv11n，mAP提升2.2%，精确率提升4%
- Conclusion: SME-YOLO有效解决了PCB微小缺陷检测的挑战，提出的NWDLoss、EUCB和MSFA模块显著提升了检测精度，验证了方法的有效性


### [41] [Topology-Guaranteed Image Segmentation: Enforcing Connectivity, Genus, and Width Constraints](https://arxiv.org/abs/2601.11409)
*Wenxiao Li,Xue-Cheng Tai,Jun Liu*

Main category: cs.CV

TL;DR: 提出结合宽度信息的拓扑先验图像分割框架，通过持久同调与PDE平滑修改上水平集极值点，使拓扑结构能捕获宽度属性，并融入变分模型和神经网络实现分割。

- Motivation: 现有拓扑先验在图像分割中虽能保持连通性和亏格等结构，但缺乏宽度信息（如厚度、长度），传统数学定义和持久同调方法无法满足实际分割需求，需要将宽度信息显式整合到拓扑特征中。
- Method: 提出新数学框架，将宽度信息整合到拓扑结构表征中。利用持久同调结合偏微分方程平滑概念，修改上水平集的局部极值点，使拓扑结构能捕获宽度属性。将此增强的拓扑描述融入变分图像分割模型，并通过适当损失函数设计神经网络，实现具有所需拓扑和宽度属性的分割。
- Result: 数值实验表明该方法有效，能保持拓扑保真度（如连通性和亏格数），同时显式地将宽度特征（如线厚度和长度）嵌入分割的图像结构中。
- Conclusion: 提出的框架成功克服了传统拓扑方法缺乏宽度信息的限制，通过整合持久同调与PDE平滑，实现了既能保持拓扑不变性又能捕获宽度属性的图像分割，为实际应用提供了更全面的结构保持能力。


### [42] [PubMed-OCR: PMC Open Access OCR Annotations](https://arxiv.org/abs/2601.11425)
*Hunter Heidenreich,Yosheb Getachew,Olivia Dinica,Ben Elliott*

Main category: cs.CV

TL;DR: PubMed-OCR是一个从PubMed Central开放获取PDF中提取的科学文章OCR语料库，包含209.5K篇文章、1.5M页、约13亿单词，支持布局感知建模和OCR相关研究。

- Motivation: 为支持布局感知建模、坐标基础问答和OCR依赖流程评估，需要大规模、结构化的科学文献OCR语料库。现有资源有限，特别是针对科学文献的布局标注数据不足。
- Method: 从PubMed Central开放获取PDF中提取页面图像，使用Google Cloud Vision进行OCR处理，生成包含单词、行、段落级别边界框的紧凑JSON格式标注。
- Result: 构建了包含209.5K篇文章、1.5M页、约13亿单词的大规模语料库，支持多种下游任务，分析了期刊覆盖率和检测到的布局特征等语料特性。
- Conclusion: PubMed-OCR为OCR相关研究提供了有价值的资源，但存在依赖单一OCR引擎和启发式行重建等局限性。数据已公开发布，鼓励社区扩展和改进。


### [43] [Map2Thought: Explicit 3D Spatial Reasoning via Metric Cognitive Maps](https://arxiv.org/abs/2601.11442)
*Xiangjun Gao,Zhensong Zhang,Dave Zhenyu Chen,Songcen Xu,Long Quan,Eduardo Pérez-Pellitero,Youngkyoon Jang*

Main category: cs.CV

TL;DR: Map2Thought是一个用于3D视觉语言模型的显式可解释空间推理框架，通过度量认知地图和认知思维链实现几何推理，在少量监督下达到接近全数据集的性能。

- Motivation: 当前3D视觉语言模型缺乏显式和可解释的空间推理能力，难以进行精确的几何理解和关系推理。需要一种能够提供确定性操作和可解释推理轨迹的框架。
- Method: 提出Map2Thought框架，包含两个核心组件：1) 度量认知地图(Metric-CogMap)：结合离散网格进行关系推理和连续度量尺度表示进行精确几何理解；2) 认知思维链(Cog-CoT)：基于度量认知地图执行确定性几何操作，包括向量运算、边界框距离计算和遮挡感知的外观顺序线索。
- Result: 实验表明，Map2Thought仅使用一半监督数据就达到59.9%的准确率，接近使用全数据集的基线60.9%。在VSI-Bench上，使用10%、25%、50%训练子集时，分别比最先进方法高出5.3%、4.8%和4.0%。
- Conclusion: Map2Thought为3D视觉语言模型提供了显式、可解释的空间推理能力，通过结合离散和连续空间表示以及确定性几何操作，实现了在有限监督下的高效3D理解。


### [44] [PRISM-CAFO: Prior-conditioned Remote-sensing Infrastructure Segmentation and Mapping for CAFOs](https://arxiv.org/abs/2601.11451)
*Oishee Bintey Hoque,Nibir Chandra Mandal,Kyle Luong,Amanda Wilson,Samarth Swarup,Madhav Marathe,Abhijin Adiga*

Main category: cs.CV

TL;DR: 提出一个可解释的管道，用于从航拍和卫星图像中识别和表征集中动物饲养操作(CAFOs)，通过基础设施检测、特征提取和分类实现高精度映射。

- Motivation: 大规模畜牧作业对人类健康和环境构成重大风险，且易受传染病和极端天气威胁。随着此类操作数量增长，准确且可扩展的映射变得日益重要。
- Method: 1) 使用领域调优的YOLOv8检测器检测候选基础设施(畜舍、饲养场、粪池、筒仓)，从检测框生成SAM2掩码并过滤组件特定标准；2) 提取结构化描述符(数量、面积、方向、空间关系)并与深度视觉特征通过轻量级空间交叉注意力分类器融合；3) 输出CAFO类型预测和掩码级归因，将决策与可见基础设施关联。
- Result: 该方法在综合评估中达到最先进性能，Swin-B+PRISM-CAFO比最佳基线性能提升高达15%。在多样化美国区域展现强大预测性能，并通过系统梯度激活分析量化领域先验的影响。
- Conclusion: 提出的基础设施优先、可解释的管道能够准确识别和表征CAFOs，为大规模畜牧作业监测提供有效工具，具有实际应用价值。


### [45] [MHA2MLA-VLM: Enabling DeepSeek's Economical Multi-Head Latent Attention across Vision-Language Models](https://arxiv.org/abs/2601.11464)
*Xiaoran Fan,Zhichao Sun,Tao Ji,Lixing Shen,Tao Gui*

Main category: cs.CV

TL;DR: MHA2MLA-VLM：一种参数高效的多模态感知框架，可将现成的视觉语言模型转换为多头潜在注意力架构，显著减少KV缓存占用并加速推理。

- Motivation: 随着视觉语言模型处理日益复杂的多模态任务，KV缓存的快速增长在推理过程中造成了显著的内存和计算瓶颈。虽然多头潜在注意力（MLA）提供了压缩KV缓存和加速推理的有效手段，但如何在不进行昂贵预训练的情况下将现有VLM适配到MLA架构仍未被充分探索。
- Method: 提出MHA2MLA-VLM框架，包含两个核心技术：1）模态自适应部分RoPE策略，通过选择性屏蔽非必要维度来支持传统和多模态设置；2）模态解耦低秩近似方法，独立压缩视觉和文本KV空间。此外，引入参数高效微调以最小化适配成本，并证明最小化输出激活误差（而非参数距离）可显著减少性能损失。
- Result: 在三个代表性VLM上的广泛实验表明，MHA2MLA-VLM能够以最少的监督数据恢复原始模型性能，显著减少KV缓存占用，并能与KV量化无缝集成。
- Conclusion: MHA2MLA-VLM提供了一种参数高效且多模态感知的方法，可将现成VLM转换为MLA架构，有效解决KV缓存瓶颈问题，同时保持模型性能。


### [46] [Generative Scenario Rollouts for End-to-End Autonomous Driving](https://arxiv.org/abs/2601.11475)
*Rajeev Yasarla,Deepti Hegde,Shizhong Han,Hsin-Pai Cheng,Yunxiao Shi,Meysam Sadeghigooghari,Shweta Mahajan,Apratim Bhattacharyya,Litian Liu,Risheek Garrepalli,Thomas Svantesson,Fatih Porikli,Hong Cai*

Main category: cs.CV

TL;DR: GeRo是一个用于VLA模型的即插即用框架，通过自回归展开策略联合执行规划和语言基础未来交通场景生成，在自动驾驶中实现语言条件推理。

- Motivation: 当前VLA模型主要依赖稀疏轨迹标注的模仿学习，未能充分利用其作为生成模型的潜力，需要更好的语言基础场景生成和长期推理能力。
- Method: 1. 训练VLA模型将自车和智能体动态编码为潜在token；2. 进行语言条件自回归生成，给定多视角图像、场景描述和自车动作问题，生成未来潜在token和文本响应；3. 使用展开一致性损失稳定预测。
- Result: 在Bench2Drive上，驾驶分数和成功率分别提升+15.7和+26.2；结合强化学习实现SOTA闭环和开环性能，展示强大的零样本鲁棒性。
- Conclusion: 生成式语言条件推理为更安全、可解释的端到端自动驾驶提供了有前景的基础，GeRo框架展示了VLA模型在场景生成和规划方面的潜力。


### [47] [ReScene4D: Temporally Consistent Semantic Instance Segmentation of Evolving Indoor 3D Scenes](https://arxiv.org/abs/2601.11508)
*Emily Steiner,Jianhao Zheng,Henry Howard-Jenkins,Chris Xie,Iro Armeni*

Main category: cs.CV

TL;DR: ReScene4D：一种用于稀疏4D室内语义实例分割的新方法，能够在间歇性3D扫描中保持时间一致性实例识别，无需密集观测。

- Motivation: 室内环境会随时间变化（物体移动、出现、消失），现有方法难以在间歇性3D扫描中保持时间一致的实例识别。3DSIS方法缺乏时间推理需要离散匹配，4D LiDAR方法依赖高频时间测量不适用于室内环境的长期演化。
- Method: 提出ReScene4D方法，将3DSIS架构适配到4DSIS任务，无需密集观测。探索跨观测信息共享策略，利用共享上下文实现一致实例跟踪并提升3DSIS质量。
- Result: 在3RScan数据集上达到最先进性能，建立了理解演化室内场景的新基准。定义了新指标t-mAP来奖励时间身份一致性。
- Conclusion: ReScene4D成功解决了稀疏4D室内语义实例分割任务，能够在间歇性扫描中保持时间一致的实例识别，为理解动态室内环境提供了有效解决方案。


### [48] [ShapeR: Robust Conditional 3D Shape Generation from Casual Captures](https://arxiv.org/abs/2601.11514)
*Yawar Siddiqui,Duncan Frost,Samir Aroudj,Armen Avetisyan,Henry Howard-Jenkins,Daniel DeTone,Pierre Moulon,Qirui Wu,Zhengqin Li,Julian Straub,Richard Newcombe,Jakob Engel*

Main category: cs.CV

TL;DR: ShapeR：从随意拍摄的图像序列中生成3D物体形状的新方法，通过结合SLAM、3D检测和视觉语言模型提取多模态信息，使用整流流变换器生成高质量3D形状，在真实场景中显著优于现有方法。

- Motivation: 现有3D形状生成方法通常依赖干净、无遮挡、良好分割的输入，这在真实场景中很少见。需要一种能够处理随意拍摄、遮挡、背景杂乱等真实世界挑战的方法。
- Method: 1. 使用现成的视觉惯性SLAM、3D检测算法和视觉语言模型从图像序列中提取稀疏SLAM点、多视角图像和机器生成描述；2. 训练整流流变换器有效利用这些多模态信息生成3D形状；3. 采用组合增强、课程训练（从物体级到场景级数据集）和处理背景杂乱的策略确保鲁棒性。
- Result: 在包含7个真实场景、178个野外物体的新评估基准上，ShapeR显著优于现有方法，Chamfer距离比现有最佳方法提升2.7倍。
- Conclusion: ShapeR成功解决了从随意拍摄序列中生成3D形状的挑战，通过多模态信息融合和鲁棒性技术，在真实场景中实现了高质量的3D形状生成，为实际应用提供了有效解决方案。


### [49] [UniX: Unifying Autoregression and Diffusion for Chest X-Ray Understanding and Generation](https://arxiv.org/abs/2601.11522)
*Ruiheng Zhang,Jingfeng Yao,Huangxuan Zhao,Hao Yan,Xiao He,Lei Chen,Zhou Wei,Yong Luo,Zengmao Wang,Lefei Zhang,Dacheng Tao,Bo Du*

Main category: cs.CV

TL;DR: UniX是一个统一的医学基础模型，通过解耦理解和生成任务，使用自回归分支进行理解、扩散分支进行生成，实现了胸部X光图像理解和生成的高性能协同。

- Motivation: 现有的医学基础模型在统一视觉理解和生成方面存在困难，因为这两个任务目标冲突：语义抽象vs像素级重建。现有基于参数共享自回归架构的方法通常导致一个或两个任务性能受损。
- Method: 1. 将理解和生成任务解耦：自回归分支用于理解，扩散分支用于高保真生成；2. 引入跨模态自注意力机制，用理解特征动态指导生成过程；3. 采用严格的数据清洗流程和多阶段训练策略。
- Result: 在两个代表性基准测试中，UniX实现了理解性能（Micro-F1）46.1%的提升和生成质量（FD-RadDino）24.2%的增益，仅使用LLM-CXR四分之一参数的情况下，性能达到与任务特定模型相当的水平。
- Conclusion: UniX通过解耦架构和跨模态指导机制，实现了医学图像理解和生成的协同合作，为协同医学图像理解和生成建立了可扩展的范式。
## q-bio.NC

### [50] [KOCOBrain: Kuramoto-Guided Graph Network for Uncovering Structure-Function Coupling in Adolescent Prenatal Drug Exposure](https://arxiv.org/abs/2601.11018)
*Badhan Mazumder,Lei Wu,Sir-Lord Wiafe,Vince D. Calhoun,Dong Hye Ye*

Main category: q-bio.NC

TL;DR: KOCOBrain是一个图神经网络框架，通过Kuramoto相位动力学整合结构和功能连接组，用于预测产前药物暴露并揭示相关的脑网络协调紊乱模式。

- Motivation: 产前接触精神活性物质（如大麻）会破坏神经发育并改变大规模脑网络，但识别其神经特征仍然具有挑战性。需要开发能够整合结构和功能连接信息的方法来更好地预测和解释这些影响。
- Method: 提出KOCOBrain框架：1）Kuramoto层在解剖连接上模拟神经同步，生成捕捉结构-功能耦合的相位信息嵌入；2）认知分数以受试者特定方式调制信息路由；3）采用联合目标函数增强类别不平衡情况下的鲁棒性。
- Result: 在ABCD队列中，KOCOBrain相比相关基线方法提高了产前药物暴露的预测性能，并揭示了可解释的结构-功能模式，反映了早期暴露相关的脑网络协调紊乱。
- Conclusion: KOCOBrain提供了一个统一的图神经网络框架，能够有效整合结构和功能连接信息，不仅提高了产前药物暴露的预测准确性，还能揭示相关的神经机制，为理解早期暴露对脑网络的影响提供了新工具。


### [51] [Simple Models, Rich Representations: Visual Decoding from Primate Intracortical Neural Signals](https://arxiv.org/abs/2601.11108)
*Matteo Ciferri,Matteo Ferrante,Nicola Toschi*

Main category: q-bio.NC

TL;DR: 该研究评估了从灵长类动物皮层记录中解码视觉信息的模型，发现时间动态建模比架构复杂性更重要，并开发了结合潜在重建和扩散模型的生成解码管道。

- Motivation: 理解神经活动如何产生感知是神经科学的核心挑战，研究旨在从高密度皮层记录中解码视觉信息，为脑机接口和语义神经解码提供基础。
- Method: 使用THINGS腹侧流尖峰数据集，系统评估模型架构、训练目标和数据缩放对解码性能的影响，开发了结合时间注意力和浅层MLP的简单模型，以及模块化生成解码管道（低分辨率潜在重建+语义条件扩散）。
- Result: 解码准确率主要受神经信号时间动态建模驱动而非架构复杂性；简单的时间注意力+MLP模型达到70% top-1图像检索准确率，优于线性基线、循环和卷积方法；缩放分析显示输入维度和数据集大小增加时收益递减；生成管道能从200ms脑活动中生成合理图像。
- Conclusion: 时间动态建模是神经解码的关键，简单模型可取得优异性能；提出的模块化生成框架为脑机接口和语义神经解码提供了实用原则。
## cs.NE

### [52] [Line-based Event Preprocessing: Towards Low-Energy Neuromorphic Computer Vision](https://arxiv.org/abs/2601.10742)
*Amélie Gruel,Pierre Lewden,Adrien F. Vincent,Sylvain Saïghi*

Main category: cs.NE

TL;DR: 论文提出了一种基于线段的事件数据预处理方法，通过优化事件数量来降低神经形态视觉系统的能耗，在三个基准数据集上实现了能耗与分类性能的有利权衡。

- Motivation: 神经形态视觉系统在动态视觉数据处理方面具有生物启发性、节能、低延迟和低内存等优势，但嵌入式应用中的能耗优化仍是挑战。解决方案可能在于预处理事件数据以减少神经形态硬件上的突触操作数量，从而降低能耗。
- Method: 扩展了端到端神经形态线段检测机制，引入基于线段的事件数据预处理。通过不同的线段预处理策略，在保持或提高分类准确率的同时，显著减少理论能耗。
- Result: 在三个基准事件数据集上，预处理方法在能耗和分类性能之间实现了有利权衡。根据预处理策略和分类任务复杂度，可以维持或提高分类准确率，同时显著降低理论能耗。
- Conclusion: 基于线段的事件预处理方法显著提高了神经形态分类效率，为通过事件预处理实现更节能的神经形态计算机视觉奠定了基础。
## eess.SP

### [53] [Differentiating through binarized topology changes: Second-order subpixel-smoothed projection](https://arxiv.org/abs/2601.10737)
*Giuseppe Romano,Rodrigo Arrieta,Steven G. Johnson*

Main category: eess.SP

TL;DR: 提出SSP2方法，通过Hessian正则化解决拓扑优化中SSP方法在拓扑变化时不可微的问题，保证二阶可微性同时维持几乎处处二值结构。

- Motivation: 拓扑优化中可制造的二值结构与基于梯度的优化方法存在根本矛盾。现有SSP方法在子像素级别平滑界面，但在拓扑变化（如界面合并）时无法保证可微性，违反了许多梯度优化算法的收敛保证。
- Method: 提出二阶SSP（SSP2）方法，通过对滤波场的Hessian进行正则化，在拓扑变化期间实现投影密度的二阶可微性，同时保证几乎处处二值结构。该方法相对于SSP或传统投影方案增加的计算复杂度最小。
- Result: 在热学和光子学问题上验证了SSP2的有效性。对于连接性主导（频繁拓扑变化）的情况，SSP2比SSP收敛更快；在其他情况下性能相当。SSP2还能支持更广泛的优化算法，如内点法。
- Conclusion: SSP2方法克服了SSP在拓扑变化时不可微的限制，提供了更强的收敛保证，可作为现有拓扑优化代码的直接替代方案，同时支持更多具有更强理论保证的优化算法。
## cs.AI

### [54] [Explore with Long-term Memory: A Benchmark and Multimodal LLM-based Reinforcement Learning Framework for Embodied Exploration](https://arxiv.org/abs/2601.10744)
*Sen Wang,Bangwei Liu,Zhenkun Gao,Lizhuang Ma,Xuhong Wang,Yuan Xie,Xin Tan*

Main category: cs.AI

TL;DR: 本文提出LMEE框架和LMEE-Bench基准，通过MemoryExplorer方法增强智能体的长期记忆和主动探索能力，在长时程具身任务中取得显著优势。

- Motivation: 现有主流一次性具身任务主要关注任务完成结果，忽视了探索过程和记忆利用的关键环节。理想的具身智能体应具备终身学习能力，利用长期情景记忆优化决策，以处理长时程复杂任务。
- Method: 提出LMEE框架统一探索认知和决策行为；构建LMEE-Bench数据集和基准；提出MemoryExplorer方法，通过强化学习微调多模态大语言模型，鼓励主动记忆查询，采用包含动作预测、边界选择和问答的多任务奖励函数。
- Result: 与最先进的具身探索模型相比，该方法在长时程具身任务中取得了显著优势，实现了主动探索能力。
- Conclusion: LMEE框架和MemoryExplorer方法有效解决了现有具身任务忽视探索过程和记忆利用的问题，为具身智能体的终身学习能力提供了新的解决方案。
## cs.LG

### [55] [Matching High-Dimensional Geometric Quantiles for Test-Time Adaptation of Transformers and Convolutional Networks Alike](https://arxiv.org/abs/2601.11022)
*Sravan Danda,Aditya Challa,Shlok Mehendale,Snehanshu Saha*

Main category: cs.LG

TL;DR: 提出了一种架构无关的测试时自适应方法，通过添加适配器网络预处理输入图像，使用分位数损失进行训练，匹配高维几何分位数来纠正分布偏移。

- Motivation: 现有测试时自适应方法大多依赖于修改分类器权重，严重依赖特定架构，难以扩展到通用架构。需要一种架构无关的方法来处理测试数据分布与训练数据分布的轻微差异。
- Method: 提出架构无关的TTA方法：在分类器前添加适配器网络预处理输入图像，使用提出的分位数损失训练适配器，通过匹配高维几何分位数来纠正分布偏移。
- Result: 在CIFAR10-C、CIFAR100-C和TinyImageNet-C数据集上验证了方法有效性，训练了经典卷积网络和Transformer网络，证明了方法的架构无关性。
- Conclusion: 提出的架构无关测试时自适应方法通过适配器网络和分位数损失有效处理分布偏移，理论上证明了在适当条件下最小化分位数损失可以学习到最优适配器。


### [56] [GMM-COMET: Continual Source-Free Universal Domain Adaptation via a Mean Teacher and Gaussian Mixture Model-Based Pseudo-Labeling](https://arxiv.org/abs/2601.11161)
*Pascal Schlachter,Bin Yang*

Main category: cs.LG

TL;DR: 提出首个持续源自由通用域自适应方法GMM-COMET，通过高斯混合模型伪标签和均值教师框架，在多个未标记目标域序列上实现稳定自适应

- Motivation: 现实场景中源数据可能不再可用，且目标域标签空间可能与源域不同，现有SF-UniDA方法只假设单一域偏移，需要处理多个不同未标记目标域的持续自适应问题
- Method: 结合高斯混合模型伪标签和均值教师框架，引入一致性损失增强鲁棒性，在持续SF-UniDA设置下实现稳定自适应
- Result: GMM-COMET在所有评估场景中持续改进源模型性能，成为持续SF-UniDA的第一个强基线方法
- Conclusion: 提出的方法为持续源自由通用域自适应提供了首个有效解决方案，在多个不同未标记目标域序列上实现了稳定性能提升


### [57] [When Are Two Scores Better Than One? Investigating Ensembles of Diffusion Models](https://arxiv.org/abs/2601.11444)
*Raphaël Razafindralambo,Rémy Sun,Frédéric Precioso,Damien Garreau,Pierre-Alexandre Mattei*

Main category: cs.LG

TL;DR: 扩散模型集成通常能改善分数匹配损失和模型似然，但无法稳定提升图像质量指标如FID，在表格数据中某些集成策略表现更优

- Motivation: 尽管集成方法在监督学习中已被证明有效，但在无条件分数扩散模型中的应用仍未被充分探索，本研究旨在探究集成是否能为生成建模带来实际益处
- Method: 研究多种集成策略（深度集成、蒙特卡洛Dropout等），在CIFAR-10和FFHQ图像数据集上进行实验，同时探索表格数据中的随机森林集成，并提供分数模型求和的理论分析
- Result: 分数集成通常能改善分数匹配损失和模型似然，但无法稳定提升图像质量指标如FID；在表格数据中，某些集成策略表现优于其他方法
- Conclusion: 扩散模型集成在理论指标上有效，但在实际感知质量指标上效果有限，这为理解分数估计与图像质量之间的关系提供了新视角，同时理论分析对模型组合技术（如引导）也有启示
## eess.IV

### [58] [Convolutions Need Registers Too: HVS-Inspired Dynamic Attention for Video Quality Assessment](https://arxiv.org/abs/2601.11045)
*Mayesha Maliha R. Mithila,Mylene C. Q. Farias*

Main category: eess.IV

TL;DR: DAGR-VQA：首个将寄存器令牌直接集成到卷积主干中的NR-VQA框架，通过动态注意力机制生成时间自适应显著性图，无需显式运动估计，在多个数据集上表现优异且计算效率高。

- Motivation: 现有NR-VQA方法虽然利用显著性或transformer注意力，但仅通过静态图作为辅助输入处理视频信号的全局上下文，未能将上下文从根本上嵌入视频序列的特征提取中。需要一种能够动态跟踪显著区域并嵌入全局上下文的方法。
- Method: 提出DAGR-VQA框架，将可学习的寄存器令牌作为全局上下文载体嵌入卷积主干，实现动态、HVS启发的注意力机制，生成时间自适应显著性图。将动态显著性图与RGB输入集成，通过时空transformer进行感知一致的视频质量评估。
- Result: 在LSVQ、KonVid-1k、LIVE-VQC和YouTube-UGC数据集上表现优异，超越大多数顶级基线。消融研究表明寄存器令牌促进了稳定且时间一致的注意力机制发展。在1080p分辨率下达到387.7 FPS，适合实时应用。
- Conclusion: DAGR-VQA首次成功将寄存器令牌集成到卷积主干中，实现了动态显著性预测和高效的视频质量评估，为多媒体流系统等实时应用提供了有效的解决方案。


### [59] [Visual question answering-based image-finding generation for pulmonary nodules on chest CT from structured annotations](https://arxiv.org/abs/2601.11075)
*Maiko Nagao,Kaito Urata,Atsushi Teramoto,Kazuyoshi Imaizumi,Masashi Kondo,Hiroshi Fujita*

Main category: eess.IV

TL;DR: 利用LIDC-IDRI数据集构建胸部CT图像的视觉问答数据集，开发基于医生兴趣的交互式诊断支持系统，通过VQA模型生成影像学发现描述。

- Motivation: 传统影像诊断通常提供固定描述，无法根据医生具体关注点动态生成发现。本研究旨在开发交互式诊断支持系统，能够根据医生提问生成针对性的影像学发现，提高诊断效率和针对性。
- Method: 从LIDC-IDRI数据集中提取肺结节ROI区域，基于数据库中记录的形态学特征定义影像发现和问题。构建包含裁剪图像、对应问题和影像发现的数据集，并在其上微调VQA模型。使用BLEU等语言评估指标评估生成的影像发现。
- Result: 构建的VQA数据集包含自然表达的放射学描述。生成的影像发现在CIDEr指标上获得3.896的高分，基于形态学特征的评估显示与参考发现高度一致。
- Conclusion: 提出的方法能有效构建胸部CT图像的VQA数据集，并生成符合医生兴趣的影像发现，可作为交互式诊断支持系统，提高影像诊断的针对性和实用性。


### [60] [Generation of Chest CT pulmonary Nodule Images by Latent Diffusion Models using the LIDC-IDRI Dataset](https://arxiv.org/abs/2601.11085)
*Kaito Urata,Maiko Nagao,Atsushi Teramoto,Kazuyoshi Imaizumi,Masashi Kondo,Hiroshi Fujita*

Main category: eess.IV

TL;DR: 使用潜在扩散模型（LDM）生成基于文本提示的胸部CT结节图像，解决医学影像数据不平衡问题，SDv2在指导尺度为5时表现最佳。

- Motivation: 临床实践中难以收集特定病例（如低发病率小细胞癌或难以区分良恶性的肿瘤）的大量CT图像，导致数据不平衡问题，影响计算机辅助诊断系统性能。
- Method: 使用LIDC-IDRI数据集创建结节图像与基于医生评估的文本提示对，对Stable Diffusion v1.5和v2.0进行微调，通过调整指导尺度（GS）控制文本一致性。
- Result: SDv2（GS=5）在图像质量、多样性和文本一致性方面表现最佳，主观评估显示生成图像与真实临床图像无统计学显著差异。
- Conclusion: 提出的基于LDM的胸部CT结节图像生成方法能成功捕捉特定医学特征，生成高质量图像，为解决医学影像数据不平衡问题提供了有效方案。
## cs.CR

### [61] [VidLeaks: Membership Inference Attacks Against Text-to-Video Models](https://arxiv.org/abs/2601.11210)
*Li Wang,Wenyu Chen,Ning Yu,Zheng Li,Shanqing Guo*

Main category: cs.CR

TL;DR: VidLeaks：首个针对文本到视频模型的成员推理攻击框架，通过空间重建保真度和时间生成稳定性检测稀疏-时间记忆泄露，在三种黑盒设置下均能有效识别训练数据成员。

- Motivation: 强大的文本到视频模型在训练过程中可能记忆并泄露训练数据，引发版权和隐私担忧。现有成员推理攻击方法主要针对图像或文本等静态数据，无法有效处理视频的时空复杂性，特别是关键帧中记忆信号的稀疏性和随机时间动态引入的不稳定性。
- Method: 提出VidLeaks框架，通过两种互补信号探测稀疏-时间记忆：1) 空间重建保真度(SRF)，使用Top-K相似度放大稀疏记忆关键帧中的空间记忆信号；2) 时间生成稳定性(TGS)，通过多次查询测量语义一致性来捕捉时间泄露。在三种渐进限制的黑盒设置下评估：监督、基于参考和仅查询。
- Result: 在三个代表性T2V模型上的实验显示严重漏洞：即使在严格的仅查询设置下，VidLeaks在AnimateDiff上达到82.92%的AUC，在InstructVideo上达到97.01%的AUC，表明存在现实且可利用的隐私风险。
- Conclusion: T2V模型通过稀疏和时间记忆泄露大量成员信息，为审计视频生成系统提供了首个具体证据，并推动了新防御机制的开发需求。
## cs.RO

### [62] [H-AIM: Orchestrating LLMs, PDDL, and Behavior Trees for Hierarchical Multi-Robot Planning](https://arxiv.org/abs/2601.11063)
*Haishan Zeng,Peng Li*

Main category: cs.RO

TL;DR: H-AIM是一个用于异构机器人团队执行长期任务的层次化自主智能多机器人规划框架，通过LLM解析指令、经典规划器优化行动序列、行为树实现反应控制，显著提升了任务成功率。

- Motivation: 在具身人工智能中，异构机器人团队执行高级指令的长期任务仍面临挑战。虽然大语言模型在指令解析和初步规划方面有潜力，但在长期推理和动态多机器人协调方面存在局限。
- Method: 提出H-AIM框架，采用三级级联架构：1) 利用LLM解析指令并生成PDDL问题描述；2) 结合LLM语义推理和经典规划器搜索能力产生优化行动序列；3) 将规划结果编译为行为树进行反应控制。通过共享黑板机制支持动态异构机器人团队的通信和状态同步。
- Result: 在MACE-THOR基准数据集（包含8种不同家庭布局的42个复杂任务）上验证，H-AIM将任务成功率从12%提升到55%，目标条件召回率从32%提升到72%，显著优于最强基线LaMMA-P。
- Conclusion: H-AIM框架通过结合LLM的语义理解和经典规划器的搜索能力，有效解决了异构机器人团队执行长期任务的规划问题，显著提升了任务执行性能。
## cs.CL

### [63] [CTest-Metric: A Unified Framework to Assess Clinical Validity of Metrics for CT Report Generation](https://arxiv.org/abs/2601.11488)
*Vanshali Sharma,Andrea Mia Bejar,Gorkem Durak,Ulas Bagci*

Main category: cs.CL

TL;DR: 提出了CTest-Metric框架，首次统一评估放射学报告生成指标在临床环境中的可行性，包含三个测试模块，发现GREEN Score与专家判断最一致。

- Motivation: 在生成式AI时代，放射学报告生成仍依赖次优的评估指标，缺乏统一的框架来评估指标在临床环境中的鲁棒性和适用性。
- Method: 开发了CTest-Metric框架，包含三个模块：1) 写作风格泛化性测试（基于LLM的重述）；2) 合成错误注入（分级严重程度）；3) 指标与专家相关性（使用175个"分歧"病例的临床医生评分）。评估了8个常用指标在7个基于CT-CLIP编码器的LLM上的表现。
- Result: 发现：1) 词汇NLG指标对风格变化高度敏感；2) GREEN Score与专家判断最一致（Spearman~0.70）；3) CRG显示负相关；4) BERTScore-F1对事实错误注入最不敏感。
- Conclusion: CTest-Metric为评估放射学报告生成指标提供了首个统一框架，有助于可重复的基准测试和未来指标开发，将发布框架、代码和部分匿名评估数据。
