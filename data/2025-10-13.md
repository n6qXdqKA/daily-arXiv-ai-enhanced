[[toc]]

## cs.CV

### [1] [Beyond CNNs: Efficient Fine-Tuning of Multi-Modal LLMs for Object Detection on Low-Data Regimes](https://arxiv.org/abs/2510.08589)
*Nirmal Elamon,Rouzbeh Davoudi*

Main category: cs.CV

TL;DR: 该研究比较了微调的传统CNN、零样本预训练多模态LLM和微调多模态LLM在图像中人工文本叠加检测任务上的表现，发现LLM仅需少量数据微调即可显著提升性能，达到或超越需要大量数据的CNN基线。

- Motivation: 探索如何有效利用多模态大语言模型进行视觉理解任务，特别是在数据有限的情况下，挖掘LLM在专门视觉任务中的潜力，弥补传统CNN模型与新兴多模态模型之间的差距。
- Method: 对传统CNN、零样本预训练多模态LLM和微调多模态LLM进行综合比较，重点研究LLM在少量数据（少于1000张图像）下的微调效果。
- Result: 微调后的多模态LLM在人工文本叠加检测任务上实现了高达36%的准确率提升，匹配或超越了需要大量数据的CNN基线模型，展示了LLM在数据效率方面的优势。
- Conclusion: 多模态LLM在视觉理解任务中具有出色的适应性和数据效率，为低资源视觉环境下的跨模态学习提供了有效策略，证明了语言引导模型在精确视觉理解中的潜力。


### [2] [Reproducible Evaluation of Data Augmentation and Loss Functions for Brain Tumor Segmentation](https://arxiv.org/abs/2510.08617)
*Saumya B*

Main category: cs.CV

TL;DR: 对U-Net在脑肿瘤MRI分割中的性能进行可重复评估，使用focal loss和基础数据增强策略，达到90%的精确度，建立了透明可复现的基准。

- Motivation: 脑肿瘤分割对诊断和治疗规划至关重要，但类别不平衡和模型泛化能力有限等问题阻碍了进展，需要建立可复现的基准研究。
- Method: 在公开MRI数据集上实验，使用U-Net架构，重点调整focal loss参数，评估三种数据增强技术：水平翻转、旋转和缩放。
- Result: 使用focal loss的U-Net达到90%的精确度，与最先进结果相当，所有代码和结果公开可用。
- Conclusion: 本研究建立了透明可复现的基准，为未来脑肿瘤分割中数据增强策略和损失函数设计的研究提供指导。


### [3] [Adjusting Initial Noise to Mitigate Memorization in Text-to-Image Diffusion Models](https://arxiv.org/abs/2510.08625)
*Hyeonggeun Han,Sehwan Kim,Hyungjun Joo,Sangwoo Hong,Jungwoo Lee*

Main category: cs.CV

TL;DR: 本文提出两种通过调整初始噪声来减少文本到图像扩散模型记忆训练数据的方法，既能降低记忆化又能保持图像与文本的对齐质量。

- Motivation: 文本到图像扩散模型经常记忆和复制训练数据，引发隐私和版权担忧。现有方法延迟应用分类器自由引导(CFG)来避免记忆化，但会导致图像与提示词对齐不佳。
- Method: 发现初始噪声样本对逃逸吸引盆地的时间有重要影响，提出两种策略：集体调整和个体调整初始噪声，以找到能促进更早逃逸的初始样本。
- Result: 这些方法显著减少了记忆化，同时保持了图像与文本的良好对齐。
- Conclusion: 初始噪声在决定记忆化逃逸时间中起关键作用，通过适当调整初始噪声可以有效缓解扩散模型的记忆化问题。


### [4] [The Digital Mirror: Gender Bias and Occupational Stereotypes in AI-Generated Images](https://arxiv.org/abs/2510.08628)
*Siiri Leppälampi,Sonja M. Hyrynsalmi,Erno Vanhala*

Main category: cs.CV

TL;DR: 研究发现DALL-E 3和Ideogram在生成职业图像时都存在性别刻板印象偏见，需要采取措施增加多样性表现。

- Motivation: 现有研究主要关注AI生成图像的质量和创作过程，忽视了表现偏见问题，特别是在职业场景中的性别刻板印象。
- Method: 通过生成750多张职业图像，使用主题分析方法评估DALL-E 3和Ideogram两个AI图像生成工具的表现偏见。
- Result: 两个工具都强化了传统性别刻板印象，尽管程度不同，AI可视化工具存在强化单一表现的风险。
- Conclusion: 需要为从业者、个人和研究者提供建议，在生成可见性别图像时增加多样性表现，减轻有害的性别偏见。


### [5] [Dynamic Mixture-of-Experts for Visual Autoregressive Model](https://arxiv.org/abs/2510.08629)
*Jort Vincenti,Metod Jazbec,Guoxuan Xia*

Main category: cs.CV

TL;DR: 提出一种动态混合专家路由器集成到VAR中，通过尺度感知阈值在计算量和质量之间进行权衡，无需额外训练即可实现20% FLOPs减少和11%推理加速。

- Motivation: VAR模型在递增分辨率下重复调用Transformer导致计算冗余，需要解决计算效率问题。
- Method: 在VAR中集成动态混合专家路由器，采用尺度感知阈值策略平衡专家选择。
- Result: 减少20% FLOPs，推理速度提升11%，图像质量与密集基线模型相当。
- Conclusion: 该方法有效解决了VAR的计算冗余问题，实现了计算效率与图像质量的平衡。


### [6] [Out-of-Distribution Detection in LiDAR Semantic Segmentation Using Epistemic Uncertainty from Hierarchical GMMs](https://arxiv.org/abs/2510.08631)
*Hanieh Shojaei Miandashti,Claus Brenner*

Main category: cs.CV

TL;DR: 提出了一种基于层次贝叶斯建模的无监督OOD检测方法，通过分离认知不确定性和偶然不确定性，显著提升了LiDAR点云中未知物体的检测性能。

- Motivation: 现有无监督OOD检测方法依赖预测熵，但会混淆认知不确定性和偶然不确定性，导致将分布内模糊区域误分类为OOD。需要一种能有效分离这两种不确定性的方法。
- Method: 采用层次贝叶斯建模高斯混合模型参数在深度神经网络特征空间中，仅使用认知不确定性进行OOD检测，无需辅助数据或额外训练阶段。
- Result: 在SemanticKITTI数据集上，相比预测熵方法，AUROC提升18%，AUPRC提升22%，FPR95从76%降至40%（减少36%）。
- Conclusion: 该方法通过层次贝叶斯建模有效分离认知不确定性，显著提升了无监督OOD检测性能，无需额外数据或训练。


### [7] [Hi-OSCAR: Hierarchical Open-set Classifier for Human Activity Recognition](https://arxiv.org/abs/2510.08635)
*Conor McCarthy,Loes Quirijnen,Jan Peter van Zandwijk,Zeno Geradts,Marcel Worring*

Main category: cs.CV

TL;DR: Hi-OSCAR：一种用于活动识别的分层开放集分类器，能够在保持最先进准确率的同时拒绝未知活动，并将未知类别定位到最近的内部节点。

- Motivation: 在人类活动识别中，存在生活活动范围与标注传感器数据集训练活动之间的巨大差距，未正确处理未见活动会严重削弱分类器的可靠性，且不同活动类别之间存在不同程度的相似性和包含关系。
- Method: 将活动类别组织成结构化层次，提出Hi-OSCAR分层开放集分类器，支持开放集分类并允许将未知类别定位到最近的内部节点。
- Result: 能够以最先进准确率识别已知活动，同时拒绝未知活动，并提供超越二元"已知/未知"分类的洞察。
- Conclusion: Hi-OSCAR方法有效解决了开放集活动识别问题，同时发布了新的公开数据集NFI_FARED来支持未来研究。


### [8] [Detection of high-frequency oscillations using time-frequency analysis](https://arxiv.org/abs/2510.08637)
*Mostafa Mohammadpour,Mehdi Zekriyapanah Gashti,Yusif S. Gasimov*

Main category: cs.CV

TL;DR: 提出了一种基于无监督聚类的高频振荡检测新方法，在80-500Hz频段有效区分HFOs与尖峰、背景活动和伪迹，在控制数据集上达到97.67%敏感度和98.57%精确度，与手术结果相关性更强。

- Motivation: 高频振荡是识别癫痫灶的新生物标志物，但视觉识别耗时费力且主观，需要开发自动检测方法用于研究和临床应用。
- Method: 使用S变换从时频域提取事件，采用无监督聚类技术对事件进行分类，区分HFOs与尖峰、背景活动和伪迹。
- Result: 在控制数据集上敏感度97.67%、精确度98.57%、F分数97.78%；在癫痫患者中，切除与非切除接触点的HFOs比率达0.73，与手术结果相关性更强。
- Conclusion: HFOs是癫痫患者癫痫发生性的有前景生物标志物，切除HFOs（特别是快速波纹）可达到无癫痫发作，而残留HFOs则导致癫痫复发。


### [9] [Into the Rabbit Hull: From Task-Relevant Concepts in DINO to Minkowski Geometry](https://arxiv.org/abs/2510.08638)
*Thomas Fel,Binxu Wang,Michael A. Lepori,Matthew Kowal,Andrew Lee,Randall Balestriero,Sonia Joseph,Ekdeep S. Lubana,Talia Konkle,Demba Ba,Martin Wattenberg*

Main category: cs.CV

TL;DR: 本文分析了DINOv2视觉模型的内部表示机制，通过稀疏自编码器构建了32,000个概念字典，揭示了模型在分类、分割和深度估计任务中的功能专门化，并提出了基于凸混合原型的Minkowski表示假说来解释视觉transformer的表征结构。

- Motivation: 尽管DINOv2被广泛用于物体、场景和动作识别，但其内部感知机制仍不明确。研究旨在揭示该模型的表示本质，超越传统的线性表示假说。
- Method: 采用线性表示假说作为基线，使用稀疏自编码器构建32,000个单元的概念字典，分析不同下游任务如何利用这些概念，并研究表示几何和统计特性。
- Result: 发现分类任务利用'Elsewhere'概念实现学习否定；分割依赖边界检测器形成连贯子空间；深度估计使用三种单目深度线索。表示部分密集而非严格稀疏，字典向更高一致性演化，token占据低维局部连接集。
- Conclusion: 提出Minkowski表示假说，认为token是通过凸混合原型组合形成的，这种结构基于概念空间理论和多头注意力机制，为解释视觉transformer表示提供了新视角。


### [10] [PhyDAE: Physics-Guided Degradation-Adaptive Experts for All-in-One Remote Sensing Image Restoration](https://arxiv.org/abs/2510.08653)
*Zhe Dong,Yuzhe Sun,Haochen Jiang,Tianzhu Liu,Yanfeng Gu*

Main category: cs.CV

TL;DR: 提出PhyDAE方法，通过物理引导的退化自适应专家系统，将隐式特征转化为显式决策信号，精确识别和处理遥感图像中的多种异质退化问题，在性能和效率上均优于现有方法。

- Motivation: 现有的一体化修复方法过度依赖隐式特征表示，缺乏对退化物理的显式建模，难以有效处理遥感图像采集过程中的复杂异质退化问题。
- Method: 采用两阶段级联架构，通过残差流形投影器(RMP)和频率感知退化分解器(FADD)从流形几何和频率角度分析退化特征，结合物理感知专家模块和温度控制稀疏激活策略。
- Result: 在三个基准数据集上的实验表明，PhyDAE在四种修复任务中均取得最优性能，同时显著减少参数数量和计算复杂度，实现性能与效率的最佳平衡。
- Conclusion: PhyDAE通过显式建模退化物理和自适应专家系统，有效解决了遥感图像多退化修复问题，在保持高性能的同时大幅提升了计算效率。


### [11] [Hulu-Med: A Transparent Generalist Model towards Holistic Medical Vision-Language Understanding](https://arxiv.org/abs/2510.08668)
*Songtao Jiang,Yuan Wang,Sibo Song,Tianxiang Hu,Chenyi Zhou,Bin Pu,Yan Zhang,Zhibo Yang,Yang Feng,Joey Tianyi Zhou,Jin Hao,Zijian Chen,Ruijia Wu,Tao Tang,Junhui Lv,Hongxia Xu,Hongwei Wang,Jun Xiao,Bin Feng,Fudong Zhu,Kenli Li,Weidi Xie,Jimeng Sun,Jian Wu,Zuozhu Liu*

Main category: cs.CV

TL;DR: Hulu-Med是一个透明的医学视觉语言模型，统一处理医学文本、2D/3D图像和视频等多种数据模态，在30个基准测试中表现出最先进的性能。

- Motivation: 解决现实临床决策中整合多种数据模态（医学文本、2D/3D图像、视频）的挑战，以及现有通用视觉语言模型在医学应用中存在的流程不透明、数据稀缺和架构不灵活等问题。
- Method: 基于统一的基于补丁的视觉编码器和LLM解码器构建，通过渐进式训练在1670万个样本上从2D扩展到3D和视频理解，采用医学感知的令牌减少技术实现高效训练。
- Result: 在30个基准测试中表现出最先进的性能，超越领先的开源模型，在视觉问答、医学报告生成以及多语言和罕见疾病场景的复杂推理任务中与专有系统竞争。
- Conclusion: 通过开源完整流程证明高性能医学VLM可以透明实现，为可访问和有影响力的临床AI提供了基础工具。


### [12] [Thinking with Camera: A Unified Multimodal Model for Camera-Centric Understanding and Generation](https://arxiv.org/abs/2510.08673)
*Kang Liao,Size Wu,Zhonghua Wu,Linyi Jin,Chao Wang,Yikai Wang,Fei Wang,Wei Li,Chen Change Loy*

Main category: cs.CV

TL;DR: Puffin是一个统一的相机中心多模态模型，通过将相机视为语言来扩展空间感知能力，整合了语言回归和基于扩散的生成技术，能够从任意视角理解和生成场景。

- Motivation: 相机中心的理解和生成是空间智能的两个基石，但通常被孤立研究。本文旨在开发一个统一的相机中心多模态模型，弥合相机与视觉语言之间的模态差距。
- Method: 提出将相机视为语言的新范式，使用Puffin-4M数据集（400万视觉-语言-相机三元组）进行训练，结合全局相机参数和像素级相机映射，实现灵活可靠的空间生成。
- Result: 实验表明Puffin在相机中心生成和理解任务上优于专用模型，通过指令调优能够泛化到空间想象、世界探索和摄影指导等多样化跨视角任务。
- Conclusion: Puffin通过统一的相机中心方法推进了多模态空间智能研究，将发布代码、模型、数据集管道和基准以促进该领域发展。


### [13] [Structured Output Regularization: a framework for few-shot transfer learning](https://arxiv.org/abs/2510.08728)
*Nicolas Ewen,Jairo Diaz-Rodriguez,Kelly Ramsay*

Main category: cs.CV

TL;DR: 提出结构化输出正则化(SOR)框架，通过冻结网络内部结构并使用组套索和L1惩罚，在少样本医学图像分类任务中实现竞争性结果。

- Motivation: 传统迁移学习冻结部分权重并添加任务特定层的方法限制了模型适应领域特定特征的能力，且在数据极少时仍可能导致过拟合。
- Method: 提出SOR框架，冻结内部网络结构（如卷积滤波器），同时使用组套索和L1惩罚的组合，仅需最小额外参数即可针对特定数据定制模型。
- Result: 在三个少样本医学图像分类任务上评估SOR，使用DenseNet121和EfficientNetB4基础网络相比现有基准取得了竞争性结果。
- Conclusion: SOR是一个简单有效的框架，可广泛应用于各种网络组件，在迁移学习任务中具有广泛的适用性。


### [14] [BEAR: Benchmarking and Enhancing Multimodal Language Models for Atomic Embodied Capabilities](https://arxiv.org/abs/2510.08759)
*Yu Qi,Haibo Zhao,Ziyu Guo,Siyuan Ma,Ziyan Chen,Yaokun Han,Renrui Zhang,Zitiantao Lin,Shiji Xin,Yijian Huang,Kai Cheng,Peiheng Wang,Jiazheng Liu,Jiayi Zhang,Yizhe Zhu,Wenqing Wang,Yiran Qin,Xupeng Zhu,Haojie Huang,Lawson L. S. Wong*

Main category: cs.CV

TL;DR: BEAR是一个全面的多模态大语言模型（MLLM）具身能力评估基准，包含4,469个跨14个领域的图像-视频-文本任务，涵盖从低级感知到高级规划的6个类别。评估发现现有MLLM在具身能力方面存在持续局限，为此提出了BEAR-Agent增强模型，显著提升了MLLM性能。

- Motivation: 现有基准主要关注特定领域如规划或空间理解，缺乏对MLLM具身能力的全面系统评估。需要建立一个细粒度的基准来填补这一空白。
- Method: 提出BEAR基准，包含4,469个跨14个领域的图像-视频-文本任务，涵盖6个类别：指向、轨迹理解、空间推理到高级规划。同时提出BEAR-Agent，集成预训练视觉模型来增强MLLM的感知、3D理解和规划能力。
- Result: 对20个代表性MLLM的广泛评估显示它们在所有具身能力领域都存在持续局限。BEAR-Agent在BEAR基准上显著提升了MLLM性能，获得9.12%的绝对增益和17.5%的相对改进。
- Conclusion: BEAR基准揭示了MLLM在具身能力方面的系统局限，BEAR-Agent能有效增强这些能力，且改进具身能力有益于模拟环境中的具身任务。


### [15] [SAFER-AiD: Saccade-Assisted Foveal-peripheral vision Enhanced Reconstruction for Adversarial Defense](https://arxiv.org/abs/2510.08761)
*Jiayang Liu,Daniel Tso,Yiming Bu,Qinru Qiu*

Main category: cs.CV

TL;DR: 提出了一种基于生物视觉机制（中央-外周处理、眼跳运动、皮层填充）的对抗防御框架，通过强化学习引导的眼跳选择性采样来重构图像，无需重新训练分类器即可提升系统鲁棒性。

- Motivation: 传统对抗防御方法依赖计算密集的优化，而人类视觉系统通过生物机制天然具备对抗扰动的鲁棒性。研究假设注意力引导的非均匀稀疏采样和预测编码在其中起关键作用。
- Method: 结合三种生物机制：中央-外周处理、眼跳运动和皮层填充。使用强化学习引导的眼跳选择性捕获多个中央-外周图像片段，整合成重构图像后再进行分类。
- Result: 在ImageNet数据集上的实验表明，该方法能提升多种分类器和攻击类型下的系统鲁棒性，同时显著减少训练开销。
- Conclusion: 生物启发的预处理方法能有效缓解对抗噪声、保持语义完整性，且无需重新训练下游分类器，可与现有系统无缝集成。


### [16] [Detecting spills using thermal imaging, pretrained deep learning models, and a robotic platform](https://arxiv.org/abs/2510.08770)
*Gregory Yeghiyan,Jurius Azar,Devson Butani,Chan-Jin Chung*

Main category: cs.CV

TL;DR: 提出基于RGB和热成像的实时泄漏检测系统，使用预训练深度学习模型，在消费级硬件上实现44ms推理时间和100%准确率。

- Motivation: 开发能够在不同光照条件下稳定运行、部署在安全关键场景中的实时泄漏检测系统。
- Method: 使用预训练的VGG19和NasNetMobile等轻量级模型，结合RGB和热成像数据，在包含4000张图像的平衡二分类数据集上进行训练。
- Result: 热成像模型在推理速度、准确率和模型大小方面表现更优，VGG19热成像模型达到100%准确率，模型大小小于350MB，推理时间低至44ms。
- Conclusion: 基于热成像的VGG19模型在真实机器人测试中表现最佳，证明了该系统在安全关键环境中的可部署性。


### [17] [LinearSR: Unlocking Linear Attention for Stable and Efficient Image Super-Resolution](https://arxiv.org/abs/2510.08771)
*Xiaohui Li,Shaobin Zhuang,Shuo Cao,Yang Yang,Yuandong Pu,Qi Qin,Siqi Luo,Bin Fu,Yihao Liu*

Main category: cs.CV

TL;DR: LinearSR是一个基于线性注意力的图像超分辨率框架，通过解决训练不稳定性和感知-失真权衡问题，实现了高效且高质量的图像超分辨率。

- Motivation: 生成式图像超分辨率模型依赖自注意力机制，但其二次复杂度（O(N^2)）造成计算瓶颈。线性注意力提供O(N)解决方案，但在真实感超分辨率中面临训练不稳定等挑战。
- Method: 提出LinearSR框架：1）使用基于"拐点"的早期停止引导微调（ESGF）解决训练不稳定问题；2）采用信噪比混合专家（MoE）架构缓解感知-失真权衡；3）建立轻量级TAG引导范式。
- Result: LinearSR模型在保持最先进感知质量的同时实现了卓越效率，其核心扩散前向传播（1-NFE）达到SOTA级速度，整体多步推理时间保持高度竞争力。
- Conclusion: 该工作首次为真实感超分辨率领域提供了稳健的线性注意力应用方法，为高效生成式超分辨率研究建立了基础范式。


### [18] [Re-Identifying Kākā with AI-Automated Video Key Frame Extraction](https://arxiv.org/abs/2510.08775)
*Paula Maddigan,Andrew Lensen,Rachael C. Shaw*

Main category: cs.CV

TL;DR: 提出一种从kākā鹦鹉视频中提取高质量关键帧的无监督方法，用于个体识别和重识别，替代传统侵入性标记方法。

- Motivation: 传统野生动物监测方法（如鸟类腿环标记）耗时且具有侵入性，需要开发基于计算机视觉的非侵入性高效替代方案。
- Method: 结合YOLO和Grounding DINO进行目标检测、光流模糊检测、DINOv2图像编码和聚类方法，从视频中识别代表性关键帧。
- Result: 所提出的关键帧选择方法在kākā重识别任务中实现了高准确率。
- Conclusion: 该非侵入性高效方法为野生动物监测提供了有价值的替代方案，有助于生态学和保护生物学的新方法开发。


### [19] [Q-Router: Agentic Video Quality Assessment with Expert Model Routing and Artifact Localization](https://arxiv.org/abs/2510.08789)
*Shuo Xing,Soumik Dey,Mingyang Wu,Ashirbad Mishra,Hansi Wu,Binbin Li,Zhengzhong Tu*

Main category: cs.CV

TL;DR: Q-Router是一个用于通用视频质量评估的智能框架，通过多层级模型路由系统动态选择专家模型，解决了现有VQA模型在泛化性、可解释性和可扩展性方面的局限。

- Motivation: 现有VQA模型存在三个主要问题：(1)在不同内容和任务间泛化能力差；(2)可解释性有限；(3)缺乏对新颖用例或内容类型的可扩展性。
- Method: 提出Q-Router框架，集成多样化专家模型，使用视觉-语言模型作为实时路由器，根据输入视频语义动态推理并集成最合适的专家模型。构建基于计算预算的多层级路由系统，最重层级包含特定的时空伪影定位以实现可解释性。
- Result: 在多个基准测试中，Q-Router匹配或超越了最先进的VQA模型，同时显著提高了泛化性和可解释性。在Q-Bench-Video基准上表现优异，并能有效定位时空伪影。
- Conclusion: Q-Router通过智能设计结合了专业专家的互补优势，在异构视频源和任务中实现了灵活性和鲁棒性，有望成为下一代VQA系统的基础，并具有作为视频生成模型后训练奖励函数的潜力。


### [20] [Alignment, Mining and Fusion: Representation Alignment with Hard Negative Mining and Selective Knowledge Fusion for Medical Visual Question Answering](https://arxiv.org/abs/2510.08791)
*Yuanhao Zou,Zhaozheng Yin*

Main category: cs.CV

TL;DR: 提出一个解决医学视觉问答挑战的框架，通过统一的多层次模态对齐、硬负样本挖掘和门控交叉注意力模块，在多个Med-VQA数据集上实现最先进性能。

- Motivation: 现有Med-VQA方法在模态对齐上缺乏统一解决方案，硬负样本问题研究不足，且常用知识融合技术可能引入无关信息。
- Method: 1) 多层次、多模态、多视图、多阶段的统一模态对齐方案；2) 使用软标签的硬负样本挖掘方法；3) 集成答案词汇作为先验知识的门控交叉注意力模块。
- Result: 在RAD-VQA、SLAKE、PathVQA和VQA-2019等常用Med-VQA数据集上超越了之前的最先进方法。
- Conclusion: 该框架通过统一的模态对齐、硬负样本挖掘和知识选择机制，有效解决了Med-VQA中的关键挑战。


### [21] [SkipSR: Faster Super Resolution with Token Skipping](https://arxiv.org/abs/2510.08799)
*Rohan Choudhury,Shanchuan Lin,Jianyi Wang,Hao Chen,Qi Zhao,Feng Cheng,Lu Jiang,Kris Kitani,Laszlo A. Jeni*

Main category: cs.CV

TL;DR: SkipSR是一种加速视频超分辨率的方法，通过识别低细节区域并跳过这些区域的计算，仅对需要细化的区域进行超分辨率处理，在保持感知质量的同时显著减少计算量。

- Motivation: 基于扩散的超分辨率方法在处理视频时速度慢、成本高，限制了向更高分辨率和更长视频的扩展。许多视频区域本质上是低细节的，从细化中获益甚微，但现有方法对所有像素进行统一处理。
- Method: 提出SkipSR框架，直接从低分辨率输入中识别低细节区域，然后完全跳过这些区域的计算，仅对需要细化的区域进行超分辨率处理。
- Result: 在标准SR基准测试中，该方法在720p视频上比现有模型端到端延迟减少高达60%，且没有可感知的质量损失。
- Conclusion: SkipSR通过选择性处理策略，在保持感知质量的同时显著加速了视频超分辨率处理，为更高分辨率和更长视频的处理提供了可行的解决方案。


### [22] [D-CoDe: Scaling Image-Pretrained VLMs to Video via Dynamic Compression and Question Decomposition](https://arxiv.org/abs/2510.08818)
*Yiyang Huang,Yizhou Wang,Yun Fu*

Main category: cs.CV

TL;DR: D-CoDe是一个无需训练的适配框架，通过动态压缩和问题分解解决图像预训练视觉语言模型在视频理解中的感知瓶颈和token过载问题。

- Motivation: 将图像预训练的视觉语言模型扩展到视频领域面临挑战，主要问题是处理密集且时间延长的视觉输入超出了图像模型的能力，存在感知瓶颈和token过载问题。
- Method: 提出动态压缩（自适应选择代表性帧和空间token的内容感知聚合）和问题分解（将原始查询重新表述为子问题），两者结合无需额外训练。
- Result: 实验表明D-CoDe在各种基准测试中有效提升了视频理解能力，在具有挑战性的长视频基准上表现优异。
- Conclusion: D-CoDe框架通过动态压缩和问题分解成功解决了视频大语言模型中的关键挑战，展示了处理复杂视频语言任务的潜力。


### [23] [FOLK: Fast Open-Vocabulary 3D Instance Segmentation via Label-guided Knowledge Distillation](https://arxiv.org/abs/2510.08849)
*Hongrui Wu,Zhicheng Gao,Jin Cao,Kelu Yao,Wen Shen,Zhihua Wei*

Main category: cs.CV

TL;DR: 提出FOLK方法，通过标签引导的知识蒸馏实现快速开放词汇3D实例分割，避免2D映射带来的噪声和计算开销，显著提升推理速度

- Motivation: 现有方法将3D实例映射到2D RGB-D图像再使用视觉语言模型分类，会引入2D遮挡噪声且计算内存成本高，推理速度慢
- Method: 设计教师模型提取高质量实例嵌入，通过标签引导蒸馏算法将开放词汇知识蒸馏到3D学生模型中，学生模型可直接从点云分类实例
- Result: 在ScanNet200数据集上达到35.7的AP50分数，运行速度比先前方法快6.0到152.2倍
- Conclusion: FOLK方法通过知识蒸馏有效解决了开放词汇3D实例分割中的噪声和效率问题，实现了高性能和快速推理


### [24] [Modeling Time-Lapse Trajectories to Characterize Cranberry Growth](https://arxiv.org/abs/2510.08901)
*Ronan John,Anis Chihoub,Ryan Meegan,Gina Sidelli,Jeffery Neyhart,Peter Oudemans,Kristin Dana*

Main category: cs.CV

TL;DR: 提出了一种基于自监督视觉变换器的作物生长监测方法，避免繁琐的图像标注，通过时间回归和类别预测任务学习植物外观演变的潜在空间，生成可解释的2D时间轨迹。

- Motivation: 蔓越莓种植中的变化监测通常需要人工完成，耗时且效率低。深度学习虽然有望解决这一问题，但面临高维特征难以解释和需要大量手工标注的挑战。
- Method: 使用自监督方法微调视觉变换器(ViTs)，通过双重预训练任务(时间回归和类别预测)学习时间序列中植物和果实外观演变的潜在空间表示。
- Result: 生成的2D时间轨迹能够预测作物随时间的变化，并区分不同蔓越莓品种的时间差异。提供了一个包含8个品种、52次观察的新时间序列数据集。
- Conclusion: 该方法具有通用性，可应用于其他作物和场景，为作物生长监测提供了一种无需繁琐标注的自动化解决方案。


### [25] [PHyCLIP: $\ell_1$-Product of Hyperbolic Factors Unifies Hierarchy and Compositionality in Vision-Language Representation Learning](https://arxiv.org/abs/2510.08919)
*Daiki Yoshikawa,Takashi Matsubara*

Main category: cs.CV

TL;DR: PHyCLIP提出使用双曲空间的ℓ₁-乘积度量来同时表达概念层次结构和跨概念组合性，解决了现有视觉语言模型难以同时捕捉这两种语义结构的难题。

- Motivation: 现有视觉语言模型虽然在大规模多模态表示学习上取得显著成功，但难以同时表达概念家族内的层次结构（如狗⊑哺乳动物⊑动物）和跨概念家族的组合性（如"车里的狗"⊑狗,车）。双曲空间能有效捕捉树状层次结构，但其对组合性的表达能力尚不明确。
- Method: PHyCLIP采用双曲空间因子的笛卡尔积上的ℓ₁-乘积度量。概念家族内的层次结构在单个双曲因子中出现，跨概念组合通过ℓ₁-乘积度量捕获，类似于布尔代数。
- Result: 在零样本分类、检索、层次分类和组合理解任务上的实验表明，PHyCLIP优于现有的单空间方法，并在嵌入空间中提供更具可解释性的结构。
- Conclusion: PHyCLIP通过双曲空间的乘积度量成功解决了同时表达层次结构和组合性的挑战，为多模态表示学习提供了更强大的框架。


### [26] [SegTrans: Transferable Adversarial Examples for Segmentation Models](https://arxiv.org/abs/2510.08922)
*Yufei Song,Ziqi Zhou,Qi Lu,Hangtao Zhang,Yifan Hu,Lulu Xue,Shengshan Hu,Minghui Li,Leo Yu Zhang*

Main category: cs.CV

TL;DR: SegTrans是一种新的迁移攻击框架，通过将输入样本划分为多个局部区域并重新映射语义信息来生成多样化的增强样本，从而提高对抗样本在不同分割模型间的可迁移性。

- Motivation: 分割模型在白盒设置下对对抗样本具有显著脆弱性，但现有攻击方法在不同分割模型间的迁移性较差。复杂上下文依赖性和特征分布差距导致迁移成功率不理想。
- Method: 将输入样本划分为多个局部区域，重新映射语义信息生成增强样本，用这些样本替代原始样本进行扰动优化，仅保留局部语义信息而非全局信息。
- Result: 在PASCAL VOC和Cityscapes两个基准数据集、四种分割模型和三种骨干网络上，SegTrans显著提高了对抗迁移成功率，平均提升8.55%，计算效率提升超过100%。
- Conclusion: SegTrans在不引入额外计算开销的情况下，显著提高了对抗样本在不同分割模型间的可迁移性，优于现有最先进方法。


### [27] [Defense against Unauthorized Distillation in Image Restoration via Feature Space Perturbation](https://arxiv.org/abs/2510.08925)
*Han Hu,Zhuoran Zheng,Chen Lyu*

Main category: cs.CV

TL;DR: 提出了ASVP防御方法，通过奇异值分解在图像复原模型内部特征图中注入结构化高频扰动，有效阻止知识蒸馏攻击，同时保持教师模型输出质量。

- Motivation: 知识蒸馏攻击威胁深度模型知识产权，现有分类任务防御方法难以扩展到图像复原任务，因为复原是生成任务，需要空间一致性和细节保持，微小扰动不足以阻止学生学习。
- Method: ASVP方法在运行时对教师模型内部特征图进行奇异值分解，放大前k个奇异值来注入结构化高频扰动，破坏蒸馏所需的对齐关系。
- Result: 在5个图像复原任务中测试，ASVP能将学生模型的PSNR降低最多4dB，SSIM降低60-75%，对教师模型性能影响可忽略，相比现有方法防御效果更强更一致。
- Conclusion: ASVP为保护开源图像复原模型免受未经授权的知识蒸馏提供了实用解决方案。


### [28] [RO-Bench: Large-scale robustness evaluation of MLLMs with text-driven counterfactual videos](https://arxiv.org/abs/2510.08936)
*Zixi Yang,Jiapeng Li,Muxi Diao,Yinuo Jing,Kongming Liang*

Main category: cs.CV

TL;DR: 提出了Ro-Bench基准测试，用于评估多模态大语言模型在动态分布外反事实视频上的鲁棒性，发现现有模型性能显著下降，并通过反事实数据微调提升了模型性能。

- Motivation: 多模态大语言模型在视频理解任务中表现出色，但其在面对被操纵视频内容时的鲁棒性尚未得到充分研究。
- Method: 创建Ro-Bench基准测试，包含通过编辑风格、物体、背景及其组合生成的高质量、多样化和时间相关的反事实视频数据，评估了8个最新的视频MLLM模型。
- Result: 当前模型在反事实视频内容上表现出显著的性能下降，通过反事实数据微调MLLM可提升鲁棒性，在Ro-Bench上性能提升21.73%，在MVBench数据集的20个任务中提升12.78%。
- Conclusion: 反事实数据能有效增强MLLM的视频理解能力，强调了评估和改进模型鲁棒性的重要性。


### [29] [Denoised Diffusion for Object-Focused Image Augmentation](https://arxiv.org/abs/2510.08955)
*Nisha Pillai,Aditi Virupakshaiah,Harrison W. Smith,Amanda J. Ashworth,Prasanna Gowda,Phillip R. Owens,Adam R. Rivers,Bindu Nanduri,Mahalingam Ramkumar*

Main category: cs.CV

TL;DR: 提出了一种面向对象的动物健康监测数据增强框架，专门针对数据受限场景，通过分割动物、变换和扩散合成来增强动物检测性能

- Motivation: 解决无人机动物健康监测中数据稀缺问题，特别是针对特定农场条件下动物品种、环境和行为变化导致的数据不足
- Method: 分割动物与背景，通过变换和基于扩散的合成方法创建真实多样的场景，增强动物检测和监测性能
- Result: 初步实验表明增强数据集在动物检测任务上优于基线模型
- Conclusion: 该方法通过生成领域特定数据，在数据稀缺场景下实现实时动物健康监测，弥合有限数据与实际应用之间的差距


### [30] [Unleashing Perception-Time Scaling to Multimodal Reasoning Models](https://arxiv.org/abs/2510.08964)
*Yifan Li,Zhenghao Chen,Ziheng Wu,Kun Zhou,Ruipu Luo,Can Zhang,Zhentao He,Yufei Zhan,Wayne Xin Zhao,Minghui Qiu*

Main category: cs.CV

TL;DR: 提出了Perception-Time Scaling (PTS)新范式，通过鼓励丰富的token感知和分解复杂感知问题，显著提升大视觉语言模型的视觉感知精度，在DisTANCE基准上从8.0%提升到64.7%。

- Motivation: 当前基于推理时间缩放的方法在视觉推理方面取得进展，但对视觉感知的影响尚不清楚。现有LVLMs采用快速感知范式，将视觉理解视为一次性输出，缺乏对底层感知过程的建模。
- Method: 提出Perception-Time Scaling (PTS)范式，鼓励token丰富的感知，将复杂感知问题分解为可处理的子问题，使感知能够与推理时间缩放对齐并从中受益。结合强化学习技术实现。
- Result: PTS显著提升感知精度，在DisTANCE基准上的高精度性能从8.0%提升到64.7%，在域外任务上泛化良好。即使使用纯合成数据，与数学推理数据结合也能在推理和真实世界感知基准上获得一致提升。
- Conclusion: PTS通过引入更多感知相关token和增加对图像token的关注，有效解决了当前LVLMs在视觉感知方面的局限性，为视觉感知与推理时间缩放的结合提供了新思路。


### [31] [mmJoints: Expanding Joint Representations Beyond (x,y,z) in mmWave-Based 3D Pose Estimation](https://arxiv.org/abs/2510.08970)
*Zhenyu Wang,Mahathir Monjur,Shahriar Nirjon*

Main category: cs.CV

TL;DR: mmJoints框架通过为预训练的毫米波3D姿态估计器输出添加关节描述符，显式估计关节被感知的概率和位置预测的可靠性，从而提高可解释性和下游任务性能。

- Motivation: 在毫米波姿态估计中，稀疏信号和弱反射导致模型从统计先验而非传感器数据推断关节位置，这种对先验知识的过度依赖会降低下游任务（如手势和活动识别）的性能。
- Method: 引入mmJoints框架，为黑盒毫米波3D姿态估计器的输出增强额外的关节描述符，显式估计关节被感知的可能性和位置预测的可靠性。
- Result: 在13种姿态估计设置中使用超过115,000个信号帧进行评估，mmJoints估计描述符的错误率低于4.2%，关节位置精度提升达12.5%，活动识别性能提升达16%。
- Conclusion: mmJoints通过显式建模姿态估计中的偏差，不仅提高了可解释性，还显著提升了姿态估计精度和下游任务性能。


### [32] [Hierarchical Scheduling for Multi-Vector Image Retrieval](https://arxiv.org/abs/2510.08976)
*Maoliang Li,Ke Li,Yaoyang Liu,Jiayu Chen,Zihao Zheng,Yinjun Wu,Xiang Chen*

Main category: cs.CV

TL;DR: 提出了HiMIR框架，通过分层多粒度图像检索和跨层次相似性一致性，在提高检索精度的同时减少计算冗余

- Motivation: 传统检索方法精度有限，现有多向量检索方法在图像对象对齐和细粒度图像片段冗余方面存在不足
- Method: 采用分层范式处理不同图像对象，利用跨层次相似性一致性和层次稀疏性减少冗余匹配计算，自动配置数据集参数
- Result: 相比现有MVR系统，HiMIR在精度上有显著提升，同时计算量减少高达3.5倍
- Conclusion: HiMIR框架在精度和效率上都优于现有方法，适用于多样化场景


### [33] [HandEval: Taking the First Step Towards Hand Quality Evaluation in Generated Images](https://arxiv.org/abs/2510.08978)
*Zichuan Wang,Bo Peng,Songlin Yang,Zhenchen Tang,Jing Dong*

Main category: cs.CV

TL;DR: 提出了首个针对生成手部区域的质量评估任务，开发了HandEval模型，在多个下游应用中显著提升了生成手部真实性和AIGC检测准确性。

- Motivation: 现有文本到图像模型在复杂局部区域（特别是人手）生成准确细节方面仍存在困难，生成的手部常出现结构扭曲和不真实纹理，但手部区域质量评估一直被忽视。
- Method: 首先构建HandPair数据集（包含48k张高质量和低质量手部配对图像），然后开发HandEval模型，利用多模态大语言模型的视觉理解能力并融入手部关键点先验知识。
- Result: HandEval在人类标注测试集上比现有SOTA方法更符合人类判断，在图像生成和AIGC检测应用中分别显著提升了生成手部真实性和检测准确性。
- Conclusion: 该工作填补了生成手部质量评估的空白，展示了其在多个下游应用中的普遍有效性，为提升AIGC质量提供了重要工具。


### [34] [Uncolorable Examples: Preventing Unauthorized AI Colorization via Perception-Aware Chroma-Restrictive Perturbation](https://arxiv.org/abs/2510.08979)
*Yuki Nii,Futa Waseda,Ching-Chun Chang,Isao Echizen*

Main category: cs.CV

TL;DR: 提出首个防御性范例"不可着色样本"，通过在灰度图像中嵌入不可察觉的扰动来阻止未经授权的AI着色，保护漫画和电影等视觉内容的版权。

- Motivation: AI着色技术存在版权侵权风险，如未经授权对黑白漫画和电影进行着色并转售，但目前缺乏有效的防护方法。
- Method: 提出PAChroma方法，使用拉普拉斯滤波器优化不可察觉的扰动以保持感知质量，并在优化过程中应用多样输入变换以增强跨模型迁移性和对后处理的鲁棒性。
- Result: 在ImageNet和Danbooru数据集上的实验表明，PAChroma能有效降低着色质量同时保持视觉外观。
- Conclusion: 这是保护视觉内容免受非法AI着色的首个防御方法，为生成媒体中的版权保护防御开辟了新途径。


### [35] [Speculative Jacobi-Denoising Decoding for Accelerating Autoregressive Text-to-image Generation](https://arxiv.org/abs/2510.08994)
*Yao Teng,Fuyun Wang,Xian Liu,Zhekai Chen,Han Shi,Yu Wang,Zhenguo Li,Weiyang Liu,Difan Zou,Xihui Liu*

Main category: cs.CV

TL;DR: 提出Speculative Jacobi-Denoising Decoding (SJD2)框架，通过将去噪过程融入Jacobi迭代，实现自回归模型的并行token生成，显著加速图像生成过程。

- Motivation: 自回归文本到图像模型由于顺序token解码过程导致推理速度缓慢，需要数千次模型前向传播才能生成单张图像，效率低下。
- Method: 引入next-clean-token预测范式，使预训练自回归模型能够接受噪声扰动token嵌入并通过低成本微调预测下一个干净token，利用去噪轨迹引导模型走向更稳定的Jacobi轨迹。
- Result: 实验表明该方法能够通过减少模型前向传播次数来加速生成，同时保持生成图像的视觉质量。
- Conclusion: SJD2框架成功解决了自回归模型推理效率低下的问题，实现了并行token生成，在保持图像质量的同时显著提升了生成速度。


### [36] [On Epistemic Uncertainty of Visual Tokens for Object Hallucinations in Large Vision-Language Models](https://arxiv.org/abs/2510.09008)
*Hoigi Seo,Dong Un Kang,Hyunjin Cho,Joohoon Lee,Se Young Chun*

Main category: cs.CV

TL;DR: 本文提出通过识别和掩码视觉编码器中不确定的视觉标记来减轻大视觉语言模型中的物体幻觉问题。

- Motivation: 大视觉语言模型存在物体幻觉问题，即生成图像中不存在的物体描述。研究发现视觉编码器中不确定的视觉标记是导致幻觉的关键因素。
- Method: 提出对抗扰动方法识别不确定视觉标记，并在视觉编码器的中间层自注意力过程中掩码这些标记，抑制其对视觉编码的影响。
- Result: 实验表明该方法显著减少了大视觉语言模型中的物体幻觉，并能与其他现有方法协同工作。
- Conclusion: 通过修改视觉编码器来识别和掩码不确定视觉标记，是缓解物体幻觉问题的简单有效策略。


### [37] [Towards Better & Faster Autoregressive Image Generation: From the Perspective of Entropy](https://arxiv.org/abs/2510.09012)
*Xiaoxiao Ma,Feng Zhao,Pengyang Ling,Haibo Qiu,Zhixiang Wei,Hu Yu,Jie Huang,Zhixiong Zeng,Lin Ma*

Main category: cs.CV

TL;DR: 提出了一种基于熵信息的解码策略，通过动态温度控制和熵感知接受规则，在提高自回归图像生成质量的同时加速合成速度。

- Motivation: 发现当前自回归图像生成模型中的采样问题，图像token相比文本token具有更低的信息密度和非均匀空间分布。
- Method: 1) 基于token分布空间熵的动态温度控制；2) 推测解码中的熵感知接受规则。
- Result: 在多个基准测试中验证了方法的有效性，实现了接近无损的生成质量，推理成本约为传统加速方法的85%。
- Conclusion: 该方法在提升生成质量和采样速度方面具有有效性和通用性，适用于多种自回归图像生成模型。


### [38] [Exploring Single Domain Generalization of LiDAR-based Semantic Segmentation under Imperfect Labels](https://arxiv.org/abs/2510.09035)
*Weitong Kong,Zichao Zeng,Di Wen,Jiale Wei,Kunyu Peng,June Moh Goo,Jan Boehm,Rainer Stiefelhagen*

Main category: cs.CV

TL;DR: 本文提出了DGLSS-NL任务，即带噪声标签的LiDAR语义分割领域泛化，并开发了DuNe双视图框架，通过强-弱分支特征一致性约束和置信度感知过滤，在三个数据集上实现了最先进的性能。

- Motivation: LiDAR标注存在噪声问题，且在领域偏移下会进一步恶化，威胁自动驾驶系统可靠性。现有噪声标签学习方法在3D LiDAR分割中效果不佳，需要专门解决方案。
- Method: 提出DuNe双视图框架，包含强分支和弱分支，通过特征级一致性约束和基于置信度过滤的交叉熵损失来处理噪声标签。
- Result: 在10%对称标签噪声下，在SemanticKITTI达到56.86% mIoU，nuScenes达到42.28%，SemanticPOSS达到52.58%，算术平均49.57%，调和平均48.50%。
- Conclusion: DuNe框架在DGLSS-NL任务中表现出强大的领域泛化能力，为LiDAR语义分割中的噪声标签问题提供了有效解决方案。


### [39] [Lesion-Aware Post-Training of Latent Diffusion Models for Synthesizing Diffusion MRI from CT Perfusion](https://arxiv.org/abs/2510.09056)
*Junhyeok Lee,Hyunwoong Kim,Hyungjin Chung,Heeseong Eom,Joon Jang,Chul-Ho Sohn,Kyu Sung Choi*

Main category: cs.CV

TL;DR: 提出了一种用于医学图像翻译的潜在扩散模型后训练框架，通过引入病灶感知的像素空间目标来提升病灶区域的生成精度，在脑CT到MRI的转换中表现出优越性能。

- Motivation: 现有潜在扩散模型在医学图像生成中虽然高效，但可能丢失对临床诊断至关重要的像素级细节，特别是对于只占图像小部分的病灶区域，这会严重影响诊断可靠性。
- Method: 提出后训练框架，在预训练的潜在扩散模型中引入病灶感知的医学像素空间目标，特别关注病灶区域的精确重建。
- Result: 在817名急性缺血性卒中患者数据集上的实验表明，该框架在从CT灌注扫描合成DWI和ADC图像时，提升了整体图像质量并改善了病灶描绘，优于现有图像翻译模型。
- Conclusion: 该后训练策略易于适配预训练模型，在医学图像翻译任务中具有广泛应用潜力，能够提升临床诊断的可靠性。


### [40] [Visual Anomaly Detection for Reliable Robotic Implantation of Flexible Microelectrode Array](https://arxiv.org/abs/2510.09071)
*Yitong Chen,Xinyao Xu,Ping Zhu,Xinyong Han,Fangbo Qin,Shan Yu*

Main category: cs.CV

TL;DR: 开发了一种基于视觉Transformer的图像异常检测框架，用于机器人柔性微电极植入系统的四个检查点监控，确保植入过程的可靠性和安全性。

- Motivation: 柔性微电极植入大脑皮层具有挑战性，因为FME探针的可变形纤维状结构及其与关键生物组织的相互作用需要仔细监控以确保可靠性和安全性。
- Method: 利用机器人FME植入系统的显微摄像头，在四个检查点使用统一的异常检测框架。采用预训练的视觉Transformer，提出渐进粒度补丁特征采样方法处理不同位置的敏感度-容错度权衡问题，并选择信噪比更高的特征通道。
- Result: 所提方法在植入系统收集的图像数据集上验证了有效性。
- Conclusion: 该图像异常检测框架能够有效监控柔性微电极植入过程，提高植入的可靠性和安全性。


### [41] [MambaH-Fit: Rethinking Hyper-surface Fitting-based Point Cloud Normal Estimation via State Space Modelling](https://arxiv.org/abs/2510.09088)
*Weijia Wang,Yuanzhi Su,Pei-Gen Ye,Yuan-Gen Wang,Xuequan Lu*

Main category: cs.CV

TL;DR: MambaH-Fit是一个基于状态空间建模的点云法向量估计框架，通过注意力驱动的层次特征融合和补丁状态空间模型，有效建模细粒度几何结构。

- Motivation: 现有法向量估计方法在建模细粒度几何结构方面存在不足，而现有的Mamba方法主要关注全局形状结构，对局部几何细节建模不够充分。
- Method: 提出注意力驱动的层次特征融合方案自适应融合多尺度点云补丁特征，并构建补丁状态空间模型将点云补丁建模为隐式超曲面。
- Result: 在基准数据集上的广泛实验表明，该方法在准确性、鲁棒性和灵活性方面优于现有方法。
- Conclusion: 所提出的组件通过消融研究得到验证，MambaH-Fit能够有效提升点云法向量估计的性能。


### [42] [GL-DT: Multi-UAV Detection and Tracking with Global-Local Integration](https://arxiv.org/abs/2510.09092)
*Juanqin Liu,Leonardo Plotegher,Eloy Roura,Shaoming He*

Main category: cs.CV

TL;DR: 提出GL-DT框架，通过时空特征融合和全局-局部协作检测策略提升无人机多目标跟踪性能，解决小目标检测和轨迹连续性等问题。

- Motivation: 无人机在军事侦察、环境监测等领域的广泛应用对多目标跟踪技术提出了更高要求，但复杂背景、小尺度目标和频繁遮挡等问题仍挑战现有方法。
- Method: 采用GL-DT框架，包括时空特征融合模块联合建模运动和外观特征，结合全局-局部协作检测策略增强小目标检测，并引入JPTrack跟踪算法。
- Result: 实验结果表明该方法显著提高了多目标跟踪的连续性和稳定性，同时保持了实时性能。
- Conclusion: 该研究为无人机检测和跟踪技术的发展提供了有力支持，有效解决了现有方法在检测精度和轨迹连续性方面的挑战。


### [43] [Dense2MoE: Restructuring Diffusion Transformer to MoE for Efficient Text-to-Image Generation](https://arxiv.org/abs/2510.09094)
*Youwei Zheng,Yuxi Ren,Xin Xia,Xuefeng Xiao,Xiaohua Xie*

Main category: cs.CV

TL;DR: 将密集的DiT转换为MoE结构，通过专家混合和块混合实现结构化稀疏化，在保持性能的同时减少60%的激活参数

- Motivation: DiT模型参数规模大导致推理开销高，现有剪枝方法会因模型容量减少而严重降低性能
- Method: 1. 用MoE层替换DiT块中的FFN，减少62.5%的FFN激活参数；2. 提出块混合(MoB)选择性激活DiT块；3. 设计多步蒸馏流程，包括基于泰勒度量的专家初始化、负载均衡的知识蒸馏和MoB优化的组特征损失
- Result: 将大型扩散变换器转换为MoE结构，减少60%激活参数的同时保持原始性能，在广泛实验中优于基于剪枝的方法
- Conclusion: Dense2MoE为高效文本到图像生成建立了新范式


### [44] [A Novel Multi-branch ConvNeXt Architecture for Identifying Subtle Pathological Features in CT Scans](https://arxiv.org/abs/2510.09107)
*Irash Perera,Uthayasanker Thayasivam*

Main category: cs.CV

TL;DR: 提出了一种用于COVID-19诊断的多分支ConvNeXt架构，在CT扫描上实现了0.9937的ROC-AUC和0.9757的验证准确率，优于现有模型。

- Motivation: 医疗影像智能分析在临床诊断中至关重要，特别是识别细微病理特征。本文旨在开发专门针对医学图像分析挑战的新架构。
- Method: 采用多分支ConvNeXt架构，集成全局平均池化、全局最大池化和新的注意力加权池化三个并行分支，结合端到端流程和两阶段训练策略。
- Result: 在2,609个CT切片数据集上验证，获得ROC-AUC 0.9937、验证准确率0.9757、F1分数0.9825，优于所有先前报告的模型。
- Conclusion: 现代多分支架构结合仔细的数据处理可以实现与或超过最先进模型的性能，证明了先进深度学习技术在稳健医疗诊断中的有效性。


### [45] [SOS: Synthetic Object Segments Improve Detection, Segmentation, and Grounding](https://arxiv.org/abs/2510.09110)
*Weikai Huang,Jieyu Zhang,Taoyang Jia,Chenhao Zheng,Ziqi Gao,Jae Sung Park,Ranjay Krishna*

Main category: cs.CV

TL;DR: SOS是一个基于物体中心合成策略的简单可扩展数据合成管道，通过将高质量合成物体片段粘贴到新图像中，生成准确的掩码、边界框和指代表达式，在检测和定位任务上优于大型真实图像数据集。

- Motivation: 解决视觉分组任务中大型标注数据集成本高、覆盖偏差大、难以扩展的问题，以及合成数据缺乏灵活性、准确性和组合多样性的问题。
- Method: 使用物体中心组合策略，通过结构化布局先验和生成式重光照，将高质量合成物体片段粘贴到新图像中。
- Result: 在10万张合成图像上训练的模型在检测和定位任务上优于GRIT(2000万)和V3Det(20万)数据集，LVIS检测提升10.9 AP，gRefCOCO定位提升8.4 NAcc。在有限真实数据情况下表现更佳。
- Conclusion: SOS支持可控数据集构建，改善低数据和封闭词汇设置下的泛化能力，为目标数据生成提供支持，特别是在具有挑战性的类内指代任务中。


### [46] [MSDM: Generating Task-Specific Pathology Images with a Multimodal Conditioned Diffusion Model for Cell and Nuclei Segmentation](https://arxiv.org/abs/2510.09121)
*Dominik Winter,Mai Bui,Monica Azqueta Gavaldon,Nicolas Triltsch,Marco Rosati,Nicolas Brieu*

Main category: cs.CV

TL;DR: 提出多模态语义扩散模型(MSDM)生成细胞核分割的合成图像-掩码对，通过整合形态学、颜色特征和元数据来解决标注数据稀缺问题，显著提升分割模型性能。

- Motivation: 计算病理学中标注数据稀缺，特别是罕见或非典型形态的细胞核分割面临挑战，手工标注成本高昂，需要合成数据作为经济有效的替代方案。
- Method: 使用多模态语义扩散模型(MSDM)，通过细胞核形态学(水平和垂直图)、RGB颜色特征和BERT编码的元数据进行条件生成，利用多头交叉注意力整合异质模态。
- Result: 合成图像与真实数据高度匹配，在匹配生物条件下生成图像与真实图像的嵌入Wasserstein距离较低；合成样本显著提高了柱状细胞分割模型的准确性。
- Conclusion: 多模态扩散增强策略能系统性地丰富数据集，直接针对模型缺陷，提升细胞核分割模型的鲁棒性和泛化能力，为生成模型在计算病理学中的广泛应用铺平道路。


### [47] [Polar Separable Transform for Efficient Orthogonal Rotation-Invariant Image Representation](https://arxiv.org/abs/2510.09125)
*Satya P. Singh,Rashmi Chaudhry,Anand Srivastava,Jagath C. Rajapakse*

Main category: cs.CV

TL;DR: 提出PSepT（极坐标可分离变换），一种可分离的正交变换，解决了极坐标中的不可分离性障碍，显著降低了计算复杂度和内存需求。

- Motivation: 传统的正交矩图像表示方法（如Zernike和伪Zernike矩）存在高计算复杂度和数值不稳定性的问题，特别是在大阶数时，这限制了其在高阶矩分析中的应用。
- Method: 通过张量积构造离散余弦变换（DCT）径向基和傅里叶谐波角向基，实现完全核分解，使得径向和角向处理可以独立进行。
- Result: PSepT将计算复杂度从O(n^3N^2)到O(n^6N^2)降低到O(N^2 log N)，内存需求从O(N^4)降低到O(N^2)，条件数缩放从O(N^4)降低到O(√N)。
- Conclusion: PSepT在数值稳定性、计算效率和分类性能方面表现优异，为之前经典方法无法实现的高阶矩分析开辟了新的可能性。


### [48] [Training Feature Attribution for Vision Models](https://arxiv.org/abs/2510.09135)
*Aziz Bacha,Thomas George*

Main category: cs.CV

TL;DR: 提出训练特征归因方法，将测试预测与特定训练图像的特定区域关联，提供细粒度的模型解释，揭示传统方法无法发现的误分类驱动因素和伪相关性。

- Motivation: 深度神经网络被视为不透明系统，需要可解释性方法来提高信任度。现有方法通常将测试预测归因于输入特征或训练样本，但作者认为应该同时研究这两个视角。
- Method: 探索训练特征归因方法，该方法将测试预测与特定训练图像的特定区域联系起来。
- Result: 在视觉数据集上的实验表明，训练特征归因能提供细粒度的、测试特定的解释：识别导致误分类的有害样本，并揭示传统归因方法无法发现的伪相关性（如基于补丁的捷径）。
- Conclusion: 训练特征归因为深度模型的内部工作机制提供了新的见解，能够发现传统方法遗漏的重要解释信息。


### [49] [Online Topological Localization for Navigation Assistance in Bronchoscopy](https://arxiv.org/abs/2510.09144)
*Clara Tomasini,Luis Riazuelo,Ana C. Murillo*

Main category: cs.CV

TL;DR: 提出了一种基于图像的支气管镜拓扑定位方法，无需患者CT扫描即可在手术中提供导航辅助，仅使用模拟数据训练且具有良好的泛化能力。

- Motivation: 传统支气管镜导航方法依赖患者CT扫描和额外传感器，需要额外设置和训练。拓扑定位通常足以辅助外科医生导航，且不需要精确的度量定位。
- Method: 开发了基于图像的支气管镜拓扑定位流程，仅在模拟数据上进行训练，无需真实患者CT扫描，降低了数据标注成本。
- Result: 该方法在结果上超越了现有方法，特别是在真实数据测试序列上表现优异。
- Conclusion: 该图像支气管镜拓扑定位方法提供了一种无需患者CT扫描的有效导航辅助方案，具有成本效益和良好的泛化性能。


### [50] [Instance-Level Generation for Representation Learning](https://arxiv.org/abs/2510.09171)
*Yankun Wu,Zakaria Laskar,Giorgos Kordopatis-Zilos,Noa Garcia,Giorgos Tolias*

Main category: cs.CV

TL;DR: 提出一种无需真实图像即可生成多样化对象实例的新方法，通过合成数据训练显著提升实例级识别在多个领域的检索性能。

- Motivation: 实例级识别需要精细标注，但大规模标注数据集创建困难，限制了其在实际应用中的广泛使用。
- Method: 从多个领域在多样化条件和背景下合成生成对象实例，构建大规模训练集，不依赖任何真实图像。
- Result: 在七个跨领域ILR基准测试中，基于生成数据微调的基础视觉模型显著提升了检索性能。
- Conclusion: 该方法为数据收集和整理提供了高效有效的替代方案，只需目标领域名称即可实现实例级识别，具有广泛的实际应用前景。


### [51] [TARO: Toward Semantically Rich Open-World Object Detection](https://arxiv.org/abs/2510.09173)
*Yuchen Zhang,Yao Lu,Johannes Betz*

Main category: cs.CV

TL;DR: TARO是一个新颖的目标检测框架，不仅识别未知物体，还将其分类到语义层次结构中的粗粒度父类别，相比传统开放集检测方法提供更细粒度的未知物体分类。

- Motivation: 传统目标检测器局限于'封闭世界'假设，无法处理现实场景中的新物体。现有开放集检测方法将所有未知物体归为单一'Unknown'类别，这在安全关键场景中信息不足，需要更细粒度的分类来支持决策。
- Method: TARO采用独特架构：基于sparsemax的物体性建模头、层次引导的重标记组件提供辅助监督、学习层次关系的分类模块。
- Result: 实验显示TARO能将29.9%的未知物体分类到有意义的粗粒度类别，显著减少未知与已知类别间的混淆，在未知召回率和已知mAP上均取得竞争性表现。
- Conclusion: TARO框架成功解决了开放世界目标检测中未知物体细粒度分类的问题，为安全关键应用提供了更实用的解决方案。


### [52] [Online Video Depth Anything: Temporally-Consistent Depth Prediction with Low Memory Consumption](https://arxiv.org/abs/2510.09182)
*Johann-Friedrich Feiden,Tim Küchler,Denis Zavadski,Bogdan Savchynskyy,Carsten Rother*

Main category: cs.CV

TL;DR: 提出了在线视频深度估计方法oVDA，通过借鉴LLM的缓存和掩码技术，解决了VDA只能批处理的问题，在精度和VRAM使用上优于现有在线方法，在边缘设备上实现高效部署。

- Motivation: 现有的Video Depth Anything (VDA)方法依赖批处理，无法在在线场景中使用。需要开发能够在实时在线设置中运行的高效视频深度估计方法，特别是在边缘设备上。
- Method: 借鉴大语言模型的技术，在推理时缓存潜在特征，在训练时使用帧掩码技术，实现高效的在线视频深度估计。
- Result: oVDA在精度和VRAM使用上均优于所有竞争在线视频深度估计方法，在NVIDIA A100上达到42 FPS，在NVIDIA Jetson边缘设备上达到20 FPS。
- Conclusion: oVDA成功将VDA扩展到在线设置，通过LLM技术实现了高效的实时深度估计，特别适合边缘设备部署，将发布代码和编译脚本。


### [53] [Modern Deep Learning Approaches for Cricket Shot Classification: A Comprehensive Baseline Study](https://arxiv.org/abs/2510.09187)
*Sungwoo Kang*

Main category: cs.CV

TL;DR: 本文首次对板球击球动作分类进行了全面的基准研究，比较了七种深度学习方法在四种研究范式下的表现，发现学术文献中的高精度声明与实际实现结果存在显著差距。

- Motivation: 板球击球动作分类在体育视频分析中仍具挑战性，需要有效建模空间和时间特征。现有文献中的高精度声明缺乏标准化评估，需要系统性的基准研究来验证实际性能。
- Method: 实现并系统评估了传统CNN-LSTM架构、注意力模型、视觉变换器、迁移学习方法以及现代EfficientNet-GRU组合，在统一基准上使用PyTorch Lightning进行可重复研究。
- Result: 研究发现学术文献声称的精度（96%、99.2%、93%）与实际重新实现结果（46.0%、55.6%、57.7%）存在巨大差距。现代SOTA方法（EfficientNet-B0 + GRU）达到92.25%精度。
- Conclusion: 现代架构和系统优化可以带来实质性改进，标准化评估协议在体育视频分析研究中至关重要，所有实现遵循现代MLOps实践提供可重复研究平台。


### [54] [Towards Safer and Understandable Driver Intention Prediction](https://arxiv.org/abs/2510.09200)
*Mukilan Karuppasamy,Shankar Gangisetty,Shyam Nandan Rai,Carlo Masone,C V Jawahar*

Main category: cs.CV

TL;DR: 该论文提出了一个可解释的驾驶员意图预测框架VCBM，通过新的多模态数据集DAAD-X和概念瓶颈模型来生成时空一致的解释，提高了自动驾驶系统的可解释性。

- Motivation: 随着自动驾驶系统与人类交互的增加，决策过程的可解释性对安全驾驶至关重要。深度学习系统在理解环境表示和驾驶任务方面仍面临挑战，需要可解释的驾驶员意图预测方法。
- Method: 提出了Video Concept Bottleneck Model (VCBM)框架，使用新的多模态数据集DAAD-X，该数据集包含从驾驶员视线和车辆视角推导的层次化文本解释。VCBM能够固有地生成时空一致的解释，无需依赖后处理技术。
- Result: 在DAAD-X数据集上的评估表明，基于transformer的模型比传统CNN模型具有更好的可解释性。还引入了多标签t-SNE可视化技术来展示多个解释之间的解缠和因果相关性。
- Conclusion: VCBM框架为驾驶员意图预测提供了有效的可解释性解决方案，transformer架构在可解释性方面优于CNN，多标签可视化技术有助于理解解释之间的因果关系。


### [55] [Cattle-CLIP: A Multimodal Framework for Cattle Behaviour Recognition](https://arxiv.org/abs/2510.09203)
*Huimin Liu,Jing Gao,Daria Baran,AxelX Montout,Neill W Campbell,Andrew W Dowsey*

Main category: cs.CV

TL;DR: Cattle-CLIP是一个基于CLIP模型的多模态深度学习框架，通过添加时间整合模块和专门的数据增强策略，用于牛只行为识别，在监督学习下达到96.1%的准确率。

- Motivation: 牛只行为是动物健康和生产力的重要指标，现有视频监控方法在数据稀缺的行为识别任务中表现不佳，需要开发能够在小样本场景下有效工作的识别方法。
- Method: 基于CLIP模型构建多模态框架，添加时间整合模块，采用定制化数据增强策略和专门文本提示，解决预训练模型与真实监控视频之间的领域差距问题。
- Result: 在CattleBehaviours6数据集上，监督学习达到96.1%整体准确率，其中进食、饮水和站立反刍行为的召回率接近100%，在小样本场景下也表现出良好的泛化能力。
- Conclusion: 多模态学习在农业和动物行为分析中具有巨大潜力，Cattle-CLIP框架能够有效处理数据稀缺的行为识别任务，为牲畜监测提供了可靠解决方案。


### [56] [3D Reconstruction from Transient Measurements with Time-Resolved Transformer](https://arxiv.org/abs/2510.09205)
*Yue Li,Shida Sun,Yu Hong,Feihu Xu,Zhiwei Xiong*

Main category: cs.CV

TL;DR: 提出了一种通用的时间分辨Transformer(TRT)架构，用于提升光子效率成像中的3D重建性能。该架构包含专门为时空瞬态测量设计的注意力机制，包括时空自注意力编码器和时空交叉注意力解码器。

- Motivation: 解决光子效率成像中由于传感器量子效率低和噪声水平高导致的3D重建挑战，特别是在长距离或复杂场景下。
- Method: 设计了TRT架构，包含时空自注意力编码器（通过分割或下采样探索局部和全局相关性）和时空交叉注意力解码器（在token空间集成局部和全局特征）。开发了TRT-LOS和TRT-NLOS两个任务特定实现。
- Result: 在合成数据和真实世界数据上的广泛实验表明，两种实现都显著优于现有方法。贡献了大规模高分辨率合成LOS数据集和真实世界NLOS测量数据。
- Conclusion: TRT架构有效提升了光子效率成像中的3D重建性能，为LOS和NLOS成像提供了通用解决方案。


### [57] [Stable Video Infinity: Infinite-Length Video Generation with Error Recycling](https://arxiv.org/abs/2510.09212)
*Wuyang Li,Wentao Pan,Po-Chien Luan,Yang Gao,Alexandre Alahi*

Main category: cs.CV

TL;DR: 提出Stable Video Infinity (SVI)方法，能够生成无限长度视频，具有高时间一致性、合理的场景转换和可控的流式故事情节，通过错误回收微调技术解决自回归生成中的误差累积问题。

- Motivation: 现有长视频生成方法局限于单提示外推，产生同质化场景和重复动作，根本挑战在于训练假设（基于干净数据）与测试时自回归现实（基于自生成、易出错输出）之间的关键差异。
- Method: 采用错误回收微调，通过闭环回收将DiT自生成的错误转化为监督提示，包括：(i)注入历史错误干预干净输入；(ii)使用一步双向积分高效近似预测；(iii)在离散时间步动态存储错误到重放内存。
- Result: SVI能够将视频从秒级扩展到无限时长，无需额外推理成本，同时保持与多种条件（音频、骨架、文本流）的兼容性，在三个基准测试中验证了其多功能性和最先进性能。
- Conclusion: SVI通过主动识别和纠正自身错误，成功解决了长视频生成中的误差累积问题，实现了无限长度视频的高质量生成。


### [58] [Tag-Enriched Multi-Attention with Large Language Models for Cross-Domain Sequential Recommendation](https://arxiv.org/abs/2510.09224)
*Wangyu Wu,Xuhang Chen,Zhenhong Chen,Jing-En Jiang,Kim-Fung Tsang,Xiaowei Huang,Fei Ma,Jimin Xiao*

Main category: cs.CV

TL;DR: 提出TEMA-LLM框架，结合大语言模型进行语义标签生成和增强，通过多注意力机制建模跨域用户偏好，在电商推荐系统中显著优于现有方法。

- Motivation: 跨域序列推荐系统需要准确捕捉领域特定和跨域行为模式，以提供个性化和无缝的消费者体验。现有方法在语义理解方面存在局限。
- Method: 使用LLM生成领域感知的描述性标签，将标签嵌入与项目标识符、文本和视觉特征融合构建增强的项目表示，引入标签增强的多注意力机制联合建模域内和跨域用户偏好。
- Result: 在四个大规模电商数据集上的实验表明，TEMA-LLM持续优于最先进的基线方法，证明了基于LLM的语义标签和多注意力集成的优势。
- Conclusion: 该方法突显了LLM在推进消费电子领域智能、以用户为中心服务方面的潜力。


### [59] [Clear Roads, Clear Vision: Advancements in Multi-Weather Restoration for Smart Transportation](https://arxiv.org/abs/2510.09228)
*Vijay M. Galshetwar,Praful Hambarde,Prashant W. Patil,Akshay Dudhane,Sachin Chaudhary,Santosh Kumar Vipparathi,Subrahmanyam Murala*

Main category: cs.CV

TL;DR: 这篇论文是关于恶劣天气条件下图像和视频恢复技术的综述，涵盖雾霾、雨雪等天气对智能交通系统视觉输入的影响，系统分类了传统方法和现代数据驱动模型。

- Motivation: 恶劣天气条件显著降低图像和视频质量，对依赖视觉输入的智能交通系统（如自动驾驶、交通监控）构成严重挑战，需要开发有效的恢复技术来缓解天气引起的视觉损伤。
- Method: 将现有方法分类为传统基于先验的方法和现代数据驱动模型（包括CNN、transformer、扩散模型和新兴的视觉语言模型），并根据处理范围进一步分为单任务模型、多任务/多天气系统和全能框架。
- Result: 提供了全面的技术分类和评估，讨论了白天和夜间恢复挑战、基准数据集和评估协议，并维护了相关论文和开源实现的持续更新。
- Conclusion: 指出了当前研究的局限性，并展望了未来方向，如混合/复合退化恢复、实时部署和智能AI框架，旨在为智能交通环境中天气弹性视觉系统的发展提供有价值的参考。


### [60] [Diagnosing Shoulder Disorders Using Multimodal Large Language Models and Consumer-Grade Cameras](https://arxiv.org/abs/2510.09230)
*Jindong Hong,Wencheng Zhang,Shiqin Qiao,Jianhai Chen,Jianing Qiu,Chuanyang Zheng,Qian Xu,Yun Ji,Qianyue Wen,Weiwei Sun,Hao Li,Huizhen Li,Huichao Wang,Kai Wu,Meng Li,Yijun He,Lingjie Luo,Jiankai Sun*

Main category: cs.CV

TL;DR: 提出基于消费级设备视频的肩部疾病诊断框架HMVDx，使用多模态大语言模型分别处理动作理解和疾病诊断任务，诊断准确率比直接视频诊断提升79.6%。

- Motivation: 在医疗资源稀缺地区，肩部疾病早期准确诊断面临挑战，需要低成本、易扩展的辅助诊断方案。
- Method: 提出HMVDx框架，将动作理解和疾病诊断任务分离，分别由两个多模态大语言模型完成，并引入基于医疗决策逻辑的可用性指数新指标。
- Result: HMVDx在肩关节损伤诊断中的准确率比直接视频诊断提高了79.6%。
- Conclusion: 该研究展示了低成本多模态大语言模型在医疗应用中的潜力，为未来医学视频理解研究提供了重要技术贡献。


### [61] [Zero-shot image privacy classification with Vision-Language Models](https://arxiv.org/abs/2510.09253)
*Alina Elena Baia,Alessio Xompero,Andrea Cavallaro*

Main category: cs.CV

TL;DR: 本文通过建立零样本基准测试，系统比较了视觉语言模型与专用模型在图像隐私预测任务中的表现，发现VLMs虽然资源消耗大但准确率反而低于专用小模型，不过在抗图像扰动方面表现更好。

- Motivation: 当前文献倾向于采用通用视觉语言模型进行图像隐私预测，但缺乏系统评估，可能忽视了专用模型的性能上限，需要建立公平比较基准。
- Method: 建立零样本图像隐私分类基准，使用任务对齐提示评估排名前三的开源VLMs，并与已有的视觉专用和多模态方法在性能、效率和鲁棒性方面进行对比。
- Result: VLMs虽然参数多、推理慢、资源密集，但在隐私预测准确率上反而落后于专用小模型；不过VLMs对图像扰动表现出更高的鲁棒性。
- Conclusion: 在图像隐私预测任务中，专用轻量模型仍优于通用VLMs，但VLMs在鲁棒性方面有优势，这为模型选择提供了重要参考。


### [62] [Hallucination Filtering in Radiology Vision-Language Models Using Discrete Semantic Entropy](https://arxiv.org/abs/2510.09256)
*Patrick Wienholt,Sophie Caselitz,Robert Siepmann,Philipp Bruners,Keno Bressem,Christiane Kuhl,Jakob Nikolas Kather,Sven Nebelung,Daniel Truhn*

Main category: cs.CV

TL;DR: 该研究使用离散语义熵(DSE)来检测和过滤可能产生幻觉的问题，显著提高了黑盒视觉语言模型在放射学图像视觉问答中的准确性。

- Motivation: 为了解决黑盒视觉语言模型在放射学图像问答中容易产生幻觉的问题，研究者希望找到一种可靠的方法来识别和拒绝可能产生错误回答的问题。
- Method: 使用GPT-4o和GPT-4.1模型，在温度1.0下对每个问题回答15次，通过双向蕴含检查将意义等价的回答分组，计算语义簇的相对频率得到DSE值。然后过滤掉高熵问题(DSE > 0.3或0.6)。
- Result: 在706个图像-问题对中，基线准确率为GPT-4o 51.7%和GPT-4.1 54.8%。过滤高熵问题(DSE > 0.3)后，GPT-4o在剩余334个问题上的准确率提升至76.3%，GPT-4.1在剩余499个问题上的准确率提升至63.8%。
- Conclusion: DSE能够通过量化语义不一致性来可靠地检测黑盒视觉语言模型中的幻觉，显著提高诊断答案的准确性，为临床VLM应用提供了有效的过滤策略。


### [63] [MomentSeg: Moment-Centric Sampling for Enhanced Video Pixel Understanding](https://arxiv.org/abs/2510.09274)
*Ming Dai,Sen Yang,Boqiang Duan,Wankou Yang,Jingdong Wang*

Main category: cs.CV

TL;DR: 提出统一框架联合优化时序语句定位和参考视频对象分割，通过[MOMENT]令牌进行关键时刻识别，并设计时刻中心采样策略和双向锚点更新传播机制来提升分割质量。

- Motivation: 现有LLM方法采样策略要么依赖手工启发式规则忽略时序线索，要么使用外部关键帧模型增加系统复杂度，需要更统一的解决方案。
- Method: 1) 训练时使用[FIND]令牌通过时序令牌相似性匹配识别关键时刻；2) 推理时采用时刻中心采样策略密集采样重要时刻；3) 提出双向锚点更新传播机制利用最相关时刻作为高质量掩码初始化。
- Result: 该方法自然整合了关键时刻定位能力，避免了外部时间戳编码需求，同时保持了运动细节和全局上下文。
- Conclusion: 提出的统一框架有效解决了RefVOS中的时序推理和细粒度视觉理解问题，通过联合优化TSG和RefVOS实现了更好的分割性能。


### [64] [Spotlight on Token Perception for Multimodal Reinforcement Learning](https://arxiv.org/abs/2510.09285)
*Siyuan Huang,Xiaoye Qu,Yafu Li,Yun Luo,Zefeng He,Daizong Liu,Yu Cheng*

Main category: cs.CV

TL;DR: 提出VPPO算法，通过令牌感知视角优化多模态强化学习，仅关注视觉依赖度高的关键令牌，显著提升LVLMs的多模态推理能力。

- Motivation: 现有多模态推理方法在RLVR优化过程中忽视了视觉感知的关键作用，需要从令牌感知的新视角来改进。
- Method: 提出视觉感知策略优化(VPPO)算法，通过双重机制：基于整体视觉依赖度重新加权轨迹优势，并仅对感知关键令牌进行策略更新。
- Result: 在8个感知和推理基准测试中，VPPO在7B和32B模型规模上均显著优于领先的开源RL调优模型。
- Conclusion: 建立了分析多模态RLVR的令牌级感知新视角，并提出了有效优化策略来显著增强LVLMs的多模态推理能力。


### [65] [Foraging with the Eyes: Dynamics in Human Visual Gaze and Deep Predictive Modeling](https://arxiv.org/abs/2510.09299)
*Tejaswi V. Panchagnula*

Main category: cs.CV

TL;DR: 人类视觉注视轨迹遵循类似动物觅食的Levy行走模式，这种随机轨迹具有重尾步长分布，在稀疏资源环境中实现最优效率。

- Motivation: 传统模型强调基于图像的显著性，但眼动的基本时空统计特性仍未充分探索。理解这些动态在注意力建模和基于视觉的界面中有广泛应用。
- Method: 进行大规模人类被试实验，40名参与者观看50张多样化图像，使用高速眼动仪记录超过400万个注视点。分析数据并训练卷积神经网络从图像输入预测注视热图。
- Result: 分析显示人类眼睛的注视轨迹遵循类似动物觅食的Levy行走模式。CNN模型能够准确再现新颖图像中的显著注视区域，证明关键注视行为组件可从视觉结构单独学习。
- Conclusion: 人类视觉探索遵循类似于自然觅食的统计规律，为通过生成和预测框架建模注视开辟了新途径。


### [66] [CapGeo: A Caption-Assisted Approach to Geometric Reasoning](https://arxiv.org/abs/2510.09302)
*Yuying Li,Siyi Qian,Hao Liang,Leqi Zheng,Ruichuan An,Yongzhen Guo,Wentao Zhang*

Main category: cs.CV

TL;DR: 提出CapGeo框架，通过将几何图形转换为文本描述来提升多模态大语言模型的几何推理能力，并创建CapGeo-Bench基准数据集进行评估。

- Motivation: 当前最先进的多模态大语言模型在几何推理方面表现不佳，瓶颈在于理解几何图形而非推理本身。由于几何图形可以用简洁文本描述，将视觉内容转换为标题是可行的方向。
- Method: 引入CapGeo框架，通过标题辅助推理桥接视觉和文本模态。同时提出CapGeo-Bench数据集，包含4641个精选图形-标题对，并使用基于关键点的评估指标。
- Result: 配备标题后模型性能显著提升：Qwen2.5-VL-72B从8.6%提升至59.0%，Claude-Opus-4从44.8%提升至73.0%。评估指标与下游性能强相关。
- Conclusion: 该框架和基准为推进多模态大语言模型的几何推理能力开辟了新途径。


### [67] [RadioFlow: Efficient Radio Map Construction Framework with Flow Matching](https://arxiv.org/abs/2510.09314)
*Haozhe Jia,Wenshuo Chen,Xiucheng Wang,Nan Cheng,Hongbo Zhang,Kuimou Yu,Songning Lai,Nanjian Jia,Bowen Tian,Hongru Xiao,Yutao Yue*

Main category: cs.CV

TL;DR: RadioFlow是一个基于流匹配的生成框架，通过单步高效采样实现高保真无线电地图生成，相比扩散模型减少了8倍参数和4倍推理时间。

- Motivation: 现有基于扩散的方法存在模型尺寸大、迭代去噪慢、推理延迟高等问题，阻碍了实际部署，需要更高效的无线电地图生成方法。
- Method: 提出RadioFlow框架，学习噪声和数据之间的连续传输轨迹，实现单步高效采样，显著加速训练和推理过程。
- Result: 实验表明RadioFlow在保持重建精度的同时，相比领先的扩散基线(RadioDiff)减少了8倍参数和4倍推理时间。
- Conclusion: RadioFlow为未来6G网络的可扩展、节能和实时电磁数字孪生提供了有前景的技术路径。


### [68] [Hybrid-grained Feature Aggregation with Coarse-to-fine Language Guidance for Self-supervised Monocular Depth Estimation](https://arxiv.org/abs/2510.09320)
*Wenyao Zhang,Hongsi Liu,Bohan Li,Jiawei He,Zekun Qi,Yunnan Wang,Shengyang Zhao,Xinqiang Yu,Wenjun Zeng,Xin Jin*

Main category: cs.CV

TL;DR: 提出Hybrid-depth框架，通过整合CLIP和DINO基础模型来提升单目深度估计性能，采用从粗到细的渐进学习策略，在KITTI基准测试中显著优于现有方法。

- Motivation: 当前自监督单目深度估计方法由于语义-空间知识提取不足而存在性能限制，需要更充分的上下文信息来改善深度估计质量。
- Method: 1) 从CLIP和DINO聚合多粒度特征，在对比语言指导下设计代理任务进行深度感知特征对齐；2) 基于粗特征整合相机姿态信息和像素级语言对齐来细化深度预测，可作为即插即用模块与现有MDE管道集成。
- Result: 在KITTI基准测试中显著优于最先进方法，所有指标均有提升，同时有益于下游任务如BEV感知。
- Conclusion: 通过语言指导聚合CLIP的语义上下文和DINO的空间细节，有效解决了特征粒度不匹配问题，为自监督单目深度估计提供了有效的解决方案。


### [69] [Instance-Aware Robust Consistency Regularization for Semi-Supervised Nuclei Instance Segmentation](https://arxiv.org/abs/2510.09329)
*Zenan Lin,Wei Li,Jintao Chen,Zihao Wu,Wenxiong Kang,Changxin Gao,Liansheng Wang,Jin-Gang Yu*

Main category: cs.CV

TL;DR: 提出IRCR-Net用于病理图像中的半监督细胞核实例分割，通过实例感知一致性正则化和形态学先验知识减少伪标签噪声，提升密集分布和重叠细胞核的分割精度

- Motivation: 病理图像中细胞核实例分割对肿瘤微环境分析至关重要，但标注数据成本高且稀缺，现有半监督方法在实例级一致性正则化不足，缺乏病理结构先验知识利用，且训练中容易引入噪声伪标签
- Method: 提出IRCR-Net网络，包含匹配驱动的实例感知一致性(MIAC)和先验驱动的实例感知一致性(PIAC)机制，利用细胞核形态学先验知识评估伪标签质量，丢弃低质量伪标签，增强高质量预测
- Result: 实验结果表明该方法在多个公共数据集上显著提升半监督细胞核实例分割性能，在某些场景下甚至超越全监督方法
- Conclusion: IRCR-Net通过实例感知一致性正则化和形态学先验知识有效解决了半监督细胞核分割中的伪标签噪声问题，在标注数据稀缺的情况下实现了优异的性能


### [70] [Enhancing Infrared Vision: Progressive Prompt Fusion Network and Benchmark](https://arxiv.org/abs/2510.09343)
*Jinyuan Liu,Zihang Chen,Zhu Liu,Zhiying Jiang,Long Ma,Xin Fan,Risheng Liu*

Main category: cs.CV

TL;DR: 提出了一种渐进式提示融合网络（PPFN）用于热红外图像增强，通过基于热成像过程建立提示对并融合来调制模型特征，结合选择性渐进训练机制处理单一或复合退化问题。

- Motivation: 现有红外图像增强方法主要针对单一退化问题，难以处理耦合退化；而通用增强方法由于成像模型差异在RGB传感器上效果有限。
- Method: PPFN基于热成像过程建立提示对，融合对应退化类型的提示对来调制模型特征；引入选择性渐进训练（SPT）机制逐步优化模型对复合情况的处理。
- Result: 该方法在特定退化下提供有前景的视觉结果，在复杂退化场景中性能显著提升，达到8.76%的改进。
- Conclusion: PPFN能够有效去除相机噪声、保留关键结构细节并增强热图像整体对比度，同时构建了高质量多场景红外基准数据集。


### [71] [Boosting Multi-modal Keyphrase Prediction with Dynamic Chain-of-Thought in Vision-Language Models](https://arxiv.org/abs/2510.09358)
*Qihang Ma,Shengyu Li,Jie Tang,Dingkang Yang,Shaodong Chen,Yingyi Zhang,Chao Feng,Jiao Ran*

Main category: cs.CV

TL;DR: 本文提出利用视觉语言模型进行多模态关键词预测，通过零样本和监督微调评估模型性能，采用Fine-tune-CoT提升推理能力，并提出动态CoT策略解决"过度思考"问题。

- Motivation: 传统多模态方法在处理缺失和未见场景时存在显著局限性，现有基准测试因训练测试重叠而高估模型能力。
- Method: 使用零样本和监督微调评估VLM性能下限；采用Fine-tune-CoT利用教师模型生成的高质量推理数据微调小模型；提出动态CoT策略在训练中自适应注入CoT数据。
- Result: 在多个数据集上的实验结果表明所提方法的有效性。
- Conclusion: 提出的动态CoT策略能有效提升视觉语言模型在多模态关键词预测任务中的性能。


### [72] [BLINK-Twice: You see, but do you observe? A Reasoning Benchmark on Visual Perception](https://arxiv.org/abs/2510.09361)
*Junyan Ye,Dongzhi Jiang,Jun He,Baichuan Zhou,Zilong Huang,Zhiyuan Yan,Hongsheng Li,Conghui He,Weijia Li*

Main category: cs.CV

TL;DR: BLINK-Twice是一个视觉中心推理基准，专注于从纯视觉内容进行推理，超越了浅层感知，需要细粒度观察和分析推理。

- Motivation: 现有的多模态大语言模型推理基准主要评估基于语言的推理，将视觉输入视为可替换的上下文，缺乏对视觉中心推理的专门评估。
- Method: 构建包含七种视觉挑战类型的基准，使用自然对抗图像对强制模型依赖视觉内容，并提供带注释的推理链进行细粒度评估。
- Result: 评估了20个领先的MLLM，发现BLINK-Twice对当前模型构成重大挑战，现有语言空间推理策略效果不稳定且冗余，重复图像观察和主动视觉交互能提升性能。
- Conclusion: 需要为视觉推理开发新的范式，强调主动视觉交互和细粒度观察的重要性。


### [73] [Visibility-Aware Densification for 3D Gaussian Splatting in Dynamic Urban Scenes](https://arxiv.org/abs/2510.09364)
*Yikang Zhang,Rui Fan*

Main category: cs.CV

TL;DR: VAD-GS是一个针对城市场景的3D高斯溅射框架，通过体素化可见性推理、多样性感知视图选择和基于块匹配的多视角立体重建来恢复缺失的几何结构。

- Motivation: 传统3DGS方法严重依赖初始点云质量，在城市无界动态环境中，由于观测视锥体不重叠，往往导致点云覆盖不均匀和不完整，产生失真和伪影。现有密度化策略无法重建缺失结构。
- Method: 1. 体素化可见性推理识别不可靠几何结构 2. 多样性感知视图选择选取信息丰富的支持视图 3. 基于块匹配的多视角立体重建恢复缺失结构
- Result: 在Waymo和nuScenes数据集上的实验表明，VAD-GS优于最先进的3DGS方法，显著提高了静态和动态对象重建几何的质量。
- Conclusion: VAD-GS能够通过可靠的几何先验生成新的高斯基元，即使在缺乏初始点的区域也能有效恢复几何结构，解决了3DGS在城市场景中的几何恢复挑战。


### [74] [Minkowski-MambaNet: A Point Cloud Framework with Selective State Space Models for Forest Biomass Quantification](https://arxiv.org/abs/2510.09367)
*Jinxiang Tu,Dayong Ren,Fei Shi,Zhenhong Jia,Yahong Ren,Jiwei Qin,Fang He*

Main category: cs.CV

TL;DR: 提出Minkowski-MambaNet框架，直接从原始LiDAR点云估计森林体积和地上生物量，无需数字地形模型，在丹麦国家森林清单数据上表现优于现有方法。

- Motivation: 准确量化森林生物量对碳循环监测至关重要。虽然机载LiDAR能捕捉3D森林结构，但从点云直接估计木质体积和地上生物量具有挑战性，因为需要建模长程依赖关系来区分树木。
- Method: 将Mamba模型的选择性状态空间模型集成到Minkowski网络中，有效编码全局上下文和长程依赖关系以改进树木区分。加入跳跃连接以增强特征并加速收敛。
- Result: 在丹麦国家森林清单LiDAR数据上的评估显示，Minkowski-MambaNet显著优于最先进方法，提供更准确和稳健的估计。
- Conclusion: 该工作为大规模森林生物量分析提供了强大工具，推进了基于LiDAR的森林清查技术。


### [75] [Utilizing dynamic sparsity on pretrained DETR](https://arxiv.org/abs/2510.09380)
*Reza Sedghi,Anand Subramoney,David Kappel*

Main category: cs.CV

TL;DR: 提出了两种无需重新训练的方法来利用DETR中MLP层的稀疏性：静态指示器稀疏化(SIBS)和微门控稀疏化(MGS)，其中MGS通过轻量级门控机制实现85-95%的激活稀疏度，在COCO数据集上保持或提升性能的同时显著减少计算量。

- Motivation: 基于transformer的模型在视觉任务中的推理效率仍然是一个挑战，特别是在目标检测等任务中。本文分析了DETR中MLP层固有的稀疏性，旨在开发无需重新训练的方法来利用这种稀疏性。
- Method: 提出了两种方法：1) SIBS：基于固定激活模式的启发式方法预测神经元不活动性；2) MGS：在预训练DETR基础上训练的轻量级门控机制，使用小型线性层预测动态稀疏性。
- Result: 在COCO数据集上的实验表明，MGS实现了85-95%的激活稀疏度，在保持甚至提升性能的同时显著减少了计算量。
- Conclusion: 该方法提供了一种实用、输入自适应的稀疏化方法，使得无需完全重新训练即可高效部署预训练的视觉transformer模型。


### [76] [Mono4DEditor: Text-Driven 4D Scene Editing from Monocular Video via Point-Level Localization of Language-Embedded Gaussians](https://arxiv.org/abs/2510.09438)
*Jin-Chuan Shi,Chengye Su,Jiajun Wang,Ariel Shamir,Miao Wang*

Main category: cs.CV

TL;DR: Mono4DEditor是一个用于从单目视频重建的4D场景中进行文本驱动编辑的新框架，通过量化CLIP特征增强3D高斯表示，实现语义精确的局部编辑。

- Motivation: 从单目视频重建的4D场景基于文本提示进行编辑在内容创作和虚拟环境中具有广泛应用价值，但面临在复杂动态场景中实现语义精确局部编辑的挑战。
- Method: 使用量化CLIP特征增强3D高斯形成语言嵌入动态表示；提出两阶段点级定位策略，先通过CLIP相似度选择候选高斯，再细化空间范围；使用基于扩散的视频编辑模型进行目标编辑，通过流和涂鸦引导确保空间保真度和时间一致性。
- Result: 实验表明Mono4DEditor能够在多样化场景和对象类型上实现高质量的文本驱动编辑，同时保持未编辑区域的外观和几何完整性，在灵活性和视觉保真度上超越先前方法。
- Conclusion: Mono4DEditor通过语言嵌入表示和精确定位策略，成功解决了4D场景文本驱动编辑的挑战，为动态场景编辑提供了有效的解决方案。


### [77] [Dynamic Weight-based Temporal Aggregation for Low-light Video Enhancement](https://arxiv.org/abs/2510.09450)
*Ruirui Lin,Guoxi Huang,Nantheera Anantrasirichai*

Main category: cs.CV

TL;DR: DWTA-Net是一个两阶段低光视频增强框架，通过联合利用短期和长期时间线索，有效抑制噪声和伪影，提升视觉质量。

- Motivation: 解决现有学习方法在真实低光场景中因无法有效利用时间信息而难以处理严重噪声的问题。
- Method: 第一阶段使用Visual State-Space块进行多帧对齐，恢复亮度、颜色和结构；第二阶段引入基于动态权重的时间聚合循环细化模块，通过光流引导自适应平衡静态和动态区域，并使用纹理自适应损失函数。
- Result: 在真实世界低光视频上的实验表明，DWTA-Net能有效抑制噪声和伪影，相比最先进方法提供更优的视觉质量。
- Conclusion: DWTA-Net通过有效利用时间信息，在低光视频增强任务中取得了显著改进，特别是在噪声抑制和细节保持方面表现优异。


### [78] [SilvaScenes: Tree Segmentation and Species Classification from Under-Canopy Images in Natural Forests](https://arxiv.org/abs/2510.09458)
*David-Alexandre Duclos,William Guimont-Martin,Gabriel Jeanson,Arthur Larochelle-Tremblay,Théo Defosse,Frédéric Moore,Philippe Nolet,François Pomerleau,Philippe Giguère*

Main category: cs.CV

TL;DR: 提出了SilvaScenes数据集，用于解决森林环境中树木实例分割和物种分类的挑战，包含1476棵树24个物种的标注数据，在五个生物气候区域收集。

- Motivation: 现有数据集主要关注城市环境或有限物种，无法满足复杂自然环境中森林管理的感知需求，如精确林业、生物多样性监测和林业设备自动化。
- Method: 在加拿大魁北克五个生物气候区域收集林下图像，由林业专家进行标注，包含1476棵树24个物种的实例分割标注，并基于此数据集对现代深度学习实例分割方法进行基准测试。
- Result: 树木分割相对容易，最高mAP达到67.65%，但物种分类极具挑战性，mAP仅为35.69%。
- Conclusion: SilvaScenes数据集填补了森林环境感知数据集的空白，证明了树木物种分类在复杂自然环境中仍然是一个重大挑战，为未来研究提供了重要基准。


### [79] [D-TPT: Dimensional Entropy Maximization for Calibrating Test-Time Prompt Tuning in Vision-Language Models](https://arxiv.org/abs/2510.09473)
*Jisu Han,Wonjun Hwang*

Main category: cs.CV

TL;DR: 提出一种维度熵最大化方法，通过正则化文本特征分布来缓解主导维度依赖，改善测试时提示调优中的校准性能退化问题。

- Motivation: 对比视觉语言模型存在由跨模态单一主导特征维度引起的模态间隙问题，主导维度具有高预测敏感性，限制其影响可以改善校准误差。
- Method: 提出维度熵最大化方法，通过将文本特征分布正则化向均匀分布，减轻主导维度的依赖。
- Result: 该方法缓解了测试时提示调优中校准性能的退化，为实际部署场景中视觉语言模型的可靠性提供了简单有效的解决方案。
- Conclusion: 维度熵最大化是一种有效的方法，能够提高视觉语言模型在测试时适应中的校准可靠性。


### [80] [Few-shot multi-token DreamBooth with LoRa for style-consistent character generation](https://arxiv.org/abs/2510.09475)
*Ruben Pascual,Mikel Sesma-Sara,Aranzazu Jurio,Daniel Paternain,Mikel Galar*

Main category: cs.CV

TL;DR: 提出一种基于DreamBooth的多token策略，结合LoRA高效微调，实现从少量参考角色中生成无限数量新角色，同时保持艺术风格一致性。

- Motivation: 解决动画和游戏行业需要从少量人类设计角色中生成大量新角色，同时保持艺术风格一致性的问题。
- Method: 基于DreamBooth框架，采用多token策略为单个角色和集体风格分配独立token，结合LoRA参数高效微调，移除类别特定正则化集，在生成时引入随机token和嵌入。
- Result: 在五个小型专业数据集上的评估显示，该方法能生成高质量、多样化的角色，同时保持参考角色的独特美学特征，人类评估进一步验证了其有效性。
- Conclusion: 该方法在保持艺术风格一致性的同时，实现了无限角色生成，为动画、游戏等创意领域提供了新的可能性。


### [81] [A methodology for clinically driven interactive segmentation evaluation](https://arxiv.org/abs/2510.09499)
*Parhom Esmaeili,Virginia Fernandez,Pedro Borges,Eli Gibson,Sebastien Ourselin,M. Jorge Cardoso*

Main category: cs.CV

TL;DR: 提出了一种基于临床的交互式医学图像分割评估方法，构建了标准化评估框架，评估了多种先进算法在不同任务中的表现。

- Motivation: 交互式分割是构建稳健、可泛化医学图像分割算法的有前景策略，但不一致和不切实际的评估阻碍了公平比较并歪曲了真实性能。
- Method: 提出了临床基础的评估任务和指标定义方法，构建了用于标准化评估管道的软件框架，评估了多种最先进算法在异质复杂任务中的表现。
- Result: 发现：(i)处理用户交互时最小化信息损失对模型稳健性至关重要；(ii)自适应缩放机制提升稳健性和收敛速度；(iii)验证提示行为/预算与训练不同时性能下降；(iv)2D方法在板状图像和粗糙目标上表现良好，但3D上下文有助于处理大或不规则形状目标；(v)非医学领域模型在对比度差和复杂形状时性能下降。
- Conclusion: 提出了标准化的临床基础评估框架，揭示了交互式分割算法的关键性能特征，为公平比较和真实性能评估提供了基础。


### [82] [PhysToolBench: Benchmarking Physical Tool Understanding for MLLMs](https://arxiv.org/abs/2510.09507)
*Zixin Zhang,Kanghao Chen,Xingwang Lin,Lutao Jiang,Xu Zheng,Yuanhuiyi Lyu,Litao Guo,Yinchuan Li,Ying-Cong Chen*

Main category: cs.CV

TL;DR: PhysToolBench是首个专门评估多模态大语言模型对物理工具理解能力的基准测试，包含1000多个图像-文本对，评估工具识别、工具理解和工具创造三个难度层次的能力。

- Motivation: 虽然现代MLLMs在具身AI中利用其广泛常识进行高级规划，但它们对物理工具的真正理解程度尚未量化，需要专门的评估基准。
- Method: 构建包含1000+图像-文本对的VQA数据集，评估32个MLLMs在工具识别、工具理解和工具创造三个层次的能力。
- Result: 评估显示MLLMs在工具理解方面存在显著缺陷，特别是在工具操作原理理解和工具创造方面表现不佳。
- Conclusion: 当前MLLMs对物理工具的理解能力有限，需要进一步改进，作者提供了初步解决方案，代码和数据集已公开。


### [83] [Diagonal Artifacts in Samsung Images: PRNU Challenges and Solutions](https://arxiv.org/abs/2510.09509)
*David Vázquez-Padín,Fernando Pérez-González,Alejandro Martín-Del-Río*

Main category: cs.CV

TL;DR: 三星智能手机存在对角线伪影问题，影响PRNU相机源验证，但PRO模式的原始图像可避免此问题。伪影也可用于减少HDR误检和定位人像模式中的合成虚化区域。

- Motivation: 研究三星智能手机图像中的对角线伪影及其对PRNU相机源验证的影响，探索在无法获取原始图像情况下的解决方案。
- Method: 分析多款三星手机模型的图像伪影模式，比较普通JPEG图像和PRO模式原始图像的PRNU验证效果，探索伪影在法证应用中的潜在用途。
- Result: 发现某些Galaxy S和A系列模型存在共享伪影模式导致指纹冲突；PRO模式原始图像可进行可靠PRNU验证；伪影可用于改善HDR图像检测和定位合成虚化区域。
- Conclusion: 对角线伪影既是对PRNU验证的挑战，也可转化为法证工具，特别是在无法获取原始图像的情况下具有应用价值。


### [84] [PRNet: Original Information Is All You Have](https://arxiv.org/abs/2510.09531)
*PeiHuang Zheng,Yunlong Zhao,Zheng Cui,Yang Li*

Main category: cs.CV

TL;DR: 提出PRNet实时检测框架，通过渐进式细化模块和增强切片采样技术，有效解决航拍图像中小目标检测因浅层空间细节与语义信息对齐不佳导致的漏检和误检问题。

- Motivation: 航拍图像中的小目标检测由于像素表示有限，在特征提取过程中面临严重的信息退化问题。浅层空间细节无法有效与语义信息对齐，导致频繁的漏检和误检。现有FPN方法通过后处理增强来缓解这些损失，但重建的细节往往偏离原始图像信息，阻碍与语义内容的融合。
- Method: 提出PRNet实时检测框架，包含两个核心模块：渐进式细化颈部（PRN）通过骨干网络重用和迭代细化实现空间-语义对齐；增强切片采样（ESSamp）通过优化的重排和卷积在降采样过程中保留浅层信息。
- Result: 在VisDrone、AI-TOD和UAVDT数据集上的大量实验表明，PRNet在可比较的计算约束下优于最先进的方法，实现了优越的精度-效率权衡。
- Conclusion: PRNet通过优先保留和有效利用原始浅层空间特征，成功增强了小目标表示能力，为航拍图像中的小目标检测提供了有效的解决方案。


### [85] [FLOWING: Implicit Neural Flows for Structure-Preserving Morphing](https://arxiv.org/abs/2510.09537)
*Arthur Bizzi,Matias Grynberg,Vitor Matias,Daniel Perazzo,João Paulo Lima,Luiz Velho,Nuno Gonçalves,João Pereira,Guilherme Schardong,Tiago Novello*

Main category: cs.CV

TL;DR: FLOWING是一个基于微分向量流的变形框架，通过将变形重新构建为流构造来确保连续性、可逆性和时间一致性，在2D图像和3D形状变形中实现高质量结果。

- Motivation: 传统多层感知机作为隐式神经表示进行变形建模时，需要昂贵的正则化，导致训练不稳定且难以有效对齐特征。
- Method: 将变形重新构建为微分向量流的构造，通过在网络架构中直接编码结构流属性来确保连续性和可逆性。
- Result: 在面部变形、图像变形和高斯溅射变形等应用中，FLOWING实现了最先进的变形质量，并具有更快的收敛速度。
- Conclusion: 基于流的方法能够产生原则性且稳定的变换，实现准确且结构保持的变形。


### [86] [TC-LoRA: Temporally Modulated Conditional LoRA for Adaptive Diffusion Control](https://arxiv.org/abs/2510.09561)
*Minkyoung Cho,Ruben Ohana,Christian Jacobsen,Adityan Jothi,Min-Hung Chen,Z. Morley Mao,Ethem Can*

Main category: cs.CV

TL;DR: TC-LoRA提出了一种动态条件控制方法，通过超网络为每个扩散步骤生成LoRA适配器，实现权重层面的条件控制，相比静态激活修改方法显著提升了生成质量和空间条件遵循能力。

- Motivation: 当前可控扩散模型使用静态架构修改中间激活来注入条件指导，这种静态条件策略限制了模型在从粗到细的生成过程中动态适应的能力。
- Method: 使用超网络根据时间和用户条件为冻结的主干网络动态生成LoRA适配器，实现权重层面的参数化条件控制。
- Result: 在各种数据域上的实验表明，这种动态参数控制相比静态激活方法显著提升了生成保真度和空间条件遵循能力。
- Conclusion: TC-LoRA建立了一种替代方法，通过更深入的权重功能适应来修改模型的条件策略，使控制能够与任务和生成阶段的动态需求保持一致。


### [87] [FSP-DETR: Few-Shot Prototypical Parasitic Ova Detection](https://arxiv.org/abs/2510.09583)
*Shubham Trehan,Udhav Ramachandran,Akash Rao,Ruth Scimeca,Sathyanarayanan N. Aakur*

Main category: cs.CV

TL;DR: FSP-DETR是一个统一的检测框架，能够在单一模型中实现鲁棒的少样本检测、开放集识别和跨生物医学任务的泛化，特别适用于标注数据稀缺和新类别频繁出现的生物医学场景。

- Motivation: 生物医学目标检测面临标注数据稀缺和新类别频繁出现的根本约束，现有方法通常孤立处理这些任务，缺乏统一的解决方案。
- Method: 基于类别无关的DETR骨干网络，通过原始支持图像构建类别原型，使用增强视图和轻量级Transformer解码器学习嵌入空间，联合优化原型匹配损失、基于对齐的分离损失和KL散度正则化。
- Result: 在卵细胞、血细胞和疟疾检测任务上的广泛实验表明，FSP-DETR显著优于先前的少样本和基于原型的检测器，特别是在低样本和开放集场景中。
- Conclusion: FSP-DETR提供了推理时的灵活性，支持未见类别识别、背景拒绝和跨任务适应而无需重新训练，为生物医学目标检测提供了统一的解决方案。


### [88] [Vision Language Models: A Survey of 26K Papers](https://arxiv.org/abs/2510.09586)
*Fengming Lin*

Main category: cs.CV

TL;DR: 对CVPR、ICLR和NeurIPS 2023-2025年26,104篇论文的研究趋势进行透明可复现的测量分析，揭示了三个宏观转变：多模态视觉语言大模型的兴起、生成方法的稳步扩展以及3D和视频活动的持续活跃。

- Motivation: 量化计算机视觉和机器学习领域的研究趋势，揭示技术演变的宏观模式，为社区提供可审计的研究趋势分析框架。
- Method: 通过标题和摘要的规范化处理、短语保护，使用手工构建的词典匹配来分配最多35个主题标签，挖掘任务、架构、训练机制、目标、数据集和多模态线索。
- Result: 发现三个主要趋势：1) 多模态视觉语言大模型工作急剧增加，将经典感知重构为指令跟随和多步推理；2) 生成方法稳步扩展，扩散研究集中在可控性、蒸馏和速度；3) 3D和视频活动保持活跃，从NeRF转向高斯泼溅，更强调以人和智能体为中心的理解。
- Conclusion: 研究趋势在跨会议和年份中表现一致，多模态和生成方法成为主导，参数高效适应和轻量级视觉语言桥梁成为主流，训练实践从零构建转向指令调优和微调强骨干网络。


### [89] [SpaceVista: All-Scale Visual Spatial Reasoning from mm to km](https://arxiv.org/abs/2510.09606)
*Peiwen Sun,Shiqiang Lang,Dongming Wu,Yi Ding,Kaituo Feng,Huadai Liu,Zhen Ye,Rui Liu,Yun-Hui Liu,Jianan Wang,Xiangyu Yue*

Main category: cs.CV

TL;DR: 该论文提出了一个全尺度空间推理解决方案SpaceVista，包括自动构建的SpaceVista-1M数据集（包含100万空间问答对）、SpaceVista-7B模型和人工标注的基准测试，旨在解决现有方法对室内3D扫描的依赖和缺乏有效全尺度建模的问题。

- Motivation: 解决空间推理领域对室内3D扫描的过度依赖和人工标注成本高的问题，同时克服现有方法在全尺度场景建模上的不足，避免对单个场景的过拟合。
- Method: 整合结构化空间推理知识系统、尺度感知建模和渐进式训练范式，使用任务特定的专家驱动自动化流水线构建数据集，并开发接受密集输入、使用尺度作为锚点的空间推理模型。
- Result: 在5个基准测试（包括SpaceVista-Bench）上表现出色，展示了在所有尺度和场景上的强大泛化能力。
- Conclusion: 提出的SpaceVista解决方案成功推进了全尺度空间推理，为机器人、自动驾驶等应用提供了更强大的空间智能能力。


### [90] [VITA-VLA: Efficiently Teaching Vision-Language Models to Act via Action Expert Distillation](https://arxiv.org/abs/2510.09607)
*Shaoqi Dong,Chaoyou Fu,Haihan Gao,Yi-Fan Zhang,Chi Yan,Chu Wu,Xiaoyu Liu,Yunhang Shen,Jing Huo,Deqiang Jiang,Haoyu Cao,Yang Gao,Xing Sun,Ran He,Caifeng Shan*

Main category: cs.CV

TL;DR: 提出了一种基于蒸馏的框架，通过从预训练的小型动作模型转移知识，为视觉语言模型赋予动作执行能力，显著降低训练成本并提升性能。

- Motivation: 视觉语言动作模型虽然能提升机器人操作的泛化能力，但从头训练成本高昂。本文旨在通过知识蒸馏方法，在保留预训练视觉语言模型结构的同时，为其添加动作执行能力。
- Method: 采用两阶段训练策略：1）轻量级对齐，将VLM隐藏状态映射到小型动作模型的动作空间；2）选择性微调语言模型、状态编码器和动作模块。通过添加动作token和状态编码器来整合多模态输入。
- Result: 在LIBERO数据集上达到97.3%平均成功率（提升11.8%），在LIBERO-LONG上达到93.5%（提升24.5%）。真实世界实验中，在五个操作任务上平均成功率82.0%（提升17%）。
- Conclusion: 动作蒸馏方法能有效使视觉语言模型生成精确动作，同时大幅降低训练成本，在仿真和真实世界任务中都表现出优越性能。


### [91] [StreamingVLM: Real-Time Understanding for Infinite Video Streams](https://arxiv.org/abs/2510.09608)
*Ruyi Xu,Guangxuan Xiao,Yukang Chen,Liuning He,Kelly Peng,Yao Lu,Song Han*

Main category: cs.CV

TL;DR: StreamingVLM是一个为实时理解无限视频流设计的视觉语言模型，通过统一的训练-推理对齐框架，使用KV缓存重用策略实现高效的长视频处理，在保持实时性能的同时显著提升长视频理解能力。

- Motivation: 现有视觉语言模型处理长视频时面临计算成本二次增长和性能下降的问题，滑动窗口方法要么破坏连贯性要么延迟过高，需要一种能够实时稳定理解无限视频流的方法。
- Method: 提出统一的训练-推理对齐框架，在推理时维护紧凑的KV缓存，重用注意力汇聚点、近期视觉token和文本token的状态。通过简单的监督微调策略，在短重叠视频块上应用完整注意力来模拟推理时的注意力模式。
- Result: 在Inf-Streams-Eval基准测试中，StreamingVLM以66.18%的胜率击败GPT-4O mini，在单张NVIDIA H100上保持高达8 FPS的稳定实时性能。监督微调策略还提升了通用VQA能力，在LongVideoBench和OVOBench Realtime上分别提升4.30和5.96分。
- Conclusion: StreamingVLM成功解决了长视频处理的效率和性能问题，实现了实时稳定的无限视频流理解，同时提升了模型的通用视觉问答能力。
## cs.SD

### [92] [MMAudioSep: Taming Video-to-Audio Generative Model Towards Video/Text-Queried Sound Separation](https://arxiv.org/abs/2510.09065)
*Akira Takahashi,Shusuke Takahashi,Yuki Mitsufuji*

Main category: cs.SD

TL;DR: MMAudioSep是一个基于预训练视频到音频模型的生成式声音分离模型，能够通过视频或文本查询进行声音分离，无需从头训练。

- Motivation: 利用预训练音频生成模型中学习到的视频/文本与音频关系知识，实现更高效的模型训练，避免从头训练的需求。
- Method: 基于预训练的视频到音频模型进行微调，使其具备声音分离功能，同时保留原有的视频到音频生成能力。
- Result: 与现有的确定性方法和生成式方法相比，MMAudioSep在声音分离性能上表现更优，且保持视频到音频生成能力。
- Conclusion: 展示了基础声音生成模型在声音相关下游任务中的应用潜力，为音频处理任务提供了新的解决方案。
## cs.LG

### [93] [FreqCa: Accelerating Diffusion Models via Frequency-Aware Caching](https://arxiv.org/abs/2510.08669)
*Jiacheng Liu,Peiliang Cai,Qinming Zhou,Yuqi Lin,Deyang Kong,Benhao Huang,Yupei Pan,Haowen Xu,Chang Zou,Junshu Tang,Shikang Zheng,Linfeng Zhang*

Main category: cs.LG

TL;DR: 本文提出了一种频率感知缓存方法（FreqCa），通过分析扩散模型中不同频率分量的动态特性，分别对低频和高频分量采用不同的缓存策略，显著降低了扩散变换器的推理成本。

- Motivation: 现有的特征缓存方法假设相邻时间步的特征相似或连续，但这种假设并不总是成立。通过频域分析发现，扩散模型特征中的低频和高频分量具有不同的动态特性，这启发了针对不同频率分量设计专门的缓存策略。
- Method: 1. 频域分析揭示低频分量具有高相似性但连续性差，高频分量具有高连续性但相似性差；2. 提出FreqCa方法：直接重用低频分量，使用二阶Hermite插值器预测高频分量；3. 提出缓存累积残差特征（CRF），将内存占用减少99%。
- Result: 在FLUX.1-dev、FLUX.1-Kontext-dev、Qwen-Image和Qwen-Image-Edit等多个数据集上的实验证明了该方法在生成和编辑任务中的有效性。
- Conclusion: 频率感知缓存方法通过利用不同频率分量的特性差异，实现了高效的推理加速，同时大幅减少了内存占用，为扩散变换器的实际应用提供了可行的解决方案。


### [94] [Reinforcement Learning-Driven Edge Management for Reliable Multi-view 3D Reconstruction](https://arxiv.org/abs/2510.08839)
*Motahare Mounesan,Sourya Saha,Houchao Gan,Md. Nurul Absur,Saptarshi Debroy*

Main category: cs.LG

TL;DR: 提出基于强化学习的边缘资源管理框架，用于在资源受限和易受干扰的环境中实现可靠的多视角3D重建，通过两个协作的Q学习代理分别负责相机选择和服务器选择。

- Motivation: 边缘环境中的动态资源可用性（如图像质量下降、网络不稳定、服务器负载波动）对实时多视角3D重建的可靠性构成挑战，特别是在消防救援等关键应用中需要及时准确的三维场景建模。
- Method: 采用两个协作的Q学习代理：一个负责相机选择，一个负责服务器选择，两者完全在线运行，通过与边缘环境交互学习策略。在包含实验室终端设备和FABRIC基础设施的分布式测试平台上进行实现和评估。
- Result: 该框架在动态环境中有效平衡端到端延迟和重建质量，提高了应用可靠性。
- Conclusion: 基于强化学习的边缘资源管理框架能够在资源受限和易受干扰的环境中实现可靠的多视角3D重建，为智能城市边缘基础设施提供有效的解决方案。


### [95] [The Boundaries of Fair AI in Medical Image Prognosis: A Causal Perspective](https://arxiv.org/abs/2510.08840)
*Thai-Hoang Pham,Jiayuan Chen,Seungyeon Lee,Yuanlong Wang,Sayoko Moroi,Xueru Zhang,Ping Zhang*

Main category: cs.LG

TL;DR: FairTTE是首个用于评估医学影像中时间到事件预测公平性的综合框架，揭示了不同成像模态中普遍存在的偏见问题。

- Motivation: 现有公平性研究主要关注医学图像诊断任务，而忽视了预后场景中的时间到事件预测公平性问题。
- Method: 开发FairTTE框架，整合先进的TTE预测和公平性算法，利用因果分析技术识别和量化医学影像数据集中的偏见来源。
- Result: 大规模评估显示偏见在不同成像模态中普遍存在，现有公平性方法缓解效果有限，且分布偏移下公平性更难维持。
- Conclusion: 需要针对所有偏见形式的整体方法，开发更稳健、公平的预后模型。


### [96] [Sparse components distinguish visual pathways & their alignment to neural networks](https://arxiv.org/abs/2510.08858)
*Ammar I Marvi,Nancy G Kanwisher,Meenakshi Khosla*

Main category: cs.LG

TL;DR: 本文通过稀疏分解方法识别视觉皮层三个通路的主要组件，发现腹侧通路选择性地处理面孔、地点、身体、文字和食物，外侧通路处理社交互动、隐含运动和手部动作，背侧通路组件较难解释。作者提出SCA方法，发现标准视觉DNN与腹侧通路的表征对齐度更高。

- Motivation: 探索为什么在人类视觉皮层中功能不同的三个通路（腹侧、背侧、外侧）能够被单一任务训练的深度神经网络很好地建模，这暗示了这些通路之间可能存在共同的计算原理。
- Method: 采用新颖的稀疏分解方法识别每个视觉通路中的主导组件，并引入稀疏组件对齐（SCA）方法来测量大脑与机器之间的表征对齐。
- Result: 发现三个视觉通路在组件响应特征上存在明显差异：腹侧通路对特定类别（如面孔、地点）有选择性，外侧通路对动态社交信息敏感，背侧通路组件较难解释。SCA方法显示标准视觉DNN与腹侧通路的对齐度高于其他通路。
- Conclusion: SCA方法比传统群体水平几何方法能更精细地揭示大脑与机器视觉系统之间的表征对齐差异，提供了一种对系统潜在神经调谐轴敏感的衡量方法。


### [97] [Bi-level Meta-Policy Control for Dynamic Uncertainty Calibration in Evidential Deep Learning](https://arxiv.org/abs/2510.08938)
*Zhen Yang,Yansong Ma,Lei Chen*

Main category: cs.LG

TL;DR: 提出了Meta-Policy Controller (MPC)框架，通过元学习动态调整KL散度系数和狄利克雷先验强度，解决传统EDL方法在动态数据分布下校准不足的问题。

- Motivation: 传统EDL方法使用静态超参数进行不确定性校准，在动态数据分布下适应性差，导致高风险决策任务中校准和泛化性能不佳。
- Method: 采用双层优化：内层通过动态配置的损失函数更新模型参数；外层通过策略网络基于多目标奖励优化KL散度系数和类别特定的狄利克雷先验强度。
- Result: 实验结果表明MPC显著提升了模型预测的可靠性和校准性，改善了不确定性校准、预测准确率以及基于置信度的样本剔除后的性能保持。
- Conclusion: MPC框架通过动态调整不确定性建模参数，有效提升了EDL方法在动态环境中的适应性和可靠性。


### [98] [Efficient Bayesian Inference from Noisy Pairwise Comparisons](https://arxiv.org/abs/2510.09333)
*Till Aczel,Lucas Theis,Wattenhofer Roger*

Main category: cs.LG

TL;DR: BBQ是一个贝叶斯Bradley-Terry变体，通过显式建模评分者质量来改进生成模型的人类评估，提供更可靠和成本效益的排名方法。

- Motivation: 标准评估指标无法反映人类偏好，而人工评估虽然更可靠但成本高且噪声大。现有Bradley-Terry方法要么忽略评分者变异性，要么缺乏收敛保证。
- Method: 提出BBQ方法，使用贝叶斯框架显式建模评分者质量，通过期望最大化算法提供单调似然收敛保证，对不可靠参与者进行降权或移除。
- Result: BBQ实现了更快的收敛速度、良好校准的不确定性估计，以及相比基线Bradley-Terry模型更稳健、可解释的排名，即使在有噪声或众包评分者的情况下。
- Conclusion: 该框架能够实现更可靠和成本效益更高的生成模型人类评估。


### [99] [STaTS: Structure-Aware Temporal Sequence Summarization via Statistical Window Merging](https://arxiv.org/abs/2510.09593)
*Disharee Bhowmick,Ranjith Ramanathan,Sathyanarayanan N. Aakur*

Main category: cs.LG

TL;DR: STaTS是一个轻量级的无监督框架，用于结构感知的时间序列摘要，通过自适应压缩时间序列为紧凑的标记序列，实现高达30倍的序列压缩同时保留核心时间动态。

- Motivation: 现有模型通常处理原始或固定窗口序列，将所有时间步视为同等信息量，导致在长序列或噪声序列中效率低下、鲁棒性差和可扩展性有限。时间序列数据包含的潜在时间结构、局部平稳状态转换、重复模式和变异性爆发很少在标准表示学习流程中被利用。
- Method: STaTS使用基于BIC的统计差异准则在多个时间分辨率上检测变化点，然后使用简单函数（如均值）或生成模型（如GMM）对每个段进行摘要。该框架作为模型无关的预处理器，可与现有无监督时间序列编码器集成而无需重新训练。
- Result: 在150多个数据集上的广泛实验表明，STaTS能够实现85-90%的完整模型性能，同时显著降低计算成本。在噪声条件下提高了鲁棒性，并保留了判别结构，优于均匀和基于聚类的压缩基线。
- Conclusion: STaTS为高效、结构感知的时间序列建模提供了一个原则性的通用解决方案，在保持核心时间动态的同时实现了显著的序列压缩。
## cs.CR

### [100] [Goal-oriented Backdoor Attack against Vision-Language-Action Models via Physical Objects](https://arxiv.org/abs/2510.09269)
*Zirun Zhou,Zhengyang Xiao,Haochuan Xu,Jing Sun,Di Wang,Jingfeng Zhang*

Main category: cs.CR

TL;DR: 本文提出了一种针对视觉-语言-动作模型的物理后门攻击方法GoBA，通过在训练数据中注入物理触发器，使模型在遇到特定物理对象时执行预定义的目标导向动作，而在正常情况下表现正常。

- Motivation: 现有的VLA模型依赖未经筛选的训练数据，存在严重安全隐患。现有后门攻击大多假设白盒访问且仅导致任务失败，而非执行特定动作。本文揭示了一种更实际的威胁：攻击者可通过在训练数据中注入物理对象作为触发器来操控VLA模型。
- Method: 基于流行的VLA基准LIBERO，构建了BadLIBERO数据集，包含多样化的物理触发器和目标导向后门动作。提出三级评估方法，将受害VLA在GoBA下的动作分为三个状态：无事可做、尝试执行、成功执行。
- Result: 实验表明，当物理触发器存在时，GoBA能使受害VLA在97%的输入中成功实现后门目标，同时在干净输入上不会造成性能下降。研究发现动作轨迹和触发器颜色显著影响攻击性能，而触发器大小影响很小。
- Conclusion: GoBA攻击展示了VLA模型面临的实际安全威胁，强调了在模型训练和部署中加强安全防护的必要性。
## eess.AS

### [101] [Look before Transcription: End-to-End SlideASR with Visually-Anchored Policy Optimization](https://arxiv.org/abs/2510.08618)
*Rui Hu,Delai Qiu,Yining Wang,Shengping Liu,Jitao Sang*

Main category: eess.AS

TL;DR: 提出VAPO方法，通过视觉锚定策略优化来改进演讲幻灯片自动语音识别，解决专业术语识别问题

- Motivation: 自动语音识别系统在学术讲座等专业领域常因专业术语识别困难而表现不佳，现有方法要么复杂低效，要么退化为简单OCR系统
- Method: 提出视觉锚定策略优化(VAPO)，基于思维链推理范式，强制模型执行"先看后转录"的结构化过程，使用强化学习优化推理过程
- Result: VAPO显著提高了领域特定术语的识别准确率，建立了有效的端到端SlideASR范式
- Conclusion: VAPO方法通过结构化推理过程有效解决了SlideASR任务中的专业术语识别问题，为相关研究提供了新基准
## eess.IV

### [102] [Interlaced dynamic XCT reconstruction with spatio-temporal implicit neural representations](https://arxiv.org/abs/2510.08641)
*Mathias Boulanger,Ericmoore Jossou*

Main category: eess.IV

TL;DR: 该论文提出了一种结合时空隐式神经表示和ADMM优化的动态X射线CT重建方法，在交错采集方案下优于现有最先进方法，并展示了在噪声鲁棒性和实际应用扩展方面的优势。

- Motivation: 研究动态X射线CT在交错采集方案下的重建问题，旨在利用隐式神经表示的归纳偏置来提高重建效率和对噪声的鲁棒性。
- Method: 结合ADMM优化与INCODE条件框架，使用时空隐式神经表示，引入加权最小二乘数据保真项进行显式噪声建模。
- Result: 在所有测试场景中都表现出色，优于TIMBIR方法；对中等噪声水平具有良好的鲁棒性；在更具挑战性的噪声环境下性能显著提升。
- Conclusion: 该方法具有模块化特性，能够直接建模探测器非理想性并集成环形伪影校正，通过批量轴向切片联合优化实现了4D体积重建概念验证，为大规模数据集处理提供了并行化可能性。


### [103] [Progressive Uncertainty-Guided Evidential U-KAN for Trustworthy Medical Image Segmentation](https://arxiv.org/abs/2510.08949)
*Zhen Yang,Yansong Ma,Lei Chen*

Main category: eess.IV

TL;DR: 提出Evidential U-KAN方法，通过渐进式证据不确定性引导注意力机制和语义保持证据学习策略，提升医学图像分割的准确性和可靠性。

- Motivation: 现有证据深度学习(EDL)方法忽视利用不确定性图中的注意力线索来优化模糊边界分割，且KL正则化会抑制错误类证据，损害不确定性评估。
- Method: 提出PEUA机制渐进优化注意力并使用低秩学习去噪注意力权重；引入SAEL策略，包含语义平滑证据生成器和保真度增强正则项来保留关键语义。
- Result: 在4个数据集上的广泛实验表明，该方法在准确性和可靠性方面优于竞争方法。
- Conclusion: Evidential U-KAN为可信赖的医学图像分割提供了新颖解决方案，能有效提升分割性能。


### [104] [FS-RWKV: Leveraging Frequency Spatial-Aware RWKV for 3T-to-7T MRI Translation](https://arxiv.org/abs/2510.08951)
*Yingtie Lei,Zimeng Li,Chi-Man Pun,Yupeng Liu,Xuhang Chen*

Main category: eess.IV

TL;DR: 提出了FS-RWKV框架，用于从3T MRI合成7T质量的图像，通过频率空间全向移位和结构保真增强模块，在保持解剖细节的同时提升全局组织对比度恢复。

- Motivation: 7T MRI虽然能提供更高的空间分辨率和组织对比度，但由于设备成本和技术要求限制了临床广泛应用。从可获取的3T MRI合成7T质量图像是解决这一可及性挑战的可行方案。
- Method: 基于RWKV架构，提出FS-RWKV框架，包含两个关键模块：频率空间全向移位（FSO-Shift）进行离散小波分解和全向空间移位以增强全局上下文表示；结构保真增强块（SFEB）通过频率感知特征融合自适应强化解剖结构。
- Result: 在UNC和BNU数据集上的综合实验表明，FS-RWKV在T1w和T2w模态上均优于现有的CNN、Transformer、GAN和RWKV基线方法，实现了更优的解剖保真度和感知质量。
- Conclusion: FS-RWKV框架通过结合频率空间处理和结构增强，有效解决了3T到7T MRI图像合成的挑战，为高场强MRI的广泛临床应用提供了可行的计算替代方案。


### [105] [SAM2-3dMed: Empowering SAM2 for 3D Medical Image Segmentation](https://arxiv.org/abs/2510.08967)
*Yeqing Yang,Le Xu,Lixia Tian*

Main category: eess.IV

TL;DR: SAM2-3dMed是一个针对3D医学图像分割的改进模型，通过引入切片相对位置预测和边界检测模块，解决了SAM2在医学图像应用中的领域差距问题，在多个医学数据集上取得了优于现有方法的分割性能。

- Motivation: SAM2在视频对象分割中表现出色，但直接应用于3D医学图像存在两个领域差距：1）切片间的双向解剖连续性vs视频的单向时间流；2）医学图像需要精确的边界分割，而视频任务对此关注不足。
- Method: 提出SAM2-3dMed框架，包含两个关键创新：1）切片相对位置预测模块，通过自监督方式建模切片间的双向依赖关系；2）边界检测模块，增强关键器官和组织边界的分割精度。
- Result: 在医学分割十项全能数据集中的肺、脾和胰腺三个不同医学数据集上的广泛实验表明，SAM2-3dMed显著优于最先进方法，在分割重叠和边界精度方面都取得了优越性能。
- Conclusion: 该方法不仅提升了3D医学图像分割性能，还为将视频中心的基础模型适应到空间体积数据提供了一般性范例。


### [106] [Rewiring Development in Brain Segmentation: Leveraging Adult Brain Priors for Enhancing Infant MRI Segmentation](https://arxiv.org/abs/2510.09306)
*Alemu Sisay Nigru,Michele Svanera,Austin Dibble,Connor Dalby,Mattia Savardi,Sergio Benini*

Main category: eess.IV

TL;DR: LODi框架利用成人脑MRI分割模型的先验知识，通过迁移学习和领域自适应策略，提升婴儿脑MRI分割性能，实现快速、准确、年龄自适应的分割。

- Motivation: 婴儿脑MRI分割面临解剖结构持续变化、运动伪影和高质量标注数据稀缺等挑战，而成人脑MRI数据丰富，可作为先验知识来源。
- Method: 在大型成人数据集上预训练分割模型，通过弱监督学习使用FreeSurfer生成的银标准标签，结合层次特征精炼和多级一致性约束进行领域自适应。
- Result: 在内部和外部数据集上的广泛实验表明，该方法优于传统监督学习和领域特定模型。
- Conclusion: 利用成人脑先验作为基础，可实现跨生命周期的更可靠、可泛化的脑MRI分割。


### [107] [A Biophysically-Conditioned Generative Framework for 3D Brain Tumor MRI Synthesis](https://arxiv.org/abs/2510.09365)
*Valentin Biller,Lucas Zimmer,Can Erdur,Sandeep Nagar,Daniel Rückert,Niklas Bubeck,Jonas Weidner*

Main category: eess.IV

TL;DR: 提出了首个基于体素级连续肿瘤浓度的生成模型，用于合成高质量脑肿瘤MRI图像，并应用于BraTS 2025修复挑战中的健康组织恢复任务。

- Motivation: 磁共振成像修复支持众多临床和研究应用，需要能够生成空间一致且解剖学准确的图像。
- Method: 使用基于组织分割和肿瘤浓度的潜在扩散模型，通过将肿瘤浓度设为零来适应健康组织修复任务。
- Result: 健康组织修复的PSNR为18.5，肿瘤修复的PSNR为17.4，生成了3D空间一致且解剖学一致的图像。
- Conclusion: 该模型在脑肿瘤MRI合成和健康组织修复方面都表现出色，能够生成高质量且解剖学准确的图像。
## cs.GR

### [108] [Generating Sizing Fields for Mesh Generation via GCN-based Simplification of Adaptive Background Grids](https://arxiv.org/abs/2510.08645)
*Xunyang Zhu,Hongfei Ye,Yifei Wang,Taoran Liu,Jianjun Chen*

Main category: cs.GR

TL;DR: 提出基于图卷积网络的自适应背景网格简化框架，通过边分数回归预测最优边折叠候选，显著减少网格元素数量并提升尺寸场查询效率

- Motivation: 传统背景网格在几何贴合、计算轻量和避免伪影方面存在挑战，需要一种高效简化方法
- Method: 使用图卷积网络将网格简化任务重新定义为边分数回归问题，通过自定义损失函数同时考虑几何保真度和尺寸场精度
- Result: 简化后背景网格元素减少74%-94%，尺寸场查询时间降低35%-88%
- Conclusion: 该数据驱动方法有效替代了昂贵的程序化评估，在复杂工程模型中展现出良好效果


### [109] [A 3D Generation Framework from Cross Modality to Parameterized Primitive](https://arxiv.org/abs/2510.08656)
*Yiming Liang,Huan Yu,Zili Wang,Shuyou Zhang,Guodong Yi,Jin Wang,Jianrong Tan*

Main category: cs.GR

TL;DR: 提出了一种基于参数化基元的多阶段3D模型生成框架，通过文本和图像输入指导生成，能够生成光滑表面模型并显著减少存储开销。

- Motivation: 当前AI驱动的3D模型生成虽然利用了跨模态技术，但在生成光滑表面模型和减少存储开销方面仍面临挑战。
- Method: 采用多阶段框架，包括基于参数化基元的模型生成算法，识别模型组成元素的形状特征并用高质量表面的参数化基元替换；同时提出相应的模型存储方法，仅保留基元参数。
- Result: 在虚拟场景和真实场景数据集上的实验显示，该方法取得了Chamfer距离0.003092、VIoU 0.545、F1分数0.9139和NC 0.8369的优异性能，基元参数文件大小约为6KB。
- Conclusion: 该方法特别适用于简单模型的快速原型制作，在保持模型表面质量的同时显著减少了存储需求。
## cs.AI

### [110] [Unified World Models: Memory-Augmented Planning and Foresight for Visual Navigation](https://arxiv.org/abs/2510.08713)
*Yifei Dong,Fengyi Wu,Guangyu Chen,Zhi-Qi Cheng,Qiyu Hu,Yuxuan Zhou,Jingdong Sun,Jun-Yan He,Qi Dai,Alexander G Hauptmann*

Main category: cs.AI

TL;DR: UniWM是一个统一的世界模型，通过整合视觉预测和规划来解决视觉导航中的状态-动作不对齐问题，显著提升了导航性能。

- Motivation: 现有模块化架构将导航规划与视觉世界建模分离，导致状态-动作不对齐，在动态场景中适应性有限。需要统一框架来紧密对齐预测与控制。
- Method: 提出UniWM统一记忆增强世界模型，在单一多模态自回归主干中整合自我中心视觉预测和规划。采用分层记忆机制结合短期感知线索和长期轨迹上下文。
- Result: 在四个基准测试中导航成功率提升高达30%，轨迹误差显著降低，在TartanDrive数据集上表现出优异的零样本泛化能力。
- Conclusion: UniWM是实现统一、想象力驱动的具身导航的重要进展，证明了视觉预测与规划统一框架的有效性。


### [111] [Auto-scaling Continuous Memory for GUI Agent](https://arxiv.org/abs/2510.09038)
*Wenyi Wu,Kun Zhou,Ruoxin Yuan,Vivian Yu,Stephen Wang,Zhiting Hu,Biwei Huang*

Main category: cs.AI

TL;DR: 提出了一种连续记忆机制，用于增强GUI代理在陌生界面和长任务中的泛化能力，通过固定长度的连续嵌入编码轨迹，显著降低上下文成本并保留视觉细节。

- Motivation: 现有GUI代理将历史轨迹压缩为文本标记，导致上下文长度膨胀且丢失关键视觉线索（如控件大小和位置），需要更高效的记忆机制。
- Method: 使用VLM作为编码器将GUI轨迹编码为固定长度的连续嵌入，直接输入到主干网络；采用自动扩展数据飞轮收集训练数据，仅微调记忆编码器（1.2%参数）。
- Result: 随着记忆大小和检索深度的增加，性能单调提升；在真实GUI基准测试中，长任务和分布偏移下的成功率持续改善；Qwen-2.5-VL-7B+连续记忆达到与GPT-4o、Claude-4等闭源模型相当的性能。
- Conclusion: 连续记忆机制能有效提升GUI代理的泛化能力，以较低成本实现与顶级闭源模型竞争的性能，为GUI自动化提供了可扩展的解决方案。


### [112] [OSCAR: Orthogonal Stochastic Control for Alignment-Respecting Diversity in Flow Matching](https://arxiv.org/abs/2510.09060)
*Jingxuan Wu,Zhenglin Wan,Xingrui Yu,Yuzhe Yang,Bo An,Ivor Tsang*

Main category: cs.AI

TL;DR: 提出了一种无需训练、在推理时控制流式文本到图像模型的方法，通过特征空间目标和正交随机扰动来增加生成多样性，同时保持图像质量和提示对齐。

- Motivation: 流式文本到图像模型遵循确定性轨迹，用户需要重复采样才能发现多样模式，这个过程成本高且效率低下。
- Method: 使用特征空间目标鼓励轨迹间的横向扩展，并通过时间调度的随机扰动重新引入不确定性。关键的是，该扰动被投影为与生成流正交，从而在不降低图像细节或提示保真度的情况下增加变化。
- Result: 在固定采样预算下，该方法在多个文本到图像设置中持续改进了多样性指标（如Vendi Score和Brisque），同时保持了图像质量和对齐度。
- Conclusion: 该方法提供了一种原则性的解释，说明为什么生成质量能够稳健地保持，同时显著提高生成多样性。
## cs.CL

### [113] [Identifying & Interactively Refining Ambiguous User Goals for Data Visualization Code Generation](https://arxiv.org/abs/2510.09390)
*Mert İnan,Anthony Sicilia,Alex Xie,Saujas Vaduguru,Daniel Fried,Malihe Alikhani*

Main category: cs.CL

TL;DR: 本文研究人机通信中目标共享时的歧义问题，特别关注数据可视化领域。作者开发了歧义类型分类法并提出量化指标，证明多轮对话能减少歧义并提高代码准确性。

- Motivation: 人机通信中建立共享目标时，自然语言的歧义会导致看似正确但不符合用户意图的输出，这在数据可视化代码生成中尤为明显。
- Method: 开发歧义类型分类法和量化指标，使用DS-1000数据集的Matplotlib问题，评估三种语用模型（Gricean合作原则、话语表征理论、问题讨论）的多轮对话策略。
- Result: 歧义指标比不确定性基线更符合人工标注，多轮对话能显著减少歧义并提高代码准确性。
- Conclusion: 多轮对话能有效减少人机通信中的歧义，提高代码生成与用户目标的匹配度，语用模型为对话策略提供了有效指导。


### [114] [Dyna-Mind: Learning to Simulate from Experience for Better AI Agents](https://arxiv.org/abs/2510.09577)
*Xiao Yu,Baolin Peng,Michel Galley,Hao Cheng,Qianhui Wu,Janardhan Kulkarni,Suman Nath,Zhou Yu,Jianfeng Gao*

Main category: cs.CL

TL;DR: Dyna-Mind是一个两阶段训练框架，通过模拟未来状态来增强AI代理在复杂交互环境中的推理和决策能力。第一阶段ReSim训练代理从真实经验生成结构化推理轨迹，第二阶段Dyna-GRPO使用结果奖励和中间状态反馈来强化模拟和决策能力。

- Motivation: 当前AI代理在数学和编程方面表现出专家级能力，但在长视野交互任务中表现不佳。受人类认知启发，需要让AI代理具备"替代性试错"能力，即行动前进行心理模拟，以提升在复杂交互环境中的理解和表现。
- Method: 提出Dyna-Mind两阶段框架：1) ReSim：从环境交互收集的真实经验构建扩展搜索树，训练代理生成结构化推理轨迹；2) Dyna-GRPO：在线强化学习方法，使用结果奖励和中间状态作为反馈来加强模拟和决策能力。
- Result: 在Sokoban、ALFWorld和AndroidWorld三个基准测试上的实验表明：1) ReSim有效为AI代理注入模拟能力；2) Dyna-GRPO利用结果和交互级信号学习更好的长视野规划密集型任务策略。
- Conclusion: 模拟在使AI代理在日益挑战的环境中更有效地推理、规划和行动方面发挥着核心作用。
