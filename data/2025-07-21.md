[[toc]]

## cs.CV

### [1] [Open-Vocabulary Object Detection in UAV Imagery: A Review and Future Perspectives](https://arxiv.org/abs/2507.13359)
*Yang Zhou,Junjie Li,CongYang Ou,Dawei Yan,Haokui Zhang,Xizhe Xue*

Main category: cs.CV

TL;DR: 该论文综述了无人机航拍场景中的开放词汇目标检测（OVOD），探讨了其核心原理、方法分类、数据集及未来研究方向。

- Motivation: 传统无人机目标检测方法局限于预定义类别，而跨模态文本-图像对齐技术（如CLIP）推动了开放词汇检测的发展，提升了无人机在航拍场景中的智能性和自主性。
- Method: 论文通过系统分类现有OVOD方法，并结合无人机视觉特点，构建了一个全面的综述框架。
- Result: 论文总结了OVOD在无人机航拍中的应用现状、关键挑战及未来发展方向。
- Conclusion: 该综述为研究人员提供了清晰的路线图和参考，促进了这一快速发展的领域的创新。


### [2] [Low-Light Enhancement via Encoder-Decoder Network with Illumination Guidance](https://arxiv.org/abs/2507.13360)
*Le-Anh Tran,Chung Nguyen Tran,Ngoc-Luu Nguyen,Nhan Cach Dang,Jordi Carrabina,David Castells-Rufas,Minh Son Nguyen*

Main category: cs.CV

TL;DR: EDNIG是一种基于U-Net的新型深度学习框架，用于低光图像增强，通过亮度引导和SPP模块提升性能，并在GAN框架中优化。

- Motivation: 解决低光图像增强问题，通过亮度引导和上下文特征提取提升模型性能。
- Method: 结合U-Net架构，引入亮度图和SPP模块，使用Swish激活函数，并在GAN框架中优化。
- Result: 在定量指标和视觉质量上优于现有方法，同时模型复杂度较低。
- Conclusion: EDNIG适用于实际应用，性能优越且高效。


### [3] [VLMs have Tunnel Vision: Evaluating Nonlocal Visual Reasoning in Leading VLMs](https://arxiv.org/abs/2507.13361)
*Shmuel Berman,Jia Deng*

Main category: cs.CV

TL;DR: 研究发现，尽管视觉语言模型（VLMs）在复杂视觉任务上表现出色，但在非局部视觉推理任务中表现不佳，甚至接近随机准确率。

- Motivation: 评估VLMs在非局部视觉推理任务中的能力，以揭示其核心视觉推理能力的不足。
- Method: 设计了三种非局部视觉任务（比较感知、扫视搜索和平滑视觉搜索），测试主流模型（如Gemini 2.5 Pro、Claude Vision 3.7、GPT-o4-mini）的表现。
- Result: 即使在这些对人类来说简单的任务上，主流模型的表现也仅略高于随机准确率。
- Conclusion: 当前模型在原始视觉敏锐度上有进步，但仍缺乏核心视觉推理能力。


### [4] [Enhancing Spatial Reasoning in Vision-Language Models via Chain-of-Thought Prompting and Reinforcement Learning](https://arxiv.org/abs/2507.13362)
*Binbin Ji,Siddharth Agrawal,Qiance Tang,Yvonne Wu*

Main category: cs.CV

TL;DR: 研究探讨了视觉语言模型（VLMs）的空间推理能力，通过Chain-of-Thought（CoT）提示和强化学习优化性能。发现结构化多阶段提示（SceneGraph CoT）显著提升准确性，而简单CoT可能损害性能。使用GRPO强化学习方法在SAT数据集上微调模型，表现优于监督微调（SFT），尤其在OOD条件下更稳健。

- Motivation: 探索如何通过提示策略和强化学习提升VLMs的空间推理能力，解决现有方法（如SFT）在泛化和鲁棒性上的不足。
- Method: 1. 评估不同CoT提示策略的效果；2. 提出SceneGraph CoT结构化提示方法；3. 使用GRPO强化学习方法在SAT数据集上微调模型，并在CVBench上评估。
- Result: SceneGraph CoT显著提升空间推理准确性；GRPO在Pass@1评估中优于SFT，且在OOD条件下表现更稳健，避免了SFT因语言模式过拟合导致的性能下降。
- Conclusion: 结构化提示和强化学习（GRPO）能有效提升VLMs的空间推理能力和泛化性能，为未来研究提供了实用方法。代码已开源。


### [5] [Just Add Geometry: Gradient-Free Open-Vocabulary 3D Detection Without Human-in-the-Loop](https://arxiv.org/abs/2507.13363)
*Atharv Goel,Mehar Khurana*

Main category: cs.CV

TL;DR: 利用2D视觉语言模型进行开放词汇3D物体检测，无需人工标注3D标签，通过几何策略推断3D边界框，并在多种输入条件下实现竞争性性能。

- Motivation: 现有3D物体检测数据集受限于狭窄的类别分类和昂贵的人工标注，难以适应开放世界场景。2D视觉语言模型具有丰富的语义理解和开放词汇检测能力，可用于解决这一问题。
- Method: 使用2D视觉语言检测器生成文本条件提案，通过SAM分割并利用相机几何和LiDAR或单目伪深度反投影到3D空间。引入基于DBSCAN聚类和Rotating Calipers的几何膨胀策略推断3D边界框。
- Result: 在LiDAR和RGB-D输入等多种设置下，方法实现了竞争性的定位性能，且无需训练并支持开放词汇。
- Conclusion: 展示了2D基础模型在可扩展3D感知中的潜力，为开放世界3D检测提供了新思路。


### [6] [OmniVec2 -- A Novel Transformer based Network for Large Scale Multimodal and Multitask Learning](https://arxiv.org/abs/2507.13364)
*Siddharth Srivastava,Gaurav Sharma*

Main category: cs.CV

TL;DR: 提出了一种新颖的多模态多任务网络及训练算法，支持12种模态数据输入，通过共享Transformer架构和跨模态注意力机制实现统一嵌入空间，并在25个数据集上取得先进性能。

- Motivation: 解决多模态和多任务场景下的数据融合与任务协同问题，提升模型在多样化数据上的表现。
- Method: 采用模态专用分词器、共享Transformer架构和跨注意力机制，提出迭代模态切换预训练策略和模态对训练算法。
- Result: 在12种模态的25个数据集上实现先进性能，验证了架构、预训练策略和多任务训练的有效性。
- Conclusion: 该方法在多模态多任务场景中表现出色，为复杂数据融合和任务协同提供了有效解决方案。


### [7] [Transformer-Based Framework for Motion Capture Denoising and Anomaly Detection in Medical Rehabilitation](https://arxiv.org/abs/2507.13371)
*Yeming Cai,Yang Wang,Zhenglin Li*

Main category: cs.CV

TL;DR: 提出了一种基于Transformer的端到端深度学习框架，用于增强医疗康复，通过处理噪声和缺失数据，实时检测异常动作。

- Motivation: 解决因遮挡和环境因素导致的数据噪声和缺失问题，同时确保患者安全。
- Method: 结合光学运动捕捉和Transformer模型，利用时间序列建模去噪和补全数据。
- Result: 在卒中和骨科康复数据集上表现出优异的数据重建和异常检测性能。
- Conclusion: 提供了一种可扩展、经济高效的远程康复解决方案，减少现场监督需求。


### [8] [Enhancing Breast Cancer Detection with Vision Transformers and Graph Neural Networks](https://arxiv.org/abs/2507.13372)
*Yeming Cai,Zhenglin Li,Yang Wang*

Main category: cs.CV

TL;DR: 本文提出了一种结合Vision Transformers和Graph Neural Networks的创新框架，用于提升乳腺癌检测的准确性，在CBIS-DDSM数据集上达到84.2%的准确率。

- Motivation: 乳腺癌是全球女性死亡的主要原因，早期检测对提高生存率至关重要。
- Method: 整合Vision Transformers（ViT）和Graph Neural Networks（GNN），利用ViT捕捉全局图像特征和GNN建模结构关系的能力。
- Result: 在CBIS-DDSM数据集上实现了84.2%的准确率，优于传统方法。
- Conclusion: 该框架不仅提高了检测准确性，还通过可解释的注意力热图辅助临床决策。


### [9] [Butter: Frequency Consistency and Hierarchical Fusion for Autonomous Driving Object Detection](https://arxiv.org/abs/2507.13373)
*Xiaojian Lin,Wenxin Zhang,Yuchu Jiang,Wangyu Wu,Yiran Guo,Kangxu Wang,Zongzheng Zhang,Guijin Wang,Lei Jin,Hao Zhao*

Main category: cs.CV

TL;DR: Butter是一种新型目标检测框架，通过增强分层特征表示提升检测鲁棒性，引入FAFCE和PHFFNet模块，显著提高了检测精度并降低了模型复杂度。

- Motivation: 现有架构（如YOLO和DETR）在动态环境中难以保持多尺度特征一致性，且难以平衡检测精度与计算效率。
- Method: Butter提出FAFCE组件（自适应频率滤波增强特征一致性）和PHFFNet模块（渐进式分层特征融合），优化多尺度特征表示。
- Result: 在BDD100K、KITTI和Cityscapes数据集上，Butter表现出卓越的特征表示能力，显著提升检测精度并降低复杂度。
- Conclusion: Butter通过分层特征优化与融合，在实时自动驾驶场景中实现了精度、可部署性和计算效率的平衡。


### [10] [Smart Routing for Multimodal Video Retrieval: When to Search What](https://arxiv.org/abs/2507.13374)
*Kevin Dela Rosa*

Main category: cs.CV

TL;DR: ModaRoute是一个基于LLM的智能路由系统，通过动态选择多模态视频检索的最优模态，减少计算开销并保持高效检索。

- Motivation: 传统密集文本标注需要昂贵的离线处理且会遗漏关键视觉信息，因此需要一种更高效的解决方案。
- Method: 利用GPT-4.1分析查询意图并预测信息需求，动态路由查询到ASR、OCR和视觉索引。
- Result: 计算开销减少41%，Recall@5达到60.9%，平均每查询使用1.78种模态。
- Conclusion: 智能路由为多模态检索系统提供了一种实用且经济的解决方案。


### [11] [A Comprehensive Survey for Real-World Industrial Defect Detection: Challenges, Approaches, and Prospects](https://arxiv.org/abs/2507.13378)
*Yuqi Cheng,Yunkang Cao,Haiming Yao,Wei Luo,Cheng Jiang,Hui Zhang,Weiming Shen*

Main category: cs.CV

TL;DR: 该论文综述了工业缺陷检测的现状，重点分析了从封闭集到开放集检测方法的转变，并探讨了2D和3D模态下的挑战与趋势。

- Motivation: 传统检测方法难以满足现代制造业对精度、自动化和可扩展性的需求，而计算机视觉和深度学习的进步为缺陷检测提供了新思路。
- Method: 通过深入分析封闭集和开放集缺陷检测策略，结合2D和3D模态，梳理其近年来的发展。
- Result: 开放集检测方法逐渐成为主流，减少了对大量缺陷标注的依赖，并能识别新型异常。
- Conclusion: 论文提供了工业缺陷检测领域的全面视角，指出了未来研究方向和应用潜力。


### [12] [Using Multiple Input Modalities Can Improve Data-Efficiency and O.O.D. Generalization for ML with Satellite Imagery](https://arxiv.org/abs/2507.13385)
*Arjun Rao,Esther Rolf*

Main category: cs.CV

TL;DR: 论文探讨了在卫星图像机器学习（SatML）中结合其他地理数据层对模型性能的影响，发现多模态输入能显著提升性能，尤其在数据有限和跨区域场景下。

- Motivation: 现有SatML模型主要依赖光学图像输入，但其他地理数据层（如高程模型、传感器数据）可能提供额外价值，研究旨在验证这一点。
- Method: 通过为SatML基准任务生成增强数据集（添加其他地理数据层），评估多模态输入在分类、回归和分割任务中的效果。
- Result: 多模态输入显著提升模型性能，尤其在数据有限和跨区域测试中；硬编码融合策略优于学习融合方法。
- Conclusion: 多模态输入可提高SatML的数据效率和泛化能力，硬编码融合策略值得进一步研究。


### [13] [Minimalist Concept Erasure in Generative Models](https://arxiv.org/abs/2507.13386)
*Yang Zhang,Er Jin,Yanfei Dong,Yixuan Wu,Philip Torr,Ashkan Khakzar,Johannes Stegmaier,Kenji Kawaguchi*

Main category: cs.CV

TL;DR: 提出了一种基于生成输出分布距离的最小化概念擦除方法，通过端到端优化和神经元掩码提升擦除鲁棒性，同时保持模型性能。

- Motivation: 生成模型依赖大规模无标注数据引发安全和版权问题，现有擦除方法过度修改模型影响其效用。
- Method: 基于生成输出分布距离设计目标函数，通过端到端反向传播优化，引入神经元掩码替代微调。
- Result: 在流匹配模型上验证，方法能鲁棒擦除概念且不损害模型性能。
- Conclusion: 为更安全、负责任的生成模型提供了可行方案。


### [14] [From Binary to Semantic: Utilizing Large-Scale Binary Occupancy Data for 3D Semantic Occupancy Prediction](https://arxiv.org/abs/2507.13387)
*Chihiro Noguchi,Takaki Yamamoto*

Main category: cs.CV

TL;DR: 论文提出了一种利用大规模二进制占用数据的方法，通过分解预测过程为二进制和语义占用模块，提升了3D语义占用预测的性能。

- Motivation: 在视觉为中心的自动驾驶系统中，3D语义占用预测需要昂贵的LiDAR标注数据，而二进制占用数据成本较低但未被充分利用。
- Method: 提出了一种基于二进制占用的框架，将预测过程分解为二进制和语义占用模块，利用二进制数据进行预训练和学习自动标注。
- Result: 实验表明，该方法在预训练和自动标注任务中优于现有方法，显著提升了3D语义占用预测的效果。
- Conclusion: 该框架有效利用了低成本二进制占用数据，为3D语义占用预测提供了新的解决方案。


### [15] [InSyn: Modeling Complex Interactions for Pedestrian Trajectory Prediction](https://arxiv.org/abs/2507.13397)
*Kaiyuan Zhai,Juan Chen,Chao Wang,Zeyi Xu*

Main category: cs.CV

TL;DR: 提出了一种基于Transformer的模型InSyn，用于行人轨迹预测，通过显式捕捉多样化的交互模式（如同步或冲突）和改进初始步预测误差。

- Motivation: 现有方法主要依赖相对位置建模行人交互，但忽略了特定交互模式（如配对行走或冲突行为），导致在拥挤场景中预测精度受限。
- Method: 提出InSyn模型，结合Transformer架构显式捕捉多样化交互模式，并引入SSOS训练策略以减少初始步预测误差。
- Result: 在ETH和UCY数据集上表现优于基线模型，尤其在高密度场景中，SSOS策略将初始步预测误差降低约6.58%。
- Conclusion: InSyn模型通过显式建模交互模式和SSOS策略，显著提升了行人轨迹预测的准确性。


### [16] [MADI: Masking-Augmented Diffusion with Inference-Time Scaling for Visual Editing](https://arxiv.org/abs/2507.13401)
*Shreya Kadambi,Risheek Garrepalli,Shubhankar Borse,Munawar Hyatt,Fatih Porikli*

Main category: cs.CV

TL;DR: MADI框架通过Masking-Augmented gaussian Diffusion（MAgD）和推理时容量扩展机制，显著提升了扩散模型的可编辑性和可控性。

- Motivation: 尽管扩散模型在文本到图像生成中表现出色，但在结构化视觉编辑和组合控制方面仍面临挑战。
- Method: 提出MADI框架，包括MAgD训练策略（结合去噪和掩码重建）和推理时Pause Tokens机制。
- Result: MADI显著提升了扩散模型的编辑能力和组合性，尤其在密集提示下表现更优。
- Conclusion: MADI为扩散模型在通用生成架构中的应用铺平了道路。


### [17] [UL-DD: A Multimodal Drowsiness Dataset Using Video, Biometric Signals, and Behavioral Data](https://arxiv.org/abs/2507.13403)
*Morteza Bodaghi,Majid Hosseini,Raju Gottumukkala,Ravi Teja Bhupatiraju,Iftikhar Ahmad,Moncef Gabbouj*

Main category: cs.CV

TL;DR: 该研究提供了一个多模态的驾驶员疲劳检测数据集，包含面部、行为和生物特征信号，旨在更全面地捕捉疲劳状态的变化。

- Motivation: 现有数据集通常只关注离散的疲劳标签，缺乏连续状态变化的记录。本研究旨在填补这一空白，提供更全面的多模态数据。
- Method: 数据集整合了3D面部视频、红外摄像、后视视频、生物特征信号（如心率、皮肤电活动等）以及方向盘握力数据和模拟器遥测数据。数据采集自19名受试者，每次持续40分钟。
- Result: 数据集总时长1,400分钟，记录了从警觉到疲劳的连续状态变化，而非离散标签。
- Conclusion: 该数据集为疲劳检测研究提供了更全面的多模态资源，未来可支持更精确的模型开发。


### [18] [AortaDiff: Volume-Guided Conditional Diffusion Models for Multi-Branch Aortic Surface Generation](https://arxiv.org/abs/2507.13404)
*Delin An,Pan Du,Jian-Xun Wang,Chaoli Wang*

Main category: cs.CV

TL;DR: AortaDiff是一种基于扩散的框架，直接从CT/MRI体积生成平滑的主动脉表面，解决了现有方法依赖大数据集和手动干预的问题，适用于CFD分析。

- Motivation: 准确的3D主动脉构建对临床诊断和CFD模拟至关重要，但现有方法依赖大数据集和手动干预，生成的网格几何一致性差。
- Method: AortaDiff使用体积引导的条件扩散模型生成主动脉中心线，自动提取血管轮廓并拟合为平滑3D表面。
- Result: 实验表明，AortaDiff在有限训练数据下有效，能构建正常和病理主动脉网格，几何保真度高。
- Conclusion: AortaDiff是一种端到端、低依赖大数据集的实用解决方案，适用于心血管研究。


### [19] [COREVQA: A Crowd Observation and Reasoning Entailment Visual Question Answering Benchmark](https://arxiv.org/abs/2507.13405)
*Ishant Chintapatla,Kazuma Choji,Naaisha Agarwal,Andrew Lin,Hannah You,Charles Duong,Kevin Zhu,Sean O'Brien,Vasu Sharma*

Main category: cs.CV

TL;DR: COREVQA是一个新的视觉蕴含基准测试，用于评估视觉语言模型在拥挤场景中的推理能力，结果显示当前模型表现不佳。

- Motivation: 现有视觉问答基准测试很少评估模型在视觉蕴含任务（如基于图像接受或反驳假设）中的能力。
- Method: 提出了COREVQA基准测试，包含5608张图像和合成的真/假陈述对，图像来自CrowdHuman数据集。
- Result: 即使表现最好的视觉语言模型准确率也低于80%，其他模型表现更差（39.98%-69.95%）。
- Conclusion: 当前视觉语言模型在拥挤场景中的视觉蕴含推理能力存在显著局限性。


### [20] [IConMark: Robust Interpretable Concept-Based Watermark For AI Images](https://arxiv.org/abs/2507.13407)
*Vinu Sankar Sadasivan,Mehrdad Saberi,Soheil Feizi*

Main category: cs.CV

TL;DR: IConMark是一种新型的语义水印方法，通过嵌入可解释的概念到AI生成的图像中，提高水印的鲁棒性和可读性，优于传统方法。

- Motivation: 随着生成式AI和合成媒体的快速发展，区分AI生成图像与真实图像对防止错误信息和确保数字真实性至关重要。传统水印技术易受对抗攻击，效果有限。
- Method: IConMark通过在AI生成图像中嵌入有意义的语义属性，而非噪声或扰动，实现可解释的水印。该方法还结合了StegaStamp和TrustMark，形成混合方法IConMark+SS和IConMark+TM。
- Result: IConMark及其变体在检测准确性和图像质量保持上表现优越，AUROC分数分别比最佳基线高出10.8%、14.5%和15.9%。
- Conclusion: IConMark为可解释水印技术提供了新方向，其鲁棒性和可读性使其成为对抗图像操纵的有效工具。


### [21] [A Deep Learning-Based Ensemble System for Automated Shoulder Fracture Detection in Clinical Radiographs](https://arxiv.org/abs/2507.13408)
*Hemanth Kumar M,Karthika M,Saianiruth M,Vasanthakumar Venugopal,Anandakumar D,Revathi Ezhumalai,Charulatha K,Kishore Kumar J,Dayana G,Kalyan Sivasailam,Bargava Subramanian*

Main category: cs.CV

TL;DR: AI驱动的多模型深度学习系统通过集成技术显著提高了肩部骨折的检测准确率，达到95.5%，适用于临床快速筛查。

- Motivation: 解决肩部骨折在急诊和高流量临床环境中漏诊率高的问题，利用AI技术提供早期检测支持。
- Method: 开发基于10,000张标注肩部X光片的多模型深度学习系统，采用Faster R-CNN、EfficientDet和RF-DETR架构，并应用Soft-NMS、WBF和NMW融合等集成技术。
- Result: NMW集成模型表现最佳，准确率达95.5%，F1分数为0.9610，召回率和定位精度均较高。
- Conclusion: 集成AI模型能可靠检测肩部骨折，适合实时诊断工作流，但仅限于二元骨折检测，设计用于快速筛查而非详细分类。


### [22] [AI-ming backwards: Vanishing archaeological landscapes in Mesopotamia and automatic detection of sites on CORONA imagery](https://arxiv.org/abs/2507.13420)
*Alessandro Pistola,Valentina Orru',Nicolo' Marchetti,Marco Roccetti*

Main category: cs.CV

TL;DR: 通过结合古老的CORONA卫星影像升级深度学习模型，显著提升了考古遗址自动识别的精度，并发现了四个新遗址。

- Motivation: 利用CORONA卫星影像改进AI模型，以识别因人为活动而消失的考古遗址。
- Method: 在Bing卷积网络模型基础上，使用CORONA影像对伊拉克阿布格莱布地区进行重新训练。
- Result: 检测精度显著提升（IoU超过85%，总体准确率达90%），并发现四个新遗址。
- Conclusion: AI技术与CORONA影像结合，为考古遗址识别提供了突破性进展。


### [23] [CaSTFormer: Causal Spatio-Temporal Transformer for Driving Intention Prediction](https://arxiv.org/abs/2507.13425)
*Sirui Wang,Zhou Guan,Bingxi Zhao,Tongjia Gu*

Main category: cs.CV

TL;DR: CaSTFormer是一种因果时空变换器，用于建模驾驶员行为与环境间的因果关系，提升驾驶意图预测的准确性和透明度。

- Motivation: 当前方法难以准确建模复杂的时空依赖性和人类驾驶行为的不可预测性，需要更鲁棒的预测模型。
- Method: 提出CaSTFormer，包含Reciprocal Shift Fusion（RSF）机制、Causal Pattern Extraction（CPE）模块和Feature Synthesis Network（FSN）。
- Result: 在Brain4Cars数据集上达到最先进性能，有效捕捉复杂因果时空依赖。
- Conclusion: CaSTFormer显著提升了驾驶意图预测的准确性和透明度。


### [24] ["PhyWorldBench": A Comprehensive Evaluation of Physical Realism in Text-to-Video Models](https://arxiv.org/abs/2507.13428)
*Jing Gu,Xian Liu,Yu Zeng,Ashwin Nagarajan,Fangrui Zhu,Daniel Hong,Yue Fan,Qianqi Yan,Kaiwen Zhou,Ming-Yu Liu,Xin Eric Wang*

Main category: cs.CV

TL;DR: PhyWorldBench是一个评估视频生成模型物理模拟能力的基准，涵盖从基础物理现象到复杂场景，并引入“反物理”类别。通过人类评估和MLLM方法测试12个先进模型，发现其在遵循物理规律上的挑战。

- Motivation: 视频生成模型在物理现象模拟方面存在不足，需要系统评估其物理一致性。
- Method: 设计PhyWorldBench基准，包含多级物理现象和“反物理”类别，结合人类评估和MLLM方法测试12个模型。
- Result: 模型在物理模拟上存在显著挑战，特别是在复杂和反物理场景中表现不佳。
- Conclusion: 研究为提升视频生成模型的物理一致性提供了基准和建议，未来需进一步优化模型能力。


### [25] [Uncertainty Quantification Framework for Aerial and UAV Photogrammetry through Error Propagation](https://arxiv.org/abs/2507.13486)
*Debao Huang,Rongjun Qin*

Main category: cs.CV

TL;DR: 提出了一种用于摄影测量点云不确定性量化的框架，通过误差协方差矩阵为每个点提供精度认证，解决了多视角立体（MVS）阶段的不确定性估计问题。

- Motivation: 摄影测量点云的精度高度依赖场景，且MVS阶段的不确定性估计尚未标准化，需要一种自监督且符合误差传播路径的方法。
- Method: 提出了一种自校准方法，利用可靠的n视点（n≥6）和MVS阶段的相关线索（如匹配成本值）回归视差不确定性。
- Result: 在多种公开数据集上验证，方法优于现有方法，实现了高边界率且未高估不确定性。
- Conclusion: 该框架为摄影测量点云提供了鲁棒且可认证的不确定性量化，适用于多样化场景。


### [26] [Sugar-Beet Stress Detection using Satellite Image Time Series](https://arxiv.org/abs/2507.13514)
*Bhumika Laxman Sadbhave,Philipp Vaeth,Denise Dejon,Gunther Schorcht,Magda Gregorová*

Main category: cs.CV

TL;DR: 本文提出了一种基于3D卷积自编码器的无监督方法，用于从Sentinel-2卫星图像时间序列中检测甜菜田的胁迫情况。

- Motivation: 卫星图像时间序列（SITS）数据因其丰富的频谱和时间特性，在农业任务中表现优异。本研究旨在通过无监督方法解决甜菜田胁迫检测问题。
- Method: 采用3D卷积自编码器模型提取Sentinel-2图像序列的特征，并结合特定采集日期的时间编码以捕捉甜菜生长动态。
- Result: 学习到的特征用于下游聚类任务，区分胁迫与健康田块。该系统可直接应用于不同年份的数据。
- Conclusion: 该方法为甜菜田胁迫检测提供了一种实用且易用的工具。


### [27] [SparseC-AFM: a deep learning method for fast and accurate characterization of MoS$_2$ with C-AFM](https://arxiv.org/abs/2507.13527)
*Levi Harris,Md Jayed Hossain,Mufan Qiu,Ruichen Zhang,Pingchuan Ma,Tianlong Chen,Jiaqi Gu,Seth Ariel Tongay,Umberto Celano*

Main category: cs.CV

TL;DR: SparseC-AFM是一种深度学习模型，通过稀疏C-AFM扫描快速重建2D材料的导电性图，显著减少数据采集时间。

- Motivation: 解决传统C-AFM技术因扫描速度慢而难以满足大规模生产需求的问题。
- Method: 利用深度学习模型SparseC-AFM从稀疏扫描数据中重建高分辨率导电性图。
- Result: 实现11倍以上的采集时间减少，且模型预测结果与传统高分辨率扫描数据相似。
- Conclusion: SparseC-AFM为2D材料的工业级表征提供了高效解决方案。


### [28] [Total Generalized Variation of the Normal Vector Field and Applications to Mesh Denoising](https://arxiv.org/abs/2507.13530)
*Lukas Baumgärtner,Ronny Bergmann,Roland Herzog,Stephan Schmidt,Manuel Weiß*

Main category: cs.CV

TL;DR: 提出了一种新的二阶总广义变分（TGV）公式，用于处理嵌入在三维空间中的三角形网格上的法向量。

- Motivation: 扩展离散TGV模型，使其适用于流形值函数（如单位球面上的法向量）。
- Method: 构建了一个定制的切向Raviart-Thomas型有限元空间，以扩展TGV公式到流形设置。
- Result: 在网格去噪实验中，新正则化方法与现有方法进行了比较。
- Conclusion: 新方法为处理流形值函数提供了一种有效的正则化工具。


### [29] [$\nabla$NABLA: Neighborhood Adaptive Block-Level Attention](https://arxiv.org/abs/2507.13546)
*Dmitrii Mikhailov,Aleksey Letunovskiy,Maria Kovaleva,Vladimir Arkhipkin,Vladimir Korviakov,Vladimir Polovnikov,Viacheslav Vasilev,Evelina Sidorova,Denis Dimitrov*

Main category: cs.CV

TL;DR: 论文提出了一种名为NABLA的新型注意力机制，通过动态适应视频扩散变换器中的稀疏模式，显著降低了计算复杂度，同时保持生成质量。

- Motivation: 基于Transformer的架构在视频生成任务中取得了显著成功，但全注意力机制的二次复杂度成为高分辨率和长视频序列的关键瓶颈。
- Method: 提出了NABLA（Neighborhood Adaptive Block-Level Attention），利用块级注意力和自适应稀疏驱动阈值，减少计算开销，无需定制低层算子设计，可与PyTorch的Flex Attention无缝集成。
- Result: 实验表明，NABLA在训练和推理速度上比基线快2.7倍，几乎不影响定量指标（如CLIP分数、VBench分数和人类评估分数）和视觉质量。
- Conclusion: NABLA是一种高效且易于集成的注意力机制，显著提升了视频生成任务的性能。


### [30] [LoRA-Loop: Closing the Synthetic Replay Cycle for Continual VLM Learning](https://arxiv.org/abs/2507.13568)
*Kaihong Wang,Donghyun Kim,Margrit Betke*

Main category: cs.CV

TL;DR: 提出了一种基于LoRA增强的合成重放框架，通过任务特定的低秩适配器改进Stable Diffusion模型，以提升持续学习中的样本对齐和知识保留。

- Motivation: 现有合成重放方法生成的样本可能因未捕捉领域特定细节和细粒度语义而误导微调，影响知识保留。
- Method: 采用LoRA增强的合成重放框架，分两阶段基于置信度选择样本：先选择真实任务数据微调LoRA，再生成并筛选合成样本用于蒸馏。
- Result: 在MTIL基准测试中表现优于现有合成重放技术，平衡了可塑性、稳定性和零样本能力。
- Conclusion: 通过LoRA适配生成器，显著提升了视觉语言模型在持续学习中的鲁棒性。


### [31] [NoiseSDF2NoiseSDF: Learning Clean Neural Fields from Noisy Supervision](https://arxiv.org/abs/2507.13595)
*Tengkai Wang,Weihao Li,Ruikai Cui,Shi Qiu,Nick Barnes*

Main category: cs.CV

TL;DR: 论文提出NoiseSDF2NoiseSDF方法，通过噪声监督从噪声点云中学习干净的神经SDF，显著提升噪声输入下的表面重建质量。

- Motivation: 低质量扫描设备捕获的点云常含大量噪声，导致表面重建不准确。
- Method: 扩展Noise2Noise范式到3D神经场，通过最小化噪声SDF表示间的MSE损失，隐式去噪并优化表面估计。
- Result: 在ShapeNet等基准测试中，方法显著提升了噪声输入下的表面重建质量。
- Conclusion: NoiseSDF2NoiseSDF有效解决了噪声点云下的表面重建问题。


### [32] [Learning Deblurring Texture Prior from Unpaired Data with Diffusion Model](https://arxiv.org/abs/2507.13599)
*Chengxu Liu,Lu Qi,Jinshan Pan,Xueming Qian,Ming-Hsuan Yang*

Main category: cs.CV

TL;DR: 提出了一种基于扩散模型的框架（\ours），用于从未配对数据中学习图像去模糊，通过生成纹理先验知识来恢复模糊图像的纹理。

- Motivation: 由于获取大量真实的模糊-清晰图像对困难且昂贵，从未配对数据中学习盲图像去模糊更具实用性和前景。现有方法依赖对抗学习，忽略了真实世界模糊模式的复杂性。
- Method: 提出Texture Prior Encoder（TPE）和Texture Transfer Transformer层（TTformer），利用扩散模型生成纹理先验，并通过自适应滤波去除空间变化的模糊。
- Result: 在广泛使用的基准测试中，\ours表现优于现有最先进方法，提供了有前景的无监督去模糊解决方案。
- Conclusion: \ours通过扩散模型和纹理先验学习，为图像去模糊提供了一种高效且实用的方法，尤其在处理真实世界复杂模糊时表现优异。


### [33] [Efficient Burst Super-Resolution with One-step Diffusion](https://arxiv.org/abs/2507.13607)
*Kento Kawai,Takeru Oba,Kyotaro Tokoro,Kazutoshi Akita,Norimichi Ukita*

Main category: cs.CV

TL;DR: 本文提出了一种基于扩散模型的随机采样方法，用于从低分辨率（LR）图像序列中生成高保真超分辨率（SR）图像，显著减少了运行时间并保持图像质量。

- Motivation: 传统的确定性训练方法生成的SR图像模糊且感知质量差，本文旨在通过扩散模型生成清晰且高保真的SR图像。
- Method: 使用随机采样器结合高阶ODE以及通过知识蒸馏实现的一步扩散，提高了扩散模型的效率。
- Result: 实验结果表明，该方法将运行时间减少至基线的1.6%，同时在图像失真和感知质量方面保持了SR质量。
- Conclusion: 该方法通过高效的扩散模型实现了高质量的SR图像生成，显著提升了运行效率。


### [34] [CoTasks: Chain-of-Thought based Video Instruction Tuning Tasks](https://arxiv.org/abs/2507.13609)
*Yanan Wang,Julio Vizcarra,Zhi Li,Hao Niu,Mori Kurokawa*

Main category: cs.CV

TL;DR: CoTasks提出了一种基于链式思维（CoT）的视频指令调优框架，通过分解复杂视频问题为四个实体级基础任务，显著提升了视频大语言模型的推理性能。

- Motivation: 现有视频大语言模型缺乏细粒度对象级视频理解的链式思维推理能力，需要结构化注释支持逐步推理。
- Method: CoTasks将复杂视频问题分解为帧定位、实体跟踪、时空关系提取四个基础任务，并将中间推理步骤嵌入输入。
- Result: 在NeXT-QA基准测试中，LLaVA-video-7B和Qwen2.5-VL-3B分别提升了3.3和17.4分，尤其在因果、时序和描述性子类别中表现突出。
- Conclusion: CoTasks作为一种结构化CoT监督框架，有效提升了视频组合推理能力。


### [35] [Moving Object Detection from Moving Camera Using Focus of Expansion Likelihood and Segmentation](https://arxiv.org/abs/2507.13628)
*Masahiro Ogawa,Qi An,Atsushi Yamashita*

Main category: cs.CV

TL;DR: FoELS方法结合光流和纹理信息，有效分离移动和静态物体，适用于复杂场景和相机运动。

- Motivation: 现有方法主要依赖光流，难以在复杂结构化场景中检测移动物体。
- Method: FoELS通过计算光流中的扩展焦点（FoE）并融合纹理信息，生成运动概率。
- Result: 在DAVIS 2016数据集和真实交通视频中表现优异，达到先进水平。
- Conclusion: FoELS在复杂场景和相机运动中表现出色，为3D重建和机器人导航提供有效解决方案。


### [36] [EPSilon: Efficient Point Sampling for Lightening of Hybrid-based 3D Avatar Generation](https://arxiv.org/abs/2507.13648)
*Seungjun Moon,Sangjoon Yu,Gyeong-Moon Park*

Main category: cs.CV

TL;DR: EPSilon提出了一种高效的混合3D头像生成方法，通过空点采样策略（ERO和EIO）显著提升了训练和推理速度，同时保持生成质量。

- Motivation: 现有基于NeRF和SMPL的混合方法在生成高质量头像时因变形计算成本高而导致推理速度慢。
- Method: EPSilon采用空射线忽略（ERO）和空区间忽略（EIO）策略，减少无效采样点，优化计算效率。
- Result: EPSilon仅使用3.9%的采样点，推理速度提升约20倍，训练收敛速度提升4倍。
- Conclusion: EPSilon通过高效采样策略，在保持生成质量的同时大幅提升了计算效率。


### [37] [When Person Re-Identification Meets Event Camera: A Benchmark Dataset and An Attribute-guided Re-Identification Framework](https://arxiv.org/abs/2507.13659)
*Xiao Wang,Qian Zhu,Shujuan Wu,Bo Jiang,Shiliang Zhang,Yaowei Wang,Yonghong Tian,Bin Luo*

Main category: cs.CV

TL;DR: 论文提出了一种新的大规模RGB-事件数据集EvReID，并基于此提出了TriPro-ReID框架，用于提升行人重识别的特征学习。

- Motivation: 当前基于事件相机的行人重识别方法受限于小规模或模拟数据集，难以评估实际性能。
- Method: 构建EvReID数据集，并提出TriPro-ReID框架，结合RGB和事件流数据及行人属性进行对比学习。
- Result: 在EvReID和MARS数据集上的实验验证了框架的有效性。
- Conclusion: EvReID数据集和TriPro-ReID框架为未来研究提供了数据和基准支持。


### [38] [Global Modeling Matters: A Fast, Lightweight and Effective Baseline for Efficient Image Restoration](https://arxiv.org/abs/2507.13663)
*Xingyu Jiang,Ning Gao,Hongkun Dou,Xiuhui Zhang,Xiaoqing Zhong,Yue Deng,Hongjue Li*

Main category: cs.CV

TL;DR: 论文提出了一种名为PW-FNet的高效图像修复方法，结合了小波和傅里叶变换，显著降低了计算复杂度并提升了修复质量。

- Motivation: 恶劣天气条件下自然图像质量下降，影响下游任务性能。现有基于Transformer的方法虽有效但计算复杂，难以实时处理。
- Method: PW-FNet采用金字塔小波多输入多输出结构实现多尺度分解，并在块内用傅里叶变换替代自注意力机制。
- Result: 实验表明，PW-FNet在多种修复任务中优于现有方法，且计算成本和推理时间显著降低。
- Conclusion: PW-FNet通过小波和傅里叶变换的结合，实现了高效且高质量的图像修复。


### [39] [MaskHOI: Robust 3D Hand-Object Interaction Estimation via Masked Pre-training](https://arxiv.org/abs/2507.13673)
*Yuechen Xie,Haobo Jiang,Jian Yang,Yigong Zhang,Jin Xie*

Main category: cs.CV

TL;DR: MaskHOI是一种基于掩码自编码器（MAE）的预训练框架，用于提升3D手-物体交互（HOI）姿态估计的精度，通过区域特定掩码分配和骨架驱动掩码引导解决几何模糊和遮挡问题。

- Motivation: 由于RGB图像的几何模糊性和交互中的严重遮挡，单目RGB输入下的手-物体交互姿态估计极具挑战性。
- Method: 提出MaskHOI框架，采用区域特定掩码分配和骨架驱动掩码引导，结合掩码符号距离场（SDF）驱动的多模态学习机制。
- Result: 实验表明，该方法显著优于现有最先进方法。
- Conclusion: MaskHOI通过几何感知和遮挡鲁棒的特征学习，有效提升了3D手-物体交互姿态估计的精度。


### [40] [HeCoFuse: Cross-Modal Complementary V2X Cooperative Perception with Heterogeneous Sensors](https://arxiv.org/abs/2507.13677)
*Chuheng Wei,Ziye Qin,Walter Zimmer,Guoyuan Wu,Matthew J. Barth*

Main category: cs.CV

TL;DR: HeCoFuse是一个统一的框架，用于解决异构传感器配置下的V2X协同感知问题，通过分层融合机制和自适应学习策略，显著提升了感知性能。

- Motivation: 现实中的V2X协同感知系统因传感器配置的异构性导致特征融合和感知可靠性问题，亟需一种统一的解决方案。
- Method: 提出HeCoFuse框架，采用分层融合机制（通道和空间注意力）和自适应空间分辨率调整模块，结合动态融合类型调整策略。
- Result: 在TUMTraf-V2X数据集上，HeCoFuse在多种传感器配置下表现优异，3D mAP最高达43.38%，优于基线方法。
- Conclusion: HeCoFuse在异构传感器配置下表现出色，成为当前TUM-Traf V2X数据集上的最先进方法。


### [41] [Gaussian kernel-based motion measurement](https://arxiv.org/abs/2507.13693)
*Hongyi Liu,Haifeng Wang*

Main category: cs.CV

TL;DR: 提出了一种基于高斯核的运动测量方法，用于高精度结构健康监测，解决了现有视觉方法在亚像素级运动测量中精度不足或参数调优复杂的问题。

- Motivation: 结构健康监测对高精度运动测量的需求日益增长，现有视觉方法在亚像素级测量中精度不足或需复杂参数调优。
- Method: 开发了一种基于高斯核的运动测量方法，通过跟踪高斯核位置提取帧间运动，引入运动一致性和超分辨率约束以提高精度和鲁棒性。
- Result: 数值和实验验证表明，该方法无需针对不同样本定制参数即可实现高精度。
- Conclusion: 该方法为结构健康监测提供了一种高精度、无需复杂参数调优的运动测量解决方案。


### [42] [GOSPA and T-GOSPA quasi-metrics for evaluation of multi-object tracking algorithms](https://arxiv.org/abs/2507.13706)
*Ángel F. García-Fernández,Jinhao Gu,Lennart Svensson,Yuxuan Xia,Jan Krejčí,Oliver Kost,Ondřej Straka*

Main category: cs.CV

TL;DR: 本文提出了两种用于多目标跟踪（MOT）算法性能评估的准度量，分别扩展了GOSPA和T-GOSPA度量，具有灵活的非对称惩罚成本。

- Motivation: 现有GOSPA和T-GOSPA度量在评估MOT算法时缺乏灵活性，无法根据应用需求调整惩罚成本。
- Method: 扩展GOSPA和T-GOSPA度量，引入非对称惩罚成本和局部化误差成本，并增加轨迹切换成本。
- Result: 通过仿真实验验证了T-GOSPA准度量在评估贝叶斯MOT算法中的有效性。
- Conclusion: 提出的准度量提供了更灵活的MOT评估工具，适用于特定应用场景。


### [43] [PoemTale Diffusion: Minimising Information Loss in Poem to Image Generation with Multi-Stage Prompt Refinement](https://arxiv.org/abs/2507.13708)
*Sofia Jamil,Bollampalli Areen Reddy,Raghvendra Kumar,Sriparna Saha,Koustava Goswami,K. J. Joseph*

Main category: cs.CV

TL;DR: 提出了一种无需训练的新方法PoemTale Diffusion，通过多阶段提示优化循环和自注意力机制改进诗歌文本到图像的生成。

- Motivation: 现有文本到图像扩散模型在处理复杂、抽象的诗歌语言时表现不佳，导致信息丢失。
- Method: 结合多阶段提示优化循环和自注意力机制，生成多张一致图像以传达诗歌含义，并创建P4I数据集支持研究。
- Result: 人类和定量评估验证了方法的有效性，生成图像能更好地捕捉诗歌信息。
- Conclusion: PoemTale Diffusion为诗歌到图像生成提供了新视角，显著提升了信息保留能力。


### [44] [Augmented Reality in Cultural Heritage: A Dual-Model Pipeline for 3D Artwork Reconstruction](https://arxiv.org/abs/2507.13719)
*Daniele Pannone,Alessia Castronovo,Maurizio Mancini,Gian Luca Foresti,Claudio Piciarelli,Rossana Gabrieli,Muhammad Yasir Bilal,Danilo Avola*

Main category: cs.CV

TL;DR: 提出了一种针对博物馆环境的增强现实流程，通过单张图像识别艺术品并生成精确3D模型。

- Motivation: 旨在解决艺术品复杂轮廓和纹理带来的重建挑战，提升博物馆的互动体验。
- Method: 结合GLPN和Depth-Anything两种预训练深度估计模型，生成优化的深度图并转换为高质量点云和网格。
- Result: 实验结果显示重建精度和视觉真实感显著提升。
- Conclusion: 该系统为博物馆提供了一种增强访客互动体验的强健工具。


### [45] [Tackling fake images in cybersecurity -- Interpretation of a StyleGAN and lifting its black-box](https://arxiv.org/abs/2507.13722)
*Julia Laubmann,Johannes Reschke*

Main category: cs.CV

TL;DR: 论文分析了StyleGAN生成器的内部机制，探讨了其关键技术和权重修剪的效果，揭示了潜在向量的作用及其伦理风险。

- Motivation: 研究StyleGAN生成器的工作原理，以理解其如何生成高度逼真的合成人脸，并探索其潜在的技术和伦理问题。
- Method: 使用PyTorch框架训练StyleGAN模型，通过权重修剪和潜在向量分析，研究其内部机制。
- Result: 发现大量权重可修剪而不显著影响输出，潜在向量能精确控制面部特征，但也存在被滥用的风险。
- Conclusion: StyleGAN的技术能力具有学术价值，但其潜在的滥用风险需引起伦理关注。


### [46] [Can Synthetic Images Conquer Forgetting? Beyond Unexplored Doubts in Few-Shot Class-Incremental Learning](https://arxiv.org/abs/2507.13739)
*Junsu Kim,Yunhoe Ku,Seungryul Baek*

Main category: cs.CV

TL;DR: Diffusion-FSCIL利用冻结的文本到图像扩散模型作为骨干，通过多尺度特征提取和潜在重放解决少样本类增量学习的挑战，显著优于现有方法。

- Motivation: 少样本类增量学习（FSCIL）面临数据有限和灾难性遗忘的挑战，需要一种能同时学习新信息并保留旧知识的方法。
- Method: 采用冻结的扩散模型作为骨干，提取多尺度特征作为潜在重放，辅以特征蒸馏减少生成偏差，仅需少量可训练组件。
- Result: 在CUB-200、miniImageNet和CIFAR-100上，Diffusion-FSCIL超越现有方法，有效保留旧类性能并适应新类。
- Conclusion: Diffusion-FSCIL通过冻结骨干和多尺度特征提取，实现了高效且性能优越的少样本类增量学习。


### [47] [Encapsulated Composition of Text-to-Image and Text-to-Video Models for High-Quality Video Synthesis](https://arxiv.org/abs/2507.13753)
*Tongtong Su,Chengyu Wang,Bingyan Liu,Jun Huang,Dongming Lu*

Main category: cs.CV

TL;DR: EVS是一种无需训练的封装视频合成器，结合T2I和T2V模型，提升生成视频的视觉质量和运动平滑性。

- Motivation: 现有T2V模型在生成高质量视频时存在画面闪烁和伪影问题，EVS旨在解决这些问题。
- Method: 利用预训练的T2I模型优化低质量视频帧，同时使用T2V模型确保运动一致性。
- Result: 实验证明EVS在视觉质量和运动平滑性上优于现有方法，推理速度提升1.6-4.5倍。
- Conclusion: EVS通过结合T2I和T2V模型的优势，显著提升了视频生成的质量和效率。


### [48] [Learning Spectral Diffusion Prior for Hyperspectral Image Reconstruction](https://arxiv.org/abs/2507.13769)
*Mingyang Yu,Zhijian Wu,Dingjiang Huang*

Main category: cs.CV

TL;DR: 本文提出了一种基于扩散模型的光谱扩散先验（SDP）和光谱先验注入模块（SPIM），用于提升高光谱图像（HSI）重建的高频细节恢复能力。

- Motivation: 现有深度学习方法在HSI重建中难以准确捕捉高频细节，因此需要一种更有效的方法来提升重建质量。
- Method: 通过扩散模型隐式学习HSI的光谱扩散先验（SDP），并设计光谱先验注入模块（SPIM）动态指导模型恢复细节。
- Result: 在MST和BISRNet两种HSI方法上，该方法性能优于现有网络约0.5 dB。
- Conclusion: 提出的SDP和SPIM显著提升了HSI重建的性能，特别是在高频细节恢复方面。


### [49] [Feature Engineering is Not Dead: Reviving Classical Machine Learning with Entropy, HOG, and LBP Feature Fusion for Image Classification](https://arxiv.org/abs/2507.13772)
*Abhijit Sen,Giridas Maiti,Bikram K. Parida,Bhanu P. Mishra,Mahima Arya,Denys I. Bondar*

Main category: cs.CV

TL;DR: 论文提出了一种基于排列熵（PE）的图像分类方法，结合HOG和LBP特征，训练SVM分类器，在多个基准数据集上表现优异。

- Motivation: 在图像分类中，特征工程在可解释性和计算效率方面仍具优势，尤其是与深度学习模型相比。
- Method: 扩展PE至二维图像，提出多尺度、多方向的熵特征提取方法，结合HOG和LBP特征，训练SVM分类器。
- Result: 在Fashion-MNIST等数据集上表现优异，提供了一种轻量级、可解释的替代方案。
- Conclusion: 熵特征与经典描述符结合，为图像分类提供了高效且可解释的解决方案。


### [50] [Teaching Vision-Language Models to Ask: Resolving Ambiguity in Visual Questions](https://arxiv.org/abs/2507.13773)
*Pu Jian,Donglei Yu,Wen Yang,Shuo Ren,Jiajun Zhang*

Main category: cs.CV

TL;DR: 论文提出ClearVQA基准，解决视觉问答中用户模糊问题的交互式澄清挑战。

- Motivation: 现有研究通过重述问题解决模糊性，但忽略了用户反馈的交互性。缺乏评估交互澄清能力的基准，且模型倾向于回答而非提问。
- Method: 引入ClearVQA基准，针对三类常见模糊问题，涵盖多种VQA场景。
- Result: ClearVQA基准填补了交互式澄清评估的空白。
- Conclusion: ClearVQA为视觉问答中的交互式澄清提供了评估工具，推动相关研究。


### [51] [SuperCM: Improving Semi-Supervised Learning and Domain Adaptation through differentiable clustering](https://arxiv.org/abs/2507.13779)
*Durgesh Singh,Ahcène Boubekki,Robert Jenssen,Michael Kampffmeyer*

Main category: cs.CV

TL;DR: 论文提出了一种显式可微分聚类模块，用于半监督学习和无监督域适应，通过利用监督数据计算聚类中心，提升了模型性能。

- Motivation: 现有方法通常隐式地利用聚类假设，而本文希望通过显式引入可微分聚类模块，更直接地利用监督数据优化聚类中心。
- Method: 提出了一种端到端的训练策略，结合可微分聚类模块，显式利用监督数据计算聚类中心。
- Result: 实验表明该方法在半监督学习和无监督域适应任务中表现优异，尤其在低监督条件下效果显著。
- Conclusion: 显式引入可微分聚类模块是一种简单有效的策略，可作为独立模型或现有方法的正则化器。


### [52] [Localized FNO for Spatiotemporal Hemodynamic Upsampling in Aneurysm MRI](https://arxiv.org/abs/2507.13789)
*Kyriakos Flouris,Moritz Halter,Yolanne Y. R. Lee,Samuel Castonguay,Luuk Jacobs,Pietro Dirix,Jonathan Nestmann,Sebastian Kozerke,Ender Konukoglu*

Main category: cs.CV

TL;DR: 提出了一种名为LoFNO的3D架构，通过结合几何先验和神经算子框架，提升血流数据的时空分辨率，直接预测壁面剪切应力（WSS），优于传统方法。

- Motivation: 磁共振血流成像的低时空分辨率和信噪比限制了其诊断价值，需要一种新方法来提升分辨率和预测能力。
- Method: LoFNO结合拉普拉斯特征向量作为几何先验，并采用EDSR层进行上采样，直接从临床影像数据预测WSS。
- Result: LoFNO在速度和WSS预测上优于插值和其他深度学习方法，提升了脑血管诊断的精确性。
- Conclusion: LoFNO通过整合几何先验和神经算子框架，显著提升了血流数据的时空分辨率和诊断能力。


### [53] [DynFaceRestore: Balancing Fidelity and Quality in Diffusion-Guided Blind Face Restoration with Dynamic Blur-Level Mapping and Guidance](https://arxiv.org/abs/2507.13797)
*Huu-Phu Do,Yu-Wei Chen,Yi-Cheng Liao,Chi-Wei Hsiao,Han-Yang Wang,Wei-Chen Chiu,Ching-Chun Huang*

Main category: cs.CV

TL;DR: DynFaceRestore提出了一种动态调整扩散采样起始时间和局部引导强度的盲脸恢复方法，有效平衡了保真度和细节质量。

- Motivation: 现有盲脸恢复方法因固定扩散采样时间和全局引导尺度，导致保真度和细节质量不平衡。
- Method: 通过学习将退化输入映射到高斯模糊图像，动态选择起始时间步，并应用局部动态引导调整。
- Result: DynFaceRestore在定量和定性评估中均达到最先进性能。
- Conclusion: 该方法在盲脸恢复中表现出鲁棒性和高效性，平衡了保真度与细节质量。


### [54] [One Step Closer: Creating the Future to Boost Monocular Semantic Scene Completion](https://arxiv.org/abs/2507.13801)
*Haoang Lu,Yuanqi Su,Xiaoning Zhang,Hao Hu*

Main category: cs.CV

TL;DR: 提出了一种新的时间3D语义场景补全框架CF-SSC，通过预测伪未来帧扩展感知范围，提升遮挡推理和场景补全准确性。

- Motivation: 现有单目SSC方法在真实交通场景中难以处理遮挡和视野外区域，需改进。
- Method: 结合位姿和深度建立3D对应关系，融合过去、当前和预测的未来帧，显式建模时空关系。
- Result: 在SemanticKITTI和SSCBench-KITTI-360基准测试中表现最优。
- Conclusion: CF-SSC通过时空建模显著提升了3D场景补全性能。


### [55] [GRAM-MAMBA: Holistic Feature Alignment for Wireless Perception with Adaptive Low-Rank Compensation](https://arxiv.org/abs/2507.13803)
*Weiqi Yang,Xu Zhou,Jingfu Guan,Hao Du,Tianyu Bai*

Main category: cs.CV

TL;DR: GRAM-MAMBA框架通过线性复杂度的Mamba模型和优化的GRAM矩阵策略，解决了多模态融合中的效率、模态对齐和缺失数据问题，显著提升了性能。

- Motivation: 现有多模态融合系统在资源受限环境中面临模型复杂、模态对齐不足和缺失数据鲁棒性差的问题。
- Method: 结合Mamba模型处理时间序列数据，使用GRAM矩阵优化模态对齐，并引入低秩自适应层补偿缺失模态。
- Result: 在SPAWC2021和USC-HAD数据集上，GRAM-MAMBA表现优于基线，性能提升显著且参数训练量极少。
- Conclusion: GRAM-MAMBA为资源受限环境中的高效鲁棒多模态感知提供了有效解决方案。


### [56] [SkySense V2: A Unified Foundation Model for Multi-modal Remote Sensing](https://arxiv.org/abs/2507.13812)
*Yingying Zhang,Lixiang Ru,Kang Wu,Lei Yu,Lei Liang,Yansheng Li,Jingdong Chen*

Main category: cs.CV

TL;DR: SkySense V2提出了一种统一的多模态遥感基础模型，通过单一Transformer主干和自适应SSL策略，解决了现有方法冗余和效率低下的问题，并在多个任务中表现优异。

- Motivation: 现有遥感基础模型通常需要为每种数据模态训练单独的主干网络，导致冗余和参数利用效率低下，且预训练方法未能充分适应遥感图像的特点。
- Method: SkySense V2采用单一Transformer主干处理多模态数据，结合自适应SSL策略、自适应块合并模块、可学习模态提示令牌和MoE模块。
- Result: 在7个任务的16个数据集上评估，SkySense V2平均比SkySense提升1.8分。
- Conclusion: SkySense V2通过统一架构和针对性优化，显著提升了多模态遥感任务的性能。


### [57] [Team of One: Cracking Complex Video QA with Model Synergy](https://arxiv.org/abs/2507.13820)
*Jun Xie,Zhaoran Zhao,Xiongjun Guan,Yingjian Zhu,Hongzhu Yi,Xinming Wang,Feng Chen,Zhepeng Wang*

Main category: cs.CV

TL;DR: 提出了一种新颖的开放视频问答框架，通过多模型协作提升推理深度和鲁棒性，显著优于现有基线。

- Motivation: 现有视频-语言模型在复杂场景中表现不足，如上下文理解有限、时序建模弱、对模糊或组合查询泛化能力差。
- Method: 引入提示-响应集成机制，通过结构化思维链协调多个异构视频-语言模型，并利用外部大语言模型作为评估和集成器。
- Result: 在CVRR-ES数据集上显著优于现有基线，表现出更强的泛化能力和鲁棒性。
- Conclusion: 该方法为无需重新训练的多模态推理提供了一种轻量级、可扩展的策略，为未来视频-语言模型发展奠定基础。


### [58] [A Quantum-assisted Attention U-Net for Building Segmentation over Tunis using Sentinel-1 Data](https://arxiv.org/abs/2507.13852)
*Luigi Russo,Francesco Mauro,Babak Memar,Alessandro Sebastianelli,Silvia Liberata Ullo,Paolo Gamba*

Main category: cs.CV

TL;DR: 研究探讨了使用Quanvolution预处理增强Attention U-Net模型在城市建筑分割中的能力，结果显示该方法在保持精度的同时减少了参数。

- Motivation: 城市建筑分割在规划、灾害响应等领域至关重要，但高分辨率卫星图像的处理具有挑战性。
- Method: 结合Quanvolution预处理和Attention U-Net模型，利用Sentinel-1 SAR图像进行建筑分割。
- Result: 方法在测试精度上与标准模型相当，同时显著减少了网络参数。
- Conclusion: 量子辅助深度学习框架在大规模城市建筑分割中具有潜力。


### [59] [Depth3DLane: Fusing Monocular 3D Lane Detection with Self-Supervised Monocular Depth Estimation](https://arxiv.org/abs/2507.13857)
*Max van den Hoven,Kishaan Jeeveswaran,Pieter Piscaer,Thijs Wensveen,Elahe Arani,Bahram Zonooz*

Main category: cs.CV

TL;DR: Depth3DLane提出了一种双路径框架，结合自监督深度估计，无需昂贵传感器或深度数据，实现了单目3D车道检测。

- Motivation: 解决单目3D车道检测中缺乏显式空间信息的问题，避免依赖昂贵传感器或大规模深度数据。
- Method: 通过自监督深度网络生成点云，结合鸟瞰图和前视图路径提取空间和语义信息，使用3D车道锚点采样特征。
- Result: 在OpenLane基准测试中表现优异，且无需相机标定即可应用。
- Conclusion: Depth3DLane在无标定场景下具有竞争力，扩展了单目3D车道检测的适用性。


### [60] [PositionIC: Unified Position and Identity Consistency for Image Customization](https://arxiv.org/abs/2507.13861)
*Junjie Hu,Tianyang Han,Kai Ma,Jialin Gao,Hao Dou,Song Yang,Xianhua He,Jianhui Zhang,Junfeng Luo,Xiaoming Wei,Wenqiang Zhang*

Main category: cs.CV

TL;DR: PositionIC框架通过位置和身份一致性实现多主体图像定制，解决了现有方法在细粒度空间控制上的不足。

- Motivation: 现有图像定制方法在实体级空间控制上表现不足，限制了实际应用。缺乏绑定身份与精确位置的可扩展数据集是主要原因。
- Method: 提出PositionIC框架，构建双向生成范式合成数据，设计轻量级位置调制层解耦空间嵌入。
- Result: 实验表明，该方法能实现精确空间控制并保持图像定制的高一致性。
- Conclusion: PositionIC为开放世界多实体场景下的可控高保真图像定制提供了新思路，将公开发布以促进研究。


### [61] [When Seeing Overrides Knowing: Disentangling Knowledge Conflicts in Vision-Language Models](https://arxiv.org/abs/2507.13868)
*Francesco Ortu,Zhijing Jin,Diego Doimo,Alberto Cazzaniga*

Main category: cs.CV

TL;DR: 研究分析了视觉语言模型（VLMs）如何处理内部知识与外部信息之间的冲突，通过引入多模态反事实查询数据集，定位并修改控制冲突的注意力头，从而引导模型行为。

- Motivation: 视觉语言模型在处理复杂任务时，内部参数知识与外部信息之间可能产生冲突，导致幻觉和不可靠响应，但其机制尚不明确。
- Method: 引入多模态反事实查询数据集，定位控制冲突的注意力头，并通过修改这些头来引导模型行为。
- Result: 研究发现少量注意力头控制冲突，修改这些头可引导模型偏向内部知识或视觉输入；这些头的注意力定位优于基于梯度的归因方法。
- Conclusion: 通过定位和修改特定注意力头，可以有效控制VLMs在知识冲突中的行为，提升模型可靠性。


### [62] [Real-Time Fusion of Visual and Chart Data for Enhanced Maritime Vision](https://arxiv.org/abs/2507.13880)
*Marten Kreis,Benjamin Kiefer*

Main category: cs.CV

TL;DR: 提出了一种通过融合实时视觉数据和海图信息来增强海洋视觉的新方法，利用基于Transformer的神经网络实现导航标志的精准匹配。

- Motivation: 解决动态和挑战性海洋环境中导航标志定位和关联的准确性问题。
- Method: 引入基于Transformer的端到端神经网络，预测浮标查询的边界框和置信度分数，直接匹配图像域检测与世界空间海图标记。
- Result: 在真实海洋场景数据集上，显著提升了目标定位和关联的准确性。
- Conclusion: 该方法在动态和复杂环境中表现优于基线方法，为海洋视觉增强提供了有效解决方案。


### [63] [PCR-GS: COLMAP-Free 3D Gaussian Splatting via Pose Co-Regularizations](https://arxiv.org/abs/2507.13891)
*Yu Wei,Jiahui Zhang,Xiaoqin Zhang,Ling Shao,Shijian Lu*

Main category: cs.CV

TL;DR: PCR-GS是一种无需COLMAP的3D高斯溅射技术，通过相机姿态共正则化改进复杂相机轨迹下的3D场景建模和姿态估计。

- Motivation: 现有3D-GS方法在复杂相机轨迹（如剧烈旋转和平移）下表现不佳，导致相机姿态估计和联合优化陷入局部最小值。
- Method: PCR-GS通过特征重投影正则化（对齐相邻视图的DINO特征）和小波频率正则化（优化旋转矩阵）实现相机姿态共正则化。
- Result: 实验表明，PCR-GS在剧烈变化的相机轨迹下实现了优越的无姿态3D-GS场景建模。
- Conclusion: PCR-GS通过双重正则化显著提升了复杂场景下的3D建模和相机姿态估计性能。


### [64] [Enhancing LiDAR Point Features with Foundation Model Priors for 3D Object Detection](https://arxiv.org/abs/2507.13899)
*Yujian Mo,Yan Wu,Junqiao Zhao,Jijun Wang,Yinghao Hu,Jun Yan*

Main category: cs.CV

TL;DR: 论文提出了一种利用DepthAnything生成深度先验的方法，以增强LiDAR点云特征，提升3D目标检测性能。

- Motivation: 解决LiDAR点云特征表达能力有限的问题，尤其是反射率属性的弱区分能力。
- Method: 融合DepthAnything预测的深度先验与原始LiDAR属性，提出点级特征提取模块和双路径RoI特征提取框架，并引入双向门控RoI特征融合模块。
- Result: 在KITTI基准测试中，检测精度显著提升。
- Conclusion: 视觉基础模型先验可有效提升LiDAR-based 3D目标检测性能。


### [65] [TimeNeRF: Building Generalizable Neural Radiance Fields across Time from Few-Shot Input Views](https://arxiv.org/abs/2507.13929)
*Hsiang-Hui Hung,Huu-Phu Do,Yung-Hui Li,Ching-Chun Huang*

Main category: cs.CV

TL;DR: TimeNeRF是一种通用的神经渲染方法，能够在任意视角和时间下渲染新视图，即使输入视图较少。它结合了多视角立体视觉、神经辐射场和解耦策略，实现了少样本泛化能力，并能构建任意时间的神经辐射场。实验表明，TimeNeRF无需逐场景优化即可生成平滑的时间过渡视图。

- Motivation: 当前NeRF技术在合成新视图方面表现优异，但在时间维度的3D场景建模方面潜力尚未充分挖掘，且缺乏专用数据集。数字领域（如元宇宙）对昼夜自然过渡的3D环境建模需求迫切。
- Method: 结合多视角立体视觉、神经辐射场和解耦策略，构建隐式内容辐射场表示场景，并支持任意时间的神经辐射场构建。通过体积渲染合成新视图。
- Result: TimeNeRF在少样本设置下无需逐场景优化即可渲染新视图，并能生成平滑的时间过渡视图，捕捉从黎明到黄昏的自然场景变化。
- Conclusion: TimeNeRF为时间维度的3D场景建模提供了一种高效、通用的解决方案，适用于元宇宙等需要动态场景的应用。


### [66] [DiViD: Disentangled Video Diffusion for Static-Dynamic Factorization](https://arxiv.org/abs/2507.13934)
*Marzieh Gheisari,Auguste Genovesio*

Main category: cs.CV

TL;DR: DiViD是一种端到端视频扩散框架，用于显式分离静态外观和动态运动，通过全局静态标记和帧特定动态标记实现，优于现有方法。

- Motivation: 现有基于VAE和GAN的方法存在信息泄漏和模糊重建问题，需要一种更有效的视频静态-动态分离方法。
- Method: DiViD采用序列编码器提取全局静态标记和帧特定动态标记，结合条件DDPM解码器，引入共享噪声计划、时间变化KL瓶颈和交叉注意力等归纳偏置。
- Result: DiViD在真实基准测试中表现优异，具有最高的交换联合准确率，同时保持静态保真度和动态传递性，减少交叉泄漏。
- Conclusion: DiViD是首个实现显式静态-动态分解的视频扩散框架，性能优于现有方法。


### [67] [Generalist Forecasting with Frozen Video Models via Latent Diffusion](https://arxiv.org/abs/2507.13942)
*Jacob C Walker,Pedro Vélez,Luisa Polania Cabrera,Guangyao Zhou,Rishabh Kabra,Carl Doersch,Maks Ovsjanikov,João Carreira,Shiry Ginosar*

Main category: cs.CV

TL;DR: 研究发现视觉模型的感知能力与短期预测性能强相关，提出了一种通用预测框架，通过潜在扩散模型预测未来特征，并在多个任务中验证了其有效性。

- Motivation: 探索视觉模型的感知能力与预测性能的关系，以提升通用系统在不同抽象层次上的预测能力。
- Method: 提出通用预测框架，利用潜在扩散模型在冻结视觉骨干网络中预测未来特征，并通过轻量级任务特定解码器实现。
- Result: 在九个模型和四个任务中验证了框架的有效性，发现感知能力与预测性能强相关。
- Conclusion: 结合表征学习和生成模型对视频理解具有重要意义。


### [68] [Evaluation of Human Visual Privacy Protection: A Three-Dimensional Framework and Benchmark Dataset](https://arxiv.org/abs/2507.13981)
*Sara Abdulaziz,Giacomo D'Amicantonio,Egor Bondarev*

Main category: cs.CV

TL;DR: 本文提出了一种评估视觉隐私保护方法的框架，并发布了HR-VISPR数据集，用于训练可解释的隐私度量。

- Motivation: AI驱动的监控技术引发了对敏感数据处理的隐私担忧，需要客观的评估方法。
- Method: 提出了一个三维（隐私、实用性和实用性）评估框架，并利用HR-VISPR数据集评估了11种隐私保护方法。
- Result: 框架能够区分隐私级别，并揭示隐私、实用性和实用性之间的权衡。
- Conclusion: 该研究和数据集为隐私保护提供了结构化评估工具，适用于多种场景。


### [69] [CSD-VAR: Content-Style Decomposition in Visual Autoregressive Models](https://arxiv.org/abs/2507.13984)
*Quang-Binh Nguyen,Minh Luu,Quang Nguyen,Anh Tran,Khoi Nguyen*

Main category: cs.CV

TL;DR: CSD-VAR是一种基于VAR的内容-风格分解方法，通过尺度感知优化、SVD校正和增强K-V记忆，显著提升了内容保持和风格化效果。

- Motivation: 探索VAR作为生成框架用于内容-风格分解，利用其尺度生成过程改进解耦效果。
- Method: 提出CSD-VAR方法，包括尺度感知交替优化、SVD校正和增强K-V记忆。
- Result: CSD-VAR在内容保持和风格化保真度上优于现有方法。
- Conclusion: CSD-VAR为内容-风格分解提供了高效框架，并在实验中表现优异。


### [70] [DreamScene: 3D Gaussian-based End-to-end Text-to-3D Scene Generation](https://arxiv.org/abs/2507.13985)
*Haoran Li,Yuli Tian,Kun Lan,Yong Liao,Lin Wang,Pan Hui,Peng Yuan Zhou*

Main category: cs.CV

TL;DR: DreamScene是一个端到端框架，通过文本或对话生成高质量、可编辑的3D场景，解决了现有方法在自动化、3D一致性和细粒度控制方面的不足。

- Motivation: 从自然语言生成3D场景在游戏、电影和设计中有广泛应用前景，但现有方法在自动化、一致性和控制方面存在挑战。
- Method: DreamScene结合场景规划模块（GPT-4代理推断语义和空间约束）、基于图的布局算法、几何生成（FPS）和渐进相机采样策略，支持细粒度编辑。
- Result: 实验表明，DreamScene在质量、一致性和灵活性上优于现有方法，为开放域3D内容创作提供实用解决方案。
- Conclusion: DreamScene通过创新方法实现了高质量、可编辑的3D场景生成，为相关领域提供了实用工具。


### [71] [Automatic Classification and Segmentation of Tunnel Cracks Based on Deep Learning and Visual Explanations](https://arxiv.org/abs/2507.14010)
*Yong Feng,Xiaolei Zhang,Shijin Feng,Yong Zhao,Yihan Chen*

Main category: cs.CV

TL;DR: 提出了一种基于深度学习的两步法，用于隧道裂缝的分类和分割，提高了准确性和效率。

- Motivation: 隧道裂缝是隧道安全状态的重要指标，需要一种更准确和高效的方法来分类和分割裂缝。
- Method: 第一步使用DenseNet-169进行隧道图像分类，第二步基于DeepLabV3+进行裂缝分割，并通过可视化技术评估模型逻辑。
- Result: 分类模型准确率为92.23%，FPS为39.80；分割模型的IoU为57.01%，F1得分为67.44%，均优于其他先进模型。
- Conclusion: 该方法结合了分类和分割，并通过可视化解释提升了模型的可理解性，为隧道健康状况的快速准确评估提供了基础。


### [72] [Analysis of Plant Nutrient Deficiencies Using Multi-Spectral Imaging and Optimized Segmentation Model](https://arxiv.org/abs/2507.14013)
*Ji-Yan Wu,Zheng Yong Poh,Anoop C. Patil,Bongsoo Park,Giovanni Volpe,Daisuke Urano*

Main category: cs.CV

TL;DR: 提出了一种基于多光谱成像和增强YOLOv5模型的深度学习框架，用于植物叶片异常分割，显著优于基线模型。

- Motivation: 精准农业需要准确检测植物叶片营养缺乏，以实现早期干预施肥、疾病和压力管理。
- Method: 采用多光谱成像和增强YOLOv5模型，结合基于Transformer的注意力机制，处理九通道多光谱输入。
- Result: 模型在Dice分数和IoU上平均提升12%，尤其在检测黄化和色素积累等挑战性症状上表现优异。
- Conclusion: 结合多光谱成像和光谱-空间特征学习，为植物表型和精准农业提供了有前景的解决方案。


### [73] [Moodifier: MLLM-Enhanced Emotion-Driven Image Editing](https://arxiv.org/abs/2507.14024)
*Jiarong Ye,Sharon X. Huang*

Main category: cs.CV

TL;DR: 提出一种情绪驱动的图像编辑方法，包括数据集MoodArchive、模型MoodifyCLIP和编辑工具Moodifier，用于精确调整图像情绪同时保持内容完整性。

- Motivation: 情绪驱动的图像编辑在创意产业潜力巨大，但因情绪抽象且表现多样，精确操作具有挑战性。
- Method: 1. 构建MoodArchive数据集（8M+图像，带层级情绪标注）；2. 开发MoodifyCLIP模型，将情绪映射为视觉属性；3. 提出Moodifier编辑模型，结合MLLMs实现无训练的情绪转换。
- Result: Moodifier在情绪准确性和内容保留上优于现有方法，适用于多领域（如角色表情、时尚设计等）。
- Conclusion: 通过将抽象情绪与具体视觉变化关联，为实际应用中的情绪内容创作开辟新可能。


### [74] [QuantEIT: Ultra-Lightweight Quantum-Assisted Inference for Chest Electrical Impedance Tomography](https://arxiv.org/abs/2507.14031)
*Hao Fang,Sihao Teng,Hao Yu,Siyi Yuan,Huaiwu He,Zhe Liu,Yunjie Yang*

Main category: cs.CV

TL;DR: 提出了一种基于量子辅助网络的超轻量级EIT图像重建框架QuantEIT，显著降低了模型复杂度，并在无监督、无需训练数据的情况下实现了高精度重建。

- Motivation: EIT图像重建的逆问题具有病态性，传统深度学习方法依赖复杂网络结构，效率低且难以扩展。
- Method: QuantEIT结合并行2量子比特电路生成潜在表示，并通过单层线性网络重建电导率。
- Result: 在模拟和真实2D/3D肺部EIT数据上，QuantEIT仅用0.2%参数即达到或超越传统方法的精度，且抗噪性更强。
- Conclusion: QuantEIT首次将量子电路引入EIT重建，为高效、轻量化的医学成像提供了新思路。


### [75] [Training-free Token Reduction for Vision Mamba](https://arxiv.org/abs/2507.14042)
*Qiankun Ma,Ziyao Zhang,Chi Su,Jie Chen,Zhen Song,Hairong Zheng,Wen Gao*

Main category: cs.CV

TL;DR: Vision Mamba（视觉Mamba）作为Vision Transformers（ViTs）的竞争者，因其线性计算复杂度的高效性而备受关注。本文提出了一种无需训练的Mamba Token Reduction（MTR）框架，显著降低计算量且性能影响小。

- Motivation: 探索Vision Mamba的效率以扩展其应用，但现有ViTs的token缩减技术直接应用于Mamba会导致性能下降。
- Method: 提出Mamba结构感知的重要性评分，并基于此设计无需训练的MTR框架。
- Result: MTR在Vim-B骨干上减少约40%的FLOPs，ImageNet性能仅下降1.6%。
- Conclusion: MTR是一种高效、无需训练的token缩减方法，适用于多种Mamba模型。


### [76] [Foundation Models as Class-Incremental Learners for Dermatological Image Classification](https://arxiv.org/abs/2507.14050)
*Mohamed Elkhayat,Mohamed Mahmoud,Jamil Fayyad,Nourhan Bayasi*

Main category: cs.CV

TL;DR: 该论文探讨了在皮肤病分类中利用冻结基础模型（FM）进行类增量学习（CIL），提出了一种轻量级MLP增量训练方法，性能优于现有技术，并探索了零训练场景下的原型分类方法。

- Motivation: 探索基础模型在皮肤病分类中的增量学习潜力，填补现有研究空白。
- Method: 冻结FM主干，为每个任务增量训练轻量级MLP；同时测试零训练场景下的原型分类方法。
- Result: 提出的方法在CIL任务中表现优异，超越现有技术；原型分类方法也取得竞争性结果。
- Conclusion: 冻结FM在皮肤病持续学习中表现强大，支持其在真实医疗应用中的广泛采用。


### [77] [VLA-Mark: A cross modal watermark for large vision-language alignment model](https://arxiv.org/abs/2507.14067)
*Shuliang Liu,Qi Zheng,Jesse Jiaxi Xu,Yibo Yan,He Geng,Aiwei Liu,Peijie Jiang,Jia Liu,Yik-Cheung Tam,Xuming Hu*

Main category: cs.CV

TL;DR: VLA-Mark是一种视觉对齐的水印框架，通过跨模态协调嵌入可检测水印，同时保持语义保真度。

- Motivation: 现有文本水印方法破坏了视觉-文本对齐，需要一种保护知识产权且不影响多模态一致性的解决方案。
- Method: 结合多尺度视觉-文本对齐指标（局部补丁亲和性、全局语义一致性和上下文注意力模式）动态平衡水印强度和语义保留。
- Result: 实验显示，VLA-Mark在PPL和BLEU上优于传统方法，检测准确率达98.8% AUC，抗攻击能力为96.1%。
- Conclusion: VLA-Mark为质量保持的多模态水印设定了新标准。


### [78] [Unmasking Performance Gaps: A Comparative Study of Human Anonymization and Its Effects on Video Anomaly Detection](https://arxiv.org/abs/2507.14083)
*Sara Abdulaziz,Egor Bondarev*

Main category: cs.CV

TL;DR: 论文分析了四种匿名化技术对异常检测性能的影响，发现算法设计对匿名化数据的响应是关键，同时探讨了隐私保护与检测效用的权衡。

- Motivation: 深度学习在监控视频异常检测中取得进展，但涉及敏感数据收集引发隐私问题。研究旨在评估不同匿名化技术对异常检测的影响。
- Method: 在UCF-Crime数据集上应用四种匿名化技术（模糊、掩码、加密、虚拟替换），并评估四种异常检测方法（MGFN、UR-DMU、BN-WVAD、PEL4VAD）。
- Result: 实验表明，匿名化数据下异常检测仍可行，且某些匿名化技术（如加密和掩码）甚至能提升部分模型的AUC性能。
- Conclusion: 研究揭示了算法对匿名化的敏感性，强调了隐私保护与检测效用的权衡，并对比了传统匿名化与新兴隐私保护方案的优劣。


### [79] [Multi-Centre Validation of a Deep Learning Model for Scoliosis Assessment](https://arxiv.org/abs/2507.14093)
*Šimon Kubov,Simon Klíčník,Jakub Dandár,Zdeněk Straka,Karolína Kvaková,Daniel Kvak*

Main category: cs.CV

TL;DR: 论文提出了一种基于深度学习的自动化软件（Carebot AI Bones），用于测量脊柱侧弯的Cobb角，结果显示其与放射科医生的测量结果高度一致，可用于临床工作流。

- Motivation: 脊柱侧弯影响2-4%的青少年，传统手动测量Cobb角耗时且存在观察者间差异。研究旨在评估自动化软件的准确性和实用性。
- Method: 研究回顾性评估了103张脊柱X光片，使用Carebot AI Bones软件进行自动测量，并与两位放射科医生的独立测量结果对比。
- Result: AI与放射科医生的测量结果高度一致（MAE约3.9度，Pearson相关系数0.88-0.91），且分类一致性（Cohen kappa）达到0.51-0.64。
- Conclusion: 该软件能复现专家水平的Cobb角测量和分类，可优化脊柱侧弯的临床报告和分诊流程。


### [80] [C-DOG: Training-Free Multi-View Multi-Object Association in Dense Scenes Without Visual Feature via Connected δ-Overlap Graphs](https://arxiv.org/abs/2507.14095)
*Yung-Hong Sun,Ting-Hung Lin,Jiangang Chen,Hongrui Jiang,Yu Hen Hu*

Main category: cs.CV

TL;DR: C-DOG是一种无需训练的框架，通过结合连接delta-overlap图建模和极线几何，在多视图中鲁棒地关联目标检测，适用于噪声和视觉不可区分的情况。

- Motivation: 解决现有方法在目标视觉不可区分或观测噪声时失效的问题。
- Method: 使用连接delta-overlap图建模和极线几何，结合IQR过滤和3D反投影误差标准。
- Result: 在合成基准测试中优于几何基线，并在高目标密度、无视觉特征和有限相机重叠等挑战下保持鲁棒性。
- Conclusion: C-DOG适用于现实场景中可扩展的3D重建。


### [81] [NoHumansRequired: Autonomous High-Quality Image Editing Triplet Mining](https://arxiv.org/abs/2507.14119)
*Maksim Kuprashevich,Grigorii Alekseenko,Irina Tolstykh,Georgii Fedorov,Bulat Suleimanov,Vladimir Dokholyan,Aleksandr Gordeev*

Main category: cs.CV

TL;DR: 论文提出了一种自动化、模块化的流水线，用于生成高质量的图像编辑三元组（原始图像、指令、编辑后图像），解决了现有方法依赖人工标注的问题。

- Motivation: 现有生成模型需要大量高质量的三元组数据，但人工标注成本高且难以满足像素级准确性要求。
- Method: 利用公共生成模型和任务调优的Gemini验证器，自动化生成和验证三元组，并通过反转和组合自举扩大数据集。
- Result: 发布了NHR-Edit数据集（358k高质量三元组）和Bagel-NHR-Edit模型，在跨数据集评估中表现最佳。
- Conclusion: 该方法实现了大规模高质量数据集的自动化生成，推动了图像编辑领域的研究，并开源了数据集和模型。


### [82] [Franca: Nested Matryoshka Clustering for Scalable Visual Representation Learning](https://arxiv.org/abs/2507.14137)
*Shashanka Venkataramanan,Valentinos Pariza,Mohammadreza Salehi,Lukas Knobel,Spyros Gidaris,Elias Ramzi,Andrei Bursuc,Yuki M. Asano*

Main category: cs.CV

TL;DR: Franca是首个完全开源的视觉基础模型，性能媲美甚至超越专有模型，解决了SSL聚类方法的局限性，并引入了多头聚类投影器和位置解耦策略。

- Motivation: 解决专有模型的不透明性和SSL聚类方法的局限性，推动开源高性能视觉模型的发展。
- Method: 使用透明训练流程和公开数据，提出多头聚类投影器和位置解耦策略。
- Result: 在多个下游基准测试中表现优异，性能与专有模型相当或更好。
- Conclusion: Franca为透明高性能视觉模型设定了新标准，推动了可复现和通用基础模型的发展。
## cs.SI

### [83] [Leveraging the Spatial Hierarchy: Coarse-to-fine Trajectory Generation via Cascaded Hybrid Diffusion](https://arxiv.org/abs/2507.13366)
*Baoshen Guo,Zhiqing Hong,Junyi Li,Shenhao Wang,Jinhua Zhao*

Main category: cs.SI

TL;DR: Cardiff是一种基于级联混合扩散的轨迹合成框架，用于细粒度和隐私保护的移动性生成，通过分层次生成轨迹解决了现有方法的局限性。

- Motivation: 由于隐私问题和数据收集成本高，细粒度的人类移动轨迹难以大规模公开。现有轨迹合成方法常忽略轨迹的结构复杂性，无法处理高维分布或生成真实的细粒度轨迹。
- Method: Cardiff采用粗到细的级联方法，分两阶段生成轨迹：离散路段级和连续GPS级。第一阶段使用扩散变换器进行潜在去噪，第二阶段通过噪声增强机制实现高保真生成。
- Result: 在三个真实世界轨迹数据集上的实验表明，Cardiff在多项指标上优于现有基线方法。
- Conclusion: Cardiff不仅通过级联去噪逐步生成高保真轨迹，还能灵活平衡隐私保护与实用性。
## cs.GR

### [84] [StructInbet: Integrating Explicit Structural Guidance into Inbetween Frame Generation](https://arxiv.org/abs/2507.13377)
*Zhenglin Pan,Haoran Xie*

Main category: cs.GR

TL;DR: StructInbet提出了一种基于显式结构引导的中间帧生成系统，通过结构指导和时序注意力机制提高过渡帧的可控性和一致性。

- Motivation: 解决中间帧生成中像素轨迹的模糊性问题，并确保角色外观的一致性。
- Method: 引入显式结构指导和时序注意力机制，结合前后关键帧的视觉信息。
- Result: 生成可控且一致的过渡帧，减少了模糊性。
- Conclusion: StructInbet通过结构指导和时序注意力机制，有效提升了中间帧生成的质量和可控性。


### [85] [TexGS-VolVis: Expressive Scene Editing for Volume Visualization via Textured Gaussian Splatting](https://arxiv.org/abs/2507.13586)
*Kaiyuan Tang,Kuangshi Ai,Jun Han,Chaoli Wang*

Main category: cs.GR

TL;DR: 论文提出TexGS-VolVis框架，通过纹理高斯泼溅技术改进体积可视化，实现高质量、几何一致的风格化和灵活的场景编辑。

- Motivation: 现有体积可视化方法依赖复杂预定义规则且风格单一，限制了灵活性和效果。
- Method: 采用纹理高斯泼溅框架（TexGS-VolVis），结合2D高斯基元和额外纹理属性，支持图像和文本驱动的非真实感编辑。
- Result: TexGS-VolVis在效率和视觉质量上优于现有方法，支持灵活的场景编辑。
- Conclusion: TexGS-VolVis为体积可视化提供了更高效、灵活且高质量的解决方案。
## cs.LG

### [86] [Generalist Bimanual Manipulation via Foundation Video Diffusion Models](https://arxiv.org/abs/2507.12898)
*Yao Feng,Hengkai Tan,Xinyi Mao,Guodong Liu,Shuhe Huang,Chendong Xiang,Hang Su,Jun Zhu*

Main category: cs.LG

TL;DR: VIDAR是一个两阶段框架，通过扩散模型预训练和掩码逆向动力学模型解决双手机器人操作中的数据稀缺和异构性问题。

- Motivation: 双手机器人操作中数据稀缺和异构性限制了其扩展性。
- Method: 提出VIDAR框架，结合大规模视频预训练和掩码逆向动力学模型，无需像素级标签。
- Result: 仅需20分钟人类演示，VIDAR在未见过的任务和背景中表现优异，超越现有方法。
- Conclusion: 视频基础模型与掩码动作预测结合，有望实现可扩展和通用的机器人操作。


### [87] [Whose View of Safety? A Deep DIVE Dataset for Pluralistic Alignment of Text-to-Image Models](https://arxiv.org/abs/2507.13383)
*Charvi Rastogi,Tian Huey Teh,Pushkar Mishra,Roma Patel,Ding Wang,Mark Díaz,Alicia Parrish,Aida Mostafazadeh Davani,Zoe Ashwood,Michela Paganini,Vinodkumar Prabhakaran,Verena Rieser,Lora Aroyo*

Main category: cs.LG

TL;DR: 论文提出了一种多元对齐方法，通过DIVE数据集和人口统计学视角改进文本到图像（T2I）模型的多样性和安全性。

- Motivation: 当前T2I模型未能充分考虑人类多样性，导致系统与人类价值观不一致。
- Method: 引入DIVE数据集，利用多元人口统计学视角评估模型，并探讨数据收集策略和模型可操控性。
- Result: 证实人口统计学是多样观点的重要代理，揭示了与传统评估不同的危害感知差异。
- Conclusion: 为构建更公平和对齐的T2I系统提供了基础工具。


### [88] [Improving Out-of-distribution Human Activity Recognition via IMU-Video Cross-modal Representation Learning](https://arxiv.org/abs/2507.13482)
*Seyyed Saeid Cheshmi,Buyao Lyu,Thomas Lisko,Rajesh Rajamani,Robert A. McGovern,Yogatheesan Varatharajah*

Main category: cs.LG

TL;DR: 提出了一种基于跨模态自监督预训练的方法，用于从大规模未标记的IMU-视频数据中学习表示，提高了在分布外IMU数据集上的人体活动识别任务的泛化能力。

- Motivation: 解决现有基于惯性传感器的人体活动识别方法依赖特定应用标签、泛化能力不足的问题。
- Method: 采用跨模态自监督预训练方法，利用未标记的IMU-视频数据学习通用表示。
- Result: 在零样本和少样本评估中，该方法优于当前最先进的IMU-视频预训练和仅IMU预训练方法。
- Conclusion: 跨模态预训练是学习通用数据表示的有效工具，特别是在动态数据模态（如IMU信号）中。
## math.NA

### [89] [Multiresolution local smoothness detection in non-uniformly sampled multivariate signals](https://arxiv.org/abs/2507.13480)
*Sara Avesani,Gianluca Giacchi,Michael Multerer*

Main category: math.NA

TL;DR: 提出了一种基于小波系数衰减行为的边缘检测方法，用于非均匀采样多元信号的局部规律性检测。该方法利用快速样本变换（samplet transform）分析信号的点态规律性，并在多维和散乱数据中表现优异。

- Motivation: 传统小波方法在低维结构化数据中表现良好，但在高维和非均匀采样数据中效果有限。本文旨在解决这一问题，提供一种适用于多维和散乱数据的规律性检测方法。
- Method: 利用快速样本变换（samplet transform）分析信号的点态规律性，建立样本系数衰减与信号规律性之间的联系。
- Result: 该方法在多维和非均匀采样数据中表现出色，并通过数值实验验证了其在一维、二维和三维信号中的有效性。
- Conclusion: 样本变换为高维和散乱数据的规律性检测提供了高效工具，扩展了传统小波方法的应用范围。
## cs.NE

### [90] [Neural Architecture Search with Mixed Bio-inspired Learning Rules](https://arxiv.org/abs/2507.13485)
*Imane Hamzaoui,Riyadh Baghdadi*

Main category: cs.NE

TL;DR: 通过神经架构搜索（NAS）自动发现并混合使用不同生物启发学习规则，提升生物启发神经网络的准确性和可扩展性。

- Motivation: 生物启发神经网络在对抗鲁棒性和能量效率方面表现优异，但在准确性和可扩展性上落后于基于反向传播（BP）的模型。
- Method: 扩展NAS搜索空间以包含生物启发学习规则，自动为每层选择最佳架构和学习规则。
- Result: 混合使用不同学习规则的网络在多个数据集上创下生物启发模型的新记录，部分情况下甚至超越BP网络。
- Conclusion: 层间学习规则的多样性有助于提升准确性和可扩展性，推动进一步研究混合学习规则的应用。
## cs.CY

### [91] [Food safety trends across Europe: insights from the 392-million-entry CompreHensive European Food Safety (CHEFS) database](https://arxiv.org/abs/2507.13802)
*Nehir Kizililsoley,Floor van Meer,Osman Mutlu,Wouter F Hoenderdaal,Rosan G. Hobé,Wenjuan Mu,Arjen Gerssen,H. J. van der Fels-Klerx,Ákos Jóźwiak,Ioannis Manikas,Ali Hürriyetoǧlu,Bas H. M. van der Velden*

Main category: cs.CY

TL;DR: 论文介绍了CHEFS数据库，整合了EFSA的食品安全监测数据，解决了数据分散问题，并展示了其在分析欧洲食品安全趋势中的应用。

- Motivation: EFSA的食品安全监测数据分散且难以访问，阻碍了人工智能分析趋势和预测风险的能力。
- Method: 创建CHEFS数据库，统一和结构化EFSA的监测数据，涵盖农药残留、兽药残留和化学污染物。
- Result: CHEFS数据库成功整合数据，并用于分析2000-2024年的欧洲食品安全趋势，揭示了监测活动变化、常见不合格产品和污染物。
- Conclusion: CHEFS数据库是一个集中化的数据源和战略工具，有助于指导食品安全政策、研究和监管。
## cs.AI

### [92] [Cross-modal Causal Intervention for Alzheimer's Disease Prediction](https://arxiv.org/abs/2507.13956)
*Yutao Jin,Haowen Xiao,Jielei Chu,Fengmao Lv,Yuxiao Li,Tianrui Li*

Main category: cs.AI

TL;DR: 提出了一种名为ADPC的视觉-语言因果干预框架，用于辅助诊断阿尔茨海默病（AD），通过消除混杂因素提高分类准确性。

- Motivation: 早期识别和干预轻度认知障碍（MCI）可以延缓AD进展，但诊断AD仍面临多模态数据选择偏差和变量复杂关系的挑战。
- Method: ADPC利用大型语言模型（LLM）总结临床数据，结合MRI和fMRI图像，通过因果干预消除混杂因素，分类CN/MCI/AD。
- Result: 实验表明ADPC在区分CN/MCI/AD上表现优异，达到SOTA指标。
- Conclusion: 研究展示了因果推理与多模态学习结合在神经疾病诊断中的潜力。


### [93] [Generative AI-Driven High-Fidelity Human Motion Simulation](https://arxiv.org/abs/2507.14097)
*Hari Iyer,Neel Macwan,Atharva Jitendra Hude,Heejin Jeong,Shenghan Guo*

Main category: cs.AI

TL;DR: 该研究提出了一种基于生成式AI的人体运动模拟方法（G-AI-HMS），通过结合文本到文本和文本到运动模型，提高了工业任务中运动模拟的保真度。

- Motivation: 现有的人体运动模拟方法在运动保真度上表现不佳，影响了工业任务中工人行为、安全和生产效率的评估。
- Method: G-AI-HMS利用大型语言模型将任务描述转化为运动感知语言，并通过计算机视觉验证AI生成的运动与真实人类动作的相似性。
- Result: 在八项任务的案例研究中，AI增强的运动在大多数场景中表现优于人工描述，显著降低了关节误差和时间错位。
- Conclusion: G-AI-HMS显著提升了运动模拟的质量，为工业任务提供了更可靠的评估工具。
## cs.CR

### [94] [A Novel APVD Steganography Technique Incorporating Pseudorandom Pixel Selection for Robust Image Security](https://arxiv.org/abs/2507.13367)
*Mehrab Hosain,Rajiv Kapoor*

Main category: cs.CR

TL;DR: 提出了一种结合APVD和伪随机像素选择的新型隐写方法，解决了传统APVD中的“未使用块”问题，提升了安全性、嵌入容量和图像质量。

- Motivation: 传统APVD方法存在“未使用块”问题，导致安全性降低、嵌入容量受限和图像质量下降。
- Method: 结合APVD与伪随机像素选择，优化像素嵌入策略。
- Result: 新方法在安全性、嵌入容量和图像质量（PSNR、UIQ、SSIM）上优于现有技术。
- Conclusion: 该方法适用于多种图像类型，确保安全传输且不损害图像质量。


### [95] [GIFT: Gradient-aware Immunization of diffusion models against malicious Fine-Tuning with safe concepts retention](https://arxiv.org/abs/2507.13598)
*Amro Abdalla,Ismail Shaheen,Dan DeGenaro,Rupayan Mallick,Bogdan Raita,Sarah Adel Bargal*

Main category: cs.CR

TL;DR: GIFT是一种梯度感知免疫技术，用于防御扩散模型免受恶意微调攻击，同时保留其生成安全内容的能力。

- Motivation: 现有安全机制（如安全检查器）易被绕过，概念擦除方法在对抗性微调下失效，因此需要一种更鲁棒的防御方法。
- Method: GIFT将免疫问题建模为双层优化问题：上层目标通过表示噪声和最大化降低有害概念的表示能力，下层目标保留安全数据的性能。
- Result: 实验表明，GIFT显著削弱模型重新学习有害概念的能力，同时保持安全内容的生成质量。
- Conclusion: GIFT为构建抗对抗性微调攻击的安全生成模型提供了有前景的方向。
## q-bio.NC

### [96] [Convergent transformations of visual representation in brains and models](https://arxiv.org/abs/2507.13941)
*Pablo Marcos-Manchón,Lluís Fuentemilla*

Main category: q-bio.NC

TL;DR: 研究探讨视觉感知是由外部世界结构还是大脑内部架构塑造，发现人类和深度神经网络在视觉编码中存在共同的表征轨迹。

- Motivation: 探索视觉感知的驱动因素，验证人类和人工视觉系统是否遵循相似的编码原则。
- Method: 结合跨被试相似性和模型层次对齐的统一框架，分析三个独立fMRI数据集。
- Result: 发现一个跨个体保守的双通路网络，与视觉DNN层次一致，语言模型则不符。
- Conclusion: 人类和人工视觉系统对外部世界结构的编码存在收敛的计算解决方案。
## eess.IV

### [97] [Flatten Wisely: How Patch Order Shapes Mamba-Powered Vision for MRI Segmentation](https://arxiv.org/abs/2507.13384)
*Osama Hardan,Omar Elshenhabi,Tamer Khattab,Mohamed Mabrok*

Main category: eess.IV

TL;DR: 研究了Vision Mamba模型中图像扫描顺序对MRI分割性能的影响，提出了一种参数无关的多扫描模块MS2D，发现扫描顺序对性能有显著影响。

- Motivation: Vision Mamba模型在医学图像处理中依赖1D序列化2D图像，但扫描顺序的设计选择未被充分研究，尤其是在具有强解剖先验的MRI中。
- Method: 提出MS2D模块，评估21种扫描策略在三个公开数据集上的性能，使用Friedman检验分析统计显著性。
- Result: 扫描顺序对性能影响显著（Dice分数差异达27点），空间连续的扫描路径（如水平或垂直）表现最佳。
- Conclusion: 扫描顺序是Vision Mamba模型中的重要超参数，研究提供了优化路径的实证建议。


### [98] [Enhanced DeepLab Based Nerve Segmentation with Optimized Tuning](https://arxiv.org/abs/2507.13394)
*Akhil John Thomas,Christiaan Boerkamp*

Main category: eess.IV

TL;DR: 论文提出了一种基于DeepLabV3的优化神经分割方法，通过自动阈值微调和参数优化，显著提升了超声神经图像的分割精度。

- Motivation: 神经分割在医学影像中对精确识别神经结构至关重要，但现有方法在分割精度上仍有提升空间。
- Method: 采用DeepLabV3框架，结合自动阈值微调和参数优化，改进了预处理步骤。
- Result: 在超声神经图像上取得了Dice Score 0.78、IoU 0.70和Pixel Accuracy 0.95的优异结果。
- Conclusion: 优化后的方法显著优于基线模型，强调了参数选择在自动化神经检测中的重要性。


### [99] [Domain-randomized deep learning for neuroimage analysis](https://arxiv.org/abs/2507.13458)
*Malte Hoffmann*

Main category: eess.IV

TL;DR: 深度学习通过合成多样化数据训练模型，解决了神经影像分析中的泛化问题，适用于多种成像技术。

- Motivation: 解决深度学习在神经影像分析中因训练数据范围狭窄导致的模型泛化能力不足问题。
- Method: 采用域随机化策略，通过合成随机强度和内容的图像训练深度神经网络。
- Result: 模型能够处理未见过的图像类型，无需重新训练或微调，适用于多种成像技术。
- Conclusion: 合成驱动训练范式提升了模型泛化能力，但需权衡计算资源需求，有望加速通用工具的开发。


### [100] [BreastSegNet: Multi-label Segmentation of Breast MRI](https://arxiv.org/abs/2507.13604)
*Qihang Li,Jichen Yang,Yaqian Chen,Yuwen Chen,Hanxue Gu,Lars J. Grimm,Maciej A. Mazurowski*

Main category: eess.IV

TL;DR: BreastSegNet是一种多标签分割算法，用于乳腺MRI，覆盖9种解剖结构，性能优于现有模型。

- Motivation: 现有乳腺MRI分割方法仅关注少数解剖结构，限制了定量分析的实用性。
- Method: 提出BreastSegNet，手动标注1123张MRI切片，并对比9种分割模型。
- Result: nnU-Net ResEncM表现最佳，平均Dice分数0.694，部分结构分数接近0.90。
- Conclusion: BreastSegNet扩展了乳腺MRI分割的范围，模型和数据将公开。


### [101] [Converting T1-weighted MRI from 3T to 7T quality using deep learning](https://arxiv.org/abs/2507.13782)
*Malo Gicquel,Ruoyi Zhao,Anika Wuestefeld,Nicola Spotorno,Olof Strandberg,Kalle Åström,Yu Xiao,Laura EM Wisse,Danielle van Westen,Rik Ossenkoppele,Niklas Mattsson-Carlgren,David Berron,Oskar Hansson,Gabrielle Flood,Jacob Vogel*

Main category: eess.IV

TL;DR: 利用深度学习模型从3T MRI合成7T MRI，提升图像质量和分割效果，不影响下游任务性能。

- Motivation: 7T MRI提供更高分辨率和组织对比度，但普及性受限。研究旨在通过3T MRI合成接近7T质量的图像。
- Method: 训练了两种模型：专用U-Net和结合GAN的U-Net，使用172名参与者的配对3T和7T T1加权图像。
- Result: 合成7T图像在细节上与真实7T图像相当，主观视觉质量更优，且自动分割效果更接近人工分割。
- Conclusion: 合成7T图像可提升图像质量和分割效果，未来需探讨临床应用的可行性和局限性。


### [102] [Divide and Conquer: A Large-Scale Dataset and Model for Left-Right Breast MRI Segmentation](https://arxiv.org/abs/2507.13830)
*Maximilian Rokuss,Benjamin Hamm,Yannick Kirchhoff,Klaus Maier-Hein*

Main category: eess.IV

TL;DR: 公开首个带有左右乳房分割标签的乳腺MRI数据集，包含13,000多个标注案例，并提供深度学习模型。

- Motivation: 解决乳腺MRI分析中的关键空白，为女性健康工具开发提供资源。
- Method: 提供公开数据集和训练好的深度学习模型。
- Result: 数据集和模型已公开可用。
- Conclusion: 为乳腺MRI分析提供了重要工具和资源。


### [103] [Software architecture and manual for novel versatile CT image analysis toolbox -- AnatomyArchive](https://arxiv.org/abs/2507.13901)
*Lei Xu,Torkel B Brismar*

Main category: eess.IV

TL;DR: AnatomyArchive是一个基于TotalSegmentator的CT图像分析工具包，提供自动目标体积选择、解剖结构管理、体素特征提取等功能，支持2D和3D分析，并包含GPU加速的渲染工具。

- Motivation: 开发一个高效、自动化的CT图像分析工具，以支持精确的身体成分分析和医学图像数据库管理。
- Method: 基于知识图谱和TotalSegmentator模型，实现自动体积选择、解剖结构管理和特征提取，并提供GPU加速的渲染工具。
- Result: 实现了自动目标体积选择、解剖结构管理、体素特征提取等功能，并支持2D和3D分析。
- Conclusion: AnatomyArchive是一个功能强大的开源工具，适用于医学图像分析和机器学习模型开发。


### [104] [Blind Super Resolution with Reference Images and Implicit Degradation Representation](https://arxiv.org/abs/2507.13915)
*Huu-Phu Do,Po-Chih Hu,Hao-Chien Hsueh,Che-Kai Liu,Vu-Hoang Tran,Ching-Chun Huang*

Main category: eess.IV

TL;DR: 提出了一种基于参考图像的方法，用于盲超分辨率任务，通过HR参考图像生成尺度感知的退化核，显著提升了性能。

- Motivation: 现有盲超分辨率方法直接估计退化核，但忽略了不同超分辨率尺度下的适用性问题，需同时考虑退化过程和缩放因子。
- Method: 利用HR参考图像与目标LR图像，自适应地学习退化过程，生成额外的LR-HR对以提升超分辨率性能。
- Result: 在盲超分辨率任务中，该方法在训练模型和零样本方法中均优于先前方法。
- Conclusion: 结合模糊核和缩放因子，并利用参考图像，显著提升了盲超分辨率任务的效果。


### [105] [Leveraging Pathology Foundation Models for Panoptic Segmentation of Melanoma in H&E Images](https://arxiv.org/abs/2507.13974)
*Jiaqi Lv,Yijie Zhu,Carmen Guadalupe Colin Tenorio,Brinder Singh Chohan,Mark Eastwood,Shan E Ahmed Raza*

Main category: eess.IV

TL;DR: 提出一种基于深度学习的新型网络，用于黑色素瘤H&E图像中五种组织类别的分割，利用病理学基础模型Virchow2提取特征，结合Efficient-UNet实现高精度分割。

- Motivation: 黑色素瘤组织形态的准确表征对预后和治疗规划至关重要，但手动分割耗时且易受观察者差异影响，因此需要可靠的自动化方法。
- Method: 使用Virchow2病理学基础模型提取特征，与原始RGB图像融合后，通过Efficient-UNet编码器-解码器网络生成分割图。
- Result: 模型在PUMA Grand Challenge的组织分割任务中获得第一名，表现出鲁棒性和泛化能力。
- Conclusion: 研究表明，将病理学基础模型融入分割网络可加速计算病理学工作流程，具有潜在的高效性。


### [106] [OrthoInsight: Rib Fracture Diagnosis and Report Generation Based on Multi-Modal Large Models](https://arxiv.org/abs/2507.13993)
*Ningyong Wu,Jinzhi Wang,Wenhong Zhao,Chenzhan Yu,Zhigang Xiu,Duwei Dai*

Main category: eess.IV

TL;DR: OrthoInsight是一个多模态深度学习框架，用于肋骨骨折诊断和报告生成，结合了YOLOv9、医学知识图谱和LLaVA语言模型，性能优于GPT-4和Claude-3。

- Motivation: 医疗影像数据增长迅速，手动诊断耗时且易出错，需要自动化工具提高效率和准确性。
- Method: 提出OrthoInsight框架，整合YOLOv9检测骨折、医学知识图谱提供临床背景、LLaVA生成报告，结合视觉和文本数据。
- Result: 在28,675张CT图像上评估，OrthoInsight在诊断准确性、内容完整性、逻辑连贯性和临床指导价值上平均得分4.28，优于GPT-4和Claude-3。
- Conclusion: 多模态学习在医学影像分析中潜力巨大，可为放射科医生提供有效支持。


### [107] [D2IP: Deep Dynamic Image Prior for 3D Time-sequence Pulmonary Impedance Imaging](https://arxiv.org/abs/2507.14046)
*Hao Fang,Hao Yu,Sihao Teng,Tao Zhang,Siyi Yuan,Huaiwu He,Zhe Liu,Yunjie Yang*

Main category: eess.IV

TL;DR: 论文提出了一种名为D2IP的新框架，用于3D时间序列成像，通过三种策略加速收敛、增强时间一致性和计算效率，显著提升了图像质量和计算速度。

- Motivation: 现有的无监督学习方法（如DIP）在断层成像中表现优异，但计算成本高，限制了其在复杂3D或时间序列任务中的应用。
- Method: D2IP引入了三种策略：无监督参数预热启动（UPWS）、时间参数传播（TPP）和轻量级重建骨干网络3D-FastResUNet。
- Result: 在模拟和临床肺部数据集上，D2IP实现了快速准确的3D时间序列电阻抗断层成像（tsEIT）重建，图像质量提升（MSSIM增加24.8%，ERR降低8.1%），计算时间减少7.1倍。
- Conclusion: D2IP在动态肺部成像中展现出显著潜力，为临床应用提供了高效解决方案。


### [108] [UGPL: Uncertainty-Guided Progressive Learning for Evidence-Based Classification in Computed Tomography](https://arxiv.org/abs/2507.14102)
*Shravan Venkatraman,Pavan Kumar S,Rakesh Raj Madavan,Chandrakala S*

Main category: eess.IV

TL;DR: UGPL是一种不确定性引导的渐进学习框架，通过全局到局部分析提升CT图像分类准确性，显著优于现有方法。

- Motivation: 现有CT图像分类方法难以处理病理特征的细微和空间多样性，UGPL旨在通过聚焦关键区域解决这一问题。
- Method: UGPL结合证据深度学习量化预测不确定性，通过非极大值抑制机制提取信息丰富的区域，并采用自适应融合机制整合上下文和细节。
- Result: 在三个CT数据集上，UGPL在肾脏异常、肺癌和COVID-19检测中的准确率分别提高了3.29%、2.46%和8.08%。
- Conclusion: UGPL通过不确定性引导和渐进学习显著提升了CT图像分类性能，证明了其在实际应用中的潜力。
## cs.RO

### [109] [Safety Certification in the Latent space using Control Barrier Functions and World Models](https://arxiv.org/abs/2507.13871)
*Mehul Anand,Shishir Kolathaya*

Main category: cs.RO

TL;DR: 提出了一种半监督框架，利用世界模型的潜在空间中的控制屏障证书（CBCs）来合成安全的视觉运动策略。

- Motivation: 从视觉数据合成安全控制器通常需要大量标记安全关键数据，这在现实场景中往往不切实际。
- Method: 联合学习神经屏障函数和安全控制器，利用现代视觉变换器的预测能力进行潜在动力学建模。
- Result: 通过有限的标记数据和潜在空间的预测能力，实现了安全控制器的合成。
- Conclusion: 该方法为可扩展且数据高效的安全控制提供了新途径。
