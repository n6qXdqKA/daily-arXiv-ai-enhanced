[[toc]]

## cs.CV

### [1] [Multimodal Cinematic Video Synthesis Using Text-to-Image and Audio Generation Models](https://arxiv.org/abs/2506.10005)
*Sridhar S,Nithin A,Shakeel Rifath,Vasantha Raj*

Main category: cs.CV

TL;DR: 论文提出了一种基于Stable Diffusion、GPT-2和混合音频管道的自动生成60秒电影的方法，通过五场景框架和后期处理实现专业级效果。

- Motivation: 利用生成式AI技术改进多媒体创作，实现从文本到高质量视频的自动合成。
- Method: 结合Stable Diffusion生成图像，GPT-2构建叙事，混合音频管道（gTTS和YouTube音乐），并采用五场景框架、帧插值和后期处理。
- Result: 实验显示视频具有出色的视觉质量、叙事连贯性和效率。
- Conclusion: 该方法推动了文本到视频合成在创意、教育和工业领域的应用。


### [2] [LoRA-Edit: Controllable First-Frame-Guided Video Editing via Mask-Aware LoRA Fine-Tuning](https://arxiv.org/abs/2506.10082)
*Chenjian Gao,Lihe Ding,Xin Cai,Zhanpeng Huang,Zibin Wang,Tianfan Xue*

Main category: cs.CV

TL;DR: 提出了一种基于掩码的LoRA调优方法，用于灵活的视频编辑，无需改变模型架构。

- Motivation: 当前视频编辑方法依赖大规模预训练，缺乏灵活性，且首帧引导编辑对后续帧控制不足。
- Method: 采用掩码驱动的LoRA调优策略，结合输入视频和参考图像，动态调节模型注意力。
- Result: 实验表明，该方法在视频编辑性能上优于现有技术。
- Conclusion: 该方法实现了高效、灵活的视频编辑，同时保留了背景区域。


### [3] [DeepTraverse: A Depth-First Search Inspired Network for Algorithmic Visual Understanding](https://arxiv.org/abs/2506.10084)
*Bin Guo,John H. L. Hansen*

Main category: cs.CV

TL;DR: DeepTraverse是一种新型视觉架构，受算法搜索策略启发，通过系统性阐明和自适应细化学习特征，优于传统方法。

- Motivation: 传统视觉主干网络的特征构建方式单一，缺乏自适应迭代细化路径，能否通过算法搜索原则实现更结构化、逻辑化的处理流程？
- Method: DeepTraverse包含递归探索模块（深化特征分析）和自适应校准模块（动态调整特征显著性）。
- Result: 在多个图像分类基准测试中，DeepTraverse表现出色，分类准确性和特征区分度优于传统模型。
- Conclusion: 引入算法先验是一种高效、性能优越且结构化的视觉主干构建策略。


### [4] [Test-Time Adaptation for Generalizable Task Progress Estimation](https://arxiv.org/abs/2506.10085)
*Christos Ziakas,Alessandra Russo*

Main category: cs.CV

TL;DR: 提出一种测试时自适应方法，通过优化自监督目标，使进度估计模型能够在线适应测试轨迹的视觉和时间上下文。

- Motivation: 解决进度估计模型在多样化的任务、环境和体现中泛化能力不足的问题。
- Method: 采用基于梯度的元学习策略，结合专家视觉轨迹和自然语言任务描述进行训练，测试时通过语义内容优化进度估计。
- Result: 方法在多样化的分布外任务、环境和体现中表现优于当前最先进的上下文学习方法。
- Conclusion: 测试时自适应方法显著提升了进度估计模型的泛化能力。


### [5] [EfficientVLA: Training-Free Acceleration and Compression for Vision-Language-Action Models](https://arxiv.org/abs/2506.10100)
*Yantai Yang,Yuhao Wang,Zichen Wen,Luo Zhongwei,Chang Zou,Zhipeng Zhang,Chuan Wen,Linfeng Zhang*

Main category: cs.CV

TL;DR: EfficientVLA是一个训练无关的推理加速框架，通过协同利用多方面的冗余性，显著提升了Vision-Language-Action（VLA）模型的效率。

- Motivation: 现有的VLA模型（如基于扩散架构的模型）因计算和内存需求过高而受限，现有加速方法未能全面解决其多样化的瓶颈问题。
- Method: EfficientVLA整合了三种策略：1）语言模块的冗余层剪枝；2）任务感知的视觉令牌优化；3）扩散动作头的中间特征缓存。
- Result: 在CogACT模型上，EfficientVLA实现了1.93倍的推理加速，FLOPs降至28.9%，成功率仅下降0.6%。
- Conclusion: EfficientVLA通过系统性冗余消除，显著提升了VLA模型的实用性和部署效率。


### [6] [A Manually Annotated Image-Caption Dataset for Detecting Children in the Wild](https://arxiv.org/abs/2506.10117)
*Klim Kireev,Ana-Maria Creţu,Raphael Meier,Sarah Adel Bargal,Elissa Redmiles,Carmela Troncoso*

Main category: cs.CV

TL;DR: 论文介绍了首个多模态环境下检测未成年人内容的基准数据集ICCWD，包含1万张图像-标题对，并测试了三种检测方法，最高准确率为75.3%。

- Motivation: 目前缺乏用于多模态环境下检测未成年人内容的数据集或基准，因此作者填补了这一空白。
- Method: 作者构建了ICCWD数据集，包含多样化的未成年人图像及标题，并测试了三种检测方法。
- Result: 最佳检测方法的真阳性率为75.3%，表明未成年人检测任务具有挑战性。
- Conclusion: ICCWD数据集的发布有望推动更高效的未成年人检测方法的设计。


### [7] [Detecção da Psoríase Utilizando Visão Computacional: Uma Abordagem Comparativa Entre CNNs e Vision Transformers](https://arxiv.org/abs/2506.10119)
*Natanael Lucena,Fábio S. da Silva,Ricardo Rios*

Main category: cs.CV

TL;DR: 比较了CNN和ViT在多分类银屑病及类似疾病图像中的性能，ViT表现更优，尤其是DaViT-B模型，F1分数达96.4%。

- Motivation: 探索CNN和ViT在医学图像分类任务中的表现差异，尤其是银屑病检测。
- Method: 使用ImageNet预训练的CNN和ViT模型，适配特定数据集进行多分类任务。
- Result: ViT表现优于CNN，DaViT-B模型F1分数最高（96.4%）。
- Conclusion: ViT在医学图像分类中潜力显著，DaViT-B是银屑病自动检测的高效架构。


### [8] [ViCrit: A Verifiable Reinforcement Learning Proxy Task for Visual Perception in VLMs](https://arxiv.org/abs/2506.10128)
*Xiyao Wang,Zhengyuan Yang,Chao Feng,Yongyuan Liang,Yuhang Zhou,Xiaoyu Liu,Ziyi Zang,Ming Li,Chung-Ching Lin,Kevin Lin,Linjie Li,Furong Huang,Lijuan Wang*

Main category: cs.CV

TL;DR: ViCrit任务通过训练视觉语言模型定位合成视觉幻觉，提升视觉感知能力，并在多种基准测试中表现优异。

- Motivation: 解决视觉语言模型在视觉感知任务中缺乏挑战性且明确可验证任务的难题。
- Method: 引入ViCrit任务，通过注入细微视觉描述错误并让模型定位错误，提供二进制精确匹配奖励。
- Result: 模型在多种视觉语言基准测试中表现显著提升，且能力可迁移至抽象图像推理和视觉数学任务。
- Conclusion: ViCrit任务是一种有效且通用的方法，可增强视觉语言模型的视觉感知能力。


### [9] [RoCA: Robust Cross-Domain End-to-End Autonomous Driving](https://arxiv.org/abs/2506.10145)
*Rajeev Yasarla,Shizhong Han,Hsin-Pai Cheng,Litian Liu,Shweta Mahajan,Apratim Bhattacharyya,Yunxiao Shi,Risheek Garrepalli,Hong Cai,Fatih Porikli*

Main category: cs.CV

TL;DR: RoCA是一个用于跨域端到端自动驾驶的框架，通过联合概率分布建模和基令牌学习，提升模型的泛化能力和适应性。

- Motivation: 解决跨域自动驾驶部署的挑战，避免大语言模型的高成本重新训练问题。
- Method: 使用高斯过程联合建模车辆信息令牌，学习基令牌及其轨迹，实现概率推断未来轨迹。
- Result: RoCA显著提升基础模型的泛化能力，并在新域上表现优于直接微调。
- Conclusion: RoCA在跨域场景中表现出强大的泛化和适应能力。


### [10] [SPARKE: Scalable Prompt-Aware Diversity Guidance in Diffusion Models via RKE Score](https://arxiv.org/abs/2506.10173)
*Mohammad Jalali,Haoyu Lei,Amin Gohari,Farzan Farnia*

Main category: cs.CV

TL;DR: 论文提出SPARKE方法，通过条件熵实现提示感知的多样性控制，显著提升生成样本的多样性，同时降低计算复杂度。

- Motivation: 现有提示引导扩散模型在生成样本多样性方面存在不足，尤其是在语义广泛的提示下，需要一种高效的方法来评估和控制多样性。
- Method: 提出SPARKE方法，利用条件熵进行多样性引导，动态测量相似提示的多样性，并通过简化计算复杂度（从O(n^3)降至O(n)）实现大规模生成。
- Result: 实验表明，SPARKE在多个文本到图像扩散模型中显著提升了生成数据的提示感知多样性，且计算成本较低。
- Conclusion: SPARKE方法有效解决了提示感知多样性控制的挑战，为大规模生成任务提供了高效解决方案。


### [11] [Retrieval of Surface Solar Radiation through Implicit Albedo Recovery from Temporal Context](https://arxiv.org/abs/2506.10174)
*Yael Frischholz,Devis Tuia,Michael Lehning*

Main category: cs.CV

TL;DR: 论文提出了一种基于注意力机制的模拟器，用于从卫星图像序列中学习推断晴空地表反射率，以改进山区地表太阳辐射（SSR）的检索。

- Motivation: 传统方法在山区因间歇性雪覆盖和动态雪表面而失效，需要一种更灵活的方法来准确估计晴空地表反射率。
- Method: 采用基于时空视觉变换器的注意力模拟器，无需手工特征（如反照率图或云掩膜），输入多光谱卫星图像、静态地形特征和太阳几何数据，训练目标是HelioMont算法的SSR估计。
- Result: 模型在提供足够长的时间上下文时，性能与基于反照率的方法相当，尤其在山区表现突出，提升了简单和复杂地形下的泛化能力。
- Conclusion: 该方法能够内部学习地表反射率动态，为山区SSR检索提供了有效解决方案，代码和数据集已公开。


### [12] [Attention, Please! Revisiting Attentive Probing for Masked Image Modeling](https://arxiv.org/abs/2506.10178)
*Bill Psomas,Dionysis Christopoulos,Eirini Baltzi,Ioannis Kakogeorgiou,Tilemachos Aravanis,Nikos Komodakis,Konstantinos Karantzalos,Yannis Avrithis,Giorgos Tolias*

Main category: cs.CV

TL;DR: 论文提出了一种高效探测方法（EP），通过多查询交叉注意力机制改进现有注意力探测方法，显著提升了计算效率和性能。

- Motivation: 由于线性探测（LP）无法充分评估掩码图像建模（MIM）模型的潜力，且现有注意力探测方法存在参数冗余和计算效率低的问题，论文旨在探索更高效的注意力探测方法。
- Method: 引入高效探测（EP），采用多查询交叉注意力机制，减少冗余投影和可训练参数，提升计算效率。
- Result: EP在七个基准测试中优于LP和现有注意力探测方法，计算速度提升10倍，并在低样本和分层设置中表现优异。
- Conclusion: EP是一种高效、通用且可解释的注意力探测方法，适用于多种预训练范式。


### [13] [Improving Personalized Search with Regularized Low-Rank Parameter Updates](https://arxiv.org/abs/2506.10182)
*Fiona Ryan,Josef Sivic,Fabian Caba Heilbron,Judy Hoffman,James M. Rehg,Bryan Russell*

Main category: cs.CV

TL;DR: 本文提出了一种通过低秩适应调整视觉-语言双编码器模型的方法，用于个性化视觉-语言检索，显著提升了性能。

- Motivation: 个性化视觉-语言检索需要从少量示例中学习新概念，并整合个人与通用知识，现有方法难以兼顾。
- Method: 采用正则化低秩适应调整语言编码器最后一层的少量参数，结合参数加法策略整合多个个人概念。
- Result: 在两个基准测试（DeepFashion2和ConCon-Chi）上，个性化检索准确率比现有方法提升4%-22%。
- Conclusion: 该方法在保留通用知识的同时，有效实现了个性化概念的识别，为个性化检索提供了新思路。


### [14] [ScoreMix: Improving Face Recognition via Score Composition in Diffusion Generators](https://arxiv.org/abs/2506.10226)
*Parsa Rahimi,Sebastien Marcel*

Main category: cs.CV

TL;DR: ScoreMix是一种基于扩散模型的数据增强策略，通过混合不同类别的分数生成具有挑战性的合成样本，显著提升判别器性能，尤其在标注数据有限的情况下。

- Motivation: 解决标注数据有限时判别器性能不足的问题，利用扩散模型的分数组合特性生成高质量合成样本。
- Method: 通过凸组合扩散采样中不同类条件轨迹的分数，生成合成样本，并研究类别选择策略。
- Result: 在多个基准测试中显著提升判别器性能，发现混合判别器嵌入空间中距离较远的类别效果更好。
- Conclusion: ScoreMix无需大量参数搜索即可显著提升性能，为训练判别模型提供实用优势，同时缓解大数据集需求问题。


### [15] [California Crop Yield Benchmark: Combining Satellite Image, Climate, Evapotranspiration, and Soil Data Layers for County-Level Yield Forecasting of Over 70 Crops](https://arxiv.org/abs/2506.10228)
*Hamid Kamangir,Mona Hajiesmaeeli,Mason Earles*

Main category: cs.CV

TL;DR: 加州农业产量占美国总产量的12.5%，但准确预测作物产量仍具挑战。研究提出一个多模态深度学习模型，结合卫星影像、气候和土壤数据，预测效果显著（R2=0.76）。

- Motivation: 加州农业在全球占重要地位，但复杂的环境和气候因素使产量预测困难。研究旨在通过整合多源数据提高预测准确性。
- Method: 开发多模态深度学习模型，结合Landsat卫星影像、气候记录、土壤数据等，采用分层特征提取和时间序列编码。
- Result: 模型在测试数据集上R2得分为0.76，表现优异。
- Conclusion: 该模型和数据集为农业预测、气候适应和精准农业提供了重要基础，数据和代码已公开。


### [16] [DySS: Dynamic Queries and State-Space Learning for Efficient 3D Object Detection from Multi-Camera Videos](https://arxiv.org/abs/2506.10242)
*Rajeev Yasarla,Shizhong Han,Hong Cai,Fatih Porikli*

Main category: cs.CV

TL;DR: DySS是一种基于状态空间学习和动态查询的3D目标检测方法，通过稀疏查询和动态更新策略提升性能与效率。

- Motivation: 解决传统BEV方法计算成本高和稀疏查询方法在多帧视频中效率低的问题。
- Method: 利用状态空间模型（SSM）处理时序特征，引入未来预测和掩码重建任务优化训练，动态更新查询（合并、删除、拆分）。
- Result: 在nuScenes测试集上达到65.31 NDS和57.4 mAP，验证集上56.2 NDS和46.2 mAP，实时推理速度33 FPS。
- Conclusion: DySS在性能和效率上均优于现有方法，适用于自动驾驶感知任务。


### [17] [HalLoc: Token-level Localization of Hallucinations for Vision Language Models](https://arxiv.org/abs/2506.10286)
*Eunkyu Park,Minyeong Kim,Gunhee Kim*

Main category: cs.CV

TL;DR: 论文提出HalLoc数据集，用于高效、概率性的幻觉检测，包含15万标注样本，并开发了一个低开销的基线模型。

- Motivation: 解决现有幻觉检测方法计算成本高、无法处理模糊边界的问题。
- Method: 构建HalLoc数据集，训练低开销基线模型，支持并发检测。
- Result: 数据集和模型公开，可提升视觉语言模型的可靠性。
- Conclusion: HalLoc为增强视觉语言模型的信任度提供了新途径。


### [18] [Uncertainty-Aware Deep Learning for Automated Skin Cancer Classification: A Comprehensive Evaluation](https://arxiv.org/abs/2506.10302)
*Hamzeh Asgharnezhad,Pegah Tabarisaadi,Abbas Khosravi,Roohallah Alizadehsani,U. Rajendra Acharya*

Main category: cs.CV

TL;DR: 该研究通过迁移学习和不确定性量化（UQ）评估了深度学习模型在皮肤癌分类中的表现，发现基于CLIP的视觉变换器性能最佳，而集成方法在准确性和不确定性处理之间取得了良好平衡。

- Motivation: 皮肤癌的准确诊断对早期治疗至关重要，但现有深度学习模型受限于数据稀缺和缺乏不确定性意识。
- Method: 研究分两阶段：1）使用预训练特征提取器和传统分类器进行基准测试；2）引入UQ方法（MCD、集成、EMCD）评估模型输出的可靠性。
- Result: CLIP-based视觉变换器（如LAION CLIP ViT-H/14）性能最佳；集成方法在准确性和不确定性处理上表现良好，EMCD对不确定预测更敏感。
- Conclusion: 将UQ整合到基于深度学习的医疗诊断中，可提升性能和临床应用的可靠性。


### [19] [Towards Scalable SOAP Note Generation: A Weakly Supervised Multimodal Framework](https://arxiv.org/abs/2506.10328)
*Sadia Kamal,Tim Oates,Joy Wan*

Main category: cs.CV

TL;DR: 提出一种弱监督多模态框架，从有限输入生成临床结构化SOAP笔记，减轻医生负担。

- Motivation: 手动生成SOAP笔记耗时且导致医生疲劳，需自动化解决方案。
- Method: 使用弱监督多模态框架，结合病变图像和稀疏临床文本生成SOAP笔记。
- Result: 性能媲美GPT-4o等模型，并引入MedConceptEval和CCS评估临床质量。
- Conclusion: 框架可扩展且减少对标注数据的依赖，提升临床文档效率。


### [20] [Research on Audio-Visual Quality Assessment Dataset and Method for User-Generated Omnidirectional Video](https://arxiv.org/abs/2506.10331)
*Fei Zhao,Da Pan,Zelu Qi,Ping Shi*

Main category: cs.CV

TL;DR: 论文针对元宇宙中用户生成的全向视频（ODV）的视听质量评估（AVQA）问题，构建了一个数据集，并提出了一种基线模型。

- Motivation: 随着元宇宙的兴起，全向视频（ODV）从专业生成内容（PGC）转向用户生成内容（UGC），但对其视听质量评估的研究仍有限。
- Method: 构建了一个包含300个UGC ODV视频的数据集，并进行了主观AVQA实验。提出了一种基于视频特征提取、音频特征提取和视听融合模块的基线模型。
- Result: 实验结果表明，该模型在提出的数据集上表现最优。
- Conclusion: 该研究为UGC-ODV的AVQA领域提供了数据集和有效的基线模型。


### [21] [Using Vision Language Models to Detect Students' Academic Emotion through Facial Expressions](https://arxiv.org/abs/2506.10334)
*Deliang Wang,Chao Yang,Gaowei Chen*

Main category: cs.CV

TL;DR: 研究探讨了视觉语言模型（VLMs）在零样本提示下分析学生学术情绪的潜力，发现Qwen2.5-VL-7B-Instruct在识别困惑和快乐情绪上表现优于Llama-3.2-11B-Vision-Instruct，但两者均无法识别分心行为。

- Motivation: 传统监督学习方法在跨场景泛化上表现不佳，需要反复数据收集和训练，而VLMs提供了一种无需微调即可泛化的新方法。
- Method: 使用两种VLMs（Llama-3.2-11B-Vision-Instruct和Qwen2.5-VL-7B-Instruct）对5000张学生面部表情图像进行零样本分析，涵盖困惑、分心、快乐、中立和疲惫情绪。
- Result: Qwen2.5-VL-7B-Instruct在识别困惑和快乐情绪上表现更好，但两种模型均无法识别分心行为。
- Conclusion: VLMs在学术情绪分析中具有潜力，尤其是Qwen2.5-VL-7B-Instruct在识别困惑情绪上表现突出，但需进一步改进以识别分心行为。


### [22] [PointGS: Point Attention-Aware Sparse View Synthesis with Gaussian Splatting](https://arxiv.org/abs/2506.10335)
*Lintao Xiang,Hongpei Zheng,Yating Huang,Qijun Yang,Hujun Yin*

Main category: cs.CV

TL;DR: 提出了一种基于点特征感知的高斯泼溅框架，解决了3D高斯泼溅在稀疏视图输入时过拟合的问题，实现了实时高质量渲染。

- Motivation: 现有3D高斯泼溅方法需要大量校准视图，稀疏输入时容易过拟合，导致渲染质量下降。
- Method: 使用立体基础模型估计相机姿态和稠密点云，通过多尺度2D特征采样和自注意力点交互网络增强高斯点表示，最后用轻量级MLP解码为高斯参数。
- Result: 在多种基准测试中显著优于NeRF方法，在少样本设置下与最先进的3DGS方法竞争。
- Conclusion: 该方法在稀疏视图输入下实现了高质量实时渲染，解决了3DGS的过拟合问题。


### [23] [GeoCAD: Local Geometry-Controllable CAD Generation](https://arxiv.org/abs/2506.10337)
*Zhanwei Zhang,Kaiyuan Liu,Junjie Liu,Wenxiao Wang,Binbin Lin,Liang Xie,Chen Shen,Deng Cai*

Main category: cs.CV

TL;DR: GeoCAD是一种用户友好的局部几何可控CAD生成方法，通过互补标注策略生成局部几何指令，并利用LLM预测缺失部分。

- Motivation: 现有方法无法同时满足文本指令跟随和局部修改需求，GeoCAD旨在解决这一问题。
- Method: 提出互补标注策略（顶点和VLLM标注），训练时随机掩码局部部分，利用几何指令和剩余部分输入LLM预测。
- Result: 实验证明GeoCAD在生成质量、有效性和文本-CAD一致性方面表现优异。
- Conclusion: GeoCAD成功实现了局部几何可控的CAD生成，代码将开源。


### [24] [UrbanSense:AFramework for Quantitative Analysis of Urban Streetscapes leveraging Vision Large Language Models](https://arxiv.org/abs/2506.10342)
*Jun Yin,Jing Zhong,Peilin Li,Pengyu Zeng,Miao Zhang,Ran Luo,Shuai Lu*

Main category: cs.CV

TL;DR: 该论文提出了一种基于视觉语言模型的多模态研究框架，用于自动化分析城市街景风格差异，并构建了数据集UrbanDiffBench和框架UrbanSense，实验验证了其有效性。

- Motivation: 由于地理、历史和社会政治因素，城市文化和建筑风格差异显著，传统研究方法难以标准化，因此需要一种客观、数据驱动的方法来分析城市风格演变。
- Method: 提出基于视觉语言模型的多模态框架UrbanSense，构建数据集UrbanDiffBench，通过定量生成和比较城市风格表示来分析差异。
- Result: 实验结果显示，超过80%的生成描述通过t检验（p<0.05），主观评价的高Phi分数（城市0.912，时期0.833）验证了方法的有效性。
- Conclusion: 该方法能科学量化城市风格演变，为未来设计提供依据，展示了多模态框架在城市研究中的潜力。


### [25] [RealKeyMorph: Keypoints in Real-world Coordinates for Resolution-agnostic Image Registration](https://arxiv.org/abs/2506.10344)
*Mina C. Moghadam,Alan Q. Wang,Omer Taub,Martin R. Prince,Mert R. Sabuncu*

Main category: cs.CV

TL;DR: RealKeyMorph (RKM) 是一种分辨率无关的医学图像配准方法，避免了传统方法因重采样导致的伪影问题。

- Motivation: 现有机器学习配准方法需固定分辨率重采样图像，可能引入伪影，RKM旨在解决这一问题。
- Method: RKM基于KeyMorph框架，通过学习图像对的关键点并利用扫描仪提供的仿射矩阵，将关键点映射到真实世界坐标，实现分辨率无关配准。
- Result: 实验表明，RKM在腹部MRI和不同分辨率脑数据集上表现优异。
- Conclusion: RKM通过避免重采样，提供了一种更优的医学图像配准解决方案。


### [26] [Motion-R1: Chain-of-Thought Reasoning and Reinforcement Learning for Human Motion Generation](https://arxiv.org/abs/2506.10353)
*Runqi Ouyang,Haoyun Li,Zhenyuan Zhang,Xiaofeng Wang,Zheng Zhu,Guan Huang,Xingang Wang*

Main category: cs.CV

TL;DR: Motion-R1是一个结合Chain-of-Thought机制的统一运动-语言建模框架，通过分解复杂文本指令为逻辑动作路径，提升运动生成的可控性和多样性。

- Motivation: 现有文本到运动生成方法依赖端到端映射，难以捕捉深层语言结构和逻辑推理，导致生成运动缺乏可控性、一致性和多样性。
- Method: 提出Motion-R1框架，结合Chain-of-Thought机制分解指令，并采用Group Relative Policy Optimization强化学习算法联合优化推理链和运动合成。
- Result: 在多个基准数据集上，Motion-R1表现优于现有方法，尤其在需要语义理解和长期时间一致性的场景中。
- Conclusion: Motion-R1通过逻辑分解和联合优化，显著提升了运动生成的质量和多样性，代码和模型将公开。


### [27] [FaceLiVT: Face Recognition using Linear Vision Transformer with Structural Reparameterization For Mobile Device](https://arxiv.org/abs/2506.10361)
*Novendra Setyawan,Chi-Chia Sun,Mao-Hsiu Hsu,Wen-Kai Kuo,Jun-Wei Hsieh*

Main category: cs.CV

TL;DR: FaceLiVT是一种轻量级但强大的人脸识别模型，结合了CNN-Transformer架构和创新的轻量级多头线性注意力机制（MHLA），在保持高精度的同时显著降低计算复杂度。

- Motivation: 解决在资源受限平台上实现高效实时人脸识别的需求，同时平衡计算复杂度和准确性。
- Method: 采用混合CNN-Transformer架构，引入轻量级MHLA机制和重参数化令牌混合器，优化计算效率。
- Result: 在多个基准测试中表现优异，推理速度比EdgeFace快8.6倍，比纯ViT模型快21.2倍。
- Conclusion: FaceLiVT为资源受限平台提供了一种高效且实用的实时人脸识别解决方案。


### [28] [FSATFusion: Frequency-Spatial Attention Transformer for Infrared and Visible Image Fusion](https://arxiv.org/abs/2506.10366)
*Tianpei Zhang,Jufeng Zhao,Yiming Zhu,Guangmang Cui,Yuhan Lyu*

Main category: cs.CV

TL;DR: 提出了一种名为FSATFusion的红外与可见光图像融合网络，通过频率-空间注意力Transformer模块（FSAT）和改进的Transformer模块（ITM）提升全局上下文捕捉能力，显著优于现有方法。

- Motivation: 现有深度学习方法因卷积操作的局限性导致全局上下文信息丢失，影响融合性能。
- Method: 设计了FSAT模块（含频率-空间注意力机制）和ITM模块，以增强特征提取能力。
- Result: 实验表明FSATFusion在融合质量和效率上优于其他方法，且具有优秀的泛化能力。
- Conclusion: FSATFusion在红外与可见光图像融合及下游任务中表现出色。


### [29] [Revisiting Transformers with Insights from Image Filtering](https://arxiv.org/abs/2506.10371)
*Laziz U. Abdullaev,Maksim Tkachenko,Tan M. Nguyen*

Main category: cs.CV

TL;DR: 本文提出了一种统一的图像处理框架，用于解释自注意力机制及其组件（如位置编码和残差连接）的作用，并通过实验验证了其改进性能。

- Motivation: 自注意力机制的成功和局限性缺乏理论解释，现有框架未能深入分析其架构组件的机制。
- Method: 开发了一个统一的图像处理框架，解释自注意力及其组件，并引入两种独立的架构修改。
- Result: 实验表明，基于图像处理的修改不仅提高了可解释性，还显著提升了任务准确性和鲁棒性。
- Conclusion: 该框架为自注意力机制提供了更深入的理论基础，同时展示了其实际应用的潜力。


### [30] [Leveraging 6DoF Pose Foundation Models For Mapping Marine Sediment Burial](https://arxiv.org/abs/2506.10386)
*Jerry Yan,Chinmay Talegaonkar,Nicholas Antipa,Eric Terrill,Sophia Merrifield*

Main category: cs.CV

TL;DR: 论文提出了一种名为PoseIDON的计算机视觉方法，通过结合深度基础模型特征和多视角摄影测量技术，从ROV视频中估计海底物体的六自由度位姿及周围海底的朝向，进而推断埋藏深度。该方法在历史海洋倾倒场的54个物体上验证，平均埋藏深度误差约10厘米。

- Motivation: 准确估计海底人为物体的埋藏状态对理解局部沉积动态、评估生态风险、污染物迁移以及危险物质（如弹药）的回收或缓解策略至关重要。然而，由于部分遮挡、低可见度和物体退化，从遥感图像中准确估计埋藏深度仍具挑战性。
- Method: 提出PoseIDON方法，结合深度基础模型特征与多视角摄影测量技术，通过ROV视频估计物体的六自由度位姿和海底朝向，并通过CAD模型对齐和局部平面拟合推断埋藏深度。
- Result: 在54个物体（包括桶和弹药）上验证，平均埋藏深度误差约10厘米，并能反映沉积物迁移过程的空间埋藏模式。
- Conclusion: 该方法实现了海底埋藏的非侵入式、可扩展测绘，为污染场地的环境评估提供了支持。


### [31] [DART: Differentiable Dynamic Adaptive Region Tokenizer for Vision Transformer and Mamba](https://arxiv.org/abs/2506.10390)
*Shicheng Yin,Kaixuan Yin,Yang Liu,Weixing Chen,Liang Lin*

Main category: cs.CV

TL;DR: 论文提出了一种动态自适应区域分词器（DART），通过自适应划分图像为不同大小的内容相关补丁，解决了固定大小补丁导致的背景区域过度编码和局部细节丢失问题。

- Motivation: 现有非卷积模型（如ViT和Vim）依赖固定大小补丁，容易忽略关键局部细节或过度编码背景区域，尤其是当信息对象稀疏分布时。
- Method: DART结合可学习的区域评分和分段可微分分位数操作，将更密集的标记分配给信息丰富的区域。
- Result: DART仅增加约1M参数，在DeiT（ImageNet-1K）上提升2.1%准确率，同时减少45% FLOPs。
- Conclusion: DART在DeiT、Vim和VideoMamba上均能提升性能，且计算开销极小甚至减少。


### [32] [ReconMOST: Multi-Layer Sea Temperature Reconstruction with Observations-Guided Diffusion](https://arxiv.org/abs/2506.10391)
*Yuanyi Song,Pumeng Lyu,Ben Fei,Fenghua Ling,Wanli Ouyang,Lei Bai*

Main category: cs.CV

TL;DR: 本文提出ReconMOST框架，利用数据驱动的扩散模型进行多层海水温度重建，解决了传统方法数据稀疏、计算复杂的问题，并在全球范围内实现高精度重建。

- Motivation: 传统方法在海洋温度重建中面临数据稀疏、算法复杂和高计算成本的问题，而现有机器学习方法局限于海表和局部区域，难以处理云遮挡等问题。
- Method: 通过预训练无条件扩散模型学习海洋温度场的物理一致性分布模式，再利用高精度观测数据引导反向扩散过程，实现精确重建。
- Result: 在CMIP6和EN4数据上的实验显示，MSE值分别为0.049（引导）、0.680（重建）和0.633（总体），验证了方法的有效性和鲁棒性。
- Conclusion: ReconMOST扩展了机器学习在海洋温度重建中的应用，支持全球多层重建，并具备高精度和泛化能力。


### [33] [Pisces: An Auto-regressive Foundation Model for Image Understanding and Generation](https://arxiv.org/abs/2506.10395)
*Zhiyang Xu,Jiuhai Chen,Zhaojiang Lin,Xichen Pan,Lifu Huang,Tianyi Zhou,Madian Khabsa,Qifan Wang,Di Jin,Michihiro Yasunaga,Lili Yu,Xi Victoria Lin,Shaoliang Nie*

Main category: cs.CV

TL;DR: Pisces是一个新型的多模态基础模型，通过解耦视觉编码架构和定制化训练技术，在图像理解和生成任务中均表现出色。

- Motivation: 尽管多模态基础模型在图像理解和生成方面取得进展，但其性能仍不及专用模型。Pisces旨在解决视觉特征和训练过程差异带来的挑战。
- Method: 采用解耦视觉编码架构和定制化训练技术，结合数据筛选、预训练和微调。
- Result: 在20多个图像理解基准测试和GenEval图像生成基准测试中表现优异。
- Conclusion: Pisces展示了图像理解与生成的协同关系，并验证了分离视觉编码器的优势，推动了统一多模态模型的发展。


### [34] [It's Not the Target, It's the Background: Rethinking Infrared Small Target Detection via Deep Patch-Free Low-Rank Representations](https://arxiv.org/abs/2506.10425)
*Guoyi Zhang,Guangsheng Xu,Siyang Chen,Han Wang,Xiaohu Zhang*

Main category: cs.CV

TL;DR: LRRNet是一种新型的端到端红外小目标检测框架，利用红外图像背景的低秩特性，通过压缩-重建-减法范式直接建模结构感知的低秩背景表示，无需依赖基于块的处理或显式矩阵分解。

- Motivation: 红外小目标检测在复杂背景下因低信噪比、目标形态多样和缺乏视觉线索而具有挑战性，现有深度学习方法因目标内在变异性导致性能不稳定。
- Method: 提出LRRNet框架，采用压缩-重建-减法（CRS）范式，直接学习图像域中的低秩背景结构，无需显式矩阵分解。
- Result: 在多个公开数据集上，LRRNet在检测精度、鲁棒性和计算效率上优于38种现有方法，平均速度达82.34 FPS，且在噪声环境下表现稳健。
- Conclusion: LRRNet首次通过端到端深度网络直接学习低秩背景结构，显著提升了红外小目标检测的性能和实时性。


### [35] [MF2Summ: Multimodal Fusion for Video Summarization with Temporal Alignment](https://arxiv.org/abs/2506.10430)
*Shuo wang,Jihao Zhang*

Main category: cs.CV

TL;DR: MF2Summ是一种基于多模态内容理解的视频摘要模型，结合视觉和听觉信息，通过五阶段流程实现高效摘要生成。

- Motivation: 传统单模态视频摘要方法难以捕捉视频的完整语义，需要多模态融合技术提升效果。
- Method: MF2Summ采用五阶段流程：特征提取、跨模态注意力交互、特征融合、片段预测和关键镜头选择，结合Transformer和NMS/KTS算法。
- Result: 在SumMe和TVSum数据集上，MF2Summ的F1分数分别比DSNet提高1.9%和0.6%，优于其他先进方法。
- Conclusion: MF2Summ通过多模态融合显著提升了视频摘要的性能，证明了其有效性。


### [36] [Towards Robust Multimodal Emotion Recognition under Missing Modalities and Distribution Shifts](https://arxiv.org/abs/2506.10452)
*Guowei Zhong,Ruohong Huan,Mingzhen Wu,Ronghua Liang,Peng Chen*

Main category: cs.CV

TL;DR: CIDer是一个新的多模态情感识别框架，通过自蒸馏和因果推理模块解决模态缺失和分布外数据问题，性能优于现有方法。

- Motivation: 解决多模态情感识别中模态缺失和分布外数据的挑战，提升模型的实用性和鲁棒性。
- Method: 提出CIDer框架，包含自蒸馏模块（MSSD）和因果推理模块（MACI），并引入RMFM任务和新的数据集。
- Result: CIDer在RMFM和OOD场景下表现优异，参数更少且训练更快。
- Conclusion: CIDer为多模态情感识别提供了高效且鲁棒的解决方案，代码已开源。


### [37] [Rethinking Generative Human Video Coding with Implicit Motion Transformation](https://arxiv.org/abs/2506.10453)
*Bolin Chen,Ru-Ling Liao,Jie Chen,Yan Ye*

Main category: cs.CV

TL;DR: 生成视频编解码器通过隐式运动变换（IMT）提升人体视频压缩性能，解决了传统显式运动方法在复杂运动模式下的失真问题。

- Motivation: 人体视频因运动模式复杂多样，传统显式运动方法在生成人体视频编解码（GHVC）中易导致失真和运动不准确，需探索更有效的方法。
- Method: 提出隐式运动变换（IMT），将复杂人体信号转化为紧凑视觉特征，并转换为隐式运动指导以重建信号。
- Result: 实验证明IMT范式有效，能实现高效压缩和高保真合成。
- Conclusion: IMT为GHVC提供了一种更优的解决方案，显著提升了人体视频的压缩和重建质量。


### [38] [Boosting Adversarial Transferability for Hyperspectral Image Classification Using 3D Structure-invariant Transformation and Intermediate Feature Distance](https://arxiv.org/abs/2506.10459)
*Chun Liu,Bingqian Zhu,Tao Xu,Zheng Zheng,Zheng Li,Wei Yang,Zhigang Han,Jiayao Wang*

Main category: cs.CV

TL;DR: 本文提出了一种增强高光谱图像分类模型对抗样本可迁移性的新方法，通过随机分块和特征距离损失设计，显著提升了对抗样本的迁移性和攻击效果。

- Motivation: 高光谱图像（HSI）因其高维和丰富的频谱信息，与自然图像不同，现有的对抗攻击方法难以充分利用其结构和特征信息，因此需要一种新的方法来提升对抗样本的可迁移性。
- Method: 方法包括：1）在保持图像结构不变的情况下，随机分块并应用多样化变换；2）设计针对中间层的特征距离损失，结合输出层预测作为辅助损失。
- Result: 实验表明，该方法生成的对抗样本在公开数据集上对黑盒模型具有显著的可迁移性，且在防御策略下仍保持强攻击性能。
- Conclusion: 该方法有效提升了HSI对抗样本的可迁移性和攻击效果，为相关安全挑战提供了解决方案。


### [39] [Starting Positions Matter: A Study on Better Weight Initialization for Neural Network Quantization](https://arxiv.org/abs/2506.10463)
*Stone Yun,Alexander Wong*

Main category: cs.CV

TL;DR: 研究探讨了深度神经网络（DNN）量化中权重初始化对量化鲁棒性的影响，并提出了一种基于图超网络（GHN）的新方法GHN-QAT，显著提升了量化精度。

- Motivation: 量化是降低机器学习模型推理成本的重要工具，但权重初始化对量化鲁棒性的影响尚未被充分研究。
- Method: 研究了不同权重初始化对CNN量化鲁棒性的影响，并提出GHN-QAT方法，通过GHN预测量化DNN参数并微调。
- Result: GHN-QAT显著提升了4位量化精度，并在2位量化中表现优于随机初始化。
- Conclusion: GHN-QAT为量化DNN设计提供了新方法，未来可结合量化感知训练进一步优化。


### [40] [MedSeg-R: Reasoning Segmentation in Medical Images with Multimodal Large Language Models](https://arxiv.org/abs/2506.10465)
*Yu Huang,Zelin Peng,Yichen Zhao,Piao Yang,Xiaokang Yang,Wei Shen*

Main category: cs.CV

TL;DR: 提出MedSeg-R框架，结合多模态大语言模型（MLLMs）的推理能力，实现基于复杂医学指令的精确图像分割，并引入数据集MedSeg-QA。

- Motivation: 现有医学图像分割模型依赖显式指令且缺乏主动推理能力，限制了自动诊断的应用。
- Method: MedSeg-R框架包含全局上下文理解模块和像素级定位模块，结合MLLMs生成分割掩码和文本响应。
- Result: 实验显示MedSeg-R在多个基准测试中表现优异，分割精度高且支持可解释的文本分析。
- Conclusion: MedSeg-R为医学图像推理分割任务提供了有效解决方案，推动了自动诊断的发展。


### [41] [LLMs Are Not Yet Ready for Deepfake Image Detection](https://arxiv.org/abs/2506.10474)
*Shahroz Tariq,David Nguyen,M. A. P. Chamikara,Tingmin Wu,Alsharif Abuadbba,Kristen Moore*

Main category: cs.CV

TL;DR: 该研究评估了四种视觉语言模型（VLM）在零样本设置下对三种深度伪造类型的检测能力，发现其虽能生成合理解释但尚不可靠，但可作为辅助工具。

- Motivation: 深度伪造技术日益复杂，威胁媒体完整性和公众信任，而视觉语言模型（VLM）因其潜力引发对其在深度伪造检测中应用的兴趣。
- Method: 研究对四种VLM（ChatGPT、Claude、Gemini、Grok）进行零样本评估，使用包含真实与伪造图像的基准数据集，分析分类准确性和推理深度。
- Result: VLM能生成合理解释并检测表面异常，但不可靠；易受误导性视觉模式影响，但在可解释性和上下文分析方面表现突出。
- Conclusion: 通用模型虽无法独立用于深度伪造检测，但可作为混合或人机协作检测框架的组成部分。


### [42] [Sheet Music Benchmark: Standardized Optical Music Recognition Evaluation](https://arxiv.org/abs/2506.10488)
*Juan C. Martinez-Sevilla,Joan Cerveto-Serrano,Noelia Luna,Greg Chapman,Craig Sapp,David Rizo,Jorge Calvo-Zaragoza*

Main category: cs.CV

TL;DR: 介绍了Sheet Music Benchmark（SMB）数据集和OMR-NED评估指标，用于光学音乐识别（OMR）研究。

- Motivation: 解决OMR研究中缺乏标准化评估数据集和详细评估指标的问题。
- Method: 创建SMB数据集和OMR-NED指标，并进行基线实验验证。
- Result: 提供了多样化的音乐纹理数据集和细粒度的评估方法。
- Conclusion: 填补了OMR评估的空白，支持更清晰的性能比较。


### [43] [Class-Incremental Learning for Honey Botanical Origin Classification with Hyperspectral Images: A Study with Continual Backpropagation](https://arxiv.org/abs/2506.10489)
*Guyang Zhang,Waleed Abdulla*

Main category: cs.CV

TL;DR: 研究提出了一种结合持续反向传播（CB）算法的类增量学习（CIL）技术，用于蜂蜜植物来源分类，CB通过重新初始化较少使用的神经元提升性能，实验显示性能提升1-7%。

- Motivation: 蜂蜜因植物来源不同具有不同市场价值，但难以一次性收集所有品种训练模型，因此需要类增量学习技术。
- Method: 研究比较了多种CIL算法，并提出结合CB算法的方法，通过重新初始化较少使用的神经元提升性能。
- Result: 实验表明，CB算法使大多数CIL方法的性能提升了1-7%。
- Conclusion: 结合CB的CIL技术能有效提升蜂蜜植物来源分类的准确性和实用性。


### [44] [Semantic Localization Guiding Segment Anything Model For Reference Remote Sensing Image Segmentation](https://arxiv.org/abs/2506.10503)
*Shuyang Li,Shuang Wang,Zhuangzhuang Sun,Jing Xiao*

Main category: cs.CV

TL;DR: 论文提出PSLG-SAM框架，将RRSIS任务分解为粗定位和精细分割两阶段，显著减少标注需求并提升性能。

- Motivation: 解决现有RRSIS方法对密集标注的依赖和复杂场景解释的挑战。
- Method: 两阶段框架：粗定位阶段用视觉定位网络定位目标，精细分割阶段用SAM模型结合聚类和优化策略。
- Result: 在RRSIS-D和RRSIS-M数据集上性能显著优于现有方法。
- Conclusion: PSLG-SAM有效减少标注负担并提升分割精度，适用于复杂场景。


### [45] [J-DDL: Surface Damage Detection and Localization System for Fighter Aircraft](https://arxiv.org/abs/2506.10505)
*Jin Huang,Mingqiang Wei,Zikuan Li,Hangyu Qu,Wei Zhao,Xinyu Bai*

Main category: cs.CV

TL;DR: J-DDL系统通过结合2D图像和3D点云技术，优化YOLO架构，提出了一种高效、精确的战斗机表面损伤检测与定位方法。

- Motivation: 传统人工检测战斗机表面损伤存在效率低、一致性差等问题，亟需自动化解决方案以提高检测效率和准确性。
- Method: 集成激光扫描仪和相机捕获2D图像与3D点云，基于优化的YOLO架构设计损伤检测网络，引入轻量级Fasternet块、EMA模块和Inner-CIOU损失函数。
- Result: 实验验证J-DDL系统能高效检测并精确定位战斗机表面损伤，同时发布了首个公开的飞机损伤数据集。
- Conclusion: J-DDL系统显著提升了战斗机表面损伤检测的自动化水平，为未来研究提供了重要数据和工具。


### [46] [CogStream: Context-guided Streaming Video Question Answering](https://arxiv.org/abs/2506.10516)
*Zicheng Zhao,Kangyu Wang,Shijie Li,Rui Qian,Weiyao Lin,Huabin Liu*

Main category: cs.CV

TL;DR: 论文提出了一种名为CogStream的新任务，专注于流媒体视频推理，通过识别最相关的历史上下文信息来回答问题。作者还提出了一个密集标注的数据集和基线模型CogReasoner，实验证明其有效性。

- Motivation: 现有视频大语言模型（Vid-LLMs）在处理流媒体视频时存在计算负担大和无关上下文干扰的问题，需要一种更高效的方法。
- Method: 提出了CogStream任务，并开发了一个半自动生成的数据集和基线模型CogReasoner，结合视觉流压缩和历史对话检索技术。
- Result: 实验证明CogReasoner能有效解决流媒体视频推理任务。
- Conclusion: CogStream任务和CogReasoner模型为流媒体视频推理提供了新的解决方案，未来代码将开源。


### [47] [ALBERT: Advanced Localization and Bidirectional Encoder Representations from Transformers for Automotive Damage Evaluation](https://arxiv.org/abs/2506.10524)
*Teerapong Panboonyuen*

Main category: cs.CV

TL;DR: ALBERT是一个专为汽车损伤和部件分割设计的实例分割模型，结合双向编码器表示和高级定位机制，能准确区分真实与虚假损伤并分割部件。

- Motivation: 开发一个智能汽车检测和评估系统，需要准确识别和分类汽车损伤及部件。
- Method: 利用双向编码器表示和高级定位机制，训练于大规模标注的汽车数据集，涵盖26种损伤类型、7种虚假损伤和61个部件。
- Result: 模型在分割精度和损伤分类上表现优异。
- Conclusion: ALBERT为智能汽车检测和评估应用提供了有效解决方案。


### [48] [SLICK: Selective Localization and Instance Calibration for Knowledge-Enhanced Car Damage Segmentation in Automotive Insurance](https://arxiv.org/abs/2506.10528)
*Teerapong Panboonyuen*

Main category: cs.CV

TL;DR: SLICK是一个用于精确和鲁棒的汽车损伤分割的新框架，通过结构先验和领域知识解决现实中的汽车检测挑战。

- Motivation: 解决汽车损伤分割在遮挡、变形或复杂场景中的挑战，提升分割精度和鲁棒性。
- Method: 引入五个关键组件：选择性部件分割、定位感知注意力块、实例敏感细化头、跨通道校准和知识融合模块。
- Result: 在大规模汽车数据集上表现出优越的分割性能、鲁棒性和实际应用性。
- Conclusion: SLICK在汽车保险和检测工作流程中具有显著优势。


### [49] [ContextRefine-CLIP for EPIC-KITCHENS-100 Multi-Instance Retrieval Challenge 2025](https://arxiv.org/abs/2506.10550)
*Jing He,Yiqing Wang,Lingling Li,Kexin Zhang,Puhua Chen*

Main category: cs.CV

TL;DR: CR-CLIP是一种高效的视觉-文本多实例检索模型，通过跨模态注意力流模块实现双向动态交互，优化特征表示，显著提升检索性能。

- Motivation: 解决视觉-文本多实例检索任务中特征表示不够上下文感知的问题，提升语义对齐和检索准确性。
- Method: 基于AVION双编码器，引入跨模态注意力流模块，结合Symmetric Multi-Similarity Loss优化特征。
- Result: 在EPIC-KITCHENS-100数据集上达到66.78mAP和82.08nDCG，显著优于基线模型。
- Conclusion: CR-CLIP通过动态交互和特征优化，有效提升了跨模态检索性能，代码将开源。


### [50] [From Images to Insights: Explainable Biodiversity Monitoring with Plain Language Habitat Explanations](https://arxiv.org/abs/2506.10559)
*Yutong Zhou,Masahiro Ryo*

Main category: cs.CV

TL;DR: 提出一种端到端的视觉-因果框架，将物种图像转化为可解释的栖息地偏好因果分析。

- Motivation: 理解物种分布对生态研究和保护至关重要，但现有方法分散且不易为非专家使用。
- Method: 整合物种识别、全球分布检索、伪缺失采样和气候数据提取，利用因果推断方法分析环境特征对物种分布的影响。
- Result: 通过蜜蜂和花卉物种的案例展示了框架的潜力，生成易于理解的因果解释。
- Conclusion: 该框架结合多模态AI和生态建模实践，为物种栖息地描述提供了新方法。


### [51] [Balancing Tails when Comparing Distributions: Comprehensive Equity Index (CEI) with Application to Bias Evaluation in Operational Face Biometrics](https://arxiv.org/abs/2506.10564)
*Imanol Solano,Julian Fierrez,Aythami Morales,Alejandro Peña,Ruben Tolosana,Francisco Zamora-Martinez,Javier San Agustin*

Main category: cs.CV

TL;DR: 论文提出了一种名为CEI的新指标，用于检测高性能人脸识别系统中的细微人口统计偏差，特别是针对分数分布尾部的差异。

- Motivation: 现有指标难以检测高性能人脸识别系统中的细微人口统计偏差，尤其是在分数分布尾部。
- Method: 提出CEI指标，分别分析真实和冒名顶替分数分布，可配置关注尾部概率，同时考虑整体分布形状。还开发了自动化版本CEI^A。
- Result: 实验证明CEI在检测细微偏差方面优于现有方法，适用于多种数据集和模型。
- Conclusion: CEI为评估人脸识别公平性提供了强大且敏感的工具，方法也可用于其他统计分布尾部分析问题。


### [52] [LRSLAM: Low-rank Representation of Signed Distance Fields in Dense Visual SLAM System](https://arxiv.org/abs/2506.10567)
*Hongbeen Park,Minjeong Park,Giljoo Nam,Jinkyu Kim*

Main category: cs.CV

TL;DR: LRSLAM是一种基于低秩张量分解的高效视觉SLAM模型，解决了现有方法在实时性、内存占用和扩展性上的挑战，性能优于现有技术。

- Motivation: 密集视觉SLAM在实时性、鲁棒性和大规模场景扩展性方面存在挑战，现有神经隐式表示方法计算和内存成本高。
- Method: 采用低秩张量分解（Six-axis和CP分解），提升收敛速度、内存效率和重建/定位质量。
- Result: 在多个室内RGB-D数据集上验证，LRSLAM在参数效率、处理时间和准确性上表现优越。
- Conclusion: LRSLAM通过低秩分解显著提升了SLAM性能，代码将公开。


### [53] [DreamActor-H1: High-Fidelity Human-Product Demonstration Video Generation via Motion-designed Diffusion Transformers](https://arxiv.org/abs/2506.10568)
*Lizhen Wang,Zhurong Xia,Tianshu Hu,Pengrui Wang,Pengfei Wang,Zerong Zheng,Ming Zhou*

Main category: cs.CV

TL;DR: 本文提出了一种基于扩散变换器（DiT）的框架，用于生成高保真的人与产品演示视频，解决了现有方法在保留身份和空间关系上的不足。

- Motivation: 在电子商务和数字营销中，生成高质量的人与产品互动视频对产品展示至关重要，但现有方法难以同时保留人和产品的身份或理解其空间关系。
- Method: 采用DiT框架，通过注入配对的人与产品参考信息和使用掩码交叉注意力机制，结合3D身体网格模板和产品边界框提供精确运动指导，并利用结构化文本编码增强3D一致性。
- Result: 在混合数据集上训练后，该方法在保持身份完整性和生成真实演示动作方面优于现有技术。
- Conclusion: 提出的框架有效解决了人与产品互动视频生成中的身份保留和空间关系问题，具有实际应用价值。


### [54] [Improving Medical Visual Representation Learning with Pathological-level Cross-Modal Alignment and Correlation Exploration](https://arxiv.org/abs/2506.10573)
*Jun Wang,Lixing Zhu,Xiaohan Yu,Abhir Bhalerao,Yulan He*

Main category: cs.CV

TL;DR: 论文提出PLACE框架，通过病理级对齐和相关性探索提升医学图像与报告的多模态学习效果，无需额外标注。

- Motivation: 解决医学领域数据稀缺问题，同时应对报告冗长、语义复杂及病理一致性不足的挑战。
- Method: 提出病理级跨模态对齐（PCMA）方法，结合视觉病理观察提取器和相关性代理任务。
- Result: 在分类、检索、分割、检测和报告生成等任务上达到SOTA性能。
- Conclusion: PLACE框架显著提升了医学视觉表征学习的效果和泛化能力。


### [55] [DanceChat: Large Language Model-Guided Music-to-Dance Generation](https://arxiv.org/abs/2506.10574)
*Qing Wang,Xiaohang Yang,Yilan Dong,Naveen Raj Govindaraj,Gregory Slabaugh,Shanxin Yuan*

Main category: cs.CV

TL;DR: DanceChat利用大型语言模型（LLM）生成文本舞蹈指导，结合音乐和节奏特征，通过扩散模型合成多样化且与音乐风格一致的舞蹈动作。

- Motivation: 音乐与舞蹈之间存在语义鸿沟，音乐仅提供抽象线索，且单一音乐可对应多种舞蹈动作。现有方法因数据稀缺和音乐信息有限，难以生成多样且符合风格的舞蹈。
- Method: 1. LLM生成伪指令；2. 多模态特征提取与融合；3. 扩散模型合成动作，结合多模态对齐损失。
- Result: 在AIST++数据集和人类评估中，DanceChat在质量和多样性上均优于现有方法。
- Conclusion: DanceChat通过LLM提供显式指导，解决了音乐到舞蹈生成中的多样性和风格对齐问题。


### [56] [Text to Image for Multi-Label Image Recognition with Joint Prompt-Adapter Learning](https://arxiv.org/abs/2506.10575)
*Chun-Mei Feng,Kai Yu,Xinxing Xu,Salman Khan,Rick Siow Mong Goh,Wangmeng Zuo,Yong Liu*

Main category: cs.CV

TL;DR: T2I-PAL利用文本生成图像减少模态差异，结合热图和原型学习提升多标签识别性能，无需全语义标注。

- Motivation: 解决CLIP模型中文本与图像模态差异问题，提升仅用文本进行参数高效微调时的图像识别性能。
- Method: 利用文本生成图像模型生成多样图像，结合类热图和可学习原型增强局部特征表示，结合提示调优和适配器学习。
- Result: 在多个基准测试中平均性能提升3.47%。
- Conclusion: T2I-PAL无需全语义标注，兼容现有CLIP框架，显著提升多标签识别性能。


### [57] [Harmonizing Geometry and Uncertainty: Diffusion with Hyperspheres](https://arxiv.org/abs/2506.10576)
*Muskan Dosi,Chiranjeev Chiranjeev,Kartik Thakral,Mayank Vatsa,Richa Singh*

Main category: cs.CV

TL;DR: 论文探讨了扩散模型是否保留超球面数据的类别几何结构，提出HyperSphereDiff方法以解决欧几里得空间建模中的局限性。

- Motivation: 现实问题常涉及非欧几里得分布（如超球面流形），传统扩散模型的各向同性高斯噪声无法捕捉角度几何，导致生成性能不佳。
- Method: 引入HyperSphereDiff，使用方向性噪声对齐超球面结构，保留类别几何并捕捉角度不确定性。
- Result: 理论和实验证明，该方法能更准确地生成几何感知的模型，在多个数据集上表现优异。
- Conclusion: HyperSphereDiff有效解决了超球面数据的几何建模问题，提升了生成模型的准确性。


### [58] [Rethinking Random Masking in Self Distillation on ViT](https://arxiv.org/abs/2506.10582)
*Jihyeon Seong,Hyunkyung Han*

Main category: cs.CV

TL;DR: 研究了在DINO框架中随机掩码的作用，提出了一种非对称掩码策略，仅在学生的全局视图中应用随机掩码，从而提升模型鲁棒性和下游任务性能。

- Motivation: 随机掩码可能无意中消除关键语义信息，因此需要更智能的掩码策略。
- Method: 在DINO框架中，仅对学生的全局视图应用随机掩码，保留学生的局部视图和教师的全局视图。
- Result: 在mini-ImageNet数据集上，该方法生成了更鲁棒和细粒度的注意力图，提升了下游任务性能。
- Conclusion: 非对称随机掩码策略在自蒸馏框架中有效，能提升模型性能。


### [59] [Hierarchical Error Assessment of CAD Models for Aircraft Manufacturing-and-Measurement](https://arxiv.org/abs/2506.10594)
*Jin Huang,Honghua Chen,Mingqiang Wei*

Main category: cs.CV

TL;DR: 提出了一种名为HEA-MM的分层误差评估框架，用于飞机CAD模型的质量检测，通过全局、部件和特征三个层次进行误差分析。

- Motivation: 航空设备的高质量要求（高性能、高稳定性和高可靠性）需要精确的误差评估方法。
- Method: 使用结构光扫描仪获取工件3D数据，通过全局、部件和特征三个层次进行误差分析，包括优化基元细化和圆形特征检测。
- Result: 实验证明该方法在飞机CAD模型上的有效性。
- Conclusion: HEA-MM框架为航空制造提供了高效的误差评估工具。


### [60] [Semantic-decoupled Spatial Partition Guided Point-supervised Oriented Object Detection](https://arxiv.org/abs/2506.10601)
*Xinyuan Liu,Hang Xu,Yike Ma,Yucheng Zhang,Feng Dai*

Main category: cs.CV

TL;DR: SSP框架通过语义解耦的空间分区，解决了点监督下密集场景中样本分配和实例混淆的问题，显著提升了检测性能。

- Motivation: 高密度场景中标注成本高，现有方法因基于规则的样本分配不足而表现不佳。
- Method: 提出SSP框架，结合规则驱动的先验注入和数据驱动的标签净化，包括像素级空间分区样本分配和语义空间分区框提取。
- Result: 在DOTA-v1.0等数据集上，SSP达到45.78% mAP，优于PointOBB-v2 4.10%，与ORCNN和ReDet结合分别达到47.86%和48.50% mAP。
- Conclusion: SSP为密集场景的定向目标检测提供了一种高效且性能优越的解决方案。


### [61] [High-resolution efficient image generation from WiFi CSI using a pretrained latent diffusion model](https://arxiv.org/abs/2506.10605)
*Eshan Ramesh,Nishio Takayuki*

Main category: cs.CV

TL;DR: LatentCSI利用预训练的潜在扩散模型（LDM）从WiFi CSI测量生成环境图像，通过轻量级神经网络直接映射CSI振幅到LDM的潜在空间，实现高效高质量的图像合成。

- Motivation: 传统方法依赖复杂且计算密集的技术（如GANs），而LatentCSI旨在绕过像素空间生成挑战，避免显式图像编码阶段，提升效率和图像质量。
- Method: 使用轻量级神经网络将CSI振幅映射到LDM潜在空间，结合文本引导的扩散模型去噪，最后通过LDM解码器生成高分辨率图像。
- Result: 在公开数据集和自采数据集上验证，LatentCSI在计算效率和感知质量上优于基线方法，并具备文本引导可控性。
- Conclusion: LatentCSI提供了一种高效、高质量且可控的图像生成方法，适用于WiFi CSI到图像的转换。


### [62] [MSTAR: Box-free Multi-query Scene Text Retrieval with Attention Recycling](https://arxiv.org/abs/2506.10609)
*Liang Yin,Xudong Xie,Zhang Li,Xiang Bai,Yuliang Liu*

Main category: cs.CV

TL;DR: MSTAR是一种无需边界框标注的场景文本检索方法，通过动态多粒度文本表示和风格感知指令统一多种查询类型，显著提升性能。

- Motivation: 现有方法依赖昂贵的边界框标注且难以统一多样查询需求，MSTAR旨在解决这些问题。
- Method: 采用渐进视觉嵌入动态捕捉文本多粒度表示，结合风格感知指令和多实例匹配模块增强视觉-语言对齐。
- Result: 在7个公共数据集和MQTR数据集上表现优异，MAP提升6.4%，MQTR上平均提升8.5%。
- Conclusion: MSTAR在减少标注成本的同时显著提升检索性能，为多查询场景文本检索提供新基准。


### [63] [TexTailor: Customized Text-aligned Texturing via Effective Resampling](https://arxiv.org/abs/2506.10612)
*Suin Lee,Dae-Shik Kim*

Main category: cs.CV

TL;DR: TexTailor是一种新颖的方法，通过文本描述生成一致的对象纹理，解决了现有方法在纹理一致性和视角选择上的不足。

- Motivation: 现有文本到纹理合成方法在扩散过程中未能充分整合先前合成的纹理信息，且视角选择固定，导致纹理一致性差。
- Method: TexTailor采用重采样方案整合纹理信息，并微调深度感知扩散模型，同时提出性能保持损失和自适应相机位置调整。
- Result: 在Objaverse和ShapeNet数据集上的实验表明，TexTailor在合成视角一致纹理方面优于现有方法。
- Conclusion: TexTailor通过改进纹理整合和视角选择，显著提升了纹理合成的一致性和质量。


### [64] [Anatomy-Grounded Weakly Supervised Prompt Tuning for Chest X-ray Latent Diffusion Models](https://arxiv.org/abs/2506.10633)
*Konstantinos Vilouras,Ilias Stogiannidis,Junyu Yan,Alison Q. O'Neil,Sotirios A. Tsaftaris*

Main category: cs.CV

TL;DR: 本文提出了一种针对医学影像的文本到图像潜在扩散模型微调框架，解决了临床信息与影像对齐不足的问题，并在标准数据集和外部数据上表现优异。

- Motivation: 医学影像领域的文本到图像潜在扩散模型因数据有限而研究不足，且现有模型未能有效对齐临床文本与影像信息。
- Method: 提出了一种微调框架，优化预训练模型的多模态对齐能力，适用于下游任务如短语定位。
- Result: 在MS-CXR数据集上达到新SOTA，并在VinDr-CXR上表现稳健。
- Conclusion: 该框架为医学影像领域的多模态任务提供了高效解决方案，代码将开源。


### [65] [Symmetrical Flow Matching: Unified Image Generation, Segmentation, and Classification with Score-Based Generative Models](https://arxiv.org/abs/2506.10634)
*Francisco Caetano,Christiaan Viviers,Peter H. N. De With,Fons van der Sommen*

Main category: cs.CV

TL;DR: SymmFlow是一种对称流匹配方法，统一了语义分割、分类和图像生成，通过双向一致性保持生成多样性，并在多个任务上取得优异表现。

- Motivation: 传统方法在分布转换中缺乏灵活性和一致性，SymmFlow旨在通过对称学习目标解决这些问题，同时保留语义信息。
- Method: 提出对称学习目标，联合建模正向和反向转换，引入新训练目标以保留语义信息，支持灵活的条件输入。
- Result: 在CelebAMask-HQ和COCO-Stuff上分别取得FID 11.9和7.0的优异生成效果，同时在分割和分类任务中表现良好。
- Conclusion: SymmFlow为多任务学习提供了高效统一的框架，具有广泛的应用潜力。


### [66] [GigaVideo-1: Advancing Video Generation via Automatic Feedback with 4 GPU-Hours Fine-Tuning](https://arxiv.org/abs/2506.10639)
*Xiaoyi Bao,Jindi Lv,Xiaofeng Wang,Zheng Zhu,Xinze Chen,YuKun Zhou,Jiancheng Lv,Xingang Wang,Guan Huang*

Main category: cs.CV

TL;DR: GigaVideo-1提出了一种无需人工标注的高效视频生成微调框架，通过自动反馈提升预训练模型的性能。

- Motivation: 现有视频生成模型的微调方法依赖人工标注和大量计算资源，限制了实用性。
- Method: 设计了基于提示的数据引擎和奖励引导的训练策略，利用预训练视觉语言模型的反馈优化样本权重。
- Result: 在VBench-2.0基准测试中，GigaVideo-1在17个维度上平均提升4%，仅需4 GPU小时。
- Conclusion: GigaVideo-1无需人工标注和大量数据，展示了高效且有效的视频生成优化能力。


### [67] [PiPViT: Patch-based Visual Interpretable Prototypes for Retinal Image Analysis](https://arxiv.org/abs/2506.10669)
*Marzieh Oghbaie,Teresa Araújoa,Hrvoje Bogunović*

Main category: cs.CV

TL;DR: PiPViT是一种基于视觉Transformer的原型模型，通过对比学习和多分辨率输入处理，学习可解释的原型，用于医学图像分类，并在视网膜OCT图像分类中表现优异。

- Motivation: 解决现有原型方法在医学图像中可视化不一致和原型过于细粒度的问题，提升解释性和临床相关性。
- Method: 利用ViT捕获长距离依赖关系，结合对比学习和多分辨率处理，学习可解释的原型。
- Result: 在四个视网膜OCT数据集上表现优异，原型具有临床意义，解释性更强。
- Conclusion: PiPViT能透明解释决策，辅助临床诊断，具有实际应用价值。


### [68] [Enhancing Deepfake Detection using SE Block Attention with CNN](https://arxiv.org/abs/2506.10683)
*Subhram Dasgupta,Janelle Mason,Xiaohong Yuan,Olusola Odeyomi,Kaushik Roy*

Main category: cs.CV

TL;DR: 提出了一种轻量级CNN结合SE注意力模块的Deepfake检测模型，性能优异且计算资源需求低。

- Motivation: Deepfake技术威胁信息真实性，现有检测模型体积大且资源消耗高，需高效解决方案。
- Method: 设计轻量级CNN模型，集成SE注意力模块动态调整特征权重，提升检测效率。
- Result: 在Style GAN数据集上分类准确率94.14%，AUC-ROC得分0.985。
- Conclusion: 该模型为Deepfake检测提供了高效、可扩展的解决方案。


### [69] [Unsourced Adversarial CAPTCHA: A Bi-Phase Adversarial CAPTCHA Framework](https://arxiv.org/abs/2506.10685)
*Xia Du,Xiaoyuan Liu,Jizhe Zhou,Zheng Lin,Chi-man Pun,Zhe Chen,Wei Ni,Jun Luo*

Main category: cs.CV

TL;DR: 本文提出了一种名为UAC的新型框架，通过文本提示生成高保真对抗样本，解决了传统CAPTCHA在深度学习攻击下的脆弱性问题。

- Motivation: 传统CAPTCHA方案在深度神经网络攻击下日益脆弱，现有对抗攻击方法依赖原始图像特征，导致失真且适用性受限。
- Method: 提出UAC框架，利用大语言模型（LLM）生成对抗样本；针对定向攻击采用EDICT方法优化扩散模型；针对非定向攻击提出BP-UAC策略，结合多模态梯度和双路径优化。
- Result: 实验表明BP-UAC在多种系统中攻击成功率高，生成的CAPTCHA对人类和DNN均难以区分。
- Conclusion: UAC框架显著提升了CAPTCHA的多样性和对抗攻击效果，为安全领域提供了新思路。


### [70] [Underage Detection through a Multi-Task and MultiAge Approach for Screening Minors in Unconstrained Imagery](https://arxiv.org/abs/2506.10689)
*Christopher Gaul,Eduardo Fidalgo,Enrique Alegre,Rocío Alaiz Rodríguez,Eri Pérez Corral*

Main category: cs.CV

TL;DR: 提出一种多任务架构，结合FaRL视觉语言骨干网络和紧凑MLP，用于未成年人年龄筛查，解决数据不平衡和分布偏移问题。

- Motivation: 解决未成年人数据不足和分布偏移对自动筛查模型的挑战。
- Method: 使用多任务架构，结合年龄回归和多个二元分类任务，采用α加权焦点损失和年龄平衡采样。
- Result: 模型在ASORES-39k测试集上RMSE降低至5.656，F2分数提升至0.857；在ASWIFT-20k测试集上保持高召回率。
- Conclusion: 提出的方法在年龄估计和未成年人检测任务中表现出色，具有强泛化能力。


### [71] [Continual Hyperbolic Learning of Instances and Classes](https://arxiv.org/abs/2506.10710)
*Melika Ayoughi,Mina Ghadimi Atigh,Mohammad Mahdi Derakhshani,Cees G. M. Snoek,Pascal Mettes,Paul Groth*

Main category: cs.CV

TL;DR: 论文提出了一种名为HyperCLIC的持续学习算法，用于同时处理实例和类别的层次结构学习，利用双曲空间建模层次关系，并在动态真实环境中验证了其有效性。

- Motivation: 现实应用（如机器人和自动驾驶汽车）需要模型同时处理实例和类别的持续学习，但传统方法仅关注其中之一。论文旨在解决这一挑战。
- Method: 提出HyperCLIC算法，利用双曲空间建模层次关系，结合双曲分类和蒸馏目标，实现层次关系的持续嵌入。
- Result: 在EgoObjects数据集上验证，HyperCLIC在多层次粒度上表现优异，提升了层次泛化能力。
- Conclusion: HyperCLIC能有效处理实例和类别的层次结构持续学习，适用于动态真实环境。


### [72] [Uncertainty-Masked Bernoulli Diffusion for Camouflaged Object Detection Refinement](https://arxiv.org/abs/2506.10712)
*Yuqi Shen,Fengyang Xiao,Sujie Hu,Youwei Pang,Yifan Pu,Chengyu Fang,Xiu Li,Chunming He*

Main category: cs.CV

TL;DR: 提出UMBD模型，首个专为COD设计的生成式细化框架，通过不确定性引导的掩蔽机制选择性优化分割质量差的区域，显著提升性能。

- Motivation: 现有COD方法在目标与背景视觉差异细微的情况下仍有优化空间，尤其是后处理细化未被充分探索。
- Method: 提出UMBD模型，结合不确定性引导的掩蔽机制和Bernoulli扩散，选择性优化残差区域；设计HUQNet多分支网络融合多源不确定性以提高估计精度。
- Result: 在多个COD基准测试中平均MAE提升5.5%，加权F-measure提升3.2%，计算开销适中。
- Conclusion: UMBD框架能无缝集成现有COD模型，结合判别与生成优势，显著提升性能。


### [73] [Deep Learning-based Multi Project InP Wafer Simulation for Unsupervised Surface Defect Detection](https://arxiv.org/abs/2506.10713)
*Emílio Dolgener Cantú,Rolf Klemens Wittmann,Oliver Abdeen,Patrick Wagner,Wojciech Samek,Moritz Baier,Sebastian Lapuschkin*

Main category: cs.CV

TL;DR: 论文提出了一种基于深度神经网络的方法，通过CAD数据生成合成黄金标准图像，用于半导体制造中的缺陷检测，显著优于传统决策树方法。

- Motivation: 半导体制造中，尤其是InP多项目晶圆制造，由于生产规模小和设计变异性高，缺乏黄金标准图像，导致缺陷检测依赖人工且效率低下。
- Method: 使用深度神经网络从CAD数据生成逼真的InP晶圆图像，评估不同训练目标，并在合成数据和实际照片上验证图像质量。
- Result: 深度学习方法优于基线决策树方法，能够从CAD计划生成模拟黄金标准图像，用于高效缺陷检测。
- Conclusion: 该方法在模板匹配中展示了实际应用价值，为表面缺陷检测提供了更高效的解决方案。


### [74] [IQE-CLIP: Instance-aware Query Embedding for Zero-/Few-shot Anomaly Detection in Medical Domain](https://arxiv.org/abs/2506.10730)
*Hong Huang,Weixiang Sun,Zhijian Wu,Jingwen Niu,Donghuan Lu,Xian Wu,Yefeng Zheng*

Main category: cs.CV

TL;DR: IQE-CLIP是一种基于CLIP的零样本和少样本异常检测框架，专为医学领域设计，通过结合文本和视觉信息生成异常敏感嵌入。

- Motivation: 现有CLIP方法依赖特定场景的文本提示，难以区分正常和异常实例，且医学领域探索有限。
- Method: 引入基于类和可学习的提示标记，设计实例感知查询模块提取区域级上下文信息。
- Result: 在六个医学数据集上实现最先进的零样本和少样本性能。
- Conclusion: IQE-CLIP有效解决了医学领域异常检测的局限性。


### [75] [PosterCraft: Rethinking High-Quality Aesthetic Poster Generation in a Unified Framework](https://arxiv.org/abs/2506.10741)
*SiXiang Chen,Jianyu Lai,Jialin Gao,Tian Ye,Haoyu Chen,Hengyu Shi,Shitong Shao,Yunlong Lin,Song Fei,Zhaohu Xing,Yeying Jin,Junfeng Luo,Xiaoming Wei,Lei Zhu*

Main category: cs.CV

TL;DR: PosterCraft是一个统一的框架，用于生成高质量的海报，通过多阶段优化流程提升文本渲染、布局和美学效果。

- Motivation: 生成美观的海报比简单设计更具挑战性，需要精确的文本渲染和艺术内容的无缝融合。
- Method: PosterCraft采用级联工作流，包括大规模文本渲染优化、区域感知微调、美学文本强化学习和联合视觉语言反馈细化。
- Result: PosterCraft在渲染准确性、布局连贯性和视觉吸引力方面显著优于开源基线，接近商业系统的水平。
- Conclusion: PosterCraft通过自动化数据构建和多阶段优化，实现了高质量海报的生成，代码和数据集已开源。


### [76] [Stroke-based Cyclic Amplifier: Image Super-Resolution at Arbitrary Ultra-Large Scales](https://arxiv.org/abs/2506.10774)
*Wenhao Guo,Peng Lu,Xujun Peng,Zhaoran Zhao,Sheng Li*

Main category: cs.CV

TL;DR: 论文提出了一种基于笔画的循环放大器（SbCA）模型，用于解决超大规模图像超分辨率任务中的性能下降和模糊问题。

- Motivation: 现有的任意尺度图像超分辨率方法在超出训练数据范围的上采样因子时性能显著下降，导致模糊。
- Method: SbCA通过笔画向量放大器将图像分解为矢量图形进行放大，并通过细节补全模块恢复缺失细节，采用循环策略迭代优化。
- Result: 实验表明，SbCA在超大规模上采样任务（如×100）中显著优于现有方法，生成的高分辨率图像质量更高。
- Conclusion: SbCA有效解决了分布漂移问题，消除了伪影、噪声和模糊，为超大规模图像超分辨率提供了高质量解决方案。


### [77] [SlotPi: Physics-informed Object-centric Reasoning Models](https://arxiv.org/abs/2506.10778)
*Jian Li,Wan Han,Ning Lin,Yu-Liang Zhan,Ruizhi Chengze,Haining Wang,Yi Zhang,Hongsheng Liu,Zidong Wang,Fan Yu,Hao Sun*

Main category: cs.CV

TL;DR: SlotPi是一种基于物理知识的对象中心推理模型，解决了现有方法在物理知识整合和场景适应性验证上的不足。

- Motivation: 人类通过观察世界获取物理知识并推理动态场景，现有方法缺乏物理知识整合和多样化场景验证。
- Method: SlotPi结合了基于哈密顿原理的物理模块和时空预测模块，用于动态预测。
- Result: 在基准和流体数据集上，SlotPi在预测和视觉问答任务中表现优异，并在新创建的真实世界数据集中验证了其适应性。
- Conclusion: SlotPi的强适应性为开发更先进的世界模型奠定了基础。


### [78] [Human-Robot Navigation using Event-based Cameras and Reinforcement Learning](https://arxiv.org/abs/2506.10790)
*Ignacio Bugueno-Cordova,Javier Ruiz-del-Solar,Rodrigo Verschae*

Main category: cs.CV

TL;DR: 论文提出了一种结合事件相机与强化学习的机器人导航控制器，实现实时人中心导航与避障。

- Motivation: 传统图像控制器存在固定帧率、运动模糊和延迟问题，事件相机的异步特性可解决这些问题。
- Method: 结合事件相机感知、其他距离传感器及深度确定性策略梯度（DDPG）优化策略，并通过模仿学习提高样本效率。
- Result: 在模拟环境中展示了鲁棒的导航、行人跟随和避障能力。
- Conclusion: 该方法通过事件相机和强化学习的结合，有效提升了机器人导航的实时性和适应性。


### [79] [Prompts to Summaries: Zero-Shot Language-Guided Video Summarization](https://arxiv.org/abs/2506.10807)
*Mario Barbara,Alaa Maalouf*

Main category: cs.CV

TL;DR: 提出了一种无需训练数据的零样本视频摘要方法，通过结合视频语言模型和大语言模型，实现用户可控的摘要生成。

- Motivation: 视频数据爆炸式增长，需要无需领域特定训练数据的灵活摘要工具，现有方法依赖数据集或无法结合用户自然语言意图。
- Method: 利用视频语言模型生成场景描述，通过大语言模型评分，结合一致性和独特性指标生成细粒度摘要。
- Result: 在SumMe和TVSum上超越无监督方法，在QFVS上表现竞争力，无需训练数据。
- Conclusion: 预训练多模态模型结合提示和分数传播，为通用文本查询视频摘要提供了强大基础。


### [80] [Unsupervised Deformable Image Registration with Structural Nonparametric Smoothing](https://arxiv.org/abs/2506.10813)
*Hang Zhang,Xiang Chen,Renjiu Hu,Rongguang Wang,Jinwei Zhang,Min Liu,Yaonan Wang,Gaolei Li,Xinxing Cheng,Jinming Duan*

Main category: cs.CV

TL;DR: SmoothProper是一种即插即用的神经模块，用于解决稀疏特征和大位移挑战的无监督图像配准问题。

- Motivation: 传统无监督DIR方法在稀疏特征和大位移场景下表现不佳，因为神经网络预测的变形场缺乏约束。
- Method: 通过引入基于对偶优化的层和定制交互项，SmoothPropagate在网络的单次前向传递中实现平滑性和消息传递。
- Result: 在视网膜血管数据集上，SmoothProper将配准误差降至1.88像素，首次有效解决了稀疏特征和大位移问题。
- Conclusion: SmoothProper是一种模型无关、无需超参数调优的解决方案，显著提升了无监督DIR的性能。


### [81] [Occlusion-Aware 3D Hand-Object Pose Estimation with Masked AutoEncoders](https://arxiv.org/abs/2506.10816)
*Hui Yang,Wei Sun,Jian Liu,Jin Zheng,Jian Xiao,Ajmal Mian*

Main category: cs.CV

TL;DR: 论文提出了一种基于掩码自编码器的遮挡感知手-物体姿态估计方法HOMAE，通过目标聚焦掩码策略和多尺度特征融合，显著提升了遮挡情况下的估计性能。

- Motivation: 现有方法在遮挡情况下表现不佳，主要原因是缺乏全局结构感知和推理能力。
- Method: 提出目标聚焦掩码策略，结合多尺度特征预测有符号距离场（SDF），并与点云融合，增强几何感知。
- Result: 在DexYCB和HO3Dv2基准测试中达到最先进性能。
- Conclusion: HOMAE通过融合全局和局部几何信息，有效解决了遮挡问题，提升了姿态估计的鲁棒性。


### [82] [VideoDeepResearch: Long Video Understanding With Agentic Tool Using](https://arxiv.org/abs/2506.10821)
*Huaying Yuan,Zheng Liu,Junjie Zhou,Ji-Rong Wen,Zhicheng Dou*

Main category: cs.CV

TL;DR: VideoDeepResearch挑战了传统观点，仅通过文本推理模型和多模态工具包实现长视频理解，显著优于现有方法。

- Motivation: 长视频理解（LVU）任务复杂且受限于上下文窗口，传统认为需要多模态大语言模型（MLLMs）支持。本文挑战这一观点。
- Method: 提出VideoDeepResearch框架，结合文本推理模型（LRM）和多模态工具包（检索器和视觉感知器），通过选择性访问视频内容完成任务。
- Result: 在MLVU、LVBench和LongVideoBench上分别提升9.6%、6.6%和3.9%，超越现有MLLM基线。
- Conclusion: 代理系统在解决LVU问题中具有潜力，无需依赖复杂MLLMs。


### [83] [Post-Training Quantization for Video Matting](https://arxiv.org/abs/2506.10840)
*Tianrui Zhu,Houyuan Chen,Ruihao Gong,Michele Magno,Haotong Qin,Kai Zhang*

Main category: cs.CV

TL;DR: 本文提出了一种专为视频抠图设计的后训练量化（PTQ）框架PTQ4VM，通过两阶段策略、全局仿射校准和光流辅助组件，显著提升了量化模型的精度和时序一致性，甚至在4位量化下接近全精度性能。

- Motivation: 视频抠图在资源受限设备上部署时面临计算密集型模型的挑战，而现有的后训练量化方法在保持精度和时序一致性方面存在不足。
- Method: 提出两阶段PTQ策略（块重建优化和全局校准）、统计驱动的全局仿射校准（GAC）方法，以及光流辅助（OFA）组件。
- Result: PTQ4VM在不同比特宽度下均达到最先进精度，4位量化下性能接近全精度模型，同时计算量减少8倍。
- Conclusion: PTQ4VM为视频抠图量化提供了高效解决方案，显著提升了量化模型的性能和应用潜力。


### [84] [VRBench: A Benchmark for Multi-Step Reasoning in Long Narrative Videos](https://arxiv.org/abs/2506.10857)
*Jiashuo Yu,Yue Wu,Meng Chu,Zhifei Ren,Zizheng Huang,Pei Chu,Ruijie Zhang,Yinan He,Qirui Li,Songze Li,Zhenxiang Li,Zhongying Tu,Conghui He,Yu Qiao,Yali Wang,Yi Wang,Limin Wang*

Main category: cs.CV

TL;DR: VRBench是首个针对大模型多步推理能力的长叙事视频基准，包含1,010个长视频和大量标注数据，通过多阶段筛选和专家评审确保质量，并提出了多维度评估方法。

- Motivation: 现有评估方法忽视了时间推理和程序有效性，VRBench旨在填补这一空白，推动多步推理领域的发展。
- Method: 通过多阶段筛选和专家评审构建数据集，开发人机协作框架生成连贯推理链，并设计多阶段评估流程。
- Result: 评估了12个LLM和16个VLM，提供了深入分析和有价值的见解。
- Conclusion: VRBench为多步推理评估提供了全面工具，推动了该领域的进步。


### [85] [CreatiPoster: Towards Editable and Controllable Multi-Layer Graphic Design Generation](https://arxiv.org/abs/2506.10890)
*Zhao Zhang,Yutao Cheng,Dexiang Hong,Maoke Yang,Gonglei Shi,Lei Ma,Hui Zhang,Jie Shao,Xinglong Wu*

Main category: cs.CV

TL;DR: CreatiPoster是一个生成可编辑、多层图形设计的框架，结合自然语言指令或用户提供的素材，通过协议模型和条件背景模型实现专业级设计。

- Motivation: 当前AI工具在图形设计中难以准确整合用户素材、保持可编辑性和专业视觉吸引力，商业系统依赖模板库，难以复制。
- Method: 使用协议模型生成JSON规范，详细描述每层布局、层次、内容和样式，再通过条件背景模型合成背景。
- Result: CreatiPoster在图形设计生成方面超越开源和商业系统，并发布10万份无版权多层设计数据集。
- Conclusion: CreatiPoster推动了AI辅助图形设计的民主化，支持多种应用场景。


### [86] [AIR: Zero-shot Generative Model Adaptation with Iterative Refinement](https://arxiv.org/abs/2506.10895)
*Guimeng Liu,Milad Abdollahzadeh,Ngai-Man Cheung*

Main category: cs.CV

TL;DR: 论文提出了一种零样本生成模型适应方法（ZSGM），通过分析CLIP嵌入空间中文本偏移与图像偏移的不对齐问题，提出了一种改进方法AIR，显著提升了生成图像的质量。

- Motivation: 现有ZSGM方法假设图像偏移与文本偏移在CLIP嵌入空间中完全对齐，导致生成图像质量下降。本文旨在通过分析偏移不对齐问题并提出改进方法来解决这一局限性。
- Method: 首先对CLIP嵌入空间中文本偏移与图像偏移的不对齐进行实证研究，发现偏移不对齐与概念距离相关。随后提出Adaptation with Iterative Refinement (AIR)方法，基于偏移不对齐的新见解改进生成质量。
- Result: 在26种实验设置中，AIR方法在定性、定量和用户研究中均表现出最先进的性能。
- Conclusion: AIR方法通过关注偏移不对齐问题，显著提升了零样本生成模型适应中的图像质量，为未来研究提供了新方向。


### [87] [M4V: Multi-Modal Mamba for Text-to-Video Generation](https://arxiv.org/abs/2506.10915)
*Jiancheng Huang,Gengwei Zhang,Zequn Jie,Siyu Jiao,Yinlong Qian,Ling Chen,Yunchao Wei,Lin Ma*

Main category: cs.CV

TL;DR: M4V是一个基于Mamba架构的多模态文本到视频生成框架，通过多模态扩散Mamba块（MM-DiM）和奖励学习策略，显著降低了计算成本并提升了视频质量。

- Motivation: 解决传统Transformer在文本到视频生成中计算复杂度高的问题，同时提升多模态和时空建模的效率。
- Method: 提出多模态扩散Mamba块（MM-DiM），结合多模态令牌重组设计和奖励学习策略，优化计算效率和视频质量。
- Result: M4V在768×1280分辨率下生成视频时，FLOPs减少45%，并在实验中展示了高质量的视频生成能力。
- Conclusion: M4V通过高效的多模态Mamba框架，显著降低了计算成本并提升了视频生成质量，为文本到视频生成提供了实用解决方案。


### [88] [VINCIE: Unlocking In-context Image Editing from Video](https://arxiv.org/abs/2506.10941)
*Leigang Qu,Feng Cheng,Ziyan Yang,Qi Zhao,Shanchuan Lin,Yichun Shi,Yicong Li,Wenjie Wang,Tat-Seng Chua,Lu Jiang*

Main category: cs.CV

TL;DR: 本文提出了一种直接从视频中学习上下文图像编辑的方法，通过多模态序列标注和块因果扩散变换器，实现了强大的图像编辑能力。

- Motivation: 现有方法依赖任务特定流程和专家模型，限制了数据标注的灵活性。本文探索直接从视频学习上下文图像编辑的可能性。
- Method: 提出了一种可扩展的视频标注方法，设计块因果扩散变换器，通过三个代理任务（下一图像预测、当前分割预测、下一分割预测）进行训练。
- Result: 模型在上下文图像编辑任务中表现优异，并在多轮图像编辑基准测试中达到SOTA。此外，模型还展示了多概念组合、故事生成等能力。
- Conclusion: 直接从视频学习上下文图像编辑是可行的，模型在多种任务中表现出色，为未来研究提供了新方向。


### [89] [SpectralAR: Spectral Autoregressive Visual Generation](https://arxiv.org/abs/2506.10962)
*Yuanhui Huang,Weiliang Chen,Wenzhao Zheng,Yueqi Duan,Jie Zhou,Jiwen Lu*

Main category: cs.CV

TL;DR: 论文提出了一种基于频谱的自回归视觉生成框架（SpectralAR），通过将图像转换为有序频谱标记，实现了视觉序列的因果性，并在ImageNet-1K上取得了优异性能。

- Motivation: 现有方法将视觉序列构造为空间块进行自回归生成，但图像块本质上是并行的，与自回归建模的因果性矛盾。
- Method: 提出SpectralAR框架，通过嵌套频谱标记化将图像转换为有序频谱标记，并采用从粗到细的自回归生成方式。
- Result: 在ImageNet-1K上，SpectralAR仅用64个标记和310M参数即达到3.02 gFID。
- Conclusion: SpectralAR通过频谱视角实现了视觉序列的因果性，同时保持了标记效率，无需额外复杂设计。


### [90] [MMMG: A Massive, Multidisciplinary, Multi-Tier Generation Benchmark for Text-to-Image Reasoning](https://arxiv.org/abs/2506.10963)
*Yuxuan Luo,Yuhui Yuan,Junwen Chen,Haonan Cai,Ziyi Yue,Yuwei Yang,Fatima Zohra Daha,Ji Li,Zhouhui Lian*

Main category: cs.CV

TL;DR: 论文提出了知识图像生成任务和MMMG基准，用于评估图像生成模型的推理能力，发现现有模型表现不佳，并提出了一个开放基线FLUX-Reason。

- Motivation: 知识图像对人类文明和学习至关重要，但生成此类图像需要多模态推理能力，目前缺乏相关评估基准。
- Method: 提出MMMG基准，包含4,456个专家验证的知识图像-提示对，采用统一的KG表示，并引入MMMG-Score评估指标。
- Result: 评估16个先进文本到图像生成模型，发现推理能力不足（如GPT-4o得分仅50.20），并提出了FLUX-Reason基线（得分34.45）。
- Conclusion: MMMG基准揭示了图像生成模型的推理缺陷，FLUX-Reason为未来研究提供了开放基线。


### [91] [Beyond Attention or Similarity: Maximizing Conditional Diversity for Token Pruning in MLLMs](https://arxiv.org/abs/2506.10967)
*Qizhe Zhang,Mengzhen Liu,Lichen Li,Ming Lu,Yuan Zhang,Junwen Pan,Qi She,Shanghang Zhang*

Main category: cs.CV

TL;DR: CDPruner是一种新型视觉令牌剪枝方法，通过最大化保留令牌的条件多样性，显著降低多模态大语言模型的推理成本。

- Motivation: 多模态大语言模型中视觉令牌长度远大于文本令牌，导致高推理成本，现有方法存在冗余或忽略指令相关性的问题。
- Method: 提出CDPruner，基于条件多样性和DPP优化令牌剪枝，无需训练且模型无关。
- Result: 在多种MLLMs上达到SOTA性能，LLaVA上FLOPs减少95%，延迟降低78%，保持94%准确率。
- Conclusion: CDPruner通过条件多样性优化令牌选择，高效且通用，显著提升性能。


### [92] [GenWorld: Towards Detecting AI-generated Real-world Simulation Videos](https://arxiv.org/abs/2506.10975)
*Weiliang Chen,Wenzhao Zheng,Yu Zheng,Lei Chen,Jie Zhou,Jiwen Lu,Yueqi Duan*

Main category: cs.CV

TL;DR: 本文提出GenWorld数据集和SpannDetector模型，用于检测高质量AI生成视频，提升真实世界场景下的检测能力。

- Motivation: AI生成视频技术威胁信息可信度，现有检测方法因缺乏高质量真实数据集而受限。
- Method: 构建GenWorld数据集（真实模拟、高质量、多样化），并提出基于多视角一致性的SpannDetector模型。
- Result: SpannDetector在实验中表现优异，揭示了基于物理合理性的可解释检测方向。
- Conclusion: GenWorld和SpannDetector为AI生成视频检测领域提供了新思路和工具。


### [93] [QuadricFormer: Scene as Superquadrics for 3D Semantic Occupancy Prediction](https://arxiv.org/abs/2506.10977)
*Sicheng Zuo,Wenzhao Zheng,Xiaoyong Han,Longchao Yang,Yong Pan,Jiwen Lu*

Main category: cs.CV

TL;DR: 提出了一种基于超二次曲面（superquadrics）的3D占用预测方法QuadricFormer，通过几何表达性强的超二次曲面作为场景基元，高效建模复杂结构。

- Motivation: 现有方法（如密集体素或稀疏高斯）在效率和形状多样性上存在不足，无法高效建模真实驾驶场景中的复杂几何结构。
- Method: 使用超二次曲面作为场景基元，提出概率超二次曲面混合模型，并结合剪枝-分裂模块优化建模效率。
- Result: 在nuScenes数据集上实现了最先进的性能，同时保持了高效性。
- Conclusion: QuadricFormer通过超二次曲面的几何多样性，显著提升了3D占用预测的效率和准确性。


### [94] [Fine-Grained Perturbation Guidance via Attention Head Selection](https://arxiv.org/abs/2506.10978)
*Donghoon Ahn,Jiwon Kang,Sanghyun Lee,Minjae Kim,Jaewon Min,Wooseok Jang,Saungwu Lee,Sayak Paul,Susung Hong,Seungryong Kim*

Main category: cs.CV

TL;DR: 论文提出了一种名为HeadHunter的系统框架，通过迭代选择注意力头来实现对生成质量和视觉属性的细粒度控制，并引入SoftPAG方法调节扰动强度。

- Motivation: 现有注意力扰动方法缺乏确定扰动位置的原则性方法，尤其是在DiT架构中，质量相关计算分布在多个层中。
- Method: 研究注意力扰动的粒度（从层级到单个注意力头），提出HeadHunter框架和SoftPAG方法，通过线性插值调节扰动强度。
- Result: 在Stable Diffusion 3和FLUX.1等模型上验证，展示了在质量提升和风格特定指导方面的优越性能。
- Conclusion: 首次在扩散模型中进行了头级注意力扰动分析，揭示了注意力层的可解释性专业化，并提供了有效扰动策略的实用设计。


### [95] [InstaInpaint: Instant 3D-Scene Inpainting with Masked Large Reconstruction Model](https://arxiv.org/abs/2506.10980)
*Junqi You,Chieh Hubert Lin,Weijie Lyu,Zhengbo Zhang,Ming-Hsuan Yang*

Main category: cs.CV

TL;DR: InstaInpaint是一种基于参考的前馈框架，能在0.4秒内完成3D场景修复，速度比现有方法快1000倍，同时保持高性能。

- Motivation: 当前3D场景修复方法计算耗时，无法满足实时或在线应用需求。
- Method: 提出InstaInpaint框架，结合自监督掩码微调策略训练大型重建模型（LRM）。
- Result: 在标准基准测试中表现优异，支持灵活的下游应用（如物体插入和多区域修复）。
- Conclusion: InstaInpaint在速度和性能上均优于现有方法，适用于实时3D场景修复。


### [96] [SceneCompleter: Dense 3D Scene Completion for Generative Novel View Synthesis](https://arxiv.org/abs/2506.10981)
*Weiliang Chen,Jiayi Bi,Yuanhui Huang,Wenzhao Zheng,Yueqi Duan*

Main category: cs.CV

TL;DR: SceneCompleter提出了一种通过密集3D场景补全实现3D一致的生成式新视角合成框架，解决了现有方法因依赖2D补全和3D恢复而导致的几何失真问题。

- Motivation: 现有生成模型在新视角合成中依赖2D补全和3D恢复，导致几何失真和平滑表面问题。
- Method: 提出SceneCompleter框架，包含几何-外观双流扩散模型和场景编码器，联合合成RGBD空间的新视角。
- Result: 方法在多样数据集上展示了更高的视觉一致性和几何合理性。
- Conclusion: SceneCompleter通过融合结构和纹理信息，实现了更优的生成式新视角合成。
## cs.CL

### [97] [A Survey of Automatic Evaluation Methods on Text, Visual and Speech Generations](https://arxiv.org/abs/2506.10019)
*Tian Lan,Yang-Hao Zhou,Zi-Ao Ma,Fanshu Sun,Rui-Qing Sun,Junyu Luo,Rong-Cheng Tu,Heyan Huang,Chen Xu,Zhijing Wu,Xian-Ling Mao*

Main category: cs.CL

TL;DR: 本文综述了生成内容自动评估方法的现状，提出了一个跨文本、图像和音频模态的统一分类框架，并探讨了未来研究方向。

- Motivation: 当前缺乏一个系统性的框架来全面组织跨模态的生成内容自动评估方法。
- Method: 通过分析文本生成评估方法，扩展到图像和音频领域，提出五种基本范式。
- Result: 建立了一个统一的分类框架，适用于三种模态的评估方法。
- Conclusion: 未来研究应关注跨模态评估方法的发展。


### [98] [Burn After Reading: Do Multimodal Large Language Models Truly Capture Order of Events in Image Sequences?](https://arxiv.org/abs/2506.10415)
*Yingjin Song,Yupei Du,Denis Paperno,Albert Gatt*

Main category: cs.CL

TL;DR: TempVS是一个专注于多模态大语言模型（MLLMs）在图像序列中时间推理能力的基准测试，包含三种主要测试和基础任务，评估显示MLLMs表现远低于人类水平。

- Motivation: 评估和提升MLLMs在时间推理和视觉-语言模态结合方面的能力。
- Method: 设计TempVS基准测试，包含事件关系推理、句子排序和图像排序任务，并评估38种MLLMs。
- Result: MLLMs在TempVS上表现不佳，与人类能力存在显著差距。
- Conclusion: TempVS为未来研究提供了方向，数据和代码已开源。
## cs.RO

### [99] [A Navigation Framework Utilizing Vision-Language Models](https://arxiv.org/abs/2506.10172)
*Yicheng Duan,Kaiyu tang*

Main category: cs.RO

TL;DR: 提出了一种模块化的视觉语言导航框架，通过解耦视觉语言理解和动作规划，结合轻量级规划逻辑和冻结的视觉语言模型，实现高效导航。

- Motivation: 解决现有大型视觉语言模型在计算成本和实时部署上的挑战，同时提升导航系统的灵活性和适应性。
- Method: 采用模块化设计，结合冻结的视觉语言模型（Qwen2.5-VL-7B-Instruct）和轻量级规划逻辑，利用提示工程、结构化历史管理和双帧视觉输入策略。
- Result: 在Room-to-Room基准测试中初步验证了框架的有效性，但在未见环境中的泛化能力仍有挑战。
- Conclusion: 模块化方法为可扩展和高效的导航系统奠定了基础，未来可通过增强环境先验和扩展多模态输入进一步改进。


### [100] [EmbodiedGen: Towards a Generative 3D World Engine for Embodied Intelligence](https://arxiv.org/abs/2506.10600)
*Wang Xinjie,Liu Liu,Cao Yu,Wu Ruiqi,Qin Wenkang,Wang Dehui,Sui Wei,Su Zhizhong*

Main category: cs.RO

TL;DR: EmbodiedGen是一个用于生成高质量、可控且逼真的3D资产的基础平台，旨在解决现有3D资产成本高、真实性不足的问题，支持具身智能任务的可扩展性。

- Motivation: 当前具身智能任务依赖传统3D图形资产，成本高且真实性有限，限制了数据驱动方法的扩展性。
- Method: EmbodiedGen通过六个模块（如图像/文本转3D、纹理生成等）生成交互式3D世界，利用生成式AI技术。
- Result: 生成多样化、交互式的3D资产，支持物理模拟引擎导入，适用于具身智能任务的训练与评估。
- Conclusion: EmbodiedGen为具身智能研究提供了低成本、高质量的3D资产生成工具，解决了现有方法的局限性。


### [101] [Eye, Robot: Learning to Look to Act with a BC-RL Perception-Action Loop](https://arxiv.org/abs/2506.10968)
*Justin Kerr,Kush Hari,Ethan Weber,Chung Min Kim,Brent Yi,Tyler Bonnen,Ken Goldberg,Angjoo Kanazawa*

Main category: cs.RO

TL;DR: EyeRobot是一个通过强化学习训练机械眼球实现任务驱动的注视行为的机器人系统，结合手眼协调完成大范围工作空间操作任务。

- Motivation: 人类通过主动观察来行动，受此启发，开发一个能根据任务需求自主调整注视行为的机器人系统。
- Method: 使用360度摄像头收集演示数据，在仿真环境中训练注视策略（RL）和手部动作（BC），通过BC-RL循环实现手眼协调。
- Result: EyeRobot在五个全景工作空间操作任务中表现出有效的手眼协调能力，能够稳定注视并忽略干扰。
- Conclusion: EyeRobot通过任务驱动的注视策略实现了大范围工作空间的高效操作，验证了手眼协调的重要性。
## cs.GR

### [102] [Learning-based density-equalizing map](https://arxiv.org/abs/2506.10027)
*Yanwen Huang,Lok Ming Lui,Gary P. T. Choi*

Main category: cs.GR

TL;DR: 提出了一种基于深度学习的密度均衡映射框架（LDEM），解决了传统方法在精度、重叠伪影和2D到3D扩展中的问题。

- Motivation: 传统密度均衡映射方法存在精度低、极端情况下产生重叠伪影以及难以从2D扩展到3D的问题。
- Method: 使用深度神经网络，设计损失函数确保密度均匀性和几何规则性，采用分层方法预测粗粒度和密集级别的变换。
- Result: LDEM在密度均衡和双射性方面优于现有方法，适用于简单和复杂密度分布，并能无缝扩展到3D。
- Conclusion: LDEM为密度均衡映射的稳健计算提供了新思路，具有广泛的应用潜力。


### [103] [Low-Barrier Dataset Collection with Real Human Body for Interactive Per-Garment Virtual Try-On](https://arxiv.org/abs/2506.10468)
*Zaiqiang Wu,Yechen Li,Jingyuan Liu,Yuki Shibata,Takayuki Hori,I-Chao Shen,Takeo Igarashi*

Main category: cs.GR

TL;DR: 提出了一种低成本、基于真实人体的虚拟试衣方法，解决了现有方法依赖昂贵机器人模型和服装对齐不准确的问题。

- Motivation: 现有虚拟试衣方法局限于前视图且缺乏实时性，而基于单服装的方法虽有所改进，但仍受限于高昂成本和人体变形不自然。
- Method: 采用真实人体采集服装数据，避免使用机器人模型，并引入混合人物表示（结合简化DensePose图）以提升服装对齐效果。
- Result: 在图像质量和时间一致性上优于现有方法，用户研究表明系统有助于服装购买决策。
- Conclusion: 该方法低成本、高效，解决了虚拟试衣中的关键问题，具有实际应用价值。


### [104] [Edit360: 2D Image Edits to 3D Assets from Any Angle](https://arxiv.org/abs/2506.10507)
*Junchao Huang,Xinting Hu,Zhuotao Tian,Shaoshuai Shi,Li Jiang*

Main category: cs.GR

TL;DR: Edit360是一个无需调优的框架，将2D编辑扩展到多视角一致的3D编辑，利用视频扩散模型实现任意视角的用户定制编辑。

- Motivation: 现有方法通常限制在预定的视角进行编辑，缺乏灵活性，难以实现多视角一致性。
- Method: 基于视频扩散模型，引入Anchor-View Editing Propagation机制，通过选择锚点视角并传播编辑到360度范围。
- Result: 实现了高质量3D资产的重建，支持多视角一致的自定义3D内容生成。
- Conclusion: Edit360为3D编辑提供了灵活且一致的解决方案，扩展了扩散模型的应用范围。


### [105] [Transformer IMU Calibrator: Dynamic On-body IMU Calibration for Inertial Motion Capture](https://arxiv.org/abs/2506.10580)
*Chengxu Zuo,Jiawei Huang,Xiao Jiang,Yuan Yao,Xiangren Shi,Rui Cao,Xinyu Yi,Feng Xu,Shihui Guo,Yipeng Qin*

Main category: cs.GR

TL;DR: 提出了一种新型的动态校准方法，用于稀疏惯性运动捕捉系统，首次打破了IMU校准中的绝对静态假设，显著扩展了应用场景。

- Motivation: 传统的IMU校准方法依赖于绝对静态假设，限制了其应用场景。本文旨在通过放松假设，实现动态校准。
- Method: 通过两个放松假设（短时间窗口内矩阵变化可忽略，且运动/IMU读数多样化），利用Transformer模型学习矩阵与IMU读数的映射关系，并设计校准触发器。
- Result: 首次实现了隐式IMU校准，无需显式校准过程，同时实现了稀疏IMU的长期高精度运动捕捉。
- Conclusion: 该方法突破了传统限制，为IMU的动态校准和广泛应用提供了新思路。
## physics.med-ph

### [106] [Modality-AGnostic Image Cascade (MAGIC) for Multi-Modality Cardiac Substructure Segmentation](https://arxiv.org/abs/2506.10797)
*Nicholas Summerfield,Qisheng He,Alex Kuo,Ahmed I. Ghanem,Simeng Zhu,Chase Ruff,Joshua Pan,Anudeep Kumar,Prashant Nagpal,Jiwei Zhao,Ming Dong,Carri K. Glide-Hurst*

Main category: physics.med-ph

TL;DR: 该论文提出了一种名为MAGIC的模态无关图像级联方法，用于多模态心脏亚结构分割，旨在解决深度学习在跨模态和重叠结构分割中的泛化性问题。

- Motivation: 心脏亚结构在胸部放射治疗规划中至关重要，但现有深度学习方法在跨模态和重叠结构分割上缺乏泛化性。
- Method: MAGIC通过复制的编码和解码分支实现，基于nnU-Net的U形架构，支持多模态分割。实验使用76例训练、15例验证和30例测试数据，涵盖三种模态。
- Result: MAGIC在57%的案例中优于对比模型，平均DSC得分为0.75（Sim-CT）、0.68（MR-Linac）和0.80（CCTA）。
- Conclusion: MAGIC提供了一种轻量级、高效的多模态分割解决方案，简化了临床计算需求并提高了灵活性。
## eess.IV

### [107] [Rethinking Brain Tumor Segmentation from the Frequency Domain Perspective](https://arxiv.org/abs/2506.10142)
*Minye Shao,Zeyu Wang,Haoran Duan,Yawen Huang,Bing Zhai,Shizheng Wang,Yang Long,Yefeng Zheng*

Main category: eess.IV

TL;DR: HFF-Net通过频域视角改进脑肿瘤分割，利用频域分解和自适应卷积增强对肿瘤边界的敏感性，实验显示性能显著提升。

- Motivation: 现有方法在分割MRI中对比增强的脑肿瘤区域时性能不足，主要因未充分考虑MRI特异性特征（如复杂纹理和方向变化）。
- Method: 提出HFF-Net，包括频域分解模块（FDD）、自适应拉普拉斯卷积（ALC）和频域交叉注意力（FDCA），以多尺度融合肿瘤特征。
- Result: 在四个公开数据集上，HFF-Net平均Dice分数提升4.48%，对比增强区域分割提升7.33%。
- Conclusion: HFF-Net通过频域方法显著提升脑肿瘤分割性能，兼具计算效率和临床适用性。


### [108] [Prompt-Guided Latent Diffusion with Predictive Class Conditioning for 3D Prostate MRI Generation](https://arxiv.org/abs/2506.10230)
*Emerson P. Grabke,Masoom A. Haider,Babak Taati*

Main category: eess.IV

TL;DR: 论文提出了一种名为CCELLA的双头条件方法，用于解决医学图像生成中数据稀缺和性能限制的问题，显著提升了生成质量和分类器性能。

- Motivation: 医学图像生成中数据稀缺和现有方法的局限性（如依赖短提示文本编码器或非医学LDMs）促使开发更高效且科学可访问的方法。
- Method: 提出CCELLA，通过交叉注意力结合非医学大语言模型文本特征和病理分类，并设计联合损失函数和数据高效训练框架。
- Result: 在有限数据下，生成质量显著提升（3D FID 0.025），合成图像加入训练集使分类器准确率从69%提升至74%。
- Conclusion: CCELLA在数据稀缺条件下高效生成高质量医学图像，提升了生成和分类任务的性能。


### [109] [Conditional diffusion models for guided anomaly detection in brain images using fluid-driven anomaly randomization](https://arxiv.org/abs/2506.10233)
*Ana Lawry Aguila,Peirong Liu,Oula Puonti,Juan Eugenio Iglesias*

Main category: eess.IV

TL;DR: 提出了一种基于条件扩散模型的新框架，用于脑MRI中的异常检测和健康图像重建，通过合成伪病理图像改进重建效果，并在实验中表现优于现有方法。

- Motivation: 监督学习需要大量疾病数据，而罕见疾病数据稀缺。无监督异常检测方法（如扩散模型）仅需健康图像训练，但现有方法在重建健康组织或异常区域时表现不佳。
- Method: 采用弱监督方法，结合合成伪病理图像指导健康图像重建。通过流体驱动的异常随机化生成伪病理图像，确保其真实性和解剖一致性。
- Result: 模型在合成和真实病理数据集（如ATLAS）上表现优异，优于变分自编码器、条件/无条件潜在扩散模型，甚至部分监督修复方法。
- Conclusion: 提出的条件扩散模型框架在异常检测和健康图像重建中具有显著优势，尤其在数据稀缺情况下表现突出。


### [110] [DUN-SRE: Deep Unrolling Network with Spatiotemporal Rotation Equivariance for Dynamic MRI Reconstruction](https://arxiv.org/abs/2506.10309)
*Yuliang Zhu,Jing Cheng,Qi Xie,Zhuo-Xu Cui,Qingyong Zhu,Yuanyuan Liu,Xin Liu,Jianfeng Ren,Chengbo Wang,Dong Liang*

Main category: eess.IV

TL;DR: 论文提出了一种新型的深度展开网络DUN-SRE，用于动态MRI重建，通过时空旋转等变性显著提升图像质量。

- Motivation: 动态MRI具有时空对称性，现有方法未能有效利用时间对称性，限制了重建质量。
- Method: 提出DUN-SRE网络，结合(2+1)D等变卷积架构，将数据一致性和近端映射模块统一到深度展开框架中。
- Result: 在心脏CINE MRI数据集上，DUN-SRE实现了最先进的性能，尤其在保留旋转对称结构方面表现优异。
- Conclusion: DUN-SRE通过严格时空对称性约束，为动态MRI重建提供了更准确的物理建模，具有广泛适用性。


### [111] [SWDL: Stratum-Wise Difference Learning with Deep Laplacian Pyramid for Semi-Supervised 3D Intracranial Hemorrhage Segmentation](https://arxiv.org/abs/2506.10325)
*Cheng Wang,Siqi Chen,Donghua Mi,Yang Chen,Yudong Zhang,Yinsheng Li*

Main category: eess.IV

TL;DR: SWDL-Net是一种新型半监督学习框架，结合拉普拉斯金字塔和深度卷积上采样，用于颅内出血的医学图像分割，在仅有2%标注数据的情况下表现优于现有方法。

- Motivation: 医学图像标注成本高且耗时，尤其是颅内出血（ICH）的分割任务。半监督学习（SSL）可以缓解标注数据不足的问题，但传统SSL方法在高置信度伪标签或一致性正则化上表现有限。
- Method: 提出SWDL-Net框架，结合拉普拉斯金字塔的边缘锐化优势和深度卷积上采样的细节精确性，通过差异学习机制整合两者。
- Result: 在271例ICH数据集和公开基准测试中，SWDL-Net在仅2%标注数据的情况下优于现有方法；在BHSD数据集（5%标注数据）中也验证了其优越性。
- Conclusion: SWDL-Net通过互补方法整合，显著提升了半监督学习在医学图像分割中的性能，尤其在标注数据稀缺的情况下表现突出。


### [112] [ConStyX: Content Style Augmentation for Generalizable Medical Image Segmentation](https://arxiv.org/abs/2506.10675)
*Xi Chen,Zhiqiang Shen,Peng Cao,Jinzhu Yang,Osmar R. Zaiane*

Main category: eess.IV

TL;DR: 论文提出了一种名为ConStyX的新方法，通过内容和风格增强来解决医学图像分割中的域泛化问题，显著提升了模型的泛化性能。

- Motivation: 医学图像通常来自多个域，导致域偏移影响分割模型性能。现有域随机化方法依赖单一风格扰动且忽略过增强图像的负面影响。
- Method: 提出ConStyX方法，增强训练数据的内容和风格以覆盖更广域范围，并优化过增强特征的使用。
- Result: 多域实验表明ConStyX具有优越的泛化性能。
- Conclusion: ConStyX通过内容和风格增强有效解决了域泛化问题，代码已开源。


### [113] [Generalist Models in Medical Image Segmentation: A Survey and Performance Comparison with Task-Specific Approaches](https://arxiv.org/abs/2506.10825)
*Andrea Moglia,Matteo Leccardi,Matteo Cavicchioli,Alice Maccarini,Marco Marcon,Luca Mainardi,Pietro Cerveri*

Main category: eess.IV

TL;DR: 本文综述了通用模型在医学图像分割中的应用，重点介绍了Segment Anything Model (SAM)及其变体，并分析了其性能、挑战及未来方向。

- Motivation: 随着通用模型在计算机视觉领域的成功应用，本文旨在全面调查其在医学图像分割中的发展、性能及潜在挑战。
- Method: 通过分类和比较不同SAM变体（如零样本、少样本、微调等），以及与其他任务特定模型的对比，进行深入分析。
- Result: 通用模型在医学图像分割中表现出色，但仍需解决合规性、隐私、预算和可信AI等挑战。
- Conclusion: 未来研究方向包括合成数据、早期融合、NLP通用模型的经验借鉴、代理AI和临床转化。


### [114] [Med-URWKV: Pure RWKV With ImageNet Pre-training For Medical Image Segmentation](https://arxiv.org/abs/2506.10858)
*Zhenhuan Zhou*

Main category: eess.IV

TL;DR: Med-URWKV是一种基于纯RWKV的医学图像分割架构，利用预训练的VRWKV编码器提升性能，实验证明其优于从头训练的RWKV模型。

- Motivation: 探索预训练的VRWKV模型在医学图像分割任务中的潜力，解决现有方法（如CNN和Transformer）的局限性。
- Method: 提出Med-URWKV，基于U-Net框架，结合ImageNet预训练的VRWKV编码器。
- Result: 在七个数据集上表现优于从头训练的RWKV模型，验证了预训练编码器的有效性。
- Conclusion: Med-URWKV展示了预训练RWKV模型在医学图像分割中的潜力，性能优越且计算高效。


### [115] [Semi-Automated Quality Assurance in Digital Pathology: Tile Classification Approach](https://arxiv.org/abs/2506.10916)
*Meredith VandeHaar,M. Clinch,I. Yilmaz,M. A. Rahman,Y. Xiao,F. Dogany,H. M. Alazab,A. Nassar,Z. Akkus,B. Dangott*

Main category: eess.IV

TL;DR: 提出了一种基于深度学习的AI算法，用于数字病理学中的质量保证，通过分析切片并分类10种预定义伪影类型或背景，提高检测效率和准确性。

- Motivation: 数字病理学中的伪影对AI诊断模型性能有负面影响，现有方法依赖人工检查且未充分利用深度学习，亟需创新解决方案。
- Method: 采用InceptionResNet模型，通过不同切片尺寸和放大倍数的消融研究，训练单伪影和多实例模型，提出混合设计优化检测。
- Result: 实验基于133张全切片图像，验证了混合设计（单伪影二元模型和多实例模型）在伪影检测中的有效性。
- Conclusion: 混合设计能高效定位伪影，减少人工检查时间，为数字病理学质量保证提供了创新方法。
## eess.SP

### [116] [Ground Reaction Force Estimation via Time-aware Knowledge Distillation](https://arxiv.org/abs/2506.10265)
*Eun Som Jeon,Sinjini Mitra,Jisoo Lee,Omik M. Save,Ankita Shukla,Hyunglae Lee,Pavan Turaga*

Main category: eess.SP

TL;DR: 提出了一种基于时间感知知识蒸馏的框架，用于从鞋垫传感器数据中估计地面反作用力（GRF），解决了便携式传感器噪声多、精度低的问题。

- Motivation: 便携式鞋垫传感器因噪声和干扰导致GRF测量不准确，而传统跑步机测量设备昂贵且不便携。
- Method: 采用时间感知知识蒸馏框架，利用小批量数据中的相似性和时序特征，捕捉目标与输入数据的互补关系和时序特性。
- Result: 实验表明，该框架在GRF估计上优于现有基线方法。
- Conclusion: 时间感知知识蒸馏框架为便携式GRF测量提供了高精度解决方案。
## cs.MA

### [117] [AniMaker: Automated Multi-Agent Animated Storytelling with MCTS-Driven Clip Generation](https://arxiv.org/abs/2506.10540)
*Haoyuan Shi,Yunxin Li,Xinyu Chen,Longyue Wang,Baotian Hu,Min Zhang*

Main category: cs.MA

TL;DR: AniMaker是一个多智能体框架，通过高效生成多候选视频片段和故事感知的片段选择，解决了多场景、多角色视频生成中的连贯性问题。

- Motivation: 当前视频生成方法在生成多场景、多角色的连贯故事视频时存在叙事断裂和节奏问题，且单一片段质量低下会影响整体动画的逻辑和视觉一致性。
- Method: AniMaker采用多智能体框架，包括导演、摄影、评审和后制代理，结合MCTS-Gen和AniEval技术，优化片段生成和评估。
- Result: 实验表明，AniMaker在VBench和AniEval等指标上表现优异，显著提升了多候选生成效率。
- Conclusion: AniMaker推动了AI生成故事动画向生产标准迈进。
## cs.MM

### [118] [EQ-TAA: Equivariant Traffic Accident Anticipation via Diffusion-Based Accident Video Synthesis](https://arxiv.org/abs/2506.10002)
*Jianwu Fang,Lei-Lei Li,Zhedong Zheng,Hongkai Yu,Jianru Xue,Zhengguo Li,Tat-Seng Chua*

Main category: cs.MM

TL;DR: 论文提出了一种基于注意力视频扩散（AVD）的模型，用于生成交通事故视频片段，以解决交通场景中事故预测（TAA）的数据偏差问题。通过生成因果视频帧并结合等变TAA（EQ-TAA）方法，模型在无需额外标注的情况下取得了竞争性性能。

- Motivation: 当前交通场景中事故预测（TAA）方法依赖大量标注数据，且易受数据偏差影响。论文旨在通过生成因果视频片段，解决背景混杂问题，提升TAA性能。
- Method: 提出AVD模型，通过文本提示生成因果视频帧，并结合EQ-TAA方法，使用等变三重损失优化模型。
- Result: 实验表明，AVD和EQ-TAA在无需额外标注的情况下，性能优于现有方法。
- Conclusion: AVD和EQ-TAA为TAA提供了一种高效且无需标注的解决方案，显著提升了事故预测的准确性。


### [119] [HER2 Expression Prediction with Flexible Multi-Modal Inputs via Dynamic Bidirectional Reconstruction](https://arxiv.org/abs/2506.10006)
*Jie Qin,Wei Yang,Yan Su,Yiran Zhu,Weizhen Li,Yunyue Pan,Chengchang Pan,Honggang Qi*

Main category: cs.MM

TL;DR: 提出了一种自适应双模态框架，通过动态分支选择、双向跨模态GAN和混合训练协议，显著提升HER2预测的准确性和灵活性。

- Motivation: 现有HER2评估模型通常单独分析H&E或IHC图像，而临床依赖两者的协同解释。同时获取两种模态常受限于工作流程复杂性和成本。
- Method: 1) 动态分支选择器；2) 双向跨模态GAN；3) 混合训练协议。
- Result: 单模态H&E预测准确率从71.44%提升至94.25%，双模态准确率达95.09%，IHC输入可靠性为90.28%。
- Conclusion: 该框架在资源有限的环境中具有显著潜力，能够在不要求同步获取的情况下实现接近双模态的性能。


### [120] [Controllable Expressive 3D Facial Animation via Diffusion in a Unified Multimodal Space](https://arxiv.org/abs/2506.10007)
*Kangwei Liu,Junwu Liu,Xiaowei Yi,Jinlin Guo,Yun Cao*

Main category: cs.MM

TL;DR: 提出了一种基于扩散模型的多模态情感3D面部动画框架，解决了现有方法依赖单模态信号和确定性映射的问题。

- Motivation: 现有方法依赖单模态控制信号（如视频、文本或情感标签）且采用确定性回归映射，限制了情感表达的多样性和自然性。
- Method: 采用FLAME多模态情感绑定策略和注意力潜扩散模型，通过对比学习对齐多模态信号，并利用内容感知注意力和情感引导层增强运动多样性。
- Result: 实验表明，该方法在情感相似性上提升了21.6%，同时保持了生理合理的面部动态。
- Conclusion: 该框架通过多模态信号和扩散模型显著提升了3D面部动画的表达能力和自然性。


### [121] [Structured Graph Representations for Visual Narrative Reasoning: A Hierarchical Framework for Comics](https://arxiv.org/abs/2506.10008)
*Yi-Chun Chen*

Main category: cs.MM

TL;DR: 提出了一种分层知识图谱框架，用于结构化理解视觉叙事，如漫画。该方法将叙事内容分解为多个层次，并通过整合的知识图谱捕捉语义、空间和时间关系。

- Motivation: 解决视觉叙事（如漫画）的多模态理解和结构化分析问题，支持跨层次的推理任务。
- Method: 构建多层次知识图谱，从宏观故事弧到细粒度事件段，整合视觉元素（如角色、物体、动作）与文本组件（如对话、字幕）。
- Result: 在Manga109数据集上验证，支持动作检索、对话追踪等任务，表现出高精度和召回率。
- Conclusion: 为基于叙事的视觉媒体分析、交互式故事讲述和多模态推理提供了可扩展的基础。


### [122] [WDMIR: Wavelet-Driven Multimodal Intent Recognition](https://arxiv.org/abs/2506.10011)
*Weiyin Gong,Kai Zhang,Yanghai Zhang,Qi Liu,Xinjie Sun,Junyu Lu,Linbo Zhu*

Main category: cs.MM

TL;DR: 该论文提出了一种基于小波驱动的多模态意图识别框架（WDMIR），通过频域分析提升对非语言信息的理解，显著提高了识别准确率。

- Motivation: 现有方法主要关注文本分析，忽视了非语言线索中的丰富语义内容，因此需要一种更全面的方法来整合多模态信息。
- Method: 提出了小波驱动的融合模块和跨模态交互机制，分别用于频域特征分析和多模态特征增强。
- Result: 在MIntRec数据集上，WDMIR的准确率比之前方法提高了1.13%，且小波融合模块对非语言信息的语义提取效果显著（准确率提升0.41%）。
- Conclusion: WDMIR框架通过频域分析和跨模态交互，有效提升了多模态意图识别的性能，证明了非语言信息的重要性。
## cs.LG

### [123] [Omni-DPO: A Dual-Perspective Paradigm for Dynamic Preference Learning of LLMs](https://arxiv.org/abs/2506.10054)
*Shangpin Peng,Weinong Wang,Zhuotao Tian,Senqiao Yang,Xing Wu,Haotian Xu,Chengquan Zhang,Takashi Isobe,Baotian Hu,Min Zhang*

Main category: cs.LG

TL;DR: Omni-DPO是一种双视角优化框架，通过自适应加权偏好对的质量和模型学习动态，提升数据利用效率和性能表现。

- Motivation: 现有DPO方法忽略偏好对的固有质量和学习效用差异，导致数据利用和性能不佳。
- Method: 提出Omni-DPO，联合考虑偏好对的固有质量和模型学习动态，自适应加权样本。
- Result: 在文本理解和数学推理任务中，Omni-DPO显著优于基线方法，如Gemma-2-9b-it在Arena-Hard上超越Claude 3 Opus 6.7分。
- Conclusion: Omni-DPO通过双视角优化有效提升性能，具有广泛适用性和鲁棒性。


### [124] [Balanced Hyperbolic Embeddings Are Natural Out-of-Distribution Detectors](https://arxiv.org/abs/2506.10146)
*Tejaswi Kasarla,Max van Spengler,Pascal Mettes*

Main category: cs.LG

TL;DR: 论文提出了一种基于双曲嵌入的方法（Balanced Hyperbolic Learning），用于区分分布内和分布外样本，并在多个数据集和评分函数上验证了其优越性。

- Motivation: 解决深度学习中的分布外识别问题，提出双曲嵌入方法以提升性能。
- Method: 引入平衡双曲学习，优化层次失真和子层次平衡，并将双曲原型用于分类和分布外评分。
- Result: 在13个数据集和13个评分函数上，双曲嵌入方法优于现有方法，且支持层次化分布外泛化。
- Conclusion: 双曲嵌入是区分分布内外样本的有效方法，性能优于现有技术。


### [125] [Geometric Regularity in Deterministic Sampling of Diffusion-based Generative Models](https://arxiv.org/abs/2506.10177)
*Defang Chen,Zhenyu Zhou,Can Wang,Siwei Lyu*

Main category: cs.LG

TL;DR: 论文揭示了扩散生成模型中确定性采样轨迹的低维几何规律，并提出了一种动态规划方法优化采样时间表。

- Motivation: 探索扩散生成模型中采样轨迹的几何特性，以提升采样效率和生成质量。
- Method: 通过分析轨迹的低维子空间和形状规律，提出动态规划方法优化采样时间表。
- Result: 发现轨迹具有低维和“回旋镖”形状的规律，优化方法显著提升了图像生成性能。
- Conclusion: 采样轨迹的几何规律可用于优化生成模型，动态规划方法简单高效且性能优越。


### [126] [Deep Learning-Based Digitization of Overlapping ECG Images with Open-Source Python Code](https://arxiv.org/abs/2506.10617)
*Reza Karbasi,Masoud Rahimi,Abdol-Hossein Vahabie,Hadi Moradi*

Main category: cs.LG

TL;DR: 论文提出了一种两阶段方法，用于准确数字化纸质心电图（ECG）记录，特别解决了信号重叠问题。通过U-Net分割网络和自适应网格检测模块，显著提升了数字化精度。

- Motivation: 现有方法在信号重叠的ECG记录数字化中存在不足，影响了数据的可靠性和可用性。
- Method: 采用两阶段流程：1）U-Net分割网络隔离ECG主迹线；2）自适应网格检测模块将二值掩码转换为时间序列信号。
- Result: U-Net分割IoU达0.87；数字化方法在非重叠和重叠信号上均优于基线（MSE和Pearson系数显著提升）。
- Conclusion: 该方法显著提升了ECG数字化精度，尤其在信号重叠情况下，为研究和临床应用提供了可靠工具。


### [127] [Hessian Geometry of Latent Space in Generative Models](https://arxiv.org/abs/2506.10632)
*Alexander Lobashev,Dmitry Guskov,Maria Larchenko,Mikhail Tamm*

Main category: cs.LG

TL;DR: 本文提出了一种新方法，通过重构Fisher信息度量来分析生成模型的潜在空间几何结构，包括统计物理模型和扩散模型。

- Motivation: 研究生成模型潜在空间的几何结构及其与物理现象的关联，如相变。
- Method: 方法通过近似潜在变量的后验分布来学习对数配分函数，从而定义Fisher度量，并提供理论收敛保证。
- Result: 在Ising和TASEP模型上验证了方法的有效性，优于现有基线，并在扩散模型中揭示了潜在空间的相变分形结构。
- Conclusion: 该方法为扩散模型潜在空间的复杂结构及其与相变等现象的联系提供了新见解。


### [128] [ReGuidance: A Simple Diffusion Wrapper for Boosting Sample Quality on Hard Inverse Problems](https://arxiv.org/abs/2506.10955)
*Aayush Karan,Kulin Shah,Sitan Chen*

Main category: cs.LG

TL;DR: ReGuidance是一种简单的方法，用于提升基于预训练扩散模型的逆问题求解算法的样本真实性和奖励效果。

- Motivation: 现有方法（如DPS）在低信噪比的逆问题中容易偏离数据流形，导致输出不真实。
- Method: 通过反转候选解并重新初始化DPS，提升样本质量和测量一致性。
- Result: 在困难逆问题（如大范围修复和超分辨率）中，ReGuidance显著优于现有基线。
- Conclusion: ReGuidance首次为DPS提供了严格的算法保证，同时提升奖励和样本真实性。
## eess.SY

### [129] [Energy Aware Camera Location Search Algorithm for Increasing Precision of Observation in Automated Manufacturing](https://arxiv.org/abs/2506.10251)
*Rongfei Li,Francis Assadian*

Main category: eess.SY

TL;DR: 提出一种算法优化相机在眼到手配置中的位置，以最小化图像噪声，并通过模拟验证其有效性。

- Motivation: 现有研究多关注控制和观测架构，而忽略相机位置对图像质量的影响，尤其是在噪声水平随位置变化的环境中。
- Method: 开发一种相机移动策略算法，结合图像平均技术，高效搜索最优或次优位置，同时限制能耗。
- Result: 模拟实验表明，该算法在有限能量下显著提高了观测精度。
- Conclusion: 该算法为眼到手配置中的相机位置优化提供了有效解决方案，适用于自动化制造环境。


### [130] [Semi-Tensor-Product Based Convolutional Neural Networks](https://arxiv.org/abs/2506.10407)
*Daizhan Cheng*

Main category: eess.SY

TL;DR: 本文提出了一种基于域的卷积积（CP）方法，结合半张量积（STP），避免了填充带来的冗余信息，并开发了基于STP的卷积神经网络（CNN），应用于图像和三阶信号识别。

- Motivation: 传统的卷积操作需要填充（padding），可能导致冗余信息。本文旨在通过结合STP和域基CP，避免这一问题。
- Method: 提出域基CP，结合STP，开发基于STP的CNN。
- Result: 新方法避免了填充带来的冗余信息，成功应用于图像和三阶信号识别。
- Conclusion: 基于STP和域基CP的方法有效解决了传统卷积中的填充问题，具有实际应用价值。
## cs.CR

### [131] [Secure Data Access in Cloud Environments Using Quantum Cryptography](https://arxiv.org/abs/2506.10028)
*S. Vasavi Venkata Lakshmi,Ziaul Haque Choudhury*

Main category: cs.CR

TL;DR: 该研究利用量子密码学（如QKD、BB84协议和QOTP）保护云环境中的数据安全，以应对未来量子计算机的威胁。

- Motivation: 传统数据安全方法在未来量子计算机时代可能不足，需更强大的保护手段。
- Method: 使用BB84协议生成安全密钥，结合QOTP进行数据加密和解密。
- Result: 量子密码学方法为云系统提供了强大的安全防御，即使面对量子计算机攻击。
- Conclusion: 量子密码学为当前和未来的云数据安全提供了可靠解决方案。
