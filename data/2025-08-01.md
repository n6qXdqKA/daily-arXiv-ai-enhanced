[[toc]]

## cs.CV

### [1] [CHECK-MAT: Checking Hand-Written Mathematical Answers for the Russian Unified State Exam](https://arxiv.org/abs/2507.22958)
*Ruslan Khrulev*

Main category: cs.CV

TL;DR: 本文介绍了一个新基准EGE-Math Solutions Assessment Benchmark，用于评估视觉语言模型（VLMs）在评估手写数学解题能力上的表现。

- Motivation: 现有基准多关注解题能力，而本研究聚焦于理解学生解题过程、识别错误并依据固定标准评分。
- Method: 收集了122份俄罗斯统一国家考试（EGE）的手写解题扫描件及专家评分，评估了来自Google、OpenAI等七种现代VLMs的三种推理模式。
- Result: 结果显示当前模型在数学推理和与人类评分标准对齐方面存在局限。
- Conclusion: 研究为AI辅助评分开辟了新方向，相关代码已开源。


### [2] [Robust and Efficient 3D Gaussian Splatting for Urban Scene Reconstruction](https://arxiv.org/abs/2507.23006)
*Zhensheng Yuan,Haozhi Huang,Zhen Xiong,Di Wang,Guanghua Yang*

Main category: cs.CV

TL;DR: 提出了一种快速重建和实时渲染城市场景的框架，通过并行训练和可控细节策略优化效率与质量。

- Motivation: 解决多视角捕获中外观变化对重建和渲染效率与质量的负面影响。
- Method: 采用场景分区并行训练、基于可见性的图像选择、可控细节策略和外观变换模块。
- Result: 实验表明该方法在效率和质量上优于现有方法。
- Conclusion: 该框架有效支持城市场景的高效重建与实时渲染。


### [3] [Modeling Human Gaze Behavior with Diffusion Models for Unified Scanpath Prediction](https://arxiv.org/abs/2507.23021)
*Giuseppe Cartella,Vittorio Cuculo,Alessandro D'Amelio,Marcella Cornia,Giuseppe Boccignone,Rita Cucchiara*

Main category: cs.CV

TL;DR: ScanDiff结合扩散模型和Vision Transformers，生成多样且真实的注视扫描路径，优于现有方法。

- Motivation: 现有深度学习方法生成平均行为，无法捕捉人类视觉探索的变异性。
- Method: 结合扩散模型和Vision Transformers，通过文本条件实现任务驱动的扫描路径生成。
- Result: 在自由观看和任务驱动场景中，ScanDiff优于现有方法，生成更多样且准确的扫描路径。
- Conclusion: ScanDiff能更好地捕捉人类视觉行为的复杂性，推动注视预测研究。


### [4] [Recovering Diagnostic Value: Super-Resolution-Aided Echocardiographic Classification in Resource-Constrained Imaging](https://arxiv.org/abs/2507.23027)
*Krishan Agyakari Raja Babu,Om Prabhu,Annu,Mohanasankar Sivaprakasam*

Main category: cs.CV

TL;DR: 研究探讨了深度学习超分辨率技术在低质量超声心动图中的应用，显著提升了分类准确性，尤其适用于资源有限的环境。

- Motivation: 资源有限环境下，低质量超声心动图限制了诊断模型的效能，而超分辨率技术在此领域的应用尚未充分探索。
- Method: 使用SRGAN和SRResNet模型对低质量图像进行增强，并在CAMUS数据集上评估两种分类任务。
- Result: SRResNet在提升分类性能上表现显著，同时计算效率更高。
- Conclusion: 超分辨率技术能有效恢复低质量超声心动图的诊断价值，适用于资源有限环境下的AI辅助诊疗。


### [5] [Adaptive Time-step Training for Enhancing Spike-Based Neural Radiance Fields](https://arxiv.org/abs/2507.23033)
*Ranxi Lin,Canming Yao,Jiayi Li,Weihang Liu,Xin Lou,Pingqiang Zhou*

Main category: cs.CV

TL;DR: 提出了一种基于脉冲神经网络的NeRF框架（PATA），通过动态时间步长训练策略，在保持渲染质量的同时显著降低计算资源消耗。

- Motivation: 解决NeRF模型在密集点采样时的高计算资源需求问题，适应边缘计算等资源受限场景。
- Method: 采用脉冲神经网络（SNN）和动态时间步长调整策略（PATA），自动平衡渲染质量与时间步长。
- Result: 实验显示PATA在保持渲染质量的同时，减少推理时间步长64%和运行功耗61.55%。
- Conclusion: PATA为资源受限场景提供了一种高效的NeRF解决方案。


### [6] [Early Goal-Guided Multi-Scale Fusion for Real-Time Vision-Language Driving](https://arxiv.org/abs/2507.23042)
*Santosh Patapati,Trisanth Srinivasan*

Main category: cs.CV

TL;DR: NovaDrive是一种单分支视觉语言架构，通过处理多模态输入（图像、地图、LiDAR和文本）实现高效自动驾驶，提升成功率和路径效率，减少碰撞频率。

- Motivation: 自动驾驶车辆需在毫秒内反应并处理复杂路况，现有方法常依赖循环记忆，效率不足。
- Method: 采用单分支架构，结合两阶段交叉注意力块对齐路径点与地图，并引入平滑损失避免突变。基于LLaMA-3.2微调实现实时推理。
- Result: 在nuScenes/Waymo子集上，成功率提升4%，路径效率提升0.11，碰撞频率降低1.4%。
- Conclusion: NovaDrive通过多模态融合和优化损失函数，显著提升自动驾驶性能，且具备扩展潜力。


### [7] [Reference-Guided Diffusion Inpainting For Multimodal Counterfactual Generation](https://arxiv.org/abs/2507.23058)
*Alexandru Buburuzan*

Main category: cs.CV

TL;DR: 论文提出两种新的合成数据生成方法MObI和AnydoorMed，分别用于自动驾驶和医学图像分析，通过扩散模型实现高真实感和可控性的多模态数据生成。

- Motivation: 由于真实数据采集成本高且复杂，合成数据方法在安全关键应用中变得重要，但需高真实感和可控性。
- Method: MObI利用扩散模型实现多模态对象修复，支持3D定位；AnydoorMed扩展至医学图像，通过扩散模型修复异常。
- Result: 两种方法在多模态场景中实现了高真实感和语义一致性，展示了扩散模型在跨模态应用中的潜力。
- Conclusion: 这些方法表明扩散模型可适应多种感知模态，为构建高真实感、可控的多模态反事实场景铺平道路。


### [8] [Vision-Language Fusion for Real-Time Autonomous Driving: Goal-Centered Cross-Attention of Camera, HD-Map, & Waypoints](https://arxiv.org/abs/2507.23064)
*Santosh Patapati,Trisanth Srinivasan,Murari Ambati*

Main category: cs.CV

TL;DR: XYZ-Drive是一个结合视觉和语言的单一模型，通过融合摄像头、地图和路径点数据实现自动驾驶，性能优于现有方法。

- Motivation: 自动驾驶需要几何精度和语义理解，但现有方法通常分开处理。XYZ-Drive旨在通过单一模型实现高效、透明的驾驶。
- Method: 使用轻量级目标中心交叉注意力层融合摄像头帧、地图和路径点数据，并通过部分微调的LLaMA-3.2 11B模型输出驾驶指令。
- Result: 在MD-NEX基准测试中，XYZ-Drive达到95%成功率，SPL为0.80，优于PhysNav-DG 15%，碰撞率减半。
- Conclusion: 早期、基于token的意图和地图融合能实现准确、透明且实时的自动驾驶。


### [9] [Vocabulary-free Fine-grained Visual Recognition via Enriched Contextually Grounded Vision-Language Model](https://arxiv.org/abs/2507.23070)
*Dmitry Demidov,Zaigham Zaheer,Omkar Thawakar,Salman Khan,Fahad Shahbaz Khan*

Main category: cs.CV

TL;DR: 论文提出了一种无需训练的方法E-FineR，用于细粒度图像分类，结合大型语言模型（LLMs）和视觉语言模型（VLMs），在开放集识别中表现优异，且具有更好的可解释性。

- Motivation: 传统细粒度图像分类方法依赖固定词汇和封闭集分类，难以适应现实世界中新类别的出现。现有方法未能充分利用LLMs的分类能力，且依赖未经充分分析的猜测类别名称。
- Method: 提出E-FineR方法，无需训练，结合LLMs和VLMs，通过语言驱动的理解实现细粒度分类。
- Result: E-FineR在细粒度视觉识别中达到SOTA性能，并在零样本和少样本分类中表现优异，无需人工干预。
- Conclusion: E-FineR支持从固定标签预测转向灵活的语言驱动理解，为现实应用提供了可扩展和通用的解决方案。


### [10] [Details Matter for Indoor Open-vocabulary 3D Instance Segmentation](https://arxiv.org/abs/2507.23134)
*Sanghun Jung,Jingjing Zheng,Ke Zhang,Nan Qiao,Albert Y. C. Chen,Lu Xia,Chi Liu,Yuyin Sun,Xiao Zeng,Hsiang-Wei Huang,Byron Boots,Min Sun,Cheng-Hao Kuo*

Main category: cs.CV

TL;DR: 提出了一种结合多种互补概念的新方法，用于开放词汇3D实例分割（OV-3DIS），通过两阶段方案（3D提案生成和实例分类）实现最优性能。

- Motivation: 现有OV-3DIS方法中的概念互补但未结合，需设计新方案以整合并优化这些概念。
- Method: 采用两阶段方案：1）基于3D跟踪的提案聚合生成提案，并通过迭代合并/移除处理重叠或部分提案；2）用Alpha-CLIP替代标准CLIP，引入标准化最大相似度（SMS）评分优化分类。
- Result: 在ScanNet200和S3DIS数据集上，所有AP和AR指标均达到最优，甚至超过封闭词汇方法。
- Conclusion: 通过整合互补概念并优化关键挑战，提出的方法在OV-3DIS任务中实现了最先进的性能。


### [11] [X-NeMo: Expressive Neural Motion Reenactment via Disentangled Latent Attention](https://arxiv.org/abs/2507.23143)
*Xiaochen Zhao,Hongyi Xu,Guoxian Song,You Xie,Chenxu Zhang,Xiu Li,Linjie Luo,Jinli Suo,Yebin Liu*

Main category: cs.CV

TL;DR: X-NeMo是一个基于扩散模型的零样本肖像动画方法，通过驱动视频的面部运动生成静态肖像动画，解决了身份泄漏和表情捕捉问题。

- Motivation: 解决现有方法中身份泄漏和难以捕捉细微及极端表情的问题。
- Method: 提出端到端训练框架，提取1D身份无关运动描述符，通过交叉注意力控制图像生成。
- Result: 实验表明X-NeMo优于现有方法，生成高表现力动画并保持身份相似性。
- Conclusion: X-NeMo通过创新的运动描述符和训练框架，有效解决了身份泄漏问题，提升了动画质量。


### [12] [Neural Multi-View Self-Calibrated Photometric Stereo without Photometric Stereo Cues](https://arxiv.org/abs/2507.23162)
*Xu Cao,Takafumi Taketomi*

Main category: cs.CV

TL;DR: 提出了一种神经逆向渲染方法，从多视角图像中联合重建几何、空间变化反射率和光照条件，无需光照校准或中间线索。

- Motivation: 解决传统多视角光度立体方法需要光照校准或中间线索（如每视角法线图）的局限性，实现从原始图像中直接优化所有场景参数。
- Method: 使用神经隐式场表示几何和反射率，结合阴影感知的体积渲染。通过空间网络预测有符号距离和反射率潜在码，反射率网络基于潜在码和角度编码的方向估计反射率。
- Result: 在形状和光照估计精度上优于现有方法，适用于视角未对齐的多光源图像，并能处理复杂几何和反射率物体。
- Conclusion: 该方法在无需额外校准的情况下，实现了高效的场景参数联合优化，展示了优越的性能和泛化能力。


### [13] [CNN-based solution for mango classification in agricultural environments](https://arxiv.org/abs/2507.23174)
*Beatriz Díaz Peón,Jorge Torres Gómez,Ariel Fajardo Márquez*

Main category: cs.CV

TL;DR: 设计了一个基于CNN的水果检测与分类系统，用于芒果质量评估，结合Resnet-18和级联检测器，实现了高效准确的分类与检测。

- Motivation: 开发自动评估水果质量的系统，以支持农场库存管理。
- Method: 使用图像处理和CNN（Resnet-18）进行分类，级联检测器进行检测，并通过MatLab App Designer开发图形界面。
- Result: 系统在水果分类和检测方面表现出高效性和准确性。
- Conclusion: 结合CNN和级联检测器的方法为农业质量控制提供了可靠解决方案。


### [14] [Single Image Rain Streak Removal Using Harris Corner Loss and R-CBAM Network](https://arxiv.org/abs/2507.23185)
*Jongwook Si,Sungyoung Kim*

Main category: cs.CV

TL;DR: 提出了一种结合角点损失和残差卷积块注意力模块的图像去雨方法，显著提升了去雨效果。

- Motivation: 单图像去雨任务需要同时保留细节和视觉质量，传统方法容易丢失边界和纹理信息。
- Method: 引入角点损失防止边界和纹理丢失，并使用R-CBAM模块动态调整特征重要性。
- Result: 在Rain100L和Rain100H数据集上分别达到33.29 dB和26.16 dB的PSNR，优于现有方法。
- Conclusion: 该方法有效提升了去雨效果，尤其在保留细节和边界方面表现突出。


### [15] [Multi-Modal Motion Retrieval by Learning a Fine-Grained Joint Embedding Space](https://arxiv.org/abs/2507.23188)
*Shiyao Yu,Zi-An Wang,Kangning Yin,Zheng Tian,Mingyuan Zhang,Weixin Si,Shihao Zou*

Main category: cs.CV

TL;DR: 提出了一种多模态运动检索框架，首次引入音频模态，通过序列级对比学习实现精细对齐，显著提升检索性能。

- Motivation: 现有方法缺乏直观的用户交互模式且忽视模态的序列表示，限制了运动检索的性能和用户体验。
- Method: 构建一个包含文本、音频、视频和运动的联合嵌入空间，采用序列级对比学习方法对齐多模态信息。
- Result: 在多个子任务中表现优于现有方法，如文本到运动检索的R@10提升10.16%，视频到运动检索的R@1提升25.43%。
- Conclusion: 多模态运动检索框架具有显著优势，为运动获取领域提供了新的可能性。


### [16] [A Novel Dataset for Flood Detection Robust to Seasonal Changes in Satellite Imagery](https://arxiv.org/abs/2507.23193)
*Youngsun Jang,Dongyoun Kim,Chulwoo Pack,Kwanghee Won*

Main category: cs.CV

TL;DR: 该研究提出了一个用于卫星图像中洪水区域分割的新数据集，填补了现有基准数据集的不足，并测试了多种模型，结果表明需要进一步的多模态和时间学习策略。

- Motivation: 现有卫星图像基准数据集在洪水区域分割任务上存在不足，研究旨在填补这一空白。
- Method: 收集了2019年美国中西部洪水的卫星图像，构建了包含10个地点、每个地点10张图像的数据集，并测试了多种语义分割模型。
- Result: 模型表现一般，表明未来需要多模态和时间学习策略。
- Conclusion: 数据集将公开，为洪水区域分割研究提供资源，并指出未来研究方向。


### [17] [Adversarial-Guided Diffusion for Multimodal LLM Attacks](https://arxiv.org/abs/2507.23202)
*Chengwei Xia,Fan Ma,Ruijie Quan,Kun Zhan,Yi Yang*

Main category: cs.CV

TL;DR: 提出一种对抗引导扩散（AGD）方法，通过扩散模型生成对抗图像欺骗多模态大语言模型（MLLMs），同时保持原始图像的低失真。

- Motivation: 解决传统对抗攻击方法因高频扰动易被防御的问题，提出一种更鲁棒的对抗攻击方法。
- Method: 在反向扩散过程中引入对抗引导噪声，将目标语义嵌入噪声成分，利用扩散模型的全频谱特性增强攻击效果。
- Result: AGD在攻击性能和对抗防御鲁棒性上优于现有方法。
- Conclusion: AGD是一种高效且鲁棒的对抗攻击方法，适用于多模态大语言模型。


### [18] [Confidence-aware agglomeration classification and segmentation of 2D microscopic food crystal images](https://arxiv.org/abs/2507.23206)
*Xiaoyu Ji,Ali Shakouri,Fengqing Zhu*

Main category: cs.CV

TL;DR: 提出了一种结合分类和分割的监督学习方法，用于检测食品晶体团聚现象，提高了分类准确性和尺寸分布预测。

- Motivation: 食品晶体团聚现象影响产品质量，但手动标注2D显微图像中的团聚现象困难。
- Method: 提出基线模型生成分割伪标签，训练实例分类模型同时进行像素分割，结合分类和分割优势，并加入后处理模块。
- Result: 方法提高了团聚分类的准确性和尺寸分布预测，成功分类潜在团聚实例。
- Conclusion: 该方法有效解决了食品晶体团聚检测的挑战，优于现有方法。


### [19] [YOLO-ROC: A High-Precision and Ultra-Lightweight Model for Real-Time Road Damage Detection](https://arxiv.org/abs/2507.23225)
*Zicheng Lin,Weichao Pan*

Main category: cs.CV

TL;DR: 提出了一种轻量级高精度模型YOLO-ROC，通过BMS-SPPF模块和多尺度特征提取优化，显著提升小目标检测能力，同时减少计算复杂度。

- Motivation: 现有深度学习方法在道路损伤检测中存在多尺度特征提取不足和计算复杂度高的问题，影响小目标检测和实时部署。
- Method: 设计BMS-SPPF模块增强多尺度特征提取，采用分层通道压缩策略降低计算复杂度。
- Result: 在RDD2022_China_Drone数据集上mAP50达67.6%，小目标D40类别提升16.8%，模型大小仅2.0MB。
- Conclusion: YOLO-ROC在精度和效率上均优于基线模型，具有良好泛化能力。


### [20] [Toward Safe, Trustworthy and Realistic Augmented Reality User Experience](https://arxiv.org/abs/2507.23226)
*Yanming Xiu*

Main category: cs.CV

TL;DR: 研究通过开发ViDDAR和VIM-Sense系统，利用视觉语言模型和多模态推理模块检测AR中的有害内容，并提出未来方向以保障AR体验的安全性和可信度。

- Motivation: 随着AR技术融入日常生活，确保其虚拟内容的安全性和可信度变得至关重要，尤其是防止任务有害内容或用户感知的微妙操控。
- Method: 开发了ViDDAR和VIM-Sense系统，结合视觉语言模型（VLMs）和多模态推理模块，检测AR中的攻击性内容。
- Result: 提出了三个未来方向：虚拟内容的自动化感知对齐质量评估、多模态攻击检测，以及VLMs在AR设备上的高效用户中心化部署。
- Conclusion: 研究旨在建立一个可扩展、以人为本的框架，以保障AR体验的安全，并寻求在感知建模、多模态AR内容实现和轻量级模型适应方面的反馈。


### [21] [Ambiguity-Guided Learnable Distribution Calibration for Semi-Supervised Few-Shot Class-Incremental Learning](https://arxiv.org/abs/2507.23237)
*Fan Lyu,Linglan Zhao,Chengyan Liu,Yinying Mei,Zhang Zhang,Jian Zhang,Fuyuan Hu,Liang Wang*

Main category: cs.CV

TL;DR: 论文提出广义半监督少样本类增量学习（GSemi-FSCIL），通过引入基类和所有已见过的新类作为未标记数据，更贴近实际场景。为解决现有方法难以区分基类和新类未标记样本的问题，提出了一种基于模糊引导的可学习分布校准（ALDC）策略，实验表明其性能优于现有方法。

- Motivation: 现有半监督少样本类增量学习（Semi-FSCIL）假设未标记数据仅来自当前会话的新类，与实际场景不符。为更贴近现实，论文重新定义Semi-FSCIL为GSemi-FSCIL，扩展未标记数据来源。
- Method: 提出ALDC策略，动态利用丰富的基类样本校正少样本新类的特征分布偏差。
- Result: 在三个基准数据集上的实验表明，ALDC优于现有方法，达到新的最优性能。
- Conclusion: GSemi-FSCIL更贴近实际场景，ALDC策略有效解决了未标记数据来源扩展带来的挑战，性能显著提升。


### [22] [Generalized Reinforcement Learning for Retriever-Specific Query Rewriter with Unstructured Real-World Documents](https://arxiv.org/abs/2507.23242)
*Sungguk Cha,DongWook Kim,Taeseung Hahn,Mintae Kim,Youngsub Han,Byoung-Ki Jeon*

Main category: cs.CV

TL;DR: RL-QR是一个基于强化学习的查询重写框架，用于优化RAG系统的查询，无需人工标注数据，适用于文本和多模态数据库，实验显示性能显著提升，但在语义和混合检索器中仍有挑战。

- Motivation: 优化RAG系统的查询重写，解决多样化、非结构化文档的查询问题，同时避免依赖人工标注数据。
- Method: 引入RL-QR框架，通过合成场景-问题对和GRPO算法，训练针对特定检索器的查询重写器。
- Result: 在多模态RAG中NDCG@3提升11%，在词汇检索器中提升9%，但在语义和混合检索器中未观察到改进。
- Conclusion: RL-QR为RAG系统提供了一种可扩展、无需标注的查询优化方案，但在语义检索方面仍需进一步改进。


### [23] [Automated Mapping the Pathways of Cranial Nerve II, III, V, and VII/VIII: A Multi-Parametric Multi-Stage Diffusion Tractography Atlas](https://arxiv.org/abs/2507.23245)
*Lei Xie,Jiahao Huang,Jiawei Zhang,Jianzhong He,Yiang Pan,Guoqiang Xie,Mengjun Li,Qingrun Zeng,Mingchu Li,Yuanjing Feng*

Main category: cs.CV

TL;DR: 本文提出了一种基于扩散MRI的自动化颅神经（CN）通路映射方法，通过多阶段纤维聚类生成全面的CN图谱，验证了其与专家手动注释的高度一致性。

- Motivation: 颅神经在脑功能中至关重要，但其复杂的解剖结构和颅底环境使得全面映射其通路具有挑战性。
- Method: 采用多参数纤维追踪和多阶段纤维聚类策略，分析了来自50名HCP受试者的约1,000,000条流线，生成了CN图谱。
- Result: 图谱能自动识别5对CN的8条纤维束，并在多个数据集（HCP、MDM和临床病例）中表现出高空间一致性和鲁棒性。
- Conclusion: 该CN图谱提升了扩散成像领域对多对CN通路的自动化映射效率，有助于复杂脑结构的分析和理解。


### [24] [A Deep Dive into Generic Object Tracking: A Survey](https://arxiv.org/abs/2507.23251)
*Fereshteh Aghaee Meibodi,Shadi Alijani,Homayoun Najjaran*

Main category: cs.CV

TL;DR: 本文全面综述了通用目标跟踪领域的三大类方法（Siamese-based、discriminative和transformer-based），特别关注快速发展的transformer-based方法，分析了其设计原则、创新与局限，并提供了统一的比较框架。

- Motivation: 通用目标跟踪因复杂的时空动态性（如遮挡、相似干扰物和外观变化）仍具挑战性，需对现有方法进行系统总结以推动领域发展。
- Method: 通过定性和定量比较，分析三类方法的核心设计、创新与局限，提出新的分类方式，并提供视觉和表格化的统一比较。
- Result: 研究发现transformer-based方法因其强大的时空建模能力发展迅速，论文总结了代表性方法及主要评估基准。
- Conclusion: 本文为通用目标跟踪领域提供了全面综述，突出了transformer-based方法的潜力，并提出了未来研究方向。


### [25] [Towards Measuring and Modeling Geometric Structures in Time Series Forecasting via Image Modality](https://arxiv.org/abs/2507.23253)
*Mingyang Yu,Xiahui Guo,Peng chen,Zhenkai Li,Yang Shu*

Main category: cs.CV

TL;DR: 论文提出了一种新的时间序列评估指标TGSI和训练损失函数SATL，以改进时间序列数据的几何结构建模。

- Motivation: 传统数值指标（如MSE）无法评估时间序列的几何结构，而几何结构对理解时间动态至关重要。
- Method: 提出TGSI指标将时间序列转化为图像以评估几何结构，并设计SATL损失函数（包含一阶差分损失、频域损失和感知特征损失）以在训练中优化结构建模。
- Result: 实验表明，使用SATL训练的模型在MSE和TGSI指标上均优于基线方法，且推理时无额外计算成本。
- Conclusion: TGSI和SATL有效提升了时间序列预测的几何结构建模能力。


### [26] [Learning Semantic-Aware Threshold for Multi-Label Image Recognition with Partial Labels](https://arxiv.org/abs/2507.23263)
*Haoxian Ruan,Zhihua Xu,Zhijing Yang,Guang Ma,Jieming Xie,Changxiang Fan,Tianshui Chen*

Main category: cs.CV

TL;DR: 论文提出了一种名为SATL的新算法，通过动态学习类别特定阈值和改进伪标签生成，显著提升了多标签图像识别的性能。

- Motivation: 传统方法使用固定阈值生成伪标签，忽略了不同类别的分数分布差异，导致伪标签不准确，影响模型性能。
- Method: 提出SATL算法，动态计算每个类别的正负样本分数分布，并基于此学习类别特定阈值；同时引入差分排序损失以增强阈值区分度。
- Result: 在Microsoft COCO和VG-200等大规模多标签数据集上的实验表明，SATL显著提升了有限标签场景下的性能。
- Conclusion: SATL通过动态阈值学习和差分排序损失，有效解决了伪标签生成不准确的问题，提升了多标签图像识别的性能。


### [27] [PixNerd: Pixel Neural Field Diffusion](https://arxiv.org/abs/2507.23268)
*Shuai Wang,Ziteng Gao,Chenhui Zhu,Weilin Huang,Limin Wang*

Main category: cs.CV

TL;DR: 论文提出了一种名为PixelNerd的单尺度、单阶段、端到端的解决方案，通过神经场建模解码，避免了传统两阶段训练中的累积误差和解码伪影，并在ImageNet和文本生成图像任务中取得了优异性能。

- Motivation: 当前扩散变换器的成功依赖于预训练的变分自编码器（VAE）压缩的潜在空间，但两阶段训练范式会引入累积误差和解码伪影。现有解决方案通过返回像素空间增加了复杂性。
- Method: 提出PixelNerd，利用神经场表示进行补丁级解码，实现单尺度、单阶段、高效的端到端训练。
- Result: 在ImageNet 256×256和512×512上分别取得2.15和2.84的FID分数，无需复杂级联或VAE。文本生成图像任务中，PixNerd-XXL/16在GenEval和DPG基准测试中表现优异。
- Conclusion: PixelNerd通过神经场表示提供了一种高效且性能优越的替代方案，避免了传统方法的复杂性。


### [28] [Towards Affordable Tumor Segmentation and Visualization for 3D Breast MRI Using SAM2](https://arxiv.org/abs/2507.23272)
*Solha Kang,Eugene Kim,Joris Vankerschaver,Utku Ozbulak*

Main category: cs.CV

TL;DR: 研究探讨了如何利用Segment Anything Model 2（SAM2）在低成本、最小输入条件下实现乳腺MRI中的3D肿瘤分割。

- Motivation: 乳腺MRI的人工解释耗时且主观，商业AI工具在低收入国家难以普及。
- Method: 使用单一边界框标注，通过三种切片追踪策略（从上到下、从下到上、从中心向外）传播分割预测。
- Result: 中心向外传播策略表现最佳，SAM2在零样本条件下实现了高分割性能。
- Conclusion: 通用基础模型如SAM2可在资源有限的环境中提供低成本、高效的3D医学图像分析解决方案。


### [29] [iLRM: An Iterative Large 3D Reconstruction Model](https://arxiv.org/abs/2507.23277)
*Gyeongjin Kang,Seungtae Nam,Xiangyu Sun,Sameh Khamis,Abdelrahman Mohamed,Eunbyung Park*

Main category: cs.CV

TL;DR: iLRM是一种迭代式大型3D重建模型，通过解耦场景表示、分解多视图交互和注入高分辨率信息，显著提升了3D高斯重建的效率和可扩展性。

- Motivation: 现有基于Transformer的方法在多视图或高分辨率输入时计算成本过高，限制了其可扩展性。
- Method: iLRM采用迭代细化机制，通过解耦场景表示、两阶段注意力方案和逐层高分辨率信息注入，实现高效3D重建。
- Result: 在RE10K和DL3DV数据集上，iLRM在重建质量和速度上均优于现有方法，且具有更高的可扩展性。
- Conclusion: iLRM通过创新设计解决了现有方法的计算瓶颈，为高效、高质量的3D重建提供了新思路。


### [30] [UniLiP: Adapting CLIP for Unified Multimodal Understanding, Generation and Editing](https://arxiv.org/abs/2507.23278)
*Hao Tang,Chenwei Xie,Xiaoyi Bao,Tingyu Weng,Pandeng Li,Yun Zheng,Liwei Wang*

Main category: cs.CV

TL;DR: UniLIP扩展了CLIP的功能，支持重建、生成和编辑，通过两阶段训练和自蒸馏策略保持原有理解能力，同时在生成和编辑任务中表现优异。

- Motivation: 现有基于CLIP的统一方法需要额外模块支持重建和生成任务，导致性能下降或重建不一致。UniLIP旨在解决这一问题，扩展CLIP的应用范围。
- Method: 采用两阶段训练和自蒸馏策略，逐步将重建能力融入CLIP；提出双条件架构，结合MLLM和扩散变换器，利用可学习查询和多模态隐藏状态。
- Result: 在文本到图像生成任务中，UniLIP在GenEval和WISE基准上分别得分0.87和0.53；在图像编辑任务中，得分3.62，超越现有模型。
- Conclusion: UniLIP成功扩展了CLIP的功能，使其在理解和生成/编辑任务中均表现优异，为多任务模型提供了新思路。


### [31] [Bidirectional Likelihood Estimation with Multi-Modal Large Language Models for Text-Video Retrieval](https://arxiv.org/abs/2507.23284)
*Dohwan Ko,Ji Soo Lee,Minhyuk Choi,Zihang Meng,Hyunwoo J. Kim*

Main category: cs.CV

TL;DR: BLiM框架通过双向似然估计和候选先验归一化（CPN）解决文本-视频检索中的候选先验偏差问题，显著提升性能。

- Motivation: 多模态大语言模型（MLLMs）在文本-视频检索中存在候选先验偏差，导致检索结果偏向高先验候选而非相关候选。
- Method: 提出BLiM框架，结合双向似然估计和CPN模块，通过生成文本和视频特征双向训练模型，并校准候选先验偏差。
- Result: 在四个基准测试中，BLiM+CPN平均R@1提升6.4%，有效缓解偏差并突出查询-候选相关性。
- Conclusion: BLiM和CPN不仅提升检索性能，还适用于其他多模态任务，减少对文本先验的依赖。


### [32] [LED Benchmark: Diagnosing Structural Layout Errors for Document Layout Analysis](https://arxiv.org/abs/2507.23295)
*Inbum Heo,Taewook Hwang,Jeesu Jung,Sangkeun Jung*

Main category: cs.CV

TL;DR: 论文提出了一种名为Layout Error Detection (LED)的新基准，用于评估文档布局预测的结构鲁棒性，并构建了合成数据集LED-Dataset。

- Motivation: 尽管文档布局分析技术有所进步，但仍存在区域合并、分割和内容缺失等结构错误，传统评估指标（如IoU和mAP）无法有效检测这些错误。
- Method: LED定义了八种标准化错误类型，并设计了三个互补任务：错误存在检测、错误类型分类和元素级错误类型分类。同时构建了LED-Dataset，通过注入基于DLA模型经验分布的现实结构错误生成。
- Result: 实验表明，LED能有效区分结构理解能力，揭示传统指标无法显示的模态偏差和性能权衡。
- Conclusion: LED为文档布局分析提供了更全面的评估工具，有助于改进模型的结构鲁棒性。


### [33] [Training-free Geometric Image Editing on Diffusion Models](https://arxiv.org/abs/2507.23300)
*Hanshen Zhu,Zhen Zhu,Kaile Zhang,Yiming Gong,Yuliang Liu,Xiang Bai*

Main category: cs.CV

TL;DR: 提出了一种解耦的图像几何编辑方法FreeFine，通过分离对象变换、源区域修复和目标区域细化，显著提升了编辑精度和图像保真度。

- Motivation: 现有扩散基编辑方法难以处理大规模或结构复杂的变换，因此需要一种更有效的解决方案。
- Method: 采用解耦管道，分别处理对象变换、源区域修复和目标区域细化，并使用无需训练的扩散方法FreeFine实现修复和细化。
- Result: 在GeoBench基准测试中，FreeFine在图像保真度和编辑精度上优于现有方法，尤其在复杂变换下表现突出。
- Conclusion: FreeFine通过解耦和训练自由的扩散方法，有效提升了图像几何编辑的质量和灵活性。


### [34] [ST-SAM: SAM-Driven Self-Training Framework for Semi-Supervised Camouflaged Object Detection](https://arxiv.org/abs/2507.23307)
*Xihang Hu,Fuming Sun,Jiazhe Liu,Feilong Xu,Xiaoli Zhang*

Main category: cs.CV

TL;DR: ST-SAM是一种高效的半监督伪装目标检测框架，通过自训练策略和混合提示减少标注依赖，仅需1%标注数据即可达到最优性能。

- Motivation: 减少对昂贵像素级标注的依赖，解决现有方法在稀缺监督下的预测偏差和计算开销问题。
- Method: 采用自训练策略动态筛选和扩展高置信度伪标签，结合混合提示利用Segment Anything Model的潜力。
- Result: 在COD基准数据集上表现优异，仅需1%标注数据即超越现有方法，甚至媲美全监督方法。
- Conclusion: ST-SAM为高效标注的半监督伪装目标检测提供了新范式。


### [35] [PriorFusion: Unified Integration of Priors for Robust Road Perception in Autonomous Driving](https://arxiv.org/abs/2507.23309)
*Xuewei Tang,Mengmeng Yang,Tuopu Wen,Peijin Jia,Le Cui,Mingshang Luo,Kehua Sheng,Bo Zhang,Diange Yang,Kun Jiang*

Main category: cs.CV

TL;DR: 论文提出PriorFusion框架，通过整合语义、几何和生成先验，提升复杂环境下道路元素的感知准确性。

- Motivation: 自动驾驶在无高清地图支持的复杂环境中面临道路元素感知不准确的问题，现有方法未能充分利用道路元素的结构化先验。
- Method: 提出PriorFusion框架，结合实例感知注意力机制、数据驱动的形状模板空间和扩散模型，生成准确预测。
- Result: 在大规模自动驾驶数据集上验证，显著提升感知准确性，尤其在挑战性条件下表现优异。
- Conclusion: PriorFusion框架通过整合多类先验，显著改善了道路元素的感知效果，为自动驾驶提供了更可靠的解决方案。


### [36] [Forgetting of task-specific knowledge in model merging-based continual learning](https://arxiv.org/abs/2507.23311)
*Timm Hess,Gido M van de Ven,Tinne Tuytelaars*

Main category: cs.CV

TL;DR: 研究线性合并模型在持续学习中的表现，发现合并能保留或增强共享知识，但任务特定知识会快速退化。增量训练的模型合并效果优于并行训练的模型。

- Motivation: 探讨在持续学习（CL）中，线性合并模型对共享知识和任务特定知识的影响。
- Method: 通过计算机视觉实验，使用可控视觉线索，比较增量训练和并行训练模型的合并效果。
- Result: 合并能保留或增强共享知识，但任务特定知识快速退化；增量训练的模型合并效果更优。
- Conclusion: 线性合并模型在持续学习中有效，增量训练方式更适合模型合并。


### [37] [The Cow of Rembrandt - Analyzing Artistic Prompt Interpretation in Text-to-Image Models](https://arxiv.org/abs/2507.23313)
*Alfio Ferrara,Sergio Picascia,Elisabetta Rocchetti*

Main category: cs.CV

TL;DR: 研究了基于Transformer的文本到图像扩散模型如何编码内容和风格概念，发现模型在生成艺术作品时表现出不同程度的内容-风格分离。

- Motivation: 探索扩散模型如何在没有明确指导的情况下内部表示内容和风格概念。
- Method: 利用交叉注意力热图将生成图像中的像素归因于特定提示词，分离内容和风格描述词影响的区域。
- Result: 发现内容词主要影响对象相关区域，风格词影响背景和纹理区域，表明模型对内容-风格区分有潜在理解。
- Conclusion: 扩散模型在无监督情况下能自发区分内容和风格，为理解大规模生成模型的内部表示提供了新视角。


### [38] [Impact of Hyperparameter Optimization on the Accuracy of Lightweight Deep Learning Models for Real-Time Image Classification](https://arxiv.org/abs/2507.23315)
*Vineet Kumar Rakesh,Soumya Mazumdar,Tapas Samanta,Sarbajit Pal,Amitabha Das*

Main category: cs.CV

TL;DR: 论文分析了超参数调整对七种高效深度学习架构在ImageNet-1K数据集上的准确性和收敛行为的影响，重点研究了实时应用的实用性。

- Motivation: 研究超参数调整对轻量级卷积和基于Transformer的模型在资源受限应用（如嵌入式系统和边缘设备）中的影响，以优化实时图像分类性能。
- Method: 在一致的训练设置下，对七种模型进行训练，并通过消融研究分析关键超参数（如学习率、批量大小、输入分辨率等）的影响。
- Result: 结果表明，余弦学习率衰减和可调批量大小能显著提高准确性和收敛速度，同时保持低延迟和内存成本。RepVGG-A2在准确性和部署成本之间取得了良好平衡。
- Conclusion: 研究结果为构建适用于实时图像处理管道的资源高效深度学习模型提供了实用指导。


### [39] [FastDriveVLA: Efficient End-to-End Driving via Plug-and-Play Reconstruction-based Token Pruning](https://arxiv.org/abs/2507.23318)
*Jiajun Cao,Qizhe Zhang,Peidong Jia,Xuhui Zhao,Bo Lan,Xiaoan Zhang,Xiaobao Wei,Sixiang Chen,Zhuo Li,Yang Wang,Liyun Li,Xianming Liu,Ming Lu,Shanghang Zhang*

Main category: cs.CV

TL;DR: FastDriveVLA提出了一种基于重建的视觉令牌剪枝框架，专注于自动驾驶场景中的前景信息，显著降低了计算成本。

- Motivation: 现有的视觉令牌剪枝方法在自动驾驶场景中表现不佳，而人类驾驶员主要关注前景区域，因此保留前景信息的视觉令牌对决策至关重要。
- Method: 提出了FastDriveVLA框架，包括ReconPruner剪枝器，通过MAE风格像素重建和对抗性前景-背景重建策略训练。
- Result: 在nuScenes闭环规划基准测试中，FastDriveVLA在不同剪枝比例下均取得了最佳性能。
- Conclusion: FastDriveVLA通过专注于前景信息，显著提升了视觉令牌剪枝在自动驾驶中的效果，且无需重新训练即可应用于不同VLA模型。


### [40] [FASTopoWM: Fast-Slow Lane Segment Topology Reasoning with Latent World Models](https://arxiv.org/abs/2507.23325)
*Yiming Yang,Hongbin Lin,Yueru Luo,Suzhong Fu,Chao Zheng,Xinrui Yan,Shuqi Mei,Kun Tang,Shuguang Cui,Zhen Li*

Main category: cs.CV

TL;DR: FASTopoWM是一种新颖的快速-慢速车道段拓扑推理框架，通过潜在世界模型增强，显著提升了车道段检测和中心线感知性能。

- Motivation: 现有车道拓扑推理方法在利用时间信息提升检测和推理性能方面存在不足，且易受姿态估计失败的影响。
- Method: 提出FASTopoWM框架，通过并行监督历史和新初始化查询，引入潜在查询和BEV世界模型，增强时间感知。
- Result: 在OpenLane-V2基准测试中，车道段检测和中心线感知性能优于现有方法（mAP 37.4% vs 33.6%，OLS 46.3% vs 41.5%）。
- Conclusion: FASTopoWM通过潜在世界模型和时间传播设计，显著提升了车道拓扑推理性能。


### [41] [Learning Semantic Directions for Feature Augmentation in Domain-Generalized Medical Segmentation](https://arxiv.org/abs/2507.23326)
*Yingkai Wang,Yaoyao Zhu,Xiuding Cai,Yuhao Xiao,Haotian Wu,Yu Yao*

Main category: cs.CV

TL;DR: 提出了一种针对医学图像分割的领域泛化框架，通过隐式特征扰动和自适应一致性约束，提升模型在不同临床领域的鲁棒性和泛化性能。

- Motivation: 医学图像分割在临床中至关重要，但领域偏移导致模型在未见领域性能下降，限制了实际应用。
- Method: 采用可学习的语义方向选择器和基于协方差的语义强度采样器，结合自适应一致性约束，调整领域变异特征并保持解剖一致性。
- Result: 在两个多中心公开基准测试中，框架表现优于现有领域泛化方法，实现了跨领域的鲁棒分割性能。
- Conclusion: 该框架有效解决了医学图像分割中的领域偏移问题，提升了模型的泛化能力和临床实用性。


### [42] [Contrastive Learning-Driven Traffic Sign Perception: Multi-Modal Fusion of Text and Vision](https://arxiv.org/abs/2507.23331)
*Qiang Lu,Waikit Xiu,Xiying Li,Shenyu Hu,Shengbo Sun*

Main category: cs.CV

TL;DR: 论文提出了一种结合开放词汇检测和跨模态学习的两阶段框架，用于解决交通标志识别中的长尾分布和小目标多尺度问题，取得了显著的性能提升。

- Motivation: 交通标志识别是自动驾驶感知系统的核心，但现有技术面临长尾分布和小目标多尺度特征提取的挑战。
- Method: 提出NanoVerse YOLO模型（集成RepVL-PAN和SPD-Conv模块）用于检测，以及TSR-MCL模型（结合视觉和语义特征对比学习）用于分类。
- Result: 在TT100K数据集上，mAP达到78.4%，准确率和召回率分别为91.8%和88.9%，显著优于主流算法。
- Conclusion: 该方法在复杂开放场景中表现出优异的准确性和泛化能力。


### [43] [MagicRoad: Semantic-Aware 3D Road Surface Reconstruction via Obstacle Inpainting](https://arxiv.org/abs/2507.23340)
*Xingyue Peng,Yuandong Lyu,Lang Zhang,Jian Zhu,Songtao Wang,Jiaxin Deng,Songxin Lu,Weiliang Ma,Dangen She,Peng Jia,XianPeng Lang*

Main category: cs.CV

TL;DR: 提出了一种鲁棒的道路表面重建框架，结合了遮挡感知的2D高斯面元与语义引导的颜色增强，以恢复干净、一致的道路表面。

- Motivation: 道路表面重建对自动驾驶至关重要，但现有方法在动态遮挡、视觉杂乱和光照天气变化下表现不佳。
- Method: 采用平面适应的高斯表示进行大规模建模，利用分割引导的视频修复去除动态和静态前景物体，并通过语义感知的HSV空间校正增强颜色一致性。
- Result: 在城市规模数据集上的实验表明，该方法在视觉一致性和几何保真度上显著优于现有方法。
- Conclusion: 该框架在复杂城市环境中实现了鲁棒且高质量的道路表面重建。


### [44] [The Impact of Image Resolution on Face Detection: A Comparative Analysis of MTCNN, YOLOv XI and YOLOv XII models](https://arxiv.org/abs/2507.23341)
*Ahmet Can Ömercikoğlu,Mustafa Mansur Yönügül,Pakize Erdoğmuş*

Main category: cs.CV

TL;DR: 研究了输入分辨率对三种深度学习人脸检测器性能的影响，发现YOLOv11在高分辨率下表现最佳，YOLOv12召回率略高，MTCNN在实时性上较差。

- Motivation: 现实世界中的低分辨率图像会降低人脸检测性能，因此需要系统研究分辨率对不同模型的影响。
- Method: 使用WIDER FACE数据集，评估YOLOv11、YOLOv12和MTCNN在多种分辨率下的性能指标（如精度、召回率、mAP等）。
- Result: YOLOv11在高分辨率下检测精度最高，YOLOv12召回率略优，MTCNN实时性不足但地标定位表现良好。
- Conclusion: 研究结果为根据不同操作约束选择分辨率感知的人脸检测模型提供了实用建议。


### [45] [Who is a Better Talker: Subjective and Objective Quality Assessment for AI-Generated Talking Heads](https://arxiv.org/abs/2507.23343)
*Yingjie Zhou,Jiezhang Cao,Zicheng Zhang,Farong Wen,Yanwei Jiang,Jun Jia,Xiaohong Liu,Xiongkuo Min,Guangtao Zhai*

Main category: cs.CV

TL;DR: 论文提出了最大的AGTH质量评估数据集THQA-10K，评估了12种T2I模型和14种Talker生成的AGTHs质量，并提出了基于第一帧、Y-T切片和音唇一致性的客观质量评估方法。

- Motivation: 当前AI生成的说话头部（AGTHs）质量参差不齐，缺乏全面的质量评估研究，因此需要建立大规模数据集和方法来解决这一问题。
- Method: 构建THQA-10K数据集，包含10,457个AGTHs，招募志愿者进行主观评分，并提出基于第一帧、Y-T切片和音唇一致性的客观评估方法。
- Result: 实验结果表明，提出的客观评估方法在AGTH质量评估中达到了最先进的性能。
- Conclusion: THQA-10K数据集和提出的评估方法为AGTH质量研究提供了重要工具，推动了该领域的发展。


### [46] [IN45023 Neural Network Design Patterns in Computer Vision Seminar Report, Summer 2025](https://arxiv.org/abs/2507.23357)
*Radu-Andrei Bourceanu,Neil De La Fuente,Jan Grimm,Andrei Jardan,Andriy Manucharyan,Cornelius Weiss,Roman Pflugfelder*

Main category: cs.CV

TL;DR: 报告分析了计算机视觉中关键设计模式的演变，包括ResNet、ViT、GANs、LDMs、DINO和MAE等六篇有影响力的论文。

- Motivation: 探讨计算机视觉领域的关键设计模式如何从基础架构发展到当前的最新技术，以推动图像识别和生成模型的进步。
- Method: 通过分析六篇论文，分别研究了残差连接（ResNet）、注意力机制（ViT）、对抗训练（GANs）、潜在扩散（LDMs）、自监督学习（DINO）和掩码自编码（MAE）等方法。
- Result: 展示了从ResNet到MAE的技术演进，突出了每种方法的创新点和性能提升，如ViT的注意力机制和LDMs的高效生成能力。
- Conclusion: 计算机视觉领域的设计模式不断演进，从深度网络到自监督学习，技术逐渐成熟，为未来研究提供了坚实基础。


### [47] [Short-LVLM: Compressing and Accelerating Large Vision-Language Models by Pruning Redundant Layers](https://arxiv.org/abs/2507.23362)
*Ji Ma,Wei Suo,Peng Wang,Yanning Zhang*

Main category: cs.CV

TL;DR: 论文提出了一种名为Short-LVLM（SVL）的新框架，通过利用重要的视觉语言（VL）标记和减少层间特征差距，解决了直接应用NLP层剪枝方法在大型视觉语言模型（LVLM）中无效的问题。

- Motivation: 大型视觉语言模型（LVLM）虽然具有强大的多模态理解和推理能力，但由于参数庞大和计算成本高，实际应用受限。NLP中的层剪枝方法在LVLM中是否有效尚不明确。
- Method: 通过实验发现，非必要的VL标记和层间特征差距是LVLM层剪枝的主要挑战。基于此，提出了Short-LVLM框架，利用重要VL标记并减少特征差距。
- Result: Short-LVLM在性能和效率之间取得了更好的平衡，同时具有无需训练、模型无关和高兼容性的优势。
- Conclusion: Short-LVLM为LVLM的压缩提供了一种有效的训练免费解决方案，具有广泛的应用潜力。


### [48] [VMatcher: State-Space Semi-Dense Local Feature Matching](https://arxiv.org/abs/2507.23371)
*Ali Youssef*

Main category: cs.CV

TL;DR: VMatcher是一种混合Mamba-Transformer网络，用于图像对的半密集特征匹配，结合了Mamba的高效长序列处理和Transformer的注意力机制，显著提升了效率。

- Motivation: 现有基于Transformer的特征匹配方法虽然性能优越，但计算成本高，而Mamba的线性复杂度提供了效率优势。
- Method: 提出了一种混合Mamba-Transformer架构，包括分层设计，结合两者的优势。
- Result: VMatcher在效率和性能上均表现优异，适用于实时应用。
- Conclusion: VMatcher通过混合设计在特征匹配任务中实现了高效和性能的平衡。


### [49] [UniEmo: Unifying Emotional Understanding and Generation with Learnable Expert Queries](https://arxiv.org/abs/2507.23372)
*Yijie Zhu,Lingsen Zhang,Zitong Yu,Rui Shao,Tao Tan,Liqiang Nie*

Main category: cs.CV

TL;DR: UniEmo是一个统一框架，将情感理解与生成任务结合，通过分层情感理解链和多尺度特征提取实现互补增强。

- Motivation: 情感理解与生成任务通常是分开处理的，但它们本质互补，可以相互增强。
- Method: 提出分层情感理解链和可学习专家查询，融合情感表示引导扩散模型生成情感图像，并引入情感相关系数和条件损失。
- Result: UniEmo在情感理解和生成任务上显著优于现有方法。
- Conclusion: 联合训练和生成驱动的双重反馈机制提升了模型的理解能力。


### [50] [Multi-Prompt Progressive Alignment for Multi-Source Unsupervised Domain Adaptation](https://arxiv.org/abs/2507.23373)
*Haoran Chen,Zexiao Wang,Haidong Cao,Zuxuan Wu,Yu-Gang Jiang*

Main category: cs.CV

TL;DR: 提出了一种渐进式对齐策略MP^2A，用于改进CLIP在多源无监督域适应中的性能，通过逐步引入高置信度样本减少噪声影响。

- Motivation: 现有方法在同时对齐所有伪标签数据时容易受噪声和难分类样本影响，导致误差传播和特征学习不理想，尤其在多源场景下问题更严重。
- Method: MP^2A方法首先在高置信度目标样本上训练模型，逐步引入更具挑战性的样本，以减少初始标签噪声的影响。
- Result: 在ImageCLEF、Office-Home和DomainNet三个基准测试中，MP^2A表现优于现有CLIP-based MS-UDA方法。
- Conclusion: 渐进式对齐策略有效减少了噪声干扰，提升了域不变特征的学习效果，在多源无监督域适应中表现优异。


### [51] [NeRF Is a Valuable Assistant for 3D Gaussian Splatting](https://arxiv.org/abs/2507.23374)
*Shuangkang Fang,I-Chao Shen,Takeo Igarashi,Yufeng Wang,ZeSheng Wang,Yi Yang,Wenrui Ding,Shuchang Zhou*

Main category: cs.CV

TL;DR: NeRF-GS结合了NeRF和3DGS的优势，通过联合优化解决了3DGS的局限性，提升了性能。

- Motivation: 3DGS存在初始化敏感、空间感知有限和高斯间相关性弱的问题，NeRF的连续空间表示可以弥补这些不足。
- Method: 通过渐进对齐3DGS和NeRF的空间特征，并优化残差向量，实现两者的联合优化。
- Result: 在基准数据集上，NeRF-GS表现优于现有方法，达到SOTA性能。
- Conclusion: NeRF和3DGS是互补的，结合两者为高效3D场景表示提供了新思路。


### [52] [AGA: An adaptive group alignment framework for structured medical cross-modal representation learning](https://arxiv.org/abs/2507.23402)
*Wei Li,Xun Gong,Jiao Li,Xiaobin Sun*

Main category: cs.CV

TL;DR: 提出Adaptive Grouped Alignment (AGA)框架，通过双向分组机制和自适应阈值门控模块，从医学图像和报告中提取结构化语义，无需依赖大量负样本。

- Motivation: 当前医学领域的视觉语言预训练方法简化了临床报告的结构，且对比学习依赖大量负样本，不适用于小规模医学数据集。
- Method: AGA通过稀疏相似度矩阵实现双向分组，设计自适应阈值门控模块动态学习分组阈值，并引入实例感知组对齐损失和双向跨模态组对齐模块。
- Result: 在公开和私有数据集上，AGA在图像文本检索和分类任务中表现出色，适用于微调和零样本设置。
- Conclusion: AGA有效解决了医学视觉语言预训练中的结构化语义提取和小样本问题，具有广泛的应用潜力。


### [53] [Out-of-Distribution Detection in Medical Imaging via Diffusion Trajectories](https://arxiv.org/abs/2507.23411)
*Lemar Abdi,Francisco Caetano,Amaan Valiuddin,Christiaan Viviers,Hamdi Joudeh,Fons van der Sommen*

Main category: cs.CV

TL;DR: 提出了一种基于Stein分数的去噪扩散模型（SBDDM）的无监督OOD检测方法，显著降低了计算成本并提升了性能。

- Motivation: 解决当前生成方法在计算成本、可靠性和适应性上的局限性，提高医学影像中异常检测的效率。
- Method: 利用SBDDM的前向扩散轨迹，通过Stein分数捕捉轨迹曲率，仅需五步扩散即可实现准确的异常评分。
- Result: 在Near-OOD和Far-OOD检测中相对提升了10.43%和18.10%，计算成本大幅降低。
- Conclusion: SBDDM是一种高效、可靠的OOD检测方法，适用于实时计算机辅助诊断。


### [54] [Honey Adulteration Detection using Hyperspectral Imaging and Machine Learning](https://arxiv.org/abs/2507.23416)
*Mokhtar A. Al-Awadhi,Ratnadeep R. Deshmukh*

Main category: cs.CV

TL;DR: 开发了一种基于机器学习的系统，通过高光谱成像数据自动检测蜂蜜中糖浆的掺假。

- Motivation: 当前化学检测方法复杂且耗时，需要一种更高效、准确的替代方法。
- Method: 系统分为两个子系统：蜜源分类和掺假检测。使用LDA提取特征，KNN进行分类和检测。
- Result: 在公开数据集上的交叉验证准确率为96.39%。
- Conclusion: 该系统是化学检测方法的有效替代方案。


### [55] [Beyond Linear Bottlenecks: Spline-Based Knowledge Distillation for Culturally Diverse Art Style Classification](https://arxiv.org/abs/2507.23436)
*Abdellah Zakaria Sellam,Salah Eddine Bekhouche,Cosimo Distante,Abdelmalik Taleb-Ahmed*

Main category: cs.CV

TL;DR: 论文提出了一种改进的双教师知识蒸馏框架，通过引入Kolmogorov-Arnold Networks (KANs) 替代传统的MLP投影和预测头，以解决艺术风格分类中非线性特征交互和全局构图上下文建模的挑战。

- Motivation: 艺术风格分类因缺乏专家标注数据和风格元素间复杂的非线性交互而具有挑战性。现有的双教师自监督框架虽减少了对标注数据的依赖，但其线性投影层和局部关注难以建模全局构图上下文和复杂风格特征交互。
- Method: 改进双教师知识蒸馏框架，用KANs替代传统MLP投影和预测头，保留两个教师网络的互补指导（一个关注局部纹理和笔触模式，另一个捕捉更广泛的风格层次），并利用KANs的样条激活精确建模非线性特征相关性。
- Result: 在WikiArt和Pandora18k数据集上的实验表明，该方法在Top-1准确率上优于基础双教师架构，且KANs在解耦复杂风格流形方面表现更优，线性探针准确率高于MLP投影。
- Conclusion: KANs在建模非线性特征交互和全局构图上下文方面具有优势，显著提升了艺术风格分类的性能。


### [56] [Adjustable Spatio-Spectral Hyperspectral Image Compression Network](https://arxiv.org/abs/2507.23447)
*Martin Hermann Paul Fuchs,Behnood Rasti,Begüm Demir*

Main category: cs.CV

TL;DR: 论文提出了一种可调整的基于学习的超光谱图像压缩网络（HyCASS），用于同时处理光谱和空间维度的压缩，并通过实验验证其有效性。

- Motivation: 随着超光谱数据在遥感领域的快速增长，高效存储需求日益突出，但现有研究尚未全面分析光谱和空间压缩的单独及联合效应对学习型超光谱图像压缩的影响。
- Method: HyCASS包含六个模块：光谱编码器、空间编码器、压缩比适配编码器、压缩比适配解码器、空间解码器和光谱解码器，结合卷积层和Transformer块捕捉短程和长程冗余。
- Result: 在两个超光谱基准数据集上的实验表明，HyCASS优于现有学习型压缩模型，并提供了在不同压缩比下平衡光谱和空间压缩的指导原则。
- Conclusion: HyCASS为超光谱图像压缩提供了一种有效的可调整解决方案，并揭示了光谱和空间压缩的优化策略。


### [57] [Machine learning and machine learned prediction in chest X-ray images](https://arxiv.org/abs/2507.23455)
*Shereiff Garrett,Abhinav Adhikari,Sarina Gautam,DaShawn Marquis Morris,Chandra Mani Adhikari*

Main category: cs.CV

TL;DR: 论文研究了两种机器学习算法（基线CNN和DenseNet-121）在胸部X光图像分类中的应用，发现DenseNet-121在决策时更关注关键区域。

- Motivation: 利用机器学习解决复杂问题，如通过胸部X光图像预测疾病，减少显式编程的需求。
- Method: 使用5824张胸部X光图像，分别训练基线CNN和DenseNet-121模型，并进行性能比较。
- Result: 两种模型在二元分类任务中表现良好，但DenseNet-121在决策时更准确地聚焦于图像的关键部分。
- Conclusion: DenseNet-121在胸部X光图像分类中优于基线CNN，尤其在关注关键区域方面表现更佳。


### [58] [Mitigating Resolution-Drift in Federated Learning: Case of Keypoint Detection](https://arxiv.org/abs/2507.23461)
*Taeheon Lim,Joohyung Lee,Kyungjae Lee,Jungchan Cho*

Main category: cs.CV

TL;DR: 联邦学习（FL）在保护用户数据隐私的同时实现分布式系统的高效学习，但现有研究主要关注分类任务。本文针对非分类任务（如人体姿态估计）中的分辨率漂移问题，提出了一种基于热图知识蒸馏的分辨率自适应联邦学习（RAF）方法，显著提升了性能。

- Motivation: 现有联邦学习研究主要集中于分类任务，而忽略了非分类任务（如人体姿态估计）中的分辨率漂移问题。本文旨在解决这一问题，并探索分辨率作为非独立同分布数据的重要性。
- Method: 提出分辨率自适应联邦学习（RAF），通过高分辨率输出（教师）与低分辨率输出（学生）之间的多分辨率知识蒸馏，增强分辨率鲁棒性。
- Result: 实验和理论分析表明，RAF有效缓解了分辨率漂移，显著提升了性能，并能无缝集成到现有FL框架中。
- Conclusion: RAF不仅适用于人体姿态估计，其t-SNE分析还揭示了分类任务与高分辨率表示任务的差异，表明RAF可推广到其他依赖空间细节的任务。


### [59] [CST Anti-UAV: A Thermal Infrared Benchmark for Tiny UAV Tracking in Complex Scenes](https://arxiv.org/abs/2507.23473)
*Bin Xie,Congxuan Zhang,Fagan Wang,Peng Liu,Feng Lu,Zhen Chen,Weiming Hu*

Main category: cs.CV

TL;DR: 论文介绍了CST Anti-UAV数据集，专为复杂场景下的小型无人机单目标跟踪设计，包含220个视频序列和24万高质量标注框，填补了现有数据集的不足。

- Motivation: 现有无人机跟踪数据集缺乏多样性和复杂性，难以满足实际需求，因此提出CST Anti-UAV数据集以提升研究实用性。
- Method: 构建包含220个视频序列和24万标注框的数据集，并首次引入完整的手动帧级属性标注，评估20种现有SOT方法。
- Result: 实验显示，现有方法在复杂环境下跟踪小型无人机效果不佳，最佳准确率仅为35.92%，远低于其他数据集。
- Conclusion: CST Anti-UAV数据集的发布将推动更鲁棒的SOT方法和反无人机系统的创新。


### [60] [3D-R1: Enhancing Reasoning in 3D VLMs for Unified Scene Understanding](https://arxiv.org/abs/2507.23478)
*Ting Huang,Zeyu Zhang,Hao Tang*

Main category: cs.CV

TL;DR: 3D-R1是一个增强3D视觉语言模型推理能力的基础模型，通过高质量合成数据集和强化学习优化，显著提升了3D场景理解的性能。

- Motivation: 当前3D视觉语言模型在推理和泛化能力上存在不足，主要受限于高质量空间数据和静态视角假设。
- Method: 构建Scene-30K合成数据集，结合强化学习策略（如GRPO）和动态视角选择策略，优化推理能力。
- Result: 在多个3D场景基准测试中平均提升10%，验证了模型的有效性。
- Conclusion: 3D-R1通过数据增强和动态视角选择，显著提升了3D场景理解的推理和泛化能力。


### [61] [Seeing More with Less: Video Capsule Endoscopy with Multi-Task Learning](https://arxiv.org/abs/2507.23479)
*Julia Werner,Oliver Bause,Julius Oexle,Maxime Le Floch,Franz Brinkmann,Jochen Hampe,Oliver Bringmann*

Main category: cs.CV

TL;DR: 提出了一种多任务神经网络，结合胃肠道精确定位和小肠异常检测功能，解决了胶囊内窥镜电池寿命短和数据稀疏的问题。

- Motivation: 胶囊内窥镜电池寿命短和数据稀疏限制了AI模型的部署，需开发高效的多任务模型。
- Method: 开发了参数受限的多任务神经网络，结合定位和异常检测功能，使用Galar数据集和多任务方法。
- Result: 模型在定位任务上准确率93.63%，异常检测任务上87.48%，仅需100万参数。
- Conclusion: 该多任务模型优于单任务模型，为AI在胶囊内窥镜中的应用提供了重要进展。


### [62] [FastPoint: Accelerating 3D Point Cloud Model Inference via Sample Point Distance Prediction](https://arxiv.org/abs/2507.23480)
*Donghyun Lee,Dawoon Jeong,Jae W. Lee,Hongil Yoon*

Main category: cs.CV

TL;DR: FastPoint是一种基于软件的加速技术，通过预测最远点采样中的距离趋势，显著提升了3D点云处理的效率。

- Motivation: 处理大规模和不规则点云时，现有深度神经网络效率低下，FastPoint旨在解决这一问题。
- Method: 利用最远点采样中采样点间距离的可预测趋势，预测距离曲线，避免计算所有点对距离。
- Result: 在NVIDIA RTX 3090 GPU上实现了2.55倍的端到端加速，且不影响准确性。
- Conclusion: FastPoint高效加速了点云处理，同时保持了采样质量和模型性能。


### [63] [Stable-Sim2Real: Exploring Simulation of Real-Captured 3D Data with Two-Stage Depth Diffusion](https://arxiv.org/abs/2507.23483)
*Mutian Xu,Chongjie Ye,Haolin Liu,Yushuang Wu,Jiahao Chang,Xiaoguang Han*

Main category: cs.CV

TL;DR: 提出了一种名为Stable-Sim2Real的两阶段深度扩散模型，用于数据驱动的3D数据模拟，显著提升了真实世界3D视觉任务的性能。

- Motivation: 现有3D数据模拟方法依赖预定义的物理先验，难以捕捉真实数据的复杂性，而数据驱动的隐式映射方法进展缓慢。
- Method: 采用两阶段深度扩散模型：第一阶段微调Stable-Diffusion生成真实与合成深度残差；第二阶段通过3D判别器优化局部区域。
- Result: 实验表明，该方法生成的3D模拟数据与真实数据高度相似，显著提升了3D视觉任务的性能。
- Conclusion: Stable-Sim2Real为3D数据模拟提供了新路径，其两阶段扩散模型有效解决了真实数据复杂性的问题。


### [64] [Online Estimation of Table-Top Grown Strawberry Mass in Field Conditions with Occlusions](https://arxiv.org/abs/2507.23487)
*Jinshan Zhen,Yuanyue Ge,Tianxiao Zhu,Hui Zhao,Ya Xiong*

Main category: cs.CV

TL;DR: 提出了一种基于视觉的草莓质量估计方法，结合RGB-D传感和深度学习，解决了遮挡和姿态变化问题，实现了实时在线估计。

- Motivation: 解决田间条件下草莓质量估计的挑战，如频繁遮挡和姿态变化。
- Method: 使用YOLOv8-Seg进行实例分割，CycleGAN完成遮挡区域，倾斜角校正优化投影面积计算，多项式回归模型映射几何特征到质量。
- Result: 平均质量估计误差为8.11%（孤立草莓）和10.47%（遮挡情况），CycleGAN在遮挡恢复上优于LaMa模型。
- Conclusion: 该方法克服了传统方法的局限性，为复杂遮挡模式下的自动化收获和产量监测提供了鲁棒解决方案。


### [65] [Hyperbolic Cycle Alignment for Infrared-Visible Image Fusion](https://arxiv.org/abs/2507.23508)
*Timing Li,Bing Cao,Jiahe Feng,Haifang Cao,Qinghau Hu,Pengfei Zhu*

Main category: cs.CV

TL;DR: 提出了一种基于双曲空间的图像配准方法Hy-CycleAlign，通过双路径循环配准框架和双曲层次对比对齐模块，显著提升了多模态图像配准和融合的质量。

- Motivation: 现有基于欧几里得空间的配准方法难以有效处理跨模态图像的对齐问题，导致配准和融合效果不佳。
- Method: 设计了双路径循环配准框架（Hy-CycleAlign）和双曲层次对比对齐模块（H²CA），在双曲空间中实现更敏感的跨模态图像配准。
- Result: 实验表明，该方法在多模态图像配准和融合任务中显著优于现有方法。
- Conclusion: 双曲空间为多模态图像配准提供了更有效的解决方案，Hy-CycleAlign方法具有显著优势。


### [66] [I Am Big, You Are Little; I Am Right, You Are Wrong](https://arxiv.org/abs/2507.23509)
*David A. Kelly,Akchunya Chanchal,Nathan Blake*

Main category: cs.CV

TL;DR: 论文提出使用最小充分像素集评估图像分类模型的‘集中度’，发现不同架构模型在像素集大小和位置上存在显著差异，且误分类图像通常需要更大的像素集。

- Motivation: 随着图像分类模型的多样化和复杂性增加，选择合适模型的需求日益重要。然而，对模型决策过程的理解有限，因此需要一种方法来深入分析不同模型的决策机制。
- Method: 通过最小充分像素集（捕捉图像本质的像素）来评估模型的‘集中度’，并比较不同模型在像素集位置、重叠和大小上的差异。
- Result: 发现不同架构模型（如ConvNext和EVA）在像素集大小和位置上存在显著差异，且误分类图像通常需要更大的像素集。
- Conclusion: 最小充分像素集是分析模型决策过程的有效工具，不同架构模型的‘集中度’差异显著，且误分类与像素集大小相关。


### [67] [ART: Adaptive Relation Tuning for Generalized Relation Prediction](https://arxiv.org/abs/2507.23543)
*Gopika Sudhakaran,Hikaru Shindo,Patrick Schramowski,Simone Schaub-Meyer,Kristian Kersting,Stefan Roth*

Main category: cs.CV

TL;DR: ART框架通过指令调优和自适应实例选择，提升视觉语言模型在视觉关系检测任务中的泛化能力和对新关系的处理能力。

- Motivation: 现有视觉关系检测模型在训练数据之外的关系上泛化能力不足，且提示调优方法对复杂或新关系的处理效果有限。
- Method: 提出ART框架，将VRD数据集转换为指令调优格式，并采用自适应采样算法，专注于信息丰富的关系。
- Result: ART在多个数据集上显著优于基线方法，并能推断未见过的关系概念。
- Conclusion: ART通过指令调优和自适应采样，有效提升了视觉关系检测的性能和泛化能力。


### [68] [3D-MOOD: Lifting 2D to 3D for Monocular Open-Set Object Detection](https://arxiv.org/abs/2507.23567)
*Yung-Hsu Yang,Luigi Piccinelli,Mattia Segu,Siyuan Li,Rui Huang,Yuqian Fu,Marc Pollefeys,Hermann Blum,Zuria Bauer*

Main category: cs.CV

TL;DR: 该论文提出了首个端到端的单目3D开放集目标检测器（3D-MOOD），通过将开放集2D检测提升到3D空间，并设计几何先验条件，实现了跨场景的泛化能力。

- Motivation: 现有单目3D目标检测方法局限于封闭集场景，无法应对现实世界中新环境和物体类别的挑战。
- Method: 设计了3D边界框头部，将开放集2D检测提升到3D空间，结合几何先验条件，并引入规范图像空间以优化跨数据集训练。
- Result: 在封闭集（Omni3D）和开放集（Omni3D到Argoverse 2、ScanNet）设置下均取得最先进性能。
- Conclusion: 3D-MOOD为单目3D开放集目标检测提供了有效解决方案，具有实际应用潜力。


### [69] [Gaussian Splatting Feature Fields for Privacy-Preserving Visual Localization](https://arxiv.org/abs/2507.23569)
*Maxime Pietrantoni,Gabriela Csurka,Torsten Sattler*

Main category: cs.CV

TL;DR: 该论文提出了一种基于3D高斯泼溅（3DGS）的场景表示方法（GSFFs），用于精确且保护隐私的视觉定位。通过结合显式几何模型和隐式特征场，该方法在多个真实数据集上实现了最先进的性能。

- Motivation: 视觉定位需要精确估计相机在已知环境中的位姿，同时保护隐私。3DGS提供了密集几何信息和可微光栅化算法，适合用于学习鲁棒的特征表示。
- Method: 提出GSFFs，结合3DGS和隐式特征场，通过对比框架对齐3D尺度感知特征场和2D特征编码器，并利用3D结构信息聚类正则化表示学习。
- Result: 在多个真实数据集上，隐私保护和非隐私保护的定位流程均表现出最先进的性能。
- Conclusion: GSFFs是一种高效且保护隐私的视觉定位方法，通过结合显式和隐式表示，实现了高精度定位。


### [70] [Beyond Gloss: A Hand-Centric Framework for Gloss-Free Sign Language Translation](https://arxiv.org/abs/2507.23575)
*Sobhan Asasi,Mohamed Ilyas Lakhal,Ozge Mercanoglu Sincan,Richard Bowden*

Main category: cs.CV

TL;DR: BeyondGloss是一种新颖的无注释手语翻译框架，利用视频大语言模型（VideoLLMs）的时空推理能力，通过生成细粒度、时间感知的文本描述和对比对齐模块提升性能。

- Motivation: 解决手语翻译中视觉与语言信息模态差异及捕捉手部细微变化的挑战。
- Method: 提出无注释框架BeyondGloss，结合VideoLLMs生成时间感知文本描述，使用对比对齐模块和HaMeR提取的手部特征，减少模态差异。
- Result: 在Phoenix14T和CSL-Daily基准测试中达到最先进性能。
- Conclusion: BeyondGloss框架有效解决了手语翻译的挑战，展示了其优越性能。


### [71] [MamV2XCalib: V2X-based Target-less Infrastructure Camera Calibration with State Space Model](https://arxiv.org/abs/2507.23595)
*Yaoye Zhu,Zhe Wang,Yan Wang*

Main category: cs.CV

TL;DR: MamV2XCalib是一种基于V2X的基础设施摄像头自动校准方法，利用车载LiDAR辅助，无需人工干预或特定参考物。

- Motivation: 传统手动校准方法耗时耗力且可能需要封路，亟需自动化解决方案。
- Method: 结合多尺度特征和4D相关体积估计点云与图像的关联，利用Mamba建模时间信息并估计旋转角度。
- Result: 在V2X-Seq和TUMTraf-V2X数据集上验证了方法的有效性和鲁棒性，性能优于单车辆校准方法。
- Conclusion: MamV2XCalib在V2X场景中实现了更优且稳定的校准性能，代码已开源。


### [72] [MoGA: 3D Generative Avatar Prior for Monocular Gaussian Avatar Reconstruction](https://arxiv.org/abs/2507.23597)
*Zijian Dong,Longteng Duan,Jie Song,Michael J. Black,Andreas Geiger*

Main category: cs.CV

TL;DR: MoGA提出了一种从单视角图像重建高保真3D高斯化头像的新方法，通过结合生成式头像模型和2D扩散模型，解决了3D一致性和真实性问题。

- Motivation: 现有方法依赖2D扩散模型生成稀疏且不一致的视图，导致3D伪影和模糊外观，MoGA旨在解决这些问题。
- Method: 利用生成式头像模型作为先验，结合2D扩散模型的合成视图，通过模型反演过程拟合高斯化头像，并施加3D约束。
- Result: 实验表明，MoGA优于现有技术，并能泛化到真实场景，生成的头像具有可动画性。
- Conclusion: MoGA通过结合生成式模型和扩散模型，实现了高保真且一致的3D高斯化头像重建。


### [73] [DA-Occ: Efficient 3D Voxel Occupancy Prediction via Directional 2D for Geometric Structure Preservation](https://arxiv.org/abs/2507.23599)
*Yuchen Zhou,Yan Luo,Xiangang Wang,Xingjian Gu,Mingzhou Lu*

Main category: cs.CV

TL;DR: 提出了一种基于方向性纯2D方法的高效3D占用预测方法，平衡了精度与推理速度。

- Motivation: 当前许多方法在追求高精度时牺牲了实时性，难以满足自动驾驶系统的需求。
- Method: 通过切片3D体素特征保留垂直几何信息，并采用方向性注意力机制提取多方向几何特征。
- Result: 在Occ3D-nuScenes上达到39.3% mIoU和27.7 FPS推理速度，边缘设备上为14.8 FPS。
- Conclusion: 该方法在精度与效率间取得平衡，适用于资源受限的实时部署场景。


### [74] [Mamba-based Efficient Spatio-Frequency Motion Perception for Video Camouflaged Object Detection](https://arxiv.org/abs/2507.23601)
*Xin Li,Keren Fu,Qijun Zhao*

Main category: cs.CV

TL;DR: 提出了一种基于时空频率运动感知的视频伪装目标检测方法Vcamba，结合频率和空间特征，显著提升了检测性能。

- Motivation: 现有方法主要依赖空间外观特征，但前景与背景的高相似性限制了检测准确性。频率特征和Mamba模型的长序列建模能力为解决这一问题提供了新思路。
- Method: 设计了RFVSS模块提取多尺度空间特征，AFE模块增强频率特征，SLMP和FLMP模块分别建模时空和频率-时间序列，SFMF模块融合双域特征。
- Result: 在2个数据集上的6个评估指标中表现优于现有方法，且计算成本更低。
- Conclusion: Vcamba通过结合频率和空间特征，显著提升了视频伪装目标检测的准确性和效率。


### [75] [Medical Image De-Identification Benchmark Challenge](https://arxiv.org/abs/2507.23608)
*Linmin Pei,Granger Sutton,Michael Rutherford,Ulrike Wagner,Tracy Nolan,Kirk Smith,Phillip Farmer,Peter Gu,Ambar Rana,Kailing Chen,Thomas Ferleman,Brian Park,Ye Wu,Jordan Kojouharov,Gargi Singh,Jon Lemon,Tyler Willis,Milos Vukadinovic,Grant Duffy,Bryan He,David Ouyang,Marco Pereanez,Daniel Samber,Derek A. Smith,Christopher Cannistraci,Zahi Fayad,David S. Mendelson,Michele Bufano,Elmar Kotter,Hamideh Haghiri,Rajesh Baidya,Stefan Dvoretskii,Klaus H. Maier-Hein,Marco Nolden,Christopher Ablett,Silvia Siggillino,Sandeep Kaushik,Hongzhu Jiang,Sihan Xie,Zhiyu Wan,Alex Michie,Simon J Doran,Angeline Aurelia Waly,Felix A. Nathaniel Liang,Humam Arshad Mustagfirin,Michelle Grace Felicia,Kuo Po Chih,Rahul Krish,Ghulam Rasool,Nidhal Bouaynaya,Nikolas Koutsoubis,Kyle Naddeo,Kartik Pandit,Tony O'Sullivan,Raj Krish,Qinyan Pan,Scott Gustafson,Benjamin Kopchick,Laura Opsahl-Ong,Andrea Olvera-Morales,Jonathan Pinney,Kathryn Johnson,Theresa Do,Juergen Klenk,Maria Diaz,Arti Singh,Rong Chai,David A. Clunie,Fred Prior,Keyvan Farahani*

Main category: cs.CV

TL;DR: MIDI-B Challenge旨在标准化DICOM图像去标识工具的基准测试，基于HIPAA Safe Harbor法规和DICOM属性保密配置文件，确保PHI/PII的去除同时保留研究关键元数据。

- Motivation: 医疗图像共享需符合患者隐私法律，同时保留非PHI元数据以支持AI研究。
- Method: 挑战分为训练、验证和测试三阶段，使用含合成PHI/PII的DICOM图像，参与者采用多种工具和方法。
- Result: 十支团队完成测试，正确操作百分比为97.91%至99.93%。
- Conclusion: MIDI-B挑战为图像去标识提供了标准化平台，展示了规则方法的有效性。


### [76] [Consistent Point Matching](https://arxiv.org/abs/2507.23609)
*Halid Ziya Yerebakan,Gerardo Hermosillo Valadez*

Main category: cs.CV

TL;DR: 将一致性启发式方法融入点匹配算法，提高了医学图像中解剖位置匹配的鲁棒性，并在多种数据集上验证了其优越性。

- Motivation: 解决医学图像中解剖位置匹配的鲁棒性问题，特别是在不同模态和纵向数据中。
- Method: 将一致性启发式方法融入点匹配算法，无需机器学习模型或训练数据。
- Result: 在Deep Lesion Tracking数据集上超越现有方法，同时高效运行于标准CPU硬件。
- Conclusion: 该方法实现了高精度的医学图像导航，且灵活平衡速度与鲁棒性。


### [77] [DivControl: Knowledge Diversion for Controllable Image Generation](https://arxiv.org/abs/2507.23620)
*Yucheng Xie,Fu Feng,Ruixiao Shi,Jing Wang,Yong Rui,Xin Geng*

Main category: cs.CV

TL;DR: DivControl提出了一种可分解的预训练框架，通过知识分流实现统一可控生成和高效适应，显著降低训练成本并提升性能。

- Motivation: 现有方法在图像到图像生成中要么需要为每个条件训练单独模型，要么依赖纠缠表示的统一架构，导致泛化能力差和适应成本高。
- Method: DivControl通过SVD分解ControlNet为基本组件，利用动态门进行知识分流，实现零样本泛化和高效适应。
- Result: DivControl在可控性上达到最优，训练成本降低36.4倍，同时在基本条件和未见条件上表现优异。
- Conclusion: DivControl展示了卓越的可扩展性、模块化和迁移能力，为可控生成提供了高效解决方案。


### [78] [Efficient Masked Attention Transformer for Few-Shot Classification and Segmentation](https://arxiv.org/abs/2507.23642)
*Dustin Carrión-Ojeda,Stefan Roth,Simone Schaub-Meyer*

Main category: cs.CV

TL;DR: EMAT是一种高效的少样本分类与分割方法，通过改进注意力机制和参数效率，显著提升小物体处理能力。

- Motivation: 当前SOTA方法在小物体处理上表现不佳，且现有评估设置未充分利用昂贵标注数据。
- Method: 提出EMAT，包含内存高效的掩码注意力机制、可学习降采样策略和参数效率优化。
- Result: 在PASCAL-5$^i$和COCO-20$^i$数据集上表现最优，参数减少四倍。
- Conclusion: EMAT显著提升性能，同时提出更实用的评估设置。


### [79] [FFGAF-SNN: The Forward-Forward Based Gradient Approximation Free Training Framework for Spiking Neural Networks](https://arxiv.org/abs/2507.23643)
*Changqing Xu,Ziqiang Yang,Yi Liu,Xinfang Liao,Guiqi Mo,Hao Zeng,Yintang Yang*

Main category: cs.CV

TL;DR: 提出了一种基于Forward-Forward的无梯度近似训练框架，用于高效训练SNN，并通过动态优化损失函数提升性能。

- Motivation: 解决SNN训练中的非可微性和计算复杂度问题，提升边缘设备部署的可行性。
- Method: 采用Forward-Forward框架，将脉冲激活视为黑盒模块，避免梯度近似；引入类感知复杂度适应机制动态优化损失函数。
- Result: 在MNIST、Fashion-MNIST和CIFAR-10数据集上分别达到99.58%、92.13%和75.64%的测试准确率，优于现有方法。
- Conclusion: 提出的方法显著降低了计算复杂度和内存访问需求，为SNN的高效训练和部署提供了新思路。


### [80] [Adaptively Distilled ControlNet: Accelerated Training and Superior Sampling for Medical Image Synthesis](https://arxiv.org/abs/2507.23652)
*Kunpeng Qiu,Zhiying Zhou,Yongxin Guo*

Main category: cs.CV

TL;DR: 提出了一种名为Adaptively Distilled ControlNet的任务无关框架，通过双模型蒸馏加速训练和优化，解决了医学图像标注中的隐私和标注效率问题。

- Motivation: 医学图像标注受隐私和标注效率限制，影响分割模型的性能和泛化能力。
- Method: 采用双模型蒸馏框架，教师模型基于掩码-图像对指导学生模型，并通过自适应正则化优化。
- Result: 在KiTS19和Polyps数据集上，TransUNet和SANet分别提升了2.4%/4.2%和2.6%/3.5%的性能。
- Conclusion: 该方法在医学图像生成和分割任务中表现出高效性和优越性，同时保护隐私。


### [81] [OmniTraj: Pre-Training on Heterogeneous Data for Adaptive and Zero-Shot Human Trajectory Prediction](https://arxiv.org/abs/2507.23657)
*Yang Gao,Po-Chien Luan,Kaouther Messaoud,Lan Feng,Alexandre Alahi*

Main category: cs.CV

TL;DR: 论文提出OmniTraj模型，通过显式时间元数据条件化解决零样本迁移问题，显著提升预测性能。

- Motivation: 现有预训练模型在新数据集上因时间动态变化需微调，限制了其扩展性和实用性。
- Method: 提出显式时间元数据条件化机制，并基于Transformer构建OmniTraj模型，在大规模异构数据集上预训练。
- Result: OmniTraj在零样本迁移中预测误差降低70%以上，微调后在多个数据集上达到SOTA。
- Conclusion: 显式时间条件化是解决时间动态变化问题的有效方法，OmniTraj展示了其优越性能。


### [82] [SAMSA: Segment Anything Model Enhanced with Spectral Angles for Hyperspectral Interactive Medical Image Segmentation](https://arxiv.org/abs/2507.23673)
*Alfie Roddan,Tobias Czempiel,Chi Xu,Daniel S. Elson,Stamatia Giannarou*

Main category: cs.CV

TL;DR: SAMSA是一种结合RGB基础模型和光谱分析的交互式分割框架，通过用户点击指导分割和光谱相似性计算，解决了高光谱成像（HSI）的数据限制和硬件差异问题。

- Motivation: 高光谱成像（HSI）在医学影像中提供丰富的光谱信息，但面临数据限制和硬件差异的挑战。
- Method: SAMSA通过独特的谱特征融合策略，独立于谱带数量与分辨率，结合用户点击指导RGB分割和光谱相似性计算。
- Result: 在公开数据集上，SAMSA在神经外科和猪体内高光谱数据集上分别达到81.0%/93.4%和81.1%/89.2%的DICE分数（1/5次点击）。
- Conclusion: SAMSA在少样本和零样本学习场景中表现优异，支持不同光谱特性数据集的无缝集成，为高光谱医学影像分析提供灵活框架。


### [83] [I2V-GS: Infrastructure-to-Vehicle View Transformation with Gaussian Splatting for Autonomous Driving Data Generation](https://arxiv.org/abs/2507.23683)
*Jialei Chen,Wuhao Xu,Sipeng He,Baoru Huang,Dongchun Ren*

Main category: cs.CV

TL;DR: I2V-GS提出了一种从基础设施视角到车辆视角的数据转换方法，利用高斯泼溅和自适应深度变形生成高质量驾驶数据。

- Motivation: 当前自动驾驶数据采集成本高且效率低，需要一种从真实图像合成数据的方法。
- Method: 采用自适应深度变形生成密集训练视图，级联策略修复变形图像，并利用跨视角信息进行置信度优化。
- Result: I2V-GS在车辆视角下的合成质量显著提升，NTA-Iou、NTL-Iou和FID指标分别提高45.7%、34.2%和14.9%。
- Conclusion: I2V-GS是首个实现基础设施-车辆视角转换的框架，为自动驾驶数据生成提供了高效解决方案。


### [84] [UniLDiff: Unlocking the Power of Diffusion Priors for All-in-One Image Restoration](https://arxiv.org/abs/2507.23685)
*Zihan Cheng,Liangtai Zhou,Dian Chen,Ni Tang,Xiaotong Luo,Yanyun Qu*

Main category: cs.CV

TL;DR: 提出了一种基于潜在扩散模型（LDM）的统一图像修复框架，通过Degradation-Aware Feature Fusion（DAFF）和Detail-Aware Expert Module（DAEM）模块，解决了多任务和混合退化场景下的图像修复问题。

- Motivation: All-in-One Image Restoration（AiOIR）是一个有前景但具有挑战性的研究方向，需要一种统一的框架来处理多样化的退化问题。
- Method: 采用潜在扩散模型（LDM），设计DAFF模块自适应处理多种退化类型，并通过DAEM模块增强细节恢复。
- Result: 在多任务和混合退化设置下的实验表明，该方法始终达到最先进的性能。
- Conclusion: 扩散先验在统一图像修复中具有实际潜力，代码将公开。


### [85] [Enhanced Velocity Field Modeling for Gaussian Video Reconstruction](https://arxiv.org/abs/2507.23704)
*Zhenyang Li,Xiaoyang Bai,Tongchen Zhang,Pengfei Shen,Weiwei Xu,Yifan Peng*

Main category: cs.CV

TL;DR: FlowGaussian-VR提出了一种基于流的速度场建模方案，用于高保真3D视频重建，解决了复杂运动和尺度变化中的视觉质量问题。

- Motivation: 高保真3D视频重建对VR/AR至关重要，但现有方法在复杂运动和尺度变化中表现不佳。
- Method: FlowGaussian-VR包括速度场渲染（VFR）管道和流辅助自适应致密化（FAD）策略。
- Result: 在多个真实数据集上验证，PSNR提升超过2.5 dB，动态纹理模糊减少，轨迹更规则。
- Conclusion: FlowGaussian-VR显著提升了动态场景重建的视觉质量和轨迹跟踪能力。


### [86] [Explainable Image Classification with Reduced Overconfidence for Tissue Characterisation](https://arxiv.org/abs/2507.23709)
*Alfie Roddan,Chi Xu,Serine Ajlouni,Irini Kakaletri,Patra Charalampaki,Stamatia Giannarou*

Main category: cs.CV

TL;DR: 提出一种结合风险估计的像素归因方法，提升图像分类的可解释性，并通过实验验证其优于现有方法。

- Motivation: 深度学习模型的过度自信会导致像素归因的不可靠，影响术中决策的安全性。
- Method: 迭代应用分类模型和像素归因方法生成PA图分布，计算期望值和变异系数以估计风险。
- Result: 在pCLE数据和ImageNet上验证，性能优于现有技术。
- Conclusion: 该方法不仅提供改进的PA图，还能估计风险，提升可解释性和可靠性。


### [87] [DiffuMatch: Category-Agnostic Spectral Diffusion Priors for Robust Non-rigid Shape Matching](https://arxiv.org/abs/2507.23715)
*Emery Pierson,Lei Li,Angela Dai,Maks Ovsjanikov*

Main category: cs.CV

TL;DR: 论文提出了一种数据驱动的方法，替代传统的基于公理模型的功能映射正则化和训练，通过生成模型在谱域中学习功能映射的结构特性，提高了非刚性形状匹配的准确性。

- Motivation: 现有方法仅将学习应用于特征函数，仍依赖公理模型进行训练损失或功能映射正则化，限制了准确性和适用性。本文旨在完全用数据驱动方法替代这些公理模型。
- Method: 训练一个基于分数生成模型的谱域功能映射生成模型，利用该模型在新形状集合中推广真实功能映射的结构特性。
- Result: 实验表明，学习到的正则化方法在零样本非刚性形状匹配中优于公理方法，且模型具有类别无关性。
- Conclusion: 数据驱动的功能映射正则化和训练方法可以完全替代传统公理模型，提高非刚性形状匹配的准确性和通用性。


### [88] [RAGNet: Large-scale Reasoning-based Affordance Segmentation Benchmark towards General Grasping](https://arxiv.org/abs/2507.23734)
*Dongming Wu,Yanping Fu,Saike Huang,Yingfei Liu,Fan Jia,Nian Liu,Feng Dai,Tiancai Wang,Rao Muhammad Anwer,Fahad Shahbaz Khan,Jianbing Shen*

Main category: cs.CV

TL;DR: 论文提出了一个名为RAGNet的大规模抓取导向的affordance分割基准，包含273k图像和26k推理指令，并提出了AffordanceNet框架，展示了强大的开放世界泛化能力。

- Motivation: 解决当前研究中缺乏基于推理的大规模affordance预测数据的问题，以提升开放世界场景下的有效性。
- Method: 构建RAGNet基准，包含多样化的图像和功能描述指令，并开发AffordanceNet框架，结合预训练的视觉语言模型和抓取网络。
- Result: 在affordance分割基准和真实机器人任务中表现出强大的开放世界泛化能力。
- Conclusion: RAGNet和AffordanceNet为开放世界机器人抓取提供了有效的数据和方法支持。


### [89] [Slot Attention with Re-Initialization and Self-Distillation](https://arxiv.org/abs/2507.23755)
*Rongzhen Zhao,Yi Zhao,Juho Kannala,Joni Pajarinen*

Main category: cs.CV

TL;DR: DIAS提出了一种改进的Slot Attention方法，通过重新初始化和自蒸馏减少冗余槽并优化注意力机制，提升了对象中心学习任务的性能。

- Motivation: 现有Slot Attention方法存在冗余槽竞争和缺乏内部监督的问题，导致对象分割错误。
- Method: DIAS通过重新初始化冗余槽和自蒸馏注意力图来优化Slot Attention。
- Result: 实验表明DIAS在对象发现和识别等任务上达到SOTA，并提升了视觉预测和推理能力。
- Conclusion: DIAS有效解决了现有方法的局限性，为对象中心学习提供了更优的解决方案。


### [90] [SeqAffordSplat: Scene-level Sequential Affordance Reasoning on 3D Gaussian Splatting](https://arxiv.org/abs/2507.23772)
*Di Li,Jie Feng,Jiahao Chen,Weisheng Dong,Guanbin Li,Yuhui Zheng,Mingtao Feng,Guangming Shi*

Main category: cs.CV

TL;DR: 论文提出SeqAffordSplat基准和SeqSplatNet框架，用于解决3D高斯泼溅环境中的长时程多物体交互任务。

- Motivation: 现有基于3D高斯泼溅的方法仅支持单物体单步交互，无法满足复杂场景需求。
- Method: 提出SeqSplatNet框架，结合大语言模型和条件解码器生成3D掩码，并引入预训练策略和特征注入机制。
- Result: 在SeqAffordSplat基准上取得最优性能，成功扩展了功能推理能力。
- Conclusion: SeqSplatNet为复杂场景中的长时程功能推理提供了有效解决方案。


### [91] [Half-Physics: Enabling Kinematic 3D Human Model with Physical Interactions](https://arxiv.org/abs/2507.23778)
*Li Siyao,Yao Feng,Omid Tehari,Chen Change Loy,Michael J. Black*

Main category: cs.CV

TL;DR: 提出了一种将SMPL-X嵌入可动态物理交互实体的新方法，通过“半物理”机制实现无穿透和真实物体动力学。

- Motivation: 解决当前3D人体模型（如SMPL-X）因运动学性质无法与环境物理交互的问题，如穿透和不真实的物体动力学。
- Method: 采用“半物理”机制，将3D运动学运动转化为物理模拟，保留运动学控制的同时实现物理交互。
- Result: 方法无需学习，实时运行，适用于任意体型和动作，且保持原始运动学动作的保真度。
- Conclusion: 该方法有效解决了运动学模型的物理交互问题，具有高效性和通用性。


### [92] [Phi-Ground Tech Report: Advancing Perception in GUI Grounding](https://arxiv.org/abs/2507.23779)
*Miaosen Zhang,Ziqiang Xu,Jialiang Zhu,Qi Dai,Kai Qiu,Yifan Yang,Chong Luo,Tianyi Chen,Justin Wagle,Tim Franklin,Baining Guo*

Main category: cs.CV

TL;DR: 论文研究了多模态推理模型中的GUI接地问题，提出了Phi-Ground模型家族，在多个基准测试中达到最先进性能。

- Motivation: GUI接地是计算机使用代理（CUAs）执行实际动作的核心组件，当前模型的准确性不足，限制了其实际部署。
- Method: 通过实证研究，从数据收集到模型训练，开发了Phi-Ground模型家族。
- Result: Phi-Ground在多个基准测试中表现优异，特别是在10B参数以下的模型中达到SOTA性能。
- Conclusion: 论文不仅改进了接地模型，还为其他感知任务提供了有益的经验。


### [93] [MonoFusion: Sparse-View 4D Reconstruction via Monocular Fusion](https://arxiv.org/abs/2507.23782)
*Zihan Wang,Jeff Tan,Tarasha Khurana,Neehar Peri,Deva Ramanan*

Main category: cs.CV

TL;DR: 提出了一种从稀疏视角视频中重建动态场景的方法，解决了传统多视角重建方法在稀疏视角下效果不佳的问题。

- Motivation: 传统方法需要密集多视角摄像头（如Panoptic Studio），成本高且难以捕捉多样化场景。本文旨在从少量稀疏视角摄像头（如四个静态摄像头）重建动态人类行为。
- Method: 通过独立单目重建并对其对齐，生成时间和视角一致的动态场景重建。
- Result: 在PanopticStudio和Ego-Exo4D数据集上实验表明，该方法在渲染新视角时优于现有技术。
- Conclusion: 该方法在稀疏视角下实现了高质量动态场景重建，代码和数据已开源。


### [94] [SUB: Benchmarking CBM Generalization via Synthetic Attribute Substitutions](https://arxiv.org/abs/2507.23784)
*Jessica Bader,Leander Girrbach,Stephan Alaniz,Zeynep Akata*

Main category: cs.CV

TL;DR: 论文提出SUB基准，评估概念瓶颈模型（CBMs）在分布偏移下的概念识别能力，并引入Tied Diffusion Guidance（TDG）方法精确生成图像。

- Motivation: CBMs在透明AI应用中表现优异，但在分布偏移下概念识别不可靠，需更严格的评估方法。
- Method: 基于CUB数据集，创建包含38,400张合成图像的SUB基准，采用TDG方法控制生成图像。
- Result: SUB基准和TDG方法能有效评估CBMs的鲁棒性，促进更稳健方法的发展。
- Conclusion: SUB为CBMs的评估提供了新工具，推动了透明AI模型的进一步发展。


### [95] [Gaussian Variation Field Diffusion for High-fidelity Video-to-4D Synthesis](https://arxiv.org/abs/2507.23785)
*Bowen Zhang,Sicheng Xu,Chuxin Wang,Jiaolong Yang,Feng Zhao,Dong Chen,Baining Guo*

Main category: cs.CV

TL;DR: 提出了一种从单视频输入生成高质量动态3D内容的新框架，通过直接编码高斯溅射及其时间变化，避免了高维4D扩散建模的挑战。

- Motivation: 解决直接4D扩散建模的高成本和高维度问题，实现高效动态3D内容生成。
- Method: 引入Direct 4DMesh-to-GS Variation Field VAE，编码高斯溅射及其时间变化，结合时间感知的Diffusion Transformer训练模型。
- Result: 在Objaverse数据集上训练，生成质量优于现有方法，并能泛化到真实视频输入。
- Conclusion: 为高质量动态3D内容生成提供了新途径，展示了合成数据训练的泛化能力。
## cs.LG

### [96] [Planning for Cooler Cities: A Multimodal AI Framework for Predicting and Mitigating Urban Heat Stress through Urban Landscape Transformation](https://arxiv.org/abs/2507.23000)
*Shengao Yi,Xiaojiang Li,Wei Tu,Tianhong Zhao*

Main category: cs.LG

TL;DR: GSM-UTCI是一种多模态深度学习框架，用于预测城市尺度的UTCI，具有高精度和快速计算能力，适用于城市气候适应规划。

- Motivation: 随着极端热事件加剧，城市需要高效工具评估和缓解热应力，传统物理模型计算成本高，难以扩展。
- Method: 提出GSM-UTCI框架，融合地表形态、土地覆盖数据和气象条件，使用FiLM架构动态调整空间特征。
- Result: 模型在R2和MAE上表现优异，计算时间大幅缩短，应用于费城绿化场景显示显著降温效果。
- Conclusion: GSM-UTCI是高效、精细的城市气候适应决策工具，支持多样化绿化策略评估。


### [97] [Investigating the Invertibility of Multimodal Latent Spaces: Limitations of Optimization-Based Methods](https://arxiv.org/abs/2507.23010)
*Siwoo Park*

Main category: cs.LG

TL;DR: 本文研究了任务特定AI模型中多模态潜在空间的反向能力及其广泛用途，发现这些空间在反向任务中表现不佳，缺乏语义一致性和感知连贯性。

- Motivation: 探索多模态潜在空间在反向任务中的潜力，填补现有研究空白。
- Method: 提出基于优化的框架，应用于文本-图像和文本-音频模态的双向映射。
- Result: 实验表明反向映射的感知质量差且语义不连贯，潜在空间缺乏可解释性。
- Conclusion: 多模态潜在空间需进一步研究以实现语义丰富且可逆的结构。


### [98] [FuseTen: A Generative Model for Daily 10 m Land Surface Temperature Estimation from Spatio-Temporal Satellite Observations](https://arxiv.org/abs/2507.23154)
*Sofiane Bouaziz,Adel Hafiane,Raphael Canals,Rachid Nedjai*

Main category: cs.LG

TL;DR: FuseTen是一种生成框架，通过融合Sentinel-2、Landsat 8和Terra MODIS的数据，生成每日10米空间分辨率的地表温度（LST）观测数据，解决了卫星数据时空分辨率权衡的问题。

- Motivation: 城市热浪、干旱和土地退化在气候变化背景下日益严峻，需要高精度的时空地表温度数据来研究这些问题。
- Method: FuseTen采用生成架构，结合注意力机制和归一化模块，使用基于物理原理的监督策略和PatchGAN判别器来提升数据真实性。
- Result: 实验表明，FuseTen在定量指标上平均提升32.06%，视觉保真度提升31.42%，优于线性基线方法。
- Conclusion: FuseTen是首个能够在如此精细空间分辨率下生成每日LST估计的非线性方法，为相关研究提供了重要工具。


### [99] [Continual Learning with Synthetic Boundary Experience Blending](https://arxiv.org/abs/2507.23534)
*Chih-Fan Hsu,Ming-Ching Chang,Wei-Chao Chen*

Main category: cs.LG

TL;DR: 论文提出了一种名为“Experience Blending”的新方法，通过结合存储的关键样本和合成的边界数据（SBD）来改善持续学习中的灾难性遗忘问题。

- Motivation: 持续学习中，经验回放的效果受限于存储样本的稀疏分布，导致决策边界过于简化。论文假设通过在决策边界附近引入合成数据（SBD）可以隐式正则化，提高边界稳定性并减少遗忘。
- Method: 提出“Experience Blending”框架，包括：（1）多元差分隐私噪声机制生成SBD；（2）端到端训练策略，结合存储样本和SBD。
- Result: 在CIFAR-10、CIFAR-100和Tiny ImageNet上，方法优于9个基线，准确率分别提升10%、6%和13%。
- Conclusion: 实验验证了SBD作为隐式正则化的有效性，Experience Blending显著提升了持续学习的性能。


### [100] [DepMicroDiff: Diffusion-Based Dependency-Aware Multimodal Imputation for Microbiome Data](https://arxiv.org/abs/2507.23676)
*Rabeya Tus Sadia,Qiang Cheng*

Main category: cs.LG

TL;DR: DepMicroDiff是一种结合扩散模型和依赖感知Transformer的新框架，用于微生物组数据插补，显著优于现有方法。

- Motivation: 微生物组数据分析对理解宿主健康和疾病至关重要，但数据稀疏性和噪声问题阻碍了准确的插补和下游任务。现有方法未能充分捕捉微生物间的复杂依赖关系和上下文元数据。
- Method: DepMicroDiff结合扩散生成模型和依赖感知Transformer，通过VAE预训练和基于LLM的元数据编码增强模型。
- Result: 在TCGA数据集上，DepMicroDiff在Pearson相关性、余弦相似度和误差指标上显著优于现有方法。
- Conclusion: DepMicroDiff在微生物组数据插补中表现出鲁棒性和泛化能力，为下游任务提供了更准确的数据支持。


### [101] [Consensus-Driven Active Model Selection](https://arxiv.org/abs/2507.23771)
*Justin Kay,Grant Van Horn,Subhransu Maji,Daniel Sheldon,Sara Beery*

Main category: cs.LG

TL;DR: CODA是一种主动模型选择方法，通过利用候选模型的预测结果优先标注能高效区分最佳模型的数据点，显著减少标注工作量。

- Motivation: 传统模型选择需要大量标注验证数据，成本高且耗时。CODA旨在通过主动学习减少标注需求。
- Method: CODA基于概率框架建模分类器、类别和数据点之间的关系，利用模型间的共识和分歧指导标注，并通过贝叶斯推断更新最佳模型。
- Result: 在26个基准任务上，CODA显著优于现有方法，标注工作量减少70%以上。
- Conclusion: CODA提供了一种高效的主动模型选择方法，大幅降低了标注成本。
## cs.CR

### [102] [LLM-Based Identification of Infostealer Infection Vectors from Screenshots: The Case of Aurora](https://arxiv.org/abs/2507.23611)
*Estelle Ruellan,Eric Clay,Nicholas Ascoli*

Main category: cs.CR

TL;DR: 利用LLM（如gpt-4o-mini）分析感染截图，提取潜在威胁指标（IoCs），识别感染途径并追踪恶意活动。

- Motivation: 现有研究多关注主动检测，而忽略了对感染截图等反应性分析的需求。
- Method: 使用LLM分析Aurora窃密木马的感染截图，提取URL、文件和感染主题。
- Result: 从1000张截图中提取337个URL和246个文件，识别出3个恶意活动。
- Conclusion: LLM驱动的分析为威胁情报提供了可扩展的新方法。
## cs.RO

### [103] [GSFusion:Globally Optimized LiDAR-Inertial-Visual Mapping for Gaussian Splatting](https://arxiv.org/abs/2507.23273)
*Jaeseok Park,Chanoh Park,Minsu Kim,Soohwan Kim*

Main category: cs.RO

TL;DR: GSFusion是一种结合LiDAR、惯性和视觉的在线映射系统，通过全局姿态图优化和高效的高斯初始化策略，解决了传统3DGS方法的局限性和LiDAR集成中的挑战。

- Motivation: 传统基于相机传感器的3DGS方法存在计算负载高、在低纹理或光照差环境中失效、操作范围短等问题，而LiDAR虽为替代方案，但集成时面临全局对齐和高优化时间的挑战。
- Method: 提出GSFusion系统，采用全局姿态图优化中的surfel-to-surfel约束确保地图一致性，并通过像素感知的高斯初始化和有界sigmoid约束处理稀疏数据。
- Result: 在公开和自有数据集上的实验表明，GSFusion在渲染质量和地图构建效率上优于现有3DGS SLAM系统。
- Conclusion: GSFusion通过多传感器融合和优化策略，显著提升了3DGS在复杂环境中的性能和实用性。


### [104] [H-RDT: Human Manipulation Enhanced Bimanual Robotic Manipulation](https://arxiv.org/abs/2507.23523)
*Hongzhe Bi,Lingxuan Wu,Tianwei Lin,Hengkai Tan,Zhizhong Su,Hang Su,Jun Zhu*

Main category: cs.RO

TL;DR: H-RDT利用人类操作数据增强机器人操作能力，通过两阶段训练（预训练和微调），在仿真和真实实验中显著优于现有方法。

- Motivation: 机器人模仿学习面临高质量演示数据稀缺的问题，跨机器人形态的统一训练具有挑战性。
- Method: 提出H-RDT，基于扩散变换器架构，利用人类操作视频和3D手部姿态注释进行预训练，再通过模块化编码器-解码器进行跨形态微调。
- Result: H-RDT在仿真和真实实验中分别比从头训练提高13.9%和40.5%，优于现有方法。
- Conclusion: 人类操作数据可作为学习机器人双手操作策略的强大基础。


### [105] [A Unified Perception-Language-Action Framework for Adaptive Autonomous Driving](https://arxiv.org/abs/2507.23540)
*Yi Zhang,Erik Leo Haß,Kuo-Yi Chao,Nenad Petrovic,Yinglei Song,Chengdong Wu,Alois Knoll*

Main category: cs.RO

TL;DR: 提出了一种统一的感知-语言-行动（PLA）框架，结合多传感器融合和大型语言模型（LLM），以提升自动驾驶系统的适应性和可解释性。

- Motivation: 自动驾驶系统在复杂开放环境中的适应性、鲁棒性和可解释性面临挑战，现有架构碎片化且泛化能力有限。
- Method: 采用多传感器融合（相机、LiDAR、雷达）和基于GPT-4.1的视觉-语言-行动（VLA）架构，实现低层感知与高层语义推理的统一。
- Result: 在城市交叉路口场景中，框架在轨迹跟踪、速度预测和自适应规划方面表现优异。
- Conclusion: 语言增强的认知框架有望提升自动驾驶系统的安全性、可解释性和可扩展性。


### [106] [User Experience Estimation in Human-Robot Interaction Via Multi-Instance Learning of Multimodal Social Signals](https://arxiv.org/abs/2507.23544)
*Ryo Miyoshi,Yuki Okafuji,Takuya Iwamoto,Junya Nakanishi,Jun Baba*

Main category: cs.RO

TL;DR: 提出了一种基于多模态社交信号（面部表情和语音）的Transformer模型，用于评估人机交互中的用户体验（UX），并通过多实例学习框架捕捉短期和长期交互模式，优于传统方法和第三方评估。

- Motivation: 社会机器人需要根据用户状态调整行为，而准确评估用户体验（UX）是实现这一目标的关键。现有方法往往单独关注情感或参与度等单一维度，缺乏对UX多维度特性的综合考量。
- Method: 构建了一个UX数据集，开发了基于Transformer的模型，利用面部表情和语音信号，并通过多实例学习框架捕捉交互的短期和长期模式。
- Result: 实验结果表明，该方法在UX评估上优于第三方人工评估。
- Conclusion: 该方法通过多模态信号和时序动态捕捉，提供了更全面的UX表征，为人机交互的适应性行为提供了有效支持。
## cs.HC

### [107] [iLearnRobot: An Interactive Learning-Based Multi-Modal Robot with Continuous Improvement](https://arxiv.org/abs/2507.22896)
*Kohou Wang,ZhaoXiang Liu,Lin Bai,Kun Fan,Xiang Liu,Huan Hu,Kai Wang,Shiguo Lian*

Main category: cs.HC

TL;DR: 论文提出了一种基于多模态大语言模型（MLLM）的交互式学习机器人系统，能够通过与普通用户的自然对话学习，并通过问题链和双模态检索模块提升性能。

- Motivation: 机器人部署后可能遇到未见过的场景，需提升其适应能力。
- Method: 结合MLLM，通过自然对话学习，使用问题链明确意图，双模态检索模块避免重复错误。
- Result: 实验证明系统在定量和定性上均有效提升性能。
- Conclusion: 该系统为机器人交互学习提供了新方法，增强了多样环境中的适应性和性能。


### [108] [Automated Label Placement on Maps via Large Language Models](https://arxiv.org/abs/2507.22952)
*Harry Shomer,Jiejun Xu*

Main category: cs.HC

TL;DR: 论文提出了一种基于大语言模型（LLMs）的自动标签放置（ALP）新方法，通过数据编辑任务和上下文感知的空间标注，解决了传统自动化系统难以适应地图标注需求的问题。

- Motivation: 标签放置是地图设计的关键环节，但现有自动化系统难以整合制图惯例、适应上下文或解析标注指令，导致其难以规模化应用。
- Method: 该方法将标签放置任务视为数据编辑问题，利用检索增强生成（RAG）获取标注指南，并通过指令调优的LLMs生成理想标签坐标。
- Result: 在MAPLE基准数据集上评估了四种开源LLMs，结果显示LLMs在结构化提示和领域特定检索的引导下，能够生成符合专家制图标准的空间编辑结果。
- Conclusion: 研究提出了一种可扩展的AI辅助地图标注框架，展示了基础模型在结构化数据编辑任务中的潜力。


### [109] [Accessibility Scout: Personalized Accessibility Scans of Built Environments](https://arxiv.org/abs/2507.23190)
*William Huang,Xia Su,Jon E. Froehlich,Yang Zhang*

Main category: cs.HC

TL;DR: Accessibility Scout利用大型语言模型（LLM）自动评估陌生建筑环境的无障碍性，结合个人需求，提供个性化扫描。

- Motivation: 传统手动评估费时且难以扩展，而自动方法常忽略用户个性化需求。LLM的发展为解决这一问题提供了新思路。
- Method: 开发基于LLM的系统Accessibility Scout，通过照片识别无障碍问题，并结合用户反馈逐步优化个性化扫描。
- Result: 技术评估和用户研究表明，该系统能生成超越传统ADA标准的个性化无障碍扫描。
- Conclusion: 研究为构建更可扩展和个性化的物理世界无障碍评估提供了方向。
## eess.IV

### [110] [Rethink Domain Generalization in Heterogeneous Sequence MRI Segmentation](https://arxiv.org/abs/2507.23110)
*Zheyuan Zhang,Linkai Peng,Wanying Dou,Cuiling Sun,Halil Ertugrul Aktas,Andrea M. Bejar,Elif Keles,Gorkem Durak,Ulas Bagci*

Main category: eess.IV

TL;DR: PancreasDG是一个大规模多中心3D MRI胰腺分割数据集，用于研究医学影像中的领域泛化问题，解决了现有基准中胰腺分割的不足。

- Motivation: 胰腺分割在腹部成像中具有挑战性，且现有基准中胰腺代表性不足，但其在癌症早期检测、手术和糖尿病研究中具有重要临床意义。
- Method: 提出PancreasDG数据集，包含563个MRI扫描，来自六个机构，涵盖静脉期和非同期序列，采用双盲双次协议生成像素级胰腺掩码。
- Result: 研究发现采样不足可能被误认为分布偏移，跨中心性能与源域性能相关，跨序列偏移需要专门解决方案。提出的半监督方法显著优于现有技术。
- Conclusion: PancreasDG为医学影像领域泛化设定了新基准，数据集、代码和模型将公开。


### [111] [Towards High-Resolution Alignment and Super-Resolution of Multi-Sensor Satellite Imagery](https://arxiv.org/abs/2507.23150)
*Philip Wootaek Shin,Vishal Gaur,Rahul Ramachandran,Manil Maskey,Jack Sampson,Vijaykrishnan Narayanan,Sujit Roy*

Main category: eess.IV

TL;DR: 论文提出了一种框架，用于对齐和融合30米分辨率的HLS影像与10米分辨率的HLS影像，以提升卫星影像的超分辨率质量。

- Motivation: 高分辨率卫星影像对地理空间分析至关重要，但不同传感器间的分辨率差异给数据融合和下游应用带来挑战。现有超分辨率方法依赖人工降尺度影像，不适用于光谱和时间特性不同的异构卫星传感器。
- Method: 开发了一个初步框架，以HLS10为参考，对齐和融合HLS30影像，旨在弥合传感器间的分辨率差距。
- Result: 定量和定性评估表明该方法有效，提升了超分辨率Landsat影像的质量。
- Conclusion: 研究验证了异构卫星影像超分辨率的可行性，并指出了未来改进的关键方向。


### [112] [LesionGen: A Concept-Guided Diffusion Model for Dermatology Image Synthesis](https://arxiv.org/abs/2507.23001)
*Jamil Fayyad,Nourhan Bayasi,Ziyang Yu,Homayoun Najjaran*

Main category: eess.IV

TL;DR: LesionGen是一个基于文本到图像扩散概率模型（T2I-DPM）的皮肤病图像合成框架，通过高质量图像-描述对生成多样且真实的皮肤病图像。

- Motivation: 皮肤病分类的深度学习模型需要大量多样且标注良好的数据，但现有数据集因隐私、标注成本高和人口代表性不足而受限。
- Method: LesionGen利用专家标注和伪生成的概念丰富描述，微调预训练的扩散模型，生成基于皮肤病学描述的图像。
- Result: 仅使用合成数据训练的模型分类准确率与真实图像训练的模型相当，且在少数群体性能上有显著提升。
- Conclusion: LesionGen为皮肤病图像合成提供了高效解决方案，弥补了数据不足的问题。


### [113] [MRpro - open PyTorch-based MR reconstruction and processing package](https://arxiv.org/abs/2507.23129)
*Felix Frederik Zimmermann,Patrick Schuenke,Christoph S. Aigner,Bill A. Bernhardt,Mara Guastini,Johannes Hammacher,Noah Jaitner,Andreas Kofler,Leonid Lunin,Stefan Martin,Catarina Redshaw Kranich,Jakob Schattenfroh,David Schote,Yanglei Wu,Christoph Kolbitsch*

Main category: eess.IV

TL;DR: MRpro是一个基于PyTorch的开源图像重建框架，提供统一的数据结构、可组合的算子和优化算法，支持深度学习组件，适用于多种MR成像应用。

- Motivation: 开发一个可扩展、可复现的MR图像重建框架，以促进协作研究和未来MR成像技术的发展。
- Method: MRpro包含三个主要部分：统一的数据结构、可组合的算子和优化算法库，以及深度学习的核心组件。
- Result: MRpro在多种MR成像应用中展示了其多功能性，包括运动校正重建、心脏MR指纹识别等。
- Conclusion: MRpro是一个可扩展的框架，以可复现性和可维护性为核心，为未来MR成像研究提供了基础。


### [114] [Learning Arbitrary-Scale RAW Image Downscaling with Wavelet-based Recurrent Reconstruction](https://arxiv.org/abs/2507.23219)
*Yang Ren,Hai Jiang,Wei Li,Menglong Yang,Heng Zhang,Zehua Sheng,Qingsheng Ye,Shuaicheng Liu*

Main category: eess.IV

TL;DR: 提出了一种基于小波变换的RAW图像任意尺度下采样框架，结合低频和高频模块，显著提升了图像质量。

- Motivation: 现有基于学习的方法在sRGB域下采样时存在模糊和伪影问题，而RAW图像缺乏专门的下采样框架。
- Method: 采用小波变换的无损特性，设计低频任意尺度下采样模块（LASDM）和高频预测模块（HFPM），并引入能量最大化损失函数。
- Result: 实验表明，该方法在定量和视觉上均优于现有技术。
- Conclusion: 提出的框架有效解决了RAW图像下采样问题，并发布了新的数据集和代码。


### [115] [EMedNeXt: An Enhanced Brain Tumor Segmentation Framework for Sub-Saharan Africa using MedNeXt V2 with Deep Supervision](https://arxiv.org/abs/2507.23256)
*Ahmed Jaheen,Abdelrahman Elsayed,Damir Kim,Daniil Tikhonov,Matheus Scatolin,Mohor Banerjee,Qiankun Ji,Mostafa Salem,Hu Wang,Sarim Hashmi,Mohammad Yaqub*

Main category: eess.IV

TL;DR: EMedNeXt提出了一种增强的脑肿瘤分割框架，针对资源有限的撒哈拉以南非洲地区，通过改进的架构和模型集成系统实现了高精度分割。

- Motivation: 解决MRI手动分割在资源有限地区的耗时、依赖专家和图像质量差的问题。
- Method: 基于MedNeXt V2，引入更大的感兴趣区域、改进的nnU-Net v2架构和模型集成系统。
- Result: 在隐藏验证集上，平均LesionWise DSC为0.897，NSD为0.541（0.5 mm）和0.84（1.0 mm）。
- Conclusion: EMedNeXt在资源有限地区表现出色，为脑肿瘤分割提供了高效解决方案。


### [116] [Pixel Embedding Method for Tubular Neurite Segmentation](https://arxiv.org/abs/2507.23359)
*Huayu Fu,Jiamin Li,Haozhi Qu,Xiaolin Hu,Zengcai Guo*

Main category: eess.IV

TL;DR: 提出了一种改进的神经元拓扑分割框架，通过深度学习网络和端到端流程，显著降低了神经元重建的错误率。

- Motivation: 神经元拓扑的自动分割对大规模神经影像数据处理至关重要，但复杂的神经元分支形态和纤维遮挡问题给深度学习分割带来了挑战。
- Method: 1. 设计了一个输出像素级嵌入向量的深度网络及对应的损失函数；2. 开发了端到端流程，将原始图像直接映射为SWC格式的神经元结构树；3. 提出了一种新的拓扑评估指标。
- Result: 在fMOST成像数据集上的实验表明，该方法显著降低了神经元拓扑重建的错误率。
- Conclusion: 提出的框架在神经元拓扑分割和重建方面表现出色，优于传统方法。


### [117] [Smart Video Capsule Endoscopy: Raw Image-Based Localization for Enhanced GI Tract Investigation](https://arxiv.org/abs/2507.23398)
*Oliver Bause,Julia Werner,Paul Palomero Bernardo,Oliver Bringmann*

Main category: eess.IV

TL;DR: 提出了一种针对低功耗传感器边缘设备的轻量级CNN模型，直接在Bayer图像上分类，节省89.9%的能耗。

- Motivation: 传统深度神经网络在资源受限的边缘设备上运行困难，且Bayer图像转换为RGB消耗额外能量。
- Method: 使用仅63,000参数的CNN结合Viterbi解码，直接在Bayer图像上分类，并通过定制SoC实现低功耗加速。
- Result: 分类准确率达93.06%，每图像能耗仅5.31μJ，能耗节省89.9%。
- Conclusion: 该方法显著提升了视频胶囊内窥镜的能效，适用于资源受限的边缘设备。


### [118] [JPEG Processing Neural Operator for Backward-Compatible Coding](https://arxiv.org/abs/2507.23521)
*Woo Kyoung Han,Yongjun Lee,Byeonghun Lee,Sang Hyun Park,Sunghoon Im,Kyong Hwan Jin*

Main category: eess.IV

TL;DR: JPNeO是一种基于神经网络的JPEG算法，保持与现有JPEG格式的完全兼容性，同时提升色度分量保留和重建质量。

- Motivation: 尽管学习型有损压缩算法已取得显著进展，但标准化编解码器仍是一个关键挑战。JPNeO旨在解决这一问题，同时提升性能。
- Method: 在编码和解码阶段引入神经算子，优化色度分量保留和重建保真度，同时减少内存使用和参数数量。
- Result: JPNeO在保持协议不变的情况下，实现了高性能的图像压缩，并通过实验验证了高互信息空间的存在。
- Conclusion: JPNeO是一种即插即用的高性能图像压缩解决方案，无需修改源编码协议。


### [119] [Towards Field-Ready AI-based Malaria Diagnosis: A Continual Learning Approach](https://arxiv.org/abs/2507.23648)
*Louise Guillon,Soheib Biga,Yendoube E. Kantchire,Mouhamadou Lamine Sane,Grégoire Pasquier,Kossi Yakpa,Stéphane E. Sossou,Marc Thellier,Laurent Bonnardot,Laurence Lachaud,Renaud Piarroux,Ameyo M. Dorkenoo*

Main category: eess.IV

TL;DR: 论文探讨了持续学习（CL）如何提升疟疾计算机辅助诊断（CAD）模型的鲁棒性，以应对不同采集地点的域偏移问题。

- Motivation: 疟疾诊断在资源匮乏地区面临挑战，现有CAD模型泛化能力不足，亟需解决方案。
- Method: 采用持续学习策略，包括两种基于复述和两种基于正则化的方法，评估其在多站点临床数据集上的表现。
- Result: 持续学习，尤其是基于复述的方法，显著提升了模型性能。
- Conclusion: 持续学习有望推动可部署的疟疾CAD工具开发。


### [120] [Topology Optimization in Medical Image Segmentation with Fast Euler Characteristic](https://arxiv.org/abs/2507.23763)
*Liu Li,Qiang Ma,Cheng Ouyang,Johannes C. Paetzold,Daniel Rueckert,Bernhard Kainz*

Main category: eess.IV

TL;DR: 提出了一种基于欧拉特性的快速拓扑感知分割方法，显著提升拓扑正确性。

- Motivation: 现有基于持久同调的方法计算复杂度高，难以应用于高维数据，而拓扑正确性在医学图像分割中至关重要。
- Method: 提出快速欧拉特性计算，生成拓扑违规图，并通过拓扑感知校正网络优化分割结果。
- Result: 实验表明，该方法在2D和3D数据集上显著提升拓扑正确性，同时保持像素级分割精度。
- Conclusion: 该方法为拓扑感知分割提供了一种高效且实用的解决方案。
## cs.CL

### [121] [EH-Benchmark Ophthalmic Hallucination Benchmark and Agent-Driven Top-Down Traceable Reasoning Workflow](https://arxiv.org/abs/2507.22929)
*Xiaoyu Pan,Yang Bai,Ke Zou,Yang Zhou,Jun Zhou,Huazhu Fu,Yih-Chung Tham,Yong Liu*

Main category: cs.CL

TL;DR: EH-Benchmark是一个新的眼科基准测试，用于评估医学大语言模型（MLLMs）中的幻觉问题，并提出一个三阶段框架来缓解这些问题。

- Motivation: MLLMs在眼科诊断中存在幻觉问题，限制了其准确性，现有基准测试无法有效评估或解决这些问题。
- Method: 将幻觉分为视觉理解和逻辑组合两类，并提出一个三阶段框架（知识检索、任务案例研究、结果验证）来缓解幻觉。
- Result: 实验表明，该框架显著减少了幻觉，提高了准确性、可解释性和可靠性。
- Conclusion: EH-Benchmark为MLLMs在眼科诊断中的幻觉问题提供了有效的评估和解决方案。


### [122] [MPCC: A Novel Benchmark for Multimodal Planning with Complex Constraints in Multimodal Large Language Models](https://arxiv.org/abs/2507.23382)
*Yiyan Ji,Haoran Chen,Qiguang Chen,Chengyue Wu,Libo Qin,Wanxiang Che*

Main category: cs.CL

TL;DR: 论文提出了MPCC基准，首次系统评估多模态大语言模型（MLLMs）在多模态约束规划中的能力，发现现有模型表现不佳。

- Motivation: 当前基准无法直接评估多模态现实世界规划能力，且缺乏跨模态约束。
- Method: 引入MPCC基准，包含三个现实任务（飞行、日历、会议规划）和复杂约束（预算、时间、空间），分难度级别。
- Result: 实验显示，闭源模型仅21.3%可行计划，开源模型低于11%，且模型对约束复杂度敏感。
- Conclusion: MPCC为多模态约束规划提供严格评估框架，凸显约束感知推理的改进需求。
## cs.GR

### [123] [Noise-Coded Illumination for Forensic and Photometric Video Analysis](https://arxiv.org/abs/2507.23002)
*Peter F. Michael,Zekun Hao,Serge Belongie,Abe Davis*

Main category: cs.GR

TL;DR: 论文提出了一种通过编码光照噪声调制的方法，为视频添加时间水印，以对抗虚假视频的传播，创造信息不对称优势。

- Motivation: 随着视频操纵技术的普及，虚假视频越来越难以辨别，操纵者拥有与真实视频相同的分布优势。本文旨在通过技术手段创造信息不对称，使验证方占据优势。
- Method: 通过在场景光照中编码细微的噪声调制，为视频添加时间水印。水印并非特定信息，而是未操纵场景在编码光照下的图像。
- Result: 即使对手知道该技术存在，创建虚假视频仍需解决更复杂的对抗性问题，且处于信息劣势。
- Conclusion: 该方法为高风险场景（如公共活动和采访）提供了一种有前景的保护手段，尤其是在光照可控但摄像机不可控的情况下。


### [124] [XSpecMesh: Quality-Preserving Auto-Regressive Mesh Generation Acceleration via Multi-Head Speculative Decoding](https://arxiv.org/abs/2507.23777)
*Dian Chen,Yansong Qu,Xinyang Li,Ming Li,Shengchuan Zhang*

Main category: cs.GR

TL;DR: XSpecMesh是一种用于加速自回归网格生成模型的方法，通过并行预测多个令牌和验证策略，实现了1.7倍的加速且不损失生成质量。

- Motivation: 当前自回归模型在生成高质量网格时需要大量令牌预测，导致延迟高，亟需加速方法。
- Method: 采用轻量级多头推测解码方案并行预测令牌，结合验证与重采样策略，并通过蒸馏训练解码头。
- Result: 实验表明，XSpecMesh实现了1.7倍的加速，且生成质量未下降。
- Conclusion: XSpecMesh是一种高效且质量保持的加速方法，适用于自回归网格生成模型。
## cs.AI

### [125] [Causal Identification of Sufficient, Contrastive and Complete Feature Sets in Image Classification](https://arxiv.org/abs/2507.23497)
*David A Kelly,Hana Chockler*

Main category: cs.AI

TL;DR: 论文提出因果解释方法，适用于图像分类器，兼具形式严谨性和黑盒算法适用性，并引入对比性和置信度感知的完整因果解释。

- Motivation: 现有图像分类器解释方法缺乏形式严谨性，而逻辑解释虽严谨但假设严格，不适用于图像分类器。
- Method: 提出因果解释方法，证明其形式属性，引入对比性因果解释和完整因果解释（含置信度感知）。
- Result: 实验显示不同模型在充分性、对比性和完整性上表现不同，算法高效且完全黑盒。
- Conclusion: 因果解释兼具形式严谨性和实用性，适用于图像分类器。
