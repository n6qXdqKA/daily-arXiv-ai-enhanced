[[toc]]

## cs.CV

### [1] [Text-Driven 3D Hand Motion Generation from Sign Language Data](https://arxiv.org/abs/2508.15902)
*Léore Bensabath,Mathis Petrovich,Gül Varol*

Main category: cs.CV

TL;DR: 基于大规模手语视频数据集和LLM自动生成文本-3D手势运动对，训练了文本条件下的手势运动生成模型HandMDM，在多个领域都表现出良好的演示效果。

- Motivation: 训练能够根据自然语言描述生成3D手势运动的生成模型，解决手势运动生成任务中的数据缺乏问题。
- Method: 利用大规模手语视频数据集和噪声伪注释，通过LLM翻译成手势运动描述，构建文本-3D手势运动对，训练文本条件的手势运动模型HandMDM。
- Result: 模型在多个领域都表现良好，包括未见过的手语类别、不同手语言以及非手语手势运动，展示了较强的演示能力。
- Conclusion: 通过自动化数据构建方法和模型训练，成功开发了能够根据文本描述生成3D手势运动的模型，为该领域的未来研究提供了基础。


### [2] [VT-LVLM-AR: A Video-Temporal Large Vision-Language Model Adapter for Fine-Grained Action Recognition in Long-Term Videos](https://arxiv.org/abs/2508.15903)
*Kaining Li,Shuwei He,Zihan Xu*

Main category: cs.CV

TL;DR: VT-LVLM-AR框架通过视频到事件映射器和LVLM推理模块，在长视频动作识别中实现SOTA性能，准确率达94.1%

- Motivation: 解决传统深度学习模型在长视频动作识别中的计算开销大、难以捕捉长程时序依赖和语义理解有限的问题，探索LVLM在连续视频流细粒度动作识别中的应用
- Method: 提出VT-LVLM-AR框架，包含Video-to-Event Mapper（轻量时空特征提取、自适应时序池化、概念量化）和基于LLaVA-1.5的Action Reasoning模块，使用P-Tuning v2进行参数高效适配
- Result: 在NTU RGB+D和NTU RGB+D 120数据集上达到SOTA性能，NTU RGB+D X-Sub准确率94.1%，消融实验验证各组件贡献，人类评估证明视觉事件表示的可解释性
- Conclusion: 通过有效的视频到语言转换和高效模型适配，展示了LVLM在鲁棒可解释视频动作理解方面的巨大潜力


### [3] [Boosting Pathology Foundation Models via Few-shot Prompt-tuning for Rare Cancer Subtyping](https://arxiv.org/abs/2508.15904)
*Dexuan He,Xiao Zhou,Wenbin Guan,Liyuan Zhang,Xiaoman Zhang,Sinuo Xu,Ge Wang,Lifeng Wang,Xiaojun Yuan,Xin Sun,Yanfeng Wang,Kun Sun,Ya Zhang,Weidi Xie*

Main category: cs.CV

TL;DR: PathPT是一个新颖的病理学视觉语言框架，通过空间感知视觉聚合和任务特定提示调优，显著提升罕见癌症亚型分类准确性和癌变区域定位能力。

- Motivation: 罕见癌症占所有恶性肿瘤的20-25%，但在儿科肿瘤中占比超过70%。现有方法主要依赖视觉特征，忽略了跨模态知识，且在罕见癌症诊断中的临床性能有限。
- Method: 提出PathPT框架，利用视觉语言基础模型的零样本能力，将WSI级监督转换为细粒度tile级指导，通过空间感知视觉聚合和病理学语义对齐的提示实现跨模态推理。
- Result: 在8个罕见癌症数据集（56种亚型，2910个WSI）和3个常见癌症数据集上测试，PathPT在少样本设置下始终优于现有方法，显著提升亚型分类准确性和癌变区域定位能力。
- Conclusion: PathPT为罕见癌症的AI辅助诊断提供了可扩展解决方案，在专家资源有限的环境中有效提高亚型分类准确性。


### [4] [Semantic-Aware Ship Detection with Vision-Language Integration](https://arxiv.org/abs/2508.15930)
*Jiahao Li,Jiancheng Pan,Yuze Sun,Xiaomeng Huang*

Main category: cs.CV

TL;DR: 提出了一种结合视觉语言模型和多尺度自适应滑动窗口策略的新型船舶检测框架ShipSem-VL，用于语义感知船舶检测，在复杂场景中表现优异

- Motivation: 现有船舶检测方法难以捕获细粒度语义信息，在复杂场景中效果有限，需要新的解决方案来提升检测性能
- Method: 结合视觉语言模型(VLMs)和多尺度自适应滑动窗口策略，构建专门的ShipSem-VL视觉语言数据集来捕获细粒度船舶属性
- Result: 通过三个明确定义的任务评估框架性能，从多个角度证明了其在语义感知船舶检测方面的有效性
- Conclusion: 该框架能够有效推进语义感知船舶检测技术的发展，在复杂遥感图像场景中具有显著优势


### [5] [Automatic Retrieval of Specific Cows from Unlabeled Videos](https://arxiv.org/abs/2508.15945)
*Jiawen Lyu,Manu Ramesh,Madison Simonds,Jacquelyn P. Boerman,Amy R. Reibman*

Main category: cs.CV

TL;DR: 开发了一个无需深度学习的自动化奶牛识别系统，包含自动分类器、奶牛识别器和查找器，能够在无标签视频中准确识别奶牛个体

- Motivation: 目前公开文献中很少有能够实现免提奶牛分类和识别的自动化视频系统，需要开发一个有效的系统来识别奶牛群中的个体
- Method: 系统由三部分组成：AutoCattloger（使用单个输入视频片段构建奶牛目录）、eidetic奶牛识别器（不使用深度学习技术）、CowFinder（在连续视频流中识别奶牛）
- Result: 系统成功在挤奶厅等候区的无约束行走奶牛的无标签、未分割视频中找到了个体奶牛
- Conclusion: 该系统展示了在真实农场环境中自动化奶牛识别的实用价值，为奶牛管理提供了有效的技术解决方案


### [6] [Investigating Different Geo Priors for Image Classification](https://arxiv.org/abs/2508.15946)
*Angela Zhu,Christian Lange,Max Hamilton*

Main category: cs.CV

TL;DR: 本研究评估了多种空间隐式神经表示(SINR)模型作为地理先验在iNaturalist物种视觉分类中的应用效果，分析了不同模型配置和处理未训练物种预测的方法对分类性能的影响。

- Motivation: 物种分布模型能够编码物种出现的空间模式，当位置信息可用时，这些模型可以作为视觉物种分类的有效先验知识，提高分类准确性。
- Method: 使用多种SINR模型作为地理先验，评估其在iNaturalist观测数据视觉物种分类中的表现，探索不同模型配置和处理未训练物种预测的方法。
- Result: 分析揭示了影响这些模型作为地理先验有效性的关键因素，这些因素可能与制作准确分布图时的考虑因素有所不同。
- Conclusion: SINR模型可以作为有效的物种视觉分类地理先验，但需要针对分类任务优化模型配置和处理策略，与单纯制作分布图的需求存在差异。


### [7] [Representation Learning with Adaptive Superpixel Coding](https://arxiv.org/abs/2508.15959)
*Mahmoud Khalil,Ahmad Khalil,Alioune Ngom*

Main category: cs.CV

TL;DR: 基于变换器的自监督模型ASC，通过适应性超像素层动态调整图像分割，充分利用图像内容特征，在标准图像下游任务上超过传统方法

- Motivation: 克服传统视觉模型对特定模态和固定网格结构的依赖，解决Vision Transformers中固定大小和非适应性补丁分割的限制
- Method: 提出适应性超像素编码(ASC)模型，使用变换器构建自监督学习框架，通过适应性超像素层动态调整图像分割以适应基础图像内容
- Result: 在标准图像下游任务平台上表现超过广泛使用的其他方法
- Conclusion: ASC模型通过适应性分割机制有效克服了传统视觉模型的限制，为视觉表征学习提供了更灵活和高效的方案


### [8] [Glo-VLMs: Leveraging Vision-Language Models for Fine-Grained Diseased Glomerulus Classification](https://arxiv.org/abs/2508.15960)
*Zhenhao Guo,Rachit Saluja,Tianyuan Yao,Quan Liu,Yuankai Huo,Benjamin Liechty,David J. Pisapia,Kenji Ikemura,Mert R. Sabuncu,Yihe Yang,Ruining Deng*

Main category: cs.CV

TL;DR: 本文提出了Glo-VLMs框架，通过结合病理图像和临床文本提示，在少样本学习场景下有效适配视觉语言模型进行肾小球亚型的细粒度分类。

- Motivation: 视觉语言模型在数字病理学中潜力巨大，但在区分肾小球亚型等细粒度疾病分类任务中效果有限，主要由于亚型间形态学差异细微且视觉模式与临床术语对齐困难。
- Method: 开发了Glo-VLMs系统框架，利用精选病理图像和临床文本提示进行联合图像-文本表示学习，评估不同VLM架构和适配策略在少样本学习范式下的表现。
- Result: 在每类仅8个样本的情况下，微调后的VLM达到了0.7416准确率、0.9045宏AUC和0.5277 F1分数，证明基础模型在有限监督下也能有效适配细粒度医学图像分类。
- Conclusion: 即使监督信息极其有限，大型预训练模型也能通过有效适配策略在专业临床研究应用中展现巨大潜力，为细粒度医学图像分类提供了实用解决方案。


### [9] [Contributions to Label-Efficient Learning in Computer Vision and Remote Sensing](https://arxiv.org/abs/2508.15973)
*Minh-Tan Pham*

Main category: cs.CV

TL;DR: 该论文总结了在计算机视觉和遥感领域中标签高效学习的一系列贡献，主要关注从有限标注数据中学习并利用大量未标注数据的方法开发，特别针对地球观测数据的多模态、空间分辨率变化和场景异质性等挑战。

- Motivation: 解决现实应用中标注数据稀缺的问题，开发能够从有限标注和大量未标注数据中有效学习的方法，特别针对遥感数据特有的挑战。
- Method: 提出了四种主要方法：1）基于异常感知表示的弱监督学习；2）多任务学习联合训练多个数据集；3）多模态数据的自监督和监督对比学习；4）显式和隐式建模类别层次的少样本学习。
- Result: 在自然和遥感数据集上进行了广泛实验，验证了所提出方法的有效性，反映了多个合作研究项目的成果。
- Conclusion: 论文总结了标签高效学习的重要贡献，并展望了未来研究方向，重点关注在实际应用中扩展和增强标签高效学习方法。


### [10] [Panoptic Segmentation of Environmental UAV Images : Litter Beach](https://arxiv.org/abs/2508.15985)
*Ousmane Youme,Jean Marie Dembélé,Eugene C. Ezin,Christophe Cambier*

Main category: cs.CV

TL;DR: 使用基于实例分割和全景分割的CNN方法提高海滩垃圾检测精度，解决传统CNN在复杂沙滩环境中误检问题

- Motivation: 传统CNN模型在检测海滩垃圾时容易受到沙滩颜色反射、人类足迹、阴影、藻类、沙丘等多种干扰因素的影响，导致误检率高，需要更鲁棒的检测方法
- Method: 采用基于实例分割和全景分割的CNN方法，这些方法在少量样本情况下仍能保持良好准确性
- Result: 提出的分割方法相比基础CNN模型更加鲁棒，误检率更低
- Conclusion: 基于实例分割和全景分割的CNN方法更适合复杂沙滩环境下的海洋垃圾监测任务，能够有效克服传统方法的局限性


### [11] [Automated Multi-label Classification of Eleven Retinal Diseases: A Benchmark of Modern Architectures and a Meta-Ensemble on a Large Synthetic Dataset](https://arxiv.org/abs/2508.15986)
*Jerry Cao-Xue,Tien Comlekoglu,Keyi Xue,Guanliang Wang,Jiang Li,Gordon Laurie*

Main category: cs.CV

TL;DR: 本研究使用SynFundus-1M合成数据集训练了6种深度学习架构，开发了元集成模型，在合成数据上取得了优异性能（AUC 0.9973），并在三个真实临床数据集上展现了良好的泛化能力。

- Motivation: 解决视网膜疾病分类中临床数据集稀缺的问题，利用新发布的高保真合成数据集SynFundus-1M来克服患者隐私和高成本等障碍。
- Method: 采用端到端深度学习流程，训练6种现代架构（ConvNeXtV2、SwinV2、ViT、ResNet、EfficientNetV2和RETFound基础模型），使用5折多标签分层交叉验证策略，并开发了基于XGBoost分类器的元集成模型。
- Result: 集成模型在内部验证集上达到宏平均AUC 0.9973，在三个真实临床数据集上分别达到AUC 0.7972（DR数据集）、0.9126（AIROGS青光眼数据集）和0.8800（RFMiD多标签数据集）。
- Conclusion: 这项工作为大规模合成数据集研究提供了稳健基准，证明仅使用合成数据训练的模型能够准确分类多种病理并有效泛化到真实临床图像，为加速眼科综合AI系统开发提供了可行途径。


### [12] [Diverse Signer Avatars with Manual and Non-Manual Feature Modelling for Sign Language Production](https://arxiv.org/abs/2508.15988)
*Mohamed Ilyes Lakhal,Richard Bowden*

Main category: cs.CV

TL;DR: 本文提出一种基于潜在滴涼模型(LDM)的新方法，通过简化的筛波器设计来提升语言生成的效果和效率。

- Motivation: 现有的语言生成模型存在效果和效率不高的问题，需要一种新的方法来同时提升生成质量和计算效率。
- Method: 使用潜在滴涼模型(LDM)并采用简化的筛波器设计，通过减少计算复杂度来优化生成过程。
- Result: 实验结果显示，该方法在保持生成质量的同时，显著提升了生成速度，并在多个评价指标上超过了现有的最佳方法。
- Conclusion: 该研究提供了一种高效的语言生成方法，为后续研究基于滴涼模型的语言处理应用开阔了新的途径。


### [13] [DRespNeT: A UAV Dataset and YOLOv8-DRN Model for Aerial Instance Segmentation of Building Access Points for Post-Earthquake Search-and-Rescue Missions](https://arxiv.org/abs/2508.16016)
*Aykut Sirma,Angelos Plastropoulos,Argyrios Zolotas,Gilbert Tang*

Main category: cs.CV

TL;DR: 提出了DRespNeT高分辨率数据集，用于地震后结构环境的空中实例分割，包含28个关键类别，支持实时SAR操作。优化的YOLOv8-DRN模型达到92.7% mAP50和27 FPS性能。

- Motivation: 现有数据集主要依赖卫星影像或粗粒度语义标注，无法满足地震后搜救行动中对可进入点和结构障碍物及时识别的需求。
- Method: 开发DRespNeT数据集，包含高清(1080p)空中影像的详细多边形实例分割标注，涵盖28个操作关键类别。使用YOLO-based实例分割模型进行性能评估。
- Result: 优化的YOLOv8-DRN模型在RTX-4090 GPU上达到92.7% mAP50和27 FPS的推理速度，满足实时操作需求。
- Conclusion: DRespNeT数据集和模型为SAR团队和机器人系统提供支持，增强人机协作，优化应急响应，改善幸存者救援结果。


### [14] [NeuralMeshing: Complete Object Mesh Extraction from Casual Captures](https://arxiv.org/abs/2508.16026)
*Floris Erich,Naoya Chiba,Abdullah Mustafa,Ryo Hanai,Noriaki Ando,Yusuke Yoshiyasu,Yukiyasu Domae*

Main category: cs.CV

TL;DR: 提出了一种从多个视频自动生成物体完整几何模型的系统，使用结构光运动技术和标记点实现自动化建模

- Motivation: 解决日常生活中无法使用商业3D扫描仪时，如何获取物体完整几何模型的问题
- Method: 使用两个或多个视频，通过结构光运动技术自动定位帧，利用标记点（如棋盘格或AR标记）作为已知参考点，合并多个视频结果生成完整网格
- Result: 开发了自动化系统，能够生成完整物体网格而无需依赖孔洞填充，代码已开源
- Conclusion: 该系统提供了一种实用的非商业扫描仪替代方案，能够从日常视频中重建完整3D几何模型


### [15] [CoVeRaP: Cooperative Vehicular Perception through mmWave FMCW Radars](https://arxiv.org/abs/2508.16030)
*Jinyue Song,Hansol Ku,Jayneel Vora,Nelson Lee,Ahmad Kamari,Prasant Mohapatra,Parth Pathak*

Main category: cs.CV

TL;DR: CoVeRaP是一个多车协作雷达数据集和感知框架，通过雷达、相机、GPS数据融合，显著提升3D目标检测性能，特别是在恶劣天气条件下。

- Motivation: 汽车FMCW雷达在雨雪和强光条件下可靠，但稀疏嘈杂的点云限制了3D目标检测性能，需要多车协作来提升感知能力。
- Method: 提出统一的多车协作感知框架，包含中融合和晚融合选项。使用多分支PointNet式编码器增强自注意力机制，融合空间、多普勒和强度信息到共同潜在空间，解码器生成3D边界框和深度置信度。
- Result: 实验显示，中融合配合强度编码在IoU 0.9时将平均精度提升高达9倍，始终优于单车基线方法。
- Conclusion: CoVeRaP建立了首个可复现的多车FMCW雷达感知基准，证明经济实惠的雷达共享能显著提升检测鲁棒性，数据集和代码已公开以促进进一步研究。


### [16] [Wavelet-Enhanced PaDiM for Industrial Anomaly Detection](https://arxiv.org/abs/2508.16034)
*Cory Gardner,Byungseok Min,Tae-Hyuk Ahn*

Main category: cs.CV

TL;DR: WE-PaDiM通过将离散小波变换与CNN特征结合，替代PaDiM中的随机通道选择，在MVTec AD数据集上实现了99.32%的图像级AUC和92.10%的像素级AUC。

- Motivation: PaDiM方法通过随机通道选择降低特征维度，可能会丢失结构化信息。需要一种更原则性的特征选择方法来提升工业图像异常检测性能。
- Method: 对多层级CNN特征图应用2D离散小波变换，选择特定频率子带（如LL、LH、HL），空间对齐后通道级联，再用PaDiM的多变量高斯框架建模。
- Result: 在MVTec AD数据集上，使用ResNet-18和EfficientNet B0-B6骨干网络，平均达到99.32% Image-AUC和92.10% Pixel-AUC。小波选择影响性能权衡：简单小波（如Haar）配合细节子带提升定位性能，近似子带提升图像级检测。
- Conclusion: WE-PaDiM为PaDiM中的随机特征选择提供了竞争性强且可解释的替代方案，在保持相当效率的同时实现了适用于工业检测的鲁棒结果。


### [17] [Expandable Residual Approximation for Knowledge Distillation](https://arxiv.org/abs/2508.16050)
*Zhaoyi Yan,Binghui Chen,Yunfan Liu,Qixiang Ye*

Main category: cs.CV

TL;DR: 提出Expandable Residual Approximation (ERA)方法，通过多分支残差网络分解残差知识，结合教师权重集成策略，显著提升知识蒸馏效果

- Motivation: 传统知识蒸馏中教师模型与学生模型之间的学习能力差距阻碍了知识充分传递，需要解决这一挑战
- Method: 基于Stone-Weierstrass定理的渐进逼近原理，使用多分支残差网络(MBRNet)实现残差知识分解，并引入教师权重集成(TWI)策略
- Result: 在ImageNet分类任务上Top-1准确率提升1.41%，在MS COCO目标检测任务上AP提升1.40，在计算机视觉任务中达到领先性能
- Conclusion: ERA方法通过分解残差知识和重用教师权重，有效缓解了师生模型能力差距问题，显著提升了知识蒸馏效果


### [18] [Advances and Trends in the 3D Reconstruction of the Shape and Motion of Animals](https://arxiv.org/abs/2508.16062)
*Ziqi Li,Abderraouf Amrani,Shri Rai,Hamid Laga*

Main category: cs.CV

TL;DR: 这篇论文综述了基于深度学习的动物3D重建技术，分析了从RGB图像/视频非侵入式重建动物形状和运动的最新方法，并对现有技术进行了分类和性能分析。

- Motivation: 传统3D扫描方法对动物重建存在侵入性、成本高、难以在自然环境中部署等问题，需要开发非侵入式的深度学习方法来重建动物的3D几何形状和运动。
- Method: 论文采用文献综述方法，对现有技术按输入模态、3D几何表示方式、重建技术类型和训练机制进行分类分析，并评估关键方法的性能。
- Result: 系统梳理了该领域的最新进展，分析了不同方法的优缺点，发现基于深度学习的方法能够有效实现非侵入式的动物3D重建，但仍存在一些技术挑战。
- Conclusion: 该领域具有广阔的应用前景，但仍需解决当前的技术挑战，未来研究应关注提高重建精度、处理复杂场景和开发更高效的训练方法。


### [19] [A Unified Voxel Diffusion Module for Point Cloud 3D Object Detection](https://arxiv.org/abs/2508.16069)
*Qifeng Liu,Dawei Zhao,Yabo Dong,Linzhi Shang,Liang Xiao,Juan Wang,Kunkong Zhao,Dongming Lu,Qi Zhu*

Main category: cs.CV

TL;DR: 提出了一种新颖的体素扩散模块（VDM），通过稀疏3D卷积和子流形稀疏卷积增强点云体素级表示和扩散能力，显著提升了基于Transformer和SSM的点云目标检测性能。

- Motivation: 现有的基于Transformer和状态空间模型的点云目标检测方法由于体素表示的串行处理特性，限制了空间扩散能力，影响了检测精度。受CNN架构启发，需要增强体素级表示和扩散能力。
- Method: 设计了VDM模块，包含稀疏3D卷积、子流形稀疏卷积和残差连接。通过将特征图下采样至原始分辨率的1/4来保证计算效率，实现前景体素特征扩散和细粒度空间信息聚合。
- Result: 在多个基准数据集上验证，VDM-SSMs在Waymo达到74.7 mAPH(L2)，nuScenes达到72.9 NDS，Argoverse 2达到42.3 mAP，ONCE达到67.6 mAP，在所有数据集上都创造了新的state-of-the-art性能。
- Conclusion: VDM模块能够有效增强体素级特征表示和空间扩散能力，可无缝集成到主流Transformer或SSM检测模型中，具有很好的通用性和检测精度提升效果。


### [20] [Ensemble learning of foundation models for precision oncology](https://arxiv.org/abs/2508.16085)
*Xiangde Luo,Xiyue Wang,Feyisope Eweje,Xiaoming Zhang,Sen Yang,Ryan Quinton,Jinxi Xiang,Yuchen Li,Yuanfeng Ji,Zhe Li,Yijiang Chen,Colin Bergstrom,Ted Kim,Francesca Maria Olguin,Kelley Yuan,Matthew Abikenari,Andrew Heider,Sierra Willens,Sanjeeth Rajaram,Robert West,Joel Neal,Maximilian Diehn,Ruijiang Li*

Main category: cs.CV

TL;DR: ELF是一个集成学习框架，整合了5个最先进的病理学基础模型，在53,699张全切片图像上训练，在多种临床应用中表现出优越性能。

- Motivation: 现有的病理学基础模型在不同数据集上使用不同策略训练，导致性能不一致和泛化能力有限，需要统一的解决方案。
- Method: 采用集成学习方法整合五个先进病理基础模型，生成统一的切片级表示，在20个解剖部位的53,699张WSI上进行训练。
- Result: ELF在疾病分类、生物标志物检测和抗癌治疗反应预测等临床应用中，始终优于所有组成的基础模型和现有切片级模型。
- Conclusion: 集成学习对病理学基础模型具有强大作用，ELF可作为推进AI辅助精准肿瘤学的可扩展和通用化解决方案。


### [21] [Two-flow Feedback Multi-scale Progressive Generative Adversarial Network](https://arxiv.org/abs/2508.16089)
*Sun Weikai,Song Shijie,Chi Wenjie*

Main category: cs.CV

TL;DR: 本文提出了一种新的两流反馈多尺度渐进生成对抗网络(MSPG-SEN)，通过四项核心技术改进GAN模型的图像质量、训练稳定性和计算效率，在多个数据集上达到了最先进水平。

- Motivation: 虽然双向模型在图像生成领域取得了进步，但GAN因其独特优势仍有很大发展空间。本文旨在继承GAN优点的基础上，提高图像质量和人类视觉感知，同时简化训练过程和降低训练成本。
- Method: 1) 两流反馈多尺度渐进GAN网络(MSPG-SEN)
2) 自适应感知-行为反馈循环(APFL)
3) 全局连接两流动态殊徙网络
4) 动态嵌入式注意力机制(DEMA)
- Result: 在5个数据集上达到状态前沿生成结果：INKK 89.7%、AWUN 78.3%、IONJ 85.5%、POKL 88.7%、OPIN 96.4%。APFL提高了模型稳定性和健壮性，DEMA仅需最88.7%计算资源但具有强大的跨任务能力。
- Conclusion: MSPG-SEN模型在保留GAN优势的同时，显著提升了图像生成质量和训练效率，通过四项核心技术实现了计算成本的降低和模型性能的全面提升，为GAN模型的发展提供了新的方向。


### [22] [Domain Adaptation via Feature Refinement](https://arxiv.org/abs/2508.16124)
*Savvas Karatsiolis,Andreas Kamilaris*

Main category: cs.CV

TL;DR: DAFR2是一个简单有效的无监督域自适应框架，通过批归一化统计适应、特征蒸馏和假设迁移三个关键组件的协同作用，在分布偏移下实现跨域泛化，无需目标标签、复杂架构或复杂训练目标。

- Motivation: 解决无监督域自适应中分布偏移问题，旨在创建对输入扰动鲁棒且域不变的特征空间，使模型能够在没有目标域标签的情况下泛化到相似域。
- Method: 结合三个关键组件：1) 使用未标记目标数据适应批归一化统计；2) 从源训练模型进行特征蒸馏；3) 假设迁移。通过在统计和表示层面对齐特征分布来实现域适应。
- Result: 在CIFAR10-C、CIFAR100-C、MNIST-C和PatchCamelyon-C等基准数据集上的广泛实验表明，该方法在抗腐蚀鲁棒性方面优于先前方法。理论和实证分析显示实现了改进的特征对齐、域间互信息增加以及输入扰动敏感性降低。
- Conclusion: DAFR2提供了一个简单而有效的解决方案，通过统计和表示层面的特征分布对齐，成功实现了无监督域自适应，在多个基准数据集上表现出优越的鲁棒性和泛化能力。


### [23] [4D Virtual Imaging Platform for Dynamic Joint Assessment via Uni-Plane X-ray and 2D-3D Registration](https://arxiv.org/abs/2508.16138)
*Hao Tang,Rongxi Yi,Lei Li,Kaiyi Cao,Jiapeng Zhao,Yihan Xiao,Minghai Shi,Peng Yuan,Yan Xi,Hui Tang,Wei Li,Zhan Wu,Yixin Zhou*

Main category: cs.CV

TL;DR: 一种新的4D关节分析平台，结合双机器臂CBCT系统和深度学习融合技术，实现低放射动态关节成像，在模拟中达到次像素精度，临床应用中能准确量化膝关手术后的股骨运动。

- Motivation: 传统CT无法捕获动态负重关节运动，而现有4D成像技术又存在放射过高或空间信息不完整的问题，需要一种新的低放射动态关节分析方案。
- Method: 提出一种集成4D关节分析平台，包括：(1)双机器臂CBCT系统优化立位扫描；(2)融合静态3D CBCT与动态2D X光的深度学习预处理、3D-2D投影和迭代优化管道；(3)经临床验证的定量动力学评估框架。
- Result: 在模拟研究中达到次像素精度(0.235 mm)，6210功玉99.18%，超过传统和最先进的注册方法。临床评估证明能准确量化膝关手术后患者的肾平台运动和内外侧变异。
- Conclusion: 这4D CBCT平台能够实现快速、准确和低放射的动态关节成像，为生物力学研究、精准诊断和个性化齐多科治疗提供新机会。


### [24] [High-Precision Mixed Feature Fusion Network Using Hypergraph Computation for Cervical Abnormal Cell Detection](https://arxiv.org/abs/2508.16140)
*Jincheng Li,Danyang Dong,Menglin Zheng,Jingbo Zhang,Yueqin Hang,Lichi Zhang,Lili Zhao*

Main category: cs.CV

TL;DR: 提出基于超图的宫颈细胞检测网络，融合空间相关特征和深度判别特征，显著提升异常细胞检测性能

- Motivation: 现有算法无法有效建模视觉特征相关性，且缺乏细胞间相关特征与细胞内判别特征的融合策略
- Method: 使用多级融合子网络增强特征提取能力，引入跨级特征融合策略与超图计算模块整合混合特征
- Result: 在三个公开数据集上的实验表明，该方法显著提高了宫颈异常细胞检测性能
- Conclusion: 基于超图的特征融合方法能有效提升宫颈细胞异常检测的准确性和可靠性


### [25] [Beyond Human-prompting: Adaptive Prompt Tuning with Semantic Alignment for Anomaly Detection](https://arxiv.org/abs/2508.16157)
*Pi-Wei Chen,Jerry Chun-Wei Lin,Wei-Han Chen,Jia Ji,Zih-Ching Chen,Feng-Hao Yeh,Chao-Chun Chen*

Main category: cs.CV

TL;DR: APT是一种无需先验知识的少样本异常检测框架，通过自适应提示调优和语义对齐来克服传统基于提示方法的局限性，在多个基准数据集上达到最先进性能。

- Motivation: 现有的视觉语言模型异常检测方法依赖人工设计的提示词且缺乏异常样本，导致在特定上下文异常理解方面存在显著差距。
- Method: 提出APT框架：使用噪声扰动生成的自异常样本来训练可学习提示词；引入自优化元提示引导方案(SMGS)迭代对齐提示词与通用异常语义，防止对合成噪声的过拟合。
- Result: 系统不仅推进了像素级异常检测，还在多个基准数据集上实现了最先进的性能，无需先验知识进行提示词设计。
- Conclusion: APT为现实世界异常检测提供了一个强大且通用的解决方案，克服了传统提示方法的局限性。


### [26] [RAGSR: Regional Attention Guided Diffusion for Image Super-Resolution](https://arxiv.org/abs/2508.16158)
*Haodong He,Yancheng Bai,Rui Lan,Xu Duan,Lei Sun,Xiangxiang Chu,Gui-Song Xia*

Main category: cs.CV

TL;DR: 通过区域注意力机制提升多对象场景下的超分辨率性能，解决了现有方法在细粒度区域细节生成上的不足

- Motivation: 现有的视觉-语言模型结合文本到图像模型的方法在多对象场景下生成清晰准确的区域细节时面临挑战，主要因为缺乏细粒度区域描述和模型对复杂提示的理解能力不足
- Method: 提出RAGSR方法，通过定位图像中的物体区域并为每个区域添加细粒度标题，形成区域-文本对作为文本前矢。采用新的区域引导注意力机制确保每个区域-文本对在注意力过程中得到适当考虑，同时阻止不相关区域间的不应有交互
- Result: 在标准数据集上的实验结果显示，该方法在生成觉知真实的视觉细节时表现出艰优的性能，同时保持了上下文一致性
- Conclusion: RAGSR方法通过区域注意力机制提供了对文本和图像信息集成的更精细控制，有效克服了传统超分辨率技术的局限性


### [27] [Through the Looking Glass: A Dual Perspective on Weakly-Supervised Few-Shot Segmentation](https://arxiv.org/abs/2508.16159)
*Jiaqi Ma,Guo-Sen Xie,Fang Zhao,Zechao Li*

Main category: cs.CV

TL;DR: 本文提出TLG模型，通过同源异质网络设计解决元学习中过度语义同质化问题，在弱监督少样本语义分割任务中仅用1/24参数就实现显著性能提升，并首次在相同骨干架构下超越全监督模型。

- Motivation: 传统元学习方法使用相同网络架构处理支持-查询对，导致过度语义同质化，限制了模型的表达能力和泛化性能。
- Method: 提出同源异质网络：1) 异构视觉聚合(HA)模块增强互补性；2) 异构传输(HT)模块减少语义噪声；3) 异构CLIP(HC)文本信息增强多模态泛化能力。
- Result: 在Pascal-5i上提升13.2%，在COCO-20i上提升9.7%，仅使用现有SOTA模型1/24的参数。首次实现弱监督模型在相同骨干架构下超越全监督模型。
- Conclusion: 异构网络设计能有效解决语义同质化问题，显著提升少样本语义分割性能，证明了弱监督方法在特定条件下的优越性。


### [28] [FTIO: Frequent Temporally Integrated Objects](https://arxiv.org/abs/2508.16183)
*Mohammad Mohammadzadeh Kalati,Farhad Maleki,Ian McQuillan*

Main category: cs.CV

TL;DR: FTIO是一个后处理框架，通过频繁时间集成对象和改进对象选择标准来解决无监督视频对象分割中的对象选择和时序一致性问题

- Motivation: 无监督视频对象分割面临初始分割不确定性、小对象和复杂结构对象识别困难，以及变形和快速运动导致的时序不一致性等挑战
- Method: 提出两个关键组件：1) 结合标准改进对象选择，提取频繁出现的显著对象；2) 三阶段方法通过集成缺失对象掩码区域来校正时序不一致性
- Result: 实验结果表明FTIO在多对象无监督视频对象分割中达到了最先进的性能
- Conclusion: FTIO框架有效解决了无监督视频对象分割中的对象选择和时序一致性问题，显著提升了分割性能


### [29] [SpecVLM: Enhancing Speculative Decoding of Video LLMs via Verifier-Guided Token Pruning](https://arxiv.org/abs/2508.16201)
*Yicheng Ji,Jun Zhang,Heming Xia,Jinpeng Chen,Lidan Shou,Gang Chen,Huan Li*

Main category: cs.CV

TL;DR: SpecVLM是一个针对视频大语言模型的训练无关推测解码框架，通过两阶段视频token剪枝实现无损加速，在多个基准测试中达到2.68倍解码加速。

- Motivation: 视频大语言模型依赖密集视频token表示，导致内存和计算开销巨大，现有token缩减方法存在信息损失问题，需要无损加速解码阶段。
- Method: 采用两阶段视频token剪枝：第一阶段基于验证器注意力信号选择高信息量token，第二阶段以空间均匀方式剪枝冗余token，利用推测解码框架实现高效推测。
- Result: 在四个视频理解基准测试中，SpecVLM实现了显著加速：LLaVA-OneVision-72B达到2.68倍加速，Qwen2.5-VL-32B达到2.11倍加速，且不损失准确性。
- Conclusion: SpecVLM通过创新的视频token剪枝策略和推测解码框架，成功解决了视频大语言模型的计算效率问题，为视频理解任务提供了高效的推理解决方案。


### [30] [\textsc{T-Mask}: Temporal Masking for Probing Foundation Models across Camera Views in Driver Monitoring](https://arxiv.org/abs/2508.16207)
*Thinesh Thiyakesan Ponbagavathi,Kunyu Peng,Alina Roitberg*

Main category: cs.CV

TL;DR: 该论文提出了一种名为T-Mask的新方法，通过时间令牌掩码技术改进基础模型在驾驶员监控中的跨视角泛化能力，在Drive&Act数据集上取得了显著性能提升。

- Motivation: 相机视角变化是驾驶员监控中的常见障碍，现有深度学习和预训练基础模型在未见视角下的鲁棒性研究不足，需要探索轻量级适应方法来解决跨视角泛化问题。
- Method: 提出了T-Mask方法，这是一种图像到视频的探测方法，利用时间令牌掩码技术并强调更动态的视频区域。比较了线性探测、高级探测策略，以及DINOv2和CLIP两种基础模型与参数高效微调(PEFT)和完全微调的对比。
- Result: T-Mask在跨视角top-1准确率上比强探测基线提高+1.23%，比PEFT方法提高+8.0%，且不增加任何参数。对于代表性不足的次要活动，在训练视角下识别率提高+5.42%，在跨视角设置下提高+1.36%。
- Conclusion: 研究表明使用T-Mask等轻量级探测方法适应基础模型在细粒度驾驶员观察中具有强大潜力，特别是在跨视角和低数据设置中。时间令牌选择对于构建鲁棒的驾驶员监控系统至关重要。


### [31] [Forecast then Calibrate: Feature Caching as ODE for Efficient Diffusion Transformers](https://arxiv.org/abs/2508.16211)
*Shikang Zheng,Liang Feng,Xinyu Wang,Qinming Zhou,Peiliang Cai,Chang Zou,Jiacheng Liu,Yuqi Lin,Junjie Chen,Yue Ma,Linfeng Zhang*

Main category: cs.CV

TL;DR: FoCa是一种基于特征ODE求解的扩散变换器加速方法，通过预测-校准策略在保持高质量的同时实现5-6倍的推理加速

- Motivation: 现有特征缓存方法在高加速比下难以保持生成质量，预测误差因长步预测的不稳定性而急剧增加
- Method: 从ODE角度建模隐藏特征序列，将特征缓存视为特征ODE求解问题，采用预测-校准策略来稳健整合历史特征
- Result: 在图像合成、视频生成和超分辨率任务上实现显著加速：FLUX 5.50倍、HunyuanVideo 6.45倍、Inf-DiT 3.17倍、DiT 4.53倍，且保持高质量
- Conclusion: FoCa方法有效解决了高加速比下的质量退化问题，无需额外训练即可实现近乎无损的推理加速


### [32] [OmniCache: A Trajectory-Oriented Global Perspective on Training-Free Cache Reuse for Diffusion Transformer Models](https://arxiv.org/abs/2508.16212)
*Huanpeng Chu,Wei Wu,Guanyu Fen,Yutao Zhang*

Main category: cs.CV

TL;DR: OmniCache是一种无需训练的扩散模型加速方法，通过利用去噪过程中的全局冗余性，在保持生成质量的同时显著加速采样过程

- Motivation: 扩散Transformer模型虽然性能强大，但计算成本高昂，采样步骤多且每步计算复杂，难以实时部署，需要高效的加速方法
- Method: 从DIT模型的采样角度出发，系统分析采样轨迹，在全局范围内策略性地分布缓存重用，并在缓存重用过程中动态估计并过滤噪声
- Result: 大量实验表明该方法能有效加速采样过程，同时保持竞争力的生成质量
- Conclusion: OmniCache为基于扩散的生成模型提供了实用且高效的部署解决方案


### [33] [MedOmni-45°: A Safety-Performance Benchmark for Reasoning-Oriented LLMs in Medicine](https://arxiv.org/abs/2508.16213)
*Kaiyuan Ji,Yijin Guo,Zicheng Zhang,Xiangyang Zhu,Yuan Tian,Ning Liu,Guangtao Zhai*

Main category: cs.CV

TL;DR: MedOmni-45 Degrees是一个医疗LLM基准测试，通过操纵性提示评估模型在准确性、推理忠实性和抗奉承性三个维度的表现，揭示安全性与性能之间的权衡关系。

- Motivation: 随着大语言模型在医疗决策支持中的广泛应用，需要评估其推理的可靠性，特别是链式思维忠实性（推理是否与回答和医学事实一致）和奉承性（是否遵循误导性线索而非正确性）。现有基准测试往往将这些漏洞简化为单一准确度分数。
- Method: 构建包含1,804个医疗问题的基准测试，涵盖6个专业和3种任务类型，每个问题配备7种操纵性提示类型和无提示基线，共产生约27K输入。评估7个LLM，使用准确性、CoT忠实性和抗奉承性三个指标组合成综合分数，并通过45度图可视化。
- Result: 结果显示所有模型都存在安全性与性能的权衡，没有模型能超越对角线。开源模型QwQ-32B表现最接近对角线（43.81度），在安全性和准确性之间取得平衡，但并非在两方面都领先。
- Conclusion: MedOmni-45 Degrees提供了一个专注于暴露医疗LLM推理漏洞的基准测试，可指导更安全的模型开发。


### [34] [PromptFlare: Prompt-Generalized Defense via Cross-Attention Decoy in Diffusion-Based Inpainting](https://arxiv.org/abs/2508.16217)
*Hohyun Na,Seunghoo Hong,Simon S. Woo*

Main category: cs.CV

TL;DR: PromptFlare是一种新颖的对抗性保护方法，通过利用交叉注意力机制和提示嵌入的内在特性，防止基于扩散修复模型的恶意图像修改。

- Motivation: 扩散模型的成功使得高质量图像修改变得容易，但同时也带来了恶意滥用的风险。现有方法主要依赖图像层面的不一致性，难以有效处理文本提示的影响。
- Method: 利用交叉注意力机制，识别并针对提示中不变且语义信息量少的共享token，注入对抗性噪声来抑制采样过程，作为交叉注意力诱饵分散模型注意力。
- Result: 在EditBench数据集上的广泛实验表明，该方法在各种指标上达到最先进性能，同时显著降低计算开销和GPU内存使用。
- Conclusion: PromptFlare为对抗未经授权的图像操作提供了一种强大而高效的保护方法。


### [35] [An Investigation of Visual Foundation Models Robustness](https://arxiv.org/abs/2508.16225)
*Sandeep Gupta,Roberto Passerone*

Main category: cs.CV

TL;DR: 本文综述了视觉基础模型在网络鲁棒性方面的研究，分析了应对动态环境变化和对抗攻击的防御机制及其挑战。

- Motivation: 随着视觉基础模型在安全敏感领域的广泛应用，如生物识别验证、自动驾驶感知和医学图像分析，网络鲁棒性对于建立技术可信度至关重要。需要研究如何使视觉系统有效适应光照、天气条件和传感器特性等动态环境因素。
- Method: 文章调查了计算机视觉系统中的网络鲁棒性要求，检视了当前主流的经验防御方法和鲁棒训练技术，包括应对分布偏移、噪声输入、空间失真和对抗攻击的策略。
- Result: 提供了对现有防御机制相关挑战的全面分析，包括网络属性和组件指导消融研究，以及评估网络鲁棒性的基准测试指标。
- Conclusion: 视觉基础模型需要更强的鲁棒性来应对现实世界中的各种挑战，当前的防御机制仍面临诸多挑战，需要进一步的研究和改进来确保在关键应用中的可靠性。


### [36] [FlexMUSE: Multimodal Unification and Semantics Enhancement Framework with Flexible interaction for Creative Writing](https://arxiv.org/abs/2508.16230)
*Jiahao Chen,Zhiyong Ma,Wenbiao Du,Qingyuan Chuai*

Main category: cs.CV

TL;DR: FlexMUSE是一个多模态创意写作框架，通过模态语义对齐门控和跨模态融合技术，实现了文本和图像模态的灵活交互与语义一致性，在ArtMUSE数据集上取得了优异表现。

- Motivation: 多模态创意写作(MMCW)是一个全新的抽象挑战，现有方法需要特定模态输入或昂贵训练，且存在模态间语义不一致问题。需要经济高效地实现灵活交互模式下的MMCW。
- Method: 提出FlexMUSE框架，包含T2I模块支持可选视觉输入；使用模态语义对齐门控(msaGate)限制文本输入；采用基于注意力的跨模态融合增强输入特征；设计模态语义创意直接偏好优化(mscDPO)扩展拒绝样本以促进创作创意。
- Result: FlexMUSE在包含约3k校准文本-图像对的ArtMUSE数据集上取得了有希望的结果，展示了其一致性、创造性和连贯性。
- Conclusion: FlexMUSE通过创新的模态对齐和融合技术，成功解决了多模态创意写作中的语义一致性和创造性挑战，为MMCW任务提供了有效的解决方案。


### [37] [UniEM-3M: A Universal Electron Micrograph Dataset for Microstructural Segmentation and Generation](https://arxiv.org/abs/2508.16239)
*Nan wang,Zhiyi Xia,Yiming Li,Shi Tang,Zuxin Fan,Xi Fang,Haoyi Tao,Xiaochen Cai,Guolin Ke,Linfeng Zhang,Yanhui Hong*

Main category: cs.CV

TL;DR: UniEM-3M是首个大规模多模态电子显微图像数据集，包含5091张高分辨率图像、约300万个实例分割标签和图像级文本描述，旨在解决材料科学中深度学习表征的数据稀缺问题。

- Motivation: 电子显微图像在材料科学中至关重要，但深度学习方法的进展受到大规模、多样化、专家标注数据集稀缺的阻碍，主要由于采集成本高、隐私问题和标注复杂性。
- Method: 构建了包含5091张高分辨率电子显微图像、约300万实例分割标签和图像级属性解耦文本描述的多模态数据集；训练了文本到图像扩散模型作为数据增强工具；开发了基于流的UniEM-Net作为强基线模型进行实例分割。
- Result: 定量实验表明，基于流的UniEM-Net模型在这个具有挑战性的基准测试中优于其他先进方法，为自动化材料分析提供了有效的解决方案。
- Conclusion: 通过发布部分数据集、生成模型和综合基准测试，这项工作将显著加速自动化材料分析领域的进展，解决了电子显微图像分析中的数据稀缺问题。


### [38] [Structuring GUI Elements through Vision Language Models: Towards Action Space Generation](https://arxiv.org/abs/2508.16271)
*Yi Xu,Yesheng Zhang,jiajia Liu,Jingdong Chen*

Main category: cs.CV

TL;DR: 提出IAML训练范式，通过IoU坐标采样增强数据，解决MLLM在GUI元素坐标生成中的精度问题

- Motivation: 多模态大语言模型在GUI元素结构化应用中，由于next-token预测训练的特性，在生成精确UI坐标方面存在困难，数值坐标在语言表示空间中存在语义空白
- Method: 引入IoU增强最大似然训练范式，包含基于IoU的坐标采样数据增强管道，考虑与真实坐标的接近程度，用于微调MLLM
- Result: 通过大量实验证明，IAML训练方法在性能上优于传统训练范式
- Conclusion: IAML训练范式有效解决了传统最大似然估计中的暴露偏差问题，提升了MLLM在GUI坐标生成任务中的表现


### [39] [IRSAMap:Towards Large-Scale, High-Resolution Land Cover Map Vectorization](https://arxiv.org/abs/2508.16272)
*Yu Meng,Ligao Deng,Zhihao Xi,Jiansheng Chen,Jingbo Chen,Anzhi Yue,Diyou Liu,Kai Li,Chenhao Wang,Kaiyu Li,Yupeng Deng,Xian Sun*

Main category: cs.CV

TL;DR: IRSAMap是全球首个用于大规模高分辨率多特征土地覆盖矢量制图的遥感数据集，包含180万个实例的10类典型对象，覆盖全球79个地区，为从像素级分割向对象级矢量建模的转变提供标准化基准。

- Motivation: 随着遥感图像分辨率提升和深度学习发展，土地覆盖制图正从像素级分割转向对象级矢量建模，但现有数据集面临类别标注有限、数据规模小、缺乏空间结构信息三大挑战。
- Method: 提出IRSAMap数据集，采用结合人工和AI的智能标注工作流程，包含10类典型对象的全面矢量标注系统，覆盖全球79个地区，总长度超过1000公里。
- Result: 构建了包含180万实例的大规模数据集，支持像素级分类、建筑物轮廓提取、道路中心线提取、全景分割等多任务，提供语义和空间准确性。
- Conclusion: IRSAMap为从像素基向对象基方法的转变提供了标准化基准，推动了地理特征自动化和协同建模，对全球地理信息更新和数字孪生建设具有重要价值。


### [40] [Robust Small Methane Plume Segmentation in Satellite Imagery](https://arxiv.org/abs/2508.16282)
*Khai Duc Minh Tran,Hoa Van Nguyen,Aimuni Binti Muhammad Rawi,Hareeshrao Athinarayanarao,Ba-Ngu Vo*

Main category: cs.CV

TL;DR: 基于U-Net和ResNet34编码器的新颖深度学习方案，结合双光谱增强技术，能够检测小至400平方米的甲烷羽流，在验证集上达到78.39%的F1分数

- Motivation: 检测甲烷羽流这一强效温室气体，有助于缓解快速气候变化，传统方法仅限于检测较大羽流
- Method: 使用U-Net架构配合ResNet34编码器，集成Varon比和Sanchez回归双光谱增强技术来优化输入特征，提高检测灵敏度
- Result: 能够检测小至400平方米（单个20米分辨率像素）的甲烷羽流，在验证集上获得78.39%的F1分数，在灵敏度和精度方面优于现有遥感技术
- Conclusion: 该方法在自动甲烷监测方面表现出优越性能，特别是在小羽流检测方面超越了传统遥感技术


### [41] [EdgeDoc: Hybrid CNN-Transformer Model for Accurate Forgery Detection and Localization in ID Documents](https://arxiv.org/abs/2508.16284)
*Anjith George,Sebastien Marcel*

Main category: cs.CV

TL;DR: EdgeDoc是一种新颖的文档伪造检测和定位方法，结合轻量级卷积变换器和噪声特征提取，在ICCV 2025挑战赛中表现优异

- Motivation: 数字文档伪造工具的普及对KYC流程和远程注册系统构成严重威胁，需要有效的伪造检测方法来保障服务完整性
- Method: 结合轻量级卷积变换器和从图像中提取的辅助噪声特征，增强检测细微篡改的能力
- Result: 在ICCV 2025 DeepID挑战赛中获得第三名，在FantasyID数据集上超越基线方法
- Conclusion: EdgeDoc在真实场景中表现出色，为文档伪造检测提供了有效的解决方案


### [42] [Learning Long-Range Action Representation by Two-Stream Mamba Pyramid Network for Figure Skating Assessment](https://arxiv.org/abs/2508.16291)
*Fengshun Wang,Qiurui Wang,Peilin Zhao*

Main category: cs.CV

TL;DR: 这篇论文提出了一种双流Mamba金字塔网络，用于冰上舞蹈的技术元素分(TES)和程序组件分(PCS)评估，解决了现有方法在特征处理、元素分离评估和长视频处理方面的挑战。

- Motivation: 现有方法在冰上舞蹈评分中存在三个主要问题：未考虑评分标准的特征混用、未对单独动作元素进行分离评分、以及长视频处理效率低下。
- Method: 设计了双流Mamba金字塔网络，将TES和PCS评估分离：视觉特征基础的TES流和音视频特征基础的PCS流。在PCS流中使用多级融合机制，在TES流中使用多尺度Mamba金字塔来处理不同时间尺度的动作元素。
- Result: 在FineFS标准数据集上达到了最先进的性能水平，验证了方法的有效性。
- Conclusion: 该方法能够有效地解决冰上舞蹈评分中的关键挑战，提供了一种符合实际评分标准的自动化评估方案。


### [43] [Enhanced Hybrid Technique for Efficient Digitization of Handwritten Marksheets](https://arxiv.org/abs/2508.16295)
*Junaid Ahmed Sifat,Abir Chowdhury,Hasnat Md. Imtiaz,Md. Irtiza Hossain,Md. Imran Bin Azad*

Main category: cs.CV

TL;DR: 提出了一种结合OpenCV表格检测和PaddleOCR手写文本识别的混合方法，用于数字化手写成绩单，其中改进的YOLOv8模型在准确率上表现最佳。

- Motivation: 手写成绩单的数字化面临巨大挑战，主要由于不同的手写风格和复杂的表格结构，需要开发高效准确的自动化解决方案。
- Method: 采用OpenCV进行表格检测，结合PaddleOCR进行序列手写文本识别，并实现了YOLOv8和改进版YOLOv8模型用于表格结构内的手写文本识别。
- Result: 改进的YOLOv8模型达到92.72%的准确率，优于PaddleOCR的91.37%和标准YOLOv8的88.91%，在自定义数据集上表现出色。
- Conclusion: 该方法为文档自动化领域提供了实用快速的解决方案，特别适用于手写文档理解，能够减少人工工作需求并提高数字化效率。


### [44] [A Multimodal-Multitask Framework with Cross-modal Relation and Hierarchical Interactive Attention for Semantic Comprehension](https://arxiv.org/abs/2508.16300)
*Mohammad Zia Ur Rehman,Devraj Raghuvanshi,Umang Jain,Shubhi Bansal,Nagendra Kumar*

Main category: cs.CV

TL;DR: 提出了MM-ORIENT框架，通过跨模态关系图和分层交互注意力机制，在不进行显式模态交互的情况下获得多模态表示，减少噪声影响并保留单模态判别信息

- Motivation: 多模态学习中存在单模态噪声问题，传统融合方法在追求强联合表示时可能忽略单模态中有价值的判别信息
- Method: 使用跨模态关系图重建单模态特征来获取多模态表示，基于不同模态特征决定节点邻域；提出分层交互单模态注意力(HIMA)机制来关注模态内重要信息
- Result: 在三个数据集上的广泛实验表明，该方法能有效理解多模态内容并适用于多个任务
- Conclusion: MM-ORIENT框架通过非显式交互的方式有效减少了噪声影响，同时保留了单模态的判别特征，在多任务多模态学习中表现出色


### [45] [Exploiting Information Redundancy in Attention Maps for Extreme Quantization of Vision Transformers](https://arxiv.org/abs/2508.16311)
*Lucas Maisonnave,Karim Haroun,Tom Pegeot*

Main category: cs.CV

TL;DR: 提出EAM方法，通过分析注意力图的熵值来识别冗余头，冻结低熵注意力图并量化到低精度，在ImageNet-1k上实现≤20%稀疏度时保持或提升DeiT和Swin Transformer性能

- Motivation: Transformer模型的多头自注意力机制计算复杂度和内存需求高，阻碍边缘部署。分析发现低熵注意力头贡献信息较少，存在冗余，可作为压缩目标
- Method: 使用香农熵量化每个注意力头的信息量，冻结低熵注意力图并将其值量化到低精度，避免冗余重计算
- Result: 在ImageNet-1k数据集上，EAM在注意力图稀疏度≤20%时达到相似或更高准确率，在更高稀疏度下仍保持竞争力
- Conclusion: 基于熵分析的注意力图压缩策略能有效减少计算和内存需求，同时保持模型性能，为Transformer在边缘设备部署提供可行方案


### [46] [Vision encoders should be image size agnostic and task driven](https://arxiv.org/abs/2508.16317)
*Nedyalko Prisadnikov,Danda Pani Paudel,Yuqian Fu,Luc Van Gool*

Main category: cs.CV

TL;DR: 这篇位置论文主张下一代视觉编码器应该是图像大小无关且任务驱动的，受生物效率行为的启发，提出了一种动态计算复杂性依赖于任务而非图像大小的解决方案

- Motivation: 受生物视觉的效率性启发，现代视觉编码器在处理大量视觉数据时缺乏效率性，需要根据任务动态分配计算资源
- Method: 提出了一种动态计算复杂性的视觉编码器设计，计算复杂性依赖于任务而非图像大小，并为图像分类任务提供了概念验证解决方案
- Result: 概念验证解决方案显示该方法是可行且有前景的，尽管图像分类任务并不能完全代表论文的目标
- Conclusion: 下一代视觉编码器应该向生物视觉学习，通过任务驱动的动态计算复杂性来提高效率，这是一个有前景的研究方向


### [47] [Attention Mechanism in Randomized Time Warping](https://arxiv.org/abs/2508.16366)
*Yutaro Hiraoka,Kazuya Okamura,Kota Suto,Kazuhiro Fukui*

Main category: cs.CV

TL;DR: 本文揭示随机时间扭曲(RTW)本质上是一种自注意力机制，与Transformer中的自注意力相似但具有全局视图优势，在动作识别任务上性能提升5%。

- Motivation: 探索RTW与自注意力机制之间的内在联系，理解两者在时序模式处理中的相似性和差异性，并利用RTW的全局视图优势提升性能。
- Method: 将RTW解释为一种自注意力机制，分析其权重模式与自注意力的相关性，比较两者在输入序列处理范围上的差异。
- Result: RTW权重与自注意力权重高度相关(平均相关系数0.80)，但RTW具有全局视图优势，在Something-Something V2数据集上性能提升5%。
- Conclusion: RTW可被视为一种特殊的自注意力机制，其全局处理能力相比Transformer的局部视图具有性能优势，为时序模式识别提供了新的视角。


### [48] [A Lightweight Group Multiscale Bidirectional Interactive Network for Real-Time Steel Surface Defect Detection](https://arxiv.org/abs/2508.16397)
*Yong Zhang,Cunjian Chen,Qiang Gao,Yi Wang,Bin Fang*

Main category: cs.CV

TL;DR: 提出GMBINet轻量级框架，通过新型分组多尺度双向交互模块解决钢铁表面缺陷检测中计算复杂度过高和推理速度慢的问题，在保持高精度的同时实现实时检测性能。

- Motivation: 现有深度学习方法在钢铁表面缺陷检测中虽然精度高，但计算复杂度大、推理速度慢，难以在资源受限的工业环境中部署。多分支架构方法存在计算开销增加和跨尺度特征交互不足的问题。
- Method: 提出Group Multiscale Bidirectional Interactive (GMBI)模块，采用分组策略进行多尺度特征提取，确保尺度无关的计算复杂度。集成双向渐进特征交互器(BPFI)和无参数元素乘加(EWMS)操作，在不增加计算开销的情况下增强跨尺度交互。
- Result: 在SD-Saliency-900和NRSD-MN数据集上，GMBINet在512分辨率下达到GPU 1048 FPS和CPU 16.53 FPS的实时速度，仅使用0.19M参数。在NEU-CLS缺陷分类数据集上的进一步评估证实了方法的强泛化能力。
- Conclusion: GMBINet在保持竞争性精度的同时实现了实时检测性能，展示了在工业视觉应用中超越表面缺陷检测的潜力，为资源受限环境提供了有效的解决方案。


### [49] [SAMFusion: Sensor-Adaptive Multimodal Fusion for 3D Object Detection in Adverse Weather](https://arxiv.org/abs/2508.16408)
*Edoardo Palladin,Roland Dietze,Praveen Narayanan,Mario Bijelic,Felix Heide*

Main category: cs.CV

TL;DR: 一种新的多模态传感器融合方法，专门应对自动驾驶中的恼劣天气条件，通过融合RGB、LiDAR、NIR门控摄像机和雷达数据，在洞洞、雪天等极端场景下显著提升检测精度。

- Motivation: 现有的多模态传感器融合方法在正常环境下表现优异，但在恼劣天气条件（如洞洞、大雪、污染）下效果大打折扣，影响自主机器人的对象检测和决策能力。
- Method: 采用注意力机制和深度基础的融合方案，在鸟视图（BEV）平面上学习精细融合图像和距离特征。使用transformer解码器根据距离和可见度加权不同模态数据。
- Result: 在远距离和洞洞场景下，对弱势行人的平均精度提升了17.2 AP，显著改善了自动驾马车轨在极端天气条件下的可靠性。
- Conclusion: 该方法有效缩小了理想条件下的驾驶系统与真实世界极端场景之间的差距，为自主机器人在恼劣天气中的安全运行提供了可靠的技术支撑。


### [50] [HAMSt3R: Human-Aware Multi-view Stereo 3D Reconstruction](https://arxiv.org/abs/2508.16433)
*Sara Rojas,Matthieu Armando,Bernard Ghamen,Philippe Weinzaepfel,Vincent Leroy,Gregory Rogez*

Main category: cs.CV

TL;DR: HAMSt3R是基于MASt3R的扩展方法，用于从稀疏未标定多视角图像进行联合人体和场景的3D重建，通过集成人体分割、DensePose对应关系和深度估计，实现高效的前馈式重建。

- Motivation: 现有方法如DUSt3R和MASt3R主要针对静态室外场景，在处理以人为中心的场景时表现不佳，需要开发能够同时处理人体和场景的3D重建方法。
- Method: 利用DUNE图像编码器（融合MASt3R和multi-HMR编码器），添加网络头进行人体分割、DensePose密集对应关系估计和深度预测，生成包含人体语义信息的密集3D点云。
- Result: 在EgoHumans和EgoExo4D基准测试中表现优异，能够有效重建人体同时保持通用3D重建任务的强性能，验证了在多视角立体视觉和多视角姿态回归任务中的泛化能力。
- Conclusion: HAMSt3R填补了人体与场景理解之间的空白，提供了一种完全前馈且高效的方法，适用于现实世界应用，实现了人体和场景的联合3D重建。


### [51] [HOSt3R: Keypoint-free Hand-Object 3D Reconstruction from RGB images](https://arxiv.org/abs/2508.16465)
*Anilkumar Swamy,Vincent Leroy,Philippe Weinzaepfel,Jean-Sébastien Franco,Grégory Rogez*

Main category: cs.CV

TL;DR: 提出HOSt3R方法，无需关键点检测即可从单目视频估计手-物体3D变换，并与多视角重建结合实现手-物体3D形状恢复

- Motivation: 现有基于关键点检测的方法在处理多样物体几何、弱纹理和手-物体相互遮挡时存在局限，限制了方法的可扩展性和泛化能力
- Method: 提出无关键点检测器的方法估计手-物体3D变换，并与多视角重建管道集成，无需预扫描物体模板或相机内参
- Result: 在SHOWMe基准测试中达到最先进性能，在HO3D数据集上展示了对未见物体类别的泛化能力
- Conclusion: HOSt3R方法实现了无约束、鲁棒的手-物体3D重建，为通用无缝应用提供了关键技术支持


### [52] [Arbitrary-Scale 3D Gaussian Super-Resolution](https://arxiv.org/abs/2508.16467)
*Huimin Zeng,Yue Bai,Yun Fu*

Main category: cs.CV

TL;DR: 提出了一种支持任意尺度超分辨率的3D高斯泼溅框架，通过尺度感知渲染、生成先验引导优化和渐进式超分辨率技术，在保持实时渲染速度的同时显著提升图像质量。

- Motivation: 现有3DGS超分辨率方法只能处理固定尺度因子，无法适应资源受限场景。直接渲染任意尺度会产生混叠伪影，而添加后处理上采样器会降低效率。
- Method: 构建集成框架，包含尺度感知渲染、生成先验引导优化和渐进式超分辨率技术，支持整数和非整数尺度渲染。
- Result: 单模型实现任意尺度高质量HR视图渲染，PSNR比3DGS提升6.59dB，保持与LR视图的结构一致性，实时渲染速度达85FPS（1080p）。
- Conclusion: 该方法在保持实时渲染性能的同时，有效解决了3D高斯泼溅的任意尺度超分辨率问题，为资源受限场景提供了实用解决方案。


### [53] [Seeing Clearly, Forgetting Deeply: Revisiting Fine-Tuned Video Generators for Driving Simulation](https://arxiv.org/abs/2508.16512)
*Chun-Peng Chang,Chen-Yu Wang,Julian Schmidt,Holger Caesar,Alain Pagani*

Main category: cs.CV

TL;DR: 视频生成模型在驾驶场景微调中存在视觉保真度与动态空间精度的权衡问题，简单的持续学习策略可以平衡两者

- Motivation: 研究现有视频生成模型在结构化驾驶数据集上微调的效果，发现视觉质量提升但动态元素空间精度下降的潜在权衡问题
- Method: 分析驾驶场景的规律性和重复性特征，提出使用来自多样域的简单持续学习策略（如重放）来平衡视觉质量和空间精度
- Result: 发现微调会使模型优先考虑表面级真实感而非动态精度，而持续学习策略能够在保持强视觉质量的同时保留空间精度
- Conclusion: 驾驶场景的特殊结构导致视觉质量与动态理解目标之间的对齐关系发生变化，需要采用平衡策略来同时保证视觉真实性和动态准确性


### [54] [Towards Open World Detection: A Survey](https://arxiv.org/abs/2508.16527)
*Andrei-Stefan Bulzan,Cosmin Cernazanu-Glavan*

Main category: cs.CV

TL;DR: 本文提出开放世界检测(OWD)概念，统一类无关和通用的视觉检测模型，追溯从显著性检测到VLLMs的发展路径，并预测这些子领域将融合成单一的感知领域。

- Motivation: 计算机视觉领域长期以来存在专门化分差问题，各个子领域成功累积后需要查明它们的收敛趋势和统一可能性。
- Method: 通过调研论文形式，追溯基础视觉子领域发展史，涵盖关键概念、方法论和数据集，分析从显著性检测到VLLMs的演进路径。
- Result: 提出了开放世界检测(OWD)作为统一框架，明确了各子领域间的重叠关系和收敛趋势，为未来单一感知领域的发展指明了方向。
- Conclusion: 计算机视觉各专门化子领域正在逐渐收敛，开放世界检测概念有望成为统一框架，最终实现单一感知领域的目标。


### [55] [MV-RAG: Retrieval Augmented Multiview Diffusion](https://arxiv.org/abs/2508.16577)
*Yosef Dayani,Omer Benishu,Sagie Benaim*

Main category: cs.CV

TL;DR: MV-RAG是一种新颖的文本到3D生成方法，通过检索真实世界2D图像来增强多视角扩散模型，显著改善了罕见概念和域外内容的3D一致性和准确性。

- Motivation: 现有的文本到3D生成方法在处理域外(OOD)或罕见概念时往往产生不一致或不准确的结果，需要更好的方法来利用大规模2D图像数据库。
- Method: 提出检索增强的多视角扩散模型，首先从大规模2D数据库中检索相关图像，然后基于这些图像合成一致的多视角输出。采用混合训练策略，结合多视角数据和真实2D图像集合。
- Result: 实验表明，该方法在OOD/罕见概念上显著提高了3D一致性、照片真实感和文本遵循度，同时在标准基准测试中保持竞争力。
- Conclusion: MV-RAG通过检索真实世界2D图像来增强多视角生成，为处理域外和罕见概念的文本到3D生成提供了有效解决方案。
## cs.RO

### [56] [UnPose: Uncertainty-Guided Diffusion Priors for Zero-Shot Pose Estimation](https://arxiv.org/abs/2508.15972)
*Zhaodong Jiang,Ashish Sinha,Tongtong Cao,Yuan Ren,Bingbing Liu,Binbin Xu*

Main category: cs.RO

TL;DR: UnPose是一个零样本、无模型的6D物体姿态估计和重建框架，利用预训练扩散模型的3D先验和不确定性估计，通过3D高斯泼溅表示和增量优化实现高精度姿态估计和3D重建

- Motivation: 传统6D姿态估计依赖CAD模型，但获取成本高且不实用。现有方法需要额外训练或产生幻觉几何，因此需要开发无需模型、零样本的解决方案
- Method: 使用单视角RGB-D图像，通过多视角扩散模型估计初始3D高斯泼溅模型和不确定性。增量融合新视角，利用不确定性指导优化，通过姿态图联合优化确保全局一致性
- Result: 在6D姿态估计精度和3D重建质量方面显著优于现有方法，在真实机器人操作任务中展示实用价值
- Conclusion: UnPose成功实现了无需CAD模型的零样本6D姿态估计和重建，通过扩散模型先验和不确定性引导的增量优化，为机器人应用提供了实用解决方案


### [57] [GelSLAM: A Real-time, High-Fidelity, and Robust 3D Tactile SLAM System](https://arxiv.org/abs/2508.15990)
*Hung-Jui Huang,Mohammad Amin Mirzaee,Michael Kaess,Wenzhen Yuan*

Main category: cs.RO

TL;DR: GelSLAM是一个基于触觉传感的实时3D SLAM系统，能够长时间估计物体姿态并以高保真度重建物体形状，使用表面法线和曲率进行鲁棒跟踪和闭环检测。

- Motivation: 精确感知物体的姿态和形状对于精确抓取和操作至关重要。相比视觉方法，触觉传感在精度和对遮挡的免疫性方面具有优势，特别适合手内和其他高精度操作任务。
- Method: 使用触觉传感获取表面法线和曲率信息，而非传统的点云方法，实现鲁棒的跟踪和闭环检测。系统能够实时跟踪物体运动并重建形状。
- Result: 能够以低误差和最小漂移实时跟踪物体运动，并以亚毫米精度重建形状，即使是低纹理物体（如木制工具）也能处理。
- Conclusion: GelSLAM将触觉传感从局部接触扩展到全局、长时程的空间感知，为涉及手内物体交互的精确操作任务奠定了基础。
## eess.IV

### [58] [Robust Residual Finite Scalar Quantization for Neural Compression](https://arxiv.org/abs/2508.15860)
*Xiaoxu Zhu*

Main category: eess.IV

TL;DR: 提出了RFSQ框架解决FSQ在残差量化中的信号衰减问题，通过可学习缩放因子和可逆LayerNorm两种条件策略，在ImageNet上显著优于现有方法

- Motivation: FSQ在残差量化框架中存在残差幅度衰减问题，后续层接收的信号逐渐减弱，限制了其有效性
- Method: 提出Robust Residual Finite Scalar Quantization (RFSQ)框架，包含两种新颖的条件策略：可学习缩放因子和可逆层归一化
- Result: 在ImageNet上显著优于VQ-EMA、FSQ和LFQ等基线方法，感知损失提升45%，L1重建误差降低28.7%
- Conclusion: RFSQ成为神经压缩中优越的量化方法，特别是LayerNorm策略在不同配置下表现最一致


### [59] [GUI Based Fuzzy Logic and Spatial Statistics for Unsupervised Microscopy Segmentation](https://arxiv.org/abs/2508.15979)
*Surajit Das,Pavel Zun*

Main category: eess.IV

TL;DR: 提出首个无监督细胞分割框架，结合多种统计方法，无需标注数据即可在无染色明场显微镜图像中实现高质量细胞分割，性能优于当前最先进的深度学习模型。

- Motivation: 解决无染色活细胞明场显微镜成像的低对比度、时间变化、不均匀光照和缺乏训练标签等挑战，提供比深度学习更轻量、无需训练且对非编程用户友好的解决方案。
- Method: 结合空间标准差局部均值(SSDLM)、模糊逻辑、调整变异函数、Moran's I和累积平方节点强度偏移(CSSNI)等统计方法，构建无监督分割框架，通过用户友好的GUI界面操作。
- Result: 在三个数据集上验证了方法的鲁棒性和通用性，相比2023-2024年最先进模型(Cellpose 3.0和StarDist)，IoU提升高达48%，统计显著性验证(p<0.01)，专家评估一致性高(Cohen's κ>0.75)。
- Conclusion: 该方法轻量、可解释、计算高效，为无标记显微镜细胞分割提供了实用有效的替代方案，代码和数据集已开源以确保可重复性。


### [60] [Cross-Attention Multimodal Fusion for Breast Cancer Diagnosis: Integrating Mammography and Clinical Data with Explainability](https://arxiv.org/abs/2508.16000)
*Muhaisin Tiyumba Nantogmah,Abdul-Barik Alhassan,Salamudeen Alhassan*

Main category: eess.IV

TL;DR: 这篇论文研究了如何结合临床特征和乳腺照来提高乳腺病变分类准确性，通过多模态深度学习模型实现了极高的识别性能。

- Motivation: 现有的乳腺病变识别系统主要依靠乳腺照特征，没有充分利用临床报告的价值信息。需要解决如何有效结合临床特征和乳腺照，以及如何通过可解释性AI提高模型的可靠性。
- Method: 探索了多种基于特征拼接、共同注意力和交叉注意力的多模态深度网络模型，用于整合乳腺照和分类临床特征。
- Result: 在公开数据集TCGA和CBIS-DDSM上进行测试，模型达到了AUC-ROC 0.98、准确度0.96、F1分0.94、精度0.92和召回率0.95的极高性能指标。
- Conclusion: 通过多模态深度学习方法结合临床特征和乳腺照，可以显著提高乳腺病变分类的准确性，为医生提供更可靠的诊断帮助。


### [61] [Clinically-Informed Preprocessing Improves Stroke Segmentation in Low-Resource Settings](https://arxiv.org/abs/2508.16004)
*Juampablo E. Heras Rivera,Hitender Oswal,Tianyi Ren,Yutong Pan,William Henry,Caitlin M. Neher,Mehmet Kurt*

Main category: eess.IV

TL;DR: 本文研究了一种基于CT成像的深度学习模型，用于预测置行性脑梗梗核体积，通过临床预处理流程实现了显著的性能提升。

- Motivation: 解决低资源设置中置行性脑梗识别的挑战，CT成像成本低但特异性不如MRI，需要开发更准确的自动化分割方法。
- Method: 开发了一系列模型，使用入院时CT图像预测2-9天后的DWI标注的病变体积，采用临床预处理步骤和CTA血管分割技术。
- Result: 提出的流程使Dice得分比基准nnU-Net提高38%，通过CTA血管分割进一步提高21%。
- Conclusion: 该方法为低资源设置提供了一种实用的脑梗病变自动分割方案，能够利用CT成像实现接近MRI的识别精度。


### [62] [Lightweight and Fast Real-time Image Enhancement via Decomposition of the Spatial-aware Lookup Tables](https://arxiv.org/abs/2508.16121)
*Wontae Kim,Keuntek Lee,Nam Ik Cho*

Main category: eess.IV

TL;DR: 通过SVD分解和缓存优化，提出了一种空间感知能力保持、参数和运行时间同时减少的图像增强方法

- Motivation: 解决传统3D LUT方法缺乏空间信息的问题，以及现有空间感知3D LUT方法参数多、运行时间随图像分辨率增加而增长的缺点
- Method: 将3D LUT分解为低维LUT的线性组合，采用奇异值分解(SVD)处理表格冗余部分，并改进空间特征融合模块的缓存效率
- Result: 实验结果显示，该模型在保持空间感知能力和性能的同时，有效减少了参数数量和运行时间
- Conclusion: 该方法通过分解和优化技术，成功解决了空间感知3D LUT方法的效率问题，为高效图像增强提供了新的解决方案


### [63] [Self-Validated Learning for Particle Separation: A Correctness-Based Self-Training Framework Without Human Labels](https://arxiv.org/abs/2508.16224)
*Philipp D. Lösel,Aleese Barron,Yulai Zhang,Matthias Fabian,Benjamin Young,Nicolas Francois,Andrew M. Kingston*

Main category: eess.IV

TL;DR: Error

- Motivation: Error
- Method: Error
- Result: Error
- Conclusion: Error


### [64] [Towards Diagnostic Quality Flat-Panel Detector CT Imaging Using Diffusion Models](https://arxiv.org/abs/2508.16252)
*Hélène Corbaz,Anh Nguyen,Victor Schulze-Zachau,Paul Friedrich,Alicia Durrer,Florentin Bieder,Philippe C. Cattin,Marios N Psychogios*

Main category: eess.IV

TL;DR: 使用去噪滿散概率模型(DDPM)提升平板探测器CT(FDCT)图像质量，使其可与多探测器CT(MDCT)相比较，减少患者移动需求

- Motivation: 在血塞切除手术中，FDCT图像质量较低且存在显著伪影，而使用FDCT单独拍摄可以节省患者移动到MDCT室的时间和流程
- Method: 采用去噪滿散概率模型(DDPM)对FDCT扫描图像进行质量提升处理
- Result: DDPM模型能够消除大部分伪影，提高解剖可见性，同时保持出血检测能力（前提是输入FDCT图像质量不能太低）
- Conclusion: 该方法有力地改善了FDCT图像质量，为临床工作流程的优化提供了可行方案，代码已开源


### [65] [Decoding MGMT Methylation: A Step Towards Precision Medicine in Glioblastoma](https://arxiv.org/abs/2508.16424)
*Hafeez Ur Rehman,Sumaiya Fazal,Moutaz Alazab,Ali Baydoun*

Main category: eess.IV

TL;DR: 这篇论文提出了一种基于自动编码器的CAMP框架，通过适应性稀疏罚款来预测脑米液留MGMT基因甲基化状态，准确率达到97%，显著超过现有方法。

- Motivation: 脑米液留是高激进性脑部肝癌，MGMT基因甲基化状态是预测治疗效果的关键生物标记物。但现有图像技术在预测MGMT状态时遇到了挑战，包括异质性、对比度不均等问题。
- Method: 提出CAMP框架，包含两个阶段：1）通过特制自动编码器生成合成MRI切片，捐捕和保持不同MRI模态下的细致组织和脾瘤结构；2）使用提升了适应性稀疏罚款的卷积神经网络预测MGMT甲基化状态。适应性稀疏罚款能动态调整以适应数据变化。
- Result: 在标准数据集上验证，CAMP框架达到了准确率0.97、特异性0.98和敏感性0.97的高性能指标，显著超过现有方法。该方法在MRI图像合成方面表现优异，能够保持脑组织、脂肪和脾瘤结构的细节。
- Conclusion: CAMP框架显示了在改善MRI数据解释和为脑米液留患者提供更个性化治疗策略方面的潜力，为非侵入性预测MGMT甲基化状态提供了有效的新方法。


### [66] [Disentangled Multi-modal Learning of Histology and Transcriptomics for Cancer Characterization](https://arxiv.org/abs/2508.16479)
*Yupei Zhang,Xiaofei Wang,Anran Liu,Lequan Yu,Chao Li*

Main category: eess.IV

TL;DR: 提出解耦多模态框架解决组织病理学与转录组学融合中的异质性、多尺度整合和配对数据依赖问题，在癌症诊断、预后和生存预测中优于现有方法

- Motivation: 现有多模态方法面临多模态异质性、多尺度整合不足和对配对数据的依赖等挑战，限制了临床适用性
- Method: 使用解耦多模态融合模块将WSI和转录组分解为肿瘤和微环境子空间，采用置信度引导梯度协调、跨放大倍数基因表达一致性、子空间知识蒸馏和信息token聚合等策略
- Result: 在癌症诊断、预后和生存预测的广泛实验中，该方法在多种设置下均优于最先进方法
- Conclusion: 该解耦多模态框架有效解决了多模态学习中的关键挑战，提高了临床适用性和推理效率


### [67] [Time-Aware One Step Diffusion Network for Real-World Image Super-Resolution](https://arxiv.org/abs/2508.16557)
*Tainyi Zhang,Zheng-Peng Duan,Peng-Tao Jiang,Bo Li,Ming-Ming Cheng,Chun-Le Guo,Chongyi Li*

Main category: eess.IV

TL;DR: 提出TADSR方法，通过时间感知机制充分利用SD模型在不同时间步的生成先验，实现单步超分辨率的高效控制和性能提升

- Motivation: 现有基于VSD的Real-ISR方法使用固定时间步，无法充分利用SD模型在不同噪声注入时间步的不同生成先验，导致性能次优
- Method: 提出时间感知VAE编码器将图像投影到不同时间步的潜在特征，设计时间感知VSD损失桥接师生模型时间步，实现生成先验的有效利用
- Result: 实验结果表明该方法在单步超分辨率中达到最先进性能，并能通过时间步条件在保真度和真实感之间实现可控权衡
- Conclusion: TADSR通过时间感知机制有效利用了SD模型在不同时间步的生成能力，实现了高效且可控的单步真实图像超分辨率


### [68] [A Disease-Centric Vision-Language Foundation Model for Precision Oncology in Kidney Cancer](https://arxiv.org/abs/2508.16569)
*Yuhui Tao,Zhongwei Zhao,Zilong Wang,Xufang Luo,Feng Chen,Kang Wang,Chuanfu Wu,Xue Zhang,Shaoting Zhang,Jiaxi Yao,Xingwei Jin,Xinyang Jiang,Yifan Yang,Dongsheng Li,Lili Qiu,Zhiqiang Shao,Jianming Guo,Nengwang Yu,Shuo Wang,Ying Xiong*

Main category: eess.IV

TL;DR: 开发了RenalCLIP视觉语言基础模型，用于肾肿瘤的CT影像分析，在诊断分类、预后预测等10个核心任务上表现优异，数据效率高，仅需20%训练数据即可达到基线模型100%数据的性能。

- Motivation: 解决肾肿瘤非侵入性评估的挑战，避免良性或惰性肿瘤的过度治疗，提高诊断准确性和预后分层精度。
- Method: 采用两阶段预训练策略：先增强图像和文本编码器的领域特定知识，然后通过对比学习目标对齐，构建鲁棒表示。基于27,866个CT扫描和8,809名患者数据开发验证。
- Result: 在TCIA队列的无复发生存预测中C-index达0.726，比最优基线提高约20%；诊断分类任务仅需20%训练数据即可达到基线模型100%数据的峰值性能；在报告生成、图像文本检索和零样本诊断任务中表现优异。
- Conclusion: RenalCLIP为肾癌患者管理提供了强大的工具，有望提高诊断准确性、优化预后分层并实现个性化治疗。
## cs.GR

### [69] [Wavelet-Space Super-Resolution for Real-Time Rendering](https://arxiv.org/abs/2508.16024)
*Prateek Poudel,Prashant Aryal,Kirtan Kunwar,Navin Nepal,Dinesh Bania Kshatri*

Main category: cs.GR

TL;DR: 本文探讨了在神经超分辨率渲染中使用小波空间特征分解的方法，通过小波域表示分离低高频细节，提升了细节保持能力和结构一致性。

- Motivation: 传统的RGB空间回归方法在超分辨率渲染中对细节结构的保持有限，需要一种更有效的方法来同时保持精细纹理和整体结构一致性。
- Method: 基于DFASR框架，使用稳态小波变换(SWT)来避免空间下采样，将低频和高频细节分离处理。模型预测条件于空间G缓冲区和时间成冒变历史帧的小波系数，然后通过逆小波合成重组。
- Result: 在小波家族、变换类型和网络结构的完整对比实验中，集成SWT技术将PSNR提高了最1.5dB，LPIPS平均减少17%，计算开销仅增加24ms。
- Conclusion: 小波域表示是一种有理论基础且高效的方法，能够在图形应用中显著提升神经网络收缩的感知质量，并保持实时性能。
## cs.AI

### [70] [Modular Embedding Recomposition for Incremental Learning](https://arxiv.org/abs/2508.16463)
*Aniello Panariello,Emanuele Frascaroli,Pietro Buzzega,Lorenzo Bonicelli,Angelo Porrello,Simone Calderara*

Main category: cs.AI

TL;DR: MoDER方法通过模块化框架训练多个文本专家，在推理时组合专家来合成改进的原型，增强视觉语言模型的零样本能力

- Motivation: 虽然预训练视觉语言模型具有零样本分类能力，但在下游任务偏离预训练领域时仍需微调。现有方法主要关注保持零样本能力，本文旨在将其转化为增强
- Method: 提出MoDular Embedding Recomposition (MoDER)方法，训练多个专门处理单个已见类的文本专家，存储在基础中心。推理时查询中心并组合专家来合成改进的原型
- Result: 在Class-IL和MTIL两个零样本增量协议共14个数据集上验证了方法的有效性
- Conclusion: MoDER成功将零样本能力的保持转化为增强，通过模块化专家组合方法显著提升了分类性能
## cs.CL

### [71] [Seeing is Believing: Emotion-Aware Audio-Visual Language Modeling for Expressive Speech Generation](https://arxiv.org/abs/2508.16188)
*Weiting Tan,Jiachen Lian,Hirofumi Inaguma,Paden Tomasello,Philipp Koehn,Xutai Ma*

Main category: cs.CL

TL;DR: 提出了一个音频-视觉语言模型(AVLM)，通过将全脸视觉线索整合到预训练的富有表现力的语音模型中，用于富有表现力的语音生成。

- Motivation: 探索如何通过整合视觉信息来提升语音生成的表现力，为端到端的多模态对话系统奠定基础。
- Method: 研究了多种视觉编码器和多模态融合策略，在预训练阶段识别最有效的整合方法，然后在情感识别和富有表现力的对话任务上进行微调。
- Result: 相比仅语音的基线模型取得了显著提升（例如情感识别任务中F1分数提升+5分）。
- Conclusion: AVLM证明了富有表现力的视觉信息在指导语音生成中的价值，为端到端多模态对话系统提供了基础。
## cs.LG

### [72] [RotaTouille: Rotation Equivariant Deep Learning for Contours](https://arxiv.org/abs/2508.16359)
*Odin Hoff Gardaa,Nello Blaser*

Main category: cs.LG

TL;DR: RotaTouille是一个用于轮廓数据的深度学习框架，通过复值循环卷积实现旋转和循环平移等变性，并在形状分类、重建和轮廓回归任务中表现优异。

- Motivation: 轮廓数据在多个领域普遍存在，如计算机视觉中的物体边界、气象学中的等值线等。深度学习模型需要对这些数据的旋转和循环平移具有等变性，因为输入轮廓的旋转会导致相应旋转的输出，且轮廓起始点的选择是任意的。
- Method: 提出RotaTouille框架，使用复值循环卷积实现旋转和循环平移等变性。引入并表征了等变非线性、粗化层和全局池化层，以获得用于下游任务的不变表示。
- Result: 在形状分类、重建和轮廓回归等实验中证明了RotaTouille的有效性。
- Conclusion: RotaTouille成功实现了对轮廓数据的旋转和循环平移等变性，为处理轮廓数据提供了一种有效的深度学习解决方案。


### [73] [TinyML Towards Industry 4.0: Resource-Efficient Process Monitoring of a Milling Machine](https://arxiv.org/abs/2508.16553)
*Tim Langer,Matthias Widra,Volkhard Beyer*

Main category: cs.LG

TL;DR: 本文提出了一个完整的TinyML流程，用于工业4.0中老旧机器的过程监控，开发了一个8位量化的CNN模型，在微控制器上实现了100%的测试精度和低功耗推理。

- Motivation: 在工业4.0背景下，为老旧工业机器添加过程监控能力，利用TinyML范式开发无线监控系统，实现智能工厂的改造。
- Method: 采用完整的TinyML流程，包括数据集生成（创建新的MillingVibes数据集）、机器学习模型开发，以及在微控制器上实现预处理和分类流水线。开发了8位量化的卷积神经网络模型。
- Result: 在ARM Cortex M4F微控制器上实现了100.0%的测试精度，推理时间为15.4ms，每次量化CNN推理能耗为1.462mJ，模型参数存储仅为12.59kiB。
- Conclusion: 证明了TinyML系统在结构集成过程质量监控中的可行性，为未来的TinyML过程监控解决方案提供了参考基准。


### [74] [Closer to Reality: Practical Semi-Supervised Federated Learning for Foundation Model Adaptation](https://arxiv.org/abs/2508.16568)
*Guangyu Sun,Jingtao Li,Weiming Zhuang,Chen Chen,Chen Chen,Lingjuan Lyu*

Main category: cs.LG

TL;DR: 提出了PSSFL框架和FedMox方法，解决边缘设备在联邦学习中计算资源有限和标注数据稀缺的问题，通过稀疏专家混合架构实现基础模型的高效适配

- Motivation: 基础模型需要适配下游任务，但在隐私敏感应用中，云端无法直接访问边缘私有数据。现有联邦学习方法忽视了边缘设备的计算资源限制和标注数据稀缺问题
- Method: 提出Practical Semi-Supervised Federated Learning (PSSFL)框架，其中边缘设备只有未标注的低分辨率数据，服务器有有限标注的高分辨率数据。设计了Federated Mixture of Experts (FedMox)方法，使用稀疏专家混合架构，包含空间路由器对齐分辨率特征和Soft-Mixture策略稳定半监督学习
- Result: 在真实自动驾驶数据集上的目标检测实验表明，FedMox在PSSFL设置下有效适配基础模型，显著提升性能，同时约束边缘设备的内存成本
- Conclusion: 该工作为联邦场景下可扩展和隐私保护的基础模型适配开辟了新途径
## q-bio.NC

### [75] [NeuroKoop: Neural Koopman Fusion of Structural-Functional Connectomes for Identifying Prenatal Drug Exposure in Adolescents](https://arxiv.org/abs/2508.16414)
*Badhan Mazumder,Aline Kotoski,Vince D. Calhoun,Dong Hye Ye*

Main category: q-bio.NC

TL;DR: 提出了NeuroKoop框架，利用神经Koopman算子融合结构和功能脑网络，提升产前药物暴露分类性能

- Motivation: 现有方法难以充分捕捉结构和功能连接组的互补特征，限制了产前精神活性物质暴露对青少年大脑影响的研究
- Method: 基于图神经网络的NeuroKoop框架，使用神经Koopman算子进行潜在空间融合，整合源基形态测量和功能网络连接的大脑图
- Result: 在ABCD数据集的大规模青少年队列中，NeuroKoop优于相关基线方法，揭示了显著的结构-功能连接
- Conclusion: NeuroKoop框架增强了表征学习能力，推进了对产前药物暴露神经发育影响的理解
## physics.med-ph

### [76] [Deep learning-enabled virtual multiplexed immunostaining of label-free tissue for vascular invasion assessment](https://arxiv.org/abs/2508.16209)
*Yijie Zhang,Cagatay Isil,Xilin Yang,Yuzhu Li,Anna Elia,Karin Atlan,William Dean Wallace,Nir Pillar,Aydogan Ozcan*

Main category: physics.med-ph

TL;DR: 基于深度学习的虚拟多重免疫组化技术，通过无标记组织切片的自发荧光显微镜图像，同时生成ERG、PanCK和H&E虚拟染色，用于甲状腺癌血管侵犯的准确定位和诊断。

- Motivation: 传统免疫组化技术需要每个染色使用一个组织切片，存在切片间变异性、成本高且操作繁琐的问题。多重免疫组化技术虽然能在单张切片上同时进行多个抗体染色，但操作更复杂且尚未在常规病理实验室普及。
- Method: 开发基于深度学习的虚拟多重免疫组化框架，利用无标记组织切片的自发荧光显微镜图像，同时生成ERG、PanCK和H&E虚拟染色图像。
- Result: 虚拟多重免疫组化输出图像与相同组织切片的组织化学染色结果高度匹配。经认证病理学家盲法评估显示，该技术能准确突出上皮细胞和内皮细胞，并在同一组织切片上实现小血管侵犯的识别和定位。
- Conclusion: 这种多重虚拟免疫组化方法可显著提高血管侵犯组织病理学评估的诊断准确性和效率，可能消除传统染色方案的需求，并缓解组织丢失和异质性相关问题。
## cs.HC

### [77] [Harmonious Color Pairings: Insights from Human Preference and Natural Hue Statistics](https://arxiv.org/abs/2508.15777)
*Ortensia Forni,Alexandre Darmon,Michael Benzaquen*

Main category: cs.HC

TL;DR: 通过数据驱动方法研究色彩搭配偏好，发现人类对色彩和谐的偏好与自然景观色彩分布存在统计对应关系

- Motivation: 传统色彩和谐研究多基于定性见解或有限数据集，缺乏明确共识，需要量化、数据驱动的研究方法
- Method: 使用HSL色彩空间的控制色调调板，让参与者评估13种不同色调的组合，构建偏好矩阵并定义每种颜色的可搭配指数
- Result: 偏好强烈依赖于色调，挑战了文献中普遍和谐规则的假设，但在色调平均后发现统计意义上的美学偏好模式，与自然景观色彩分布存在显著对应
- Conclusion: 研究提供了量化研究色彩和谐的框架，揭示了人类色彩偏好的感知和生态基础，为理解色彩美学提供了新视角


### [78] [Prompting with Sign Parameters for Low-resource Sign Language Instruction Generation](https://arxiv.org/abs/2508.16076)
*Md Tariquzzaman,Md Farhan Ishmam,Saiyma Sittul Muna,Md Kamrul Hasan,Hasan Mahmud*

Main category: cs.HC

TL;DR: 提出了首个孟加拉手语指令生成数据集BdSLIG，并开发了Sign Parameter-Infused提示方法，通过整合标准手语参数来提升视觉语言模型在资源匮乏手语任务上的零样本性能。

- Motivation: 许多手语在AI领域资源匮乏，特别是孟加拉手语。手语指令生成(SLIG)能够为非手语用户提供逐步文本指令来学习和模仿手语手势，促进双向交流。
- Method: 1) 创建首个孟加拉手语指令生成数据集BdSLIG；2) 提出Sign Parameter-Infused(SPI)提示方法，将标准手语参数（手形、动作、方向等）整合到文本提示中；3) 评估视觉语言模型在资源匮乏SLIG任务和长尾视觉概念上的表现。
- Result: SPI提示方法使指令更加结构化和可重现，相比自由形式的自然文本提示有更好效果。该方法提升了视觉语言模型在零样本设置下的性能。
- Conclusion: 这项工作促进了资源匮乏社区的手语学习系统的包容性和进步，为其他资源匮乏手语的AI研究提供了参考框架。
