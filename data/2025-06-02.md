[[toc]]

## cs.CV

### [1] [BioCLIP 2: Emergent Properties from Scaling Hierarchical Contrastive Learning](https://arxiv.org/abs/2505.23883)
*Jianyang Gu,Samuel Stevens,Elizabeth G Campolongo,Matthew J Thompson,Net Zhang,Jiaman Wu,Andrei Kopanev,Zheda Mai,Alexander E. White,James Balhoff,Wasila Dahdul,Daniel Rubenstein,Hilmar Lapp,Tanya Berger-Wolf,Wei-Lun Chao,Yu Su*

Main category: cs.CV

TL;DR: 论文研究了大规模对比视觉语言训练下生物视觉模型的涌现行为，通过构建TreeOfLife-200M数据集并训练BioCLIP 2模型，发现其嵌入空间具有生态和功能意义的层级特性。

- Motivation: 探索大规模训练的生物视觉模型是否能够超越初始目标，涌现出新的能力，并理解其嵌入空间的生物学意义。
- Method: 构建TreeOfLife-200M数据集，训练BioCLIP 2模型进行物种区分，并分析其嵌入空间的层级特性。
- Result: BioCLIP 2在多种生物视觉任务中表现优异，嵌入空间在物种间和物种内均展现出生态和功能意义的层级结构。
- Conclusion: 大规模训练数据促进了嵌入空间的生物学意义，层级监督和对比目标有助于涌现特性的形成。


### [2] [Generating Fit Check Videos with a Handheld Camera](https://arxiv.org/abs/2505.23886)
*Bowei Chen,Brian Curless,Ira Kemelmacher-Shlizerman,Steven M. Seitz*

Main category: cs.CV

TL;DR: 提出一种基于手持移动设备的全身视频捕捉方法，通过两张静态照片和IMU运动参考生成逼真视频。

- Motivation: 传统全身视频捕捉需要固定相机和精心构图，不够便捷。
- Method: 使用两张静态照片（正面和背面）和IMU运动参考，结合视频扩散模型和多参考注意力机制生成视频。
- Result: 实现了新场景中的渲染，光照和阴影一致，视频逼真。
- Conclusion: 该方法便捷高效，提升了视频生成的逼真度和场景适应性。


### [3] [Cora: Correspondence-aware image editing using few step diffusion](https://arxiv.org/abs/2505.23907)
*Amirhossein Almohammadi,Aryan Mikaeili,Sauradip Nag,Negar Hassanpour,Andrea Tagliasacchi,Ali Mahdavi-Amiri*

Main category: cs.CV

TL;DR: Cora是一种新的图像编辑框架，通过语义对应和噪声校正实现高质量编辑，解决了现有方法在结构变化和纹理保留上的不足。

- Motivation: 现有扩散方法在需要显著结构变化的编辑任务中表现不佳，容易出现纹理不相关或关键属性丢失的问题。
- Method: 引入基于语义对应的噪声校正和插值注意力图，平衡内容生成与保留。
- Result: 实验证明Cora在结构、纹理和身份保持上表现优异，用户研究也证实其优于其他方法。
- Conclusion: Cora为复杂图像编辑任务提供了高效且高质量的解决方案。


### [4] [Representational Difference Explanations](https://arxiv.org/abs/2505.23917)
*Neehar Kondapaneni,Oisin Mac Aodha,Pietro Perona*

Main category: cs.CV

TL;DR: 提出了一种名为RDX的方法，用于发现和可视化两种学习表示之间的差异，支持更直接和可解释的模型比较。

- Motivation: 当前的可解释AI（XAI）方法在模型比较方面效果不佳，而比较是科学分析的基础，因此需要一种更有效的工具。
- Method: 提出Representational Differences Explanations（RDX）方法，通过比较具有已知概念差异的模型来验证其有效性。
- Result: RDX在ImageNet和iNaturalist数据集上成功揭示了模型间的有意义差异和数据的细微模式，优于现有XAI方法。
- Conclusion: RDX填补了机器学习中模型比较工具的空白，提供了一种有效且可解释的模型对比方法。


### [5] [ScaleLong: A Multi-Timescale Benchmark for Long Video Understanding](https://arxiv.org/abs/2505.23922)
*David Ma,Huaqing Yuan,Xingjian Wang,Qianbo Zang,Tianci Liu,Xinyang He,Yanbin Wei,Jiawei Guo,Ni Jiahui,Zhenzhu Yang,Meng Cao,Shanghaoran Quan,Yizhi Li,Wangchunshu Zhou,Jiaheng Liu,Wenhao Huang,Ge Zhang,Shiwen Ni,Xiaojie Jin*

Main category: cs.CV

TL;DR: ScaleLong是一个新的多时间尺度长视频理解基准，通过在同一视频内容中嵌入不同时间尺度的问题，支持直接比较模型性能。

- Motivation: 现有基准未能直接比较模型在不同时间尺度上的表现，ScaleLong旨在解决这一问题。
- Method: ScaleLong包含269个长视频，每个视频设计4-8个问题，覆盖四个时间尺度（秒、十秒、分钟、小时）。
- Result: 评估23个MLLM显示U形性能曲线，最短和最长时间尺度表现更好，中间尺度表现较差。视觉标记容量增加能提升所有时间尺度的推理能力。
- Conclusion: ScaleLong为长视频理解提供了细粒度的多时间尺度基准，有助于推动MLLM能力发展。


### [6] [Point-MoE: Towards Cross-Domain Generalization in 3D Semantic Segmentation via Mixture-of-Experts](https://arxiv.org/abs/2505.23926)
*Xuweiyi Chen,Wentao Zhou,Aruni RoyChowdhury,Zezhou Cheng*

Main category: cs.CV

TL;DR: Point-MoE提出了一种混合专家架构，用于解决3D点云数据跨域泛化问题，无需依赖域标签即可自动优化专家分工。

- Motivation: 3D点云数据因来源多样（如不同传感器和场景）导致域异质性，传统方法难以实现跨域统一建模。
- Method: 采用Mixture-of-Experts架构和简单的top-k路由策略，自动分配专家处理不同域数据。
- Result: Point-MoE在混合域数据上表现优于基线模型，且能更好地泛化到未见域。
- Conclusion: 通过模型自动发现数据结构的路径，为3D理解提供了可扩展的解决方案。


### [7] [Leveraging Auxiliary Information in Text-to-Video Retrieval: A Review](https://arxiv.org/abs/2505.23952)
*Adriano Fragomeni,Dima Damen,Michael Wray*

Main category: cs.CV

TL;DR: 该论文综述了81篇利用辅助信息改进文本到视频检索的研究，分析了方法、数据集及未来方向。

- Motivation: 传统方法仅对齐视频和文本模态，而辅助信息（如视觉属性、时空上下文等）能提升检索性能并弥合语义鸿沟。
- Method: 综述了81篇论文的方法论，包括辅助信息的提取和应用。
- Result: 总结了基准数据集上的最新成果，并分析了可用数据集及其辅助信息。
- Conclusion: 提出了未来研究方向，重点是利用辅助信息进一步提升检索性能。


### [8] [MangoLeafViT: Leveraging Lightweight Vision Transformer with Runtime Augmentation for Efficient Mango Leaf Disease Classification](https://arxiv.org/abs/2505.23961)
*Rafi Hassan Chowdhury,Sabbir Ahmed*

Main category: cs.CV

TL;DR: 本文提出了一种轻量级的Vision Transformer方法，用于芒果叶病害分类，具有高效计算和低端设备兼容性，准确率达99.43%。

- Motivation: 芒果种植因病害导致重大经济损失，现有深度学习方法在计算效率和低端设备兼容性上存在不足。
- Method: 采用轻量级Vision Transformer结合自注意力机制和运行时增强技术。
- Result: 在MangoLeafBD数据集上达到99.43%准确率，模型尺寸、参数和计算量均优于现有方法。
- Conclusion: 该方法为芒果叶病害分类提供了高效且轻量化的解决方案。


### [9] [VisualSphinx: Large-Scale Synthetic Vision Logic Puzzles for RL](https://arxiv.org/abs/2505.23977)
*Yichen Feng,Zhangchen Xu,Fengqing Jiang,Yuetai Li,Bhaskar Ramasubramanian,Luyao Niu,Bill Yuchen Lin,Radha Poovendran*

Main category: cs.CV

TL;DR: VisualSphinx是一个大规模合成的视觉逻辑推理训练数据集，旨在提升视觉语言模型（VLM）的逻辑推理能力。

- Motivation: 当前VLM缺乏大规模且结构化的训练数据，限制了其在多模态推理任务中的表现。
- Method: 提出了一种规则到图像的合成流程，通过提取和扩展谜题规则生成合成图像，并组装成训练样本。
- Result: 实验表明，使用VisualSphinx训练的VLM在逻辑推理任务中表现更优，且对其他推理任务（如代数、算术和几何推理）也有帮助。
- Conclusion: VisualSphinx填补了VLM训练数据的空白，显著提升了模型的逻辑推理能力。


### [10] [DeepTopoNet: A Framework for Subglacial Topography Estimation on the Greenland Ice Sheets](https://arxiv.org/abs/2505.23980)
*Bayu Adhi Tama,Mansa Krishna,Homayra Alam,Mostafa Cham,Omar Faruque,Gong Cheng,Jianwu Wang,Mathieu Morlighem,Vandana Janeja*

Main category: cs.CV

TL;DR: 本文提出了一种名为DeepTopoNet的深度学习框架，通过动态损失平衡机制整合雷达数据和BedMachine数据，以高精度重建格陵兰冰下地形。

- Motivation: 格陵兰冰下地形的准确理解对预测冰盖质量损失及其对全球海平面上升的贡献至关重要，但观测数据的稀疏性和复杂性增加了模型预测的不确定性。
- Method: 采用动态损失平衡机制结合雷达和BedMachine数据，利用梯度特征和趋势表面特征，设计CNN架构进行亚网格尺度预测。
- Result: 在Upernavik Isstrøm区域的测试中，模型表现出高精度，优于基线方法。
- Conclusion: 深度学习能有效填补观测空白，为冰下地形推断提供可扩展的高效解决方案。


### [11] [DGIQA: Depth-guided Feature Attention and Refinement for Generalizable Image Quality Assessment](https://arxiv.org/abs/2505.24002)
*Vaishnav Ramesh,Junliang Liu,Haining Wang,Md Jahidul Islam*

Main category: cs.CV

TL;DR: 论文提出了一种结合深度引导跨注意力和Transformer-CNN桥接的NR-IQA方法，显著提升了无参考图像质量评估的性能。

- Motivation: 解决无参考图像质量评估（NR-IQA）中缺乏对未知自然失真客观泛化能力的问题。
- Method: 提出Depth-CAR机制和TCB方法，结合深度信息和多模态注意力，优化特征学习。
- Result: DGIQA模型在合成和真实数据集上表现优异，尤其在跨数据集评估和自然失真评估中超越现有方法。
- Conclusion: Depth-CAR和TCB的结合显著提升了NR-IQA的性能和泛化能力。


### [12] [Preemptive Hallucination Reduction: An Input-Level Approach for Multimodal Language Model](https://arxiv.org/abs/2505.24007)
*Nokimul Hasan Arif,Shadman Rabby,Md Hefzul Hossain Papon,Sabbir Ahmed*

Main category: cs.CV

TL;DR: 本文提出了一种基于集成学习的预处理框架，通过自适应选择输入过滤方法，显著减少大型语言模型（LLMs）的视觉幻觉问题，无需修改模型架构或训练流程。

- Motivation: 视觉幻觉问题（模型生成与视觉输入不一致的响应）影响了LLMs的可靠性，尤其在需要精确输出的场景中。现有研究多关注事后修正或模型微调，而忽略了预处理技术的作用。
- Method: 提出了一种自适应预处理框架，根据问题类型选择噪声减少（NR）、边缘增强（EE）或原始输入（org），以减少幻觉问题。
- Result: 在`HaloQuest`数据集上测试，该方法使幻觉率降低了44.3%（基于NLI评分），表明仅通过智能输入调节即可显著提升模型的事实性。
- Conclusion: 自适应预处理技术对减少幻觉问题至关重要，为构建更可靠的多模态系统提供了新方向。


### [13] [Multi-Group Proportional Representation for Text-to-Image Models](https://arxiv.org/abs/2505.24023)
*Sangwon Jung,Alex Oesterling,Claudio Mayrink Verdun,Sajani Vithana,Taesup Moon,Flavio P. Calmon*

Main category: cs.CV

TL;DR: 本文提出了一种新框架MPR，用于测量T2I模型中交叉群体的代表性，并通过优化算法改善生成图像的多样性。

- Motivation: T2I模型可能加剧刻板印象或忽视少数群体，但目前缺乏系统方法来衡量和控制这种代表性危害。
- Method: 引入MPR指标评估生成图像中群体代表性的最坏偏差，并开发优化算法。
- Result: 实验表明MPR能有效测量多交叉群体的代表性，并指导模型生成更平衡的图像。
- Conclusion: MPR为T2I模型提供了一种灵活且可定制的代表性评估和优化方法。


### [14] [DINO-R1: Incentivizing Reasoning Capability in Vision Foundation Models](https://arxiv.org/abs/2505.24025)
*Chenbin Pan,Wenbin He,Zhengzhong Tu,Liu Ren*

Main category: cs.CV

TL;DR: DINO-R1首次尝试通过强化学习提升视觉基础模型的上下文推理能力，提出GRQO训练策略，显著优于传统方法。

- Motivation: 现有视觉基础模型（如DINO系列）缺乏推理能力，而大型语言模型（如DeepSeek-R1）已通过强化学习取得显著成果。
- Method: 提出GRQO策略，结合KL正则化稳定训练，并基于Grounding-DINO构建DINO-R1系列模型。
- Result: 在COCO、LVIS和ODinW数据集上，DINO-R1显著优于监督微调基线，泛化能力强。
- Conclusion: DINO-R1成功将强化学习应用于视觉模型推理，为视觉基础模型开辟新方向。


### [15] [MaskAdapt: Unsupervised Geometry-Aware Domain Adaptation Using Multimodal Contextual Learning and RGB-Depth Masking](https://arxiv.org/abs/2505.24026)
*Numair Nadeem,Muhammad Hamza Asad,Saeed Anwar,Abdul Bais*

Main category: cs.CV

TL;DR: MaskAdapt通过结合RGB图像和深度数据，提出了一种新的无监督域适应方法，显著提升了作物与杂草的语义分割精度。

- Motivation: 现有方法依赖像素级标注且难以适应不同农田的域偏移问题，导致在真实场景中分类错误。
- Method: 通过深度梯度提取空间信息，结合跨注意力机制优化RGB特征，并采用几何感知掩码策略增强空间上下文学习。
- Result: 在真实农田数据集上，MaskAdapt优于现有SOTA方法，分割mIOU显著提升。
- Conclusion: MaskAdapt通过多模态上下文学习有效解决了作物与杂草分割中的域适应问题。


### [16] [SIM: A mapping framework for built environment auditing based on street view imagery](https://arxiv.org/abs/2505.24076)
*Huan Ning,Zhenlong Li,Manzhu Yu,Wenpeng Yin*

Main category: cs.CV

TL;DR: 本文提出了一种基于街景图像的开源映射框架，用于自动测量和映射地面物体，提升建筑环境审计的效率和准确性。

- Motivation: 传统建筑环境审计依赖耗时且昂贵的人工调查，而现有基于街景图像的映射方法和工具尚未成熟，缺乏通用框架。
- Method: 开发了一个开源框架，提供三种管道：地面物体宽度测量、已知尺寸物体的3D定位以及直径测量。
- Result: 通过三个案例研究（道路宽度测量、停车标志定位和街道树木直径测量）验证了框架的实用性。
- Conclusion: 该框架为研究人员和城市规划者提供了自动化工具，显著提升了建筑环境审计的生产力和准确性。


### [17] [ComposeAnything: Composite Object Priors for Text-to-Image Generation](https://arxiv.org/abs/2505.24086)
*Zeeshan Khan,Shizhe Chen,Cordelia Schmid*

Main category: cs.CV

TL;DR: ComposeAnything 是一个新框架，通过利用 LLM 生成 2.5D 语义布局，并结合扩散模型，显著提升了复杂文本到图像生成的准确性和质量。

- Motivation: 当前文本到图像（T2I）模型在处理复杂对象排列时表现不佳，尤其是 3D 定位和一致性方面。
- Method: 利用 LLM 生成 2.5D 语义布局（包含深度信息的 2D 边界框和详细描述），并以此作为扩散模型的先验，通过对象先验增强和空间控制去噪生成图像。
- Result: 在 T2I-CompBench 和 NSR-1K 基准测试中表现优于现有方法，尤其在 2D/3D 空间排列、高对象数量和超现实组合方面。人类评估也证实其生成图像质量和文本一致性高。
- Conclusion: ComposeAnything 通过引入 2.5D 语义布局和先验引导，显著提升了复杂文本到图像生成的能力。


### [18] [Weakly-Supervised Affordance Grounding Guided by Part-Level Semantic Priors](https://arxiv.org/abs/2505.24103)
*Peiran Xu,Yadong Mu*

Main category: cs.CV

TL;DR: 本文提出了一种弱监督功能定位方法，利用伪标签和基础模型改进功能学习，显著提升了性能。

- Motivation: 现有方法基于类激活图，适用于语义分割但不适合定位动作和功能，因此需要更有效的方法。
- Method: 基于伪标签的监督训练流程，结合标签细化、细粒度特征对齐和轻量推理模块。
- Result: 实验表明，模型性能显著优于现有方法。
- Conclusion: 该方法通过基础模型的语义知识，有效连接对象与动作，实现了功能学习的突破。


### [19] [Federated Foundation Model for GI Endoscopy Images](https://arxiv.org/abs/2505.24108)
*Alina Devkota,Annahita Amireskandari,Joel Palko,Shyam Thakkar,Donald Adjeroh,Xiajun Jiang,Binod Bhattarai,Prashnna K. Gyawali*

Main category: cs.CV

TL;DR: 提出了一种联邦学习框架，用于训练胃肠内窥镜成像的基础模型，解决了医疗数据隐私问题，并在多个下游任务中验证了其有效性。

- Motivation: 解决医疗数据隐私限制下基础模型训练的挑战，同时提升胃肠内窥镜成像的诊断性能。
- Method: 采用联邦学习框架，评估多种联邦学习算法，在无需任务特定标签的情况下训练基础模型。
- Result: 在分类、检测和分割三个下游任务中，基础模型均表现出性能提升。
- Conclusion: 联邦学习框架在隐私保护环境下有效训练基础模型，为医疗影像分析提供了可行方案。


### [20] [CSVQA: A Chinese Multimodal Benchmark for Evaluating STEM Reasoning Capabilities of VLMs](https://arxiv.org/abs/2505.24120)
*Ai Jian,Weijie Qiu,Xiaokun Wang,Peiyu Wang,Yunzhuo Hao,Jiangbo Pei,Yichen Wei,Yi Peng,Xuchen Song*

Main category: cs.CV

TL;DR: CSVQA是一个专门用于评估科学推理的多模态基准测试，包含1,378个跨STEM领域的问题-答案对，强调领域知识和复杂推理。对15个VLM的评估显示性能差距显著，最高准确率仅49.6%。

- Motivation: 现有多模态基准测试缺乏对科学推理能力的评估，尤其是在需要领域知识和视觉证据分析的场景。
- Method: 提出CSVQA基准测试，包含精心设计的问题-答案对，并制定严格的评估协议，验证模型预测是否基于有效推理步骤。
- Result: 评估显示VLM在科学推理任务中表现不佳，最高准确率仅为49.6%。
- Conclusion: CSVQA突显了提升VLM科学推理能力的紧迫性，并为未来研究提供了基准。


### [21] [S4-Driver: Scalable Self-Supervised Driving Multimodal Large Language Modelwith Spatio-Temporal Visual Representation](https://arxiv.org/abs/2505.24139)
*Yichen Xie,Runsheng Xu,Tong He,Jyh-Jing Hwang,Katie Luo,Jingwei Ji,Hubert Lin,Letian Chen,Yiren Lu,Zhaoqi Leng,Dragomir Anguelov,Mingxing Tan*

Main category: cs.CV

TL;DR: S4-Driver是一种基于多模态大语言模型的自监督运动规划算法，通过稀疏体积策略将2D视觉表示转换为3D空间，无需微调视觉编码器，性能优于现有监督方法。

- Motivation: 现有端到端自动驾驶规划方法依赖人工标注或性能不足，且多模态大语言模型在2D图像空间预训练，与3D规划空间不匹配。
- Method: 提出S4-Driver，利用稀疏体积策略将PaLI模型的视觉表示从透视视图转换到3D空间，聚合多视角和多帧输入。
- Result: 在nuScenes和Waymo数据集上验证，S4-Driver性能优于监督方法，且无需人工标注，具有良好扩展性。
- Conclusion: S4-Driver填补了输入表示空间的空白，为自监督运动规划提供了高效解决方案。


### [22] [The Butterfly Effect in Pathology: Exploring Security in Pathology Foundation Models](https://arxiv.org/abs/2505.24141)
*Jiashuai Liu,Yingjia Shang,Yingkang Zhan,Di Zhang,Yi Niu,Dong Wei,Xian Wu,Zeyu Gao,Chen Li,Yefeng Zheng*

Main category: cs.CV

TL;DR: 该论文首次系统研究了病理学基础模型在全切片图像（WSI）分析中对抗攻击的脆弱性，提出了一种无需下游任务标签的攻击框架，并在实验中验证了其有效性。

- Motivation: 随着病理学基础模型在研究和临床决策支持系统中的广泛应用，其安全性问题日益突出，但对抗攻击的脆弱性尚未被充分研究。
- Method: 提出“局部扰动具有全局影响”的原则，设计了一种无需下游任务标签的攻击框架，并改进了四种经典白盒攻击方法。
- Result: 实验表明，仅修改0.1%的切片区域即可导致下游任务准确率下降高达20%，并分析了攻击成功的关键因素及防御策略。
- Conclusion: 该研究为病理学基础模型的对抗鲁棒性和可靠部署奠定了基础，代码已开源。


### [23] [Towards a Generalizable Bimanual Foundation Policy via Flow-based Video Prediction](https://arxiv.org/abs/2505.24156)
*Chenyou Fan,Fangzheng Yan,Chenjia Bai,Jiepeng Wang,Chi Zhang,Zhen Wang,Xuelong Li*

Main category: cs.CV

TL;DR: 提出了一种基于文本到视频模型的双臂操作策略，通过两阶段范式（文本到光流和光流到视频）减少数据需求并提高泛化能力。

- Motivation: 双臂操作策略由于动作空间大和协调需求难以泛化，现有方法依赖单臂数据或预训练模型效果不佳。
- Method: 微调文本到视频模型预测轨迹，训练轻量扩散策略生成动作；引入两阶段范式（文本到光流和光流到视频）以减少语言歧义。
- Result: 在仿真和真实双臂机器人实验中验证了方法的有效性。
- Conclusion: 两阶段范式显著减少了机器人数据需求并提高了双臂操作的泛化能力。


### [24] [Threading Keyframe with Narratives: MLLMs as Strong Long Video Comprehenders](https://arxiv.org/abs/2505.24158)
*Bo Fang,Wenhao Wu,Qiangqiang Wu,Yuxin Song,Antoni B. Chan*

Main category: cs.CV

TL;DR: Nar-KFC是一种用于长视频理解的即插即用模块，通过关键帧选择和文本叙事插入，解决了视觉标记过多与语言模型上下文长度有限的矛盾。

- Motivation: 长视频理解中，视觉标记过多与语言模型上下文长度有限的矛盾导致传统方法效率低下或内容不相关。
- Method: Nar-KFC通过整数二次规划优化关键帧选择，并插入非关键帧生成的文本叙事，形成紧凑表示。
- Result: 在多个长视频基准测试中，Nar-KFC显著提升了多模态大语言模型的性能。
- Conclusion: Nar-KFC为长视频理解提供了一种高效且内容感知的压缩策略。


### [25] [Training-free zero-shot 3D symmetry detection with visual features back-projected to geometry](https://arxiv.org/abs/2505.24162)
*Isaac Aguirre,Ivan Sipiran*

Main category: cs.CV

TL;DR: 提出一种无需训练的零样本3D对称检测方法，利用DINOv2等基础视觉模型的特征，通过渲染视图提取特征并反向投影到几何体上，实现对称性检测。

- Motivation: 传统几何方法和基于学习的方法在3D对称检测中存在局限性，需要训练数据或复杂计算。本文旨在利用基础视觉模型的强大特征提取能力，简化对称检测流程。
- Method: 从3D对象的渲染视图中提取视觉特征，反向投影到几何体上，利用这些特征的对称不变性，通过算法识别反射对称平面。
- Result: 在ShapeNet子集上的实验表明，该方法优于传统几何方法和基于学习的方法，且无需训练数据。
- Conclusion: 基础视觉模型可用于解决复杂的3D几何问题，如对称检测，展示了其潜力。


### [26] [Pretraining Deformable Image Registration Networks with Random Images](https://arxiv.org/abs/2505.24167)
*Junyu Chen,Shuwen Wei,Yihao Liu,Aaron Carass,Yong Du*

Main category: cs.CV

TL;DR: 利用随机图像配准作为预训练任务，提升医学图像配准的准确性和效率。

- Motivation: 探索无需医学图像的深度学习预训练方法，以减少领域特定数据需求并提高计算效率。
- Method: 使用随机生成的图像及其配准作为预训练任务，构建基础模型。
- Result: 预训练策略提高了配准准确性，减少了下游任务的数据需求，并加速了收敛。
- Conclusion: 随机图像配准预训练是一种有效的策略，可提升医学图像配准的性能和效率。


### [27] [DrVD-Bench: Do Vision-Language Models Reason Like Human Doctors in Medical Image Diagnosis?](https://arxiv.org/abs/2505.24173)
*Tianhong Zhou,Yin Xu,Yingtao Zhu,Chuxi Xiao,Haiyang Bian,Lei Wei,Xuegong Zhang*

Main category: cs.CV

TL;DR: DrVD-Bench是一个新的多模态基准测试，用于评估视觉语言模型在临床视觉推理中的表现，发现现有模型在复杂推理任务中表现不佳，仍依赖表面模式而非真实理解。

- Motivation: 现有基准测试未能系统评估视觉语言模型是否真正具备类似临床医生的推理能力，还是仅模仿表面模式。
- Method: 提出DrVD-Bench，包含三个模块（视觉证据理解、推理轨迹评估和报告生成评估），涵盖7,789个图像-问题对，覆盖20种任务类型和17种诊断类别。
- Result: 测试19个视觉语言模型发现，随着推理复杂性增加，性能显著下降，部分模型开始展现类似人类的推理迹象，但仍依赖表面相关性。
- Conclusion: DrVD-Bench为开发可信赖的临床视觉语言模型提供了严格的评估框架。


### [28] [Seeing is Not Reasoning: MVPBench for Graph-based Evaluation of Multi-path Visual Physical CoT](https://arxiv.org/abs/2505.24182)
*Zhuobai Dong,Junchao Yi,Ziyuan Zheng,Haochen Han,Xiangxi Zheng,Alex Jinpeng Wang,Fangming Liu,Linjie Li*

Main category: cs.CV

TL;DR: MVPBench是一个评估多模态大语言模型（MLLMs）视觉物理推理能力的基准，发现当前先进模型在复杂场景中难以理解物理规律和因果推理。

- Motivation: 研究揭示MLLMs在视觉物理推理方面表现不佳，缺乏对物理规律和因果关系的理解，需开发更严格的评估方法。
- Method: 引入MVPBench基准，通过视觉链式推理（CoT）评估模型，要求逐步推理并依赖视觉线索，同时设计图式一致性指标验证推理逻辑。
- Result: 实验显示即使最先进的MLLMs在视觉推理和图像-文本对齐方面表现差，且强化学习后训练可能损害空间推理能力。
- Conclusion: 当前MLLMs在视觉物理推理上存在显著缺陷，需重新思考模型微调方法以提升性能。


### [29] [Boosting All-in-One Image Restoration via Self-Improved Privilege Learning](https://arxiv.org/abs/2505.24207)
*Gang Wu,Junjun Jiang,Kui Jiang,Xianming Liu*

Main category: cs.CV

TL;DR: SIPL通过利用自身输出作为伪特权信号，在推理阶段实现自我优化，显著提升图像修复性能。

- Motivation: 解决统一图像修复模型在多样化和混合退化任务中的优化不稳定性和任务间冲突问题。
- Method: 提出SIPL范式，引入Proxy Fusion模块和特权字典，在训练和推理阶段利用特权信息进行自我改进。
- Result: 在多项基准测试中表现优异，PSNR提升显著（如+4.58 dB）。
- Conclusion: SIPL是一种高效且广泛适用的图像修复方法，能无缝集成到多种架构中。


### [30] [STORK: Improving the Fidelity of Mid-NFE Sampling for Diffusion and Flow Matching Models](https://arxiv.org/abs/2505.24210)
*Zheng Tan,Weizhen Wang,Andrea L. Bertozzi,Ernest K. Ryu*

Main category: cs.CV

TL;DR: 提出了一种名为STORK的新型训练自由、结构无关的DM ODE求解器，适用于中NFE范围（20-50 NFE），提升了生成质量。

- Motivation: 扩散模型在高NFE下生成质量高但速度慢，中NFE范围（20-50 NFE）在实际应用中常见但研究不足。
- Method: 基于泰勒展开和刚性ODE求解器，提出STORK方法，适用于任何DM采样。
- Result: 在20-50 NFE范围内，STORK在无条件像素级和条件潜空间生成任务中提升了FID分数。
- Conclusion: STORK是一种高效且通用的DM ODE求解器，适用于中NFE范围，显著提升生成质量。


### [31] [Benchmarking Foundation Models for Zero-Shot Biometric Tasks](https://arxiv.org/abs/2505.24214)
*Redwan Sony,Parisa Farmanifard,Hamzeh Alzwairy,Nitish Shukla,Arun Ross*

Main category: cs.CV

TL;DR: 论文评估了41种视觉语言模型和多模态大语言模型在六种生物识别任务中的零样本和少样本性能，展示了这些模型在无需微调的情况下取得的高准确率。

- Motivation: 探索基础模型（如视觉语言模型和多模态大语言模型）在生物识别任务中的潜力，填补这一领域的研究空白。
- Method: 通过构建一个综合基准，评估41种模型在六种生物识别任务（如人脸验证、虹膜识别等）中的性能，并测试简单分类器头的效果。
- Result: 模型在多项任务中表现优异，例如人脸验证在LFW数据集上达到96.77%的TMR（FMR为1%），虹膜识别在IITD-R-Full数据集上达到97.55%的TMR。
- Conclusion: 预训练模型在生物识别任务中表现出色，为实现通用人工智能的长期目标提供了支持。


### [32] [Shuffle PatchMix Augmentation with Confidence-Margin Weighted Pseudo-Labels for Enhanced Source-Free Domain Adaptation](https://arxiv.org/abs/2505.24216)
*Prasanna Reddy Pulakurthi,Majid Rabbani,Jamison Heard,Sohail Dianat,Celso M. de Melo,Raghuveer Rao*

Main category: cs.CV

TL;DR: 论文提出了一种无源域自适应（SFDA）方法，结合了新的增强技术Shuffle PatchMix（SPM）和伪标签重加权策略，显著提升了性能。

- Motivation: 解决无源数据条件下模型适应目标域的问题，特别是在小数据集上避免过拟合和伪标签噪声。
- Method: 引入SPM技术通过打乱和混合图像块生成多样化增强数据，并结合伪标签重加权策略优化可靠性。
- Result: 在PACS、VisDA-C和DomainNet-126三个基准上取得最优结果，PACS上提升7.3%（单目标）和7.2%（多目标）。
- Conclusion: SPM和伪标签重加权策略为SFDA设定了新基准，代码已开源。


### [33] [Unleashing High-Quality Image Generation in Diffusion Sampling Using Second-Order Levenberg-Marquardt-Langevin](https://arxiv.org/abs/2505.24222)
*Fangyikang Wang,Hubery Yin,Lei Qian,Yinan Li,Shaobin Zhuang,Huminhao Zhu,Yilin Zhang,Yanlong Tang,Chao Zhang,Hanbin Zhao,Hui Qian,Chen Li*

Main category: cs.CV

TL;DR: 论文提出了一种名为LML的新方法，通过低秩近似和阻尼机制高效利用扩散模型的Hessian几何，显著提升图像生成质量，且计算开销极小。

- Motivation: 当前扩散模型采样技术主要依赖一阶Langevin动力学，但直接利用Hessian几何会导致计算复杂度高，难以扩展。
- Method: 提出LML方法，通过低秩近似扩散Hessian几何和阻尼机制，避免显式二次复杂度计算。
- Result: 实验表明，LML方法显著提升了图像生成质量，且计算开销可忽略。
- Conclusion: LML方法为扩散模型的高效采样提供了新思路，具有理论和实践价值。


### [34] [Reasoning Can Hurt the Inductive Abilities of Large Language Models](https://arxiv.org/abs/2505.24225)
*Haibo Jin,Peiyan Zhang,Man Luo,Haohan Wang*

Main category: cs.CV

TL;DR: 研究发现，链式思维（CoT）提示可能降低大型语言模型（LLM）的归纳推理能力，而非增强。通过理论框架和实验分析，提出了结构化干预方法以改进推理效果。

- Motivation: 探究链式思维（CoT）提示是否真的能提升大型语言模型（LLM）的归纳推理能力。
- Method: 设计了四种基于游戏的诊断任务（如国际象棋、德州扑克等），对比分析CoT推理与非推理模型的性能差异。
- Result: 发现CoT推理可能降低归纳推理性能，并提出了三种失败模式的理论框架。通过结构化干预，无需重新训练即可提升推理准确性。
- Conclusion: 有效的CoT推理不仅需要更多步骤，还需确保步骤结构合理。


### [35] [Light as Deception: GPT-driven Natural Relighting Against Vision-Language Pre-training Models](https://arxiv.org/abs/2505.24227)
*Ying Yang,Jie Zhang,Xiao Lv,Di Lin,Tao Xiang,Qing Guo*

Main category: cs.CV

TL;DR: LightD是一个通过语义引导的重新照明生成自然对抗样本的框架，适用于视觉与语言预训练模型，解决了现有方法在优化空间受限和生成不自然扰动上的问题。

- Motivation: 现有的对抗攻击方法主要针对分类任务，难以适应视觉与语言预训练模型，且生成的扰动往往不自然或语义不相关。
- Method: LightD利用ChatGPT提出上下文感知的初始照明参数，并结合预训练的重新照明模型（IC-light）进行多样化照明调整，同时通过梯度优化增强攻击效果。
- Result: LightD在图像描述和视觉问答等任务中表现出色，优于现有方法。
- Conclusion: LightD通过语义引导的重新照明，成功生成了自然且有效的对抗样本，为视觉与语言预训练模型的对抗攻击提供了新思路。


### [36] [From Hallucinations to Jailbreaks: Rethinking the Vulnerability of Large Foundation Models](https://arxiv.org/abs/2505.24232)
*Haibo Jin,Peiyan Zhang,Peiran Wang,Man Luo,Haohan Wang*

Main category: cs.CV

TL;DR: 论文提出了一个统一的理论框架，将越狱攻击和幻觉问题分别建模为令牌级和注意力级优化，并验证了两者在损失收敛和梯度一致性上的相似性。

- Motivation: 大型基础模型（LFMs）存在幻觉和越狱攻击两种漏洞，研究发现针对一种漏洞的防御措施会影响另一种，暗示两者存在深层联系。
- Method: 提出统一理论框架，将越狱攻击和幻觉问题分别建模为令牌级和注意力级优化，并通过实验验证损失收敛和梯度一致性。
- Result: 在LLaVA-1.5和MiniGPT-4上验证了两者的优化趋势和梯度一致性，并发现缓解幻觉的技术可降低越狱攻击成功率。
- Conclusion: 研究揭示了LFMs的共享失败模式，建议鲁棒性策略应同时应对两种漏洞。


### [37] [MIRAGE: Assessing Hallucination in Multimodal Reasoning Chains of MLLM](https://arxiv.org/abs/2505.24238)
*Bowen Dong,Minheng Ni,Zitong Huang,Guanglei Yang,Wangmeng Zuo,Lei Zhang*

Main category: cs.CV

TL;DR: 论文提出了一种新的基准{\dataset}，用于区分多模态大语言模型（MLLMs）中的感知诱导幻觉和推理诱导幻觉，并提出了{\method}方法来减少逻辑幻觉。

- Motivation: 多模态幻觉限制了MLLMs的正确性，且现有基准无法区分感知和推理诱导的幻觉，阻碍了诊断和改进。
- Method: 提出{\dataset}基准，通过构建正确感知但推理错误的问题来隔离推理幻觉，并引入多粒度评估指标。提出{\method}方法，结合课程强化微调和协作提示推理。
- Result: 模型规模、数据规模和训练阶段显著影响幻觉程度；当前MLLMs在空间幻觉上无改进；问题类型与幻觉模式相关。
- Conclusion: {\method}在{\dataset}上建立了基线，减少了逻辑幻觉，为改进MLLMs提供了方向。


### [38] [LTM3D: Bridging Token Spaces for Conditional 3D Generation with Auto-Regressive Diffusion Framework](https://arxiv.org/abs/2505.24245)
*Xin Kang,Zihan Zheng,Lei Chu,Yue Gao,Jiahao Li,Hao Pan,Xuejin Chen,Yan Lu*

Main category: cs.CV

TL;DR: LTM3D是一个结合扩散模型和自回归模型的3D形状生成框架，通过条件分布建模和前缀学习提升生成效果，支持多种3D表示形式。

- Motivation: 结合扩散模型和自回归模型的优势以解决3D形状生成中的挑战，提升生成形状的灵活性和结构保真度。
- Method: 使用条件分布建模主干网络（掩码自编码器和扩散模型）、前缀学习和潜在令牌重建模块，支持多种3D表示形式。
- Result: 在图像和文本条件生成任务中表现优异，优于现有方法，生成形状的提示保真度和结构准确性更高。
- Conclusion: LTM3D提供了一个通用的多模态、多表示3D生成框架，具有高灵活性和结构保真度。


### [39] [50 Years of Automated Face Recognition](https://arxiv.org/abs/2505.24247)
*Minchul Kim,Anil Jain,Xiaoming Liu*

Main category: cs.CV

TL;DR: 论文回顾了50年来人脸识别技术的发展，从早期几何方法到现代深度学习模型，探讨了关键创新和数据集对模型性能的影响，并指出未来研究方向。

- Motivation: 总结人脸识别技术的演进历程，分析关键技术进步及其对性能的影响，为未来研究提供方向。
- Method: 通过历史回顾和技术分析，梳理了从几何统计方法到深度学习模型的演进，重点讨论了数据集、损失函数和网络设计的创新。
- Result: 现代人脸识别系统在NIST FRVT评估中达到0.13%的误识率，展示了高性能，但仍存在挑战。
- Conclusion: 尽管技术取得显著进展，仍需解决可扩展性、多模态融合等问题，未来研究应关注这些方向。


### [40] [Harnessing Foundation Models for Robust and Generalizable 6-DOF Bronchoscopy Localization](https://arxiv.org/abs/2505.24249)
*Qingyao Tian,Huai Liao,Xinyan Huang,Bingyu Yang,Hongbin Liu*

Main category: cs.CV

TL;DR: PANSv2提出了一种通用且鲁棒的支气管镜定位框架，通过整合深度估计、标志点检测和中心线约束，解决了现有方法在泛化和视觉退化方面的不足。

- Motivation: 现有支气管镜定位方法泛化能力差且对视觉退化（如遮挡和运动模糊）鲁棒性不足。
- Method: PANSv2结合深度估计（EndoOmni）、标志点检测（EndoMamba）和中心线约束，并引入自动重新初始化模块以应对视觉退化。
- Result: 在10例患者数据上，PANSv2的跟踪成功率最高，SR-5指标提升18.1%。
- Conclusion: PANSv2在泛化能力和鲁棒性上表现优异，具有临床应用的潜力。


### [41] [Interactive Video Generation via Domain Adaptation](https://arxiv.org/abs/2505.24253)
*Ishaan Rawal,Suryansh Kumar*

Main category: cs.CV

TL;DR: 本文提出两种方法（掩码归一化和时序内在扩散先验）以解决交互式视频生成中的感知质量下降和轨迹控制问题。

- Motivation: 交互式视频生成（IVG）中，现有方法通过注意力掩码引导轨迹，但会导致感知质量下降。本文将其归因于域偏移问题，并提出解决方案。
- Method: 1. 掩码归一化：通过分布匹配缓解注意力掩码引起的内部协变量偏移。2. 时序内在扩散先验：确保初始噪声与IVG条件对齐，增强时空一致性。
- Result: 实验表明，掩码归一化和时序内在扩散显著提升了感知质量和轨迹控制，优于现有IVG技术。
- Conclusion: 通过域适应方法，本文成功解决了IVG中的关键问题，为高质量交互式视频生成提供了新思路。


### [42] [Out of Sight, Not Out of Context? Egocentric Spatial Reasoning in VLMs Across Disjoint Frames](https://arxiv.org/abs/2505.24257)
*Sahithya Ravi,Gabriel Sarch,Vibhav Vineet,Andrew D. Wilson,Balasaravanan Thoravi Kumaravel*

Main category: cs.CV

TL;DR: Disjoint-3DQA是一个评估视觉语言模型（VLMs）在非共视帧中空间推理能力的生成式QA基准，发现现有模型与人类表现差距显著，尤其在时间间隔增大时性能下降明显。

- Motivation: 研究动机是评估VLMs在长时间跨度的空间推理能力，特别是在物体不共视的情况下，以推动视觉、语言和具身AI的交叉研究。
- Method: 通过Disjoint-3DQA基准测试，对七种先进VLMs进行评估，并分析提供轨迹、鸟瞰图或3D坐标对性能的影响。
- Result: 模型表现比人类低28%，时间间隔增大时性能下降更显著（60%到30%）。提供3D坐标可显著提升20%性能，而轨迹或鸟瞰图效果有限。
- Conclusion: Disjoint-3DQA揭示了VLMs在多帧视觉信号中构建和维护3D场景表示的核心瓶颈，为长期空间推理研究设定了明确挑战。


### [43] [LLM-powered Query Expansion for Enhancing Boundary Prediction in Language-driven Action Localization](https://arxiv.org/abs/2505.24282)
*Zirui Shang,Xinxiao Wu,Shuo Yang*

Main category: cs.CV

TL;DR: 论文提出通过LLMs扩展语言查询以减少边界不确定性，并建模边界概率分数以提高训练稳定性，方法通用且有效。

- Motivation: 语言查询通常缺乏动作边界的具体细节，导致标注主观性和训练数据边界不确定性。
- Method: 1. 通过LLMs生成动作边界的文本描述以扩展查询；2. 建模边界概率分数，结合语义相似性和时间距离。
- Result: 实验证明方法在多个数据集上有效。
- Conclusion: 提出的方法通用且易于集成，显著减少边界不确定性并提升训练稳定性。


### [44] [EgoExOR: An Ego-Exo-Centric Operating Room Dataset for Surgical Activity Understanding](https://arxiv.org/abs/2505.24287)
*Ege Özsoy,Arda Mamur,Felix Tristram,Chantal Pellegrini,Magdalena Wysocki,Benjamin Busam,Nassir Navab*

Main category: cs.CV

TL;DR: EgoExOR是首个结合第一人称和第三人称视角的手术室数据集，提供多模态数据，支持临床交互建模。

- Motivation: 现有数据集仅提供部分视角，缺乏全面的多视角结合，EgoExOR填补了这一空白。
- Method: 数据集包含94分钟的两类脊柱手术数据，整合了穿戴设备和RGB-D相机的多模态数据，并标注了详细的场景图。
- Result: 评估了两种先进模型的性能，并提出了新的基线方法，利用多模态和多视角信号。
- Conclusion: EgoExOR为手术室感知提供了新的基础，是下一代临床感知的丰富资源。


### [45] [Category-aware EEG image generation based on wavelet transform and contrast semantic loss](https://arxiv.org/abs/2505.24301)
*Enshang Zhang,Zhicheng Zhang,Takashi Hanakawa*

Main category: cs.CV

TL;DR: 提出了一种基于Transformer的EEG信号编码器，结合DWT和门控机制，用于从EEG信号中提取视觉刺激特征，并通过预训练扩散模型重建视觉刺激。实验表明，该模型在语义对齐和分类准确率上显著优于现有方法。

- Motivation: 实现脑机接口的关键步骤是从EEG信号中重建视觉刺激，现有方法在语义层面的定量分析存在局限性。
- Method: 使用Transformer编码器结合DWT和门控机制提取EEG特征，并通过预训练扩散模型重建视觉刺激。提出了一种基于WordNet的语义评分方法。
- Result: 在THINGS-EEG数据集上，模型在单被试分类任务中达到43%的准确率，显著优于现有方法。
- Conclusion: 该方法在语义对齐和分类任务中表现优异，为脑机接口的视觉刺激重建提供了新思路。


### [46] [Progressive Class-level Distillation](https://arxiv.org/abs/2505.24310)
*Jiayan Li,Jun Li,Zhourui Zhang,Jianhua Xu*

Main category: cs.CV

TL;DR: 提出了一种名为渐进式类别级蒸馏（PCD）的新方法，通过分阶段蒸馏解决传统知识蒸馏中低概率类别信息被忽视的问题。

- Motivation: 传统知识蒸馏方法中，高置信度类别主导蒸馏过程，导致低概率类别的区分信息被忽视，知识传递不充分。
- Method: PCD方法通过排名教师-学生logits差异确定蒸馏优先级，分阶段进行双向蒸馏（从细到粗和从粗到细），实现充分的知识对齐。
- Result: 在公开基准数据集上的实验表明，PCD在分类和检测任务上优于现有方法。
- Conclusion: PCD通过分阶段蒸馏和双向学习策略，有效提升了知识蒸馏的效果。


### [47] [InteractAnything: Zero-shot Human Object Interaction Synthesis via LLM Feedback and Object Affordance Parsing](https://arxiv.org/abs/2505.24315)
*Jinlu Zhang,Yixin Chen,Zan Wang,Jie Yang,Yizhou Wang,Siyuan Huang*

Main category: cs.CV

TL;DR: 提出了一种零样本3D HOI生成框架，利用预训练模型解决开放集对象生成问题。

- Motivation: 现有方法难以从文本生成新颖的HOI，尤其是开放集对象，需解决关系推理、功能解析和姿态合成问题。
- Method: 利用LLM推断关系，2D扩散模型解析对象，多视角SDS生成初始姿态，并通过优化实现精细交互。
- Result: 实验表明方法在交互细节和开放集对象处理上优于现有工作。
- Conclusion: 框架有效解决了3D HOI生成的挑战，适用于开放集对象。


### [48] [STAR-Net: An Interpretable Model-Aided Network for Remote Sensing Image Denoising](https://arxiv.org/abs/2505.24327)
*Jingjing Liu,Jiashun Jin,Xianchao Xiu,Jianhua Zhang,Wanquan Liu*

Main category: cs.CV

TL;DR: 提出了一种名为STAR-Net的新型遥感图像去噪方法，结合低秩先验和非局部自相似性，并通过ADMM引导的深度展开网络自动学习参数，显著提升了去噪性能和鲁棒性。

- Motivation: 当前深度学习方法缺乏物理信息模型的结合，且对非局部自相似性关注不足，参数调优繁琐，导致解释性和性能受限。
- Method: 提出STAR-Net和其稀疏变体STAR-Net-S，利用低秩先验捕获非局部自相似性，并通过ADMM引导的深度展开网络自动学习参数。
- Result: 在合成和真实数据集上的实验表明，STAR-Net和STAR-Net-S优于现有最先进的去噪方法。
- Conclusion: STAR-Net成功结合了模型驱动和数据驱动方法的优势，解决了现有方法的不足，提升了去噪性能和鲁棒性。


### [49] [DisTime: Distribution-based Time Representation for Video Large Language Models](https://arxiv.org/abs/2505.24329)
*Yingsen Zeng,Zepeng Huang,Yujie Zhong,Chengjian Feng,Jie Hu,Lin Ma,Yang Liu*

Main category: cs.CV

TL;DR: DisTime是一个轻量级框架，通过连续时间嵌入和分布式时间解码器提升Video-LLMs的时间定位能力，并利用自动化标注生成大规模数据集InternVid-TG。

- Motivation: 现有Video-LLMs在时间定位上存在离散时间表示和数据集不足的问题，DisTime旨在解决这些问题。
- Method: DisTime采用可学习令牌生成连续时间嵌入，并使用分布式时间解码器生成时间概率分布，同时提出自动化标注方法生成数据集InternVid-TG。
- Result: DisTime在三个时间敏感任务中达到SOTA性能，并在Video QA任务中保持竞争力。
- Conclusion: DisTime通过连续时间表示和自动化标注显著提升了Video-LLMs的时间定位能力。


### [50] [KairosAD: A SAM-Based Model for Industrial Anomaly Detection on Embedded Devices](https://arxiv.org/abs/2505.24334)
*Uzair Khan,Franco Fummi,Luigi Capogrosso*

Main category: cs.CV

TL;DR: KairosAD是一种基于MobileSAM的新型监督学习方法，用于图像异常检测，适用于资源受限的嵌入式设备，参数减少78%，推理速度快4倍，性能与现有模型相当。

- Motivation: 解决现有异常检测模型在资源受限的嵌入式设备上部署困难的问题，特别是针对中小企业的生产线需求。
- Method: 利用Mobile Segment Anything Model (MobileSAM)进行图像异常检测，并在MVTec-AD和ViSA数据集上评估。
- Result: KairosAD参数减少78%，推理速度快4倍，AUROC性能与现有模型相当，成功部署于NVIDIA Jetson NX和AGX设备及真实生产线。
- Conclusion: KairosAD为资源受限设备提供了一种高效、实用的异常检测解决方案，适用于中小企业生产线。


### [51] [GeoVision Labeler: Zero-Shot Geospatial Classification with Vision and Language Models](https://arxiv.org/abs/2505.24340)
*Gilles Quentin Hacheme,Girmaw Abebe Tadesse,Caleb Robinson,Akram Zaytar,Rahul Dodhia,Juan M. Lavista Ferres*

Main category: cs.CV

TL;DR: GeoVision Labeler (GVL) 是一个严格零样本分类框架，通过视觉大语言模型生成图像描述，再映射到用户定义的类别，实现灵活的地球影像分类。

- Motivation: 解决地球影像分类中标注数据稀缺的问题，提供无需任务特定预训练的零样本分类方案。
- Method: GVL 结合视觉大语言模型生成图像描述，再用常规大语言模型映射到用户定义的类别，支持递归聚类和层次分类。
- Result: 在 SpaceNet v7 上达到 93.2% 的零样本准确率，在多类分类任务中表现竞争性。
- Conclusion: GVL 是一种模块化、可解释的零样本分类工具，适用于多种地球影像应用。


### [52] [KEVER^2: Knowledge-Enhanced Visual Emotion Reasoning and Retrieval](https://arxiv.org/abs/2505.24342)
*Fanhang Man,Xiaoyue Chen,Huandong Wang,Baining Zhao,Han Li,Xinlei Chen,Yong Li*

Main category: cs.CV

TL;DR: 论文提出K-EVER²框架，通过知识增强解决视觉情感分析中的抽象性和模糊性问题，无需人工标注即可实现稳健的情感预测。

- Motivation: 图像中的情感线索抽象且复杂，现有视觉语言模型难以准确建模和解释，且缺乏结构化情感知识。
- Method: 引入语义结构化的视觉情感线索表达，并通过多模态对齐整合外部情感知识。
- Result: 在三个基准测试中显著优于基线模型，最高提升19%的准确率，平均提升12.3%。
- Conclusion: K-EVER²为视觉内容的情感理解提供了可扩展且通用的解决方案。


### [53] [VUDG: A Dataset for Video Understanding Domain Generalization](https://arxiv.org/abs/2505.24346)
*Ziyi Wang,Zhi Gao,Boxuan Yu,Zirui Dai,Yuxiang Song,Qingyuan Lu,Jin Chen,Xinxiao Wu*

Main category: cs.CV

TL;DR: 论文提出VUDG数据集，用于评估视频理解中的领域泛化性能，包含11个领域和三种领域偏移，实验显示现有模型在领域偏移下性能下降。

- Motivation: 现有视频理解研究忽视真实应用中的领域偏移，领域泛化问题未充分探索。
- Method: 提出VUDG数据集，采用多专家渐进标注框架，包含多选和开放式问答对。
- Result: 实验表明多数模型（包括SOTA LVLMs）在领域偏移下性能下降。
- Conclusion: VUDG为领域泛化视频理解研究提供了宝贵资源。


### [54] [Revisiting Cross-Modal Knowledge Distillation: A Disentanglement Approach for RGBD Semantic Segmentation](https://arxiv.org/abs/2505.24361)
*Roger Ferrod,Cássio F. Dantas,Luigi Di Caro,Dino Ienco*

Main category: cs.CV

TL;DR: CroDiNo-KD提出了一种新的跨模态知识蒸馏框架，通过解耦表示、对比学习和数据增强来优化RGBD语义分割任务，挑战了传统的教师/学生范式。

- Motivation: 解决传统跨模态知识蒸馏框架在教师架构选择和蒸馏过程中的局限性，以应对实际场景中多模态数据在训练和推理阶段的不匹配问题。
- Method: 利用解耦表示、对比学习和解耦数据增强，同时学习单模态RGB和深度模型，通过交互和协作结构化神经网络模型的内部流形。
- Result: 在三个RGBD数据集上的实验表明，CroDiNo-KD优于现有跨模态知识蒸馏框架。
- Conclusion: CroDiNo-KD的成功表明需要重新思考传统的教师/学生范式，以更有效地从多模态数据中提取知识到单模态网络。


### [55] [Grid-LOGAT: Grid Based Local and Global Area Transcription for Video Question Answering](https://arxiv.org/abs/2505.24371)
*Md Intisar Chowdhury,Kittinun Aukkapinyo,Hiroshi Fujimura,Joo Ann Woo,Wasu Wasusatein,Fadoua Ghourabi*

Main category: cs.CV

TL;DR: Grid-LoGAT系统通过网格化视觉提示和边缘-云协作，在视频问答任务中表现优异。

- Motivation: 解决视频问答中图像隐私保护和转录质量提升的问题。
- Method: 分两阶段：1）使用VLM从视频帧提取文本转录；2）通过LLM处理问题生成答案。采用网格化视觉提示优化转录质量。
- Result: 在NExT-QA和STAR-QA数据集上分别达到65.9%和50.11%的准确率，优于非网格版本24分。
- Conclusion: Grid-LoGAT在隐私保护和性能上均表现优异，适用于视频问答任务。


### [56] [D2AF: A Dual-Driven Annotation and Filtering Framework for Visual Grounding](https://arxiv.org/abs/2505.24372)
*Yichi Zhang,Gongwei Chen,Jun Zhu,Jia Wan*

Main category: cs.CV

TL;DR: 论文提出D2AF框架，通过双驱动标注策略生成视觉定位任务的伪标签，克服数据规模限制并提升多样性。实验证明其显著提升模型性能。

- Motivation: 视觉定位任务依赖大规模标注数据，但人工标注成本高，现有伪标签方法依赖原始数据集标注，限制了扩展性和多样性。
- Method: 利用多模态大模型和物体检测模型，采用封闭集和开放集双驱动策略生成区域-文本对，并提出一致性及分布感知过滤方法优化数据质量。
- Result: 实验表明，增加数据量提升性能，但提升程度取决于伪标签对原始数据分布的扩展效果。过滤方法有效消除噪声数据。
- Conclusion: D2AF框架显著提升视觉定位任务性能，达到最先进水平。


### [57] [Spatiotemporal Analysis of Forest Machine Operations Using 3D Video Classification](https://arxiv.org/abs/2505.24375)
*Maciej Wielgosz,Simon Berg,Heikki Korpunen,Stephan Hoffmann*

Main category: cs.CV

TL;DR: 本文提出了一种基于深度学习的框架，用于从行车记录仪视频中分类林业操作。该方法使用3D ResNet-50架构，在手动标注的数据集上训练，取得了较高的性能（F1分数0.88，精确度0.90）。

- Motivation: 旨在利用AI技术减少林业操作中传统时间研究的手动工作量，为林业监测和效率分析提供可扩展的解决方案。
- Method: 采用3D ResNet-50架构，结合PyTorchVideo实现，并应用标准预处理和数据增强技术。
- Result: 模型在验证集上表现优异（F1分数0.88，精确度0.90），但存在过拟合问题。
- Conclusion: 该方法展示了在林业环境中捕捉时空特征的潜力，未来计划扩展数据集、改进正则化，并部署到嵌入式系统中。


### [58] [SASP: Strip-Aware Spatial Perception for Fine-Grained Bird Image Classification](https://arxiv.org/abs/2505.24380)
*Zheng Wang*

Main category: cs.CV

TL;DR: 本文提出了一种基于条带感知空间感知的细粒度鸟类分类框架，通过捕捉图像中的长距离空间依赖关系，提升模型的鲁棒性和可解释性。

- Motivation: 细粒度鸟类图像分类（FBIC）在生态监测和物种识别中具有重要意义，但由于鸟类大小、背景干扰和姿态变化等因素，传统方法难以稳定提取判别性特征。
- Method: 提出了一种结合扩展感知聚合器（EPA）和通道语义编织（CSW）的框架，通过整合局部和全局信息以及长距离和短距离语义信息，增强特征提取能力。
- Result: 在CUB-200-2011数据集上的实验表明，该方法显著提升了性能，同时保持了架构的高效性。
- Conclusion: 该框架为解决FBIC中的挑战提供了一种有效且可解释的解决方案。


### [59] [Leadership Assessment in Pediatric Intensive Care Unit Team Training](https://arxiv.org/abs/2505.24389)
*Liangyang Ouyang,Yuki Sakai,Ryosuke Furuta,Hisataka Nozawa,Hikoro Matsui,Yoichi Sato*

Main category: cs.CV

TL;DR: 本文提出了一种基于自我中心视觉的自动化分析框架，用于评估PICU团队的领导技能，通过行为线索（如注视对象、眼神交流和对话模式）进行量化分析。

- Motivation: 评估PICU团队的领导技能对培训至关重要，但传统方法依赖主观观察，缺乏客观性和可扩展性。
- Method: 使用Aria Glasses记录多模态数据（视频、音频、注视、头部运动），并利用REMoDNaV、SAM、YOLO和ChatGPT自动化处理数据，检测注视对象、眼神交流和对话分类。
- Result: 实验显示领导技能与行为指标（如注视时间、转换模式和直接指令）显著相关。
- Conclusion: 提出的框架能有效解决PICU团队技能评估问题，为培训提供客观依据。


### [60] [S3CE-Net: Spike-guided Spatiotemporal Semantic Coupling and Expansion Network for Long Sequence Event Re-Identification](https://arxiv.org/abs/2505.24401)
*Xianheng Ma,Hongchen Tan,Xiuping Liu,Yi Zhang,Huasheng Wang,Jiang Liu,Ying Chen,Hantao Liu*

Main category: cs.CV

TL;DR: 提出了一种基于事件相机的长序列行人重识别模型S3CE-Net，利用脉冲神经网络处理异步事件数据，结合时空注意力机制和特征采样策略，实现了高效且低参数的长序列Re-ID。

- Motivation: 解决在恶劣光照条件下减少背景干扰、保护面部信息并实现高时间分辨率的长序列行人重识别问题。
- Method: 基于脉冲神经网络构建S3CE-Net，引入时空注意力机制（SSAM）和时空特征采样策略（STFS），无需额外参数。
- Result: 在多个主流数据集上表现出色。
- Conclusion: S3CE-Net是一种高效、低参数的长序列事件行人重识别模型，实验验证了其优越性能。


### [61] [Leveraging Intermediate Features of Vision Transformer for Face Anti-Spoofing](https://arxiv.org/abs/2505.24402)
*Mika Feng,Koichi Ito,Takafumi Aoki,Tetsushi Ohki,Masakatsu Nishigaki*

Main category: cs.CV

TL;DR: 提出了一种基于Vision Transformer（ViT）的活体检测方法，用于区分真实与伪造人脸图像，并通过数据增强提升检测精度。

- Motivation: 恶意用户可能通过伪造人脸图像绕过认证系统，因此需要有效的活体检测方法以防止欺骗攻击。
- Method: 利用ViT的中间特征（兼顾局部与全局特征）进行训练损失和推理评分，并引入两种数据增强方法（活体数据增强和分块数据增强）。
- Result: 在OULU-NPU和SiW数据集上的实验验证了方法的有效性。
- Conclusion: 提出的方法能有效检测伪造人脸图像，提升活体检测的准确性。


### [62] [PCIE_Interaction Solution for Ego4D Social Interaction Challenge](https://arxiv.org/abs/2505.24404)
*Kanokphan Lertniphonphan,Feng Chen,Junda Xu,Fengbu Lan,Jun Xie,Tao Zhang,Zhepeng Wang*

Main category: cs.CV

TL;DR: PCIE_Interaction方案在CVPR 2025的Ego4D社交互动挑战中，通过视觉和音频融合方法，在LAM和TTM任务中分别取得0.81和0.71的mAP。

- Motivation: 解决Ego4D社交互动挑战中LAM和TTM任务的准确检测问题。
- Method: LAM任务使用面部质量增强和集成方法；TTM任务融合音频和视觉线索，并通过视觉质量评分加权。
- Result: LAM任务mAP为0.81，TTM任务mAP为0.71。
- Conclusion: PCIE_Interaction方案在社交互动检测中表现优异，代码已开源。


### [63] [IRBridge: Solving Image Restoration Bridge with Pre-trained Generative Diffusion Models](https://arxiv.org/abs/2505.24406)
*Hanting Wang,Tao Jin,Wang Lin,Shulei Wang,Hai Huang,Shengpeng Ji,Zhou Zhao*

Main category: cs.CV

TL;DR: IRBridge框架利用预训练生成模型改进图像修复，避免为每种退化类型从头训练，提高效率和性能。

- Motivation: 现有方法需为每种退化类型单独训练桥模型，计算成本高且性能有限。
- Method: 提出过渡方程连接两个扩散过程，引入IRBridge框架直接利用生成模型。
- Result: 在六种图像修复任务中，IRBridge表现出更强的鲁棒性和泛化性能。
- Conclusion: IRBridge为图像修复提供了一种更灵活高效的方法。


### [64] [PCIE_Pose Solution for EgoExo4D Pose and Proficiency Estimation Challenge](https://arxiv.org/abs/2505.24411)
*Feng Chen,Kanokphan Lertniphonphan,Qiancheng Yan,Xiaohui Fan,Jun Xie,Tao Zhang,Zhepeng Wang*

Main category: cs.CV

TL;DR: 团队PCIE_EgoPose在CVPR2025的EgoExo4D挑战赛中提出HP-ViT+和时空特征整合方法，分别在手部和身体姿态估计中取得冠军，并在熟练度估计任务中实现SOTA。

- Motivation: 解决RGB第一人称视频中手部和身体姿态估计的复杂问题，包括细微动作和频繁遮挡。
- Method: HP-ViT+结合Vision Transformer和CNN，加权融合优化手部姿态；身体姿态采用多模态时空特征整合。
- Result: 手部姿态PA-MPJPE 8.31，身体姿态MPJPE 11.25，熟练度估计Top-1准确率0.53。
- Conclusion: 方法在多个任务中表现优异，验证了技术的有效性。


### [65] [EasyText: Controllable Diffusion Transformer for Multilingual Text Rendering](https://arxiv.org/abs/2505.24417)
*Runnan Lu,Yuxuan Zhang,Jiaming Liu,Haofan Wang,Yiren Song*

Main category: cs.CV

TL;DR: EasyText是一个基于DiT的多语言文本渲染框架，通过字符定位编码和位置编码插值技术实现可控且精确的文本生成。

- Motivation: 解决多语言文本生成中的挑战，填补现有方法在多语言渲染领域的空白。
- Method: 采用DiT框架，结合字符定位编码和位置编码插值技术，并使用大规模合成数据集进行预训练和微调。
- Result: 实验证明EasyText在多语言文本渲染、视觉质量和布局感知文本集成方面表现优越。
- Conclusion: EasyText为多语言文本生成提供了一种高效且先进的解决方案。


### [66] [Bridging 3D Anomaly Localization and Repair via High-Quality Continuous Geometric Representation](https://arxiv.org/abs/2505.24431)
*Bozhong Zheng,Jinye Gan,Xiaohao Xu,Wenqiao Li,Xiaonan Huang,Na Ni,Yingna Wu*

Main category: cs.CV

TL;DR: PASDF框架通过连续、姿态不变的形状表示，提升了3D点云异常检测和修复的精度。

- Motivation: 解决现有基于补丁的方法因离散体素化或投影表示导致的几何保真度问题，实现精细异常定位。
- Method: 结合姿态对齐模块和SDF网络，动态整合姿态信息，通过连续SDF隐式学习高保真修复模板。
- Result: 在Real3D-AD和Anomaly-ShapeNet上分别达到80.2%和90.0%的AUROC分数，表现优异。
- Conclusion: 连续几何表示有效推进3D异常检测，并支持实际异常区域修复。


### [67] [SORCE: Small Object Retrieval in Complex Environments](https://arxiv.org/abs/2505.24441)
*Chunxu Liu,Chi Xie,Xiaxu Chen,Wei Li,Feng Zhu,Rui Zhao,Limin Wang*

Main category: cs.CV

TL;DR: 论文提出SORCE（复杂环境中的小目标检索），作为T2IR的新子领域，专注于通过文本查询检索复杂图像中的小目标。作者构建了SORCE-1K基准，并发现现有方法表现不佳，因此提出基于MLLM和ReP的多嵌入方法，显著提升了性能。

- Motivation: 现有T2IR基准主要关注整体图像语义或显著前景目标，忽略了复杂环境中不显眼的小目标，而实际应用中这些小目标检索至关重要。
- Method: 提出SORCE-1K基准，并利用MLLM和ReP为每张图像生成多个嵌入表示，以更好地捕捉小目标。
- Result: 多嵌入方法在SORCE-1K上显著优于现有T2IR方法，验证了其有效性。
- Conclusion: SORCE-1K为小目标检索提供了有效基准，多嵌入表示和MLLM特征为解决该任务展示了潜力。


### [68] [Diversify and Conquer: Open-set Disagreement for Robust Semi-supervised Learning with Outliers](https://arxiv.org/abs/2505.24443)
*Heejo Kong,Sung-Jin Kim,Gunho Jung,Seong-Whan Lee*

Main category: cs.CV

TL;DR: 论文提出了一种名为DAC的新框架，用于增强开放集半监督学习（SSL）的鲁棒性，通过利用多个模型的预测差异来检测异常数据。

- Motivation: 传统SSL假设标记和未标记数据具有相同的类别分布，但实际中未标记数据常包含异常类别（即离群点），导致模型性能下降。现有方法依赖单一模型的预测差异，在标记数据不足时效果不佳。
- Method: DAC通过训练多个具有不同偏见的模型，利用它们在未标记数据上的预测差异来检测离群点。关键贡献是通过单一训练过程构建这些模型，并鼓励它们在离群点上产生分歧，同时对正常数据保持一致预测。
- Result: 该方法在标记数据不足时仍能有效检测离群点，提升了开放集SSL的鲁棒性。
- Conclusion: DAC通过利用模型间的预测差异，显著提高了开放集SSL的性能，尤其在标记数据有限的情况下表现优异。


### [69] [SA-Person: Text-Based Person Retrieval with Scene-aware Re-ranking](https://arxiv.org/abs/2505.24466)
*Yingjia Xu,Jinlin Wu,Zhen Chen,Daming Gao,Yang Yang,Zhen Lei,Min Cao*

Main category: cs.CV

TL;DR: 论文提出了一种基于文本的人物检索方法，通过结合行人外观和场景上下文信息，提升检索效果。

- Motivation: 现有方法主要关注外观跨模态检索，忽略了场景上下文信息，而后者能提供有价值的补充。
- Method: 提出SA-Person框架，分两阶段：外观对齐和基于场景的重新排序（SceneRanker）。
- Result: 在SCENEPERSON-13W数据集上验证了方法的有效性。
- Conclusion: 结合外观和场景信息的框架在复杂场景检索中表现优异，代码和数据集将公开。


### [70] [SPPSFormer: High-quality Superpoint-based Transformer for Roof Plane Instance Segmentation from Point Clouds](https://arxiv.org/abs/2505.24475)
*Cheng Zeng,Xiatian Qi,Chi Chen,Kai Sun,Wangle Zhang,Yuxuan Liu,Yan Meng,Bisheng Yang*

Main category: cs.CV

TL;DR: 本文提出了一种用于点云屋顶平面实例分割的两阶段超点生成方法，结合多维手工特征和改进的解码器，显著提升了性能。

- Motivation: 现有超点Transformer在点云屋顶平面分割中性能受限，主要由于低质量超点。
- Method: 提出两阶段超点生成标准，结合手工特征，设计Kolmogorov-Arnold网络与Transformer的解码器，并进行后处理优化。
- Result: 在自建数据集和修正的RoofN3D数据集上达到最优性能，且对标注边界不敏感。
- Conclusion: 点云密度、均匀性和精度对分割性能影响显著，需增强数据多样性以提升模型鲁棒性。


### [71] [Period-LLM: Extending the Periodic Capability of Multimodal Large Language Model](https://arxiv.org/abs/2505.24476)
*Yuting Zhang,Hao Lu,Qingyong Hu,Yin Wang,Kaishen Yuan,Xin Liu,Kaishun Wu*

Main category: cs.CV

TL;DR: Period-LLM是一种多模态大语言模型，旨在解决现有模型在周期性任务中的不足，通过渐进式学习和优化策略提升性能。

- Motivation: 周期性现象广泛存在于自然过程中，但现有MLLMs因缺乏时间建模和周期冲突问题而表现不佳。
- Method: 采用“从易到难”的范式，逐步构建周期性推理能力，并提出“抵抗逻辑遗忘”优化策略。
- Result: 实验表明Period-LLM在周期性任务中优于现有MLLMs。
- Conclusion: Period-LLM为多模态周期性任务提供了有效解决方案，并建立了评估基准。


### [72] [ACM-UNet: Adaptive Integration of CNNs and Mamba for Efficient Medical Image Segmentation](https://arxiv.org/abs/2505.24481)
*Jing Huang,Yongkang Zhao,Yuhan Li,Zhitao Dai,Cheng Chen,Qiying Lai*

Main category: cs.CV

TL;DR: ACM-UNet是一种通用的医学图像分割框架，通过轻量级适配器机制结合预训练的CNN和Mamba模型，解决了结构不匹配问题，并在Synapse和ACDC基准测试中达到最先进性能。

- Motivation: 现有方法在利用预训练视觉骨干网络（如ResNet、ViT、VMamba）时存在结构不匹配问题，限制了其性能。ACM-UNet旨在通过适配器机制解决这一问题，同时结合CNN和SSM的优势。
- Method: ACM-UNet保留了UNet的简单设计，通过轻量级适配器机制整合预训练的CNN和Mamba模型，并在解码器中引入分层多尺度小波变换模块以增强特征融合。
- Result: 在Synapse和ACDC基准测试中，ACM-UNet表现优异，达到85.12% Dice Score和13.89mm HD95（Synapse数据集），计算效率高（17.93G FLOPs）。
- Conclusion: ACM-UNet通过适配器机制和分层多尺度小波变换模块，有效结合了CNN和SSM的优势，实现了高性能和计算效率的医学图像分割。


### [73] [Deformable Attention Mechanisms Applied to Object Detection, case of Remote Sensing](https://arxiv.org/abs/2505.24489)
*Anasse Boutayeb,Iyad Lahsen-cherif,Ahmed El Khadimi*

Main category: cs.CV

TL;DR: 本文提出了一种基于Deformable-DETR模型的目标检测方法，应用于光学和SAR遥感图像，取得了优异的性能。

- Motivation: 遥感图像在目标检测中具有重要应用，而基于Transformer的深度学习模型在该领域表现突出。
- Method: 使用Deformable-DETR模型，结合光学和SAR数据集（Pleiades Aircraft和SSDD），进行10折分层验证。
- Result: 模型在光学数据集上F1得分为95.12%，在SSDD上为94.54%，优于其他CNN和Transformer模型。
- Conclusion: Deformable-DETR在遥感图像目标检测中表现出色，具有广泛应用潜力。


### [74] [Reason-SVG: Hybrid Reward RL for Aha-Moments in Vector Graphics Generation](https://arxiv.org/abs/2505.24499)
*Ximing Xing,Yandong Guan,Jing Zhang,Dong Xu,Qian Yu*

Main category: cs.CV

TL;DR: Reason-SVG是一个新框架，通过“Drawing-with-Thought”范式增强LLM生成SVG的能力，结合监督微调和强化学习，显著提升SVG的质量。

- Motivation: 当前LLM在生成SVG时缺乏结构有效性、语义忠实性和视觉连贯性，Reason-SVG旨在解决这一问题。
- Method: 采用两阶段训练策略：监督微调激活基础推理能力，强化学习（GRPO）优化生成过程，并设计混合奖励函数评估质量。
- Result: Reason-SVG显著提升了LLM生成SVG的准确性和视觉吸引力。
- Conclusion: Reason-SVG通过整合DwT、SFT和强化学习，为LLM生成高质量SVG提供了新思路。


### [75] [un$^2$CLIP: Improving CLIP's Visual Detail Capturing Ability via Inverting unCLIP](https://arxiv.org/abs/2505.24517)
*Yinqi Li,Jiahe Zhao,Hong Chang,Ruibing Hou,Shiguang Shan,Xilin Chen*

Main category: cs.CV

TL;DR: 本文提出了一种改进CLIP模型的方法un²CLIP，通过结合生成模型unCLIP的能力，以提升CLIP在图像细节捕捉和密集预测任务中的表现。

- Motivation: 现有CLIP模型在图像细节区分和密集预测任务中表现不佳，需要改进以更好地捕捉视觉细节。
- Method: 利用生成模型unCLIP（通过反转CLIP图像编码器训练）改进CLIP，提出un²CLIP方法，结合生成模型的细节捕捉能力。
- Result: 实验表明，un²CLIP在多项任务（如MMVP-VLM基准、开放词汇分割任务等）中显著优于原始CLIP及其他改进方法。
- Conclusion: un²CLIP成功提升了CLIP的视觉细节捕捉能力，同时保持了其与文本编码器的对齐性。


### [76] [AMIA: Automatic Masking and Joint Intention Analysis Makes LVLMs Robust Jailbreak Defenders](https://arxiv.org/abs/2505.24519)
*Yuqi Zhang,Yuchun Miao,Zuchao Li,Liang Ding*

Main category: cs.CV

TL;DR: AMIA是一种轻量级的防御方法，通过自动屏蔽无关图像块和联合意图分析，显著提升大型视觉语言模型的安全性，同时保持实用性。

- Motivation: 针对大型视觉语言模型（LVLMs）在对抗性攻击下的脆弱性，提出无需重新训练的轻量级防御方案。
- Method: 1. 自动屏蔽文本无关的图像块以破坏对抗性扰动；2. 联合意图分析以在生成响应前发现并缓解潜在有害意图。
- Result: 防御成功率从平均52.4%提升至81.7%，实用性仅下降2%，推理开销较小。
- Conclusion: 屏蔽和意图分析对安全性与实用性的平衡至关重要。


### [77] [UniGeo: Taming Video Diffusion for Unified Consistent Geometry Estimation](https://arxiv.org/abs/2505.24521)
*Yang-Tian Sun,Xin Yu,Zehuan Huang,Yi-Hua Huang,Yuan-Chen Guo,Ziyi Yang,Yan-Pei Cao,Xiaojuan Qi*

Main category: cs.CV

TL;DR: 利用扩散模型先验辅助单目几何估计（如深度和法线）的方法因其强泛化能力受到关注。本文通过适当设计和微调，利用视频生成模型的固有一致性实现一致的几何估计，并在全局坐标系中预测几何属性，性能优越。

- Motivation: 现有方法多关注单帧相机坐标系内的几何属性估计，忽略了扩散模型在帧间对应关系中的潜力。本文旨在利用视频生成模型的固有一致性改进几何估计。
- Method: 1) 在全局坐标系中选择与视频帧共享对应关系的几何属性作为预测目标；2) 通过重用位置编码引入高效条件方法；3) 联合训练共享对应关系的多几何属性以提升性能。
- Result: 在预测视频全局几何属性上表现优异，可直接应用于重建任务，且在静态视频数据训练后能泛化到动态场景。
- Conclusion: 本文方法通过利用视频生成模型的固有一致性，实现了全局几何属性的高效估计，并展示了良好的泛化能力。


### [78] [Optimal Density Functions for Weighted Convolution in Learning Models](https://arxiv.org/abs/2505.24527)
*Simone Cammarasana,Giuseppe Patanè*

Main category: cs.CV

TL;DR: 论文提出了一种加权卷积方法，通过应用最优密度函数来调整邻近像素的贡献，显著提升了卷积神经网络的精度。

- Motivation: 传统卷积对所有邻近像素平等对待，而加权卷积通过距离调整贡献，旨在提高近似精度。
- Method: 提出框架，分别优化卷积核权重（随机梯度下降）和密度函数（DIRECT-L），应用于图像任务（如去噪）。
- Result: 加权卷积显著降低损失（提升达53%），提高测试精度，但执行时间增加11%。
- Conclusion: 加权卷积在多种超参数下表现稳健，未来将应用于2D和3D图像学习问题。


### [79] [Geospatial Foundation Models to Enable Progress on Sustainable Development Goals](https://arxiv.org/abs/2505.24528)
*Pedram Ghamisi,Weikang Yu,Xiaokang Zhang,Aldino Rizaldy,Jian Wang,Chufeng Zhou,Richard Gloaguen,Gustau Camps-Valls*

Main category: cs.CV

TL;DR: SustainFM是一个基于17个可持续发展目标的基准测试框架，用于评估地理空间基础模型（FMs）的实际效用及其与可持续发展目标的一致性。研究发现FMs在多样任务中表现优于传统方法，但需综合考虑准确性、可转移性、泛化能力和能源效率。

- Motivation: 探讨地理空间FMs在实现全球可持续发展目标中的实际效用，填补其在现实世界应用中的研究空白。
- Method: 提出SustainFM框架，通过多样化的任务（如资产财富预测和环境灾害检测）对FMs进行跨学科评估。
- Result: FMs在多数任务中优于传统方法，但需关注其可转移性、泛化能力和能源效率。
- Conclusion: 呼吁从模型为中心转向以影响为导向的部署，强调能源效率、领域适应性和伦理考量。


### [80] [Mixpert: Mitigating Multimodal Learning Conflicts with Efficient Mixture-of-Vision-Experts](https://arxiv.org/abs/2505.24541)
*Xin He,Xumeng Han,Longhui Wei,Lingxi Xie,Qi Tian*

Main category: cs.CV

TL;DR: Mixpert是一种高效的多视觉专家混合架构，通过动态路由机制分配任务到合适的专家，解决了单视觉编码器在多任务学习中的冲突问题。

- Motivation: 单视觉编码器难以处理多样化的视觉任务，而直接集成多个编码器会增加复杂性并限制联合优化潜力。
- Method: Mixpert采用混合视觉专家架构，结合动态路由机制，实现任务特定微调。
- Result: Mixpert在多任务学习中显著提升性能，且计算成本低。
- Conclusion: Mixpert高效解决了多任务冲突，适用于任何多模态大语言模型。


### [81] [Optimal Weighted Convolution for Classification and Denosing](https://arxiv.org/abs/2505.24558)
*Simone Cammarasana,Giuseppe Patanè*

Main category: cs.CV

TL;DR: 提出了一种新型加权卷积算子，通过引入空间密度函数改进传统CNN，提升特征提取能力，并在图像分类和去噪任务中表现优异。

- Motivation: 传统卷积操作对所有邻域像素赋予相同权重，无法充分利用空间信息。新方法通过加权卷积提升空间表征能力。
- Method: 将空间密度函数整合到卷积算子中，预计算密度函数以实现高效执行，兼容现有CNN架构。
- Result: 在CIFAR-100和DIV2K数据集上，加权卷积显著提升了VGG和DnCNN等模型的性能（如准确率从56.89%提升至66.94%）。
- Conclusion: 加权卷积是一种通用且高效的改进方法，适用于多维信号处理，代码已开源。


### [82] [Unleashing the Power of Intermediate Domains for Mixed Domain Semi-Supervised Medical Image Segmentation](https://arxiv.org/abs/2505.24567)
*Qinghe Ma,Jian Zhang,Lei Qi,Qian Yu,Yinghuan Shi,Yang Gao*

Main category: cs.CV

TL;DR: 论文提出了一种名为MiDSS的新场景，结合了半监督学习和域适应，以解决医学图像分割中标注数据有限和域偏移的问题。提出的UST-RUN框架通过中间域信息促进知识迁移，实验显示显著效果。

- Motivation: 医学图像分割中，标注数据有限和域偏移问题常同时存在，传统方法无法同时解决。因此，作者提出了MiDSS场景和UST-RUN框架。
- Method: UST-RUN框架包括：1）统一复制粘贴（UCP）构建中间域；2）对称引导训练策略（SymGD）监督无标签数据；3）训练过程感知的随机幅度混合（TP-RAM）逐步引入风格转换。
- Result: 在四个公开数据集上的实验表明，UST-RUN表现优异，尤其在Prostate数据集上Dice分数提升了12.94%。
- Conclusion: UST-RUN有效解决了MiDSS场景下的挑战，显著提升了医学图像分割性能。


### [83] [SARD: A Large-Scale Synthetic Arabic OCR Dataset for Book-Style Text Recognition](https://arxiv.org/abs/2505.24600)
*Omer Nacar,Yasser Al-Habashi,Serry Sibaee,Adel Ammar,Wadii Boulila*

Main category: cs.CV

TL;DR: SARD是一个大规模合成的阿拉伯语OCR数据集，旨在模拟书籍布局，包含843,622张文档图像和6.9亿单词，覆盖10种字体，为模型训练提供干净且可控的环境。

- Motivation: 现有阿拉伯语OCR数据集规模小、多样性不足或结构简单，无法满足现代OCR模型的需求。SARD填补了这一空白。
- Method: 通过合成生成大规模数据集，模拟书籍布局，覆盖多种字体，避免真实文档的噪声和失真。
- Result: SARD提供了干净的训练环境，支持多种OCR模型的基准测试，展示了其挑战和潜力。
- Conclusion: SARD是开发高效阿拉伯语OCR和视觉语言模型的重要资源。


### [84] [GARLIC: GAussian Representation LearnIng for spaCe partitioning](https://arxiv.org/abs/2505.24608)
*Panagiotis Rigas,Panagiotis Drivas,Charalambos Tzamos,Ioannis Chamodrakas,George Ioannakis,Leonidas J. Guibas,Ioannis Z. Emiris*

Main category: cs.CV

TL;DR: GARLIC是一种基于高维高斯分布的新型索引结构，用于高效学习高维向量空间，结合了高斯渲染技术和信息论优化，在快速构建和高召回率方面表现优异。

- Motivation: 高维向量空间的高效学习和检索是许多应用的核心问题，传统方法在速度和准确性上存在局限。GARLIC旨在通过高斯表示和信息论优化解决这一问题。
- Method: GARLIC利用N维高斯分布，通过分裂和克隆操作逐步优化高斯参数，平衡覆盖范围、分配置信度和语义一致性。
- Result: 在标准基准测试中，GARLIC在k-NN检索和分类任务中表现优异，召回率和准确率显著高于其他方法，且对训练数据量要求低。
- Conclusion: GARLIC是一种高效且通用的高维向量学习方法，适用于需要速度和准确性的应用场景。


### [85] [Learning from Videos for 3D World: Enhancing MLLMs with 3D Vision Geometry Priors](https://arxiv.org/abs/2505.24625)
*Duo Zheng,Shijia Huang,Yanyang Li,Liwei Wang*

Main category: cs.CV

TL;DR: VG LLM 是一种直接从视频数据中理解和推理3D空间的方法，无需额外3D输入，性能优于现有方法。

- Motivation: 提升多模态大语言模型（MLLMs）直接从视频数据中理解和推理3D空间的能力，避免依赖额外的3D输入数据。
- Method: 提出VG LLM，通过3D视觉几何编码器从视频序列中提取3D先验信息，并与视觉标记结合输入MLLM。
- Result: 在3D场景理解和空间推理任务中取得显著改进，4B模型在VSI-Bench评估中超越Gemini-1.5-Pro。
- Conclusion: VG LLM展示了直接从视频数据中高效学习3D信息的潜力，性能优于依赖显式3D输入的方法。


### [86] [NUC-Net: Non-uniform Cylindrical Partition Network for Efficient LiDAR Semantic Segmentation](https://arxiv.org/abs/2505.24634)
*Xuzhi Wang,Wei Feng,Lingdong Kong,Liang Wan*

Main category: cs.CV

TL;DR: 论文提出了一种非均匀圆柱体分割网络（NUC-Net），用于解决LiDAR点云语义分割中均匀分割方法的高计算成本和点分布不平衡问题。该方法通过非均匀分割和聚合技术显著提升了性能和效率。

- Motivation: 现有基于体素的LiDAR语义分割方法存在高计算成本和点分布不平衡的问题，限制了其效率和性能。
- Method: 提出非均匀圆柱体分割网络（NUC-Net），包括径向轴的非均匀分割方法（API）和非均匀多尺度聚合技术。
- Result: 在SemanticKITTI和nuScenes数据集上实现了最先进的性能，训练速度提升4倍，GPU内存减少2倍，推理速度提升3倍。
- Conclusion: NUC-Net是一种高效且通用的LiDAR语义分割组件，显著提升了准确性和效率，并通过理论分析验证了其有效性。


### [87] [Category-Level 6D Object Pose Estimation in Agricultural Settings Using a Lattice-Deformation Framework and Diffusion-Augmented Synthetic Data](https://arxiv.org/abs/2505.24636)
*Marios Glytsos,Panagiotis P. Filntisis,George Retsinas,Petros Maragos*

Main category: cs.CV

TL;DR: PLANTPose是一种基于RGB输入的类别级6D姿态估计框架，通过预测6D姿态和变形参数，适应未见实例，无需依赖实例特定数据。

- Motivation: 农业中水果和蔬菜的形状、大小和纹理差异大，现有方法依赖CAD模型或深度传感器，不适用于实际应用。
- Method: PLANTPose预测6D姿态和变形参数，利用Stable Diffusion增强合成训练图像的真实性。
- Result: 在包含不同形状、大小和成熟度香蕉的基准测试中，PLANTPose显著优于现有RGB方法MegaPose。
- Conclusion: PLANTPose能有效处理类别内大变化，实现准确的6D姿态估计，适用于农业场景。


### [88] [Cloud Optical Thickness Retrievals Using Angle Invariant Attention Based Deep Learning Models](https://arxiv.org/abs/2505.24638)
*Zahid Hassan Tushar,Adeleke Ademakinwa,Jianwu Wang,Zhibo Zhang,Sanjay Purushotham*

Main category: cs.CV

TL;DR: 论文提出了一种名为CAAC的新型角度不变、基于注意力的深度学习模型，用于更准确地估计云光学厚度（COT），显著优于现有方法。

- Motivation: 传统独立像素近似（IPA）方法因简化假设引入显著偏差，而现有深度学习模型缺乏鲁棒性，对辐射强度变化和角度敏感。
- Method: 提出Cloud-Attention-Net with Angle Coding（CAAC）模型，利用注意力机制和角度嵌入处理卫星视角几何和3D辐射传输效应，并采用多角度训练策略确保角度不变性。
- Result: 实验表明，CAAC显著优于现有深度学习模型，将云属性检索误差至少降低九倍。
- Conclusion: CAAC模型通过结合注意力机制和多角度训练，有效解决了COT估计中的角度和3D效应问题，提供了更准确的结果。


### [89] [A Cross Branch Fusion-Based Contrastive Learning Framework for Point Cloud Self-supervised Learning](https://arxiv.org/abs/2505.24641)
*Chengzhi Wu,Qianliang Huang,Kun Jin,Julius Pfrommer,Jürgen Beyerer*

Main category: cs.CV

TL;DR: 提出了一种基于对比跨分支注意力的点云无监督学习框架PoCCA，通过子分支实现信息交换，提升了3D点云表示学习效果。

- Motivation: 现有对比学习框架仅在损失端进行特征对比，缺乏分支间的信息交换，限制了表示学习能力。
- Method: 引入子分支，允许在损失端之前进行跨分支信息交换，适用于点云数据。
- Result: 在不使用额外训练数据的情况下，PoCCA在下游任务中实现了最先进的性能。
- Conclusion: PoCCA通过跨分支信息交换，显著提升了点云表示学习的效果。


### [90] [BIMA: Bijective Maximum Likelihood Learning Approach to Hallucination Prediction and Mitigation in Large Vision-Language Models](https://arxiv.org/abs/2505.24649)
*Huu-Thien Tran,Thanh-Dat Truong,Khoa Luu*

Main category: cs.CV

TL;DR: 论文提出了一种名为BIMA的新方法，利用归一化流理论减少视觉语言模型中的幻觉问题，显著提升了性能。

- Motivation: 大型视觉语言模型存在幻觉问题，即生成与视觉内容不符的响应，开发可信赖且可解释的系统具有挑战性。
- Method: 提出Bijective Maximum Likelihood Learning (BIMA)方法，基于归一化流理论优化解码过程。
- Result: BIMA在POPE基准测试中平均F1得分为85.06%，CHAIRS和CHAIRI分别减少7.6%和2.6%。
- Conclusion: BIMA是首批利用双射方法减少视觉语言模型幻觉的研究之一，效果显著。


### [91] [Decoupled Competitive Framework for Semi-supervised Medical Image Segmentation](https://arxiv.org/abs/2505.24667)
*Jiahe Chen,Jiahe Ying,Shen Wang,Jianwei Zheng*

Main category: cs.CV

TL;DR: 论文提出了一种解耦竞争框架（DCF），解决了半监督医学图像分割中Mean Teacher和Dual Students结构的局限性，通过动态解耦和竞争机制提升性能。

- Motivation: 解决半监督医学图像分割中Mean Teacher结构的过耦合问题和Dual Students结构的认知偏差问题。
- Method: 提出DCF框架，利用竞争机制动态解耦学生和教师模型，并促进学生间精确知识交换。
- Result: 在多个公开数据集上验证，性能优于现有先进方法。
- Conclusion: DCF有效解决了现有方法的局限性，提升了半监督医学图像分割的性能。


### [92] [6D Pose Estimation on Point Cloud Data through Prior Knowledge Integration: A Case Study in Autonomous Disassembly](https://arxiv.org/abs/2505.24669)
*Chengzhi Wu,Hao Fu,Jan-Philipp Kaiser,Erik Tabuchi Barczak,Julius Pfrommer,Gisela Lanza,Michael Heizmann,Jürgen Beyerer*

Main category: cs.CV

TL;DR: 论文提出了一种多阶段管道，用于在制造领域中准确估计螺栓的6D姿态，解决了遮挡和单视角数据限制的问题。

- Motivation: 在制造领域中，利用先验知识可以改进6D姿态估计，特别是在自动化拆卸过程中识别螺栓的6D姿态。
- Method: 提出了一种多阶段管道，结合先验知识，从遮挡和单视角数据中获取完整的螺栓6D信息。
- Result: 该方法成功捕获了所有螺栓的6D姿态信息，展示了先验知识在复杂任务中的有效性。
- Conclusion: 研究不仅推动了6D姿态估计领域的发展，还证明了领域特定知识在制造和自动化中的实用性。


### [93] [Beyond FACS: Data-driven Facial Expression Dictionaries, with Application to Predicting Autism](https://arxiv.org/abs/2505.24679)
*Evangelos Sariyanidi,Lisa Yankowitz,Robert T. Schultz,John D. Herrington,Birkan Tunc,Jeffrey Cohn*

Main category: cs.CV

TL;DR: 论文提出了一种名为Facial Basis的新型编码系统，替代传统的FACS，通过无监督方法解决其局限性，并在自闭症诊断中表现优于常用AU检测器。

- Motivation: FACS编码过程繁琐且成本高，现有自动检测方法精度不足且无法覆盖所有AU，限制了其在行为研究中的应用。
- Method: 提出数据驱动的Facial Basis系统，通过无监督学习生成局部化、可解释的3D面部运动单元，克服FACS的结构性限制。
- Result: Facial Basis在预测自闭症诊断中优于常用AU检测器，并能全面编码面部行为。
- Conclusion: Facial Basis是首个替代FACS的系统，能全面解析视频中的面部表情，并开源实现。


### [94] [Learning reusable concepts across different egocentric video understanding tasks](https://arxiv.org/abs/2505.24690)
*Simone Alberto Peirone,Francesca Pistilli,Antonio Alliegro,Tatiana Tommasi,Giuseppe Averta*

Main category: cs.CV

TL;DR: Hier-EgoPack是一个统一框架，旨在通过多任务视角提升自主系统的整体感知能力。

- Motivation: 人类对视频流的理解是多方面的，而现有系统缺乏这种能力。通过任务协同学习，可以提升自主系统的感知能力。
- Method: 提出Hier-EgoPack框架，构建任务视角集合，支持下游任务的知识迁移和技能共享。
- Result: 框架能够为机器人提供可携带的技能背包，增强其多任务处理能力。
- Conclusion: Hier-EgoPack为自主系统提供了一种高效的多任务学习与知识迁移方法。


### [95] [Conformal Prediction for Zero-Shot Models](https://arxiv.org/abs/2505.24693)
*Julio Silva-Rodríguez,Ismail Ben Ayed,Jose Dolz*

Main category: cs.CV

TL;DR: 该论文研究了CLIP模型在分形预测框架下的可靠性，提出了一种名为Conf-OT的迁移学习方法，通过最优传输问题解决预训练与适应任务之间的领域差距，显著提高了集合效率。

- Motivation: 尽管大规模预训练的视觉语言模型在下游任务中表现出强大的适应性和泛化能力，但其可靠性和不确定性尚未得到充分研究。本文旨在填补这一空白。
- Method: 采用分形预测范式，结合最优传输问题（Conf-OT），在无需额外数据分割的情况下，解决预训练与适应任务之间的领域差距。
- Result: 在15个数据集和三种非一致性评分上，Conf-OT将集合效率相对提高了20%，且速度比现有方法快15倍。
- Conclusion: Conf-OT通过最优传输有效解决了领域差距问题，显著提升了分形预测的效率，为黑盒模型的可靠性提供了理论保障。


### [96] [RT-X Net: RGB-Thermal cross attention network for Low-Light Image Enhancement](https://arxiv.org/abs/2505.24705)
*Raman Jha,Adithya Lenka,Mani Ramanagopal,Aswin Sankaranarayanan,Kaushik Mitra*

Main category: cs.CV

TL;DR: RT-X Net是一种跨注意力网络，融合RGB和热图像以增强夜间图像质量，通过自注意力网络提取特征，跨注意力机制融合信息，并在新数据集V-TIEE上验证其优越性。

- Motivation: 夜间图像因高噪声和强光源导致质量下降，热图像能提供互补信息，但现有方法未能充分利用多模态数据。
- Method: 提出RT-X Net，结合自注意力网络和跨注意力机制，融合RGB与热图像信息。
- Result: 在LLVIP和V-TIEE数据集上，RT-X Net优于现有方法。
- Conclusion: RT-X Net有效提升夜间图像质量，新数据集V-TIEE支持进一步研究。


### [97] [Reinforcing Video Reasoning with Focused Thinking](https://arxiv.org/abs/2505.24718)
*Jisheng Dang,Jingze Wu,Teng Wang,Xuanhui Lin,Nannan Zhu,Hongbo Chen,Wei-Shi Zheng,Meng Wang,Tat-Seng Chua*

Main category: cs.CV

TL;DR: TW-GRPO通过令牌加权机制和密集奖励粒度改进了GRPO，提升了多模态大语言模型在复杂推理任务中的表现。

- Motivation: 现有GRPO方法存在推理链冗长和二元奖励效率低的问题，TW-GRPO旨在解决这些局限性。
- Method: 采用令牌加权机制抑制冗余令牌，并通过多选择QA任务和软奖励实现更细粒度的梯度估计。
- Result: 在多个视频推理和通用理解基准测试中表现优异，如CLEVRER准确率提升18.8%。
- Conclusion: TW-GRPO显著提升了视觉推理的效率和准确性，为多模态任务提供了新思路。


### [98] [DreamDance: Animating Character Art via Inpainting Stable Gaussian Worlds](https://arxiv.org/abs/2505.24733)
*Jiaxu Zhang,Xianfang Zeng,Xin Chen,Wei Zuo,Gang Yu,Guosheng Lin,Zhigang Tu*

Main category: cs.CV

TL;DR: DreamDance是一个新颖的角色艺术动画框架，通过相机轨迹生成稳定的角色和场景运动。

- Motivation: 解决角色动画中相机轨迹与动态角色结合的挑战。
- Method: 分两步：相机感知场景修复和姿态感知视频修复，结合高斯场和DiT模型。
- Result: 生成高质量、一致的动态角色动画。
- Conclusion: DreamDance在动态相机效果下表现优异，具有通用性。


### [99] [Tackling View-Dependent Semantics in 3D Language Gaussian Splatting](https://arxiv.org/abs/2505.24746)
*Jiazhong Cen,Xudong Zhou,Jiemin Fang,Changsong Wen,Lingxi Xie,Xiaopeng Zhang,Wei Shen,Qi Tian*

Main category: cs.CV

TL;DR: LaGa (Language Gaussians) 提出了一种新方法，通过分解3D场景为对象并构建视角聚合的语义表示，解决了2D与3D语义理解的视角依赖性问题，显著提升了3D场景理解的性能。

- Motivation: 现有的方法通常简单地将2D语义特征投影到3D高斯上，忽略了3D对象在不同视角下可能表现出的不同语义（视角依赖性语义）。
- Method: LaGa通过分解3D场景为对象，聚类语义描述符，并根据多视角语义重新加权，构建视角聚合的语义表示。
- Result: 在相同设置下，LaGa在LERF-OVS数据集上比之前的SOTA方法提升了18.7%的mIoU。
- Conclusion: LaGa有效捕捉了视角依赖性语义的关键信息，实现了更全面的3D场景理解。


### [100] [Draw ALL Your Imagine: A Holistic Benchmark and Agent Framework for Complex Instruction-based Image Generation](https://arxiv.org/abs/2505.24787)
*Yucheng Zhou,Jiahao Yuan,Qianning Wang*

Main category: cs.CV

TL;DR: 论文介绍了LongBench-T2I，一个专为评估复杂指令下文本到图像生成模型性能的基准测试，并提出了Plan2Gen框架以提升生成效果。

- Motivation: 现有文本到图像生成模型在复杂指令（涉及多对象、属性和空间关系）下表现不佳，且缺乏针对复杂指令的评估基准。
- Method: 提出LongBench-T2I基准测试（500个复杂提示）和Plan2Gen框架（利用大语言模型分解复杂指令，无需额外训练）。
- Result: LongBench-T2I提供了多维度评估工具，Plan2Gen框架有效提升了复杂指令下的图像生成质量。
- Conclusion: LongBench-T2I填补了复杂指令评估的空白，Plan2Gen为现有模型提供了无需训练的改进方案。


### [101] [Lightweight Relational Embedding in Task-Interpolated Few-Shot Networks for Enhanced Gastrointestinal Disease Classification](https://arxiv.org/abs/2505.24792)
*Xinliu Zhong,Leo Hwa Liang,Angela S. Koh,Yeo Si Yong*

Main category: cs.CV

TL;DR: 提出了一种基于Few-Shot Learning的深度学习网络，用于优化结直肠癌的内窥镜图像分析，显著提高了诊断准确性和效率。

- Motivation: 传统结肠镜检查具有侵入性且依赖高质量图像，但图像模式相似且不足，导致诊断准确性受限。
- Method: 结合Few-Shot Learning架构，包括特征提取器、任务插值、关系嵌入和双级路由注意力机制，增强模型对未见图像模式的适应能力。
- Result: 在Kvasir数据集上表现优异，准确率达90.1%，F1分数为0.891，优于现有方法。
- Conclusion: 该模型为结直肠癌的早期检测提供了一种非侵入性且高效的解决方案。


### [102] [CL-LoRA: Continual Low-Rank Adaptation for Rehearsal-Free Class-Incremental Learning](https://arxiv.org/abs/2505.24816)
*Jiangpeng He,Zhihao Duan,Fengqing Zhu*

Main category: cs.CV

TL;DR: 论文提出了一种名为CL-LoRA的双适配器架构，用于解决类增量学习中的参数冗余和跨任务知识共享问题。

- Motivation: 现有基于适配器的方法在类增量学习中为每个新任务创建新适配器，导致参数冗余且未能利用跨任务共享知识。
- Method: CL-LoRA采用双适配器架构，包括任务共享适配器和任务特定适配器，结合知识蒸馏和梯度重分配技术。
- Result: CL-LoRA在多个基准测试中表现优异，同时减少了训练和推理计算量。
- Conclusion: CL-LoRA为基于预训练模型的持续学习提供了一种更高效和可扩展的范式。


### [103] [Segmenting France Across Four Centuries](https://arxiv.org/abs/2505.24824)
*Marta López-Rauhut,Hongyu Zhou,Mathieu Aubry,Loic Landrieu*

Main category: cs.CV

TL;DR: 论文介绍了一个针对历史地图的新数据集，用于分析大规模、长期的土地利用和覆盖变化，并评估了三种分割方法的性能。

- Motivation: 历史地图提供了研究过去几个世纪领土演变的宝贵视角，但现有数据集通常局限于单一地图类型或时期，且标注成本高。
- Method: 提出了一个覆盖法国大都市的历史地图数据集，包含18至20世纪的地图，并提供现代和手动标注的历史标签。评估了三种分割方法：全监督和两种弱监督模型。
- Result: 数据集展示了分割任务的复杂性，包括风格不一致和景观变化。弱监督模型通过现代标注或图像转换处理风格差异。
- Conclusion: 这些方法支持长期环境监测，为景观变化提供了见解。数据集和代码已公开。


### [104] [Zero-Shot Chinese Character Recognition with Hierarchical Multi-Granularity Image-Text Aligning](https://arxiv.org/abs/2505.24837)
*Yinglian Zhu,Haiyang Yu,Qizao Wang,Wei Lu,Xiangyang Xue,Bin Li*

Main category: cs.CV

TL;DR: 提出了一种基于对比范式的分层多粒度图文对齐框架（Hi-GITA），用于中文字符识别，显著提升了零样本识别性能。

- Motivation: 现有方法通常基于自回归或编辑距离后处理，且依赖单层字符表示，未能充分利用中文字符的细粒度语义信息。
- Method: 设计了图像和文本的多粒度编码器，分别提取字符图像的层次化表示和文本的笔画、部首序列表示，并通过多粒度融合模块和细粒度解耦图文对比损失实现模态对齐。
- Result: 实验表明，Hi-GITA在零样本中文字符识别任务中显著优于现有方法，例如在手写字符和部首零样本设置下准确率提升约20%。
- Conclusion: Hi-GITA通过充分利用中文字符的细粒度语义信息，实现了更高效的零样本识别，为智能文档处理提供了新思路。


### [105] [VideoCAD: A Large-Scale Video Dataset for Learning UI Interactions and 3D Reasoning from CAD Software](https://arxiv.org/abs/2505.24838)
*Brandon Man,Ghadi Nehme,Md Ferdous Alam,Faez Ahmed*

Main category: cs.CV

TL;DR: VideoCAD是一个大规模合成数据集，专注于高复杂度CAD操作，支持UI交互学习和多模态LLM评估。

- Motivation: 现有AI驱动的UI代理数据集和方法无法满足专业工程工具的需求，因此需要针对高复杂度任务的解决方案。
- Method: 通过自动化框架生成41K标注视频，提出VideoCADFormer模型学习CAD交互，并设计VQA基准测试。
- Result: VideoCADFormer优于基线模型，揭示了视频UI理解中的关键挑战，如精确动作定位和多模态推理。
- Conclusion: VideoCAD为高复杂度UI交互学习提供了新方向，并揭示了未来研究的挑战。


### [106] [Vision LLMs Are Bad at Hierarchical Visual Understanding, and LLMs Are the Bottleneck](https://arxiv.org/abs/2505.24840)
*Yuwen Tan,Yuan Qing,Boqing Gong*

Main category: cs.CV

TL;DR: 研究发现，当前大型语言模型（LLMs）缺乏对视觉世界的层次知识，限制了视觉LLMs的层次理解能力。通过构建大量视觉问答任务验证了这一点，并发现微调LLMs能部分改善其层次一致性。

- Motivation: 揭示LLMs在视觉层次知识上的不足，探索其对视觉LLMs理解能力的限制。
- Method: 使用约一百万道四选一视觉问答任务，基于六种分类法和四个图像数据集进行分析，并对视觉LLM进行微调。
- Result: LLMs在层次知识上的不足成为视觉LLMs的瓶颈，微调LLMs能部分提升其层次一致性。
- Conclusion: 视觉LLMs的完全层次理解依赖于LLMs具备相应的分类知识。


### [107] [Reading Recognition in the Wild](https://arxiv.org/abs/2505.24848)
*Charig Yang,Samiul Alam,Shakhrul Iman Siam,Michael J. Proulx,Lambert Mathias,Kiran Somasundaram,Luis Pesqueira,James Fort,Sheroze Sheriffdeen,Omkar Parkhi,Carl Ren,Mi Zhang,Yuning Chai,Richard Newcombe,Hyo Jin Kim*

Main category: cs.CV

TL;DR: 论文提出了一种新的阅读识别任务，用于判断用户何时在阅读，并引入了首个大规模多模态数据集“Reading in the Wild”。通过结合RGB、眼动和头部姿态三种模态，提出了灵活的Transformer模型，验证了这些模态的相关性和互补性。

- Motivation: 为了实现智能眼镜中的上下文感知AI，需要记录用户与世界的互动，包括阅读行为。当前研究在受限环境中进行，缺乏大规模和多样化的数据。
- Method: 引入了“Reading in the Wild”数据集，包含100小时的阅读和非阅读视频。提出了一种灵活的Transformer模型，利用RGB、眼动和头部姿态三种模态进行任务。
- Result: 验证了三种模态对阅读识别任务的相关性和互补性，并展示了数据集在分类阅读类型中的实用性。
- Conclusion: 该研究扩展了阅读理解研究的规模和多样性，为智能眼镜中的上下文感知AI提供了新方法。


### [108] [ViStoryBench: Comprehensive Benchmark Suite for Story Visualization](https://arxiv.org/abs/2505.24862)
*Cailin Zhuang,Ailin Huang,Wei Cheng,Jingwei Wu,Yaoqi Hu,Jiaqi Liao,Zhewei Huang,Hongyuan Wang,Xinyao Liao,Weiwei Cai,Hengyuan Xu,Xuanyang Zhang,Xianfang Zeng,Gang Yu,Chi Zhang*

Main category: cs.CV

TL;DR: ViStoryBench是一个用于评估故事可视化模型性能的综合性基准，涵盖多种故事类型和艺术风格，旨在促进模型的改进。

- Motivation: 为了在现实场景中提升故事可视化框架的性能，需要一种全面的评估方法。
- Method: 收集多样化的数据集，包括不同情节和视觉风格的故事，并设计多维度评估指标。
- Result: ViStoryBench提供了一个结构化框架，能够全面评估模型的优缺点。
- Conclusion: 该基准有助于研究者针对性地改进故事可视化模型。


### [109] [TalkingHeadBench: A Multi-Modal Benchmark & Analysis of Talking-Head DeepFake Detection](https://arxiv.org/abs/2505.24866)
*Xinqi Xiong,Prakrut Patel,Qingyuan Fan,Amisha Wadhwa,Sarathy Selvam,Xiao Guo,Luchao Qi,Xiaoming Liu,Roni Sengupta*

Main category: cs.CV

TL;DR: 论文介绍了TalkingHeadBench，一个用于评估先进深度伪造检测模型的多模型多生成器基准测试和数据集，旨在解决当前基准测试的不足。

- Motivation: 深度伪造技术的快速发展对媒体、政治和金融等领域构成风险，但现有检测基准未能反映最新进展，缺乏对模型鲁棒性和泛化能力的评估。
- Method: 提出TalkingHeadBench，包含由领先学术和商业模型合成的深度伪造视频，设计协议评估身份和生成器特性分布变化下的泛化能力。
- Result: 对多种检测方法（如CNN、视觉Transformer和时间模型）进行基准测试，分析其鲁棒性和泛化能力，并通过Grad-CAM可视化揭示常见失败模式和检测器偏差。
- Conclusion: TalkingHeadBench旨在推动更鲁棒和泛化的检测模型研究，以应对快速发展的生成技术。


### [110] [Time Blindness: Why Video-Language Models Can't See What Humans Can?](https://arxiv.org/abs/2505.24867)
*Ujjwal Upadhyay,Mukul Ranjan,Zhiqiang Shen,Mohamed Elhoseiny*

Main category: cs.CV

TL;DR: SpookyBench是一个专注于纯时间序列噪声帧的基准测试，揭示了当前视觉语言模型在时空关系理解上的局限性。

- Motivation: 现有视觉语言模型在空间信息被遮挡时无法捕捉纯时间模式，与人类能力形成鲜明对比。
- Method: 通过SpookyBench基准测试，评估模型在低空间信噪比下的时间模式识别能力。
- Result: 人类在SpookyBench上准确率超过98%，而先进模型为0%，显示模型对时间线索的依赖不足。
- Conclusion: 需开发新架构或训练范式以解耦空间依赖，提升时间模式识别能力。


### [111] [SiLVR: A Simple Language-based Video Reasoning Framework](https://arxiv.org/abs/2505.24869)
*Ce Zhang,Yan-Bo Lin,Ziyang Wang,Mohit Bansal,Gedas Bertasius*

Main category: cs.CV

TL;DR: SiLVR是一个简单的基于语言的视频推理框架，通过两阶段分解复杂视频理解任务，利用语言表示和强大的LLM推理能力，显著提升多模态LLM在视频语言任务中的表现。

- Motivation: 多模态LLM在复杂视频语言任务中的推理能力显著落后，SiLVR旨在通过语言表示和LLM推理填补这一差距。
- Method: SiLVR分为两阶段：1) 将原始视频转换为基于语言的表示；2) 将语言描述输入强大的LLM进行推理。采用自适应令牌缩减方案处理长上下文多感官输入。
- Result: SiLVR在多个视频语言任务（如Video-MME、Video-MMMU等）中取得最佳结果，并验证了LLM在视频推理中的有效性。
- Conclusion: SiLVR展示了无需显式视频训练的LLM仍能有效整合多感官信息，为复杂视频推理任务提供解决方案。


### [112] [GenSpace: Benchmarking Spatially-Aware Image Generation](https://arxiv.org/abs/2505.24870)
*Zehan Wang,Jiayang Xu,Ziang Zhang,Tianyu Pan,Chao Du,Hengshuang Zhao,Zhou Zhao*

Main category: cs.CV

TL;DR: GenSpace是一个评估AI图像生成模型空间感知能力的新基准和评估流程，揭示了当前模型在3D细节上的不足。

- Motivation: 研究AI图像生成模型是否具备类似人类的空间感知能力，以生成更准确的3D场景。
- Method: 提出GenSpace基准和专用评估流程，利用多视觉基础模型重建3D场景几何，提供更精确的空间忠实度度量。
- Result: AI模型虽能生成视觉吸引人的图像，但在对象放置、关系和测量等3D细节上表现不佳。
- Conclusion: 总结了当前图像生成模型在空间感知上的三大局限，为改进空间智能提供了方向。


### [113] [MoDoMoDo: Multi-Domain Data Mixtures for Multimodal LLM Reinforcement Learning](https://arxiv.org/abs/2505.24871)
*Yiqing Liang,Jielin Qiu,Wenhao Ding,Zuxin Liu,James Tompkin,Mengdi Xu,Mengzhou Xia,Zhengzhong Tu,Laixi Shi,Jiacheng Zhu*

Main category: cs.CV

TL;DR: 论文提出了一种针对多模态大语言模型（MLLMs）的系统性后训练框架RLVR，通过优化数据集混合策略提升泛化和推理能力。

- Motivation: 多模态任务复杂且多样，传统RLVR方法在多数据集训练中可能因目标冲突而受限，需优化数据混合策略以提升性能。
- Method: 开发了多模态RLVR框架，支持多领域在线强化学习，并提出数据混合策略以预测和优化最佳混合分布。
- Result: 实验表明，结合混合预测策略的多领域RLVR训练显著提升MLLM的泛化能力，最佳混合策略使模型在分布外基准上的准确率平均提升5.24%。
- Conclusion: 优化数据混合策略在多模态RLVR训练中至关重要，能显著提升模型性能。


### [114] [ProxyThinker: Test-Time Guidance through Small Visual Reasoners](https://arxiv.org/abs/2505.24872)
*Zilin Xiao,Jaywon Koo,Siru Ouyang,Jefferson Hernandez,Yu Meng,Vicente Ordonez*

Main category: cs.CV

TL;DR: ProxyThinker是一种无需训练的推理时技术，通过调整解码动态，使大型视觉语言模型继承小型视觉推理器的能力，显著提升性能并加速推理。

- Motivation: 训练大型视觉语言模型（LVLMs）时，强化微调（RFT）计算成本高，难以扩展模型规模。
- Method: 通过从RFT推理器的输出分布中减去基础模型的输出分布，ProxyThinker修改解码动态，激发慢速推理行为（如自我验证和修正）。
- Result: ProxyThinker在空间、数学和多学科推理的视觉基准测试中显著提升性能，推理速度比之前方法快38倍。
- Conclusion: ProxyThinker为大型模型的实用部署提供了高效解决方案，无需额外训练即可提升性能。


### [115] [MiniMax-Remover: Taming Bad Noise Helps Video Object Removal](https://arxiv.org/abs/2505.24873)
*Bojia Zi,Weixuan Peng,Xianbiao Qi,Jianan Wang,Shihao Zhao,Rong Xiao,Kam-Fai Wong*

Main category: cs.CV

TL;DR: MiniMax-Remover提出了一种两阶段视频对象移除方法，通过简化模型架构和最小化优化策略，显著提高了编辑质量和推理速度。

- Motivation: 视频对象移除是视频编辑的关键子任务，但现有方法存在幻觉对象、视觉伪影和计算成本高的问题。
- Method: 第一阶段移除文本输入和交叉注意力层以简化模型；第二阶段通过最小化优化策略进一步优化模型。
- Result: 方法在仅6次采样步骤下实现了最先进的视频对象移除效果，且不依赖CFG，显著提升了推理效率。
- Conclusion: MiniMax-Remover在视频对象移除任务中表现出高效性和优越性。


### [116] [ReasonGen-R1: CoT for Autoregressive Image generation models through SFT and RL](https://arxiv.org/abs/2505.24875)
*Yu Zhang,Yunqi Li,Yifan Yang,Rui Wang,Yuqing Yang,Dai Qi,Jianmin Bao,Dongdong Chen,Chong Luo,Lili Qiu*

Main category: cs.CV

TL;DR: ReasonGen-R1是一个两阶段框架，结合了链式思维推理和强化学习，用于生成视觉模型，通过文本推理优化图像生成。

- Motivation: 尽管链式思维推理和强化学习在NLP中取得突破，但在生成视觉模型中的应用尚未充分探索。
- Method: 1. 通过监督微调在推理数据集上训练模型；2. 使用Group Relative Policy Optimization（GRPO）算法优化输出。
- Result: 在GenEval、DPG和T2I基准测试中，ReasonGen-R1表现优于基线模型和现有最优模型。
- Conclusion: ReasonGen-R1通过结合文本推理和强化学习，显著提升了生成视觉模型的质量和可控性。


### [117] [Agent-X: Evaluating Deep Multimodal Reasoning in Vision-Centric Agentic Tasks](https://arxiv.org/abs/2505.24876)
*Tajamul Ashraf,Amal Saqib,Hanan Ghani,Muhra AlMahri,Yuhao Li,Noor Ahsan,Umair Nawaz,Jean Lahoud,Hisham Cholakkal,Mubarak Shah,Philip Torr,Fahad Shahbaz Khan,Rao Muhammad Anwer,Salman Khan*

Main category: cs.CV

TL;DR: Agent-X是一个大规模基准测试，用于评估视觉中心代理在多步和深度推理能力方面的表现，覆盖多种真实世界任务。

- Motivation: 现有基准测试通常局限于合成、单轮查询和单一视觉模态，无法评估真实场景中多步推理的质量。
- Method: 引入Agent-X基准，包含828个任务，涵盖多种视觉环境和工具使用，并提出细粒度的步级评估框架。
- Result: 即使最佳模型（如GPT、Gemini和Qwen系列）在多步视觉任务中的成功率也低于50%。
- Conclusion: 当前LMM在多步推理和工具使用方面存在瓶颈，需进一步研究改进。


### [118] [AdaHuman: Animatable Detailed 3D Human Generation with Compositional Multiview Diffusion](https://arxiv.org/abs/2505.24877)
*Yangyi Huang,Ye Yuan,Xueting Li,Jan Kautz,Umar Iqbal*

Main category: cs.CV

TL;DR: AdaHuman是一个从单张图像生成高保真可动画3D头像的新框架，通过创新的扩散模型和3D高斯溅射技术实现高细节和动画兼容性。

- Motivation: 现有方法难以生成适合实际应用的高细节、可动画的3D头像。
- Method: AdaHuman结合了姿势条件化的3D联合扩散模型和3D高斯溅射细化模块，生成多视角图像并优化局部细节。
- Result: 在公开基准测试和实际图像中，AdaHuman显著优于现有方法，生成的头像适合绑定和动画。
- Conclusion: AdaHuman为高保真3D头像生成提供了有效解决方案，代码和模型将公开。
## cs.AI

### [119] [Open CaptchaWorld: A Comprehensive Web-based Platform for Testing and Benchmarking Multimodal LLM Agents](https://arxiv.org/abs/2505.24878)
*Yaxin Luo,Zhaoyi Li,Jiacheng Liu,Jiacheng Cui,Xiaohan Zhao,Zhiqiang Shen*

Main category: cs.AI

TL;DR: Open CaptchaWorld是一个专门用于评估多模态LLM代理在动态CAPTCHA任务中表现的基准平台，揭示了当前代理与人类性能的显著差距。

- Motivation: CAPTCHAs是网络代理部署的关键瓶颈，而现有多模态代理在动态交互任务中的能力尚未充分测试。
- Method: 开发了Open CaptchaWorld基准平台，包含20种CAPTCHA类型和225个任务，并提出了新的评估指标CAPTCHA Reasoning Depth。
- Result: 人类表现接近完美（93.3%），而最佳MLLM代理成功率仅为40.0%。
- Conclusion: Open CaptchaWorld是诊断多模态代理局限性的重要工具，可推动更鲁棒的多模态推理系统发展。
## stat.ML

### [120] [Conformal Object Detection by Sequential Risk Control](https://arxiv.org/abs/2505.24038)
*Léo Andéol,Luca Mossina,Adrien Mazoyer,Sébastien Gerchinovitz*

Main category: stat.ML

TL;DR: 论文提出了一种基于Conformal Prediction的Conformal Object Detection（COD）方法，通过Sequential Conformal Risk Control（SeqCRC）扩展统计保证，适用于目标检测任务，并提供了实验验证和工具包。

- Motivation: 目标检测模型在关键应用中的可靠性不足，需要一种无需先验知识的统计保证方法。
- Method: 提出SeqCRC方法，扩展Conformal Risk Control（CRC）至顺序任务，设计适合不同应用的损失函数和预测集。
- Result: 实验验证了方法的有效性，展示了不同方法间的权衡和实际影响。
- Conclusion: SeqCRC为COD提供了统计保证，工具包支持进一步研究和应用。


### [121] [A Mathematical Perspective On Contrastive Learning](https://arxiv.org/abs/2505.24134)
*Ricardo Baptista,Andrew M. Stuart,Son Tran*

Main category: stat.ML

TL;DR: 本文提出了一种基于概率框架的多模态对比学习方法，通过优化编码器定义的条件概率分布，扩展了传统对比学习的应用，包括跨模态检索、分类和生成任务。

- Motivation: 传统多模态对比学习通常关注模态间的表示对齐，但缺乏对概率框架的系统性探索。本文旨在填补这一空白，通过概率视角重新定义对比学习，并探索其在跨模态任务中的潜力。
- Method: 将对比学习视为优化定义条件概率分布的编码器，提出新的概率损失函数和对齐度量方法，并在多元高斯设置下研究其性质。
- Result: 通过理论分析和数值实验（包括MNIST数据集和海洋学应用），验证了所提方法的有效性，特别是在模式搜索和生成任务中。
- Conclusion: 本文的概率框架为多模态对比学习提供了新的理论基础和算法扩展，展示了其在跨模态任务中的广泛应用潜力。


### [122] [Efficient Estimation of Regularized Tyler's M-Estimator Using Approximate LOOCV](https://arxiv.org/abs/2505.24781)
*Karim Abou-Moustafa*

Main category: stat.ML

TL;DR: 提出了一种高效估计正则化参数α的方法，通过近似留一交叉验证（LOOCV）对数似然损失，显著降低了计算复杂度。

- Motivation: 解决RTME中正则化参数α估计的高计算成本问题。
- Method: 提出近似LOOCV对数似然损失的方法，避免重复计算RTME。
- Result: 在合成和真实高维数据上验证了方法的效率和准确性。
- Conclusion: 该方法比现有方法更高效且准确。
## cs.CL

### [123] [My Answer Is NOT 'Fair': Mitigating Social Bias in Vision-Language Models via Fair and Biased Residuals](https://arxiv.org/abs/2505.23798)
*Jian Lan,Yifei Fu,Udo Schlegel,Gengyuan Zhang,Tanveer Hannan,Haokun Chen,Thomas Seidl*

Main category: cs.CL

TL;DR: 该论文研究了大型视觉语言模型（VLMs）中的社会偏见问题，提出了一种无需训练的后处理方法以减少生成响应中的偏见。

- Motivation: 社会偏见在VLMs中是一个严重问题，可能导致对某些社会群体的不公平和伦理问题，但目前对其在生成响应中的表现尚不清楚。
- Method: 研究首先评估了四种最先进的VLMs在PAIRS和SocialCounterfactuals数据集上的表现，发现模型存在性别和种族偏见。随后提出了一种后处理方法，通过调整隐藏层中的残差来减少偏见。
- Result: 实验表明，该方法在减少偏见和提高模型置信度可靠性方面优于其他训练策略。
- Conclusion: 该研究揭示了VLMs中偏见的来源，并提出了一种有效的后处理方法，为模型公平性提供了新思路。


### [124] [Mixed-R1: Unified Reward Perspective For Reasoning Capability in Multimodal Large Language Models](https://arxiv.org/abs/2505.24164)
*Shilin Xu,Yanwei Li,Rui Yang,Tao Zhang,Yueyi Sun,Wei Chow,Linfeng Li,Hang Song,Qi Xu,Yunhai Tong,Xiangtai Li,Hao Fei*

Main category: cs.CL

TL;DR: 论文提出Mixed-R1框架，通过混合奖励函数设计（Mixed-Reward）和混合后训练数据集（Mixed-45K）解决多源MLLM任务的稳定强化学习问题。

- Motivation: 现有研究仅关注MLLM的单一任务（如数学问题或图表分析），缺乏多任务统一的强化学习方法。
- Method: 设计数据引擎构建Mixed-45K数据集，并提出包含四种奖励函数的Mixed-Reward（匹配奖励、图表奖励、IoU奖励和开放式奖励BMAS）。
- Result: 实验验证了Mixed-R1在多种MLLM（如Qwen2.5-VL和Intern-VL）上的有效性。
- Conclusion: Mixed-R1为多源MLLM任务提供了一种统一的强化学习解决方案。


### [125] [LegalEval-Q: A New Benchmark for The Quality Evaluation of LLM-Generated Legal Text](https://arxiv.org/abs/2505.24826)
*Li yunhan,Wu gengshen*

Main category: cs.CL

TL;DR: 本文提出了一种评估法律文本质量的框架，包括清晰度、连贯性和术语准确性，并分析了49个LLM，发现模型质量在140亿参数后趋于稳定，推理模型表现优于基础架构。

- Motivation: 当前法律领域LLM评估主要关注事实准确性，忽视了语言质量（如清晰度、连贯性和术语准确性），本文旨在填补这一空白。
- Method: 1. 开发回归模型评估法律文本质量；2. 创建专门的法律问题集；3. 用该框架分析49个LLM。
- Result: 1. 模型质量在140亿参数后仅小幅提升；2. 工程选择（如量化和上下文长度）影响可忽略；3. 推理模型表现更优。Qwen3系列在性价比上表现最佳。
- Conclusion: 本文建立了法律LLM的标准化评估协议，揭示了当前训练数据优化的局限性，并发布了代码和模型。
## cond-mat.mtrl-sci

### [126] [Exploring Domain Wall Pinning in Ferroelectrics via Automated High Throughput AFM](https://arxiv.org/abs/2505.24062)
*Kamyar Barakati,Yu Liu,Hiroshi Funakubo,Sergei V. Kalinin*

Main category: cond-mat.mtrl-sci

TL;DR: 论文研究了铁电材料中畴壁动力学的空间依赖性，通过机器学习控制的自动化压电力显微镜量化了电场驱动的极应变畴结构动态行为，揭示了畴壁位移与局部铁电-铁弹构型的关系。

- Motivation: 由于每个极性界面被锁定在独特的局部微结构中，畴壁动力学具有强烈的空间依赖性，需要高分辨率研究。传统方法效率低，因此采用自动化技术提高研究效率。
- Method: 使用机器学习控制的自动化压电力显微镜（PFM）研究了PbTiO3薄膜中的畴壁动力学，分析了1500个开关事件。
- Result: 畴壁位移不仅取决于电场参数，还与局部铁电-铁弹构型相关。例如，双晶界在特定偏压下保持固定，而单变体边界在较低偏压下即被激活。
- Conclusion: 通过自动化高通量AFM工作流程和畴构型统计，可以建立预测性映射，为铁电存储器设计提供微观结构特定的规则集。
## cs.GR

### [127] [3DGEER: Exact and Efficient Volumetric Rendering with 3D Gaussians](https://arxiv.org/abs/2505.24053)
*Zixun Huang,Cho-Ying Wu,Yuliang Guo,Xinyu Huang,Liu Ren*

Main category: cs.GR

TL;DR: 3DGEER是一种精确高效的体积高斯渲染方法，解决了3D高斯溅射（3DGS）在大视场输入下的渲染质量问题，同时保持实时性能。

- Motivation: 3DGS在平衡渲染质量和效率方面取得了进展，但其近似投影方法在大视场输入下限制了渲染质量。现有方法未能同时实现精确性和高效性。
- Method: 从第一性原理出发，推导了3D高斯分布沿射线的密度积分闭式表达式，提出了粒子边界视锥（PBF）和双极等角投影（BEAP）表示，以加速射线关联和优化渲染。
- Result: 实验表明，3DGEER在多种相机模型下均优于现有方法，实现了实时神经渲染的最新水平。
- Conclusion: 3DGEER通过精确的渲染和高效的优化方法，显著提升了渲染质量，为实时神经渲染设定了新标准。


### [128] [TC-GS: A Faster Gaussian Splatting Module Utilizing Tensor Cores](https://arxiv.org/abs/2505.24796)
*Zimu Liao,Jifeng Ding,Rong Fu,Siwei Cui,Ruixuan Gong,Li Wang,Boni Hu,Yi Wang,Hengjie Li,XIngcheng Zhang,Hui Wang*

Main category: cs.GR

TL;DR: TC-GS通过将alpha计算映射到矩阵乘法，利用Tensor Core加速3D高斯渲染，提升速度2.18倍，总加速达5.6倍。

- Motivation: 现有3D高斯渲染中，alpha混合是时间瓶颈，且Tensor Core未被充分利用。
- Method: 提出TC-GS模块，将alpha计算转为矩阵乘法，并引入全局到局部坐标变换以减少精度误差。
- Result: 实验显示，TC-GS在保持渲染质量的同时，速度提升2.18倍，总加速5.6倍。
- Conclusion: TC-GS是一种通用模块，可无缝集成现有优化框架，显著提升3D高斯渲染效率。
## eess.IV

### [129] [Parameter-Free Bio-Inspired Channel Attention for Enhanced Cardiac MRI Reconstruction](https://arxiv.org/abs/2505.23872)
*Anam Hashmi,Julia Dietlmeier,Kathleen M. Curran,Noel E. O'Connor*

Main category: eess.IV

TL;DR: 提出了一种基于生态学原理的非线性注意力架构，用于心脏MRI重建，其参数免费模块优于现有方法。

- Motivation: 现有注意力模块缺乏理论支持，研究通过生态学原理填补这一空白。
- Method: 利用描述单物种种群增长的非线性生态差分方程设计参数免费注意力模块。
- Result: 提出的注意力模块在性能上超越了当前最先进的参数免费方法。
- Conclusion: 生态学原理可指导开发高效注意力机制，提升模型性能与可解释性。


### [130] [Estimating Head Motion in Structural MRI Using a Deep Neural Network Trained on Synthetic Artifacts](https://arxiv.org/abs/2505.23916)
*Charles Bricout,Samira Ebrahimi Kahou,Sylvain Bouix*

Main category: eess.IV

TL;DR: 该论文提出了一种基于3D卷积神经网络的自动化方法，用于评估MRI中的运动伪影，无需依赖专业硬件或噪声数据。

- Motivation: MRI中的运动伪影会影响神经解剖学指标的准确性，现有方法存在硬件依赖或数据噪声问题。
- Method: 使用合成损坏的3D体积训练卷积神经网络，评估运动严重程度。
- Result: 在独立数据集上验证，与人工评分相关性达R²=0.65，并在12/15数据集中显示厚度-运动相关性。
- Conclusion: 该方法适用于不同扫描仪和协议，为结构MRI研究提供了客观、可扩展的运动评估方案。


### [131] [Sparsity-Driven Parallel Imaging Consistency for Improved Self-Supervised MRI Reconstruction](https://arxiv.org/abs/2505.24136)
*Yaşar Utku Alçalar,Mehmet Akçakaya*

Main category: eess.IV

TL;DR: 提出了一种通过扰动训练物理驱动的深度学习模型的新方法，以减少高加速率MRI重建中的伪影。

- Motivation: 在缺乏完全采样参考数据的情况下，自监督学习在高加速率MRI重建中常引入伪影，影响图像质量。
- Method: 通过精心设计的扰动训练模型，并在稀疏域中评估模型对扰动的预测能力，引入一致性项。
- Result: 在fastMRI膝部和脑部数据集上，新方法有效减少了伪影和噪声放大，优于现有自监督方法。
- Conclusion: 提出的训练策略在高加速率MRI重建中显著提升了图像质量和可靠性。


### [132] [Beyond the LUMIR challenge: The pathway to foundational registration models](https://arxiv.org/abs/2505.24160)
*Junyu Chen,Shuwen Wei,Joel Honkamaa,Pekka Marttinen,Hang Zhang,Min Liu,Yichao Zhou,Zuopeng Tan,Zhuoyuan Wang,Yi Wang,Hongchao Zhou,Shunbo Hu,Yi Zhang,Qian Tao,Lukas Förner,Thomas Wendler,Bailiang Jian,Benedikt Wiestler,Tim Hable,Jin Kim,Dan Ruan,Frederic Madesta,Thilo Sentker,Wiebke Heyer,Lianrui Zuo,Yuwei Dai,Jing Wu,Jerry L. Prince,Harrison Bai,Yong Du,Yihao Liu,Alessa Hering,Reuben Dorent,Lasse Hansen,Mattias P. Heinrich,Aaron Carass*

Main category: eess.IV

TL;DR: LUMIR挑战赛是一个无监督脑MRI图像配准的新基准，旨在通过自监督学习推动生物合理变形建模，并在多领域任务中评估深度学习方法的性能。

- Motivation: 医学图像挑战赛推动了算法创新，但现有方法依赖标注数据。LUMIR旨在通过无监督方式解决这一问题，并评估模型在零样本任务中的泛化能力。
- Method: 提供4000多张无标注的T1加权脑MRI图像进行训练，通过自监督学习建模变形。评估包括590个测试样本和零样本任务（跨模态、疾病、协议和物种）。
- Result: 深度学习方法在配准精度和解剖合理性上表现最佳，优于优化方法，但对某些跨模态任务性能下降。
- Conclusion: LUMIR展示了无监督深度学习方法在脑MRI配准中的潜力，尤其在零样本任务中表现优异，但仍需改进跨模态适应性。


### [133] [A Novel Coronary Artery Registration Method Based on Super-pixel Particle Swarm Optimization](https://arxiv.org/abs/2505.24351)
*Peng Qi,Wenxi Qu,Tianliang Yao,Haonan Ma,Dylan Wintle,Yinyi Lai,Giorgos Papanastasiou,Chengjia Wang*

Main category: eess.IV

TL;DR: 提出了一种基于群体优化算法的多模态冠状动脉图像配准方法，显著提高了PCI手术的精确性和安全性。

- Motivation: 利用CTA的3D血管解剖信息与实时XRA结合，以提升PCI手术的导航效果并减少并发症。
- Method: 采用预处理模块和基于Steger与超像素粒子群优化算法的配准模块，处理XRA和CTA图像。
- Result: 在28对XRA和CTA图像上测试，优于四种现有方法，配准精度、鲁棒性和效率均更优。
- Conclusion: 该方法显著提升了多模态图像配准效果，有望改善冠状动脉疾病的临床治疗效果。


### [134] [Efficient RAW Image Deblurring with Adaptive Frequency Modulation](https://arxiv.org/abs/2505.24407)
*Wenlong Jiao,Binglong Li,Wei Shang,Ping Wang,Dongwei Ren*

Main category: eess.IV

TL;DR: FrENet是一种针对RAW图像去模糊的频率增强网络，通过频域操作和自适应频率调制模块提升恢复质量。

- Motivation: 现有深度学习方法主要关注sRGB图像，而RAW图像因其未处理和线性特性具有更好的恢复潜力，但研究较少。
- Method: 提出FrENet框架，直接在频域操作，引入自适应频率位置调制模块和频域跳跃连接。
- Result: FrENet在RAW图像去模糊中优于现有方法，恢复质量更高且计算效率更高，同时可扩展到sRGB图像。
- Conclusion: FrENet为RAW图像去模糊提供了高效解决方案，并展示了在sRGB图像上的扩展潜力。


### [135] [pyMEAL: A Multi-Encoder Augmentation-Aware Learning for Robust and Generalizable Medical Image Translation](https://arxiv.org/abs/2505.24421)
*Abdul-mojeed Olabisi Ilyas,Adeleke Maradesa,Jamal Banzi,Jianpan Huang,Henry K. F. Mak,Kannie W. Y. Chan*

Main category: eess.IV

TL;DR: MEAL框架通过多编码器和融合策略解决医学影像数据稀缺和增强问题，在CT-to-MRI转换中表现最佳。

- Motivation: 医学影像AI面临患者差异、图像伪影和模型泛化不足的挑战，传统增强方法忽视数据特性且难以处理大数据量。
- Method: 提出MEAL框架，利用四种增强变体和三种融合策略（CC、FL、BD）构建多编码器模型，保留增强感知特征。
- Result: MEAL-BD在CT-to-MRI转换中表现最优，PSNR和SSIM得分高于其他方法，适应几何变换和非增强输入。
- Conclusion: MEAL通过增强多样性提升特征泛化能力，为临床可靠的医学影像解决方案提供支持。


### [136] [Model-Guided Network with Cluster-Based Operators for Spatio-Spectral Super-Resolution](https://arxiv.org/abs/2505.24605)
*Ivan Pereira-Sánchez,Julia Navarro,Ana Belén Petro,Joan Duran*

Main category: eess.IV

TL;DR: 提出一种端到端的模型驱动框架，将联合空间-光谱超分辨率问题分解为空间超分辨率、光谱超分辨率和融合任务，并通过可学习模块优化各子任务。

- Motivation: 解决从低分辨率多光谱观测中重建高分辨率高光谱图像的问题，填补联合空间-光谱超分辨率研究的空白。
- Method: 将问题分解为三个子任务，分别采用基于变分的方法，并用可学习模块替代传统算子；设计了基于反向投影算法的空间上采样算子和基于聚类的光谱重建算子，融合时结合低频估计与高频注入模块，并引入非局部后处理步骤。
- Result: 在多个数据集和采样因子上的广泛评估证明了方法的有效性。
- Conclusion: 提出的框架在联合空间-光谱超分辨率任务中表现优异，代码将开源。


### [137] [TumorGen: Boundary-Aware Tumor-Mask Synthesis with Rectified Flow Matching](https://arxiv.org/abs/2505.24687)
*Shengyuan Liu,Wenting Chen,Boyun Zheng,Wentao Pan,Xiang Li,Yixuan Yuan*

Main category: eess.IV

TL;DR: TumorGen提出了一种高效的三维肿瘤合成方法，通过边界感知和流匹配技术解决了现有方法的多样性和计算效率问题。

- Motivation: 解决现有肿瘤数据合成方法中肿瘤多样性受限、计算效率低以及边界过渡不自然的问题。
- Method: 提出三个关键模块：边界感知伪掩码生成、空间约束向量场估计器和VAE引导的掩码细化器，利用流匹配技术提高效率。
- Result: 实验表明，TumorGen在计算效率和肿瘤真实性上优于现有方法。
- Conclusion: TumorGen为AI驱动的癌症诊断提供了高效且真实的肿瘤合成解决方案。


### [138] [Contrast-Invariant Self-supervised Segmentation for Quantitative Placental MRI](https://arxiv.org/abs/2505.24739)
*Xinliu Zhong,Ruiying Liu,Emily S. Nichols,Xuzhe Zhang,Andrew F. Laine,Emma G. Duerden,Yun Wang*

Main category: eess.IV

TL;DR: 提出了一种基于多回波T2*加权MRI的胎盘分割框架，通过自监督学习和无监督域适应解决边界对比弱、标注缺失和运动伪影问题。

- Motivation: 胎盘分割在T2*加权成像中面临边界对比弱、标注缺失和运动伪影的挑战，需要一种鲁棒的分割方法。
- Method: 结合掩码自编码（MAE）进行自监督预训练，掩码伪标签（MPL）实现无监督域适应，并通过全局-局部协作和语义匹配损失优化特征一致性。
- Result: 在临床多回波胎盘MRI数据集上，该方法优于单回波和简单融合基线，能有效泛化到不同回波时间。
- Conclusion: 这是首个系统利用多回波T2*加权MRI进行胎盘分割的研究，展示了其潜力。


### [139] [Beyond Pretty Pictures: Combined Single- and Multi-Image Super-resolution for Sentinel-2 Images](https://arxiv.org/abs/2505.24799)
*Aditya Retnanto,Son Le,Sebastian Mueller,Armin Leitner,Konrad Schindler,Yohan Iddawela,Michael Riffler*

Main category: eess.IV

TL;DR: SEN4X是一种混合超分辨率架构，结合单图像和多图像技术，将Sentinel-2图像分辨率提升至2.5米，显著优于现有方法。

- Motivation: Sentinel-2卫星图像分辨率较低，无法捕捉小尺度特征（如房屋、街道），需通过超分辨率技术提升。
- Method: 结合Sentinel-2的时间过采样和高分辨率Pléiades Neo数据的学习先验，提出混合架构SEN4X。
- Result: 在越南河内的城市土地覆盖分类测试中，SEN4X显著优于现有超分辨率基线。
- Conclusion: SEN4X有效提升了Sentinel-2图像的分辨率，适用于小尺度特征识别。
## physics.med-ph

### [140] [Digital twins enable full-reference quality assessment of photoacoustic image reconstructions](https://arxiv.org/abs/2505.24514)
*Janek Gröhl,Leonid Kunyansky,Jenni Poimala,Thomas R. Else,Francesca Di Cecio,Sarah E. Bohndiek,Ben T. Cox,Andreas Hauptmann*

Main category: physics.med-ph

TL;DR: 该论文提出了一种利用数字孪生技术定量评估光声图像重建算法质量的方法，并首次在实验数据中测试了一种基于傅里叶变换的重建算法。

- Motivation: 光声图像重建算法的定量比较缺乏理想参考图像，数字孪生技术可减少模拟与实际成像的差距。
- Method: 使用数字孪生框架比较多种重建算法，并测试了一种基于傅里叶变换的算法。
- Result: 数字孪生技术有效评估了数值前向模型的准确性，傅里叶变换算法与迭代时间反转结果相当但计算成本更低。
- Conclusion: 数字孪生技术为光声图像重建算法的定量评估提供了新途径，傅里叶变换算法具有高效性。
## cs.RO

### [141] [SR3D: Unleashing Single-view 3D Reconstruction for Transparent and Specular Object Grasping](https://arxiv.org/abs/2505.24305)
*Mingxu Zhang,Xiaoqi Li,Jiahui Xu,Kaichen Zhou,Hojin Bae,Yan Shen,Chuyan Xiong,Jiaming Liu,Hao Dong*

Main category: cs.RO

TL;DR: SR3D是一种无需训练的框架，通过单视角RGB和深度图像实现透明和镜面物体的3D重建与抓取。

- Motivation: 透明和镜面材料因深度感知限制难以抓取，现有方法复杂或信息利用不足。
- Method: 利用单视角3D重建模型生成物体网格，通过视图和关键点匹配确定物体3D状态，重建精确深度图。
- Result: 仿真和真实实验验证了SR3D的重建有效性。
- Conclusion: SR3D为透明和镜面物体的抓取提供了高效解决方案。


### [142] [Black-box Adversarial Attacks on CNN-based SLAM Algorithms](https://arxiv.org/abs/2505.24654)
*Maria Rafaela Gkeka,Bowen Sun,Evgenia Smirni,Christos D. Antonopoulos,Spyros Lalis,Nikolaos Bellas*

Main category: cs.RO

TL;DR: 论文研究了针对基于CNN的SLAM系统中特征检测器的对抗攻击，发现即使是中等规模的攻击也能导致76%的帧跟踪失败，且攻击深度输入比RGB输入更具破坏性。

- Motivation: 尽管深度学习在SLAM任务中取得了显著进展，但深度神经网络对对抗攻击的脆弱性限制了其在自主代理导航等应用中的可靠性。目前缺乏对针对CNN-SLAM特征检测器的对抗攻击的全面研究。
- Method: 研究采用黑盒对抗扰动方法，将其应用于输入GCN-SLAM算法的RGB图像，并在TUM数据集上进行实验。
- Result: 实验结果显示，中等规模的对抗攻击可导致76%的帧跟踪失败；攻击深度输入对SLAM系统的破坏性更大。
- Conclusion: 论文揭示了对抗攻击对基于CNN的SLAM系统的严重威胁，强调了在设计和部署此类系统时需考虑对抗鲁棒性。


### [143] [DiG-Net: Enhancing Quality of Life through Hyper-Range Dynamic Gesture Recognition in Assistive Robotics](https://arxiv.org/abs/2505.24786)
*Eran Bamani Beeri,Eden Nissinman,Avishai Sintov*

Main category: cs.RO

TL;DR: 提出了一种名为DiG-Net的新方法，用于远距离动态手势识别，显著提升了辅助机器人交互的可用性。

- Motivation: 当前手势识别方法仅限于短距离交互，限制了其在需要远距离辅助通信的场景中的应用。
- Method: 结合Depth-Conditioned Deformable Alignment (DADA)块和时空图模块，并引入Radiometric Spatio-Temporal Depth Attenuation Loss (RSTDAL)增强模型鲁棒性。
- Result: 在多样化数据集上实现了97.3%的识别准确率，显著优于现有方法。
- Conclusion: DiG-Net显著提升了辅助机器人在家庭医疗、工业安全和远程协助等场景中的可用性。


### [144] [Bi-Manual Joint Camera Calibration and Scene Representation](https://arxiv.org/abs/2505.24819)
*Haozhan Tang,Tianyi Zhang,Matthew Johnson-Roberson,Weiming Zhi*

Main category: cs.RO

TL;DR: Bi-JCR框架通过3D基础模型实现多机器人臂的联合相机校准和环境表示，无需标记物。

- Motivation: 传统相机校准过程繁琐，需多次拍摄标记物，Bi-JCR旨在简化这一过程，提升效率。
- Method: 利用3D基础模型进行无标记多视角对应，联合估计相机外参、臂间位姿和统一3D环境表示。
- Result: 实验验证了Bi-JCR在多种桌面环境中的鲁棒性，并展示了下游任务的适用性。
- Conclusion: Bi-JCR为双机器人臂协作提供了一种高效、无需标记的校准和表示解决方案。
## cs.CR

### [145] [PatchDEMUX: A Certifiably Robust Framework for Multi-label Classifiers Against Adversarial Patches](https://arxiv.org/abs/2505.24703)
*Dennis Jacob,Chong Xiang,Prateek Mittal*

Main category: cs.CR

TL;DR: PatchDEMUX是一个可证明鲁棒的多标签分类框架，通过将多标签分类任务分解为多个二分类问题，扩展了单标签分类的防御方法。

- Motivation: 现有可证明防御方法主要针对单标签分类，多标签分类的防御研究较少，而对抗补丁攻击对多标签分类器的性能有严重影响。
- Method: 将多标签分类任务视为一系列独立的二分类问题，利用现有的单标签分类防御方法（如PatchCleanser）扩展为多标签防御框架。
- Result: 在MS-COCO和PASCAL VOC数据集上，PatchDEMUX实现了非平凡的鲁棒性，同时保持了较高的干净性能。
- Conclusion: PatchDEMUX为多标签分类提供了一种可证明鲁棒的防御框架，填补了现有研究的空白。
## cs.LG

### [146] [Test-Time Training Done Right](https://arxiv.org/abs/2505.23884)
*Tianyuan Zhang,Sai Bi,Yicong Hong,Kai Zhang,Fujun Luan,Songlin Yang,Kalyan Sunkavalli,William T. Freeman,Hao Tan*

Main category: cs.LG

TL;DR: 本文提出了一种名为LaCT的大块测试时间训练方法，通过使用极大的块更新（2K至1M令牌）显著提高了硬件利用率，并改善了状态容量，适用于多种任务和模态。

- Motivation: 现有TTT方法在处理长上下文数据时效率低下，硬件利用率低（FLOPs利用率<5%），且不适合处理非1D有序序列数据。
- Method: 采用极大块更新（2K至1M令牌），提高硬件利用率，并支持非线性状态规模扩展（达模型参数的40%）。
- Result: 实验验证了LaCT在多种任务和模态中的有效性，包括图像集的新视角合成、语言模型和自回归视频扩散，最长支持1百万令牌的上下文长度。
- Conclusion: LaCT显著提升了长上下文建模和测试时间训练的效率与能力，有望推动该领域的进一步研究。


### [147] [Vision Language Models are Biased](https://arxiv.org/abs/2505.23941)
*An Vo,Khai-Nguyen Nguyen,Mohammad Reza Taesiri,Vy Tuong Dang,Anh Totti Nguyen,Daeyoung Kim*

Main category: cs.LG

TL;DR: 研究发现视觉语言模型（VLMs）因先验知识偏见在计数和识别任务中表现不佳，平均准确率仅17.05%。

- Motivation: 探索先验知识如何影响VLMs在视觉任务中的准确性，揭示其偏见问题。
- Method: 测试VLMs在7个领域的计数任务（如条纹计数），并插入文本描述以观察影响。
- Result: VLMs表现严重偏差，即使指令调整仅提升2%准确率。
- Conclusion: 研究揭示了VLMs的偏见问题，并提供了测试框架。


### [148] [From Images to Signals: Are Large Vision Models Useful for Time Series Analysis?](https://arxiv.org/abs/2505.24030)
*Ziming Zhao,ChengAo Shen,Hanghang Tong,Dongjin Song,Zhigang Deng,Qingsong Wen,Jingchao Ni*

Main category: cs.LG

TL;DR: 本文探讨了大型视觉模型（LVMs）在时间序列分析中的有效性，通过实验发现LVMs在分类任务中表现良好，但在预测任务中存在局限性。

- Motivation: 随着Transformer和大型语言模型（LLMs）在时间序列研究中的应用，大型视觉模型（LVMs）作为多模态方向的新兴技术，其有效性尚不明确。本文旨在验证LVMs在时间序列分析中的实际作用。
- Method: 研究设计了首个系统性实验，涵盖4种LVMs、8种成像方法、18个数据集和26个基线模型，针对分类和预测任务进行广泛分析。
- Result: 实验结果表明，LVMs在时间序列分类任务中表现良好，但在预测任务中存在局限性，如对特定类型LVMs和成像方法的依赖、预测周期偏差以及长回溯窗口利用能力不足。
- Conclusion: LVMs在时间序列分类中有效，但在预测任务中仍需改进。研究结果为未来基于LVMs和多模态的时间序列解决方案奠定了基础。


### [149] [Proxy-FDA: Proxy-based Feature Distribution Alignment for Fine-tuning Vision Foundation Models without Forgetting](https://arxiv.org/abs/2505.24088)
*Chen Huang,Skyler Seto,Hadi Pouransari,Mehrdad Farajtabar,Raviteja Vemulapalli,Fartash Faghri,Oncel Tuzel,Barry-John Theobald,Josh Susskind*

Main category: cs.LG

TL;DR: Proxy-FDA是一种新的正则化方法，通过特征分布对齐和动态生成代理来减少微调中的概念遗忘问题。

- Motivation: 解决基础模型在微调时对其他任务的概念遗忘问题。
- Method: 使用特征分布对齐（基于最近邻图）和动态生成代理来保留特征空间中的结构知识。
- Result: Proxy-FDA显著减少了概念遗忘，并在多种微调设置和任务中表现优异。
- Conclusion: Proxy-FDA通过结构知识保留和代理多样性提升，有效解决了概念遗忘问题。


### [150] [Towards Unified Modeling in Federated Multi-Task Learning via Subspace Decoupling](https://arxiv.org/abs/2505.24185)
*Yipan Wei,Yuchen Zou,Yapeng Li,Bo Du*

Main category: cs.LG

TL;DR: FedDEA是一种联邦解耦聚合方法，用于多任务模型集成，通过动态识别任务相关维度并重新调整优化效果，有效抑制跨任务干扰。

- Motivation: 现有联邦多任务学习方法无法有效聚合异构任务，FedDEA旨在解决这一问题。
- Method: 基于本地更新的响应强度动态识别任务相关维度，并通过重新调整优化效果实现任务级解耦聚合。
- Result: 实验表明，FedDEA能显著提升性能，并在异构任务场景下表现出鲁棒性和泛化能力。
- Conclusion: FedDEA无需任务标签或架构修改，具有广泛适用性和部署友好性。


### [151] [Provably Improving Generalization of Few-Shot Models with Synthetic Data](https://arxiv.org/abs/2505.24190)
*Lan-Cuong Nguyen,Quan Nguyen-Tri,Bang Tran Khanh,Dung D. Le,Long Tran-Thanh,Khoat Than*

Main category: cs.LG

TL;DR: 论文提出了一种理论框架，用于量化合成数据与真实数据分布差异对图像分类的影响，并提出了一种基于原型学习的算法，显著提升了小样本分类性能。

- Motivation: 小样本图像分类因标记数据稀缺而具有挑战性，合成数据虽能缓解此问题，但分布差异导致性能下降。
- Method: 开发理论框架量化分布差异，提出基于原型学习的算法优化数据划分和模型训练。
- Result: 实验表明，该方法在多个数据集上优于现有技术。
- Conclusion: 理论框架和算法有效缩小了真实与合成数据的差距，提升了小样本分类性能。


### [152] [Advancing Compositional Awareness in CLIP with Efficient Fine-Tuning](https://arxiv.org/abs/2505.24424)
*Amit Peleg,Naman Deep Singh,Matthias Hein*

Main category: cs.LG

TL;DR: CLIC是一种基于多图像和关联标题的新型微调方法，显著提升了CLIP模型的组合推理能力，并在检索性能上取得一致增益。

- Motivation: 现有视觉语言模型（如CLIP）在组合推理方面表现不佳，且改进组合性的方法往往忽视了语义理解，甚至导致检索性能下降。
- Method: 提出CLIC方法，通过结合多图像及其关联标题进行微调，提升模型的组合推理能力。
- Result: CLIC在不同架构和预训练的CLIP模型中均提升了组合性（包括词汇和语义理解），并在检索性能上取得一致改进。
- Conclusion: CLIC是当前SugarCrepe++基准上组合性最佳的CLIP模型，且代码和模型已开源。


### [153] [Graph Flow Matching: Enhancing Image Generation with Neighbor-Aware Flow Fields](https://arxiv.org/abs/2505.24434)
*Md Shahriar Rahim Siddiqui,Moshe Eliasof,Eldad Haber*

Main category: cs.LG

TL;DR: 论文提出了一种名为Graph Flow Matching (GFM)的方法，通过引入图神经网络模块增强现有流匹配模型，利用邻域信息提升生成质量。

- Motivation: 现有流匹配模型独立预测每个点的速度，忽略了邻域点之间的相关性，可能影响生成质量。
- Method: GFM将速度分解为反应项（标准流匹配网络）和扩散项（图神经网络模块），以低成本引入局部上下文信息。
- Result: 在多个图像生成基准测试中，GFM显著提升了FID和recall指标。
- Conclusion: GFM是一种轻量级增强方法，可模块化地提升现有流匹配架构的性能。


### [154] [Hyperbolic Dataset Distillation](https://arxiv.org/abs/2505.24623)
*Wenyuan Li,Guang Li,Keisuke Maeda,Takahiro Ogawa,Miki Haseyama*

Main category: cs.LG

TL;DR: 论文提出了一种基于双曲空间的HDD方法，用于数据集蒸馏，解决了传统方法在欧几里得空间中忽略数据几何和层次关系的问题。

- Motivation: 大规模数据集在深度学习中的计算和存储挑战促使了数据集蒸馏的研究，但现有方法局限于欧几里得空间，无法捕捉复杂的数据结构。
- Method: HDD方法将数据嵌入洛伦兹双曲空间，通过优化双曲距离（测地距离）来匹配合成数据与原始数据的分布，并保留层次结构。
- Result: HDD在保持模型性能的同时，仅需20%的蒸馏核心集即可实现稳定训练，且与现有DM方法兼容。
- Conclusion: HDD通过双曲空间建模层次关系，显著提升了数据集蒸馏的效率和效果。
