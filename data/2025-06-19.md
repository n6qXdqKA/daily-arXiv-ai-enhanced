[[toc]]

## cs.CV

### [1] [SemIRNet: A Semantic Irony Recognition Network for Multimodal Sarcasm Detection](https://arxiv.org/abs/2506.14791)
*Jingxuan Zhou,Yuehao Wu,Yibo Zhang,Yeyubei Zhang,Yunchong Liu,Bolin Huang,Chunhong Yuan*

Main category: cs.CV

TL;DR: 本文提出了一种语义反讽识别网络（SemIRNet），通过引入ConceptNet知识库、设计跨模态语义相似性检测模块和对比学习损失函数，提升了多模态反讽检测任务的性能。

- Motivation: 解决多模态反讽检测任务中图形隐式相关性难以准确识别的问题。
- Method: 1. 引入ConceptNet知识库增强常识推理能力；2. 设计词级和样本级跨模态语义相似性检测模块；3. 使用对比学习损失函数优化特征空间分布。
- Result: 在公开数据集上，准确率和F1值分别提升1.64%和2.88%，达到88.87%和86.33%。
- Conclusion: 知识融合和语义相似性检测对模型性能提升具有重要作用。


### [2] [Argus Inspection: Do Multimodal Large Language Models Possess the Eye of Panoptes?](https://arxiv.org/abs/2506.14805)
*Yang Yao,Lingyu Li,Jiaxin Song,Chiyu Chen,Zhenqi He,Yixu Wang,Xin Wang,Tianle Gu,Jie Li,Yan Teng,Yingchun Wang*

Main category: cs.CV

TL;DR: 该论文介绍了Argus Inspection多模态基准和Eye of Panoptes框架，用于评估MLLMs的视觉细粒度感知和常识因果推理能力，实验显示当前模型的最高性能仅为0.46。

- Motivation: 尽管MLLMs的认知和推理能力有所提升，但在视觉细粒度感知和常识因果推理方面仍存在挑战，需要更全面的评估方法。
- Method: 提出Argus Inspection多模态基准和Eye of Panoptes框架，结合Sigmoid度量与指示函数，评估MLLMs的推理能力。
- Result: 在26个主流MLLMs上的实验表明，视觉细粒度推理的最高性能仅为0.46，显示改进空间巨大。
- Conclusion: 研究为MLLMs的进一步优化提供了重要视角。


### [3] [A Hybrid ConvNeXt-EfficientNet AI Solution for Precise Falcon Disease Detection](https://arxiv.org/abs/2506.14816)
*Alavikunhu Panthakkan,Zubair Medammal,S M Anzar,Fatma Taher,Hussain Al-Ahmad*

Main category: cs.CV

TL;DR: 本文提出了一种结合ConvNeXt和EfficientNet的混合AI模型，用于准确分类猎鹰疾病（正常、肝病和曲霉病），其性能优于传统方法和单一模型架构。

- Motivation: 猎鹰训练和狩猎需要确保猎鹰健康，传统疾病诊断方法存在局限性，需要更精确的解决方案。
- Method: 采用ConvNeXt和EfficientNet混合AI模型，利用大数据集训练和验证，关注准确性、精确率、召回率和F1分数等指标。
- Result: 混合模型在疾病分类中表现优于传统方法和单一模型，实现了高精度检测。
- Conclusion: 该混合AI模型为猎鹰疾病检测提供了高效工具，并为AI驱动的鸟类医疗未来发展奠定了基础。


### [4] [ViLLa: A Neuro-Symbolic approach for Animal Monitoring](https://arxiv.org/abs/2506.14823)
*Harsha Koduri*

Main category: cs.CV

TL;DR: ViLLa是一个神经符号框架，用于可解释的动物监测，结合视觉检测、语言解析和符号推理。

- Motivation: 开发一个能够结合视觉数据和自然语言查询的系统，以透明和模块化的方式监测动物种群。
- Method: ViLLa包含三个核心组件：视觉检测模块、语言解析器和符号推理层，通过逻辑推理回答问题。
- Result: 系统在动物图像任务中表现良好，能够准确回答关于数量、存在和位置的查询。
- Conclusion: ViLLa通过分离感知、理解和推理，提供了模块化和透明度，优于黑盒模型。


### [5] [GraphGSOcc: Semantic and Geometric Graph Transformer for 3D Gaussian Splating-based Occupancy Prediction](https://arxiv.org/abs/2506.14825)
*Ke Song,Yunhe Wu,Chunchit Siu,Huiyuan Xiong*

Main category: cs.CV

TL;DR: 论文提出GraphGSOcc模型，通过结合语义和几何图Transformer解决3D高斯喷洒方法中的特征聚合和边界模糊问题。

- Motivation: 现有3D高斯喷洒方法存在特征聚合忽略语义相关性及边界模糊问题，影响3D语义占用预测效果。
- Method: 提出Dual Gaussians Graph Attention，动态构建几何图和语义图，结合多尺度图注意力框架优化边界细节和对象拓扑。
- Result: 在SurroundOcc数据集上mIoU达24.10%，GPU内存降至6.1GB，性能提升1.97%，内存减少13.7%。
- Conclusion: GraphGSOcc模型有效提升3D语义占用预测性能，同时降低计算资源消耗。


### [6] [DAVID-XR1: Detecting AI-Generated Videos with Explainable Reasoning](https://arxiv.org/abs/2506.14827)
*Yifeng Gao,Yifan Ding,Hongyu Su,Juncheng Li,Yunhan Zhao,Lin Luo,Zixing Chen,Li Wang,Xin Wang,Yixu Wang,Xingjun Ma,Yu-Gang Jiang*

Main category: cs.CV

TL;DR: 论文提出了DAVID-X数据集和DAVID-XR1模型，用于提供细粒度、可解释的AI生成视频检测方法。

- Motivation: 随着AI生成视频的普及，现有方法仅提供二元分类，缺乏对检测结果的详细解释，无法满足审计和用户需求。
- Method: 引入DAVID-X数据集（含详细缺陷标注和文字解释），并开发DAVID-XR1模型，结合视觉推理链（缺陷分类、时空定位和自然语言解释）。
- Result: 实验表明，基于通用骨干网络并经过思维链蒸馏的模型，在多种生成器和模式下具有强泛化能力。
- Conclusion: 可解释的检测方法为AI生成视频的可信识别提供了新方向。


### [7] [Recent Advances in Multi-Agent Human Trajectory Prediction: A Comprehensive Review](https://arxiv.org/abs/2506.14831)
*Céline Finet,Stephane Da Silva Martins,Jean-Bernard Hayet,Ioannis Karamouzas,Javad Amirian,Sylvie Le Hégarat-Mascle,Julien Pettré,Emanuel Aldea*

Main category: cs.CV

TL;DR: 这篇综述回顾了2020至2024年间基于深度学习的多智能体轨迹预测的最新进展，重点关注ETH/UCY基准测试中的模型，并提出了未来研究方向。

- Motivation: 随着数据驱动方法在人类轨迹预测中的广泛应用，深入理解多智能体交互对自主导航和人群建模等领域具有重要意义。
- Method: 文章根据架构设计、输入表示和预测策略对现有方法进行分类，特别关注ETH/UCY基准测试中的模型。
- Result: 综述总结了多智能体轨迹预测的最新进展，并分析了其性能表现。
- Conclusion: 文章指出了多智能体轨迹预测领域的关键挑战和未来研究方向。


### [8] [ArchShapeNet:An Interpretable 3D-CNN Framework for Evaluating Architectural Shapes](https://arxiv.org/abs/2506.14832)
*Jun Yin,Jing Zhong,Pengyu Zeng,Peilin Li,Zixuan Dai,Miao Zhang,Shuai Lu*

Main category: cs.CV

TL;DR: 论文提出了ArchForms-4000数据集和ArchShapeNet模型，用于区分人类设计与机器生成的3D建筑形式，模型表现优于人类专家。

- Motivation: 解决人类设计与机器生成3D建筑形式差异分析的挑战，推动生成工具的发展。
- Method: 构建ArchForms-4000数据集，开发ArchShapeNet 3D卷积神经网络，并引入显著性模块。
- Result: 模型在区分形式来源上表现优异，准确率94.29%，精确率96.2%，召回率98.51%。
- Conclusion: 研究揭示了人类设计在空间组织等方面的优势，为未来生成设计工具的改进提供了参考。


### [9] [Real-Time, Low-Latency Surveillance Using Entropy-Based Adaptive Buffering and MobileNetV2 on Edge Devices](https://arxiv.org/abs/2506.14833)
*Poojashree Chandrashekar Pankaj M Sajjanar*

Main category: cs.CV

TL;DR: 提出了一种高性能、低延迟的视频监控系统，适用于资源受限环境，结合熵自适应帧缓冲算法与MobileNetV2，实现高吞吐量和低延迟。

- Motivation: 解决资源受限设备（如Raspberry Pi）上视频监控系统的高性能和低延迟需求。
- Method: 提出熵自适应帧缓冲算法，并与MobileNetV2结合，优化处理流程。
- Result: 在标准数据集上保持92%以上的检测准确率，端到端推理延迟低于50ms，且对光照、背景和速度变化具有鲁棒性。
- Conclusion: 系统具有可扩展性、低成本，并符合严格的数据隐私法规，适用于智能城市或嵌入式安全架构。


### [10] [MonoVQD: Monocular 3D Object Detection with Variational Query Denoising and Self-Distillation](https://arxiv.org/abs/2506.14835)
*Kiet Dang Vu,Trung Thai Tran,Duc Dung Nguyen*

Main category: cs.CV

TL;DR: MonoVQD框架通过引入Mask Separated Self-Attention、Variational Query Denoising和自蒸馏策略，显著提升了单目3D检测性能。

- Motivation: 解决DETR架构在单目3D检测中的固有局限性，提升性能。
- Method: 提出三种创新：Mask Separated Self-Attention、Variational Query Denoising和自蒸馏策略。
- Result: 在KITTI和nuScenes数据集上表现优异，具有广泛适用性。
- Conclusion: MonoVQD框架在单目和多视角3D检测中均表现出色，具有强大的泛化能力。


### [11] [Improved Iterative Refinement for Chart-to-Code Generation via Structured Instruction](https://arxiv.org/abs/2506.14837)
*Chengzhi Xu,Yuyang Wang,Lai Wei,Lichao Sun,Weiran Huang*

Main category: cs.CV

TL;DR: 论文提出了一种基于结构化指令的迭代优化方法ChartIR，用于提升多模态大语言模型在图表到代码生成任务中的表现。

- Motivation: 当前多模态大语言模型在图表到代码生成任务中表现不佳，需要同时具备精确的视觉理解和准确的代码翻译能力。
- Method: 将任务分解为视觉理解和代码翻译两部分，设计结构化指令（描述和差异）以转换视觉特征为语言表示，并采用两阶段流程（初始代码生成和迭代优化）。
- Result: 实验表明，该方法在开源模型Qwen2-VL和闭源模型GPT-4o上均优于其他方法。
- Conclusion: ChartIR通过结构化指令和迭代优化显著提升了图表到代码生成的性能。


### [12] [PictSure: Pretraining Embeddings Matters for In-Context Learning Image Classifiers](https://arxiv.org/abs/2506.14842)
*Lukas Schiesser,Cornelius Wolff,Sophie Haas,Simon Pukrop*

Main category: cs.CV

TL;DR: PictSure是一个专注于图像嵌入模型的ICL框架，通过系统分析嵌入模型的架构、预训练和训练动态，显著提升了少样本图像分类的跨域性能。

- Motivation: 在数据稀缺领域，构建图像分类模型困难，ICL成为少样本分类的有前景方法，但现有研究忽视了图像嵌入模型的关键作用。
- Method: 提出PictSure框架，系统研究视觉编码器类型、预训练目标和微调策略对少样本分类性能的影响。
- Result: 实验表明，嵌入模型的预训练方式显著影响训练成功率和跨域性能，PictSure在跨域任务上优于现有方法。
- Conclusion: PictSure通过优化嵌入模型，在跨域少样本分类任务中表现出色，同时保持域内任务的可比性能。


### [13] [Finding Optimal Kernel Size and Dimension in Convolutional Neural Networks An Architecture Optimization Approach](https://arxiv.org/abs/2506.14846)
*Shreyas Rajeev,B Sathish Babu*

Main category: cs.CV

TL;DR: 论文提出了一种名为BKSEF的框架，用于在CNN中动态选择最优的核大小，提升模型精度并降低计算成本。

- Motivation: 核大小选择对CNN的感知野、特征提取、计算成本和模型精度有重要影响，但常被忽视。
- Method: BKSEF结合信息论、信号处理和学习理论，通过数学和实验验证的方法动态确定每层的最优核大小。
- Result: 在多个数据集上，BKSEF引导的模型精度提升3.1%，计算量减少42.8%。实际案例验证了其在医疗图像分类和交通标志识别中的有效性。
- Conclusion: BKSEF为CNN设计提供了理论和实践支持，可作为神经架构搜索和实时系统的优化工具。


### [14] [Efficient Retail Video Annotation: A Robust Key Frame Generation Approach for Product and Customer Interaction Analysis](https://arxiv.org/abs/2506.14854)
*Varun Mannam,Zhenyu Shi*

Main category: cs.CV

TL;DR: 提出一种基于深度学习的零售视频自动标注方法，替代耗时的人工标注，显著降低成本并保持准确性。

- Motivation: 传统零售视频标注依赖人工，效率低且成本高，需自动化解决方案。
- Method: 利用深度神经网络学习视频帧特征，结合零售环境优化的目标检测技术，自动识别关键帧并标注。
- Result: 实验显示方法优于传统标注，准确性接近人工标注，成本节省2倍，仅需人工验证5%的帧。
- Conclusion: 该方法高效且经济，适用于零售领域多种应用，如顾客行为分析和产品交互检测。


### [15] [Peering into the Unknown: Active View Selection with Neural Uncertainty Maps for 3D Reconstruction](https://arxiv.org/abs/2506.14856)
*Zhengquan Zhang,Feng Xu,Mengmi Zhang*

Main category: cs.CV

TL;DR: 论文提出了一种基于神经不确定性地图的主动视角选择方法（UPNet），用于高效且准确的3D物体重建，显著减少了计算开销并提升了速度。

- Motivation: 解决3D重建中如何选择最具信息量的视角以减少冗余并提升效率的问题。
- Method: 使用轻量级神经网络UPNet预测视角不确定性地图，并通过启发式方法选择最优视角。
- Result: 方法仅需一半视角即可达到与上限相当的精度，计算速度提升400倍，资源消耗减少50%以上。
- Conclusion: UPNet方法在高效3D重建中表现出色，且无需额外训练即可泛化到新物体类别。


### [16] [DETONATE: A Benchmark for Text-to-Image Alignment and Kernelized Direct Preference Optimization](https://arxiv.org/abs/2506.14903)
*Renjith Prasad,Abhilekh Borah,Hasnat Md Abdullah,Chathurangi Shyalika,Gurpreet Singh,Ritvik Garimella,Rajarshi Roy,Harshul Surana,Nasrin Imanpour,Suranjana Trivedy,Amit Sheth,Amitava Das*

Main category: cs.CV

TL;DR: 本文提出DPO-Kernels方法，通过混合损失、核化表示和发散选择增强文本到图像模型的校准，并引入DETONATE基准和AQI指标。

- Motivation: 确保文本到图像模型生成的图像准确反映用户意图，同时保持安全性和公平性。
- Method: 提出DPO-Kernels，包括混合损失、核化表示和发散选择，并引入DETONATE基准和AQI指标。
- Result: DPO-Kernels在DETONATE基准上表现出色，通过HT-SR保持强泛化能力。
- Conclusion: DPO-Kernels有效提升模型校准，DETONATE和AQI为未来研究提供工具。


### [17] [PeRL: Permutation-Enhanced Reinforcement Learning for Interleaved Vision-Language Reasoning](https://arxiv.org/abs/2506.14907)
*Yizhen Zhang,Yang Ding,Shuoshuo Zhang,Xinchen Zhang,Haoling Li,Zhong-zhi Li,Peijie Wang,Jie Wu,Lei Ji,Yelong Shen,Yujiu Yang,Yeyun Gong*

Main category: cs.CV

TL;DR: 提出了一种名为PeRL的强化学习方法，专注于多图像位置推理任务，通过多阶段策略和图像序列排列提升学习效率和性能。

- Motivation: 现有多模态强化学习方法在单图像空间推理中表现有限，难以推广到多图像位置推理的复杂场景。
- Method: 提出PeRL方法，包括图像序列排列和多阶段策略，引入rollout过滤机制优化学习轨迹。
- Result: 在5个多图像基准和3个单图像基准上，PeRL显著优于基线模型，达到最先进性能。
- Conclusion: PeRL在多图像任务中表现优异，同时保持单图像任务的竞争力。


### [18] [Frequency-Calibrated Membership Inference Attacks on Medical Image Diffusion Models](https://arxiv.org/abs/2506.14919)
*Xinkai Zhao,Yuta Tokuoka,Junichiro Iwasawa,Keita Oda*

Main category: cs.CV

TL;DR: 提出了一种针对医学图像扩散模型的频率校准重建误差（FCRE）方法，以解决现有成员推理攻击（MIA）方法在医学图像上的局限性。

- Motivation: 扩散模型在医学图像生成中的隐私风险日益突出，现有MIA方法因重建误差受图像固有难度影响而效果不佳。
- Method: 通过分析反向扩散过程，聚焦中频范围的重建误差，排除高频和低频区域，计算结构相似性指数得分以确定成员资格。
- Result: 在多个医学图像数据集上，FCRE方法优于现有MIA方法。
- Conclusion: FCRE方法有效解决了医学图像扩散模型的隐私风险评估问题。


### [19] [Vision Transformers for End-to-End Quark-Gluon Jet Classification from Calorimeter Images](https://arxiv.org/abs/2506.14934)
*Md Abrar Jahin,Shahriar Soudeep,Arian Rahman Aditta,M. F. Mridha,Nafiz Fahad,Md. Jakir Hossen*

Main category: cs.CV

TL;DR: 本文系统评估了Vision Transformer (ViT) 及其与CNN的混合模型在夸克-胶子喷注分类中的表现，发现ViT模型在性能上优于传统CNN方法。

- Motivation: 区分夸克和胶子喷注是高能物理中的关键挑战，对LHC的新物理搜索和精确测量至关重要。尽管CNN在喷注标记中表现良好，但ViT架构的潜力尚未充分探索。
- Method: 使用模拟的2012年CMS开放数据，构建多通道喷注图像（ECAL、HCAL和重建轨迹），并评估ViT及ViT-CNN混合模型的性能。
- Result: ViT模型（特别是ViT+MaxViT和ViT+ConvNeXt混合模型）在F1分数、ROC-AUC和准确率上均优于传统CNN基线。
- Conclusion: ViT架构在喷注分类中表现出色，能够捕捉长程空间关联，为未来深度学习研究提供了系统框架和基准。


### [20] [Advances in Compliance Detection: Novel Models Using Vision-Based Tactile Sensors](https://arxiv.org/abs/2506.14980)
*Ziteng Li,Malte Kuhlmann,Ilana Nisky,Nicolás Navarro-Guerrero*

Main category: cs.CV

TL;DR: 论文提出基于LRCN和Transformer的模型，利用RGB触觉图像和GelSight传感器数据，显著提高了合规性预测的准确性。

- Motivation: 传统合规性检测方法便携性和扩展性不足，依赖昂贵设备，且不适用于机器人应用；现有神经网络方法预测精度不足。
- Method: 提出基于LRCN和Transformer的模型，利用RGB触觉图像和GelSight传感器数据预测合规性指标。
- Result: 模型在多个指标上验证有效，性能显著优于基线；发现传感器与物体合规性估计的关联性。
- Conclusion: 所提模型显著提升合规性预测精度，但较硬物体的估计仍具挑战性。


### [21] [Hyper-Local Deformable Transformers for Text Spotting on Historical Maps](https://arxiv.org/abs/2506.15010)
*Yijun Lin,Yao-Yi Chiang*

Main category: cs.CV

TL;DR: PALETTE是一种端到端文本识别器，用于从多样化的历史地图中提取文本，通过超局部采样模块和合成地图数据（SynthMap+）显著提升了性能。

- Motivation: 历史地图中的文本提供了丰富的地理、历史和文化信息，但传统方法难以处理多样化的地图样式和复杂背景。
- Method: 提出PALETTE，采用超局部采样模块学习目标边界点和字符的局部特征，并结合SynthMap+生成合成数据训练模型。
- Result: PALETTE在历史地图文本识别任务中优于现有方法，特别是在长文本和倾斜文本上表现突出，并已应用于处理6万张地图。
- Conclusion: PALETTE通过创新方法解决了历史地图文本提取的挑战，为大规模地图数据处理提供了有效工具。


### [22] [Break Stylistic Sophon: Are We Really Meant to Confine the Imagination in Style Transfer?](https://arxiv.org/abs/2506.15033)
*Gary Song Yan,Yusen Zhang,Jinyu Zhao,Hao Zhang,Zhangping Yang,Guanye Xiong,Yanfei Liu,Tao Zhang,Yujie He,Siyuan Tian,Yao Gou,Min Li*

Main category: cs.CV

TL;DR: StyleWallfacer是一个统一的训练和推理框架，解决了传统风格迁移方法的问题，支持艺术家级风格迁移和文本驱动风格化。通过语义风格注入、数据增强策略和无训练的三重扩散过程，实现了高质量的风格迁移和文本控制。

- Motivation: 传统风格迁移方法存在多种问题，如风格注入效率低、内容漂移等。StyleWallfacer旨在统一框架，提升风格迁移的质量和控制能力。
- Method: 1. 基于BLIP和CLIP的语义风格注入方法；2. 基于人类反馈的数据增强策略；3. 无训练的三重扩散过程，通过自注意力层操作实现风格注入。
- Result: 实现了高质量的风格迁移和文本驱动风格化，首次在风格迁移中完成图像颜色编辑。
- Conclusion: StyleWallfacer为风格迁移领域提供了高效、统一的解决方案，具有广泛的应用潜力。


### [23] [Enhancing Vector Quantization with Distributional Matching: A Theoretical and Empirical Study](https://arxiv.org/abs/2506.15078)
*Xianghong Fang,Litao Guo,Hengchao Chen,Yuxuan Zhang,XiaofanXia,Dingjie Song,Yexin Liu,Hao Wang,Harry Yang,Yuan Yuan,Qiang Sun*

Main category: cs.CV

TL;DR: 论文提出使用Wasserstein距离对齐特征和码向量分布，解决向量量化中的训练不稳定和码本崩溃问题，显著减少量化误差并提高码本利用率。

- Motivation: 现有向量量化方法存在训练不稳定和码本崩溃问题，主要由特征与码向量分布不匹配导致。
- Method: 采用Wasserstein距离对齐特征和码向量分布。
- Result: 实现近100%码本利用率，显著减少量化误差。
- Conclusion: 理论和实证分析验证了该方法的有效性。


### [24] [SynPo: Boosting Training-Free Few-Shot Medical Segmentation via High-Quality Negative Prompts](https://arxiv.org/abs/2506.15153)
*Yufei Liu,Haoke Xiao,Jiaxing Chai,Yongcun Zhang,Rong Wang,Zijie Meng,Zhiming Luo*

Main category: cs.CV

TL;DR: SynPo是一种基于大型视觉模型（如SAM）的无训练少样本医学图像分割方法，通过改进负提示质量提升低对比度医学图像的分割性能。

- Motivation: 现有基于LVMs的无训练方法未能有效利用负提示，导致在低对比度医学图像上表现不佳。
- Method: 设计置信图协同模块（结合DINOv2和SAM），选择高置信度点作为正提示集，高斯分布选择负提示集，独立K-means聚类后输入SAM进行分割。
- Result: 实验表明SynPo性能接近基于训练的最先进少样本方法。
- Conclusion: SynPo通过优化提示选择，显著提升了无训练方法在医学图像分割中的表现。


### [25] [Enhancing point cloud analysis via neighbor aggregation correction based on cross-stage structure correlation](https://arxiv.org/abs/2506.15160)
*Jiaqi Shi,Jin Xiao,Xiaoguang Hu,Boyang Song,Hao Jiang,Tianyou Chen,Baochang Zhang*

Main category: cs.CV

TL;DR: 提出Point Distribution Set Abstraction模块（PDSA），通过高维空间相关性校正特征分布，提升计算效率和鲁棒性。

- Motivation: 现有方法在点云分析中存在无关点干扰、特征层次差距问题，且基于几何结构编码的方法计算开销大、对噪声敏感。
- Method: PDSA利用高维空间相关性校正特征分布，通过轻量级跨阶段结构描述符区分点相关性，并通过减少邻域特征矩阵方差和长距离建模增强结构同质性。
- Result: 在语义分割和分类任务中验证了方法的泛化性，性能显著提升且参数成本低。
- Conclusion: PDSA模块有效解决了现有问题，实验和可视化结果验证了其合理性和有效性。


### [26] [Echo-DND: A dual noise diffusion model for robust and precise left ventricle segmentation in echocardiography](https://arxiv.org/abs/2506.15166)
*Abdur Rahman,Keerthiveena Balraj,Manojkumar Ramteke,Anurag Singh Rathore*

Main category: cs.CV

TL;DR: 本文提出了一种名为Echo-DND的新型双噪声扩散模型，用于解决超声图像中左心室分割的挑战，通过高斯和伯努利噪声结合及多尺度融合模块，显著提升了分割精度。

- Motivation: 超声图像噪声多、对比度低且边界模糊，导致左心室分割困难，影响诊断和治疗。
- Method: 提出Echo-DND模型，结合高斯和伯努利噪声，采用多尺度融合模块和空间一致性校准技术。
- Result: 在CAMUS和EchoNet-Dynamic数据集上表现优异，Dice分数分别达到0.962和0.939。
- Conclusion: Echo-DND为超声图像分割设立了新标准，并有望推广至其他医学影像任务。


### [27] [ReSeDis: A Dataset for Referring-based Object Search across Large-Scale Image Collections](https://arxiv.org/abs/2506.15180)
*Ziling Huang,Yidan Zhang,Shin'ichi Satoh*

Main category: cs.CV

TL;DR: ReSeDis统一了大规模检索与像素级定位任务，提出了新的基准和评估指标，并展示了零样本基线的潜力。

- Motivation: 解决现有视觉搜索技术无法同时实现大规模检索和细粒度定位的问题。
- Method: 引入ReSeDis任务，结合检索与定位，设计新基准和评估指标，并测试零样本基线。
- Result: ReSeDis为多模态搜索系统提供了端到端的测试平台，展示了未来研究的潜力。
- Conclusion: ReSeDis为下一代多模态搜索系统提供了实用且可扩展的解决方案。


### [28] [Conquering the Retina: Bringing Visual in-Context Learning to OCT](https://arxiv.org/abs/2506.15200)
*Alessio Negrini,Simon Reiß*

Main category: cs.CV

TL;DR: 论文探讨了在视网膜光学相干断层扫描（OCT）领域训练通用模型的方法，通过视觉上下文学习（VICL）实现任务泛化，并提出了评估协议和基线结果。

- Motivation: 现有医学图像分析模型虽性能优异，但局限于特定任务且开发成本高，通用模型能灵活适应新任务，无需额外开发。
- Method: 使用视觉上下文学习（VICL）训练通用模型，基于少量示例实现任务泛化，并提出针对OCT的评估协议。
- Result: 在多个视网膜OCT数据集上评估了先进的医学VICL方法，建立了首个基线，展示了其潜力与当前局限。
- Conclusion: VICL在OCT领域具有潜力，但需进一步研究以克服当前限制，代码已开源以促进研究和应用。


### [29] [Privacy-Shielded Image Compression: Defending Against Exploitation from Vision-Language Pretrained Models](https://arxiv.org/abs/2506.15201)
*Xuelin Shen,Jiayin Xu,Kangsheng Yin,Wenhan Yang*

Main category: cs.CV

TL;DR: 本文提出了一种名为PSIC的图像压缩方法，通过多解码选项保护用户隐私，防止视觉语言预训练模型利用公开图像。

- Motivation: 随着视觉语言预训练模型语义理解能力的提升，公开图像的隐私保护需求日益迫切。
- Method: 提出PSIC方法，结合CLTG模块和UAEO优化函数，实现多解码选项的图像压缩。
- Result: 实验证明PSIC能有效保护隐私并保持图像质量，且兼容现有压缩模型。
- Conclusion: PSIC是一种灵活、高效的隐私保护图像压缩方案。


### [30] [DM-FNet: Unified multimodal medical image fusion via diffusion process-trained encoder-decoder](https://arxiv.org/abs/2506.15218)
*Dan He,Weisheng Li,Guofen Wang,Yuping Huang,Shiqiang Liu*

Main category: cs.CV

TL;DR: 本文提出了一种基于两阶段扩散模型的多模态医学图像融合网络（DM-FNet），通过增强特征识别能力和自适应处理不同模态图像，显著提升了融合图像的质量和信息密度。

- Motivation: 现有多模态医学图像融合方法在特征捕获和跨模态交互方面存在不足，导致融合图像质量不理想。
- Method: 采用两阶段扩散模型：第一阶段训练UNet进行图像重建，第二阶段将噪声图像输入融合网络，并结合三个关键融合模块自适应处理不同模态图像。
- Result: 实验结果表明，该方法在客观评价指标上表现优异，融合图像保留了亮度、放射性示踪剂分布、纹理和边缘清晰度。
- Conclusion: DM-FNet通过创新的网络结构和混合损失函数，实现了高质量的多模态医学图像融合。


### [31] [video-SALMONN 2: Captioning-Enhanced Audio-Visual Large Language Models](https://arxiv.org/abs/2506.15220)
*Changli Tang,Yixuan Li,Yudong Yang,Jimin Zhuang,Guangzhi Sun,Wei Li,Zejun Ma,Chao Zhang*

Main category: cs.CV

TL;DR: 视频-SALMONN 2是一种先进的视听大语言模型，通过低秩适应（LoRA）和定向偏好优化（DPO）提升视频字幕生成能力，提出多轮DPO（MrDPO）方法显著降低错误率28%。

- Motivation: 视频包含丰富信息，生成准确的自然语言描述是视频理解的关键。
- Method: 提出视频-SALMONN 2模型，结合LoRA和DPO，引入MrDPO方法周期性更新参考模型并优化训练。
- Result: 模型在7B参数下超越GPT-4o和Gemini-1.5-Pro，错误率降低28%。
- Conclusion: 视频-SALMONN 2在视频字幕任务中表现优异，代码已开源。


### [32] [Convolutional Feature Enhancement and Attention Fusion BiFPN for Ship Detection in SAR Images](https://arxiv.org/abs/2506.15231)
*Liangjie Meng,Danxia Li,Jinrong He,Lili Ma,Zhixin Li*

Main category: cs.CV

TL;DR: 提出了一种名为C-AFBiFPN的特征增强与融合框架，用于解决SAR船舶检测中的多尺度变化、小目标噪声和复杂背景问题，显著提升了检测精度。

- Motivation: SAR船舶检测面临多尺度变化、小目标噪声和复杂背景等挑战，需要更有效的特征表示和融合方法。
- Method: 提出C-AFBiFPN框架，包含卷积特征增强模块（CFE）和融合BiFormer注意力的AFBiFPN网络，以增强局部细节和全局建模能力。
- Result: 在SSDD数据集上，该方法显著提升了小目标检测精度、抗遮挡鲁棒性和多尺度适应性。
- Conclusion: C-AFBiFPN框架有效解决了SAR船舶检测的关键问题，为相关应用提供了实用解决方案。


### [33] [RA-NeRF: Robust Neural Radiance Field Reconstruction with Accurate Camera Pose Estimation under Complex Trajectories](https://arxiv.org/abs/2506.15242)
*Qingsong Yan,Qiang Wang,Kaiyong Zhao,Jie Chen,Bo Li,Xiaowen Chu,Fei Deng*

Main category: cs.CV

TL;DR: RA-NeRF是一种新方法，能够在复杂相机轨迹下预测高精度相机姿态，结合NeRF和流驱动姿态调节，显著提升重建和定位的鲁棒性。

- Motivation: 现有方法依赖准确相机姿态先验，但在复杂轨迹下表现不佳，需要更鲁棒的解决方案。
- Method: RA-NeRF采用增量式流程，结合NeRF的光度一致性和流驱动姿态调节，并引入隐式姿态滤波器消除噪声。
- Result: 在Tanks&Temple和NeRFBuster数据集上，RA-NeRF在相机姿态估计和视觉质量上均达到最先进水平。
- Conclusion: RA-NeRF在复杂相机轨迹下表现出高效性和鲁棒性，为场景重建提供了可靠解决方案。


### [34] [Retrospective Memory for Camouflaged Object Detection](https://arxiv.org/abs/2506.15244)
*Chenxi Zhang,Jiayun Wu,Qing Zhang,Yazhe Zhai,Youwei Pang*

Main category: cs.CV

TL;DR: 提出了一种名为RetroMem的回忆增强COD架构，通过整合历史知识动态调制伪装模式感知与推理，显著提升模型性能。

- Motivation: 现有COD方法缺乏显式机制获取历史上下文，限制了其在复杂伪装场景中的适应性和有效性。
- Method: 采用两阶段训练范式（学习阶段和回忆阶段），设计了密集多尺度适配器（DMA）和动态记忆机制（DMM）与推理模式重建（IPR）。
- Result: 在多个数据集上的实验表明，RetroMem显著优于现有最先进方法。
- Conclusion: RetroMem通过动态整合历史知识，显著提升了伪装场景的理解能力。


### [35] [Domain Adaptation for Image Classification of Defects in Semiconductor Manufacturing](https://arxiv.org/abs/2506.15260)
*Adrian Poniatowski,Natalie Gentner,Manuel Barusco,Davide Dalle Pezze,Samuele Salti,Gian Antonio Susto*

Main category: cs.CV

TL;DR: 论文探讨了在半导体领域应用领域适应（DA）技术，特别是在半监督和无监督设置下，以减少重新标记和训练的需求，并提出了DBACS方法以提升性能。

- Motivation: 半导体行业竞争激烈，时间和质量是关键因素，而领域适应技术能有效减少资源消耗并提升模型适应性。
- Method: 提出了DBACS方法，一种基于CycleGAN并增强损失项的模型，用于半监督和无监督设置下的领域适应。
- Result: 在真实世界的电子显微镜图像上验证了方法的有效性，证明了其在半导体领域的实用性。
- Conclusion: DBACS方法成功提升了领域适应技术在半导体领域的性能，为减少资源消耗和提升效率提供了新方向。


### [36] [MSNeRV: Neural Video Representation with Multi-Scale Feature Fusion](https://arxiv.org/abs/2506.15276)
*Jun Zhu,Xinfeng Zhang,Lv Tang,JunHao Jiang*

Main category: cs.CV

TL;DR: MSNeRV是一种多尺度特征融合框架，用于神经视频表示，解决了现有INR方法在细节密集和快速变化视频内容中的不足，并在压缩效率上超越了VTM-23.7。

- Motivation: 现有基于INR的视频压缩方法在细节密集和快速变化内容上表现不佳，主要原因是网络内部特征利用不足和缺乏视频特定设计。
- Method: 提出MSNeRV框架，包括时间窗口增强时间一致性、GoP级网格背景表示、多尺度空间解码器和尺度自适应损失函数，以及多尺度特征块。
- Result: 在HEVC ClassB和UVG数据集上评估，MSNeRV在INR方法中表现最佳，压缩效率超越VTM-23.7（动态场景）。
- Conclusion: MSNeRV通过多尺度特征融合和视频特定设计，显著提升了神经视频表示和压缩性能。


### [37] [BCRNet: Enhancing Landmark Detection in Laparoscopic Liver Surgery via Bezier Curve Refinement](https://arxiv.org/abs/2506.15279)
*Qian Li,Feng Liu,Shuojue Yang,Daiyun Shen,Yueming Jin*

Main category: cs.CV

TL;DR: 提出BCRNet框架，通过贝塞尔曲线细化策略显著提升腹腔镜肝脏手术中关键解剖标志的检测精度。

- Motivation: 腹腔镜肝脏手术中准确识别解剖结构具有挑战性，AR系统结合MRI/CT与腹腔镜图像提供解决方案，但需精确检测曲线标志。
- Method: BCRNet包含多模态特征提取模块、自适应曲线提案初始化和分层曲线细化机制，通过多阶段迭代优化贝塞尔曲线。
- Result: 在L3D和P2ILF数据集上，BCRNet表现优于现有方法，性能显著提升。
- Conclusion: BCRNet为腹腔镜手术导航提供了一种高效、精确的曲线标志检测方法。


### [38] [AI-driven visual monitoring of industrial assembly tasks](https://arxiv.org/abs/2506.15285)
*Mattia Nardon,Stefano Messelodi,Antonio Granata,Fabio Poiesi,Alberto Danese,Davide Boscaini*

Main category: cs.CV

TL;DR: ViMAT是一种无需刚性工作空间设置或视觉标记的AI驱动系统，用于实时监控工业装配任务。

- Motivation: 工业装配任务的视觉监控对防止设备损坏和确保工人安全至关重要，现有商业解决方案通常需要刚性设置或视觉标记。
- Method: ViMAT结合感知模块（从多视角视频流提取视觉观察）和推理模块（基于观察状态和任务知识推断最可能的动作）。
- Result: 在LEGO组件更换和液压模具重构任务中验证了ViMAT的有效性，通过定量和定性分析展示了其性能。
- Conclusion: ViMAT在部分和不确定视觉观察的挑战性场景中表现出色，为工业装配监控提供了灵活解决方案。


### [39] [MEGC2025: Micro-Expression Grand Challenge on Spot Then Recognize and Visual Question Answering](https://arxiv.org/abs/2506.15298)
*Xinqi Fan,Jingting Li,John See,Moi Hoon Yap,Wen-Huang Cheng,Xiaobai Li,Xiaopeng Hong,Su-Jing Wang,Adrian K. Davision*

Main category: cs.CV

TL;DR: 论文探讨了面部微表情（MEs）的识别、定位和生成，提出了结合定位与识别的统一任务ME-STR，以及利用多模态大语言模型（MLLMs）的ME-VQA任务。

- Motivation: 传统方法将微表情的定位与识别分开处理，效率低下，尤其在长视频分析中表现不佳。多模态大语言模型的出现为微表情分析提供了新思路。
- Method: 提出两个任务：ME-STR（统一序列管道）和ME-VQA（视觉问答），利用MLLMs或LVLMs增强分析能力。
- Result: MEGC 2025挑战赛引入这两个任务，要求算法在测试集上运行并提交结果。
- Conclusion: 通过整合任务和利用多模态模型，微表情分析的效率和能力有望显著提升。


### [40] [MapFM: Foundation Model-Driven HD Mapping with Multi-Task Contextual Learning](https://arxiv.org/abs/2506.15313)
*Leonid Ivanov,Vasily Yuryev,Dmitry Yudin*

Main category: cs.CV

TL;DR: 本文提出了一种名为MapFM的端到端模型，用于在线生成矢量化的高清地图，通过结合强大的基础模型和多任务学习，显著提升了地图生成的质量和准确性。

- Motivation: 在自动驾驶中，高清地图和鸟瞰图语义地图对精确定位、规划和决策至关重要，但现有方法在特征表示和环境理解方面仍有不足。
- Method: MapFM模型结合了基础模型编码相机图像，并通过多任务学习引入辅助预测头进行语义分割，以增强环境理解和预测质量。
- Result: 该方法显著提升了特征表示质量，生成了更全面的场景表示，从而提高了矢量高清地图的准确性和质量。
- Conclusion: MapFM通过多任务学习和基础模型的结合，为自动驾驶提供了更高质量的在线矢量高清地图生成方案。


### [41] [OpenPath: Open-Set Active Learning for Pathology Image Classification via Pre-trained Vision-Language Models](https://arxiv.org/abs/2506.15318)
*Lanfeng Zhong,Xin Liao,Shichuan Zhang,Shaoting Zhang,Guotai Wang*

Main category: cs.CV

TL;DR: OpenPath是一种新型的开放集主动学习方法，用于病理图像分类，通过预训练的视觉语言模型和任务特定提示，有效减少标注成本并提高模型性能。

- Motivation: 解决传统主动学习方法在开放集场景下效率低下的问题，特别是在病理图像分类中，未标注数据可能包含大量分布外样本。
- Method: 提出OpenPath方法，结合任务特定提示和多样性信息采样策略（DIS），确保样本的纯净性和信息性。
- Result: 在两个公共病理图像数据集上，OpenPath显著提升了模型性能，优于现有开放集主动学习方法。
- Conclusion: OpenPath通过高效选择分布内样本，显著减少了标注成本，适用于实际临床环境中的病理图像分类任务。


### [42] [Open-World Object Counting in Videos](https://arxiv.org/abs/2506.15368)
*Niki Amini-Naieni,Andrew Zisserman*

Main category: cs.CV

TL;DR: 论文提出了一种新的开放世界视频目标计数任务，并介绍了CountVid模型，该模型结合图像计数和视频分割跟踪技术，显著优于基线方法。

- Motivation: 解决视频中开放世界目标计数的挑战，尤其是在拥挤场景中避免重复计数和识别重现目标。
- Method: CountVid模型结合图像计数模型和可提示视频分割跟踪模型，实现自动化计数。
- Result: 实验表明CountVid在VideoCount数据集上表现优异，显著优于基线方法。
- Conclusion: CountVid和VideoCount数据集为开放世界视频目标计数提供了有效解决方案，代码和模型已开源。


### [43] [Unsupervised Pelage Pattern Unwrapping for Animal Re-identification](https://arxiv.org/abs/2506.15369)
*Aleksandr Algasov,Ekaterina Nepovinnykh,Fedor Zolotarev,Tuomas Eerola,Heikki Kälviäinen,Pavel Zemčík,Charles V. Stewart*

Main category: cs.CV

TL;DR: 提出了一种几何感知的纹理映射方法，用于解决动物皮毛或皮肤图案因变形而导致的个体重识别问题，通过将图案映射到规范UV空间，提高了特征匹配的鲁棒性。

- Motivation: 现有方法难以处理动物皮毛或皮肤图案因身体运动和姿态变化导致的几何变形问题。
- Method: 使用表面法线估计指导图案展开过程，保持3D表面与2D纹理空间的几何一致性，无需真实UV标注，可自监督训练。
- Result: 在Saimaa环斑海豹和豹子数据集上，重识别准确率提高了5.4%。
- Conclusion: 该方法通过几何感知的纹理映射，显著提升了变形图案的个体重识别性能。


### [44] [When Model Knowledge meets Diffusion Model: Diffusion-assisted Data-free Image Synthesis with Alignment of Domain and Class](https://arxiv.org/abs/2506.15381)
*Yujin Kim,Hyunsoo Kim,Hyunwoo J. Kim,Suhyun Kim*

Main category: cs.CV

TL;DR: DDIS是一种基于扩散模型的数据无关图像合成方法，通过引入领域对齐指导和类别对齐标记，显著提升了合成图像的质量和对训练数据分布的准确性。

- Motivation: 开源预训练模型的应用潜力因训练数据不可用而受限，现有数据无关图像合成方法因缺乏自然图像先验知识导致结果偏离训练数据分布。
- Method: 利用文本到图像扩散模型作为图像先验，结合领域对齐指导（DAG）和类别对齐标记（CAT），优化合成图像与训练数据分布的对齐。
- Result: 在PACS和ImageNet上的实验表明，DDIS优于现有方法，生成更符合训练数据分布的图像，达到SOTA性能。
- Conclusion: DDIS通过扩散模型和领域对齐指导，显著提升了数据无关图像合成的质量和准确性，为相关应用提供了新思路。


### [45] [NERO: Explainable Out-of-Distribution Detection with Neuron-level Relevance](https://arxiv.org/abs/2506.15404)
*Anju Chhetri,Jari Korhonen,Prashnna Gyawali,Binod Bhattarai*

Main category: cs.CV

TL;DR: 论文提出了一种名为NERO的新型OOD评分机制，通过利用特征层的神经元级相关性来提升OOD检测的可靠性，并在胃肠道影像基准测试中验证了其有效性。

- Motivation: 在医学影像领域，确保深度学习模型的可靠性至关重要，尤其是识别分布外（OOD）样本的能力。现有方法可能无法完全捕捉OOD多样性，因此需要更有效的解决方案。
- Method: 提出NERO方法，通过聚类神经元级相关性形成代表性中心点，并引入相关性距离度量来量化新样本与中心点的偏差，同时结合缩放相关性和特征范数优化性能。
- Result: 在胃肠道影像基准测试Kvasir和GastroVision上，NERO优于现有OOD检测方法。
- Conclusion: NERO通过神经元级相关性和距离度量显著提升了OOD检测性能，为医学影像中的可靠性问题提供了有效解决方案。


### [46] [Hunyuan3D 2.1: From Images to High-Fidelity 3D Assets with Production-Ready PBR Material](https://arxiv.org/abs/2506.15442)
*Team Hunyuan3D,Shuhui Yang,Mingxin Yang,Yifei Feng,Xin Huang,Sheng Zhang,Zebin He,Di Luo,Haolin Liu,Yunfei Zhao,Qingxiang Lin,Zeqiang Lai,Xianghui Yang,Huiwen Shi,Zibo Zhao,Bowen Zhang,Hongyu Yan,Lifu Wang,Sicong Liu,Jihong Zhang,Meng Chen,Liang Dong,Yiwen Jia,Yulin Cai,Jiaao Yu,Yixuan Tang,Dongyuan Guo,Junlin Yu,Hao Zhang,Zheng Ye,Peng He,Runzhou Wu,Shida Wei,Chao Zhang,Yonghao Tan,Yifu Sun,Lin Niu,Shirui Huang,Bojian Zheng,Shu Liu,Shilin Chen,Xiang Yuan,Xiaofeng Yang,Kai Liu,Jianchen Zhu,Peng Chen,Tian Liu,Di Wang,Yuhong Liu,Linus,Jie Jiang,Jingwei Huang,Chunchao Guo*

Main category: cs.CV

TL;DR: 本教程以Hunyuan3D 2.1为例，提供3D数据处理、生成模型训练及性能评估的完整指南，适合游戏、虚拟现实和工业设计应用。

- Motivation: 3D AI生成内容（AIGC）领域虽发展迅速，但因其复杂性，主要限于研究人员和开发者。本教程旨在降低门槛，提供实用指导。
- Method: 教程涵盖数据准备、模型架构（Hunyuan3D-DiT和Hunyuan3D-Paint）、训练策略、评估指标及部署。
- Result: 通过Hunyuan3D 2.1系统，用户可生成高分辨率、带纹理的3D资产。
- Conclusion: 教程帮助用户掌握3D生成模型的开发或微调能力，适用于多种应用场景。


### [47] [Multimodal Large Language Models for Medical Report Generation via Customized Prompt Tuning](https://arxiv.org/abs/2506.15477)
*Chunlei Li,Jingyang Hou,Yilei Shi,Jingliang Hu,Xiao Xiang Zhu,Lichao Mou*

Main category: cs.CV

TL;DR: MRG-LLM是一种新型多模态大语言模型，通过动态提示定制机制结合冻结LLM和可学习视觉编码器，在医学报告生成中表现优异。

- Motivation: 医学影像数据生成报告仍具挑战性，LLM的潜力有待进一步探索。
- Method: 结合冻结LLM与可学习视觉编码器，引入动态提示定制机制，生成实例特定提示。
- Result: 在IU X-ray和MIMIC-CXR数据集上达到最先进性能。
- Conclusion: MRG-LLM为医学报告生成提供了高效解决方案，代码将公开。


### [48] [GenHOI: Generalizing Text-driven 4D Human-Object Interaction Synthesis for Unseen Objects](https://arxiv.org/abs/2506.15483)
*Shujia Li,Haiyu Zhang,Xinyuan Chen,Yaohui Wang,Yutong Ban*

Main category: cs.CV

TL;DR: GenHOI是一个两阶段框架，旨在实现对新物体的泛化和高质量4D人-物交互（HOI）序列的合成。

- Motivation: 由于大规模4D HOI数据集的稀缺，现有方法难以扩展到4D HOI合成。
- Method: 第一阶段使用Object-AnchorNet从3D HOI数据集中重建稀疏3D HOI关键帧；第二阶段通过Contact-Aware Diffusion Model（ContactDM）插值生成密集4D HOI序列。
- Result: 在OMOMO和3D-FUTURE数据集上取得最优结果，展示了强大的泛化能力和高质量4D HOI生成能力。
- Conclusion: GenHOI通过两阶段设计有效解决了4D HOI合成的挑战，为未来研究提供了新方向。


### [49] [NTIRE 2025 Image Shadow Removal Challenge Report](https://arxiv.org/abs/2506.15524)
*Florin-Alexandru Vasluianu,Tim Seizinger,Zhuyun Zhou,Cailian Chen,Zongwei Wu,Radu Timofte,Mingjia Li,Jin Hu,Hainuo Wang,Hengxing Liu,Jiarui Wang,Qiming Hu,Xiaojie Guo,Xin Lu,Jiarong Yang,Yuanfei Bao,Anya Hu,Zihao Fan,Kunyu Wang,Jie Xiao,Xi Wang,Xueyang Fu,Zheng-Jun Zha,Yu-Fan Lin,Chia-Ming Lee,Chih-Chung Hsu,Xingbo Wang,Dong Li,Yuxu Chen,Bin Chen,Yuanbo Zhou,Yuanbin Chen,Hongwei Wang,Jiannan Lin,Qinquan Gao,Tong Tong,Zhao Zhang,Yanyan Wei,Wei Dong,Han Zhou,Seyed Amirreza Mousavi,Jun Chen,Haobo Liang,Jiajie Jing,Junyu Li,Yan Yang,Seoyeon Lee,Chaewon Kim,Ziyu Feng,Shidi Chen,Bowen Luan,Zewen Chen,Vijayalaxmi Ashok Aralikatti,G Gyaneshwar Rao,Nikhil Akalwadi,Chaitra Desai,Ramesh Ashok Tabib,Uma Mudenagudi,Anas M. Ali,Bilel Benjdira,Wadii Boulila,Alexandru Brateanu,Cosmin Ancuti,Tanmay Chaturvedi,Manish Kumar,Anmol Srivastav,Daksh Trivedi,Shashwat Thakur,Kishor Upla,Zeyu Xiao,Zhuoyuan Li,Boda Zhou,Shashank Shekhar,Kele Xu,Qisheng Xu,Zijian Gao,Tianjiao Wan,Suiyi Zhao,Bo Wang,Yan Luo,Mingshen Wang,Yilin Zhang*

Main category: cs.CV

TL;DR: NTIRE 2025 Shadow Removal Challenge吸引了306名参与者，17支团队提交了解决方案，分为重建保真度和视觉感知两个评估轨道。

- Motivation: 研究阴影去除技术的性能，通过挑战赛形式推动技术进步。
- Method: 使用WSRD+数据集，模拟自阴影和投射阴影的交互，评估重建保真度和用户视觉感知。
- Result: 306名参与者注册，17支团队提交了最终解决方案。
- Conclusion: 挑战赛成功评估了阴影去除技术的性能，展示了多样化的解决方案。


### [50] [CLAIM: Clinically-Guided LGE Augmentation for Realistic and Diverse Myocardial Scar Synthesis and Segmentation](https://arxiv.org/abs/2506.15549)
*Farheen Ramzan,Yusuf Kiberu,Nikesh Jathanna,Shahnaz Jamil-Copley,Richard H. Clayton,Chen,Chen*

Main category: cs.CV

TL;DR: CLAIM框架通过临床引导的LGE增强和扩散生成技术，合成多样化且解剖学一致的心肌疤痕图像，并联合训练分割网络，提升疤痕分割的准确性。

- Motivation: 解决LGE图像稀缺和标签质量不一的问题，以支持心肌疤痕的准确分割和诊断。
- Method: 提出CLAIM框架，结合SMILE模块（基于临床知识的疤痕生成）和联合训练策略，生成解剖学一致的疤痕图像并优化分割网络。
- Result: CLAIM生成的疤痕图像解剖学一致且多样化，分割性能优于基线模型。
- Conclusion: CLAIM为可控且真实的疤痕合成提供了有效方法，支持下游医学影像任务。


### [51] [RaCalNet: Radar Calibration Network for Sparse-Supervised Metric Depth Estimation](https://arxiv.org/abs/2506.15560)
*Xingrui Qin,Wentao Zhao,Chuan Cao,Yihe Niu,Houcheng Jiang,Jingchuan Wang*

Main category: cs.CV

TL;DR: RaCalNet提出了一种无需密集监督的毫米波雷达深度估计框架，通过稀疏LiDAR监督实现高精度深度预测，显著降低成本和数据需求。

- Motivation: 传统方法依赖密集LiDAR监督，成本高且数据需求大，RaCalNet旨在解决这一问题。
- Method: 通过稀疏LiDAR监督重新校准和优化雷达点，构建深度先验，指导单目深度预测，避免密集监督。
- Result: 在ZJU-4DRadarCam数据集和实际场景中，RaCalNet表现优异，RMSE分别降低35.30%和34.89%。
- Conclusion: RaCalNet证明了稀疏监督的有效性，显著提升了深度估计的精度和效率。


### [52] [Control and Realism: Best of Both Worlds in Layout-to-Image without Training](https://arxiv.org/abs/2506.15563)
*Bonan Li,Yinhan Hu,Songhua Liu,Xinchao Wang*

Main category: cs.CV

TL;DR: WinWinLay提出了一种无需训练的方法，通过非局部注意力能量函数和自适应更新策略，解决了布局到图像生成中的定位不精确和伪影问题。

- Motivation: 现有基于预训练扩散模型的方法在布局到图像生成中存在定位不精确和伪影问题，WinWinLay旨在解决这些问题。
- Method: WinWinLay采用非局部注意力能量函数和基于Langevin动力学的自适应更新策略，优化控制精度和图像真实性。
- Result: 实验表明，WinWinLay在元素布局控制和视觉逼真度上优于现有方法。
- Conclusion: WinWinLay通过创新的训练无关策略，显著提升了布局到图像生成的质量。


### [53] [Show-o2: Improved Native Unified Multimodal Models](https://arxiv.org/abs/2506.15564)
*Jinheng Xie,Zhenheng Yang,Mike Zheng Shou*

Main category: cs.CV

TL;DR: Show-o2是一种改进的统一多模态模型，结合自回归建模和流匹配技术，支持图像和视频的多模态理解与生成。

- Motivation: 旨在构建一个统一的多模态模型，能够同时处理文本、图像和视频任务，并实现高效的多模态理解与生成。
- Method: 基于3D因果变分自编码器空间，通过双路径空间（时间）融合构建统一视觉表示，并采用两阶段训练方法。
- Result: Show-o2模型在多模态理解和生成任务中表现出色，支持文本、图像和视频的多样化处理。
- Conclusion: Show-o2展示了统一多模态模型的潜力，为多模态任务提供了高效且可扩展的解决方案。


### [54] [Baltimore Atlas: FreqWeaver Adapter for Semi-supervised Ultra-high Spatial Resolution Land Cover Classification](https://arxiv.org/abs/2506.15565)
*Junhao Wu,Aboagye-Ntow Stephen,Chuyuan Wang,Gang Chen,Xin Huang*

Main category: cs.CV

TL;DR: 提出了一种参数高效的半监督分割框架，用于0.3米空间分辨率影像，结合SAM2知识和遥感专用FreqWeaver适配器，显著提升细粒度细节建模能力。

- Motivation: 超高空间分辨率土地覆盖分类面临像素级标注成本高、尺度变化大以及大规模视觉模型适应性有限等挑战，现有方法多依赖标注数据且仅适用于1米分辨率影像。
- Method: 采用半监督分割框架，结合SAM2知识和FreqWeaver适配器，参数效率高（仅占总参数的5.96%）。
- Result: 在未标注数据上表现优异，结构一致性更强，比现有参数高效调优策略提升1.78%，比最先进高分辨率遥感分割方法提升3.44%。
- Conclusion: 该方法在弱监督下处理高分辨率影像时表现出色，参数效率高且细节建模能力强。


### [55] [A Unified Graph-based Framework for Scalable 3D Tree Reconstruction and Non-Destructive Biomass Estimation from Point Clouds](https://arxiv.org/abs/2506.15577)
*Di Wang,Shi Li*

Main category: cs.CV

TL;DR: 提出了一种基于图的新型统一框架，用于大规模点云的端到端处理，显著提升了森林地上生物量（AGB）估计的可行性和可扩展性。

- Motivation: 当前定量结构模型（QSM）方法在个体树依赖、高质量点云数据需求和多预处理步骤方面存在局限性，限制了其实际应用。
- Method: 采用创新的基于图的流程，集成树分割、叶木分离和3D骨架重建，通过路径和抽象等图操作进行树拓扑推理。
- Result: 在多种条件下（如叶覆盖、空间尺度和数据源）验证表现优异，叶覆盖场景相对误差约20%，低密度ULS数据集约30%。
- Conclusion: 该框架为大规模非破坏性AGB估计提供了稳健且可扩展的解决方案，减少了预处理依赖，并确立了ULS作为TLS的可行替代方案。


### [56] [One-Step Diffusion for Detail-Rich and Temporally Consistent Video Super-Resolution](https://arxiv.org/abs/2506.15591)
*Yujing Sun,Lingchen Sun,Shuaizheng Liu,Rongyuan Wu,Zhengqiang Zhang,Lei Zhang*

Main category: cs.CV

TL;DR: 论文提出了一种名为DLoRAL的双LoRA学习范式，用于在视频超分辨率任务中同时实现细节丰富和时间一致性。

- Motivation: 现有基于稳定扩散（SD）的Real-VSR方法通常在时间一致性和空间细节之间妥协，导致视觉质量不佳。论文旨在解决这一问题。
- Method: 通过双LoRA学习范式（DLoRAL），结合跨帧检索模块（CFR）和一致性-LoRA（C-LoRA）与细节-LoRA（D-LoRA），交替优化以实现细节和时间一致性。
- Result: 实验表明，DLoRAL在准确性和速度上均表现出色。
- Conclusion: DLoRAL通过双LoRA学习范式成功实现了视频超分辨率中细节和时间一致性的平衡。


### [57] [Mono-Modalizing Extremely Heterogeneous Multi-Modal Medical Image Registration](https://arxiv.org/abs/2506.15596)
*Kyobin Choo,Hyunkyung Han,Jinyeong Kim,Chanyong Yoon,Seong Jae Hwang*

Main category: cs.CV

TL;DR: 提出了一种名为M2M-Reg的新框架，用于处理多模态图像配准问题，通过单模态相似性训练模型，并引入GradCyCon正则化器提升性能。

- Motivation: 临床实践中，多模态图像配准（DIR）因模态间高度异质性导致传统无监督方法效果不佳，相似性度量难以捕捉对齐关系。
- Method: 提出M2M-Reg框架，利用单模态相似性训练多模态DIR模型，并引入GradCyCon正则化器促进微分同胚。
- Result: 在ADNI数据集上，M2M-Reg在PET-MRI和FA-MRI配准中DSC提升2倍。
- Conclusion: M2M-Reg有效解决了高度异质性多模态DIR问题，无需真实变换或分割掩码。


### [58] [BoxFusion: Reconstruction-Free Open-Vocabulary 3D Object Detection via Real-Time Multi-View Box Fusion](https://arxiv.org/abs/2506.15610)
*Yuqing Lan,Chenyang Zhu,Zhirui Gao,Jiazhao Zhang,Yihan Cao,Renjiao Yi,Yijie Wang,Kai Xu*

Main category: cs.CV

TL;DR: 提出了一种无需重建的实时3D目标检测框架，结合预训练视觉模型和CLIP，通过多视图融合实现高效检测。

- Motivation: 现有3D目标检测方法依赖密集点云重建，计算和内存开销大，难以实时部署。
- Method: 利用预训练视觉模型进行单视图检测，结合CLIP获取开放词汇语义，通过关联和优化模块融合多视图检测结果。
- Result: 在ScanNetV2和CA-1M数据集上达到在线方法的SOTA性能，支持超1000平方米环境的实时感知。
- Conclusion: 无需重建的框架在多种场景下表现优异，实现了高效实时的3D目标检测。


### [59] [HOIDiNi: Human-Object Interaction through Diffusion Noise Optimization](https://arxiv.org/abs/2506.15625)
*Roey Ron,Guy Tevet,Haim Sawdayee,Amit H. Bermano*

Main category: cs.CV

TL;DR: HOIDiNi是一个基于文本驱动的扩散框架，用于生成真实且合理的人-物交互（HOI），通过优化噪声空间实现高接触精度和自然运动。

- Motivation: 解决现有方法在真实感和物理正确性之间的权衡问题，提出一种两阶段优化方法以实现更优的HOI生成。
- Method: 采用Diffusion Noise Optimization (DNO)在预训练扩散模型的噪声空间中优化，分为物体中心阶段和人体中心阶段。
- Result: 在GRAB数据集上，HOIDiNi在接触精度、物理有效性和整体质量上优于现有方法。
- Conclusion: HOIDiNi能够生成复杂且可控的交互动作，仅通过文本驱动即可实现高质量的人-物交互。


### [60] [FindingDory: A Benchmark to Evaluate Memory in Embodied Agents](https://arxiv.org/abs/2506.15635)
*Karmesh Yadav,Yusuf Ali,Gunshi Gupta,Yarin Gal,Zsolt Kira*

Main category: cs.CV

TL;DR: 论文提出了一种新的基准测试，用于评估大型视觉语言模型在长期记忆和推理任务中的表现，特别是在机器人控制任务中。

- Motivation: 当前视觉语言模型在处理长期记忆和大量图像时存在局限性，需要更高效的机制来支持长期记忆的集成。
- Method: 在Habitat模拟器中设计了一个包含60个任务的基准测试，这些任务需要持续的环境交互和上下文感知。
- Result: 提出了基线模型，结合了先进的视觉语言模型和低级导航策略，评估了其在记忆密集型任务中的表现。
- Conclusion: 新基准测试为长期记忆和推理任务提供了可扩展的评估框架，并指出了改进方向。


### [61] [Demystifying the Visual Quality Paradox in Multimodal Large Language Models](https://arxiv.org/abs/2506.15645)
*Shuo Xing,Lanqing Guo,Hongyuan Hua,Seoyoung Lee,Peiran Li,Yufei Wang,Zhangyang Wang,Zhengzhong Tu*

Main category: cs.CV

TL;DR: 研究发现，多模态大语言模型（MLLMs）在视觉质量与任务表现之间存在矛盾，图像偏离人类感知的高保真度时表现更好。作者提出了一种轻量级适配模块VQ-TTT，动态调整输入图像以提升任务表现。

- Motivation: 探索视觉输入质量如何影响MLLMs的表现，发现高保真图像未必带来更好的模型理解。
- Method: 通过控制图像退化与风格变化，测试MLLMs表现；提出VQ-TTT模块，动态调整输入图像频率内容。
- Result: VQ-TTT显著提升MLLMs在所有数据集上的平均准确率，无需额外数据或模型。
- Conclusion: MLLMs需要适应性而非普遍“干净”的视觉输入，VQ-TTT为这一需求提供了解决方案。


### [62] [Dual-Stage Value-Guided Inference with Margin-Based Reward Adjustment for Fast and Faithful VLM Captioning](https://arxiv.org/abs/2506.15649)
*Ankan Deria,Adinath Madhavrao Dukre,Feilong Tang,Sara Atito,Sudipta Roy,Muhammad Awais,Muhammad Haris Khan,Imran Razzak*

Main category: cs.CV

TL;DR: ViMaR是一种两阶段推理框架，通过结合时间差分价值模型和边距感知奖励调整，显著提升视觉语言模型的效率和输出保真度。

- Motivation: 现有视觉语言模型推理方法计算成本高且易产生低置信度生成，导致幻觉问题。
- Method: ViMaR分两阶段：首阶段筛选最高价值候选描述，次阶段选择性优化弱视觉基础部分，并引入边距惩罚。
- Result: ViMaR在多个模型上生成更可靠、准确且详细的描述，速度提升4倍以上，并展示跨模型泛化能力。
- Conclusion: ViMaR具有可扩展性和可迁移性，能通过自训练显著提升模型性能。


### [63] [UniRelight: Learning Joint Decomposition and Synthesis for Video Relighting](https://arxiv.org/abs/2506.15673)
*Kai He,Ruofan Liang,Jacob Munkberg,Jon Hasselgren,Nandita Vijaykumar,Alexander Keller,Sanja Fidler,Igor Gilitschenski,Zan Gojcic,Zian Wang*

Main category: cs.CV

TL;DR: 提出了一种联合估计反照率并生成重光照输出的通用方法，利用视频扩散模型的生成能力，提升了场景理解和光照效果的真实性。

- Motivation: 现有端到端重光照模型因多光照数据稀缺而泛化能力有限，而两阶段流水线易产生误差累积且难以处理复杂光照或材质。
- Method: 采用单次联合估计反照率和生成重光照输出的方法，结合视频扩散模型的生成能力。
- Result: 模型在合成和真实视频数据上训练，表现出强泛化能力，在视觉保真度和时间一致性上优于先前方法。
- Conclusion: 该方法通过联合优化提升了重光照任务的性能，适用于复杂光照和材质场景。


### [64] [Sekai: A Video Dataset towards World Exploration](https://arxiv.org/abs/2506.15675)
*Zhen Li,Chuanhao Li,Xiaofeng Mao,Shaoheng Lin,Ming Li,Shitian Zhao,Zhaopan Xu,Xinyue Li,Yukang Feng,Jianwen Sun,Zizhen Li,Fanrui Zhang,Jiaxin Ai,Zhixiang Wang,Yuwei Wu,Tong He,Jiangmiao Pang,Yu Qiao,Yunde Jia,Kaipeng Zhang*

Main category: cs.CV

TL;DR: 论文介绍了Sekai数据集，一个高质量的第一人称视角全球视频数据集，用于世界探索训练，解决了现有数据集的局限性。

- Motivation: 现有视频生成数据集不适合世界探索训练，存在地点有限、时长短、场景静态和缺乏探索相关标注的问题。
- Method: 开发了一个高效的工具箱，用于收集、预处理和标注视频，包括位置、场景、天气等信息，并使用部分数据训练了交互式视频世界探索模型YUME。
- Result: Sekai数据集包含5000多小时视频，覆盖100多个国家和750个城市，实验验证了其质量。
- Conclusion: Sekai数据集将推动视频生成和世界探索领域的发展，并激发有价值的应用。


### [65] [Evolutionary Caching to Accelerate Your Off-the-Shelf Diffusion Model](https://arxiv.org/abs/2506.15682)
*Anirud Aggarwal,Abhinav Shrivastava,Matthew Gwilliam*

Main category: cs.CV

TL;DR: ECAD是一种基于遗传算法的缓存调度方法，显著加速扩散模型的推理速度，同时保持生成质量。

- Motivation: 扩散模型推理速度慢且计算成本高，现有方法依赖固定启发式规则，效果有限。
- Method: 提出ECAD，通过遗传算法学习高效的缓存调度策略，无需修改模型参数或参考图像。
- Result: 在多个模型和基准测试中，ECAD显著提升推理速度（如PixArt-alpha加速至2.58倍），并改善生成质量（COCO FID提升4.47）。
- Conclusion: ECAD是一种可扩展且通用的扩散模型加速方法，适用于不同模型和分辨率。
## cs.LG

### [66] [PIPE: Physics-Informed Position Encoding for Alignment of Satellite Images and Time Series](https://arxiv.org/abs/2506.14786)
*Haobo Li,Eunseo Jung,Zixin Chen,Zhaowei Wang,Yueya Wang,Huamin Qu,Alexis Kai Hon Lau*

Main category: cs.LG

TL;DR: 论文提出了一种名为PIPE的轻量级方法，通过物理信息位置编码提升多模态时间序列预测的准确性，尤其在卫星图像和数值数据的应用中表现优异。

- Motivation: 现有方法主要关注文本数据，忽略了视觉数据中的物理信息（如卫星图像的时空背景），导致预测效果受限。
- Method: PIPE通过物理信息位置索引和变频率位置编码机制，将物理信息嵌入视觉语言模型，同时保留物理信息和序列顺序。
- Result: 在最大开源卫星图像数据集上，PIPE在深度学习和气候领域方法中均达到最优性能，台风强度预测提升12%。
- Conclusion: PIPE显著提升了多模态对齐和预测准确性，为视觉数据在时间序列预测中的应用提供了有效解决方案。


### [67] [Reinforcing VLMs to Use Tools for Detailed Visual Reasoning Under Resource Constraints](https://arxiv.org/abs/2506.14821)
*Sunil Kumar,Bowen Zhao,Leo Dirac,Paulina Varshavskaya*

Main category: cs.LG

TL;DR: 论文提出了一种结合GRPO训练、简单奖励结构和工具调用接口的小规模视觉语言模型，用于提升有限计算资源下的详细视觉推理能力。

- Motivation: 尽管大模型在推理能力上取得了显著进展，但视觉语言模型（VLMs）在有限计算资源下仍难以进行详细视觉推理。
- Method: 采用Group Relative Policy Optimization（GRPO）训练小规模模型，结合简单奖励结构、简化工具调用接口、额外分配工具调用结果令牌，以及侧重视觉难例的训练数据。
- Result: 相比同类基线模型，该方法在部分视觉问答（VQA）任务中表现更优，得益于外部工具提供的详细视觉信息。
- Conclusion: 通过GRPO训练和工具调用优化，小规模视觉语言模型在有限计算资源下也能实现更好的详细视觉推理能力。


### [68] [CACTUS as a Reliable Tool for Early Classification of Age-related Macular Degeneration](https://arxiv.org/abs/2506.14843)
*Luca Gherardini,Imre Lengyel,Tunde Peto,Caroline C. W. Klaverd,Magda A. Meester-Smoord,Johanna Maria Colijnd,EYE-RISK Consortium,E3 Consortium,Jose Sousa*

Main category: cs.LG

TL;DR: 论文提出CACTUS工具，用于改进AMD分期分类，解决医疗数据不完整和模型透明度问题。

- Motivation: 医疗数据通常不完整且有限，影响ML模型性能，同时模型透明度不足。AMD早期诊断至关重要，但缺乏有效治疗方法。
- Method: 引入CACTUS工具，结合遗传、饮食、临床和人口因素进行分类，提供可解释性和灵活性。
- Result: CACTUS优于标准ML模型，能识别关键因素并提供结果可信度，消除无关或偏差数据。
- Conclusion: CACTUS为临床决策提供支持，帮助医生反馈并解决偏差，提升AMD分类效果。


### [69] [Pixel-level Certified Explanations via Randomized Smoothing](https://arxiv.org/abs/2506.15499)
*Alaa Anani,Tobias Lorenz,Mario Fritz,Bernt Schiele*

Main category: cs.LG

TL;DR: 论文提出了一种基于随机平滑的认证框架，保证任何黑盒归因方法的像素级鲁棒性，并通过稀疏化和平滑化归因图，将其重新表述为分割问题。

- Motivation: 现有的后验归因方法在输入微小扰动时归因图会剧烈变化，但预测结果不变，这降低了其可信度，因此需要严格的鲁棒性保证。
- Method: 采用随机平滑技术，将归因图稀疏化和平滑化，重新定义为分割问题，并认证每个像素的重要性。
- Result: 在12种归因方法和5个ImageNet模型上的广泛评估表明，认证后的归因具有鲁棒性、可解释性和忠实性。
- Conclusion: 该框架为归因方法提供了可靠的鲁棒性保证，适用于下游任务。
## cs.MM

### [70] [Omnidirectional Video Super-Resolution using Deep Learning](https://arxiv.org/abs/2506.14803)
*Arbind Agrahari Baniya,Tsz-Kwan Lee,Peter W. Eklund,Sunil Aryal*

Main category: cs.MM

TL;DR: 本文提出了一种针对360度视频的超分辨率方法S3PO，通过新型数据集360VDS和优化的深度学习模型，解决了传统VSR技术在360度视频中的失真问题。

- Motivation: 360度视频在VR中广泛应用，但其空间分辨率有限，影响视觉质量。传统VSR技术无法解决360度视频的失真问题，且缺乏相关数据集。
- Method: 创建360VDS数据集，提出S3PO模型，采用循环建模和注意力机制，优化特征提取和损失函数以解决球形失真。
- Result: S3PO在360度视频数据集上优于大多数传统VSR模型和特定超分辨率模型。
- Conclusion: S3PO通过针对性训练和优化，有效提升了360度视频的超分辨率效果。
## cs.RO

### [71] [Towards Perception-based Collision Avoidance for UAVs when Guiding the Visually Impaired](https://arxiv.org/abs/2506.14857)
*Suman Raj,Swapnil Padhi,Ruchi Bhoot,Prince Modi,Yogesh Simmhan*

Main category: cs.RO

TL;DR: 无人机通过机载传感器结合机器学习和计算机视觉算法，为视觉障碍者提供户外导航辅助。

- Motivation: 探索无人机在户外城市环境中辅助视觉障碍者导航的可行性。
- Method: 提出基于感知的路径规划系统，结合局部和全局规划，使用几何问题表述和多DNN框架进行障碍物避障。
- Result: 在校园环境中验证了算法在三种场景下的可行性：人行道行走、停车区附近和拥挤街道。
- Conclusion: 无人机系统在辅助视觉障碍者导航方面具有实际应用潜力。


### [72] [Robust Instant Policy: Leveraging Student's t-Regression Model for Robust In-context Imitation Learning of Robot Manipulation](https://arxiv.org/abs/2506.15157)
*Hanbit Oh,Andrea M. Salcedo-Vázquez,Ixchel G. Ramirez-Alpizar,Yukiyasu Domae*

Main category: cs.RO

TL;DR: 提出了一种鲁棒的上下文模仿学习算法RIP，通过学生t回归模型减少LLM生成的幻觉轨迹，提升任务成功率。

- Motivation: 解决LLM在模仿学习中因幻觉轨迹导致的可靠性问题。
- Method: 利用学生t分布聚合LLM生成的候选轨迹，忽略异常值。
- Result: 在模拟和真实环境中，RIP显著优于现有方法，任务成功率提升至少26%。
- Conclusion: RIP在低数据场景下表现优异，适用于日常任务。


### [73] [MCOO-SLAM: A Multi-Camera Omnidirectional Object SLAM System](https://arxiv.org/abs/2506.15402)
*Miaoxin Pan,Jinnan Li,Yaowen Zhang,Yi Yang,Yufeng Yue*

Main category: cs.RO

TL;DR: MCOO-SLAM是一种多相机全向物体SLAM系统，利用环绕视角相机配置，在复杂户外场景中实现鲁棒、一致且语义丰富的建图。

- Motivation: 现有SLAM方法依赖RGB-D或单目相机，视野窄、易受遮挡且深度感知有限，导致物体建模不准确和数据关联不可靠。
- Method: 结合点特征和物体级地标，引入语义-几何-时间融合策略，设计全向闭环模块，并构建分层3D场景图。
- Result: 实验表明，MCOO-SLAM在真实场景中实现了精确定位和可扩展的物体级建图，对遮挡、姿态变化和环境复杂性具有更强鲁棒性。
- Conclusion: MCOO-SLAM通过多相机全向视角和语义增强，显著提升了复杂户外场景中的SLAM性能。


### [74] [Particle-Grid Neural Dynamics for Learning Deformable Object Models from RGB-D Videos](https://arxiv.org/abs/2506.15680)
*Kaifeng Zhang,Baoyu Li,Kris Hauser,Yunzhu Li*

Main category: cs.RO

TL;DR: 论文提出了一种结合粒子与空间网格的神经动力学框架，用于建模可变形物体的动态行为，并通过实验验证其优于现有方法。

- Motivation: 可变形物体的动态建模因物理属性多样和视觉信息有限而具有挑战性。
- Method: 采用粒子-网格混合表示，结合高斯渲染技术，实现全学习化的数字孪生模型。
- Result: 模型能够从稀疏视角的RGB-D数据中学习多种物体的动态行为，并在类别级别泛化到未见实例。
- Conclusion: 该方法在有限视角下优于现有学习与物理模拟器，并展示了在任务规划中的应用潜力。
## cs.SE

### [75] [An Empirical Study of Bugs in Data Visualization Libraries](https://arxiv.org/abs/2506.15084)
*Weiqi Lu,Yongqiang Tian,Xiaohan Zhong,Haoyang Ma,Zhenyang Xu,Shing-Chi Cheung,Chengnian Sun*

Main category: cs.SE

TL;DR: 该研究首次全面分析了数据可视化库中的错误，研究了564个错误，提出了症状和根源的分类，并探索了视觉语言模型在检测错误中的可行性。

- Motivation: 数据可视化库的准确性对用户体验和决策至关重要，但视觉错误可能误导用户，因此需要深入理解这些错误的特性以改进检测和修复方法。
- Method: 研究收集了五个常用库中的564个错误，系统分析了其症状和根源，并提出了分类。同时探索了视觉语言模型在检测错误中的应用。
- Result: 发现不正确/不准确的图表在数据可视化库中普遍存在，主要根源是图形计算错误。视觉语言模型在检测错误中的效果因提示而异，效果在29%至57%之间。
- Conclusion: 研究为数据可视化库的自动化测试提供了关键见解，并指出了视觉语言模型在错误检测中的潜力与局限性。
## cs.AI

### [76] [Embodied Web Agents: Bridging Physical-Digital Realms for Integrated Agent Intelligence](https://arxiv.org/abs/2506.15677)
*Yining Hong,Rui Sun,Bingxuan Li,Xingcheng Yao,Maxine Wu,Alexander Chien,Da Yin,Ying Nian Wu,Zhecan James Wang,Kai-Wei Chang*

Main category: cs.AI

TL;DR: 论文提出了一种新型AI代理范式——Embodied Web Agents，旨在融合物理世界交互与网络规模推理能力，并开发了统一仿真平台和基准测试。

- Motivation: 当前AI代理在物理世界交互和网络信息推理之间存在割裂，限制了其解决跨领域任务的能力。
- Method: 开发了Embodied Web Agents任务环境和基准测试，整合3D仿真环境与功能性网络接口。
- Result: 实验显示现有AI系统与人类能力存在显著差距，揭示了跨领域智能的挑战与机遇。
- Conclusion: 论文为融合物理与数字智能的研究提供了平台和基准，推动了跨领域AI代理的发展。
## cs.GR

### [77] [Human Motion Capture from Loose and Sparse Inertial Sensors with Garment-aware Diffusion Models](https://arxiv.org/abs/2506.15290)
*Andela Ilic,Jiaxi Jiang,Paul Streli,Xintong Liu,Christian Holz*

Main category: cs.GR

TL;DR: 提出了一种基于稀疏、松散附着IMU传感器的全身姿态估计新任务，通过模拟数据和扩散模型解决，性能优于现有方法。

- Motivation: 现有方法假设IMU传感器紧密附着于人体，但实际场景中常不成立，因此研究松散附着情况下的姿态估计。
- Method: 模拟松散IMU数据，开发基于Transformer的扩散模型，结合服装参数训练。
- Result: 在模拟和合成数据上训练的扩散模型在定量和定性上均优于现有方法。
- Conclusion: 为松散IMU传感器姿态估计提供了新方向，性能显著提升。


### [78] [One-shot Face Sketch Synthesis in the Wild via Generative Diffusion Prior and Instruction Tuning](https://arxiv.org/abs/2506.15312)
*Han Wu,Junyao Li,Kangbo Zhao,Sen Zhang,Yukai Shi,Liang Lin*

Main category: cs.GR

TL;DR: 提出一种基于扩散模型的一次性人脸素描合成方法，解决数据稀缺问题，并引入新基准数据集OS-Sketch。

- Motivation: 现有方法依赖大量训练数据，面临数据稀缺和高成本问题，性能在数据不足时显著下降。
- Method: 通过梯度优化扩散模型的文本指令，利用单对照片-素描图像进行训练和推理。
- Result: 实验表明，该方法能在一次性场景下生成逼真且一致的素描，优于其他方法。
- Conclusion: 该方法更便捷且适用性更广，数据集将公开。


### [79] [Nabla-R2D3: Effective and Efficient 3D Diffusion Alignment with 2D Rewards](https://arxiv.org/abs/2506.15684)
*Qingming Liu,Zhen Liu,Dinghuai Zhang,Kui Jia*

Main category: cs.GR

TL;DR: Nabla-R2D3是一种基于强化学习的对齐框架，用于优化3D扩散模型，仅需2D奖励信号即可高效生成高质量的3D内容。

- Motivation: 现有3D生成模型（如扩散模型）在遵循指令、对齐人类偏好及生成逼真纹理、几何和物理属性方面存在不足。
- Method: 基于Nabla-GFlowNet方法，Nabla-R2D3通过2D奖励信号对3D扩散模型进行高效调整。
- Result: 实验表明，Nabla-R2D3在少量调整步骤内能获得更高奖励并减少先验遗忘，优于传统基线方法。
- Conclusion: Nabla-R2D3为3D生成模型提供了一种高效且样本利用率高的对齐解决方案。
## eess.IV

### [80] [Empirical Studies of Large Scale Environment Scanning by Consumer Electronics](https://arxiv.org/abs/2506.14771)
*Mengyuan Wang,Yang Liu,Haopeng Wang,Haiwei Dong,Abdulmotaleb El Saddik*

Main category: eess.IV

TL;DR: 本文对Matterport Pro3消费级3D扫描设备在大规模环境重建中的表现进行了实证评估，展示了其高密度点云和高对齐精度的优势。

- Motivation: 评估Matterport Pro3在大规模环境重建中的效果，探索其性能提升和局限性，并与iPhone等其他设备进行比较。
- Method: 通过1,099个扫描点对六层建筑（17,567平方米）进行详细扫描，分析设备性能并提出改进方案。
- Result: Pro3生成的点云密度更高（1,877,324点 vs. iPhone的506,961点），对齐精度更高（RMSE 0.0118米），C2C平均距离误差为0.0408米。
- Conclusion: Matterport Pro3适合大规模应用，结合LiDAR和先进对齐技术，能生成高质量3D模型。


### [81] [Deploying and Evaluating Multiple Deep Learning Models on Edge Devices for Diabetic Retinopathy Detection](https://arxiv.org/abs/2506.14834)
*Akwasi Asare,Dennis Agyemanh Nana Gookyi,Derrick Boateng,Fortunatus Aabangbio Wulnye*

Main category: eess.IV

TL;DR: 该研究提出了一种基于Edge Impulse和深度学习模型的实时糖尿病视网膜病变（DR）检测方法，适用于边缘设备，具有高准确性和低延迟。

- Motivation: 糖尿病视网膜病变（DR）是全球糖尿病患者视力损害的主要原因，传统诊断方法耗时且资源密集，亟需高效、低成本的解决方案。
- Method: 研究使用Kaggle EyePACS数据集，通过预处理增强数据，并训练多种CNN模型（如MobileNet、ShuffleNet等），优化为TensorFlowLite格式并量化，以适配边缘设备。
- Result: MobileNet准确率达96.45%，SqueezeNet模型仅176KB，延迟17ms，适合实时检测；其他模型在资源效率上表现优异。
- Conclusion: 边缘AI技术为DR早期检测提供了可扩展、低成本的解决方案，尤其适用于资源有限的医疗环境。


### [82] [Improving Prostate Gland Segmenting Using Transformer based Architectures](https://arxiv.org/abs/2506.14844)
*Shatha Abudalou*

Main category: eess.IV

TL;DR: 研究探讨了Transformer模型（UNETR和SwinUNETR）在T2加权MRI图像中前列腺分割的鲁棒性，相比传统3D UNet，SwinUNETR在跨域和标签噪声下表现更优。

- Motivation: 解决T2加权MRI图像中前列腺分割的跨域差异和读者间变异性问题，提升自动分割的精确性。
- Method: 比较UNETR、SwinUNETR与3D UNet的性能，采用单队列、5折交叉验证混合队列和基于腺体大小的数据集三种训练策略，使用Optuna调参。
- Result: SwinUNETR在单读者训练和混合训练中表现最佳，Dice分数最高提升5分，尤其在腺体大小子集中表现突出。
- Conclusion: SwinUNETR通过全局和移位窗口自注意力机制有效降低标签噪声和类别不平衡敏感性，适合临床部署。


### [83] [Foundation Artificial Intelligence Models for Health Recognition Using Face Photographs (FAHR-Face)](https://arxiv.org/abs/2506.14909)
*Fridolin Haugg,Grace Lee,John He,Leonard Nürnberg,Dennis Bontempi,Danielle S. Bitterman,Paul Catalano,Vasco Prudente,Dmitrii Glubokov,Andrew Warrington,Suraj Pai,Dirk De Ruysscher,Christian Guthier,Benjamin H. Kann,Vadim N. Gladyshev,Hugo JWL Aerts,Raymond H. Mak*

Main category: eess.IV

TL;DR: FAHR-Face是一个基于4000万张面部图像训练的基础模型，通过微调用于生物年龄估计和生存风险预测，表现出色且具有临床实用性。

- Motivation: 通过面部外观非侵入性地评估健康和疾病风险，提供低成本、可扩展的生物标志物。
- Method: FAHR-FaceAge通过两阶段微调处理公开图像，FAHR-FaceSurvival微调癌症患者照片，测试了模型鲁棒性和独立性，并在临床数据集中验证。
- Result: FAHR-FaceAge在年龄估计上误差最低（5.1年），FAHR-FaceSurvival能稳健预测死亡率，最高风险组死亡率是最低组的3倍以上。
- Conclusion: 单一基础模型可生成捕捉生物衰老和疾病风险的面部标志物，且在小临床数据集上有效训练。


### [84] [Recursive Variational Autoencoders for 3D Blood Vessel Generative Modeling](https://arxiv.org/abs/2506.14914)
*Paula Feldman,Miguel Fainstein,Viviana Siless,Claudio Delrieux,Emmanuel Iarussi*

Main category: eess.IV

TL;DR: 提出了一种递归变分神经网络（RvNN），用于生成准确且多样化的血管3D模型，解决了现有规则方法无法捕捉真实解剖数据复杂性的问题。

- Motivation: 解剖树在临床诊断和治疗规划中至关重要，但现有方法难以准确表示其复杂拓扑和几何结构。
- Method: 开发了RvNN，利用血管的层次结构学习低维流形，编码分支连接性和几何特征，生成新的血管几何结构。
- Result: 生成的血管模型在半径、长度和弯曲度等方面与真实数据高度相似，适用于医学培训和模拟。
- Conclusion: RvNN首次用于血管合成，为医学领域提供了高效且多样化的血管生成工具。


### [85] [NeuroMoE: A Transformer-Based Mixture-of-Experts Framework for Multi-Modal Neurological Disorder Classification](https://arxiv.org/abs/2506.14970)
*Wajih Hassan Raza,Aamir Bader Shah,Yu Wen,Yidan Shen,Juan Diego Martinez Lemus,Mya Caryn Schiess,Timothy Michael Ellmore,Renjie Hu,Xin Fu*

Main category: eess.IV

TL;DR: 提出了一种基于Transformer的Mixture-of-Experts框架，用于多模态MRI和临床数据的神经疾病分类，显著提升了诊断准确性。

- Motivation: 多模态MRI和临床数据的整合在神经疾病诊断中具有潜力，但现有深度学习方法未能有效利用这些数据。
- Method: 采用Transformer编码器捕捉MRI数据的空间关系，结合模态特定专家进行特征提取，并通过自适应融合门控机制整合输出。
- Result: 验证准确率达到82.47%，比基线方法提升超过10%。
- Conclusion: 该框架在多模态学习应用于临床数据方面具有显著潜力，能有效区分重叠疾病状态。


### [86] [Classification of Multi-Parametric Body MRI Series Using Deep Learning](https://arxiv.org/abs/2506.15182)
*Boah Kim,Tejas Sudharshan Mathai,Kimberly Helm,Peter A. Pinto,Ronald M. Summers*

Main category: eess.IV

TL;DR: 提出了一种基于深度学习的分类模型，用于准确分类8种不同的多参数磁共振成像（mpMRI）序列类型，以提高放射科医生的工作效率。

- Motivation: 由于DICOM头部信息常因协议多样性和技术员错误而不准确，影响了mpMRI数据的读取效率。
- Method: 使用ResNet、EfficientNet和DenseNet等多种深度学习分类器对8种MRI序列进行分类，并比较其性能。
- Result: DenseNet-121模型在内部数据集上达到最高F1分数（0.966）和准确率（0.972），在外部数据集上也表现良好。
- Conclusion: DenseNet-121模型在分类mpMRI序列类型任务中表现出高准确性和泛化能力。


### [87] [Privacy-Preserving Chest X-ray Classification in Latent Space with Homomorphically Encrypted Neural Inference](https://arxiv.org/abs/2506.15258)
*Jonghun Kim,Gyeongdeok Jo,Shinyoung Ra,Hyunjin Park*

Main category: eess.IV

TL;DR: 提出了一种基于VQGAN和同态加密（HE）的医疗图像推理框架，通过压缩图像和多项式逼近激活函数，显著降低计算负担，同时保持图像质量。

- Motivation: 医疗图像包含敏感信息，需要隐私保护，但HE推理计算成本高，特别是对大图像（如胸片）。
- Method: 使用VQGAN压缩图像为潜在表示，用低阶多项式逼近激活函数，并引入Squeeze and Excitation模块优化HE框架。
- Result: 在胸片数据集上测试，压缩因子为8时性能与计算成本达到最优平衡，HE推理虽慢但实用性强。
- Conclusion: 该方法在医疗图像隐私保护中具有实际应用潜力，尽管HE推理仍有性能差异。


### [88] [FedWSIDD: Federated Whole Slide Image Classification via Dataset Distillation](https://arxiv.org/abs/2506.15365)
*Haolong Jin,Shenglin Liu,Cong Cong,Qingmin Feng,Yongzhi Liu,Lina Huang,Yingzi Hu*

Main category: eess.IV

TL;DR: FedWSIDD是一种新的联邦学习范式，通过数据集蒸馏（DD）生成和传输合成切片，解决医学图像分析中的计算资源异构性和隐私问题。

- Motivation: 联邦学习在医学图像分析中面临计算资源异构性和隐私保护的挑战，特别是在全切片图像（WSI）分类任务中。
- Method: 提出FedWSIDD，利用数据集蒸馏生成合成切片，并在服务器端聚合和分发这些切片。客户端采用新的DD算法，结合染色归一化生成紧凑且信息丰富的合成切片。
- Result: 在CAMELYON16和CAMELYON17等任务上的实验表明，FedWSIDD支持异构本地模型，提升分类性能，同时保护隐私。
- Conclusion: FedWSIDD是解决复杂WSI分类任务的有效方案。


### [89] [A Real-time Endoscopic Image Denoising System](https://arxiv.org/abs/2506.15395)
*Yu Xing,Shishi Huang,Meng Lv,Guo Chen,Huailiang Wang,Lingzhi Sui*

Main category: eess.IV

TL;DR: 论文提出了一种针对医疗内窥镜中模拟图像传感器的混合去噪系统，有效解决了噪声问题并提升了图像质量。

- Motivation: 单次使用内窥镜虽降低了感染风险，但小尺寸传感器导致光子捕获不足、动态范围受限及噪声显著，影响图像质量。
- Method: 开发了噪声模型并提出了结合传统图像处理与学习技术的混合去噪系统。
- Result: 实验显示系统有效降噪，PSNR从21.16提升至33.05，且实时运行于FPGA平台。
- Conclusion: 混合去噪系统显著提升内窥镜图像质量，适用于实际医疗场景。


### [90] [Advanced cervical cancer classification: enhancing pap smear images with hybrid PMD Filter-CLAHE](https://arxiv.org/abs/2506.15489)
*Ach Khozaimi,Isnani Darti,Syaiful Anam,Wuryansari Muharini Kusumawinahyu*

Main category: eess.IV

TL;DR: 研究探讨了图像预处理技术对CNN在宫颈癌分类中的影响，提出了一种混合PMD-CLAHE方法，显著提升了模型性能。

- Motivation: 宫颈癌早期检测至关重要，但CNN性能受图像质量影响，需优化预处理技术。
- Method: 评估了PMD、CLAHE及混合PMD-CLAHE预处理技术，并在多个预训练CNN模型上测试。
- Result: 混合方法显著提升性能，最高提升13.62%准确率、10.04%精确率、13.08%召回率和14.34% F1分数。
- Conclusion: 混合PMD-CLAHE技术为CNN在宫颈癌分类中的性能提升提供了新思路。


### [91] [Automated MRI Tumor Segmentation using hybrid U-Net with Transformer and Efficient Attention](https://arxiv.org/abs/2506.15562)
*Syed Haider Ali,Asrar Ahmad,Muhammad Ali,Asifullah Khan,Muhammad Shahban,Nadeem Shaukat*

Main category: eess.IV

TL;DR: 该研究提出了一种混合UNet-Transformer模型，用于本地医院MRI数据集的肿瘤分割，通过数据增强和高效架构设计，实现了竞争性性能。

- Motivation: 现有AI分割模型基于公共数据集训练，缺乏本地患者群体的异质性，需开发适用于本地数据集的模型以优化临床治疗计划。
- Method: 采用混合UNet-Transformer架构，结合多种注意力模块，并通过数据增强和预训练权重初始化提升性能。
- Result: 在本地MRI数据集上，Dice系数为0.764，IoU为0.736，表现优异。
- Conclusion: 研究强调了针对特定临床环境开发模型的重要性，为肿瘤分割的临床部署提供了有效解决方案。
## cs.SD

### [92] [pycnet-audio: A Python package to support bioacoustics data processing](https://arxiv.org/abs/2506.14864)
*Zachary J. Ruff,Damon B. Lesmeister*

Main category: cs.SD

TL;DR: 论文介绍了被动声学监测方法及其自动化工具pycnet-audio，用于处理大规模野生动物声音数据。

- Motivation: 传统手动处理大规模声学数据效率低下，需自动化工具支持。
- Method: 利用PNW-Cnet模型扩展检测80种森林野生动物及环境噪声。
- Result: pycnet-audio提供高效处理流程，支持多种目标信号检测。
- Conclusion: 自动化工具显著提升声学数据处理效率，适用于生态研究。


### [93] [An accurate and revised version of optical character recognition-based speech synthesis using LabVIEW](https://arxiv.org/abs/2506.15029)
*Prateek Mehta,Anasuya Patil*

Main category: cs.SD

TL;DR: 开发了一种基于OCR的语音合成系统，帮助视障人士通过声音获取知识。

- Motivation: 视障人士通常依赖盲文书籍和音频，但这些方式有限，无法满足个性化需求。语音是更有效的沟通方式。
- Method: 使用LabVIEW实现OCR技术，构建准确、可靠、经济且用户友好的语音合成系统。
- Result: 系统成功实现，能够通过OCR将文本转换为语音。
- Conclusion: 该系统为视障人士提供了一种更灵活的知识获取方式。
