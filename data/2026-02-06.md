[[toc]]

## cs.CV

### [1] [SIDeR: Semantic Identity Decoupling for Unrestricted Face Privacy](https://arxiv.org/abs/2602.04994)
*Zhuosen Bao,Xia Du,Zheng Lin,Jizhe Zhou,Zihan Fang,Jiening Wu,Yuxin Zhang,Zhe Chen,Chi-man Pun,Wei Ni,Jun Luo*

Main category: cs.CV

TL;DR: SIDeR是一个语义解耦驱动的无限制人脸隐私保护框架，通过将人脸图像分解为机器可识别的身份特征和视觉可感知的外观组件，在扩散模型潜在空间中生成视觉匿名但机器身份一致的对抗样本。

- Motivation: 随着人脸识别在在线银行、身份验证等网络服务中的深度集成，如何在图像存储和传输过程中实现身份信息与视觉表征的有效解耦，已成为隐私保护的关键挑战。
- Method: SIDeR将人脸图像分解为身份特征向量和语义外观组件，利用扩散模型潜在空间中的语义引导重组，通过动量驱动的无限制扰动优化和语义-视觉平衡因子，生成多个视觉多样、高度自然的对抗样本。对于授权访问，可通过正确密码恢复原始图像。
- Result: 在CelebA-HQ和FFHQ数据集上的实验表明，SIDeR在黑盒场景下达到99%的攻击成功率，在PSNR恢复质量上比基线方法高出41.28%。
- Conclusion: SIDeR框架有效解决了人脸隐私保护中的身份-视觉解耦问题，既能保护视觉隐私又能保持机器身份一致性，同时支持授权恢复功能。


### [2] [UniTrack: Differentiable Graph Representation Learning for Multi-Object Tracking](https://arxiv.org/abs/2602.05037)
*Bishoy Galoaa,Xiangyu Bai,Utsav Nandi,Sai Siddhartha Vivek Dhir Rangoju,Somaieh Amraee,Sarah Ostadabbas*

Main category: cs.CV

TL;DR: UniTrack提出了一种即插即用的图论损失函数，通过统一可微分学习直接优化多目标跟踪特定目标，无需修改现有架构即可提升跟踪性能。

- Motivation: 现有基于图的MOT方法通常需要重新设计跟踪架构，缺乏一个统一的训练目标来同时优化检测精度、身份保持和时空一致性，导致跟踪性能受限。
- Method: UniTrack通过可微分图表示学习，将检测精度、身份保持和时空一致性集成到单个端到端可训练损失函数中，为现有MOT系统提供通用训练目标。
- Result: 在多种跟踪模型和基准测试中验证，包括Trackformer、MOTR、FairMOT、ByteTrack、GTR和MOTE，身份切换减少53%，IDF1提升12%，GTR在SportsMOT上MOTA提升9.7%。
- Conclusion: UniTrack作为一种通用可微分损失函数，能够显著提升多目标跟踪性能，无需修改现有架构，在各种模型和数据集上表现出一致的改进。


### [3] [VISTA: Enhancing Visual Conditioning via Track-Following Preference Optimization in Vision-Language-Action Models](https://arxiv.org/abs/2602.05049)
*Yiye Chen,Yanan Jian,Xiaoyi Dong,Shuxin Cao,Jing Wu,Patricio Vela,Benjamin E. Lundell,Dongdong Chen*

Main category: cs.CV

TL;DR: 提出VISTA训练框架，通过偏好优化和潜在空间蒸馏增强VLA模型的视觉条件化，解决视觉-动作错位问题，提升任务性能

- Motivation: 现有VLA模型在扩展到动作空间时会产生视觉-动作错位问题，导致动作预测对当前视觉状态的依赖性较弱，产生不可靠的动作输出
- Method: 首先通过跟踪跟随代理任务的偏好优化对齐动作预测与视觉输入，然后在监督微调期间通过潜在空间蒸馏将增强的对齐转移到指令跟随任务
- Result: 方法在离散OpenVLA上改善了视觉条件化和任务性能，在连续OpenVLA-OFT设置中也获得了一致的性能提升，无需架构修改或额外数据收集
- Conclusion: 通过显式加强视觉条件化可以有效解决VLA模型中的视觉-动作错位问题，提升模型在机器人操作任务中的可靠性和性能


### [4] [Food Portion Estimation: From Pixels to Calories](https://arxiv.org/abs/2602.05078)
*Gautham Vinod,Fengqing Zhu*

Main category: cs.CV

TL;DR: 本文综述了基于图像的饮食评估中食物体积估计的各种策略，包括深度图、多视角输入、模板匹配等辅助方法，以及深度学习在单目图像和组合输入中的应用。

- Motivation: 基于图像的饮食评估对于准确监测个体健康、预防慢性疾病和肥胖至关重要，但现有方法面临从2D图像估计3D食物尺寸的挑战。
- Method: 探索了多种策略：使用深度图、多视角输入等辅助输入，模板匹配等模型方法，以及深度学习（单目图像或图像与辅助输入组合）来精确预测食物分量。
- Result: 综述了不同策略在准确分量估计方面的应用，但没有提供具体的实验结果或性能比较数据。
- Conclusion: 基于图像的饮食评估需要克服2D到3D的尺寸估计挑战，多种策略已被开发，深度学习为这一领域提供了有前景的解决方案。


### [5] [Visual concept ranking uncovers medical shortcuts used by large multimodal models](https://arxiv.org/abs/2602.05096)
*Joseph D. Janizek,Sonnet Xu,Junayd Lateef,Roxana Daneshjou*

Main category: cs.CV

TL;DR: 提出Visual Concept Ranking (VCR)方法，用于识别大型多模态模型中的视觉概念，并用于审计医疗任务中模型的行为，特别是在皮肤病变分类任务中发现不同人口统计子组间的性能差距。

- Motivation: 在医疗等安全关键领域，需要审计方法来发现机器学习模型的缺陷，确保模型可靠性。大型多模态模型在医疗任务中可能存在未发现的性能差距和视觉概念依赖问题。
- Method: 提出Visual Concept Ranking (VCR)方法，用于识别大型多模态模型中的重要视觉概念。该方法应用于皮肤恶性病变分类任务（补充实验包括胸部X光片和自然图像），通过生成与不同视觉特征依赖相关的假设，并通过手动干预进行验证。
- Result: 研究发现大型多模态模型在不同人口统计子组间存在意外的性能差距。VCR方法成功识别了模型依赖的视觉概念，并通过手动干预验证了这些假设。
- Conclusion: VCR方法能够有效审计大型多模态模型在医疗任务中的行为，识别模型依赖的视觉概念和性能差距，为提高模型在安全关键领域的可靠性提供了工具。


### [6] [CLEAR-HPV: Interpretable Concept Discovery for HPV-Associated Morphology in Whole-Slide Histology](https://arxiv.org/abs/2602.05126)
*Weiyi Qin,Yingci Liu-Swetz,Shiwei Tan,Hao Wang*

Main category: cs.CV

TL;DR: CLEAR-HPV是一个用于HPV相关全切片组织病理学的概念级可解释注意力引导框架，通过注意力机制在无概念标签的情况下自动发现形态学概念，将高维特征空间压缩为10个可解释概念，同时保持预测性能。

- Motivation: 虽然基于注意力的多实例学习在HPV相关全切片组织病理学的切片级预测中表现出色，但其形态学可解释性有限。现有方法难以提供概念级别的解释，需要概念标签进行训练，这限制了其在临床实践中的应用。
- Method: CLEAR-HPV框架通过注意力机制重构MIL潜在空间，在注意力加权的潜在空间中自动发现角质化、基底样和基质等形态学概念，无需训练时的概念标签。该方法生成空间概念图，并使用紧凑的概念分数向量表示每个切片，将高维特征空间（如1536维）压缩为仅10个可解释概念。
- Result: CLEAR-HPV在TCGA-HNSCC、TCGA-CESC和CPTAC-HNSCC数据集上表现出一致的泛化能力。其概念分数向量保留了原始MIL嵌入的预测信息，同时实现了高维特征空间到可解释概念的压缩，提供了紧凑的概念级可解释性。
- Conclusion: CLEAR-HPV为基于注意力的全切片组织病理学MIL模型提供了一个通用的、与主干网络无关的框架，实现了概念级别的可解释性，有助于HPV相关癌症的预后和治疗反应评估。


### [7] [ARGaze: Autoregressive Transformers for Online Egocentric Gaze Estimation](https://arxiv.org/abs/2602.05132)
*Jia Li,Wenjie Zhao,Shijian Deng,Bolin Lai,Yuheng Wu,RUijia Chen,Jon E. Froehlich,Yuhang Zhao,Yapeng Tian*

Main category: cs.CV

TL;DR: ARGaze：一种基于自回归解码的在线第一人称视线估计方法，将视线预测重新定义为序列预测任务，利用当前视觉特征和最近视线目标的固定长度上下文窗口，在多个基准测试中达到SOTA性能。

- Motivation: 在线第一人称视线估计对AR和辅助技术至关重要，但缺乏明确的头部或眼睛信号，只能从稀疏的间接线索（如手-物交互和显著场景内容）推断视觉注意力。研究发现视线在目标导向活动中具有强时间连续性，最近的视线位置为预测下一时刻视线提供了有力先验。
- Method: ARGaze将视线估计重新定义为序列预测任务：在每个时间步，Transformer解码器基于（1）当前视觉特征和（2）最近视线目标估计的固定长度"视线上下文窗口"来预测当前视线。这种设计强制因果性并支持有界资源流式推理。
- Result: 在多个第一人称基准测试的在线评估中实现了最先进的性能。广泛的消融实验验证了自回归建模与有界视线历史对鲁棒预测的关键作用。
- Conclusion: ARGaze通过自回归序列预测框架有效利用了视线的时间连续性，为在线第一人称视线估计提供了新颖且高效的解决方案，在保持因果性和资源效率的同时显著提升了预测性能。


### [8] [AirGlove: Exploring Egocentric 3D Hand Tracking and Appearance Generalization for Sensing Gloves](https://arxiv.org/abs/2602.05159)
*Wenhui Cui,Ziyi Kou,Chuan Qin,Ergys Ristani,Li Guan*

Main category: cs.CV

TL;DR: AirGlove：通过有限数据将现有手套表示泛化到新手套设计，显著提升视觉手部追踪在传感手套上的性能

- Motivation: 传感手套在遥操作和机器人策略学习中很重要，但现有方法存在限制：传感器追踪受信号质量和校准影响，而基于视觉的方法在裸手上表现良好但在手套上性能未充分探索
- Method: 提出AirGlove方法，利用现有手套数据，通过有限数据将学习到的手套表示泛化到新手套设计，解决裸手模型与手套设计之间的外观差距问题
- Result: 实验表明，AirGlove能有效将手部姿态模型泛化到新手套设计，相比其他方案获得显著性能提升
- Conclusion: AirGlove通过泛化手套表示解决了视觉手部追踪在传感手套上的性能下降问题，为手套手部追踪提供了有效解决方案


### [9] [SHaSaM: Submodular Hard Sample Mining for Fair Facial Attribute Recognition](https://arxiv.org/abs/2602.05162)
*Anay Majee,Rishabh Iyer*

Main category: cs.CV

TL;DR: SHaSaM提出了一种基于子模优化的两阶段方法，通过挖掘难样本和组合损失函数来减少敏感属性对模型预测的影响，在提升公平性的同时保持性能。

- Motivation: 深度神经网络容易从标注数据中继承社会人口统计偏见，导致不公平预测。现有方法容易受到属性组间数据不平衡的影响，无意中强调敏感属性，反而加剧不公平性和性能下降。
- Method: 提出SHaSaM（子模难样本挖掘）方法，包含两个阶段：1) SHaSaM-MINE：使用子模子集选择策略挖掘难正负样本，缓解数据不平衡；2) SHaSaM-LEARN：基于子模条件互信息设计组合损失函数，最大化目标类别决策边界同时最小化敏感属性影响。
- Result: 在CelebA和UTKFace数据集上的实验表明，SHaSaM在模型公平性（Equalized Odds）上提升达2.7分，准确率提升3.5%，且训练轮次更少，达到最先进水平。
- Conclusion: SHaSaM通过统一的子模优化框架，有效限制模型学习与敏感属性相关的特征，在显著提升公平性的同时不牺牲性能，为解决深度学习的公平性问题提供了新思路。


### [10] [LOBSTgER-enhance: an underwater image enhancement pipeline](https://arxiv.org/abs/2602.05163)
*Andreas Mentzelopoulos,Keith Ellenbogen*

Main category: cs.CV

TL;DR: 提出基于扩散模型的图像修复方法，用于逆转水下摄影中的对比度降低、空间模糊和波长相关色彩失真问题

- Motivation: 水下摄影面临对比度降低、空间模糊和波长相关色彩失真等固有挑战，这些问题会掩盖海洋生物的活力，环保摄影师通常需要复杂的后期处理流程来纠正这些失真
- Method: 开发图像到图像处理流程，通过引入合成退化管道，使用基于扩散的生成方法学习逆转水下退化效果。在Keith Ellenbogen的约2.5k张高质量环保摄影图像数据集上进行训练和评估
- Result: 该方法在合成512x768图像时实现了高感知一致性和强泛化能力，使用约1100万参数的模型在约2500张图像上从头训练
- Conclusion: 提出的基于扩散模型的方法能有效逆转水下摄影退化问题，为环保摄影师提供高效的图像修复解决方案


### [11] [ShapePuri: Shape Guided and Appearance Generalized Adversarial Purification](https://arxiv.org/abs/2602.05175)
*Zhe Li,Bernhard Kainz*

Main category: cs.CV

TL;DR: ShapePuri：通过形状引导的净化框架提升对抗鲁棒性，首次在AutoAttack基准上突破80%鲁棒准确率

- Motivation: 深度神经网络在视觉识别中表现出色，但对人类不可察觉的对抗攻击仍然脆弱。现有的对抗训练和净化方法虽然取得进展，但基于扩散的净化通常涉及高计算成本和信息损失。
- Method: 提出ShapePuri防御框架，通过将模型表示与稳定的结构不变性对齐来增强鲁棒性。包含两个组件：1) Shape Encoding Module (SEM)：通过有符号距离函数(SDF)提供密集几何指导；2) Global Appearance Debiasing (GAD)：通过随机变换减轻外观偏差。
- Result: 在AutoAttack协议下，ShapePuri达到84.06%的干净准确率和81.64%的鲁棒准确率，成为首个在该基准上突破80%阈值的防御框架。
- Conclusion: 该方法提供了可扩展且高效的对抗防御，在推理过程中保持预测稳定性，无需辅助模块或额外计算成本。


### [12] [PoseGaussian: Pose-Driven Novel View Synthesis for Robust 3D Human Reconstruction](https://arxiv.org/abs/2602.05190)
*Ju Shen,Chen Chen,Tam V. Nguyen,Vijayan K. Asari*

Main category: cs.CV

TL;DR: PoseGaussian：一个基于姿态引导的高斯泼溅框架，用于高保真人体新视角合成，通过双重姿态利用实现几何优化和时间一致性，达到实时100FPS渲染和SOTA性能。

- Motivation: 现有方法通常只将人体姿态作为条件或用于变形，未能充分利用姿态信息来应对动态人体场景中的挑战，如关节运动和严重自遮挡。
- Method: 提出姿态引导的高斯泼溅框架，姿态发挥双重作用：1) 作为结构先验与颜色编码器融合以优化深度估计；2) 作为时间线索通过专用姿态编码器增强帧间一致性。构建完全可微分的端到端训练管道。
- Result: 在ZJU-MoCap、THuman2.0和内部数据集上验证，在感知质量和结构准确性方面达到SOTA性能（PSNR 30.86，SSIM 0.979，LPIPS 0.028），同时保持100FPS的实时渲染效率。
- Conclusion: PoseGaussian通过将姿态信号嵌入几何和时间阶段，显著提升了动态人体场景新视角合成的鲁棒性和泛化能力，在保持高斯泼溅效率的同时实现了高质量的实时渲染。


### [13] [GT-SVJ: Generative-Transformer-Based Self-Supervised Video Judge For Efficient Video Reward Modeling](https://arxiv.org/abs/2602.05202)
*Shivanshu Shekhar,Uttaran Bhattacharya,Raghavendra Addanki,Mehrab Tanjim,Somdeb Sarkhel,Tong Zhang*

Main category: cs.CV

TL;DR: 提出Generative-Transformer-based Self-Supervised Video Judge (GTSVJ)，将视频生成模型重新用作奖励模型，通过对比学习训练能量模型来评估视频质量，大幅减少人工标注需求。

- Motivation: 当前基于视觉语言模型(VLM)的视频奖励建模方法难以捕捉细微的时间动态，需要大量人工标注数据。视频生成模型天生具备建模时间结构的能力，但尚未被用于奖励建模。
- Method: 将视频生成模型重新构建为能量模型(EBM)，通过对比学习训练模型区分高质量和低质量视频。设计三种潜在空间扰动方法生成合成负样本：时间切片、特征交换和帧重排，迫使模型学习有意义的时空特征而非表面伪影。
- Result: 在GenAI-Bench和MonteBench上达到最先进性能，仅使用3万个人工标注样本，比现有VLM方法减少6-65倍标注数据。
- Conclusion: 视频生成模型可有效转化为时间感知的奖励模型，通过能量模型框架和精心设计的合成负样本训练，能够精确评估视频质量，大幅降低人工标注成本。


### [14] [Dual-Representation Image Compression at Ultra-Low Bitrates via Explicit Semantics and Implicit Textures](https://arxiv.org/abs/2602.05213)
*Chuqin Zhou,Xiaoyue Ling,Yunuo Chen,Jincheng Dai,Guo Lu,Wenjun Zhang*

Main category: cs.CV

TL;DR: 提出统一框架，在超低码率下通过结合显式和隐式表示来平衡语义保真度和感知真实性，无需训练即可实现最佳率-感知性能。

- Motivation: 现有神经编解码器在超低码率下性能显著下降，而基于预训练模型的生成压缩方法面临语义保真度与感知真实性的权衡困境：显式表示方法保留内容结构但缺乏细节纹理，隐式方法能合成视觉细节但易产生语义漂移。
- Method: 提出统一框架，以训练免费方式整合显式和隐式表示：1）在扩散模型中条件化显式高层语义；2）使用反向信道编码隐式传递细粒度细节；3）引入可插拔编码器，通过调制隐式信息灵活控制失真-感知权衡。
- Result: 在Kodak、DIV2K和CLIC2020数据集上实现最先进的率-感知性能，DISTS BD-Rate分别超越DiffC方法29.92%、19.33%和20.89%。
- Conclusion: 通过统一显式和隐式表示，在超低码率下有效解决了语义保真度与感知真实性的权衡问题，实现了优异的压缩性能。


### [15] [E.M.Ground: A Temporal Grounding Vid-LLM with Holistic Event Perception and Matching](https://arxiv.org/abs/2602.05215)
*Jiahao Nie,Wenbin An,Gongjie Zhang,Yicheng Xu,Yap-Peng Tan,Alex C. Kot,Shijian Lu*

Main category: cs.CV

TL;DR: E.M.Ground：一种新颖的视频大语言模型，通过事件标记、平滑处理和多粒度特征聚合来改进时序视频定位，显著优于现有方法。

- Motivation: 现有视频大语言模型在时序视频定位任务中主要依赖精确时间戳匹配开始和结束帧，未能捕捉事件的语义连续性和完整性，导致定位模糊。
- Method: 提出E.M.Ground模型，引入三个关键技术：1）特殊<event>标记聚合查询事件所有帧信息；2）Savitzky-Golay平滑减少时间戳相似度噪声；3）多粒度帧特征聚合增强匹配可靠性和时序理解。
- Result: 在基准数据集上的大量实验表明，E.M.Ground始终显著优于最先进的视频大语言模型。
- Conclusion: E.M.Ground通过整体连贯的事件感知方法有效解决了时序视频定位中的语义连续性问题，实现了更准确的视频事件定位。


### [16] [Cross-Domain Few-Shot Segmentation via Multi-view Progressive Adaptation](https://arxiv.org/abs/2602.05217)
*Jiahao Nie,Guanqiao Fu,Wenbin An,Yap-Peng Tan,Alex C. Kot,Shijian Lu*

Main category: cs.CV

TL;DR: 提出多视角渐进适应方法，通过数据增强和策略优化提升跨域小样本分割性能

- Motivation: 现有跨域小样本分割方法在目标域中性能受限，源域训练的模型在目标域中初始小样本能力弱，加上显著的领域差距，严重阻碍了目标样本的有效利用和适应过程
- Method: 提出多视角渐进适应方法，包含两个核心组件：1) 混合渐进增强：通过累积强数据增强生成更多样化和复杂的视图；2) 双链多视角预测：通过顺序和并行学习路径在广泛监督下充分利用这些渐进复杂视图
- Result: 在跨域小样本分割任务中，MPA方法显著优于现有最先进方法，性能提升达+7.0%
- Conclusion: 通过从数据和策略两个角度渐进适应小样本能力到目标域，MPA方法能够有效克服领域差距，实现鲁棒且准确的跨域适应


### [17] [Boosting SAM for Cross-Domain Few-Shot Segmentation via Conditional Point Sparsification](https://arxiv.org/abs/2602.05218)
*Jiahao Nie,Yun Xing,Wenbin An,Qingsong Zhao,Jiawei Shao,Yap-Peng Tan,Alex C. Kot,Shijian Lu,Xuelong Li*

Main category: cs.CV

TL;DR: 提出Conditional Point Sparsification (CPS)方法，通过自适应稀疏化密集匹配点来提升SAM在跨域少样本分割中的性能。

- Motivation: 现有基于SAM的训练免费少样本分割方法依赖密集点匹配，但在跨域场景（如医疗、卫星图像）中表现不佳，主要原因是域偏移破坏了SAM学习的点-图像交互，且点密度在这种条件下起关键作用。
- Method: 提出Conditional Point Sparsification (CPS)方法，这是一种训练免费的方法，利用参考图像的真实掩码作为可靠指导，自适应地稀疏化密集匹配点，从而更准确地引导SAM在跨域图像中的交互。
- Result: 大量实验表明，CPS在多种跨域少样本分割数据集上优于现有的基于SAM的训练免费方法。
- Conclusion: CPS通过自适应点稀疏化有效解决了SAM在跨域少样本分割中的性能问题，为训练免费方法在跨域场景中的应用提供了有效解决方案。


### [18] [PatchFlow: Leveraging a Flow-Based Model with Patch Features](https://arxiv.org/abs/2602.05238)
*Boxiang Zhang,Baijian Yang,Xiaoming Wang,Corey Vian*

Main category: cs.CV

TL;DR: 提出一种结合局部邻域感知补丁特征与归一化流模型的压铸表面缺陷检测方法，通过适配器模块弥合预训练特征提取器与工业图像之间的差距，在多个数据集上实现SOTA性能

- Motivation: 压铸在工业中至关重要，但表面缺陷严重影响质量控制。传统方法依赖人工检测，效率低且易出错。计算机视觉技术虽被探索用于自动化缺陷检测，但现有方法在预训练特征与工业图像之间存在差距，需要更高效准确的解决方案
- Method: 结合局部邻域感知补丁特征与归一化流模型，引入适配器模块弥合通用预训练特征提取器与工业产品图像之间的差距，实现无需异常样本训练的无监督异常检测
- Result: 在MVTec AD数据集上达到99.28%的图像级AUROC，错误率降低20%；在VisA数据集上达到96.48%的图像级AUROC，错误率降低28.2%；在专有压铸数据集上达到95.77%的异常检测准确率
- Conclusion: 该方法展示了计算机视觉和深度学习技术在提升压铸行业检测能力方面的潜力，通过创新的特征适配机制实现了高效准确的无监督异常检测


### [19] [Active Label Cleaning for Reliable Detection of Electron Dense Deposits in Transmission Electron Microscopy Images](https://arxiv.org/abs/2602.05250)
*Jieyun Tan,Shuo Liu,Guibin Zhang,Ziqi Li,Jian Geng,Lei Zhang,Lei Cao*

Main category: cs.CV

TL;DR: 提出一种主动标签清洗方法，通过主动学习选择最有价值的噪声样本进行专家重新标注，有效降低标注成本并提升模型性能

- Motivation: 肾小球疾病中电子致密沉积物（EDD）的自动检测面临高质量标注数据稀缺的挑战。众包虽能降低标注成本，但会引入标签噪声，需要有效的方法来清洗噪声标签
- Method: 提出主动标签清洗方法：1）使用主动学习选择最有价值的噪声样本进行专家重新标注；2）构建高精度清洗模型；3）标签选择模块利用众包标签与模型预测之间的差异进行样本选择和实例级噪声分级
- Result: 在私有数据集上达到67.18% AP₅₀，比直接在噪声标签上训练提升18.83%。性能达到完全专家标注的95.79%，同时减少73.30%的标注成本
- Conclusion: 该方法为在有限专家资源下开发可靠的医疗AI提供了实用且经济高效的解决方案，有效平衡了标注成本与模型性能


### [20] [RFM-Pose:Reinforcement-Guided Flow Matching for Fast Category-Level 6D Pose Estimation](https://arxiv.org/abs/2602.05257)
*Diya He,Qingchen Liu,Cong Zhang,Jiahu Qin*

Main category: cs.CV

TL;DR: RFM-Pose：基于流匹配和强化学习的高效类别级6D物体姿态估计框架，显著降低计算成本

- Motivation: 当前基于分数的生成模型虽然解决了旋转对称性模糊问题，但采样成本高导致效率受限。需要一种既能保持性能又能显著降低计算成本的姿态估计方法。
- Method: 1) 采用流匹配生成模型，沿最优传输路径从简单先验分布生成姿态候选；2) 将流匹配采样过程建模为马尔可夫决策过程，应用近端策略优化微调采样策略；3) 将流场解释为可学习策略，映射估计器为价值网络，在强化学习框架内联合优化姿态生成和假设评分。
- Result: 在REAL275基准测试中，RFM-Pose在保持良好性能的同时显著降低了计算成本。该方法还可轻松适配到物体姿态跟踪任务，并在该设置下获得有竞争力的结果。
- Conclusion: RFM-Pose通过流匹配和强化学习的结合，实现了高效且准确的类别级6D物体姿态估计，为虚拟现实和具身智能中的物体交互提供了实用解决方案。


### [21] [ReGLA: Efficient Receptive-Field Modeling with Gated Linear Attention Network](https://arxiv.org/abs/2602.05262)
*Junzhou Li,Manqi Zhao,Yilin Gao,Zhiheng Yu,Yin Li,Dongsheng Jiang,Li Xiao*

Main category: cs.CV

TL;DR: ReGLA是一个轻量级混合网络，结合高效卷积和ReLU门控线性注意力，在保持低延迟的同时实现高精度，特别适用于高分辨率图像任务。

- Motivation: 解决轻量级模型（特别是Transformer架构）在高分辨率图像上平衡精度和延迟的挑战，这些模型通常存在延迟过高的问题。
- Method: 1. ELRF模块：增强卷积效率同时保持大感受野；2. RGMA模块：保持线性复杂度同时增强局部特征表示；3. 多教师蒸馏策略提升下游任务性能。
- Result: ReGLA-M在ImageNet-1K 224px上达到80.85% Top-1精度，512px延迟仅4.98ms。在下游任务中，相比类似规模的iFormer模型，COCO目标检测提升3.1% AP，ADE20K语义分割提升3.6% mIoU。
- Conclusion: ReGLA通过创新的混合架构设计，在高分辨率视觉应用中实现了精度和延迟的良好平衡，成为该领域的先进解决方案。


### [22] [Unlocking Prototype Potential: An Efficient Tuning Framework for Few-Shot Class-Incremental Learning](https://arxiv.org/abs/2602.05271)
*Shengqin Jiang,Xiaoran Feng,Yuankai Qi,Haokui Zhang,Renlong Hang,Qingshan Liu,Lina Yao,Quan Z. Sheng,Ming-Hsuan Yang*

Main category: cs.CV

TL;DR: 提出原型微调框架，通过冻结特征提取器并优化原型来改进少样本类增量学习，使用双校准方法提升原型判别能力。

- Motivation: 传统FSCIL方法使用冻结预训练特征提取器生成静态类原型，存在表示偏差问题。现有提示调优方法在数据极度稀缺下，模型吸收新信息和增强全局判别能力有限。本文认为FSCIL主要挑战不是特征获取，而是在静态高质量特征空间中优化决策区域。
- Method: 提出原型微调框架，将静态质心演变为动态可学习组件。采用双校准方法：类特定偏移和任务感知偏移，协同工作提升增量类原型的判别能力。
- Result: 在多个基准测试中取得优越性能，同时只需要极少的可学习参数。
- Conclusion: 通过冻结特征提取器并微调原型的新视角，有效解决了FSCIL中数据稀缺下的知识保留和新类学习问题，提供了一种高效的原型优化方法。


### [23] [Magic-MM-Embedding: Towards Visual-Token-Efficient Universal Multimodal Embedding with MLLMs](https://arxiv.org/abs/2602.05275)
*Qi Li,Yanzhe Zhao,Yongxin Zhou,Yameng Wang,Yandong Yang,Yuanjia Zhou,Jue Wang,Zuojian Wang,Jinxiang Liu*

Main category: cs.CV

TL;DR: Magic-MM-Embedding：一种高效的多模态嵌入模型，通过视觉令牌压缩和多阶段训练策略，在保持SOTA性能的同时大幅降低计算成本

- Motivation: 当前多模态大语言模型在通用多模态检索中表现出色，但处理大量视觉令牌时计算成本过高，限制了实际应用。需要开发既高效又高性能的解决方案。
- Method: 提出Magic-MM-Embedding模型系列，基于两大支柱：(1) 高效MLLM架构，包含视觉令牌压缩技术以减少推理延迟和内存占用；(2) 多阶段渐进训练策略，包括：继续预训练恢复能力 → 大规模对比预训练和困难负样本挖掘增强判别力 → MLLM-as-a-Judge指导的任务感知微调。
- Result: 综合实验表明，该模型在性能上大幅超越现有方法，同时在推理效率上更高。
- Conclusion: Magic-MM-Embedding成功解决了MLLMs在通用多模态检索中的效率瓶颈问题，实现了高性能与高效率的平衡，为实际应用提供了可行的解决方案。


### [24] [Fast-SAM3D: 3Dfy Anything in Images but Faster](https://arxiv.org/abs/2602.05293)
*Weilun Feng,Mingqiang Wu,Zhiliang Chen,Chuanguang Yang,Haotong Qin,Yuqi Li,Xiaokun Liu,Guoxin Fan,Zhulin An,Libo Huang,Yulun Zhang,Michele Magno,Yongjun Xu*

Main category: cs.CV

TL;DR: Fast-SAM3D：通过异构感知的动态计算分配，显著加速SAM3D的3D重建推理速度，实现2.67倍加速且保真度损失可忽略。

- Motivation: SAM3D虽然能处理复杂场景的开放世界3D重建，但其推理延迟过高阻碍了实际部署。现有通用加速策略在该场景下表现脆弱，主要原因是忽视了pipeline内在的多层次异构性。
- Method: 提出训练免费的Fast-SAM3D框架，包含三个异构感知机制：1）模态感知步长缓存，解耦结构演化与布局更新；2）联合时空令牌雕刻，聚焦高熵区域细化；3）频谱感知令牌聚合，自适应解码分辨率。
- Result: 实验表明Fast-SAM3D实现最高2.67倍端到端加速，保真度损失可忽略，为高效单视图3D生成建立了新的帕累托前沿。
- Conclusion: 通过系统分析SAM3D推理动态并针对性解决其异构性问题，Fast-SAM3D显著提升了3D重建效率，为实际部署提供了可行方案。


### [25] [FlashBlock: Attention Caching for Efficient Long-Context Block Diffusion](https://arxiv.org/abs/2602.05305)
*Zhuokun Chen,Jianfei Cai,Bohan Zhuang*

Main category: cs.CV

TL;DR: FlashBlock通过重用块外注意力输出来减少扩散模型中的重复计算，提高生成长内容时的推理效率

- Motivation: 块扩散虽然通过KV缓存和块式因果推理提高了推理效率，但在长上下文场景中，仍然存在对增长的KV缓存重复计算注意力带来的显著开销。研究发现块扩散中块外注意力在扩散步骤间保持稳定，而块内注意力变化显著，这为优化提供了机会。
- Method: 提出FlashBlock机制，利用块外注意力在扩散步骤间保持稳定的特性，缓存并重用这些稳定的注意力输出，从而减少注意力计算和KV缓存访问，同时不改变扩散过程。该方法与稀疏注意力正交，可作为补充的残差重用策略。
- Result: 在扩散语言模型和视频生成任务上的实验表明，FlashBlock实现了最高1.44倍的token吞吐量提升，注意力时间减少最高1.6倍，且对生成质量影响可忽略。
- Conclusion: FlashBlock通过重用稳定的块外注意力输出，有效减少了扩散模型生成长内容时的计算开销，显著提高了推理效率，同时保持了生成质量。


### [26] [Wid3R: Wide Field-of-View 3D Reconstruction via Camera Model Conditioning](https://arxiv.org/abs/2602.05321)
*Dongki Jung,Jaehoon Choi,Adil Qureshi,Somi Jeong,Dinesh Manocha,Suyong Yeon*

Main category: cs.CV

TL;DR: Wid3R是一个支持广角相机模型的视觉几何重建前馈神经网络，能够处理鱼眼和全景图像，无需校准和去畸变

- Motivation: 现有方法通常假设输入图像经过校正或使用针孔相机拍摄，限制了在真实世界鱼眼和全景相机场景中的应用，需要复杂的校准和去畸变处理
- Method: 使用球谐函数的射线表示和网络中的新型相机模型标记，实现畸变感知的3D重建，支持广角相机类型
- Result: 在Stanford2D3D上实现了高达+77.33的改进，表现出强大的零样本鲁棒性，是首个支持从360度图像直接进行前馈3D重建的多视图基础模型
- Conclusion: Wid3R是一个通用的多视图3D估计方法，能够建模广角相机类型，在真实世界场景中具有更广泛的应用前景


### [27] [MTPano: Multi-Task Panoramic Scene Understanding via Label-Free Integration of Dense Prediction Priors](https://arxiv.org/abs/2602.05330)
*Jingdong Zhang,Xiaohang Zhan,Lingzhi Zhang,Yizhou Wang,Zhengming Yu,Jionghao Wang,Wenping Wang,Xin Li*

Main category: cs.CV

TL;DR: MTPano是一个通过无标签训练流程建立的多任务全景基础模型，利用透视先验生成伪标签，通过双分支网络处理旋转不变/变任务，在多个基准测试中达到SOTA性能。

- Motivation: 全景场景理解面临高分辨率多任务标注稀缺的挑战，现有透视基础模型直接适应全景域会因几何畸变和坐标系差异而失败，且球面空间中密集预测任务间的关系未被充分探索。
- Method: 1) 利用透视密集先验生成伪标签：将全景图投影为透视块，用现成基础模型生成无领域差距的伪标签，再重投影作为监督；2) 全景双桥网络：将任务分为旋转不变（深度、分割）和旋转变（表面法线）组，通过几何感知调制层分离特征流；3) ERP令牌混合器和双分支BridgeNet处理畸变，配合梯度截断促进跨任务信息共享；4) 引入辅助任务（图像梯度、点图等）丰富跨任务学习。
- Result: 在多个基准测试中达到最先进性能，与任务特定的全景专家基础模型相比具有竞争力。
- Conclusion: MTPano通过无标签训练流程和创新的网络架构，成功解决了全景场景理解中的数据稀缺和任务干扰问题，为多任务全景基础模型提供了有效解决方案。


### [28] [Consistency-Preserving Concept Erasure via Unsafe-Safe Pairing and Directional Fisher-weighted Adaptation](https://arxiv.org/abs/2602.05339)
*Yongwoo Kim,Sungmin Cha,Hyunsoo Kim,Jaewon Lee,Donghyun Kim*

Main category: cs.CV

TL;DR: PAIR框架通过不安全-安全配对数据，将概念擦除从简单移除重构为保持一致的语义重对齐，在有效擦除有害概念的同时保留结构和语义一致性。

- Motivation: 现有概念擦除方法主要关注移除不安全概念，但缺乏对相应安全替代的指导，导致原始生成与擦除后生成之间的结构和语义一致性难以保持。
- Method: 提出PAIR框架：1) 从不安全输入生成结构语义保真的安全对应物，形成配对数据；2) 配对语义重对齐目标，将目标概念映射到语义对齐的安全锚点；3) Fisher加权初始化DoRA，使用配对数据初始化参数高效的低秩适应矩阵。
- Result: 大量实验表明，该方法显著优于现有最先进基线，在保持结构完整性、语义连贯性和生成质量的同时，实现了有效的概念擦除。
- Conclusion: PAIR框架通过不安全-安全配对数据，将概念擦除从简单移除重构为保持一致的语义重对齐，实现了细粒度擦除，在移除目标概念的同时保持整体语义一致性。


### [29] [Learning with Adaptive Prototype Manifolds for Out-of-Distribution Detection](https://arxiv.org/abs/2602.05349)
*Ningkang Peng,JiuTao Zhou,Yuhao Zhang,Xiaoqian Peng,Qianfeng Yu,Linjing Qian,Tingyu Lu,Yi Chen,Yanhui Gu*

Main category: cs.CV

TL;DR: APEX提出自适应原型框架解决OOD检测中静态同质性假设和学习-推理断开两大问题，通过自适应原型流形和后验感知OOD评分实现SOTA性能。

- Motivation: 现有基于原型的OOD检测方法存在两个根本性缺陷：1) 静态同质性假设（所有类别使用固定的表示资源）；2) 学习-推理断开（推理时丢弃丰富的原型质量知识）。这些缺陷限制了模型的能力和性能。
- Method: 提出APEX框架，采用两阶段修复过程优化学习特征流形：1) 自适应原型流形(APM)，利用最小描述长度原则自动确定每个类别的最优原型复杂度K_c*，解决原型碰撞问题；2) 后验感知OOD评分(PAOS)，量化原型质量（内聚性和分离性）来弥合学习-推理断开。
- Result: 在CIFAR-100等基准测试上的综合实验验证了方法的优越性，APEX实现了新的最先进性能。
- Conclusion: APEX通过解决原型方法中的两个根本缺陷，显著提升了OOD检测性能，为机器学习模型在现实世界中的安全部署提供了更有效的解决方案。


### [30] [Multimodal Latent Reasoning via Hierarchical Visual Cues Injection](https://arxiv.org/abs/2602.05359)
*Yiming Zhang,Qiangyu Yan,Borui Jiang,Kai Han*

Main category: cs.CV

TL;DR: 提出HIVE框架，通过分层视觉线索注入实现多模态潜在推理，避免依赖显式文本链式思维，提升复杂场景理解能力

- Motivation: 当前多模态大语言模型采用"快速思考"范式，依赖端到端生成或显式语言链式思维，存在效率低、冗长和易产生幻觉的问题。需要更稳健的推理机制
- Method: HIVE框架：递归扩展transformer块创建内部循环进行迭代推理优化，将分层视觉线索（从全局场景到细粒度区域细节）注入到潜在表示中，在潜在空间中进行多步推理
- Result: 实验表明：结合视觉知识时测试时间缩放有效，分层信息集成显著增强模型对复杂场景的理解能力
- Conclusion: 提出了一种新颖的多模态潜在推理框架，通过分层视觉线索注入实现"慢思考"推理，在潜在空间中整合多模态信号，提升推理的稳健性和准确性


### [31] [Breaking Semantic Hegemony: Decoupling Principal and Residual Subspaces for Generalized OOD Detection](https://arxiv.org/abs/2602.05360)
*Ningkang Peng,Xiaoqian Peng,Yuhao Zhang,Qianfeng Yu,Feng Xing,Peirong Ma,Xichen Yang,Yi Chen,Tingyu Lu,Yanhui Gu*

Main category: cs.CV

TL;DR: 论文揭示了OOD检测中的"简单性悖论"：现有SOTA模型能识别语义复杂的OOD样本，但对结构简单或高频噪声样本存在"几何盲区"，并提出D-KNN框架通过正交分解解决该问题。

- Motivation: 现有基于特征的OOD检测方法存在"简单性悖论"：模型对语义复杂的OOD样本敏感，但对结构简单或高频噪声样本存在"几何盲区"。作者将这种现象归因于深度特征空间中的"语义霸权"，并通过神经坍缩理论揭示其数学本质。
- Method: 提出D-KNN框架：1）使用正交分解将语义成分与结构残差显式分离；2）引入双空间校准机制重新激活模型对弱残差信号的敏感性；3）无需训练，即插即用。
- Result: 在CIFAR和ImageNet基准测试中达到新的SOTA性能：1）解决简单性悖论时，将FPR95从31.3%降至2.3%；2）处理高斯噪声等传感器故障时，将AUROC从79.7%提升至94.9%。
- Conclusion: D-KNN框架通过几何解耦有效打破了特征空间中的语义霸权，解决了OOD检测中的简单性悖论，显著提升了模型对结构简单样本和高频噪声的检测能力。


### [32] [Imagine a City: CityGenAgent for Procedural 3D City Generation](https://arxiv.org/abs/2602.05362)
*Zishan Liu,Zecong Tang,RuoCheng Wu,Xinzhe Zheng,Jingyu Hu,Ka-Hei Hui,Haoran Xie,Bo Dai,Zhengzhe Liu*

Main category: cs.CV

TL;DR: CityGenAgent：基于自然语言的层次化程序化3D城市生成框架，通过分解为区块程序和建筑程序，结合监督微调和强化学习，实现高质量、可控的城市生成与编辑。

- Motivation: 现有3D城市生成方法在高质量资产创建、可控性和可操作性方面存在不足，需要更自然、可控的生成方案来满足自动驾驶、虚拟现实等应用需求。
- Method: 将城市生成分解为区块程序和建筑程序两个可解释组件，采用两阶段学习策略：1）监督微调确保程序的结构正确性和语义对齐；2）强化学习通过空间对齐奖励和视觉一致性奖励提升空间推理和文本-视觉对齐能力。
- Result: 综合评估显示，CityGenAgent在语义对齐、视觉质量和可控性方面优于现有方法，支持自然语言编辑和操作，为可扩展的3D城市生成奠定了坚实基础。
- Conclusion: CityGenAgent通过层次化程序化生成和两阶段学习策略，实现了高质量、可控的3D城市生成，为交互式3D城市创建提供了有效的解决方案。


### [33] [SAIL: Self-Amplified Iterative Learning for Diffusion Model Alignment with Minimal Human Feedback](https://arxiv.org/abs/2602.05380)
*Xiaoxuan He,Siming Fu,Wanli Li,Zhiyuan Li,Dacheng Yin,Kang Rong,Fengyun Rao,Bo Zhang*

Main category: cs.CV

TL;DR: SAIL是一个自增强迭代学习框架，仅需少量人工标注偏好对，通过让扩散模型自我生成样本、自我标注偏好并迭代优化，实现高效对齐，仅需现有方法6%的偏好数据。

- Motivation: 当奖励模型难以获取且大规模偏好数据集收集成本过高时，如何仅用最少人工反馈实现扩散模型与人类偏好的对齐成为一个关键挑战。本文探索是否能够通过挖掘扩散模型自身潜力，无需辅助奖励模型即可实现有效对齐。
- Method: 提出SAIL框架：从少量人工标注偏好对开始，采用闭环方式让模型逐步生成多样化样本，基于其演化理解自我标注偏好，并利用自增强数据集进行自我精炼。引入排名偏好混合策略平衡探索与初始人类先验的遵循，防止灾难性遗忘。
- Result: 在多个基准测试中，SAIL一致优于最先进方法，同时仅需现有方法6%的偏好数据。实验表明扩散模型具有显著的自改进能力，当被适当利用时，可以有效替代大规模人工标注和外部奖励模型。
- Conclusion: 扩散模型拥有强大的自我改进能力，SAIL框架通过最小化人工反馈实现了高效对齐，揭示了扩散模型自身潜力可以替代传统依赖大规模标注和外部奖励模型的方法。


### [34] [VRIQ: Benchmarking and Analyzing Visual-Reasoning IQ of VLMs](https://arxiv.org/abs/2602.05382)
*Tina Khezresmaeilzadeh,Jike Zhong,Konstantinos Psounis*

Main category: cs.CV

TL;DR: VRIQ基准测试显示当前视觉语言模型在视觉推理方面表现不佳，抽象谜题任务准确率仅28%，自然图像任务45%，主要失败原因是感知限制而非推理能力不足。

- Motivation: 随着视觉语言模型的发展，需要评估它们是否能可靠地进行非语言推理。作者旨在创建系统化的基准来分析和诊断VLMs在视觉推理方面的能力与局限。
- Method: 引入VRIQ基准，包含抽象谜题风格和自然图像推理两类任务。使用工具增强推理进行评估，并设计诊断探针来分离感知和推理失败的原因，细分为形状、计数、位置、3D/深度等具体感知类别。
- Result: 模型在抽象谜题上表现接近随机（28%准确率），自然图像任务稍好（45%）。工具增强推理改进有限。诊断分析显示56%失败源于纯感知问题，43%源于感知和推理共同问题，仅1%源于纯推理问题。
- Conclusion: 当前VLMs即使是增强版，在抽象推理上仍不可靠，主要瓶颈是感知限制而非推理能力。VRIQ基准为改进多模态系统的视觉推理提供了原则性基础。


### [35] [Dolphin-v2: Universal Document Parsing via Scalable Anchor Prompting](https://arxiv.org/abs/2602.05384)
*Hao Feng,Wei Shi,Ke Zhang,Xiang Fei,Lei Liao,Dingkang Yang,Yongkun Du,Xuecheng Wu,Jingqun Tang,Yang Liu,Hong Chen,Can Huang*

Main category: cs.CV

TL;DR: Dolphin-v2 是一个两阶段文档图像解析模型，通过联合文档类型分类和布局分析，采用混合解析策略（整体页面解析处理拍摄文档，元素级并行解析处理数字文档），显著提升了文档解析性能。

- Motivation: 当前文档解析领域存在两个主要问题：1）模型碎片化，用户需要面对复杂的模型选择，系统可扩展性受限；2）现有两阶段方法依赖轴对齐边界框进行布局检测，无法有效处理扭曲或拍摄的文档。
- Method: 两阶段方法：第一阶段联合进行文档类型分类（数字文档 vs 拍摄文档）和布局分析，对数字文档进行更细粒度的元素检测和阅读顺序预测；第二阶段采用混合解析策略：拍摄文档整体页面解析处理几何扭曲，数字文档基于检测到的布局锚点进行元素级并行解析。
- Result: 在 DocPTBench、OmniDocBench 和自建 RealDoc-160 基准测试中，Dolphin-v2 相比原始 Dolphin 有显著改进：在挑战性的 OmniDocBench 上整体提升 +14.78 分，拍摄文档错误减少 91%，同时通过并行处理保持高效推理。
- Conclusion: Dolphin-v2 通过引入文档类型感知的混合解析策略，解决了现有文档解析系统在处理拍摄文档和数字文档时的局限性，在保持高效推理的同时显著提升了性能，特别是在拍摄文档处理方面取得了突破性进展。


### [36] [Parallel Swin Transformer-Enhanced 3D MRI-to-CT Synthesis for MRI-Only Radiotherapy Planning](https://arxiv.org/abs/2602.05387)
*Zolnamar Dorjsembe,Hung-Yi Chen,Furen Xiao,Hsing-Kuo Pao*

Main category: cs.CV

TL;DR: 提出Parallel Swin Transformer-Enhanced Med2Transformer架构，用于从MRI生成合成CT，解决放疗计划中MRI缺乏电子密度信息的问题，通过双Swin Transformer分支建模局部解剖细节和长距离上下文依赖。

- Motivation: 当前放疗工作流程依赖MRI和CT联合采集，增加了配准不确定性和程序复杂性。MRI缺乏电子密度信息，无法直接用于剂量计算，而合成CT生成面临MRI-CT非线性关系和解剖变异性的挑战。
- Method: 提出3D Parallel Swin Transformer-Enhanced Med2Transformer架构，集成卷积编码与双Swin Transformer分支，建模局部解剖细节和长距离上下文依赖。采用多尺度移位窗口注意力与分层特征聚合提高解剖保真度。
- Result: 在公共和临床数据集上的实验显示，相比基线方法具有更高的图像相似度和改进的几何精度。剂量学评估显示临床可接受的性能，平均靶区剂量误差为1.69%。
- Conclusion: 提出的架构能够有效从MRI生成合成CT，支持MRI-only放疗计划，减少对CT扫描的依赖，提高放疗工作流程的效率和准确性。


### [37] [Dataset Distillation via Relative Distribution Matching and Cognitive Heritage](https://arxiv.org/abs/2602.05391)
*Qianxin Xia,Jiawei Du,Yuhan Zhang,Jielei Wang,Guoming Lu*

Main category: cs.CV

TL;DR: 提出统计流匹配方法，用于数据集蒸馏，通过对齐目标类别中心到非目标类别中心的统计流来优化合成图像，大幅降低计算和内存开销，同时提出分类器继承策略提升性能。

- Motivation: 现有线性梯度匹配方法在数据集蒸馏中存在计算和内存开销大的问题，需要加载数千张真实图像并对合成图像进行多轮可微分增强，导致效率低下。
- Method: 提出统计流匹配框架，通过对齐目标类别中心到非目标类别中心的常数统计流来优化合成图像；同时提出分类器继承策略，重用原始数据集上训练的分类器，仅需轻量级线性投影器。
- Result: 方法性能达到或优于最先进方法，GPU内存使用降低10倍，运行时间缩短4倍；分类器继承策略仅需边际存储即可实现显著性能提升。
- Conclusion: 统计流匹配为数据集蒸馏提供了一种稳定高效的监督学习框架，显著降低了计算和内存开销，同时通过分类器继承策略进一步提升了性能效率。


### [38] [Explainable Pathomics Feature Visualization via Correlation-aware Conditional Feature Editing](https://arxiv.org/abs/2602.05397)
*Yuechen Yang,Junlin Guo,Ruining Deng,Junchao Zhu,Zhengyi Lu,Chongyu Qu,Yanfan Zhu,Xingyi Guo,Yu Wang,Shilin Zhao,Haichun Yang,Yuankai Huo*

Main category: cs.CV

TL;DR: 提出MAD框架，通过VAE学习解耦的潜在空间，在编辑病理特征时保持生物合理性，避免生成伪影

- Motivation: 病理组学特征难以解释，现有扩散模型假设特征独立，但病理特征本质相关，编辑单一特征会偏离生物流形产生伪影
- Method: 提出MAD框架：1) 使用VAE学习解耦的潜在空间；2) 在潜在空间中正则化特征轨迹；3) 用优化后的特征指导条件扩散模型生成高保真图像
- Result: 实验证明MAD能在编辑病理特征时导航特征流形，在条件特征编辑方面优于基线方法，同时保持结构一致性
- Conclusion: MAD框架实现了可控且生物合理的细胞核编辑，解决了病理特征相关性带来的编辑挑战


### [39] [TSBOW: Traffic Surveillance Benchmark for Occluded Vehicles Under Various Weather Conditions](https://arxiv.org/abs/2602.05414)
*Ngoc Doan-Minh Huynh,Duong Nguyen-Ngoc Tran,Long Hoang Pham,Tai Huu-Phuong Tran,Hyung-Joon Jeon,Huy-Hung Nguyen,Duong Khac Vu,Hyung-Min Jeon,Son Hong Phan,Quoc Pham-Nam Ho,Chi Dai Tran,Trinh Le Ba Khanh,Jae Wook Jeon*

Main category: cs.CV

TL;DR: 该研究提出了TSBOW数据集，这是一个针对各种极端天气条件下遮挡车辆检测的交通监控基准数据集，包含超过32小时的真实交通数据和数百万标注帧。

- Motivation: 全球变暖加剧了极端天气事件的频率和严重性，这降低了CCTV信号和视频质量，同时扰乱了交通流，增加了交通事故率。现有数据集通常仅限于轻度雾霾、雨和雪，无法捕捉极端天气条件。
- Method: 研究引入了TSBOW数据集，包含来自人口密集城市区域超过32小时的真实交通数据，包括48,000多个手动标注和320万半标注帧，涵盖八个交通参与者类别。建立了TSBOW的对象检测基准。
- Result: TSBOW数据集突出了遮挡和恶劣天气带来的挑战，其多样的道路类型、尺度和视角使其成为推进智能交通系统的关键资源。数据集已在GitHub上公开。
- Conclusion: 研究结果强调了基于CCTV的交通监控的潜力，为新的研究和应用铺平了道路。TSBOW数据集为在极端天气条件下进行遮挡车辆检测研究提供了重要基准。


### [40] [VMF-GOS: Geometry-guided virtual Outlier Synthesis for Long-Tailed OOD Detection](https://arxiv.org/abs/2602.05415)
*Ningkang Peng,Qianfeng Yu,Yuhao Zhang,Yafei Liu,Xiaoqian Peng,Peirong Ma,Yi Chen,Peiheng Li,Yanhui Gu*

Main category: cs.CV

TL;DR: 提出几何引导虚拟离群值合成(GOS)框架，无需外部数据即可在长尾分布下进行OOD检测，通过vMF分布建模在特征空间低似然环带采样虚拟离群值，结合双粒度语义损失提升检测性能。

- Motivation: 现有OOD检测方法依赖大规模外部数据集进行离群值暴露，但在实际部署中面临数据获取成本高和隐私敏感性问题。长尾分布下尾类样本稀缺导致特征空间决策边界模糊，需要开发不依赖外部数据的高效检测方法。
- Method: 提出几何引导虚拟离群值合成(GOS)策略：1) 使用von Mises-Fisher分布对特征空间统计特性建模；2) 在特征空间低似然环带区域进行方向性采样生成虚拟离群值；3) 引入双粒度语义损失(DGS)，通过对比学习最大化ID特征与合成边界离群值的区分度。
- Result: 在CIFAR-LT等基准测试上的大量实验表明，该方法优于使用外部真实图像的现有最优方法，实现了无需外部数据依赖的优越检测性能。
- Conclusion: 提出的数据无关框架成功消除了对外部数据集的依赖，通过几何引导的虚拟离群值合成和双粒度语义损失，在长尾分布下实现了高效的OOD检测，为实际部署提供了可行的解决方案。


### [41] [Disco: Densely-overlapping Cell Instance Segmentation via Adjacency-aware Collaborative Coloring](https://arxiv.org/abs/2602.05420)
*Rui Sun,Yiwen Yang,Kaiyu Guo,Chen Jiang,Dongli Xu,Zhaonan Liu,Tan Pan,Limei Han,Xue Jiang,Wu Wei,Yuan Cheng*

Main category: cs.CV

TL;DR: 提出Disco框架，通过数据驱动的拓扑标记策略和约束深度学习系统解决密集重叠细胞实例分割问题，基于细胞邻接图色数分析发现真实世界细胞图多为非二部图且包含奇数长度循环。

- Motivation: 现有基于轮廓检测和距离映射的方法在处理复杂密集细胞区域时面临挑战，基于图着色的方法虽提供新范式，但在真实场景中密集重叠和复杂拓扑的有效性尚未验证。
- Method: 提出Disco框架：1) "显式标记"策略将拓扑挑战转化为可学习的分类任务，递归分解细胞图并隔离"冲突集"；2) "隐式消歧"机制通过强制不同实例间的特征差异性解决冲突区域的模糊性。
- Result: 发布大规模数据集GBC-FS 2025，包含高度复杂密集的亚细胞核排列；首次系统分析四个不同数据集的细胞邻接图色数特性，发现大多数真实世界细胞图是非二部图，具有高比例的奇数长度循环（主要是三角形）。
- Conclusion: 简单2-着色理论不足以处理复杂组织，而更高色数模型会导致表示冗余和优化困难；提出的Disco框架通过邻接感知协作着色有效解决密集重叠细胞实例分割问题。


### [42] [NeVStereo: A NeRF-Driven NVS-Stereo Architecture for High-Fidelity 3D Tasks](https://arxiv.org/abs/2602.05423)
*Pengcheng Chen,Yue Hu,Wenhao Li,Nicole M Gunderson,Andrew Feng,Zhenglong Sun,Peter Beerel,Eric J Seibel*

Main category: cs.CV

TL;DR: NeVStereo：一个结合NeRF渲染与立体视觉的联合框架，能够从多视角RGB图像中同时估计相机位姿、多视角深度、新视角合成和表面重建，解决了现有方法在几何一致性和多任务协同方面的不足。

- Motivation: 现有方法存在局限性：前馈系统（如VGGT、pi3）专注于端到端匹配和几何预测，但不输出新视角合成；基于神经渲染的方法（如NeRF）能提供高质量渲染和几何细节，但通常假设固定相机位姿且对位姿误差敏感。目前缺乏一个统一框架能够从随意拍摄的图像中同时提供准确位姿、可靠深度、高质量渲染和精确3D表面。
- Method: NeVStereo结合了NeRF驱动的新视角合成和立体视觉架构：1）使用NeRF-based NVS生成适合立体匹配的渲染；2）置信度引导的多视角深度估计；3）NeRF耦合的束调整进行位姿优化；4）迭代细化阶段同时更新深度和辐射场以提高几何一致性。该设计缓解了NeRF常见的表面堆叠、伪影和位姿-深度耦合问题。
- Result: 在室内、室外、桌面和航空基准测试中，NeVStereo实现了强大的零样本性能：深度误差降低达36%，位姿精度提升10.4%，NVS保真度提高4.5%，网格质量达到SOTA水平（F1 91.93%，Chamfer 4.35 mm）。
- Conclusion: NeVStereo成功地将NeRF渲染能力与立体视觉几何估计相结合，提供了一个统一的框架，能够从多视角RGB输入中同时获得准确的相机位姿、多视角深度、高质量新视角合成和精确表面重建，在多个基准测试中超越了现有方法。


### [43] [Multi-AD: Cross-Domain Unsupervised Anomaly Detection for Medical and Industrial Applications](https://arxiv.org/abs/2602.05426)
*Wahyu Rahmaniar,Kenji Suzuki*

Main category: cs.CV

TL;DR: Multi-AD是一个基于CNN的无监督异常检测模型，通过SE注意力模块、知识蒸馏和判别器网络，在医疗和工业图像上实现了跨域的高性能异常检测。

- Motivation: 传统深度学习模型在跨域应用中缺乏标注数据，特别是在医疗早期疾病诊断和工业缺陷检测等关键领域，需要有效的无监督异常检测方法。
- Method: 提出Multi-AD模型，采用SE注意力模块增强特征提取，通过知识蒸馏从教师模型向学生模型传递信息特征，使用判别器网络增强正常与异常数据的区分能力，并集成多尺度特征检测不同大小的异常。
- Result: 在多个医疗数据集（脑MRI、肝CT、视网膜OCT）和工业数据集（MVTec AD）上评估，在图像级和像素级任务上都优于现有方法，医疗图像AUROC达81.4%（图像级）和97.0%（像素级），工业图像达99.6%（图像级）和98.4%（像素级）。
- Conclusion: Multi-AD通过创新的注意力机制、知识蒸馏和多尺度特征集成，实现了跨医疗和工业领域的鲁棒无监督异常检测，具有实际应用价值。


### [44] [LD-SLRO: Latent Diffusion Structured Light for 3-D Reconstruction of Highly Reflective Objects](https://arxiv.org/abs/2602.05434)
*Sanghoon Jeon,Gihyun Jung,Suhyeon Ka,Jae-Sang Hyun*

Main category: cs.CV

TL;DR: 提出基于潜在扩散模型的LD-SLRO方法，用于恢复高反光物体表面条纹投影图像，改善3D重建精度

- Motivation: 高反光、低粗糙度物体的条纹投影三维重建面临挑战，镜面反射和间接光照导致条纹图案严重失真或丢失
- Method: 使用潜在扩散模型，首先编码相位偏移条纹图像提取表面反射特征的潜在表示，然后作为条件输入扩散模型，概率性抑制反射伪影并恢复丢失的条纹信息
- Result: 实验结果表明该方法在条纹质量和3D重建精度上优于现有方法，将平均均方根误差从1.8176 mm降低到0.9619 mm
- Conclusion: LD-SLRO方法能有效处理高反光表面的条纹投影问题，提高3D重建精度，具有输入输出条纹配置的灵活性


### [45] [Stable Velocity: A Variance Perspective on Flow Matching](https://arxiv.org/abs/2602.05435)
*Donglin Yang,Yongxing Zhang,Xin Yu,Liang Hou,Xin Tao,Pengfei Wan,Xiaojuan Qi,Renjie Liao*

Main category: cs.CV

TL;DR: 提出Stable Velocity框架，通过方差分析改进流匹配的训练和采样：训练时用StableVM减少方差，用VA-REPA增强监督；采样时利用低方差区域的闭式解实现2倍加速。

- Motivation: 传统流匹配依赖单样本条件速度，导致训练目标方差高，优化不稳定且收敛慢。需要解决高方差问题以提升训练效率和采样速度。
- Method: 1) 分析条件速度方差，识别高方差（先验附近）和低方差（数据分布附近）区域；2) 提出StableVM无偏方差减少目标；3) 提出VA-REPA自适应增强低方差区域的辅助监督；4) 利用低方差区域动力学闭式解实现StableVS采样加速。
- Result: 在ImageNet 256×256及SD3.5、Flux、Qwen-Image、Wan2.2等大型预训练模型上，训练效率提升，低方差区域内采样速度提高2倍以上，且不降低样本质量。
- Conclusion: 通过方差分析提出的Stable Velocity框架能有效改进流匹配的训练稳定性和采样效率，为扩散模型提供了实用的优化方案。


### [46] [Synthetic Defect Geometries of Cast Metal Objects Modeled via 2d Voronoi Tessellations](https://arxiv.org/abs/2602.05440)
*Natascha Jeziorski,Petra Gospodnetić,Claudia Redenbach*

Main category: cs.CV

TL;DR: 提出参数化方法建模3D缺陷网格，结合数字孪生和物理模拟生成合成数据用于无损检测的机器学习训练

- Motivation: 工业缺陷检测需要大量高质量训练数据，但真实缺陷数据获取困难且稀有缺陷样本不足，需要可控的合成数据生成方法
- Method: 开发参数化3D缺陷模型，在数字孪生中添加到物体几何体，然后使用基于物理的蒙特卡洛模拟生成合成检测数据
- Result: 能够生成可变且任意大的合成数据集，包含足够数量的稀有缺陷，同时生成像素级完美标注
- Conclusion: 该方法为无损检测的机器学习训练提供了可控的合成数据生成方案，可扩展到各种检测方法


### [47] [DisCa: Accelerating Video Diffusion Transformers with Distillation-Compatible Learnable Feature Caching](https://arxiv.org/abs/2602.05449)
*Chang Zou,Changlin Li,Yang Li,Patrol Li,Jianbing Wu,Xiao He,Songtao Liu,Zhao Zhong,Kailin Huang,Linfeng Zhang*

Main category: cs.CV

TL;DR: 提出一种适用于扩散模型的蒸馏兼容可学习特征缓存机制，通过轻量级神经网络预测器替代传统训练免费启发式方法，结合受限均值流方法实现稳定无损蒸馏，将视频生成加速11.8倍同时保持生成质量。

- Motivation: 现有视频生成扩散模型面临计算负担快速增加的问题。特征缓存方法虽然训练免费且加速效果好，但进一步压缩时会出现语义和细节丢失；训练感知步数蒸馏方法在图像生成中成功，但在视频生成中步数减少时质量急剧下降。将训练免费特征缓存应用于步数蒸馏模型时，由于采样步数更稀疏，质量损失更严重。
- Method: 1. 首次引入蒸馏兼容可学习特征缓存机制，使用轻量级可学习神经网络预测器替代传统训练免费启发式方法，更准确地捕捉高维特征演化过程。2. 探索大规模视频模型高度压缩蒸馏的挑战，提出保守的受限均值流方法，实现更稳定和无损的蒸馏。
- Result: 通过提出的方法，将视频生成加速边界进一步推至11.8倍，同时保持生成质量。大量实验证明了该方法的有效性。
- Conclusion: 本文提出的蒸馏兼容可学习特征缓存机制和受限均值流方法，有效解决了现有视频生成扩散模型加速方法中的质量损失问题，实现了高质量的视频生成加速。


### [48] [Attention Retention for Continual Learning with Vision Transformers](https://arxiv.org/abs/2602.05454)
*Yue Lu,Xiangyu Zhou,Shizhou Zhang,Yinghui Xing,Guoqiang Liang,Wencong Zhang*

Main category: cs.CV

TL;DR: 提出基于注意力保持的持续学习方法，通过梯度掩码防止Vision Transformers中的注意力漂移，缓解灾难性遗忘

- Motivation: 持续学习中灾难性遗忘是核心挑战，研究发现Vision Transformers中的注意力漂移是导致遗忘的主要原因，即学习新任务后对先前学习视觉概念的注意力发生显著偏移
- Method: 提出注意力保持框架：1）使用层间展开机制提取先前任务的注意力图并生成实例自适应二值掩码；2）学习新任务时应用这些掩码将先前注意力区域相关的梯度置零，防止已学习视觉概念被破坏；为兼容现代优化器，通过按比例缩放参数更新来保持相对幅度
- Result: 实验和可视化证明该方法能有效缓解灾难性遗忘并保持视觉概念，在多种持续学习场景中实现了最先进的性能和强大的泛化能力
- Conclusion: 通过约束Vision Transformers中的注意力漂移，提出的注意力保持框架为缓解持续学习中的灾难性遗忘提供了有效解决方案，并展示了良好的通用性


### [49] [MerNav: A Highly Generalizable Memory-Execute-Review Framework for Zero-Shot Object Goal Navigation](https://arxiv.org/abs/2602.05467)
*Dekang Qi,Shuang Zeng,Xinyuan Chang,Feng Xiong,Shichao Xie,Xiaolong Wu,Mu Xu*

Main category: cs.CV

TL;DR: 提出Memory-Execute-Review框架，在视觉语言导航任务中同时提升成功率和泛化能力，超越有监督微调和无训练方法。

- Motivation: 现有视觉语言导航方法存在权衡：有监督微调方法成功率较高但泛化差，无训练方法泛化好但成功率低，难以同时获得两者优势。
- Method: 提出三层框架：1) 分层记忆模块提供信息支持；2) 执行模块进行常规决策和行动；3) 审查模块处理异常情况并修正行为。
- Result: 在4个数据集上，无训练设置下平均成功率提升7%，零样本设置下提升5%。在HM3D_v0.1和HM3D_OVON数据集上，零样本设置下分别提升8%和6%。在MP3D和HM3D_OVON数据集上，不仅超越所有无训练方法，还超越了有监督微调方法。
- Conclusion: Memory-Execute-Review框架成功解决了视觉语言导航中成功率和泛化能力的权衡问题，实现了全面的性能领先。


### [50] [SOMA-1M: A Large-Scale SAR-Optical Multi-resolution Alignment Dataset for Multi-Task Remote Sensing](https://arxiv.org/abs/2602.05480)
*Peihao Wu,Yongxiang Yao,Yi Wan,Wenfei Zhang,Ruipeng Zhao,Jiayuan Li,Yongjun Zhang*

Main category: cs.CV

TL;DR: SOMA-1M是一个包含130万对像素级精确对齐的SAR-光学图像数据集，覆盖0.5-10米多分辨率，支持多尺度基础模型训练。

- Motivation: 现有基准数据集存在单空间分辨率、数据规模不足、对齐精度低等限制，无法有效支持多尺度基础模型的训练和泛化。
- Method: 构建SOMA-1M数据集，整合Sentinel-1、PIESAT-1、Capella Space和Google Earth图像，采用从粗到细的图像匹配框架确保像素级对齐，包含12种典型土地覆盖类别。
- Result: 在SOMA-1M上监督训练显著提升了图像匹配、图像融合、SAR辅助云去除和跨模态转换等四项视觉任务的性能，其中多模态遥感图像匹配达到当前SOTA水平。
- Conclusion: SOMA-1M为鲁棒的多模态算法和遥感基础模型提供了基础资源，将公开发布以促进相关研究。


### [51] [Feature points evaluation on omnidirectional vision with a photorealistic fisheye sequence -- A report on experiments done in 2014](https://arxiv.org/abs/2602.05487)
*Julien Moreau,S. Ambellouis,Yassine Ruichek*

Main category: cs.CV

TL;DR: 该报告是2014年博士研究期间未发表的草稿，贡献了PFSeq鱼眼序列数据集，并系统评估了鱼眼图像在自标定场景下的最佳特征检测与描述算法。

- Motivation: 解决鱼眼相机自标定中的"鸡与蛋"问题：无法利用精确投影模型进行最优特征检测，同时需要良好特征来完成相机标定。研究旨在找到车载顶置鱼眼相机（指向天顶）在自标定场景下的最佳特征检测与描述方法。
- Method: 提供PFSeq鱼眼序列数据集，并进行全面的实验评估。研究比较了标准特征算法在鱼眼图像上的性能，但未与专门为全向图像设计的算法进行对比。
- Result: 报告提供了详细的实验结果和数据集，但作为2014年的草稿，实验未重新运行，也未根据最新技术进展进行更新。数据集已公开可用。
- Conclusion: 该研究为鱼眼图像特征检测与描述提供了基准数据集和实验分析，但由于是未发表的草稿且未更新，其结论主要反映2014年的技术水平，需要谨慎参考。


### [52] [VGGT-Motion: Motion-Aware Calibration-Free Monocular SLAM for Long-Range Consistency](https://arxiv.org/abs/2602.05508)
*Zhuang Xiong,Chen Zhang,Qingshan Xu,Wenbing Tao*

Main category: cs.CV

TL;DR: VGGT-Motion提出了一种无需标定的单目SLAM系统，通过运动感知子图构建和锚点驱动的Sim(3)配准，解决了长序列中的尺度漂移问题，实现了公里级轨迹的高效全局一致性。

- Motivation: 尽管基于3D视觉基础模型的无标定单目SLAM取得进展，但长序列中的尺度漂移仍然严重。运动无关的分区会破坏上下文一致性并导致零运动漂移，而传统的几何对齐计算成本高昂。
- Method: 1) 运动感知子图构建机制：使用光流指导自适应分区，修剪静态冗余，封装转弯以保持局部几何稳定性；2) 锚点驱动的直接Sim(3)配准策略：利用上下文平衡的锚点实现无搜索、像素级密集对齐和高效闭环，无需昂贵的特征匹配；3) 轻量子图级位姿图优化：以线性复杂度强制全局一致性，支持可扩展的长距离操作。
- Result: 实验表明，VGGT-Motion显著提高了轨迹精度和效率，在零样本、长距离无标定单目SLAM中实现了最先进的性能。
- Conclusion: VGGT-Motion通过创新的运动感知子图构建和高效的全局一致性方法，有效解决了长序列SLAM中的尺度漂移问题，为无标定单目SLAM提供了可扩展的解决方案。


### [53] [Mapper-GIN: Lightweight Structural Graph Abstraction for Corrupted 3D Point Cloud Classification](https://arxiv.org/abs/2602.05522)
*Jeongbin You,Donggun Kim,Sejun Park,Seungsang Oh*

Main category: cs.CV

TL;DR: Mapper-GIN：基于拓扑分解的轻量级3D点云分类方法，通过Mapper算法将点云分割为重叠区域构建区域图，使用图同构网络进行分类，在ModelNet40-C基准上仅用0.5M参数即实现强鲁棒性。

- Motivation: 现有3D点云鲁棒性方法通常依赖扩大网络规模或专门的数据增强，本文探索仅通过结构抽象是否能提升鲁棒性，研究基于Mapper算法的拓扑分解方法。
- Method: 提出Mapper-GIN轻量级流程：1) 使用Mapper算法（PCA透镜、立方覆盖、密度聚类）将点云分割为重叠区域；2) 基于区域重叠构建区域图；3) 使用图同构网络进行图分类。
- Result: 在ModelNet40-C基准上，Mapper-GIN仅用0.5M参数即在噪声和变换扰动下获得竞争性且稳定的准确率，相比需要重架构或额外机制的方法，通过简单的区域级图抽象和GIN消息传递实现强鲁棒性。
- Conclusion: 区域图结构为3D视觉识别提供了高效且可解释的鲁棒性来源，表明结构抽象本身即可显著提升点云分类的鲁棒性，无需复杂架构或专门增强。


### [54] [Generalization of Self-Supervised Vision Transformers for Protein Localization Across Microscopy Domains](https://arxiv.org/abs/2602.05527)
*Ben Isselmann,Dilara Göksu,Andreas Weinmann*

Main category: cs.CV

TL;DR: 本文研究了自监督学习（SSL）预训练模型在显微镜图像跨域迁移中的表现，发现领域相关的预训练（如HPA）在蛋白质定位任务上表现最佳，甚至略微超过直接在目标数据集上训练的模型。

- Motivation: 显微镜数据集通常规模较小，难以训练出鲁棒的深度学习模型。虽然自监督学习可以通过无标签数据进行预训练，但尚不清楚这些表示在不同染色协议和通道配置的显微镜领域之间的迁移能力如何。
- Method: 使用三种DINO预训练的Vision Transformer模型：ImageNet-1k、Human Protein Atlas（HPA）和OpenCell。在OpenCell数据集上生成图像嵌入，然后训练监督分类头来评估蛋白质定位性能。
- Result: 所有预训练模型都表现出良好的迁移能力。显微镜特定的HPA预训练模型表现最佳（平均宏观F1分数=0.8221±0.0062），略优于直接在OpenCell上训练的DINO模型（0.8057±0.0090）。
- Conclusion: 大规模预训练具有重要价值，领域相关的自监督学习表示能够有效泛化到相关但不同的显微镜数据集，即使在任务特定标签数据有限的情况下也能实现强大的下游性能。


### [55] [SSG: Scaled Spatial Guidance for Multi-Scale Visual Autoregressive Generation](https://arxiv.org/abs/2602.05534)
*Youngwoo Shin,Jiwan Hur,Junmo Kim*

Main category: cs.CV

TL;DR: SSG是一种无需训练、推理时引导的方法，通过强调目标高频信号（语义残差）来纠正VAR模型在推理时的层次漂移问题，提升图像生成质量。

- Motivation: 视觉自回归模型在推理时由于容量限制和累积误差，其粗到细的层次结构会发生漂移，导致生成质量下降。需要解决训练-推理不一致的问题。
- Method: 提出SSG方法：1）强调目标高频信号（语义残差）；2）使用DSE从频域角度锐化和隔离语义残差；3）在推理时引导生成保持预期的层次结构。
- Result: SSG在多个VAR模型上都能一致提升生成保真度和多样性，同时保持低延迟，揭示了粗到细图像生成中未开发的效率潜力。
- Conclusion: SSG通过信息论视角解决了VAR模型的层次漂移问题，提供了一种无需训练、推理时引导的通用方法，显著提升了图像生成质量。


### [56] [A Comparative Study of 3D Person Detection: Sensor Modalities and Robustness in Diverse Indoor and Outdoor Environments](https://arxiv.org/abs/2602.05538)
*Malaz Tamim,Andrea Matic-Flierl,Karsten Roscher*

Main category: cs.CV

TL;DR: 本文系统评估了相机、LiDAR及融合方法在3D行人检测中的性能，发现融合方法在挑战场景中表现最佳，但对传感器错位敏感。

- Motivation: 现有研究多关注自动驾驶场景，本文旨在探索3D行人检测在多样化室内外场景中的性能和鲁棒性，为机器人、工业监控等安全关键应用提供指导。
- Method: 使用JRDB数据集，对比三种代表性模型：BEVDepth（相机）、PointPillars（LiDAR）和DAL（相机-LiDAR融合），分析在不同遮挡程度和距离下的性能表现。
- Result: 融合方法在挑战场景中表现最优，但对传感器错位和某些LiDAR损坏敏感；相机方法性能最低，对遮挡、距离和噪声最敏感；LiDAR方法在特定损坏下表现较好。
- Conclusion: 传感器融合能显著提升3D行人检测性能，但系统仍存在对传感器错位和损坏的脆弱性，需要进一步研究解决这些挑战。


### [57] [FastVMT: Eliminating Redundancy in Video Motion Transfer](https://arxiv.org/abs/2602.05551)
*Yue Ma,Zhikai Wang,Tianhao Ren,Mingzhe Zheng,Hongyu Liu,Jiayi Guo,Mark Fong,Yuxuan Xue,Zixiang Zhao,Konrad Schindler,Qifeng Chen,Linfeng Zhang*

Main category: cs.CV

TL;DR: FastVMT通过消除DiT架构中的运动冗余和梯度冗余，实现了3.43倍加速的视频运动迁移方法

- Motivation: 现有基于Diffusion Transformer的视频运动迁移方法存在计算效率低下的问题，主要源于两个结构性冗余：运动冗余（帧间运动小而平滑，但DiT架构未利用此特性）和梯度冗余（沿扩散轨迹梯度变化缓慢）
- Method: 1. 针对运动冗余：将注意力层限制在局部邻域，避免为不相关的远距离图像区域计算交互权重；2. 针对梯度冗余：设计优化方案重用先前扩散步骤的梯度，跳过不必要的梯度计算
- Result: FastVMT平均实现了3.43倍的速度提升，同时保持了生成视频的视觉保真度和时间一致性
- Conclusion: 通过识别并消除DiT架构中的结构性计算冗余，可以在不牺牲质量的情况下显著加速视频运动迁移过程


### [58] [IndustryShapes: An RGB-D Benchmark dataset for 6D object pose estimation of industrial assembly components and tools](https://arxiv.org/abs/2602.05555)
*Panagiotis Sapoutzoglou,Orestis Vaggelis,Athina Zacharia,Evangelos Sartinas,Maria Pateraki*

Main category: cs.CV

TL;DR: IndustryShapes是一个新的RGB-D工业工具和组件基准数据集，专为实例级和新物体6D姿态估计方法设计，填补了实验室研究与实际工业部署之间的差距。

- Motivation: 现有数据集主要关注家用或消费产品，使用合成、干净的桌面数据集，或在受控实验室环境中捕获物体，缺乏针对工业场景的真实数据集。需要为工业机器人应用提供更贴近实际制造场景的测试平台。
- Method: 创建包含五种具有挑战性属性的新物体类型的RGB-D数据集，在真实的工业装配环境中捕获。数据集分为经典集和扩展集：经典集包含4.6k图像和6k标注姿态；扩展集提供额外数据模态以支持无模型和基于序列的方法评估，包括首次提供的RGB-D静态上机序列。
- Result: 数据集包含从简单到复杂的多样化场景，包括单个和多个物体，以及同一物体的多个实例。通过对代表性最先进方法的评估，显示该领域仍有改进空间。
- Conclusion: IndustryShapes为工业机器人应用中的6D姿态估计提供了首个真实且具有挑战性的基准数据集，填补了研究与实践之间的空白，推动了该领域的发展。


### [59] [PIRATR: Parametric Object Inference for Robotic Applications with Transformers in 3D Point Clouds](https://arxiv.org/abs/2602.05557)
*Michael Schwingshackl,Fabio F. Oberweger,Mario Niedermeyer,Huemer Johannes,Markus Murschitz*

Main category: cs.CV

TL;DR: PIRATR是一个端到端的3D物体检测框架，用于点云中的机器人应用，能够联合估计多类别6自由度姿态和类别特定参数属性，在合成环境中训练后能有效泛化到真实室外LiDAR数据。

- Motivation: 解决机器人应用中需要同时进行几何定位和估计任务相关参数属性的问题，弥合低级几何推理和可操作世界模型之间的差距。
- Method: 基于PI3DETR扩展，采用模块化、类别特定的头部设计，直接从遮挡影响的点云数据中联合估计6自由度姿态和参数属性，通过预定义规则调整3D模型。
- Result: 在自动化叉车平台上验证，针对三种结构功能不同的类别（起重机抓具、装载平台、托盘），在合成环境训练后无需微调即可在真实室外LiDAR扫描中达到0.919的检测mAP。
- Conclusion: PIRATR建立了姿态感知、参数化感知的新范式，为可扩展的仿真训练感知系统在动态机器人环境中的部署铺平了道路。


### [60] [ShapeGaussian: High-Fidelity 4D Human Reconstruction in Monocular Videos via Vision Priors](https://arxiv.org/abs/2602.05572)
*Zhenxiao Liang,Ning Zhang,Youbao Tang,Ruei-Sung Lin,Qixing Huang,Peng Chang,Jing Xiao*

Main category: cs.CV

TL;DR: ShapeGaussian：一种从单目视频进行4D人体重建的高保真、无模板方法，通过结合视觉先验解决模板方法对姿态估计错误的敏感性，实现更鲁棒的重建。

- Motivation: 现有4D人体重建方法存在局限性：无模板方法（如4DGS）缺乏视觉先验，难以捕捉高变形人体运动；模板方法（如HUGS）依赖SMPL模型，对姿态估计错误敏感，容易产生不真实伪影。需要一种既能保持高保真度又对姿态估计错误鲁棒的方法。
- Method: 采用两阶段流程：1）使用预训练模型学习粗粒度可变形几何，建立数据驱动的先验基础；2）通过神经变形模型细化几何，捕捉细粒度动态细节。利用2D视觉先验减轻姿态估计错误的影响，采用多参考帧解决2D关键点不可见问题。
- Result: 实验表明ShapeGaussian在重建精度上超越模板方法，在多种人体运动中实现更优的视觉质量和鲁棒性，特别是在单目视频中表现出色。
- Conclusion: ShapeGaussian通过有效整合无模板视觉先验，实现了高保真且鲁棒的4D人体重建，解决了现有方法对姿态估计错误的敏感性问题，在单目视频场景中表现优异。


### [61] [Visual Implicit Geometry Transformer for Autonomous Driving](https://arxiv.org/abs/2602.05573)
*Arsenii Shirokov,Mikhail Kuznetsov,Danila Stepochkin,Egor Evdokimov,Daniil Glazkov,Nikolay Patakin,Anton Konushin,Dmitry Senushkin*

Main category: cs.CV

TL;DR: ViGT是一个用于自动驾驶的视觉隐式几何Transformer模型，能够从环视摄像头估计连续的3D占据场，采用无标定架构和自监督训练，在多个数据集上达到SOTA性能。

- Motivation: 构建自动驾驶的几何基础模型，解决现有方法对传感器配置依赖性强、需要昂贵标注、以及缺乏通用几何表示的问题。
- Method: 提出ViGT模型，采用无标定架构适应不同传感器配置，通过自监督训练利用图像-LiDAR同步数据，在BEV中估计连续3D占据场，无需人工标注。
- Result: 在5个大规模自动驾驶数据集上训练，在点云估计任务上达到最佳平均排名，在Occ3D-nuScenes基准上与监督方法性能相当。
- Conclusion: ViGT展示了构建可扩展、通用且无需标注的自动驾驶几何基础模型的可行性，为多几何任务提供了统一的表示框架。


### [62] [A Hybrid CNN and ML Framework for Multi-modal Classification of Movement Disorders Using MRI and Brain Structural Features](https://arxiv.org/abs/2602.05574)
*Mengyu Li,Ingibjörg Kristjánsdóttir,Thilo van Eimeren,Kathrin Giehl,Lotta M. Ellingsen,the ASAP Neuroimaging Initiative*

Main category: cs.CV

TL;DR: 提出结合CNN与机器学习的混合框架，利用多模态MRI数据对非典型帕金森病亚型进行早期鉴别诊断

- Motivation: 非典型帕金森病（如PSP和MSA）早期症状与帕金森病重叠，常导致误诊，需要可靠的影像生物标志物进行早期鉴别诊断
- Method: 结合卷积神经网络与机器学习技术，使用多模态输入数据：T1加权MRI、12个深部脑结构分割掩膜及其体积测量值，构建混合分类框架
- Result: 分类性能优异：PSP vs PD的AUC为0.95，MSA vs PD为0.86，PSP vs MSA为0.92，证明空间与结构信息结合的有效性
- Conclusion: 融合CNN图像特征与体积特征可提高APD亚型分类准确性，有助于临床实践中更可靠的早期诊断和针对性干预


### [63] [LocateEdit-Bench: A Benchmark for Instruction-Based Editing Localization](https://arxiv.org/abs/2602.05577)
*Shiyu Wu,Shuyan Li,Jing Li,Jing Liu,Yequan Wang*

Main category: cs.CV

TL;DR: 提出LocateEdit-Bench数据集，包含23.1万张编辑图像，专门用于评估针对指令驱动图像编辑的伪造定位方法

- Motivation: 现有AI生成伪造定位方法主要关注基于修复的篡改，无法应对最新的指令驱动编辑范式，需要建立能跟上图像编辑技术发展的评估基准
- Method: 构建包含23.1万张编辑图像的大规模数据集，涵盖4种前沿编辑模型和3种常见编辑类型，开发多指标评估协议分析现有定位方法
- Result: 建立了专门针对指令驱动图像编辑的伪造定位基准数据集，为跟踪图像编辑技术发展提供了基础
- Conclusion: 该工作填补了现有伪造定位方法在应对指令驱动编辑方面的空白，为未来伪造定位方法的发展提供了重要基础，数据集将在接受后开源


### [64] [LoGoSeg: Integrating Local and Global Features for Open-Vocabulary Semantic Segmentation](https://arxiv.org/abs/2602.05578)
*Junyang Chen,Xiangbo Lv,Zhiqiang Kou,Xingdong Sheng,Ning Xu,Yiguo Qiao*

Main category: cs.CV

TL;DR: LoGoSeg是一个高效的单阶段开放词汇语义分割框架，通过对象存在先验、区域感知对齐和双流融合机制，无需外部掩码提议或额外数据集，在多个基准测试中表现出色。

- Motivation: 现有开放词汇语义分割方法依赖图像级预训练的视觉语言模型，导致空间对齐不精确，在模糊或杂乱场景中产生错误分割。这些方法缺乏强对象先验和区域级约束，容易产生对象幻觉或漏检。
- Method: 提出LoGoSeg框架，包含三个关键创新：(1) 对象存在先验：通过全局图像-文本相似性动态加权相关类别，减少幻觉；(2) 区域感知对齐模块：建立精确的区域级视觉-文本对应关系；(3) 双流融合机制：结合局部结构信息和全局语义上下文。
- Result: 在六个基准测试（A-847、PC-459、A-150、PC-59、PAS-20和PAS-20b）上的广泛实验表明，该方法在开放词汇设置下具有竞争性性能和强泛化能力。
- Conclusion: LoGoSeg通过集成对象存在先验、区域感知对齐和双流融合，有效解决了开放词汇语义分割中的空间对齐不精确和对象幻觉问题，无需外部掩码提议或额外数据集，实现了高效且性能优越的分割。


### [65] [Geometric Observability Index: An Operator-Theoretic Framework for Per-Feature Sensitivity, Weak Observability, and Dynamic Effects in SE(3) Pose Estimation](https://arxiv.org/abs/2602.05582)
*Joe-Mei Feng,Sheng-Wei Yu*

Main category: cs.CV

TL;DR: 提出了几何可观测性指数(GOI)框架，用于分析SE(3)上相机姿态估计中单个特征测量的敏感性，统一了条件分析、Fisher信息几何和影响函数理论。

- Motivation: 传统敏感性分析工具无法解释单个图像特征如何影响姿态估计，也不能说明为什么动态或不一致的观测会不成比例地扭曲现代SLAM和SfM系统。需要一种统一的理论框架来分析每个特征对姿态估计的影响。
- Method: 将影响函数理论扩展到矩阵李群，推导出SE(3)上左平凡化M估计器的固有扰动算子。通过曲率算子和可观测子空间的李代数结构量化单个测量的贡献，GOI允许沿可观测曲率主方向进行谱分解。
- Result: GOI揭示了弱可观测性与放大敏感性之间的直接对应关系。在总体状态下，GOI与SE(3)上的Fisher信息几何一致，产生了Cramer-Rao界的单测量类似物。该谱机制解释了经典退化情况(如纯旋转和消失视差)以及沿弱曲率方向的动态特征放大。
- Conclusion: GOI提供了测量影响的几何一致描述，统一了条件分析、Fisher信息几何、影响函数理论和动态场景可检测性。由于这些量直接出现在高斯-牛顿流程中，曲率谱和GOI还产生了轻量级、无需训练的诊断信号，用于识别动态特征和检测弱可观测配置，无需修改现有SLAM架构。


### [66] [A Mixed Reality System for Robust Manikin Localization in Childbirth Training](https://arxiv.org/abs/2602.05588)
*Haojie Cheng,Chang Liu,Abhiram Kanneganti,Mahesh Arjandas Choolani,Arundhati Tushar Gosavi,Eng Tat Khoo*

Main category: cs.CV

TL;DR: 开发混合现实分娩训练系统，结合虚拟指导与触觉模拟人互动，提升医学生分娩培训效果

- Motivation: 医学生获得阴道分娩实践机会受限：临床轮转时间缩短、患者不愿配合、分娩过程不可预测。需要减轻临床医生教学负担并提高学员学习效率
- Method: 开发混合现实系统：1) 扩展商用头戴显示器穿透功能，通过外部RGB-D摄像头空间校准实现物理训练对象实时视觉整合；2) 采用粗到精定位流程：先用基准标记对齐母体模拟人定义分娩区域，再在该区域内注册预扫描的新生儿头部；3) 在模拟人附近叠加虚拟指导手，学员可跟随专家轨迹进行触觉互动
- Result: 1) 系统在独立头显上实现准确稳定的模拟人定位，无需外部计算资源；2) 83名四年级医学生大规模用户研究：混合现实训练在分娩、产后及整体任务表现得分显著高于虚拟现实训练，且学员一致更偏好混合现实训练
- Conclusion: 混合现实分娩训练系统能有效结合虚拟指导与真实触觉反馈，提供独立练习机会，减轻专家监督负担，显著提升医学生分娩培训效果


### [67] [EgoPoseVR: Spatiotemporal Multi-Modal Reasoning for Egocentric Full-Body Pose in Virtual Reality](https://arxiv.org/abs/2602.05590)
*Haojie Cheng,Shaun Jing Heng Ong,Shaoyu Cai,Aiden Tat Yang Koh,Fuxi Ouyang,Eng Tat Khoo*

Main category: cs.CV

TL;DR: EgoPoseVR：用于VR的端到端第一人称全身姿态估计框架，通过融合头戴设备运动信号与RGB-D观测，实现准确、稳定的实时姿态跟踪。

- Motivation: 现有的头戴相机第一人称姿态估计方法在VR头显应用中面临时间不稳定性、下半身估计不准确和缺乏实时性能等问题，需要一种更稳健的解决方案。
- Method: 提出EgoPoseVR端到端框架，通过双模态融合管道整合头显运动信号与第一人称RGB-D观测。使用时空编码器提取帧级和关节级表示，通过交叉注意力融合互补运动信息，并利用运动学优化模块增强姿态估计的准确性和稳定性。
- Result: 实验表明EgoPoseVR优于现有第一人称姿态估计模型。用户研究显示在真实场景中，EgoPoseVR在准确性、稳定性、沉浸感和未来使用意愿方面获得显著更高的主观评分。
- Conclusion: EgoPoseVR实现了稳健的全身姿态跟踪，为准确VR化身提供实用解决方案，无需额外身体穿戴传感器或房间尺度跟踪系统。


### [68] [CAViT -- Channel-Aware Vision Transformer for Dynamic Feature Fusion](https://arxiv.org/abs/2602.05598)
*Aon Safdar,Mohamed Saadeldin*

Main category: cs.CV

TL;DR: CAViT提出了一种双注意力架构，用动态的通道自注意力替代ViT中静态的MLP，实现内容感知的特征交互，在减少参数和计算量的同时提升性能。

- Motivation: Vision Transformers中的通道混合机制是静态的，依赖于固定的多层感知机，缺乏对输入内容的适应性，限制了模型的表达能力。
- Method: CAViT采用双注意力架构，在每个Transformer块中先进行空间自注意力，再进行通道自注意力，实现动态的、内容感知的特征交互。
- Result: 在五个基准数据集（自然和医学领域）上，CAViT比标准ViT基线准确率提升高达+3.6%，同时减少30%以上的参数和FLOPs，注意力图显示更清晰、语义更明确的激活模式。
- Conclusion: 通过用动态注意力机制替代静态MLP，CAViT实现了更有效的特征表示，在保持模型简洁性的同时提升了性能，验证了注意力驱动特征混合的有效性。


### [69] [Multi-instance robust fitting for non-classical geometric models](https://arxiv.org/abs/2602.05602)
*Zongliang Zhang,Shuxiang Li,Xingwang Huang,Zongyue Wang*

Main category: cs.CV

TL;DR: 提出一种用于从噪声数据中重建多个非经典模型实例的鲁棒拟合方法，通过基于模型到数据误差的估计器和元启发式优化器解决多实例拟合问题。

- Motivation: 现有鲁棒拟合方法主要针对经典模型（如直线、圆、平面），而针对非经典模型（如螺旋曲线、程序化角色模型、自由曲面）的方法较少，且现有方法主要关注重建单个非经典模型实例，需要解决从噪声数据中重建多个非经典模型实例的问题。
- Method: 将多实例拟合任务形式化为优化问题，包含估计器和优化器两部分：1）提出基于模型到数据误差的新型估计器，无需预定义误差阈值即可处理异常值；2）由于估计器对模型参数不可微，采用元启发式算法作为优化器寻找全局最优解。
- Result: 通过在多种非经典模型上的实验结果表明该方法的有效性，代码已在GitHub开源。
- Conclusion: 该方法能够有效地从噪声数据中重建多个非经典模型实例，为处理非经典模型的多实例拟合问题提供了可行的解决方案。


### [70] [Unified Sensor Simulation for Autonomous Driving](https://arxiv.org/abs/2602.05617)
*Nikolay Patakin,Arsenii Shirokov,Anton Konushin,Dmitry Senushkin*

Main category: cs.CV

TL;DR: XSIM是一个用于自动驾驶的传感器仿真框架，通过扩展3DGUT splatting并引入广义滚动快门建模，解决了球形相机（如LiDAR）的投影问题，提升了场景表示的几何一致性和真实感。

- Motivation: 现有3DGUT splatting方法在处理自动驾驶应用中的球形相机（如LiDAR）时存在局限性，特别是在循环投影和方位边界的时间不连续性方面，导致粒子投影错误，需要专门的解决方案。
- Method: 1) 扩展3DGUT splatting并引入广义滚动快门建模；2) 提出相位建模机制，显式处理方位边界处的高斯时间与形状不连续性；3) 引入扩展的3D高斯表示，包含两个不同的不透明度参数以解决几何与颜色分布不匹配问题。
- Result: 在Waymo Open Dataset、Argoverse 2和PandaSet等多个自动驾驶数据集上评估，XSIM框架一致优于现有基线方法，在所有数据集上实现了最先进的性能。
- Conclusion: XSIM提供了一个统一灵活的传感器建模框架，能够渲染动态环境中的复杂传感器失真，显著提升了场景表示的几何一致性和真实感，为自动驾驶传感器仿真提供了有效解决方案。


### [71] [ROMAN: Reward-Orchestrated Multi-Head Attention Network for Autonomous Driving System Testing](https://arxiv.org/abs/2602.05629)
*Jianlei Chi,Yuzhen Wu,Jiaxuan Hou,Xiaodong Zhang,Ming Fan,Suhui Sun,Weijun Dai,Bo Li,Jianguo Sun,Jun Sun*

Main category: cs.CV

TL;DR: ROMAN是一种用于自动驾驶系统测试的新型场景生成方法，结合多头注意力网络和交通法规加权机制，专门生成高风险违规场景以进行更彻底的ADS评估。

- Motivation: 当前自动驾驶系统测试方法面临两大挑战：1) 难以生成复杂高风险的法律违规场景；2) 未能考虑多车辆交互的复杂关键情况。现有测试方法在生成高风险违规场景方面能力有限，无法全面评估ADS的安全性。
- Method: ROMAN采用多头注意力机制建模车辆、交通信号等因素间的交互，并结合基于LLM的风险加权模块，从严重性和发生频率两个维度评估违规行为，通过交通法规加权机制生成高风险违规场景。
- Result: 在CARLA仿真平台测试百度Apollo ADS的实验显示，ROMAN在平均违规数量上比ABLE高出7.91%，比LawBreaker高出55.96%，同时保持更高的场景多样性。ROMAN是唯一能为所有输入交通法规条款生成违规场景的方法。
- Conclusion: ROMAN能够有效生成高风险交通法规违规场景，显著优于现有方法，为自动驾驶系统的全面安全评估提供了更有效的测试工具。


### [72] [UniSurg: A Video-Native Foundation Model for Universal Understanding of Surgical Videos](https://arxiv.org/abs/2602.05638)
*Jinlin Wu,Felix Holm,Chuxi Chen,An Wang,Yaxin Hu,Xiaofan Ye,Zelin Zang,Miao Xu,Lihua Zhou,Huai Liao,Danny T. M. Chan,Ming Feng,Wai S. Poon,Hongliang Ren,Dong Yi,Nassir Navab,Gaofeng Meng,Jiebo Luo,Hongbin Liu,Zhen Lei*

Main category: cs.CV

TL;DR: UniSurg是一个基于视频原生架构的手术视频基础模型，通过从像素级重建转向潜在运动预测，结合运动引导、时空亲和性自蒸馏和特征多样性正则化三大创新，在17个基准测试中显著超越现有方法。

- Motivation: 现有手术视频分析基础模型主要依赖像素级重建目标，浪费模型容量在烟雾、镜面反射、流体运动等低层次视觉细节上，而非对手术理解至关重要的语义结构。
- Method: 基于V-JEPA架构，提出三大技术创新：1) 运动引导的潜在预测，优先处理语义重要区域；2) 时空亲和性自蒸馏，强制关系一致性；3) 特征多样性正则化，防止纹理稀疏手术场景中的表示崩溃。使用UniSurg-15M数据集（3658小时视频，50个来源，13个解剖区域）进行大规模预训练。
- Result: 在17个基准测试中显著超越SOTA方法：手术工作流识别（EgoSurgery +14.6% F1，PitVis +10.3%）、动作三元组识别（CholecT50 39.54% mAP-IVT）、技能评估、息肉分割和深度估计。
- Conclusion: UniSurg通过从像素级重建转向运动预测的学习范式转变，建立了通用、运动导向的手术视频理解新标准。


### [73] [Enhancing Personality Recognition by Comparing the Predictive Power of Traits, Facets, and Nuances](https://arxiv.org/abs/2602.05650)
*Amir Ansari,Jana Subirana,Bruna Silva,Sergio Escalera,David Gallardo-Pujol,Cristina Palmero*

Main category: cs.CV

TL;DR: 使用更细粒度的人格层次（nuances）进行人格识别，比传统的facet和trait层次表现更好，在视听交互数据上MSE降低达74%

- Motivation: 传统人格识别模型依赖宽泛的人格特质分数作为ground truth，但相似的特质分数可能通过多样化的、情境依赖的行为表现，加上训练数据有限，导致泛化能力差
- Method: 使用UDIVA v0.5数据集，训练基于transformer的模型，包含跨模态（视听）和跨主体（双人感知）注意力机制，探索大五人格模型中更细粒度的层次（facets和nuances）
- Result: nuance层次模型在多个交互场景中一致优于facet和trait层次模型，平均平方误差降低高达74%
- Conclusion: 在人格识别中，使用更细粒度的人格层次（特别是nuances）可以显著提升模型性能，为基于行为数据的人格评估提供了更精确的方法


### [74] [ShapeUP: Scalable Image-Conditioned 3D Editing](https://arxiv.org/abs/2602.05676)
*Inbar Gat,Dana Cohen-Bar,Guy Levy,Elad Richardson,Daniel Cohen-Or*

Main category: cs.CV

TL;DR: ShapeUP：基于图像条件的三维编辑框架，通过监督式潜在空间转换实现精确、可扩展的三维编辑，在保持结构一致性的同时提供细粒度视觉控制。

- Motivation: 现有三维编辑方法面临视觉可控性、几何一致性和可扩展性之间的权衡：优化方法速度慢，多视图二维传播存在视觉漂移，无训练潜在操作方法受限于冻结先验且无法受益于模型扩展。
- Method: 将三维编辑定义为监督式潜在空间转换任务，在原生三维表示中训练3D Diffusion Transformer（DiT）。使用三元组数据（源三维形状、编辑后的二维图像、编辑后的三维形状）学习直接映射，实现图像作为提示的细粒度控制。
- Result: ShapeUP在身份保持和编辑保真度方面均优于当前有训练和无训练的基线方法，提供隐式、无需掩码的定位能力，同时保持与原始资产严格的结构一致性。
- Conclusion: ShapeUP为原生三维内容创作提供了一个稳健且可扩展的范式，通过监督式潜在空间转换有效利用预训练三维基础模型的生成先验，解决了现有三维编辑方法的局限性。


### [75] [Poster: Camera Tampering Detection for Outdoor IoT Systems](https://arxiv.org/abs/2602.05706)
*Shadi Attarha,Kanaga Shanmugi,Anna Förster*

Main category: cs.CV

TL;DR: 本文提出两种相机篡改图像检测方法：基于规则的方法和基于深度学习的方法，并比较它们在准确性、计算需求和训练数据要求方面的表现。

- Motivation: 户外智能相机系统易受故意破坏或恶劣环境影响而失效，但静止图像（而非视频）的篡改检测更具挑战性，因为缺乏连续帧序列。目前缺乏相关数据集支持该领域研究。
- Method: 提出两种方法：1）基于规则的方法，使用预定义规则检测图像异常；2）基于深度学习的方法，利用神经网络模型学习篡改特征。同时公开包含正常、模糊和旋转图像的数据集。
- Result: 深度学习模型提供更高的检测准确性，而基于规则的方法更适合资源有限且无法进行长时间校准的场景。公开的数据集填补了该领域资源空白。
- Conclusion: 两种方法各有适用场景：深度学习适合高精度需求，规则方法适合资源受限环境。公开数据集将促进相机篡改检测技术的发展。


### [76] [Exploring the Temporal Consistency for Point-Level Weakly-Supervised Temporal Action Localization](https://arxiv.org/abs/2602.05718)
*Yunchuan Ma,Laiyun Qing,Guorong Li,Yuqing Liu,Yuankai Qi,Qingming Huang*

Main category: cs.CV

TL;DR: 本文提出了一种多任务学习框架，通过三个自监督时序理解任务增强点监督时序动作定位模型的时序理解能力

- Motivation: 现有PTAL方法仅使用点监督的片段级分类，缺乏对动作帧间时序关系的显式建模。理解帧间时序关系对于模型理解动作定义和定位完整动作帧至关重要
- Method: 设计多任务学习框架，包含三个自监督时序理解任务：动作完成、动作顺序理解和动作规律性理解，利用点监督提升模型的时序理解能力
- Result: 在四个基准数据集上的大量实验结果表明，该方法相比多个最先进方法具有显著效果
- Conclusion: 这是首次显式探索时序一致性用于点监督动作定位的尝试，提出的方法通过增强时序理解能力有效提升了动作定位性能


### [77] [Adaptive Global and Fine-Grained Perceptual Fusion for MLLM Embeddings Compatible with Hard Negative Amplification](https://arxiv.org/abs/2602.05729)
*Lexiang Hu,Youze Xue,Dian Li,Gang Liu,Zhouchen Lin*

Main category: cs.CV

TL;DR: 提出AGFF-Embed方法，通过自适应融合全局和细粒度语义信息，提升MLLM嵌入模型在复杂场景下的理解能力

- Motivation: 当前多模态嵌入模型（CLIP和MLLM）只能捕获全局语义信息，而复杂场景需要同时理解全局和细粒度元素，需要兼容的融合机制
- Method: AGFF-Embed方法：提示MLLM生成关注不同维度语义信息的多个嵌入，然后自适应平滑聚合；结合显式梯度放大技术实现批次内困难负样本增强
- Result: 在MMEB和MMVP-VLM基准测试中，AGFF-Embed在全局和细粒度理解方面都实现了最先进的性能
- Conclusion: AGFF-Embed通过自适应融合全局和细粒度感知，有效提升了MLLM嵌入模型在复杂多模态场景下的理解能力


### [78] [Depth as Prior Knowledge for Object Detection](https://arxiv.org/abs/2602.05730)
*Moussa Kassem Sbeyti,Nadja Klein*

Main category: cs.CV

TL;DR: DepthPrior：一种利用深度信息作为先验知识而非融合特征的框架，通过深度感知的训练和推理策略，显著提升小目标和远距离目标的检测性能，无需修改检测器架构。

- Motivation: 小目标和远距离目标检测面临尺度变化、低分辨率和背景杂波等挑战，在安全关键应用中尤为重要。深度信息能改善检测，但现有方法需要复杂的架构修改。需要一种不改变检测器架构就能利用深度信息的方法。
- Method: 提出DepthPrior框架，将深度作为先验知识而非融合特征。训练阶段使用深度损失加权（DLW）和深度损失分层（DLS），推理阶段使用深度感知置信度阈值（DCT）。仅需深度估计的初始成本，无需修改检测器架构。
- Result: 在四个基准数据集（KITTI、MS COCO、VisDrone、SUN RGB-D）和两种检测器（YOLOv11、EfficientDet）上验证，小目标检测mAP提升高达+9%，mAR提升高达+7%，推理恢复率高达95:1（真阳性vs假阳性）。
- Conclusion: DepthPrior通过将深度作为先验知识而非融合特征，有效解决了小目标和远距离目标检测的挑战，无需额外传感器、架构修改或性能成本，为安全关键应用提供了可靠的解决方案。


### [79] [Neuro-Inspired Visual Pattern Recognition via Biological Reservoir Computing](https://arxiv.org/abs/2602.05737)
*Luca Ciampi,Ludovico Iannello,Fabrizio Tonelli,Gabriele Lagani,Angelo Di Garbo,Federico Cremisi,Giuseppe Amato*

Main category: cs.CV

TL;DR: 使用体外培养的皮层神经元网络作为物理储层，通过高密度多电极阵列进行刺激和读取，实现生物储层计算系统，成功完成从简单刺激到MNIST手写数字的视觉模式识别任务。

- Motivation: 传统储层计算依赖人工循环模型近似神经动态，而本研究旨在利用活体神经回路的自发和刺激诱发活动作为计算基质，探索将生物神经基质整合到神经形态计算框架中的新途径。
- Method: 采用体外培养的皮层神经元网络作为物理储层，通过高密度多电极阵列同时进行刺激和读取：输入模式通过选定电极传递，其余电极捕获高维神经响应，形成生物基础的特征表示，然后训练线性读出层（单层感知器）对这些储层状态进行分类。
- Result: 系统在从点状刺激、定向条状、时钟数字形状到MNIST手写数字的一系列难度递增任务中表现良好，尽管生物神经响应存在固有变异性，但系统始终能生成支持准确分类的高维表示。
- Conclusion: 体外皮层网络可作为静态视觉模式识别的有效储层，为将活体神经基质整合到神经形态计算框架开辟了新途径，展示了活体神经系统如何为设计高效且生物基础的计算模型提供信息。


### [80] [FMPose3D: monocular 3D pose estimation via flow matching](https://arxiv.org/abs/2602.05755)
*Ti Wang,Xiaohang Yu,Mackenzie Weygandt Mathis*

Main category: cs.CV

TL;DR: FMPose3D：基于流匹配的单目3D姿态估计框架，通过ODE实现高效多假设生成，并引入重投影后验期望聚合模块提升精度

- Motivation: 单目3D姿态估计存在深度模糊和遮挡问题，需要生成多个合理假设。现有扩散模型推理计算成本高，需要更高效的方法
- Method: 提出FMPose3D框架，将3D姿态估计建模为条件分布传输问题，利用流匹配学习速度场，通过ODE仅需少量积分步骤生成样本。引入重投影后验期望聚合模块从多个假设中获取准确预测
- Result: 在Human3.6M、MPI-INF-3DHP人体姿态数据集以及Animal3D、CtrlAni3D动物姿态数据集上均达到最先进性能
- Conclusion: FMPose3D通过流匹配实现了高效的多假设3D姿态生成，在人体和动物姿态估计任务上都表现出色，为单目3D姿态估计提供了新的解决方案


### [81] [ReText: Text Boosts Generalization in Image-Based Person Re-identification](https://arxiv.org/abs/2602.05785)
*Timur Mamedov,Karina Kvanchiani,Anton Konushin,Vadim Konushin*

Main category: cs.CV

TL;DR: ReText：首个在图像行人重识别中探索多模态联合学习的方法，通过混合多摄像头数据和单摄像头数据，并利用文本描述增强语义线索，实现更好的跨域泛化性能。

- Motivation: 现有方法通过复杂架构解决域差距，但研究发现具有风格多样性的单摄像头数据能带来更好的泛化。虽然单摄像头数据易于收集，但由于缺乏跨视角变化而复杂性不足。因此需要一种方法能够利用单摄像头数据，同时增强其语义信息。
- Method: ReText方法在混合的多摄像头Re-ID数据和单摄像头数据上进行训练，其中单摄像头数据通过文本描述补充语义线索。训练时联合优化三个任务：1）多摄像头数据的Re-ID；2）图像-文本匹配；3）文本引导的单摄像头数据图像重建。
- Result: 实验表明ReText实现了强大的泛化能力，在跨域Re-ID基准测试中显著优于最先进的方法。这是首个在图像行人重识别中探索多模态联合学习的方法。
- Conclusion: 通过混合多摄像头和单摄像头数据，并利用文本描述增强语义信息，ReText在跨域行人重识别中取得了优异的泛化性能，为这一领域提供了新的研究方向。


### [82] [Allocentric Perceiver: Disentangling Allocentric Reasoning from Egocentric Visual Priors via Frame Instantiation](https://arxiv.org/abs/2602.05789)
*Hengyi Wang,Ruiqiang Zhang,Chang Liu,Guanjie Wang,Zehua Ma,Han Fang,Weiming Zhang*

Main category: cs.CV

TL;DR: Allocentric Perceiver：一种无需训练的策略，通过几何专家从图像恢复3D状态，建立与指令语义意图对齐的目标中心参考系，将心理旋转从隐式推理转为显式计算，显著提升VLMs在空间推理任务中的表现。

- Motivation: 随着视觉语言导航/动作等空间任务需求的增长，VLMs在全景感知能力上受到更多关注。然而，VLMs在处理需要显式视角转换的全景空间查询时仍然脆弱，这些查询需要在目标中心框架而非观察相机视角下进行推理。
- Method: 提出Allocentric Perceiver策略：1）使用现成的几何专家从单张或多张图像恢复度量3D状态；2）实例化与指令语义意图对齐的查询条件全景参考系；3）将重建几何确定性地转换到目标框架；4）用结构化、几何基础的表示提示骨干VLM。
- Result: 在多个骨干网络家族的空间推理基准测试中，Allocentric Perceiver在全景任务上获得一致且显著的提升（约10%），同时保持强大的自我中心性能，超越了空间感知微调模型以及最先进的开源和专有模型。
- Conclusion: 通过将心理旋转从隐式推理卸载到显式计算，Allocentric Perceiver有效提升了VLMs的全景空间推理能力，为空间任务提供了强大的解决方案。


### [83] [Focus-Scan-Refine: From Human Visual Perception to Efficient Visual Token Pruning](https://arxiv.org/abs/2602.05809)
*Enwei Tong,Yuanchao Bai,Yao Zhu,Junjun Jiang,Xianming Liu*

Main category: cs.CV

TL;DR: FSR是一种受人类启发的视觉语言模型token剪枝框架，通过"聚焦-扫描-精炼"三步法，在保持高压缩率的同时提升推理精度。

- Motivation: 现有视觉语言模型生成大量视觉token导致推理延迟和内存占用高，而现有剪枝方法在激进压缩下难以平衡局部证据和全局上下文。
- Method: 提出Focus-Scan-Refine框架：1) 聚焦关键证据，结合视觉重要性和指令相关性；2) 扫描补充上下文，选择与聚焦证据差异最大的token；3) 精炼扫描上下文，通过相似性分配和分数加权合并聚合附近信息token。
- Result: 在多个VLM骨干网络和视觉语言基准测试中，FSR相比现有最先进剪枝方法，在准确率-效率权衡方面取得一致提升。
- Conclusion: FSR通过模拟人类视觉问答的认知过程，实现了更有效的视觉token剪枝，为视觉语言模型的高效推理提供了实用解决方案。


### [84] [NVS-HO: A Benchmark for Novel View Synthesis of Handheld Objects](https://arxiv.org/abs/2602.05822)
*Musawar Ali,Manuel Carranza-García,Nicola Fioraio,Samuele Salti,Luigi Di Stefano*

Main category: cs.CV

TL;DR: NVS-HO是首个针对手持物体在真实环境中仅使用RGB输入进行新视角合成的基准测试，包含手持和固定两种拍摄序列，揭示了现有方法在无约束手持条件下的显著性能差距。

- Motivation: 当前新视角合成方法在真实世界无约束手持条件下的性能评估不足，需要建立一个专门针对手持物体的RGB基准测试来推动该领域发展。
- Method: 提出NVS-HO基准测试，包含两种互补的RGB序列：手持序列（物体在静态相机前移动）和固定序列（物体固定在ChArUco板上提供精确相机位姿）。使用SfM流程和VGGT作为位姿估计器，基于NeRF和高斯泼溅训练NVS模型。
- Result: 实验显示当前方法在无约束手持条件下存在显著性能差距，表明需要更鲁棒的方法来处理真实世界手持物体的新视角合成任务。
- Conclusion: NVS-HO提供了一个具有挑战性的真实世界基准测试，能够推动基于RGB的手持物体新视角合成方法的进步。


### [85] [Sparse Video Generation Propels Real-World Beyond-the-View Vision-Language Navigation](https://arxiv.org/abs/2602.05827)
*Hai Zhang,Siqi Liang,Li Chen,Yuxian Li,Yukuan Xu,Yichao Zhong,Fu Zhang,Hongyang Li*

Main category: cs.CV

TL;DR: 提出SparseVideoNav方法，首次将视频生成模型引入超越视野导航任务，通过生成稀疏未来轨迹实现20秒视野的快速推理，相比未优化版本提速27倍，在真实世界零样本实验中达到SOTA LLM基线2.5倍的成功率。

- Motivation: 现有视觉语言导航依赖详细的语言指令，这与真实世界导航目标相矛盾。理想情况下，智能体应能在简单高层意图指导下自主导航。这引出了超越视野导航的挑战：在没有密集逐步指导的情况下定位远处不可见目标。现有LLM方法依赖短视野监督，导致短视行为，而简单扩展监督视野会破坏LLM训练稳定性。
- Method: 首次将视频生成模型引入该领域，利用其固有的长视野监督优势。提出SparseVideoNav方法，通过生成稀疏未来轨迹实现20秒视野的快速推理，达到亚秒级轨迹推断速度，相比未优化版本实现27倍加速。
- Result: 在真实世界零样本实验中，SparseVideoNav在超越视野导航任务上达到最先进LLM基线2.5倍的成功率，并首次在具有挑战性的夜间场景中实现此类能力。
- Conclusion: 视频生成模型因其固有的长视野监督优势而特别适合超越视野导航任务。SparseVideoNav通过稀疏未来轨迹生成实现了高效的长期规划，为真实世界自主导航提供了有前景的解决方案。


### [86] [Weaver: End-to-End Agentic System Training for Video Interleaved Reasoning](https://arxiv.org/abs/2602.05829)
*Yudi Shi,Shangzhe Di,Qirui Chen,Qinian Wang,Jiayin Cai,Xiaolong Jiang,Yao Hu,Weidi Xie*

Main category: cs.CV

TL;DR: Weaver是一个端到端可训练的多模态推理代理系统，通过动态调用工具和强化学习提升视频推理能力，在长视频推理基准上表现优异。

- Motivation: 现有基于文本链式思维的方法存在表示不匹配和感知能力有限的问题，无法充分处理视频推理任务，需要更强大的多模态推理系统。
- Method: 提出Weaver系统：1）端到端可训练的多模态推理代理；2）策略模型动态调用多样化工具获取视觉线索；3）集成强化学习算法探索工具使用策略。
- Result: 在多个复杂视频推理基准测试中表现优异，特别是在长视频推理任务上展现出显著性能提升。
- Conclusion: Weaver通过动态工具调用和强化学习有效解决了视频推理中的表示不匹配和感知限制问题，为多模态推理系统提供了新思路。


### [87] [UI-Mem: Self-Evolving Experience Memory for Online Reinforcement Learning in Mobile GUI Agents](https://arxiv.org/abs/2602.05832)
*Han Xiao,Guozhi Wang,Hao Wang,Shilong Liu,Yuxiang Chai,Yue Pan,Yufeng Zhou,Xiaoxin Chen,Yafei Wen,Hongsheng Li*

Main category: cs.CV

TL;DR: UI-Mem：通过分层经验记忆增强GUI在线强化学习的新框架，解决长时程任务中的信用分配问题和跨任务经验迁移问题

- Motivation: 在线强化学习在GUI代理中面临两个主要挑战：1) 长时程任务中的低效信用分配问题；2) 由于缺乏经验迁移导致的跨任务重复错误。传统回放缓冲区无法有效积累和重用结构化知识。
- Method: 提出UI-Mem框架，包含：1) 分层经验记忆：存储高层工作流、子任务技能和失败模式作为参数化模板；2) 分层组采样：在每组轨迹中注入不同级别的指导以保持结果多样性；3) 自演化循环：持续抽象新策略和错误，使记忆与代理演化策略保持一致。
- Result: 在在线GUI基准测试中，UI-Mem显著优于传统RL基线和静态重用策略，并在未见过的应用程序上表现出强大的泛化能力。
- Conclusion: UI-Mem通过分层经验记忆和自演化机制有效解决了GUI在线强化学习中的信用分配和经验迁移问题，为GUI代理学习提供了更高效的框架。


### [88] [Self-Supervised Learning with a Multi-Task Latent Space Objective](https://arxiv.org/abs/2602.05845)
*Pierre-François De Plaen,Abhishek Jha,Luc Van Gool,Tinne Tuytelaars,Marc Proesmans*

Main category: cs.CV

TL;DR: 提出一种多任务自监督学习方法，通过为不同视图类型分配独立的预测器，解决了多裁剪策略在BYOL、SimSiam等架构中的不稳定性问题，显著提升了性能。

- Motivation: 多裁剪策略虽然能增强自监督学习框架，但在基于预测器的架构（如BYOL、SimSiam、MoCo v3）中会导致训练不稳定。研究发现这种不稳定性源于所有视图共享同一个预测器。
- Method: 为每种视图类型分配独立的预测器来稳定多裁剪训练；将每个空间变换视为独立的对齐任务；添加裁剪视图（在编码前对图像部分区域进行掩码）；构建一个结合全局、局部和掩码视图的多任务非对称孪生网络框架。
- Result: 该方法稳定且适用于多种骨干网络，在ImageNet上显著提升了ResNet和ViT模型的性能。
- Conclusion: 通过为不同视图类型使用独立预测器的多任务方法，有效解决了自监督学习中多裁剪策略的不稳定性问题，为各种骨干网络带来了稳定的性能提升。


### [89] [Pathwise Test-Time Correction for Autoregressive Long Video Generation](https://arxiv.org/abs/2602.05871)
*Xunzhi Xiang,Zixuan Duan,Guiyu Zhang,Haiyu Zhang,Zhe Gao,Junta Wu,Shaofeng Zhang,Tengfei Wang,Qi Fan,Chunchao Guo*

Main category: cs.CV

TL;DR: 提出TTC方法解决蒸馏自回归扩散模型在长序列生成中的误差累积问题，无需训练即可通过初始帧锚点校准采样轨迹

- Motivation: 蒸馏自回归扩散模型虽然能实现实时短视频合成，但在长序列生成中会遭受严重的误差累积。现有的测试时优化方法对图像或短视频有效，但无法缓解长序列中的漂移问题，原因是奖励景观不稳定和蒸馏参数的超敏感性。
- Method: 提出测试时校正方法，利用初始帧作为稳定的参考锚点，沿着采样轨迹校准中间随机状态。这是一种无需训练的方法，可以与各种蒸馏模型无缝集成。
- Result: 实验表明该方法能以可忽略的开销扩展生成长度，在30秒基准测试中与资源密集型的基于训练的方法质量相当。
- Conclusion: TTC方法有效解决了蒸馏自回归扩散模型的长序列生成漂移问题，提供了一种高效且无需训练的解决方案。


### [90] [Contour Refinement using Discrete Diffusion in Low Data Regime](https://arxiv.org/abs/2602.05880)
*Fei Yu Guan,Ian Keefe,Sophie Wilkinson,Daniel D. B. Perrakis,Steven Waslander*

Main category: cs.CV

TL;DR: 提出轻量级离散扩散轮廓细化管道，用于低数据场景下的鲁棒边界检测，在医学影像等数据集上优于现有方法，推理速度提升3.5倍

- Motivation: 不规则和半透明物体的边界检测在医学影像、环境监测和制造中很重要，但这些应用通常面临标记数据稀缺和计算资源有限的问题。现有研究多关注分割掩码对齐，边界检测任务在低数据场景下研究不足。
- Method: 提出轻量级离散扩散轮廓细化管道，使用带自注意力层的CNN架构作为核心，以分割掩码为条件，迭代去噪稀疏轮廓表示。引入多个创新适应方法：简化扩散过程、定制模型架构、最小化后处理，适用于训练图像少于500的数据集。
- Result: 在医学影像数据集KVASIR上优于多个SOTA基线，在HAM10K和自定义野火数据集Smoke上表现有竞争力，同时推理帧率提升3.5倍。
- Conclusion: 该方法在低数据场景下实现了鲁棒的边界检测，通过轻量级设计和效率优化，在保持性能的同时显著提升了推理速度，适用于标记数据稀缺的实际应用场景。


### [91] [EoCD: Encoder only Remote Sensing Change Detection](https://arxiv.org/abs/2602.05882)
*Mubashir Noman,Mustansar Fiaz,Hiyam Debary,Abdul Hannan,Shah Nawaz,Fahad Shahbaz Khan,Salman Khan*

Main category: cs.CV

TL;DR: 提出了一种仅使用编码器的变化检测方法EoCD，通过早期融合时间数据并用参数免费的多尺度特征融合模块替代解码器，在保持性能的同时显著降低模型复杂度。

- Motivation: 现有变化检测方法存在两个主要问题：1）基于孪生编码器的方法需要分别提取时间特征再进行融合，计算成本高且模型复杂；2）早期融合方法虽然避免了孪生编码器的开销，但仍依赖复杂的解码器，且性能通常不如后期融合方法。需要一种既能保持性能又能降低复杂度的解决方案。
- Method: 提出编码器仅变化检测（EoCD）方法：1）对时间数据进行早期融合；2）用参数免费的多尺度特征融合模块替代传统解码器；3）证明模型性能主要依赖于编码器网络，解码器成为可选组件。
- Result: EoCD在四个具有挑战性的变化检测数据集上表现出色，在变化检测性能和预测速度之间达到了最佳平衡。该方法显著降低了整体模型复杂度，同时保持了竞争力强的检测性能。
- Conclusion: EoCD是一种简单有效的编码器仅变化检测方法，通过早期融合和参数免费特征融合模块，在降低模型复杂度的同时保持了优异的性能，证明了编码器在变化检测任务中的主导作用。


### [92] [Neural Implicit 3D Cardiac Shape Reconstruction from Sparse CT Angiography Slices Mimicking 2D Transthoracic Echocardiography Views](https://arxiv.org/abs/2602.05884)
*Gino E. Jansen,Carolina Brás,R. Nils Planken,Mark J. Schuuring,Berto J. Bouma,Ivana Išgum*

Main category: cs.CV

TL;DR: 提出一种从稀疏CT平面分割重建完整3D心脏形状的方法，应用于2D经胸超声心动图，通过神经隐式函数实现3D重建，相比临床标准方法显著提高准确性。

- Motivation: 准确的3D心脏结构表示对于解剖和功能定量分析至关重要。当前2D经胸超声心动图(TTE)只能提供有限的平面视图，难以获得完整的3D心脏形状信息，限制了定量分析的准确性。
- Method: 使用神经隐式函数从稀疏CTA平面分割重建心脏腔室和左心室心肌的3D形状。训练时，多层感知器从CTA的3D分割中学习形状先验。测试时，网络通过联合优化潜在编码和刚性变换（将观察平面映射到3D空间），从模拟TTE的CTA平面分割重建3D心脏形状。
- Result: 在保留的CTA分割数据集上，所有结构的平均Dice系数达到0.86±0.04。与临床标准Simpson双平面规则相比，左心室体积误差显著降低（4.88±4.26 mL vs. 8.14±6.04 mL），左心房体积误差也大幅降低（6.40±7.37 mL vs. 37.76±22.96 mL）。
- Conclusion: 该方法为2D经胸超声心动图提供了更准确的3D腔室量化途径，通过从稀疏平面重建完整3D心脏形状，显著提高了体积测量的准确性，具有临床应用潜力。


### [93] [CLIP-Map: Structured Matrix Mapping for Parameter-Efficient CLIP Compression](https://arxiv.org/abs/2602.05909)
*Kangjie Zhang,Wenxuan Huang,Xin Zhou,Boxiang Zhou,Dejia Song,Yuan Xie,Baochang Zhang,Lizhuang Ma,Nemo Chen,Xu Tang,Yao Hu,Shaohui Lin*

Main category: cs.CV

TL;DR: CLIP-Map：一种基于映射的CLIP压缩框架，通过可学习矩阵映射和组合预训练权重，在极端压缩下保持更好的特征表示能力

- Motivation: CLIP模型在内存和计算成本方面较高，限制了其在资源受限场景的应用。现有的基于选择的压缩方法在极端压缩时会损害特征表示能力
- Method: 提出CLIP-Map框架，使用可学习矩阵通过全映射与Kronecker分解来映射和组合预训练权重，并采用对角线继承初始化来减少分布偏移问题
- Result: 在各种压缩比下都优于基于选择的压缩框架，特别是在高压缩设置下取得了显著优势
- Conclusion: CLIP-Map通过映射而非选择的方式，在保持原始权重信息的同时实现了高效的CLIP压缩，为资源受限场景提供了更好的解决方案


### [94] [Multi-Scale Global-Instance Prompt Tuning for Continual Test-time Adaptation in Medical Image Segmentation](https://arxiv.org/abs/2602.05937)
*Lingrui Li,Yanfeng Zhou,Nan Pu,Xin Chen,Zhun Zhong*

Main category: cs.CV

TL;DR: 提出MGIPT方法，通过多尺度全局-实例提示调优解决医学图像分割中的持续测试时适应问题，克服现有方法的错误累积和灾难性遗忘

- Motivation: 医学图像在不同临床中心存在分布偏移问题，阻碍预训练分割模型在多域实际应用。现有CTTA方法存在错误累积和灾难性遗忘问题，而基于提示调优的方法缺乏多尺度多样性、实例特定知识不足且有隐私泄露风险
- Method: 提出多尺度全局-实例提示调优(MGIPT)，包含自适应尺度实例提示(AIP)和多尺度全局级提示(MGP)。AIP动态学习轻量级实例特定提示，MGP捕获不同尺度的域级知识，通过加权集成结合这两个互补组件
- Result: 在医学图像分割基准测试中，MGIPT优于最先进方法，在持续变化的目标域上实现鲁棒适应
- Conclusion: MGIPT通过增强提示的尺度多样性并捕获全局和实例级知识，有效解决了CTTA中的错误累积和灾难性遗忘问题，实现了鲁棒的跨域适应


### [95] [Better Source, Better Flow: Learning Condition-Dependent Source Distribution for Flow Matching](https://arxiv.org/abs/2602.05951)
*Junwan Kim,Jiho Park,Seonghu Jeon,Seungryong Kim*

Main category: cs.CV

TL;DR: 本文提出在条件流匹配中学习条件相关的源分布，而非使用标准高斯分布，通过方差正则化和方向对齐解决分布坍塌和不稳定性问题，在文本到图像生成中实现更快收敛和更好性能。

- Motivation: 流匹配作为扩散模型的替代方案，通常继承使用标准高斯分布作为源分布，但很少将源分布本身作为优化目标。本文旨在证明在条件生成任务中，有原则地设计条件相关的源分布是可行且有益的。
- Method: 提出在流匹配目标下学习条件相关的源分布，引入方差正则化和方向对齐机制来解决直接条件化导致的分布坍塌和不稳定性问题，并分析目标表示空间选择对结构化源分布的影响。
- Result: 在多个文本到图像基准测试中实现了一致且稳健的改进，包括FID收敛速度提升高达3倍，证明了条件相关源分布设计的实际效益。
- Conclusion: 有原则地设计源分布对于条件流匹配是可行且有益的，特别是在利用丰富条件信号方面，适当的正则化和对齐机制对于稳定有效学习至关重要。


### [96] [LSA: Localized Semantic Alignment for Enhancing Temporal Consistency in Traffic Video Generation](https://arxiv.org/abs/2602.05966)
*Mirlan Karimov,Teodora Spasojevic,Markus Braun,Julian Wiederer,Vasileios Belagiannis,Marc Pollefeys*

Main category: cs.CV

TL;DR: LSA框架通过语义特征对齐提升视频生成的时间一致性，无需推理时控制信号，在nuScenes和KITTI数据集上表现优异。

- Motivation: 现有可控视频生成方法依赖推理时的控制信号来保证时间一致性，这限制了它们作为可扩展通用数据引擎的实用性。
- Method: 提出局部语义对齐(LSA)框架，通过对比真实视频和生成视频中动态对象周围的语义特征，构建语义特征一致性损失，结合标准扩散损失微调预训练视频生成模型。
- Result: 单epoch微调后，在常见视频生成评估指标上优于基线方法。为测试时间一致性，还适配了目标检测任务的mAP和mIoU指标，在nuScenes和KITTI数据集上验证了有效性。
- Conclusion: LSA无需推理时外部控制信号和额外计算开销，能有效提升视频生成的时间一致性，为自动驾驶场景合成提供了更实用的数据生成工具。


### [97] [RISE-Video: Can Video Generators Decode Implicit World Rules?](https://arxiv.org/abs/2602.05986)
*Mingxin Liu,Shuran Ma,Shibei Meng,Xiangyu Zhao,Zicheng Zhang,Shaofeng Zhang,Zhihang Zhong,Peixian Chen,Haoyu Cao,Xing Sun,Haodong Duan,Xue Yang*

Main category: cs.CV

TL;DR: RISE-Video是一个针对文本图像到视频合成的推理导向基准测试，包含467个样本和8个类别，通过4个评估指标来衡量模型在隐含世界规则下的推理能力。

- Motivation: 当前生成视频模型虽然在视觉保真度方面取得了显著进展，但它们在理解和推理隐含世界规则方面的能力仍然是一个关键但未被充分探索的领域。需要建立一个评估框架来测试模型在复杂场景下的认知推理能力，而不仅仅是表面美学质量。
- Method: 1. 创建RISE-Video基准测试：包含467个人工标注的样本，涵盖8个严格类别（常识、空间动态、专业领域等）
2. 设计多维评估协议：包含推理对齐、时间一致性、物理合理性和视觉质量四个指标
3. 开发自动化评估管道：利用大型多模态模型模拟人类中心评估，支持可扩展评估
4. 在11个最先进的TI2V模型上进行广泛实验
- Result: 对11个最先进的TI2V模型的实验揭示了它们在模拟隐含约束下的复杂场景方面存在普遍缺陷。这些发现为未来世界模拟生成模型的进步提供了关键见解。
- Conclusion: RISE-Video基准测试将评估重点从表面美学转移到深度认知推理，揭示了当前生成视频模型在理解和应用隐含世界规则方面的局限性，为开发更智能的世界模拟生成模型提供了重要指导。


### [98] [VisRefiner: Learning from Visual Differences for Screenshot-to-Code Generation](https://arxiv.org/abs/2602.05998)
*Jie Deng,Kaichun Yao,Libo Zhang*

Main category: cs.CV

TL;DR: VisRefiner：通过视觉差异学习提升截图到代码生成的训练框架，结合差异对齐监督和强化学习自优化

- Motivation: 现有多模态大语言模型直接从截图生成代码，但缺乏观察生成代码视觉结果的能力。人类开发者通过迭代渲染、比较设计差异并学习视觉差异与代码修改的关系来改进实现。受此启发，需要让模型也能从渲染预测与参考设计之间的视觉差异中学习。
- Method: 提出VisRefiner训练框架：1）构建差异对齐监督，将视觉差异与对应代码编辑关联；2）引入强化学习自优化阶段，模型通过观察渲染输出和目标设计，识别视觉差异并相应更新代码来改进生成。
- Result: VisRefiner显著提升单步生成质量和布局保真度，同时赋予模型强大的自优化能力。实验证明从视觉差异学习对推进截图到代码生成的有效性。
- Conclusion: 学习视觉差异是提升截图到代码生成的有效方法，VisRefiner框架通过差异对齐监督和强化学习自优化，使模型能够像人类开发者一样通过视觉反馈迭代改进代码实现。


### [99] [GenArena: How Can We Achieve Human-Aligned Evaluation for Visual Generation Tasks?](https://arxiv.org/abs/2602.06013)
*Ruihang Li,Leigang Qu,Jingxu Zhang,Dongnan Gui,Mengde Xu,Xiaosong Zhang,Han Hu,Wenjie Wang,Jiaqi Wang*

Main category: cs.CV

TL;DR: 视觉生成模型评估新框架GenArena：通过成对比较范式替代传统绝对评分，显著提升评估稳定性与人类对齐度，使开源模型超越顶级专有模型

- Motivation: 视觉生成模型的快速发展超越了传统评估方法，需要采用视觉语言模型作为替代评估者。当前主流的绝对点评分标准存在随机不一致性和与人类感知对齐差的问题，需要更可靠的评估框架。
- Method: 提出GenArena统一评估框架，采用成对比较范式而非绝对评分。该方法通过比较两个生成结果而非单独评分，确保评估的稳定性和人类对齐性。
- Result: 成对比较协议使现成的开源模型能够超越顶级专有模型。评估准确率提升超过20%，与权威LMArena排行榜的Spearman相关性达到0.86，远高于点评分方法的0.36相关性。
- Conclusion: GenArena为视觉生成模型提供了严格且自动化的评估标准，解决了传统绝对评分方法的局限性，为社区提供了更可靠、人类对齐的评估框架。


### [100] [MambaVF: State Space Model for Efficient Video Fusion](https://arxiv.org/abs/2602.06017)
*Zixiang Zhao,Yukun Cui,Lilun Deng,Haowen Bai,Haotong Qin,Tao Feng,Konrad Schindler*

Main category: cs.CV

TL;DR: MambaVF：基于状态空间模型的高效视频融合框架，无需显式运动估计，通过序列状态更新和时空双向扫描机制实现长程时序建模，大幅降低计算和内存开销。

- Motivation: 现有视频融合方法严重依赖光流估计和特征变形，导致计算开销大、可扩展性有限。需要一种无需显式运动估计的高效时序建模方法。
- Method: 1) 将视频融合重新表述为序列状态更新过程，用状态空间模型以线性复杂度捕获长程时序依赖；2) 设计轻量级SSM融合模块，通过时空双向扫描机制替代传统流引导对齐，实现跨帧高效信息聚合。
- Result: 在多重曝光、多重聚焦、红外-可见光和医学视频融合等多个基准测试中达到最先进性能。相比现有方法，参数减少92.25%，计算FLOPs降低88.79%，速度提升2.1倍。
- Conclusion: MambaVF提供了一种无需显式运动估计的高效视频融合框架，通过状态空间模型实现高效的时序建模，在保持高性能的同时大幅降低计算资源需求。


### [101] [Context Forcing: Consistent Autoregressive Video Generation with Long Context](https://arxiv.org/abs/2602.06028)
*Shuo Chen,Cong Wei,Sun Sun,Ping Nie,Kai Zhou,Ge Zhang,Ming-Hsuan Yang,Wenhu Chen*

Main category: cs.CV

TL;DR: 提出Context Forcing框架，通过长上下文教师训练长上下文学生，解决现有流式调优中的师生不匹配问题，实现超过20秒的有效上下文长度

- Motivation: 现有实时长视频生成方法采用流式调优策略，使用短上下文（无记忆）教师训练长上下文学生。这种结构差异导致关键的师生不匹配问题：教师无法访问长期历史，无法指导学生处理全局时间依赖，限制了学生的上下文长度
- Method: 提出Context Forcing框架，通过长上下文教师训练长上下文学生，消除监督不匹配。为处理极端时长（如2分钟）的计算可行性，引入上下文管理系统，将线性增长的上下文转换为Slow-Fast Memory架构，显著减少视觉冗余
- Result: 该方法实现超过20秒的有效上下文长度，比LongLive和Infinite-RoPE等最先进方法长2-10倍。利用扩展的上下文，Context Forcing在长持续时间内保持卓越的一致性，在各种长视频评估指标上超越最先进基线
- Conclusion: Context Forcing通过解决师生不匹配问题，实现了显著更长的上下文长度和更好的长视频一致性，为实时长视频生成提供了有效的解决方案


### [102] [Splat and Distill: Augmenting Teachers with Feed-Forward 3D Reconstruction For 3D-Aware Distillation](https://arxiv.org/abs/2602.06032)
*David Shavin,Sagie Benaim*

Main category: cs.CV

TL;DR: 提出Splat and Distill框架，通过快速前馈3D重建增强2D视觉基础模型的3D感知能力

- Motivation: 当前视觉基础模型在2D任务上表现出色，但缺乏3D感知能力，需要增强其几何理解
- Method: 将教师模型的2D特征提升为3D高斯表示，然后投影到新视角生成2D特征图，用于监督学生模型
- Result: 在单目深度估计、表面法线估计、多视角对应和语义分割等任务上显著优于先前工作
- Conclusion: 该方法成功增强了2D视觉基础模型的3D感知能力，同时提升了特征的语义丰富度


### [103] [V-Retrver: Evidence-Driven Agentic Reasoning for Universal Multimodal Retrieval](https://arxiv.org/abs/2602.06034)
*Dongyang Chen,Chaoyang Wang,Dezhao SU,Xi Xiao,Zeyu Zhang,Jing Xiong,Qing Li,Yuzhang Shang,Shichao Ka*

Main category: cs.CV

TL;DR: V-Retrver是一个证据驱动的多模态检索框架，将检索重新定义为基于视觉检查的智能推理过程，通过外部视觉工具选择性获取视觉证据，实现多模态交替推理，显著提升检索准确性。

- Motivation: 现有多模态检索方法主要依赖语言驱动，使用静态视觉编码，缺乏主动验证细粒度视觉证据的能力，导致在视觉模糊情况下产生推测性推理。需要一种能够主动获取视觉证据的检索框架。
- Method: 提出V-Retrver框架，将多模态检索重新定义为基于视觉检查的智能推理过程。MLLM通过外部视觉工具选择性获取视觉证据，执行多模态交替推理（假设生成与目标视觉验证交替）。采用课程学习策略：监督推理激活、基于拒绝的细化和证据对齐目标的强化学习。
- Result: 在多个多模态检索基准测试中，检索准确性平均提升23.0%，感知驱动的推理可靠性和泛化能力均有显著改善。
- Conclusion: V-Retrver通过证据驱动的智能推理框架，解决了现有方法在视觉模糊情况下的推测性推理问题，显著提升了多模态检索的性能和可靠性。


### [104] [InterPrior: Scaling Generative Control for Physics-Based Human-Object Interactions](https://arxiv.org/abs/2602.06035)
*Sirui Xu,Samuel Schulter,Morteza Ziyadi,Xialin He,Xiaohan Fei,Yu-Xiong Wang,Liangyan Gui*

Main category: cs.CV

TL;DR: InterPrior是一个可扩展的框架，通过大规模模仿预训练和强化学习后训练，学习统一的生成控制器，使类人机器人能够在多样化场景中组合和泛化全身运动技能。

- Motivation: 人类很少在显式全身运动层面规划与物体的交互，而是通过高层意图（如可供性）定义目标，协调的平衡、接触和操作可以从底层物理和运动先验中自然涌现。扩展这些先验对于使类人机器人能够在多样化场景中组合和泛化全身运动技能，同时保持物理一致的全身协调至关重要。
- Method: InterPrior框架包含两个阶段：1）大规模模仿预训练，将完整参考模仿专家提炼为多功能、目标条件的变分策略，从多模态观察和高层意图重建运动；2）强化学习微调，通过物理扰动数据增强和强化学习后训练，提高对未见目标和初始化的能力，将重建的潜在技能整合到有效流形中。
- Result: InterPrior产生了能够超越训练数据泛化的运动先验，例如可以与未见物体进行交互。该框架还展示了用户交互控制的有效性，并具有实际机器人部署的潜力。
- Conclusion: InterPrior通过结合大规模模仿学习和强化学习微调，创建了一个可扩展的框架，能够学习统一的生成控制器，使类人机器人能够在多样化场景中实现全身运动技能的组合和泛化，为实际机器人应用提供了有前景的解决方案。


### [105] [Thinking with Geometry: Active Geometry Integration for Spatial Reasoning](https://arxiv.org/abs/2602.06037)
*Haoyuan Li,Qihang Cao,Tao Tang,Kun Xiang,Zihan Guo,Jianhua Han,Hang Xu,Xiaodan Liang*

Main category: cs.CV

TL;DR: GeoThinker：一种主动感知框架，通过条件化检索几何证据而非被动融合，提升多模态大语言模型的空间推理能力

- Motivation: 现有MLLMs在空间推理中被动融合几何先验，导致语义-几何错位和冗余信号，需要转向主动感知范式
- Method: 提出空间锚定融合，在选定VLM层让语义视觉先验通过帧严格交叉注意力选择性查询和整合任务相关几何，并通过重要性门控校准
- Result: 在VSI-Bench上达到72.6的峰值分数，在具身指称和自动驾驶等复杂下游场景中表现出鲁棒泛化和显著改进的空间感知
- Conclusion: 主动整合空间结构的能力对下一代空间智能至关重要，GeoThinker为空间推理提供了新的主动感知范式


### [106] [SwimBird: Eliciting Switchable Reasoning Mode in Hybrid Autoregressive MLLMs](https://arxiv.org/abs/2602.06040)
*Jintao Tong,Shilin Yan,Hongwei Xue,Xiaojun Tang,Kunyu Shi,Guannan Zhang,Ruixuan Li,Yixiong Zou*

Main category: cs.CV

TL;DR: SwimBird是一种可切换推理模式的多模态大语言模型，能根据输入动态选择文本推理、视觉推理或交错视觉-文本推理三种模式，在保持文本逻辑推理能力的同时显著提升视觉密集任务性能。

- Motivation: 现有MLLM主要依赖文本思维链进行推理，在视觉密集型任务上效果有限。最近的方法虽然通过注入连续隐藏状态作为"视觉思维"来提升视觉性能，但往往以牺牲文本逻辑推理能力为代价。核心问题在于固定的、预定义的推理模式无法根据用户查询自适应选择最合适的思考模态。
- Method: 采用混合自回归公式，统一文本思维的下一个token预测和视觉思维的下一个嵌入预测。设计了系统的推理模式策划策略，构建了包含所有三种推理模式的多样化监督微调数据集SwimBird-SFT-92K。模型能根据输入条件动态切换三种推理模式。
- Result: 在涵盖文本推理和挑战性视觉理解的多样化基准测试中，SwimBird实现了最先进的结果，相比之前固定模式的多模态推理方法获得了稳健的性能提升。
- Conclusion: 通过实现灵活的、查询自适应的模式选择，SwimBird在保持强大文本逻辑推理能力的同时，显著提升了视觉密集型任务的性能，证明了动态切换推理模式的有效性。


### [107] [Predicting Camera Pose from Perspective Descriptions for Spatial Reasoning](https://arxiv.org/abs/2602.06041)
*Xuejun Zhang,Aditi Tiwari,Zhenhailong Wang,Heng Ji*

Main category: cs.CV

TL;DR: CAMCUE是一个多图像空间推理框架，通过显式利用相机姿态作为几何锚点，实现跨视图融合和新视角推理，显著提升多视角空间推理能力。

- Motivation: 当前多模态大语言模型在多图像空间推理方面存在挑战，特别是需要从多视角观察构建连贯3D理解并进行新视角推理的透视任务。单视角感知本质上是2D的，而多视角推理需要跨视角建立一致的场景理解。
- Method: CAMCUE是一个姿态感知的多图像框架，将相机姿态作为显式几何锚点：1) 将每视图姿态注入视觉标记；2) 将自然语言视角描述映射到目标相机姿态；3) 合成姿态条件化的想象目标视图来支持回答。还构建了CAMCUE-DATA数据集，包含27,668个训练和508个测试实例。
- Result: CAMCUE将整体准确率提升9.06%，从自然语言视角描述预测目标姿态的旋转准确率超过90%（20°内），平移准确率在0.5误差阈值内。推理时间从256.6秒大幅减少到1.45秒，实现快速交互式使用。
- Conclusion: CAMCUE通过显式利用相机姿态作为几何锚点，有效解决了多图像空间推理中的透视任务，实现了从自然语言视角描述到相机姿态的直接映射，避免了昂贵的测试时搜索匹配，为实际应用提供了高效解决方案。
## cs.GR

### [108] [Untwisting RoPE: Frequency Control for Shared Attention in DiTs](https://arxiv.org/abs/2602.05013)
*Aryan Mikaeili,Or Patashnik,Andrea Tagliasacchi,Daniel Cohen-Or,Ali Mahdavi-Amiri*

Main category: cs.GR

TL;DR: RoPE频率结构分析揭示共享注意力机制导致参考复制的原因，提出选择性调制RoPE频率带的方法，实现风格对齐生成

- Motivation: 理解RoPE在多模态和共享注意力设置中的行为，解决共享注意力机制中出现的参考复制问题（模型复制参考内容而非提取风格线索）
- Method: 对RoPE进行原理性分析，发现其自然分解为具有不同位置敏感性的频率分量；提出选择性调制RoPE频率带的方法，使注意力反映语义相似性而非严格位置对齐
- Result: 高频RoPE分量主导注意力计算，导致查询主要关注空间对齐的参考标记，从而引发意外复制行为；调制方法恢复稳定有意义的共享注意力，实现有效的风格转移控制
- Conclusion: 通过选择性调制RoPE频率带，可以在现代基于transformer的扩散架构中实现适当的风格对齐生成过程，转移风格属性而不复制参考内容


### [109] [Gabor Fields: Orientation-Selective Level-of-Detail for Volume Rendering](https://arxiv.org/abs/2602.05081)
*Jorge Condor,Nicolai Hermann,Mehmet Ata Yurtsever,Piotr Didyk*

Main category: cs.GR

TL;DR: 提出Gabor Fields，一种基于Gabor核的方向选择性混合表示，用于解决高斯体表示在层次化细节和频率过滤方面的不足，实现连续频率过滤并加速渲染。

- Motivation: 高斯体表示虽然内存效率高，但缺乏像传统体素网格那样容易构建层次化表示的能力。现有解决方案要么增加内存需求，要么需要昂贵的重新拟合，且不能保证不同层次间的平滑过渡。
- Method: 提出Gabor Fields，使用方向选择性混合的Gabor核，支持连续频率过滤而无需额外成本。通过选择性剪枝基元来减少频率内容，并通过在不同频率和方向上随机采样来加速光线遍历。
- Result: 实现了高效的频率过滤，加速了渲染性能，特别是在单次和多次散射场景中。还展示了在程序化云朵设计和渲染中的应用。
- Conclusion: Gabor Fields解决了高斯体表示在层次化细节和频率过滤方面的关键限制，提供了一种高效、内存友好的解决方案，并展示了在程序化体积内容创建中的实际应用价值。
## cs.MM

### [110] [XEmoGPT: An Explainable Multimodal Emotion Recognition Framework with Cue-Level Perception and Reasoning](https://arxiv.org/abs/2602.05496)
*Hanwen Zhang,Yao Liu,Peiyuan Jiang,Lang Junjie,Xie Jun,Yihui He,Yajiao Deng,Siyu Du,Qiao Liu*

Main category: cs.MM

TL;DR: 提出XEmoGPT框架，通过专门模块增强多模态情感线索感知，构建大规模数据集支持线索级推理，并引入新的评估指标

- Motivation: 当前多模态情感识别方法存在两个主要挑战：1)通用模态编码器对细粒度情感线索不敏感；2)数据集在标注质量和规模之间存在权衡，导致情感线索监督不足。现有评估指标也无法有效评估线索级推理性能。
- Method: 提出XEmoGPT框架，包含视频情感线索桥(VECB)和音频情感线索桥(AECB)两个专门模块，通过精心设计的任务增强视频和音频编码器的细粒度情感线索感知能力。构建大规模数据集EmoCue支持线索级推理训练。
- Result: 实验结果表明XEmoGPT在情感线索感知和推理方面都取得了强劲性能。同时发布了EmoCue-360评估指标和EmoCue-Eval基准测试集。
- Conclusion: XEmoGPT通过专门的情感线索感知模块和大规模数据集，有效解决了多模态情感识别中的线索级感知和推理问题，为可解释情感识别提供了新框架。
## physics.geo-ph

### [111] [A General-Purpose Diversified 2D Seismic Image Dataset from NAMSS](https://arxiv.org/abs/2602.04890)
*Lucas de Magalhães Araujo,Otávio Oliveira Napoli,Sandra Avila,Edson Borin*

Main category: physics.geo-ph

TL;DR: Unicamp-NAMSS是一个大规模、多样化、地理分布广泛的2D地震剖面数据集，用于支持地球物理领域的机器学习研究。

- Motivation: 为地球物理机器学习研究提供高质量、多样化的数据集，现有数据集（如Parihaka和F3 Block）覆盖范围有限，无法充分代表不同地质和采集条件下的地震数据变异性。
- Method: 从国家海洋地震调查档案（NAMSS）收集公开海洋地震数据，经过全面收集和过滤处理，获得2588个清理和标准化的地震剖面，覆盖122个调查区域。采用区域不相交的分割方法，将数据集划分为训练、验证和测试集。
- Result: 数据集展示了区域内部和跨区域的显著变异性，同时在采集大区域和调查类型间保持连贯结构。与现有数据集相比，Unicamp-NAMSS覆盖了更广泛的地震外观空间，适合机器学习模型预训练。
- Conclusion: Unicamp-NAMSS数据集为机器学习任务提供了宝贵资源，包括自监督表示学习、迁移学习、超分辨率或属性预测等监督任务的基准测试，以及地震解释中的领域适应研究。
## cs.CE

### [112] [Rule-Based Spatial Mixture-of-Experts U-Net for Explainable Edge Detection](https://arxiv.org/abs/2602.05100)
*Bharadwaj Dogga,Kaaustaaub Shankar,Gibin Raju,Wilhelm Louw,Kelly Cohen*

Main category: cs.CE

TL;DR: 提出Rule-Based Spatial Mixture-of-Experts U-Net (sMoE U-Net)，结合深度学习与可解释逻辑，在边缘检测任务中实现高性能同时提供像素级可解释性。

- Motivation: 当前深度学习边缘检测模型（如U-Net）虽然性能优秀，但决策过程不透明，在安全关键应用中缺乏可验证性，需要将高性能深度学习与可解释逻辑相结合。
- Method: 提出sMoE U-Net架构：1) 在解码器跳跃连接中引入空间自适应专家混合块，根据局部特征统计动态选择"上下文"（平滑）和"边界"（锐利）专家；2) 用TSK模糊头替换标准分类层，使用显式IF-THEN规则融合深度语义特征与启发式边缘信号。
- Result: 在BSDS500基准测试中达到ODS F-score 0.7628，与纯深度基线HED（0.7688）相当，优于标准U-Net（0.7437），同时提供像素级可解释性。
- Conclusion: sMoE U-Net成功将高性能深度学习与可解释逻辑结合，在保持边缘检测性能的同时提供决策透明度，通过"规则触发图"和"策略图"实现可视化解释，适用于安全关键应用。
## quant-ph

### [113] [QuantumGS: Quantum Encoding Framework for Gaussian Splatting](https://arxiv.org/abs/2602.05047)
*Grzegorz Wilczyński,Rafał Tobiasz,Paweł Gora,Marcin Mazur,Przemysław Spurek*

Main category: quant-ph

TL;DR: QuantumGS：将变分量子电路集成到3D高斯溅射中，通过将视角方向映射到布洛赫球面来提升高频视角相关效果的渲染质量

- Motivation: 传统3D高斯溅射使用球谐函数难以准确捕捉高频视角相关效果（如锐利反射和透明度），而现有混合方法受限于经典网络在低参数量下的表达能力
- Method: 提出一种混合框架，将变分量子电路集成到高斯溅射流程中，采用独特的编码策略将视角方向直接映射到布洛赫球面，用超网络或条件机制生成的量子电路替代经典颜色调制网络
- Result: 实现了更高的表达能力和更好的泛化性能，能够更准确地渲染高频视角相关效果
- Conclusion: QuantumGS通过量子电路与神经渲染的结合，为3D高斯溅射提供了更强大的视角相关效果渲染能力，代码已开源
## cs.RO

### [114] [Differentiable Inverse Graphics for Zero-shot Scene Reconstruction and Robot Grasping](https://arxiv.org/abs/2602.05029)
*Octavio Arriaga,Proneet Sharma,Jichen Guo,Marc Otto,Siddhant Kadwe,Rebecca Adam*

Main category: cs.RO

TL;DR: 提出一种可微分神经图形模型，结合神经基础模型与基于物理的可微分渲染，实现零样本场景重建与机器人抓取，无需额外3D数据或测试时采样。

- Motivation: 现有方法依赖大量训练数据和测试时采样构建黑盒场景表示，缺乏数据效率和可解释性。需要在未见环境中实现零样本、物理一致的场景理解与交互。
- Method: 结合神经基础模型与物理可微分渲染，通过约束优化问题从单张RGBD图像和边界框估计物理一致的场景参数（网格、光照、材质、6D位姿）。
- Result: 在标准模型无关少样本基准测试中超越现有算法，零样本抓取任务验证了场景重建的准确性，实现更数据高效、可解释和泛化的机器人自主性。
- Conclusion: 该方法为在未见环境中实现零样本、物理一致的场景重建与抓取提供了新途径，减少对大数据集和测试时采样的依赖，推动机器人自主性的发展。


### [115] [VLN-Pilot: Large Vision-Language Model as an Autonomous Indoor Drone Operator](https://arxiv.org/abs/2602.05552)
*Bessie Dominguez-Dager,Sergio Suescun-Ferrandiz,Felix Escalona,Francisco Gomez-Donoso,Miguel Cazorla*

Main category: cs.RO

TL;DR: VLN-Pilot是一个利用大型视觉语言模型作为无人机室内导航"飞行员"的框架，通过自然语言指令和视觉感知实现自主导航，无需GPS。

- Motivation: 传统基于规则或几何路径规划的无人机导航方法需要大量任务特定工程，缺乏语义理解和上下文感知能力。室内GPS受限环境需要更智能、更人性化的控制方式。
- Method: 使用大型视觉语言模型作为核心"飞行员"，通过多模态推理能力解释自由形式的自然语言指令，并将其与视觉观察相结合，规划并执行无人机轨迹。框架集成了语言驱动的语义理解和视觉感知。
- Result: 在自定义的逼真室内仿真基准测试中，VLLM驱动的智能体在复杂指令跟随任务上实现了高成功率，包括具有多个语义目标的长期导航。能够处理空间关系推理、避障和动态事件响应。
- Conclusion: VLLM为基础的飞行员有望替代远程无人机操作员，显著减少操作员工作量，同时提高室内受限环境中的安全性和任务灵活性，为检查、搜救、设施监控等任务提供可扩展、人性化的无人机控制方案。


### [116] [CommCP: Efficient Multi-Agent Coordination via LLM-Based Communication with Conformal Prediction](https://arxiv.org/abs/2602.06038)
*Xiaopan Zhang,Zejin Wang,Zhixu Li,Jianpeng Yao,Jiachen Li*

Main category: cs.RO

TL;DR: 提出CommCP框架，一个基于LLM的去中心化通信系统，用于多智能体多任务具身问答（MM-EQA）问题，通过保形预测校准消息以减少干扰并提高通信可靠性。

- Motivation: 现实世界中机器人需要协作完成人类自然语言指令，但现有研究缺乏对多智能体多任务具身问答（MM-EQA）中有效信息收集和通信协调的系统性解决方案。
- Method: 提出CommCP框架：1）将MM-EQA形式化为新的多智能体多任务具身问答问题；2）采用基于LLM的去中心化通信架构；3）使用保形预测（conformal prediction）校准生成的消息，减少接收者分心并提高通信可靠性。
- Result: 在提出的MM-EQA基准测试中，CommCP显著提高了任务成功率和探索效率，优于基线方法。实验视频、代码和数据集已公开。
- Conclusion: CommCP框架有效解决了多智能体协作中的通信协调问题，为异构机器人协作完成复杂任务提供了可靠的通信解决方案。
## cs.CY

### [117] [Ethology of Latent Spaces](https://arxiv.org/abs/2602.05710)
*Philippe Boisnard*

Main category: cs.CY

TL;DR: 该研究挑战了视觉语言模型潜在空间的中立性假设，通过比较分析发现不同模型在政治和文化分类上存在显著差异，揭示了算法敏感性和新兴偏见。

- Motivation: 挑战视觉语言模型中潜在空间的中立性假设，揭示模型训练数据和架构选择如何塑造不同的感知显著性机制，从而影响对艺术品的政治和文化解读。
- Method: 采用比较分析方法，研究三个模型（OpenAI CLIP、OpenCLIP LAION、SigLIP）对301件15-20世纪艺术品的分类。使用源自向量类比的双极语义轴，量化模型在政治和文化分类上的差异。
- Result: 发现模型间存在显著差异：SigLIP将59.4%艺术品归类为政治参与，而OpenCLIP仅4%。非洲面具在SigLIP中获得最高政治分数，在OpenAI CLIP中保持非政治。在美学殖民轴上，模型间差异达72.6个百分点。
- Conclusion: 提出三个操作概念：计算潜在政治化、新兴偏见和三种算法视觉机制。训练数据集作为准档案，其话语形态在潜在空间中结晶。呼吁在数字艺术史应用中批判性重新评估VLM条件，并将学习架构整合到文化解释的算法代理中。
## cs.LG

### [118] [Temporal Pair Consistency for Variance-Reduced Flow Matching](https://arxiv.org/abs/2602.04908)
*Chika Maduabuchi,Jindong Wang*

Main category: cs.LG

TL;DR: TPC是一种轻量级方差降低方法，通过耦合同一概率路径上配对时间步的速度预测，减少生成模型训练中的梯度方差，提升采样效率

- Motivation: 连续时间生成模型（如扩散模型、流匹配）通常使用独立时间步目标训练，导致估计器方差高、采样效率低。现有方法通过显式平滑惩罚、轨迹正则化或修改概率路径来缓解，但需要修改模型架构或训练流程
- Method: 提出时间对一致性（TPC）原则，在估计器层面耦合同一概率路径上配对时间步的速度预测，不修改模型架构、概率路径或求解器。理论分析表明TPC引入二次轨迹耦合正则化，降低梯度方差同时保持流匹配目标
- Result: 在CIFAR-10和ImageNet多个分辨率上，TPC在相同或更低计算成本下获得更低的FID分数，提升样本质量和效率。可无缝扩展到现代SOTA风格流程，包括噪声增强训练、基于分数的去噪和整流流
- Conclusion: TPC是一种有效的轻量级方差降低方法，通过时间对一致性耦合改进连续时间生成模型的训练效率和样本质量，无需修改底层架构或训练流程


### [119] [Extreme Weather Nowcasting via Local Precipitation Pattern Prediction](https://arxiv.org/abs/2602.05204)
*Changhoon Song,Teng Yuan Chang,Youngjoon Hong*

Main category: cs.LG

TL;DR: exPreCast：一种用于雷达降水临近预报的高效确定性框架，结合平衡数据集，在普通和极端降雨情况下均实现最先进性能

- Motivation: 降水临近预报面临空间局部性强、精细结构复杂、预报时变性强等挑战。现有扩散模型计算成本高不适合实时应用，确定性模型偏向普通降雨。现有基准数据集要么偏向普通降雨要么只关注极端事件，限制了实际应用。
- Method: 提出exPreCast框架：集成局部时空注意力机制、纹理保持立方双上采样解码器和时间提取器，可灵活调整预报时效。同时构建了韩国气象厅的平衡雷达数据集，包含普通降水和极端事件。
- Result: 在SEVIR、MeteoNet和新建的KMA平衡数据集上的实验表明，该方法实现了最先进的性能，在普通和极端降雨情况下都能提供准确可靠的临近预报。
- Conclusion: exPreCast框架通过高效确定性方法和平衡数据集，解决了降水临近预报中的计算效率和极端事件预报难题，为实际应用提供了可靠解决方案。


### [120] [Erase at the Core: Representation Unlearning for Machine Unlearning](https://arxiv.org/abs/2602.05375)
*Jaewon Lee,Yongwoo Kim,Donghyun Kim*

Main category: cs.LG

TL;DR: 论文提出EC框架解决机器学习遗忘中的表面遗忘问题，通过在网络各层实施对比遗忘和深度监督学习，实现真正的特征级遗忘。

- Motivation: 现有机器学习遗忘方法主要改变最终分类器，但中间层特征表示基本保持不变，导致"表面遗忘"问题——虽然logit层面看似遗忘，但特征层面仍保留大量信息。
- Method: 提出Erase at the Core (EC)框架：1) 在网络中间层附加辅助模块；2) 在每层应用对比遗忘损失（针对遗忘集）和交叉熵损失（针对保留集）；3) 使用分层加权损失；4) 可作为插件集成到现有遗忘方法中。
- Result: EC不仅实现有效的logit级遗忘，还显著降低中间层与原始模型的表示相似性，同时保持保留集性能。框架模型无关，能提升现有方法的表示级遗忘效果。
- Conclusion: EC框架解决了机器学习遗忘中的表面遗忘问题，通过在网络各层次强制遗忘，实现了真正的特征级遗忘，同时保持模型在保留集上的性能。


### [121] [When Shared Knowledge Hurts: Spectral Over-Accumulation in Model Merging](https://arxiv.org/abs/2602.05536)
*Yayuan Li,Ze Peng,Jian Zhang,Jintao Guo,Yue Duan,Yinghuan Shi*

Main category: cs.LG

TL;DR: 提出SVC方法，通过校准奇异值来解决模型合并中的共享知识重复计数问题，提升合并性能

- Motivation: 现有模型合并方法主要解决任务更新间的冲突，但忽略了共享知识重复计数的问题。当任务共享对齐的谱方向时，简单的线性组合会重复累积这些方向，导致奇异值膨胀并偏向共享子空间
- Method: 提出奇异值校准(SVC)方法，这是一种无需训练和数据的后处理技术。通过量化子空间重叠并重新缩放膨胀的奇异值，恢复平衡的谱分布
- Result: 在视觉和语言基准测试中，SVC持续改进强大的合并基线并达到最先进性能。通过仅修改奇异值，SVC将Task Arithmetic的性能提升了13.0%
- Conclusion: SVC有效解决了模型合并中的共享知识重复计数问题，通过谱校准显著提升了合并模型的性能，为模型合并提供了新的优化方向


### [122] [Shiva-DiT: Residual-Based Differentiable Top-$k$ Selection for Efficient Diffusion Transformers](https://arxiv.org/abs/2602.05605)
*Jiaji Zhang,Hailiang Zhao,Guoxuan Zhu,Ruichao Sun,Jiaju Wu,Xinkui Zhao,Hanlin Tang,Weiyi Lu,Kan Liu,Tao Lan,Lin Qu,Shuiguang Deng*

Main category: cs.LG

TL;DR: Shiva-DiT：一种用于扩散变换器的高效剪枝方法，通过残差感知的Top-k选择实现确定性token计数，消除不规则张量开销，在保持保真度的同时获得1.54倍加速。

- Motivation: 扩散变换器（DiTs）由于自注意力的二次计算复杂度导致计算成本过高。现有的剪枝方法无法同时满足可微性、效率和硬件所需的严格静态预算要求。
- Method: 提出Shiva-DiT方法：1）残差感知可微Top-k选择，通过残差感知直通估计器实现确定性token计数；2）上下文感知路由器和自适应比率策略，自动学习自适应剪枝调度。
- Result: 在包括SD3.5在内的主流模型上实验表明，Shiva-DiT建立了新的帕累托前沿，实现了1.54倍的实际时钟加速，同时保持优于现有基线的保真度，有效消除了不规则张量开销。
- Conclusion: Shiva-DiT成功解决了扩散变换器剪枝中可微性、效率和静态预算之间的冲突，为高效扩散模型提供了有效的解决方案。


### [123] [Pseudo-Invertible Neural Networks](https://arxiv.org/abs/2602.06042)
*Yamit Ehrlich,Nimrod Berman,Assaf Shocher*

Main category: cs.LG

TL;DR: 提出非线性伪逆（PInv）的泛化，引入可逆神经网络SPNN，实现非线性反向投影，扩展零样本逆问题求解到非线性退化场景

- Motivation: 传统Moore-Penrose伪逆仅适用于线性系统，无法处理非线性映射。需要将伪逆概念推广到非线性领域，特别是神经网络，以解决更广泛的逆问题
- Method: 提出Surjective Pseudo-invertible Neural Networks (SPNN)，设计具有可计算非线性伪逆的架构。定义非线性反向投影（NLBP），保证非线性映射的一致性约束
- Result: SPNN满足基本几何性质，如零空间投影。将基于扩散的零空间投影方法扩展到非线性退化，实现复杂退化的零样本反演，无需重新训练扩散先验
- Conclusion: 成功将伪逆概念从线性推广到非线性领域，SPNN为非线性逆问题提供了理论框架和实用工具，扩展了零样本逆问题的应用范围


### [124] [Shared LoRA Subspaces for almost Strict Continual Learning](https://arxiv.org/abs/2602.06043)
*Prakhar Kaushik,Ankit Vaidya,Shravan Chaudhari,Rama Chellappa,Alan Yuille*

Main category: cs.LG

TL;DR: Share是一种参数高效的持续微调方法，通过学习和动态更新单个共享低秩子空间，实现跨任务和模态的无缝适应，相比传统LoRA方法减少100倍参数和281倍内存使用。

- Motivation: 大型预训练模型需要高效持续适应新任务，但面临灾难性遗忘和高昂重训练成本的问题。现有参数高效调优方法（如LoRA）缺乏严格的持续学习机制，无法在不依赖数据回放或多适配器的情况下实现知识整合。
- Method: Share构建一个基础子空间从过去任务中提取核心知识，通过识别关键子空间方向增量整合新信息。每个新任务的知识都被纳入这个演化的共享子空间，促进前向知识转移，同时最小化灾难性干扰。
- Result: Share实现了相比传统LoRA方法100倍的参数减少和281倍的内存节省，性能与联合训练模型相当。单个Share模型可以替代数百个任务特定的LoRA适配器，支持可扩展的异步持续学习。
- Conclusion: Share是一种实用且可扩展的解决方案，适用于大规模AI系统中的终身学习，在图像分类、自然语言理解、3D姿态估计和文本到图像生成等任务中验证了其有效性。
## cs.AI

### [125] [M$^2$-Miner: Multi-Agent Enhanced MCTS for Mobile GUI Agent Data Mining](https://arxiv.org/abs/2602.05429)
*Rui Lv,Juncheng Mo,Tianyi Chu,Chen Rao,Hongyi Jing,Jiajie Teng,Jiafu Chen,Shiqi Zhang,Liangzi Ding,Shuo Fang,Huaizhong Lin,Ziqiang Dang,Chenguang Ma,Lei Zhao*

Main category: cs.AI

TL;DR: M²-Miner：基于蒙特卡洛树搜索的低成本自动化移动GUI代理数据挖掘框架，通过多智能体协作和意图回收策略生成高质量用户行为轨迹数据，显著提升GUI代理性能

- Motivation: 构建强大的GUI代理需要大规模高质量的用户行为轨迹数据（意图-轨迹对）进行训练。当前手动标注方法和GUI代理数据挖掘方法面临三大挑战：高构建成本、数据质量差、数据丰富度低
- Method: 提出M²-Miner框架：1）基于蒙特卡洛树搜索的低成本自动化数据挖掘；2）协作多智能体框架（InferAgent指导、OrchestraAgent加速、JudgeAgent评估）；3）意图回收策略提取额外有价值的交互轨迹；4）渐进式模型在环训练策略提升数据挖掘成功率
- Result: 实验表明，使用M²-Miner挖掘的数据微调的GUI代理在多个常用移动GUI基准测试中达到了最先进的性能
- Conclusion: M²-Miner是首个低成本自动化的移动GUI代理数据挖掘框架，能高效生成高质量、多样化的用户行为轨迹数据，显著提升GUI代理性能，将开源以促进社区研究


### [126] [Refine and Purify: Orthogonal Basis Optimization with Null-Space Denoising for Conditional Representation Learning](https://arxiv.org/abs/2602.05464)
*Jiaquan Wang,Yan Lyu,Chen Li,Yuheng Jia*

Main category: cs.AI

TL;DR: 提出OD-CRL框架，通过自适应正交基优化和零空间去噪投影解决条件表示学习中基向量敏感性和子空间干扰问题，在多个定制化任务中达到SOTA性能。

- Motivation: 现有条件表示学习方法将通用特征投影到LLM生成的文本基向量张成的条件特征子空间，但面临两个关键限制：对子空间基向量的敏感性，以及子空间间干扰的脆弱性。
- Method: 提出OD-CRL框架，包含两个核心组件：1) 自适应正交基优化(AOBO)：通过奇异值分解和基于曲率的截断构建正交语义基向量；2) 零空间去噪投影(NSDP)：通过将嵌入投影到无关子空间的零空间来抑制非目标语义干扰。
- Result: 在定制化聚类、定制化分类和定制化检索任务上进行了广泛实验，OD-CRL实现了新的最先进性能，并展现出优越的泛化能力。
- Conclusion: OD-CRL通过解决基向量敏感性和子空间干扰问题，显著提升了条件表示学习的性能，为定制化任务提供了有效的解决方案。
## eess.IV

### [127] [Context-Aware Asymmetric Ensembling for Interpretable Retinopathy of Prematurity Screening via Active Query and Vascular Attention](https://arxiv.org/abs/2602.05208)
*Md. Mehedi Hassan,Taufiq Hasan*

Main category: eess.IV

TL;DR: 提出CAA Ensemble模型，通过模拟临床推理的双流架构解决ROP自动筛查中的数据稀缺和复杂病变问题，在ROP分期和Plus病检测上达到SOTA性能。

- Motivation: ROP是儿童可预防性失明的主要原因，自动筛查面临数据稀缺、病变复杂（结构分期+微血管异常）的挑战。现有深度学习模型依赖大型私有数据集和被动多模态融合，在小型不平衡公共数据集上泛化能力差。
- Method: 提出上下文感知非对称集成模型(CAA Ensemble)：1) MS-AQNet作为结构专家，使用临床上下文作为动态查询向量进行空间控制特征提取，定位纤维血管嵴；2) VascuMIL编码血管拓扑图(VMAP)在门控多实例学习网络中精确识别血管迂曲；3) 协同元学习器集成这些正交信号解决多目标诊断不一致。
- Result: 在188名婴儿（6,004张图像）的高度不平衡队列上测试，在两项临床任务上达到SOTA：ROP分期Macro F1-Score 0.93，Plus病检测AUC 0.996。系统具有"玻璃盒"透明度，通过反事实注意力热图和血管威胁图展示临床元数据指导视觉搜索。
- Conclusion: CAA Ensemble通过模拟临床推理的双流架构有效解决ROP筛查挑战，证明架构归纳偏置可以作为医学AI数据鸿沟的有效桥梁，同时提供可解释性。


### [128] [Towards Segmenting the Invisible: An End-to-End Registration and Segmentation Framework for Weakly Supervised Tumour Analysis](https://arxiv.org/abs/2602.05453)
*Budhaditya Mukhopadhyay,Chirag Mandal,Pavan Tummala,Naghmeh Mahmoodian,Andreas Nürnberger,Soumick Chatterjee*

Main category: eess.IV

TL;DR: 该研究探索跨模态弱监督在肝脏肿瘤消融中的应用，提出结合配准与分割的混合框架，但发现当目标模态（CT）中肿瘤缺乏可见特征时，现有配准方法存在根本性限制。

- Motivation: 肝脏肿瘤在术前MRI中清晰可见，但在术中CT中由于病理组织与健康组织对比度低而几乎不可见。本研究旨在探索跨模态弱监督的可行性，解决一种模态（MRI）可见而另一种模态（CT）不可见的病理检测问题。
- Method: 提出混合配准-分割框架：使用MSCGUNet进行跨模态图像配准，结合UNet分割模块，通过配准辅助生成CT图像的伪标签，实现从MRI到CT的标签传播。
- Result: 在CHAOS数据集上，该框架能成功配准和分割健康肝脏解剖结构（Dice分数0.72）。但在包含肿瘤的临床数据上性能大幅下降（Dice分数0.16），揭示了当目标病理在目标模态中缺乏对应视觉特征时，当前配准方法的根本局限性。
- Conclusion: 研究发现配准基础的标签传播对于可见结构可行，但分割真正不可见的病理仍是一个开放挑战。配准无法补偿目标模态中判别性特征的缺失，为未来跨模态医学图像分析研究提供了重要见解。


### [129] [Disc-Centric Contrastive Learning for Lumbar Spine Severity Grading](https://arxiv.org/abs/2602.05738)
*Sajjan Acharya,Pralisha Kansakar*

Main category: eess.IV

TL;DR: 提出基于椎间盘中心的腰椎管狭窄症自动严重程度分级方法，结合对比预训练和椎间盘级微调，使用单个解剖定位的感兴趣区域，在平衡准确率和严重-正常误分类率上表现优异

- Motivation: 传统腰椎管狭窄症严重程度分级方法可能受图像外观无关差异影响，需要更专注于椎间盘特征的方法来准确评估狭窄程度
- Method: 采用对比预训练帮助模型聚焦有意义的椎间盘特征，减少对图像外观无关差异的敏感性；结合椎间盘级微调，每个椎间盘使用单个解剖定位的感兴趣区域；包含椎间盘定位的辅助回归任务，并应用加权焦点损失处理类别不平衡
- Result: 达到78.1%的平衡准确率，严重到正常的误分类率降至2.13%，相比从头开始的监督训练有明显改进
- Conclusion: 专注于椎间盘级特征为腰椎管狭窄症评估提供了实用方法，虽然中度严重程度的椎间盘检测仍有挑战，但该方法在准确率和误分类率方面表现优异
