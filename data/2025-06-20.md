[[toc]]

## cs.CV

### [1] [SemIRNet: A Semantic Irony Recognition Network for Multimodal Sarcasm Detection](https://arxiv.org/abs/2506.14791)
*Jingxuan Zhou,Yuehao Wu,Yibo Zhang,Yeyubei Zhang,Yunchong Liu,Bolin Huang,Chunhong Yuan*

Main category: cs.CV

TL;DR: 本文提出了一种语义讽刺识别网络（SemIRNet），通过引入ConceptNet知识库、设计跨模态语义相似性检测模块以及对比学习损失函数，显著提高了多模态讽刺检测任务的性能。

- Motivation: 解决多模态讽刺检测任务中图形隐式关联难以准确识别的问题。
- Method: 1. 引入ConceptNet知识库增强常识推理能力；2. 设计词级和样本级跨模态语义相似性检测模块；3. 使用对比学习损失函数优化样本特征空间分布。
- Result: 在公开数据集上，准确率和F1值分别提升1.64%和2.88%，达到88.87%和86.33%。
- Conclusion: 知识融合和语义相似性检测对提升模型性能具有重要作用。


### [2] [Argus Inspection: Do Multimodal Large Language Models Possess the Eye of Panoptes?](https://arxiv.org/abs/2506.14805)
*Yang Yao,Lingyu Li,Jiaxin Song,Chiyu Chen,Zhenqi He,Yixu Wang,Xin Wang,Tianle Gu,Jie Li,Yan Teng,Yingchun Wang*

Main category: cs.CV

TL;DR: 该论文提出了Argus Inspection多模态基准和Eye of Panoptes框架，用于评估MLLMs在细粒度视觉感知和常识因果推理方面的能力，实验显示当前模型的性能仍有较大提升空间。

- Motivation: 随着MLLMs的发展，其在认知和推理能力上取得显著进展，但在细粒度视觉感知和常识因果推理方面仍存在挑战。
- Method: 引入Argus Inspection多模态基准和Eye of Panoptes框架，结合二进制参数Sigmoid度量与指示函数，全面评估MLLMs的推理能力。
- Result: 在26个主流MLLMs上的实验表明，视觉细粒度推理的最高性能仅为0.46，显示模型仍有较大改进空间。
- Conclusion: 研究为MLLMs的进一步优化提供了有价值的视角。


### [3] [A Hybrid ConvNeXt-EfficientNet AI Solution for Precise Falcon Disease Detection](https://arxiv.org/abs/2506.14816)
*Alavikunhu Panthakkan,Zubair Medammal,S M Anzar,Fatma Taher,Hussain Al-Ahmad*

Main category: cs.CV

TL;DR: 本文提出了一种结合ConvNeXt和EfficientNet的混合AI模型，用于准确分类猎鹰疾病，优于传统方法。

- Motivation: 猎鹰训练和狩猎中需要精确的健康监测，传统诊断方法存在不足。
- Method: 采用ConvNeXt和EfficientNet的混合模型，专注于识别正常、肝病和曲霉病。
- Result: 模型在准确性、精确度、召回率和F1分数上表现优异，优于传统方法。
- Conclusion: 该混合AI模型为猎鹰疾病检测提供了新方向，推动了AI在禽类健康领域的应用。


### [4] [ViLLa: A Neuro-Symbolic approach for Animal Monitoring](https://arxiv.org/abs/2506.14823)
*Harsha Koduri*

Main category: cs.CV

TL;DR: ViLLa是一个神经符号框架，用于可解释的动物监测，结合视觉检测、语言解析和符号推理，回答自然语言查询。

- Motivation: 开发一个透明且模块化的系统，能够结合视觉数据和语言查询来监测动物种群。
- Method: ViLLa包括视觉检测模块、语言解析器和符号推理层，通过逻辑推理回答查询。
- Result: 系统在动物图像任务中表现良好，能够将视觉内容与结构化查询结合。
- Conclusion: ViLLa提供了一种透明且模块化的方法，适用于动物监测任务。


### [5] [GraphGSOcc: Semantic and Geometric Graph Transformer for 3D Gaussian Splating-based Occupancy Prediction](https://arxiv.org/abs/2506.14825)
*Ke Song,Yunhe Wu,Chunchit Siu,Huiyuan Xiong*

Main category: cs.CV

TL;DR: 论文提出GraphGSOcc模型，通过结合语义和几何图Transformer改进3D高斯泼溅方法，解决特征聚合和边界模糊问题。

- Motivation: 现有3D高斯泼溅方法在特征聚合中忽略语义相关性，且边界模糊问题严重。
- Method: 提出Dual Gaussians Graph Attention，动态构建几何图和语义图，结合多尺度注意力框架优化边界和拓扑。
- Result: 在SurroundOcc数据集上mIoU达24.10%，GPU内存降至6.1GB，性能提升1.97%，内存减少13.7%。
- Conclusion: GraphGSOcc有效提升了3D语义占用预测的性能和效率。


### [6] [DAVID-XR1: Detecting AI-Generated Videos with Explainable Reasoning](https://arxiv.org/abs/2506.14827)
*Yifeng Gao,Yifan Ding,Hongyu Su,Juncheng Li,Yunhan Zhao,Lin Luo,Zixing Chen,Li Wang,Xin Wang,Yixu Wang,Xingjun Ma,Yu-Gang Jiang*

Main category: cs.CV

TL;DR: 论文提出DAVID-X数据集和DAVID-XR1模型，用于透明、可解释地检测AI生成视频，并提供细粒度的缺陷分类、时空定位和自然语言解释。

- Motivation: 随着AI生成视频在媒体平台上的普及，可靠区分合成内容与真实视频变得紧迫且必要。现有方法仅将其视为二分类任务，缺乏对检测过程的深入解释。
- Method: 引入DAVID-X数据集，包含AI生成视频的详细缺陷注释和书面解释；提出DAVID-XR1模型，结合视觉推理链（缺陷分类、时空定位和自然语言解释）实现透明检测。
- Result: 实验表明，基于通用骨干网络并在紧凑数据集上微调的模型，通过思维链蒸馏增强，能泛化到多种生成器和生成模式。
- Conclusion: 可解释的检测方法为AI生成视频的可信识别提供了前景，将检测从黑盒决策转变为透明、可验证的诊断过程。


### [7] [Recent Advances in Multi-Agent Human Trajectory Prediction: A Comprehensive Review](https://arxiv.org/abs/2506.14831)
*Céline Finet,Stephane Da Silva Martins,Jean-Bernard Hayet,Ioannis Karamouzas,Javad Amirian,Sylvie Le Hégarat-Mascle,Julien Pettré,Emanuel Aldea*

Main category: cs.CV

TL;DR: 本文综述了2020至2024年间基于深度学习的多智能体轨迹预测的最新进展，重点分析了ETH/UCY基准测试中的模型，并探讨了该领域的关键挑战与未来研究方向。

- Motivation: 随着数据驱动方法在人类轨迹预测中的发展，深入理解多智能体交互成为可能，这对自主导航和人群建模等领域具有重要意义。
- Method: 通过分类现有方法的架构设计、输入表示和预测策略，重点分析了ETH/UCY基准测试中的模型。
- Result: 总结了多智能体轨迹预测的最新进展，并识别了关键挑战。
- Conclusion: 提出了未来研究的方向，强调了多智能体轨迹预测领域的潜力与挑战。


### [8] [ArchShapeNet:An Interpretable 3D-CNN Framework for Evaluating Architectural Shapes](https://arxiv.org/abs/2506.14832)
*Jun Yin,Jing Zhong,Pengyu Zeng,Peilin Li,Zixuan Dai,Miao Zhang,Shuai Lu*

Main category: cs.CV

TL;DR: 论文提出ArchForms-4000数据集和ArchShapeNet模型，用于区分人类设计与机器生成的3D建筑形式，模型表现优于人类专家。

- Motivation: 当代建筑设计需求复杂多样，生成工具快速生成初始概念和探索新3D形式的能力至关重要，但缺乏对人类设计与机器生成形式的客观分析。
- Method: 构建ArchForms-4000数据集（2000人类设计+2000机器生成），提出ArchShapeNet（3D卷积神经网络，含显著性模块），并进行比较实验。
- Result: 模型在区分形式来源上表现优异（准确率94.29%，精确率96.2%，召回率98.51%），优于人类专家。
- Conclusion: 研究揭示了人类设计在空间组织、比例和谐及细节优化上的优势，为未来生成设计工具改进提供了宝贵见解。


### [9] [Real-Time, Low-Latency Surveillance Using Entropy-Based Adaptive Buffering and MobileNetV2 on Edge Devices](https://arxiv.org/abs/2506.14833)
*Poojashree Chandrashekar Pankaj M Sajjanar*

Main category: cs.CV

TL;DR: 提出了一种基于熵的自适应帧缓冲算法，结合MobileNetV2，在资源受限设备上实现高性能、低延迟的视频监控系统。

- Motivation: 针对资源受限环境（如嵌入式平台）设计高效、低延迟的视频监控系统，满足智能城市或嵌入式安全架构的需求。
- Method: 采用基于熵的自适应帧缓冲算法，并与MobileNetV2集成，优化处理速度和准确性。
- Result: 在Raspberry Pi等设备上实现端到端推理延迟低于50ms，检测准确率超过92%，且对光照、背景和速度变化具有鲁棒性。
- Conclusion: 该系统具有高性能、低成本、可扩展性，并符合严格的数据隐私法规，适用于智能城市或安全架构。


### [10] [MonoVQD: Monocular 3D Object Detection with Variational Query Denoising and Self-Distillation](https://arxiv.org/abs/2506.14835)
*Kiet Dang Vu,Trung Thai Tran,Duc Dung Nguyen*

Main category: cs.CV

TL;DR: MonoVQD是一个新颖的框架，通过改进DETR架构在单目3D检测中的性能，提出了三种主要贡献：掩码分离自注意力机制、变分查询去噪技术和自蒸馏策略。

- Motivation: 解决DETR架构在单目3D检测中的固有局限性，提升性能。
- Method: 1. 掩码分离自注意力机制；2. 变分查询去噪技术；3. 自蒸馏策略。
- Result: 在KITTI和nuScenes数据集上表现出色，具有广泛适用性和鲁棒性。
- Conclusion: MonoVQD显著提升了单目和多视角3D检测的性能，展示了其通用性。


### [11] [Improved Iterative Refinement for Chart-to-Code Generation via Structured Instruction](https://arxiv.org/abs/2506.14837)
*Chengzhi Xu,Yuyang Wang,Lai Wei,Lichao Sun,Weiran Huang*

Main category: cs.CV

TL;DR: 论文提出了一种基于结构化指令的迭代优化方法ChartIR，用于提升多模态大语言模型在图表到代码生成任务中的表现。

- Motivation: 当前多模态大语言模型在图表到代码生成任务中表现不佳，需要同时具备精确的视觉理解和准确的代码翻译能力。
- Method: 将任务分解为视觉理解和代码翻译两部分，设计描述和差异两种结构化指令，并将生成流程分为初始代码生成和迭代优化两个阶段。
- Result: 实验表明，ChartIR在开源模型Qwen2-VL和闭源模型GPT-4o上均优于其他方法。
- Conclusion: ChartIR通过结构化指令和迭代优化显著提升了图表到代码生成的性能。


### [12] [PictSure: Pretraining Embeddings Matters for In-Context Learning Image Classifiers](https://arxiv.org/abs/2506.14842)
*Lukas Schiesser,Cornelius Wolff,Sophie Haas,Simon Pukrop*

Main category: cs.CV

TL;DR: PictSure是一个专注于图像嵌入模型的ICL框架，通过分析不同视觉编码器、预训练目标和微调策略，显著提升了少样本图像分类的跨域性能。

- Motivation: 在数据稀缺领域，构建图像分类模型困难，现有ICL方法忽视了图像嵌入模型的关键作用。
- Method: 提出PictSure框架，系统研究视觉编码器类型、预训练目标和微调策略对少样本分类性能的影响。
- Result: 实验表明，嵌入模型的预训练方式显著影响训练成功率和跨域性能，PictSure在跨域任务中优于现有方法。
- Conclusion: PictSure通过优化嵌入模型，在跨域少样本分类任务中表现优异，同时保持域内任务的可比性能。


### [13] [Finding Optimal Kernel Size and Dimension in Convolutional Neural Networks An Architecture Optimization Approach](https://arxiv.org/abs/2506.14846)
*Shreyas Rajeev,B Sathish Babu*

Main category: cs.CV

TL;DR: 论文提出了一种名为BKSEF的框架，用于在CNN中动态选择最佳卷积核大小，显著提升模型精度并降低计算成本。

- Motivation: 卷积核大小在CNN设计中是关键但常被忽视的因素，影响感受野、特征提取、计算成本和模型精度。
- Method: BKSEF结合信息论、信号处理和学习理论，通过数学和实验验证的方法逐层确定最优核大小。
- Result: 在多个数据集上，BKSEF引导的模型比传统3x3核模型精度提升3.1%，计算量减少42.8%。
- Conclusion: BKSEF证明卷积核大小是可优化的参数，为高效和任务感知的CNN设计提供了理论和实践支持。


### [14] [Efficient Retail Video Annotation: A Robust Key Frame Generation Approach for Product and Customer Interaction Analysis](https://arxiv.org/abs/2506.14854)
*Varun Mannam,Zhenyu Shi*

Main category: cs.CV

TL;DR: 论文提出了一种基于深度学习的零售视频自动标注方法，通过关键帧识别和自动标注产品与顾客，显著提高了标注效率和成本效益。

- Motivation: 传统零售视频标注依赖人工，耗时且成本高，非鲁棒性帧选择问题突出，亟需自动化解决方案。
- Method: 利用深度神经网络学习视频帧的判别特征，结合针对零售环境优化的目标检测技术，实现关键帧自动识别和标注。
- Result: 实验表明，该方法在标注准确性上媲美人工标注，效率提升显著，平均节省50%成本，且仅需人工验证少于5%的帧。
- Conclusion: 该方法为零售视频标注提供了高效、低成本的自动化解决方案，适用于顾客行为分析、产品交互检测等多种场景。


### [15] [Peering into the Unknown: Active View Selection with Neural Uncertainty Maps for 3D Reconstruction](https://arxiv.org/abs/2506.14856)
*Zhengquan Zhang,Feng Xu,Mengmi Zhang*

Main category: cs.CV

TL;DR: 论文提出了一种基于神经不确定性映射的主动视角选择方法（UPNet），用于高效3D重建，显著减少计算开销并保持高精度。

- Motivation: 解决3D重建中如何选择最具信息量的视角以减少冗余计算并提高效率的问题。
- Method: 使用轻量级神经网络UPNet预测视角不确定性，通过聚合不确定性映射选择最优视角，用于训练3D神经渲染模型。
- Result: 方法仅需一半视角即可达到与上限相当的精度，计算速度提升400倍，资源消耗减少50%以上。
- Conclusion: UPNet方法在高效3D重建中表现出色，且无需额外训练即可泛化到新物体类别。


### [16] [DETONATE: A Benchmark for Text-to-Image Alignment and Kernelized Direct Preference Optimization](https://arxiv.org/abs/2506.14903)
*Renjith Prasad,Abhilekh Borah,Hasnat Md Abdullah,Chathurangi Shyalika,Gurpreet Singh,Ritvik Garimella,Rajarshi Roy,Harshul Surana,Nasrin Imanpour,Suranjana Trivedy,Amit Sheth,Amitava Das*

Main category: cs.CV

TL;DR: 论文提出DPO-Kernels方法，通过混合损失、核化表示和发散选择增强文本到图像模型的对齐性，并引入DETONATE基准和AQI指标。

- Motivation: 解决文本到图像模型在生成图像时如何更好地捕捉用户意图并确保安全性和公平性的问题。
- Method: 提出DPO-Kernels方法，包括混合损失、核化表示（RBF、多项式和小波核）和发散选择（Wasserstein和R'enyi发散）。
- Result: 构建了DETONATE基准（10万张图像对）和AQI指标，实验显示DPO-Kernels通过HT-SR保持强泛化能力。
- Conclusion: DPO-Kernels有效提升模型对齐性，DETONATE和AQI为研究提供了新工具。


### [17] [PeRL: Permutation-Enhanced Reinforcement Learning for Interleaved Vision-Language Reasoning](https://arxiv.org/abs/2506.14907)
*Yizhen Zhang,Yang Ding,Shuoshuo Zhang,Xinchen Zhang,Haoling Li,Zhong-zhi Li,Peijie Wang,Jie Wu,Lei Ji,Yelong Shen,Yujiu Yang,Yeyun Gong*

Main category: cs.CV

TL;DR: 论文提出了一种名为PeRL的强化学习方法，用于提升多模态推理任务中的视觉语言模型性能，特别是在多图像位置推理任务中表现出色。

- Motivation: 现有方法在单图像空间推理中表现有限，难以推广到涉及多图像位置关系的复杂场景，因此需要一种更通用的强化学习方法来应对这一挑战。
- Method: 提出PeRL方法，通过图像序列排列模拟多样位置关系，并设计多阶段策略和轨迹筛选机制以优化探索与利用的平衡。
- Result: 在5个多图像基准和3个单图像基准上，PeRL模型显著优于现有方法，达到多图像任务的最先进性能，同时在单图像任务中保持竞争力。
- Conclusion: PeRL为多模态强化学习提供了一种有效方法，显著提升了多图像位置推理任务的性能，同时保持了单图像任务的通用性。


### [18] [Frequency-Calibrated Membership Inference Attacks on Medical Image Diffusion Models](https://arxiv.org/abs/2506.14919)
*Xinkai Zhao,Yuta Tokuoka,Junichiro Iwasawa,Keita Oda*

Main category: cs.CV

TL;DR: 论文提出了一种频率校准重建误差（FCRE）方法，用于医学图像扩散模型的成员推断攻击（MIA），通过聚焦中频区域重建误差，显著提升了攻击效果。

- Motivation: 扩散模型在医学图像生成中的广泛应用引发了隐私担忧，现有MIA方法在医学图像上表现不佳，主要受图像固有难度和模型高频细节重建能力限制。
- Method: 提出FCRE方法，通过分析反向扩散过程，计算中频区域重建误差和结构相似性指数，排除高频和低频区域干扰，确定成员关系。
- Result: 在多个医学图像数据集上的实验表明，FCRE方法优于现有MIA方法。
- Conclusion: FCRE方法有效解决了医学图像扩散模型的隐私风险评估问题，为未来隐私保护研究提供了新思路。


### [19] [Vision Transformers for End-to-End Quark-Gluon Jet Classification from Calorimeter Images](https://arxiv.org/abs/2506.14934)
*Md Abrar Jahin,Shahriar Soudeep,Arian Rahman Aditta,M. F. Mridha,Nafiz Fahad,Md. Jakir Hossen*

Main category: cs.CV

TL;DR: 本文系统评估了Vision Transformer (ViT)及其与CNN的混合模型在夸克-胶子喷注分类中的表现，发现ViT模型在性能上优于传统CNN。

- Motivation: 区分夸克和胶子喷注是高能物理中的关键挑战，对LHC的新物理搜索和精确测量至关重要。ViT因其全局上下文建模能力而具有潜力，但在实际探测器条件下尚未充分探索。
- Method: 使用模拟的2012年CMS开放数据，构建多通道喷注图像（ECAL、HCAL和重建轨迹），并评估ViT和ViT-CNN混合模型的性能。
- Result: ViT模型（如ViT+MaxViT和ViT+ConvNeXt混合模型）在F1分数、ROC-AUC和准确率上均优于传统CNN，展示了其在喷注子结构长程空间关联中的优势。
- Conclusion: 本文为ViT在喷注分类中的应用提供了首个系统性框架和性能基准，并提供了适合进一步深度学习研究的数据集。


### [20] [Advances in Compliance Detection: Novel Models Using Vision-Based Tactile Sensors](https://arxiv.org/abs/2506.14980)
*Ziteng Li,Malte Kuhlmann,Ilana Nisky,Nicolás Navarro-Guerrero*

Main category: cs.CV

TL;DR: 论文提出基于LRCN和Transformer的模型，利用GelSight传感器的RGB触觉图像预测物体顺应性，显著提升了预测精度。

- Motivation: 传统顺应性检测方法缺乏便携性和可扩展性，依赖昂贵设备，且现有基于视觉触觉传感器的神经网络方法精度不足。
- Method: 提出两种模型：基于LRCN和Transformer架构，利用GelSight传感器的RGB触觉图像及其他信息预测顺应性。
- Result: 模型在多种指标下表现优异，显著优于基线方法，但发现传感器硬度高于物体时估计更具挑战性。
- Conclusion: 所提模型能有效预测顺应性，但需进一步研究传感器与物体硬度关系对估计的影响。


### [21] [Hyper-Local Deformable Transformers for Text Spotting on Historical Maps](https://arxiv.org/abs/2506.15010)
*Yijun Lin,Yao-Yi Chiang*

Main category: cs.CV

TL;DR: PALETTE是一种端到端文本识别器，用于处理多样化的历史地图，通过超局部采样模块和合成地图数据SynthMap+提升性能。

- Motivation: 历史地图中的文本信息具有重要价值，但提取困难，现有方法缺乏通用性和训练数据。
- Method: 提出PALETTE，结合超局部采样模块和位置嵌入，优化文本检测与识别；并开发SynthMap+生成合成训练数据。
- Result: PALETTE在历史地图数据集上优于现有方法，尤其在长文本和倾斜文本上表现突出。
- Conclusion: PALETTE和SynthMap+成功应用于大规模地图处理，支持地图搜索功能。


### [22] [Break Stylistic Sophon: Are We Really Meant to Confine the Imagination in Style Transfer?](https://arxiv.org/abs/2506.15033)
*Gary Song Yan,Yusen Zhang,Jinyu Zhao,Hao Zhang,Zhangping Yang,Guanye Xiong,Yanfei Liu,Tao Zhang,Yujie He,Siyuan Tian,Yao Gou,Min Li*

Main category: cs.CV

TL;DR: StyleWallfacer是一个统一的训练和推理框架，解决了传统风格迁移方法的问题，支持艺术家级风格迁移和文本驱动风格化。

- Motivation: 解决传统风格迁移方法中的问题，并统一不同任务的框架，实现高质量的风格迁移和文本驱动风格化。
- Method: 提出基于语义的风格注入方法、基于人类反馈的数据增强策略和无训练的三重扩散过程。
- Result: 实现了高质量的图像驱动风格迁移和文本驱动风格化，首次在风格迁移中实现图像颜色编辑。
- Conclusion: StyleWallfacer框架在风格迁移领域取得了突破性进展，提供了高效且无漂移的风格注入方法。


### [23] [Enhancing Vector Quantization with Distributional Matching: A Theoretical and Empirical Study](https://arxiv.org/abs/2506.15078)
*Xianghong Fang,Litao Guo,Hengchao Chen,Yuxuan Zhang,XiaofanXia,Dingjie Song,Yexin Liu,Hao Wang,Harry Yang,Yuan Yuan,Qiang Sun*

Main category: cs.CV

TL;DR: 本文提出了一种基于Wasserstein距离的向量量化方法，解决了训练不稳定和码书崩溃问题，显著提升了码书利用率和量化效果。

- Motivation: 现有向量量化方法存在训练不稳定和码书崩溃问题，主要由特征与码向量分布不匹配引起。
- Method: 采用Wasserstein距离对齐特征与码向量分布，提升码书利用率并减少量化误差。
- Result: 实验和理论分析验证了方法的有效性，实现了近100%的码书利用率。
- Conclusion: 通过分布对齐，显著改善了向量量化的性能。


### [24] [SynPo: Boosting Training-Free Few-Shot Medical Segmentation via High-Quality Negative Prompts](https://arxiv.org/abs/2506.15153)
*Yufei Liu,Haoke Xiao,Jiaxing Chai,Yongcun Zhang,Rong Wang,Zijie Meng,Zhiming Luo*

Main category: cs.CV

TL;DR: SynPo是一种基于大型视觉模型（如SAM）的无训练少样本医学图像分割方法，通过改进负提示质量提升低对比度图像的分割性能。

- Motivation: 现有基于LVMs的无训练方法未能有效利用负提示，导致在低对比度医学图像上表现不佳。
- Method: 设计置信图协同模块（结合DINOv2和SAM），选择高质量正负提示点，并利用K-means聚类优化提示点，最终通过SAM获取分割结果。
- Result: 实验表明SynPo性能接近基于训练的最先进少样本方法。
- Conclusion: SynPo通过优化负提示，显著提升了无训练少样本医学图像分割的效果。


### [25] [Enhancing point cloud analysis via neighbor aggregation correction based on cross-stage structure correlation](https://arxiv.org/abs/2506.15160)
*Jiaqi Shi,Jin Xiao,Xiaoguang Hu,Boyang Song,Hao Jiang,Tianyou Chen,Baochang Zhang*

Main category: cs.CV

TL;DR: 提出了一种名为PDSA的模块，通过高维空间相关性校正特征分布，提升点云分析的效率和鲁棒性。

- Motivation: 现有方法在局部坐标下聚合邻域时存在无关点干扰和特征层次差距问题，且直接几何结构编码方法计算开销大、对噪声敏感。
- Method: PDSA利用高维空间相关性校正特征分布，通过轻量级跨阶段结构描述符区分点相关性，并通过减少邻域特征矩阵方差和长距离建模增强结构同质性。
- Result: 在语义分割和分类任务上验证了方法的泛化性，性能显著提升且参数成本更低。
- Conclusion: PDSA模块有效解决了现有问题，提升了点云分析的效率和鲁棒性。


### [26] [Echo-DND: A dual noise diffusion model for robust and precise left ventricle segmentation in echocardiography](https://arxiv.org/abs/2506.15166)
*Abdur Rahman,Keerthiveena Balraj,Manojkumar Ramteke,Anurag Singh Rathore*

Main category: cs.CV

TL;DR: Echo-DND是一种新型双噪声扩散模型，用于超声心动图中左心室的高精度分割，结合高斯和伯努利噪声，并引入多尺度融合条件模块和空间一致性校准，显著提升分割性能。

- Motivation: 超声图像噪声多、对比度低且左心室边界模糊，传统分割方法效果不佳，因此需要一种更精确的分割模型。
- Method: 提出Echo-DND模型，结合高斯和伯努利噪声，采用多尺度融合条件模块和空间一致性校准技术。
- Result: 在CAMUS和EchoNet-Dynamic数据集上表现优异，Dice分数分别达到0.962和0.939，超越现有SOTA模型。
- Conclusion: Echo-DND为超声心动图分割设立了新标准，其架构有望扩展到其他医学影像任务，提升诊断准确性。


### [27] [ReSeDis: A Dataset for Referring-based Object Search across Large-Scale Image Collections](https://arxiv.org/abs/2506.15180)
*Ziling Huang,Yidan Zhang,Shin'ichi Satoh*

Main category: cs.CV

TL;DR: ReSeDis统一了文本到图像检索与像素级定位，提出了新的任务和基准，并展示了未来研究的潜力。

- Motivation: 现有技术仅解决视觉搜索中的单一问题（检索或定位），无法同时满足需求。
- Method: 引入ReSeDis任务，结合检索与定位，并设计新基准和评估指标。
- Result: 提出了零-shot基线方法，显示未来研究有显著改进空间。
- Conclusion: ReSeDis为构建下一代多模态搜索系统提供了实用测试平台。


### [28] [Conquering the Retina: Bringing Visual in-Context Learning to OCT](https://arxiv.org/abs/2506.15200)
*Alessio Negrini,Simon Reiß*

Main category: cs.CV

TL;DR: 该论文探讨了如何通过视觉上下文学习（VICL）训练通用模型，用于视网膜光学相干断层扫描（OCT）领域，并提出了一个评估协议。

- Motivation: 尽管专业模型在特定临床任务中表现优异，但其适用性有限且开发成本高。通用模型则允许动态定义任务，无需特定模型开发。
- Method: 使用视觉上下文学习（VICL）训练通用模型，基于推理时的少量示例实现任务泛化。
- Result: 在多个视网膜OCT数据集上评估了先进的医疗VICL方法，建立了首个基准，展示了其潜力与局限性。
- Conclusion: 论文开源代码以促进进一步研究和实际应用，强调了上下文学习在OCT领域的潜力。


### [29] [Privacy-Shielded Image Compression: Defending Against Exploitation from Vision-Language Pretrained Models](https://arxiv.org/abs/2506.15201)
*Xuelin Shen,Jiayin Xu,Kangsheng Yin,Wenhan Yang*

Main category: cs.CV

TL;DR: 提出了一种名为PSIC的灵活编码方法，通过在图像压缩阶段实现隐私保护，防止视觉语言预训练模型对公开图像的利用。

- Motivation: 随着视觉语言预训练模型语义理解能力的提升，公开图像的隐私保护需求日益迫切。
- Method: 设计了PSIC方法，支持多解码选项的比特流生成，结合CLTG模块和UAEO优化函数，实现隐私保护与图像质量的平衡。
- Result: 实验证明PSIC在多种下游任务中有效保护隐私，同时保持图像压缩功能。
- Conclusion: PSIC是一种即插即用的隐私保护方案，可无缝集成到现有图像压缩模型中。


### [30] [DM-FNet: Unified multimodal medical image fusion via diffusion process-trained encoder-decoder](https://arxiv.org/abs/2506.15218)
*Dan He,Weisheng Li,Guofen Wang,Yuping Huang,Shiqiang Liu*

Main category: cs.CV

TL;DR: 提出了一种基于两阶段扩散模型的融合网络（DM-FNet），用于多模态医学图像融合，解决了现有方法在特征捕获和跨模态交互上的不足。

- Motivation: 现有方法在捕获细节特征和跨模态特征交互上表现不佳，导致融合图像质量不理想。
- Method: 采用两阶段扩散模型：第一阶段通过UNet进行图像重建，第二阶段将噪声图像输入融合网络，结合三个关键融合模块自适应处理不同模态图像。
- Result: 实验表明，该方法在客观评价指标上表现优异，融合图像保留了亮度、放射性示踪剂分布、纹理和边缘清晰度。
- Conclusion: DM-FNet通过两阶段设计和混合损失函数，显著提升了多模态医学图像融合的质量和信息密度。


### [31] [video-SALMONN 2: Captioning-Enhanced Audio-Visual Large Language Models](https://arxiv.org/abs/2506.15220)
*Changli Tang,Yixuan Li,Yudong Yang,Jimin Zhuang,Guangzhi Sun,Wei Li,Zejun Ma,Chao Zhang*

Main category: cs.CV

TL;DR: 视频-SALMONN 2是一种先进的视听大语言模型，通过低秩适应（LoRA）和定向偏好优化（DPO）提升视频（带音频）字幕生成能力。提出多轮DPO（MrDPO）方法，显著降低错误率28%，并在7B参数规模下超越GPT-4o和Gemini-1.5-Pro。

- Motivation: 视频包含丰富信息，生成准确的自然语言描述是视频理解的关键。现有方法在描述完整性和准确性上仍有提升空间。
- Method: 提出视频-SALMONN 2模型，结合LoRA和DPO优化。引入MrDPO方法，周期性更新参考模型并融合真实字幕指导。
- Result: MrDPO显著提升字幕准确性，错误率降低28%。7B参数模型超越GPT-4o和Gemini-1.5-Pro，并在视频问答任务中表现优异。
- Conclusion: 视频-SALMONN 2在视频字幕生成任务中表现卓越，方法高效且参数规模小，代码已开源。


### [32] [Convolutional Feature Enhancement and Attention Fusion BiFPN for Ship Detection in SAR Images](https://arxiv.org/abs/2506.15231)
*Liangjie Meng,Danxia Li,Jinrong He,Lili Ma,Zhixin Li*

Main category: cs.CV

TL;DR: 论文提出了一种名为C-AFBiFPN的特征增强与融合框架，用于解决SAR船舶检测中的多尺度变化、小目标噪声和复杂背景问题。

- Motivation: SAR船舶检测面临多尺度变化、小目标噪声和复杂背景等挑战，需要更有效的特征表示和融合方法。
- Method: C-AFBiFPN结合了卷积特征增强模块（CFE）和集成BiFormer注意力的AFBiFPN网络，以增强局部细节和全局建模能力。
- Result: 在SSDD数据集上的实验表明，该方法显著提升了小目标检测精度、抗遮挡鲁棒性和多尺度适应性。
- Conclusion: C-AFBiFPN框架有效解决了SAR船舶检测的关键问题，提升了检测性能。


### [33] [RA-NeRF: Robust Neural Radiance Field Reconstruction with Accurate Camera Pose Estimation under Complex Trajectories](https://arxiv.org/abs/2506.15242)
*Qingsong Yan,Qiang Wang,Kaiyong Zhao,Jie Chen,Bo Li,Xiaowen Chu,Fei Deng*

Main category: cs.CV

TL;DR: RA-NeRF是一种新方法，能够在复杂相机轨迹下预测高精度相机位姿，结合NeRF和流驱动位姿调节，显著提升重建和定位的鲁棒性。

- Motivation: 现有方法依赖准确相机位姿先验，但在复杂轨迹下表现不佳，RA-NeRF旨在解决这一问题。
- Method: 采用增量式流程，结合NeRF的光度一致性和流驱动位姿调节，并引入隐式位姿滤波器消除噪声。
- Result: 在Tanks&Temple和NeRFBuster数据集上，RA-NeRF在位姿估计和视觉质量上均达到最优。
- Conclusion: RA-NeRF在复杂位姿轨迹下表现出高效性和鲁棒性，为场景重建提供了新解决方案。


### [34] [Retrospective Memory for Camouflaged Object Detection](https://arxiv.org/abs/2506.15244)
*Chenxi Zhang,Jiayun Wu,Qing Zhang,Yazhe Zhai,Youwei Pang*

Main category: cs.CV

TL;DR: 提出了一种名为RetroMem的回忆增强COD架构，通过整合历史知识动态调制伪装模式感知和推理，显著提升模型性能。

- Motivation: 现有COD方法缺乏获取历史背景的显式机制，限制了其在复杂伪装场景中的适应性和有效性。
- Method: RetroMem采用两阶段训练范式（学习阶段和回忆阶段），包括DMA、DMM和IPR组件，动态整合历史知识与当前样本上下文。
- Result: 在多个数据集上的实验表明，RetroMem显著优于现有最先进方法。
- Conclusion: RetroMem通过动态整合历史知识，显著提升了COD任务的性能。


### [35] [Domain Adaptation for Image Classification of Defects in Semiconductor Manufacturing](https://arxiv.org/abs/2506.15260)
*Adrian Poniatowski,Natalie Gentner,Manuel Barusco,Davide Dalle Pezze,Samuele Salti,Gian Antonio Susto*

Main category: cs.CV

TL;DR: 论文探讨了在半导体领域应用域适应（DA）技术，特别是在半监督和无监督设置下，以减少手动标记和重新训练的需求，并提出了DBACS方法以提升性能。

- Motivation: 半导体行业竞争激烈，上市时间和质量是关键因素。域适应技术能减少资源消耗并提高效率，因此研究其在半导体领域的应用具有重要意义。
- Method: 提出了DBACS方法，一种基于CycleGAN的模型，通过额外损失项提升性能。在半监督和无监督设置下，使用真实电子显微镜图像进行验证。
- Result: 实验证明DBACS方法在半导体领域有效，提升了域适应技术的性能。
- Conclusion: DBACS方法在半导体领域具有实用价值，能显著减少资源消耗并提高模型适应性。


### [36] [MSNeRV: Neural Video Representation with Multi-Scale Feature Fusion](https://arxiv.org/abs/2506.15276)
*Jun Zhu,Xinfeng Zhang,Lv Tang,JunHao Jiang*

Main category: cs.CV

TL;DR: MSNeRV是一种多尺度特征融合框架，用于神经视频表示，解决了现有INR方法在细节密集和快速变化视频内容中的不足。

- Motivation: 现有INR方法在细节密集和快速变化视频内容中表现不佳，主要原因是网络特征利用不足和缺乏视频特定设计。
- Method: 提出多尺度特征融合框架MSNeRV，包括时间窗口增强时间一致性、GoP级网格背景表示、多尺度空间解码器和自适应损失函数。
- Result: 在HEVC ClassB和UVG数据集上，MSNeRV在动态场景中压缩效率优于VTM-23.7（随机访问）。
- Conclusion: MSNeRV在神经视频表示中表现出色，尤其在动态场景中优于现有方法。


### [37] [BCRNet: Enhancing Landmark Detection in Laparoscopic Liver Surgery via Bezier Curve Refinement](https://arxiv.org/abs/2506.15279)
*Qian Li,Feng Liu,Shuojue Yang,Daiyun Shen,Yueming Jin*

Main category: cs.CV

TL;DR: BCRNet通过Bezier曲线细化策略提升腹腔镜肝脏手术中关键解剖标志的检测精度，优于现有方法。

- Motivation: 腹腔镜肝脏手术中准确识别解剖结构具有挑战性，AR系统结合MRI/CT与腹腔镜图像可改善导航，但需要精确检测曲线标志。
- Method: 提出BCRNet框架，包括多模态特征提取（MFE）、自适应曲线提案初始化（ACPI）和分层曲线细化（HCR）机制。
- Result: 在L3D和P2ILF数据集上表现优异，显著优于现有方法。
- Conclusion: BCRNet通过多阶段细化策略有效提升曲线标志检测精度，为手术导航提供可靠支持。


### [38] [AI-driven visual monitoring of industrial assembly tasks](https://arxiv.org/abs/2506.15285)
*Mattia Nardon,Stefano Messelodi,Antonio Granata,Fabio Poiesi,Alberto Danese,Davide Boscaini*

Main category: cs.CV

TL;DR: ViMAT是一种无需标记或固定工作空间的新型AI系统，用于实时监控工业装配任务。

- Motivation: 现有商业解决方案通常需要固定工作空间或视觉标记，限制了灵活性。ViMAT旨在克服这些限制。
- Method: ViMAT结合感知模块（从多视角视频流提取视觉观察）和推理模块（基于观察状态和任务知识推断动作）。
- Result: 在LEGO组件更换和液压模具重组任务中，ViMAT在部分和不确定视觉观察下表现有效。
- Conclusion: ViMAT在复杂真实场景中展示了其灵活性和有效性。


### [39] [MEGC2025: Micro-Expression Grand Challenge on Spot Then Recognize and Visual Question Answering](https://arxiv.org/abs/2506.15298)
*Xinqi Fan,Jingting Li,John See,Moi Hoon Yap,Wen-Huang Cheng,Xiaobai Li,Xiaopeng Hong,Su-Jing Wang,Adrian K. Davision*

Main category: cs.CV

TL;DR: 论文探讨了面部微表情（MEs）的识别、定位与生成，提出了结合定位与识别的统一任务ME-STR，并利用多模态大语言模型（MLLMs）进行ME视觉问答（ME-VQA）。

- Motivation: 传统方法将微表情的定位与识别分开处理，效率低下，尤其在长视频分析中表现不佳。多模态大语言模型的出现为ME分析提供了新思路。
- Method: 提出ME-STR任务，将定位与识别结合为统一流程；引入ME-VQA任务，利用MLLMs或LVLMs进行视觉问答。
- Result: MEGC 2025挑战赛将评估这两种新任务，参赛算法需在测试集上运行并提交结果。
- Conclusion: 结合定位与识别的统一任务及多模态模型的应用，有望提升ME分析的效率和准确性。


### [40] [MapFM: Foundation Model-Driven HD Mapping with Multi-Task Contextual Learning](https://arxiv.org/abs/2506.15313)
*Leonid Ivanov,Vasily Yuryev,Dmitry Yudin*

Main category: cs.CV

TL;DR: 本文提出了一种名为MapFM的端到端模型，用于在线生成矢量化的高精地图，通过结合强大的基础模型和辅助语义分割任务，显著提升了地图生成的质量和准确性。

- Motivation: 高精地图和BEV语义地图在自动驾驶中至关重要，但现有方法在特征表示和环境理解方面仍有不足，因此需要一种更高效的在线地图生成方法。
- Method: MapFM模型结合了基础模型对相机图像的编码能力，并引入辅助的BEV语义分割任务，通过多任务学习提升场景理解能力。
- Result: 实验表明，该方法显著提升了特征表示质量，生成的矢量高精地图具有更高的准确性和质量。
- Conclusion: MapFM通过多任务学习和基础模型的结合，为自动驾驶提供了一种高效且高质量的在线地图生成解决方案。


### [41] [OpenPath: Open-Set Active Learning for Pathology Image Classification via Pre-trained Vision-Language Models](https://arxiv.org/abs/2506.15318)
*Lanfeng Zhong,Xin Liao,Shichuan Zhang,Shaoting Zhang,Guotai Wang*

Main category: cs.CV

TL;DR: OpenPath提出了一种基于预训练视觉语言模型的开集主动学习方法，用于病理图像分类，通过任务特定提示和多样性信息采样策略，显著提高了样本选择的纯度和信息量。

- Motivation: 病理图像分类需要大规模标注数据，但获取成本高。传统主动学习方法在开集场景下效率低，且初始随机选择浪费标注资源。
- Method: OpenPath结合任务特定提示和多样性信息采样策略（PIS和EGSS），在初始和后续查询中高效选择分布内样本。
- Result: 在两个公共病理图像数据集上，OpenPath显著优于现有开集主动学习方法，提高了模型性能。
- Conclusion: OpenPath通过优化样本选择策略，有效解决了开集主动学习中的挑战，为病理图像分类提供了高效解决方案。


### [42] [Open-World Object Counting in Videos](https://arxiv.org/abs/2506.15368)
*Niki Amini-Naieni,Andrew Zisserman*

Main category: cs.CV

TL;DR: 论文提出了一种视频中开放世界物体计数的新任务，并介绍了CountVid模型，该模型结合图像计数和视频分割跟踪技术，显著优于基线方法。

- Motivation: 解决视频中开放世界物体计数的挑战，特别是在拥挤场景中避免重复计数和识别重现对象。
- Method: 提出CountVid模型，结合图像计数和可提示视频分割跟踪技术，实现自动化计数。
- Result: 在VideoCount数据集上，CountVid表现优于基线方法，提供准确计数。
- Conclusion: CountVid和VideoCount数据集为开放世界物体计数任务提供了有效解决方案，代码和数据已开源。


### [43] [Unsupervised Pelage Pattern Unwrapping for Animal Re-identification](https://arxiv.org/abs/2506.15369)
*Aleksandr Algasov,Ekaterina Nepovinnykh,Fedor Zolotarev,Tuomas Eerola,Heikki Kälviäinen,Pavel Zemčík,Charles V. Stewart*

Main category: cs.CV

TL;DR: 提出一种几何感知的纹理映射方法，将动物皮毛图案映射到规范UV空间，提升个体重识别精度。

- Motivation: 现有方法难以处理动物皮毛或皮肤图案因身体运动和姿态变化导致的几何变形。
- Method: 使用表面法线估计指导纹理映射，保持3D表面与2D纹理空间的几何一致性，无需标注数据，可自监督训练。
- Result: 在Saimaa环斑海豹和豹子数据集上，重识别精度提升5.4%。
- Conclusion: 几何感知纹理映射能有效处理变形图案，提升重识别性能。


### [44] [When Model Knowledge meets Diffusion Model: Diffusion-assisted Data-free Image Synthesis with Alignment of Domain and Class](https://arxiv.org/abs/2506.15381)
*Yujin Kim,Hyunsoo Kim,Hyunwoo J. Kim,Suhyun Kim*

Main category: cs.CV

TL;DR: DDIS是一种基于扩散模型的数据无关图像合成方法，通过引入领域对齐指导和类别对齐令牌，显著提升了合成图像的质量。

- Motivation: 开源预训练模型的应用潜力受限于训练数据的不可用性，现有数据无关图像合成方法因缺乏自然图像先验知识而生成偏离训练数据分布的样本。
- Method: DDIS利用文本到图像扩散模型作为图像先验，通过领域对齐指导（DAG）和类别对齐令牌（CAT）优化合成图像与训练数据分布的对齐。
- Result: 在PACS和ImageNet上的实验表明，DDIS优于现有数据无关图像合成方法，生成更符合训练数据分布的样本。
- Conclusion: DDIS通过结合扩散模型和领域对齐指导，实现了高质量的数据无关图像合成，为数据受限场景提供了有效解决方案。


### [45] [NERO: Explainable Out-of-Distribution Detection with Neuron-level Relevance](https://arxiv.org/abs/2506.15404)
*Anju Chhetri,Jari Korhonen,Prashnna Gyawali,Binod Bhattarai*

Main category: cs.CV

TL;DR: 论文提出了一种名为NERO的新型OOD评分机制，通过利用特征层的神经元级相关性来提升OOD检测的可靠性，并在医学影像领域验证了其有效性。

- Motivation: 在医学影像中，确保深度学习模型的可靠性至关重要，尤其是识别分布外（OOD）样本的能力。现有方法可能无法完全捕捉OOD的多样性，因此需要更有效的解决方案。
- Method: 提出NERO机制，通过聚类神经元级相关性形成代表性中心，并引入相关性距离度量来量化新样本与中心的偏差。同时结合缩放相关性和特征范数优化性能。
- Result: 在胃肠道影像基准数据集Kvasir和GastroVision上，NERO在多种深度学习架构中表现优于现有OOD检测方法。
- Conclusion: NERO通过神经元级相关性和距离度量显著提升了OOD检测能力，为医学影像中的模型可靠性提供了可解释的解决方案。


### [46] [Hunyuan3D 2.1: From Images to High-Fidelity 3D Assets with Production-Ready PBR Material](https://arxiv.org/abs/2506.15442)
*Team Hunyuan3D,Shuhui Yang,Mingxin Yang,Yifei Feng,Xin Huang,Sheng Zhang,Zebin He,Di Luo,Haolin Liu,Yunfei Zhao,Qingxiang Lin,Zeqiang Lai,Xianghui Yang,Huiwen Shi,Zibo Zhao,Bowen Zhang,Hongyu Yan,Lifu Wang,Sicong Liu,Jihong Zhang,Meng Chen,Liang Dong,Yiwen Jia,Yulin Cai,Jiaao Yu,Yixuan Tang,Dongyuan Guo,Junlin Yu,Hao Zhang,Zheng Ye,Peng He,Runzhou Wu,Shida Wei,Chao Zhang,Yonghao Tan,Yifu Sun,Lin Niu,Shirui Huang,Bojian Zheng,Shu Liu,Shilin Chen,Xiang Yuan,Xiaofeng Yang,Kai Liu,Jianchen Zhu,Peng Chen,Tian Liu,Di Wang,Yuhong Liu,Linus,Jie Jiang,Jingwei Huang,Chunchao Guo*

Main category: cs.CV

TL;DR: 本文介绍了Hunyuan3D 2.1系统，提供了一个详细的教程，指导如何从数据处理到模型训练和评估，以简化3D AI生成内容的开发流程。

- Motivation: 3D AI生成内容领域虽然发展迅速，但由于数据收集、处理和模型训练的复杂性，仍主要局限于专业人士。本文旨在通过Hunyuan3D 2.1案例，降低这一领域的门槛。
- Method: Hunyuan3D 2.1系统包含两个核心组件：Hunyuan3D-DiT用于形状生成，Hunyuan3D-Paint用于纹理合成。教程涵盖了数据处理、模型架构、训练策略、评估指标和部署。
- Result: 通过本教程，用户可以掌握开发或优化3D生成模型的能力，适用于游戏、虚拟现实和工业设计等领域。
- Conclusion: Hunyuan3D 2.1及其教程为3D AI生成内容的开发提供了实用工具和指导，有助于推动该技术的普及和应用。


### [47] [Multimodal Large Language Models for Medical Report Generation via Customized Prompt Tuning](https://arxiv.org/abs/2506.15477)
*Chunlei Li,Jingyang Hou,Yilei Shi,Jingliang Hu,Xiao Xiang Zhu,Lichao Mou*

Main category: cs.CV

TL;DR: MRG-LLM是一种新型多模态大语言模型，通过动态提示定制机制结合冻结的LLM和可学习的视觉编码器，在医学报告生成任务中表现优异。

- Motivation: 医学影像数据的报告生成具有挑战性，现有大语言模型与医学影像数据的结合仍需深入探索。
- Method: MRG-LLM结合冻结的LLM和可学习的视觉编码器，通过条件仿射变换生成实例特定的动态提示，提出提示级和提示簿级两种定制方式。
- Result: 在IU X-ray和MIMIC-CXR数据集上的实验表明，MRG-LLM在医学报告生成任务中达到最先进性能。
- Conclusion: MRG-LLM通过动态提示定制机制有效提升了医学报告生成的性能，代码将公开。


### [48] [GenHOI: Generalizing Text-driven 4D Human-Object Interaction Synthesis for Unseen Objects](https://arxiv.org/abs/2506.15483)
*Shujia Li,Haiyu Zhang,Xinyuan Chen,Yaohui Wang,Yutong Ban*

Main category: cs.CV

TL;DR: GenHOI框架通过两阶段方法实现未见物体的泛化和高质量4D人-物交互序列生成。

- Motivation: 解决4D人-物交互（HOI）数据稀缺问题，提升未见物体泛化能力和生成质量。
- Method: 1) 使用Object-AnchorNet重建稀疏3D HOI关键帧；2) 通过Contact-Aware Diffusion Model（ContactDM）插值生成密集4D HOI序列。
- Result: 在OMOMO和3D-FUTURE数据集上达到SOTA，展示了对未见物体的强泛化能力。
- Conclusion: GenHOI框架有效解决了4D HOI数据稀缺问题，并实现了高质量序列生成。


### [49] [NTIRE 2025 Image Shadow Removal Challenge Report](https://arxiv.org/abs/2506.15524)
*Florin-Alexandru Vasluianu,Tim Seizinger,Zhuyun Zhou,Cailian Chen,Zongwei Wu,Radu Timofte,Mingjia Li,Jin Hu,Hainuo Wang,Hengxing Liu,Jiarui Wang,Qiming Hu,Xiaojie Guo,Xin Lu,Jiarong Yang,Yuanfei Bao,Anya Hu,Zihao Fan,Kunyu Wang,Jie Xiao,Xi Wang,Xueyang Fu,Zheng-Jun Zha,Yu-Fan Lin,Chia-Ming Lee,Chih-Chung Hsu,Xingbo Wang,Dong Li,Yuxu Chen,Bin Chen,Yuanbo Zhou,Yuanbin Chen,Hongwei Wang,Jiannan Lin,Qinquan Gao,Tong Tong,Zhao Zhang,Yanyan Wei,Wei Dong,Han Zhou,Seyed Amirreza Mousavi,Jun Chen,Haobo Liang,Jiajie Jing,Junyu Li,Yan Yang,Seoyeon Lee,Chaewon Kim,Ziyu Feng,Shidi Chen,Bowen Luan,Zewen Chen,Vijayalaxmi Ashok Aralikatti,G Gyaneshwar Rao,Nikhil Akalwadi,Chaitra Desai,Ramesh Ashok Tabib,Uma Mudenagudi,Anas M. Ali,Bilel Benjdira,Wadii Boulila,Alexandru Brateanu,Cosmin Ancuti,Tanmay Chaturvedi,Manish Kumar,Anmol Srivastav,Daksh Trivedi,Shashwat Thakur,Kishor Upla,Zeyu Xiao,Zhuoyuan Li,Boda Zhou,Shashank Shekhar,Kele Xu,Qisheng Xu,Zijian Gao,Tianjiao Wan,Suiyi Zhao,Bo Wang,Yan Luo,Mingshen Wang,Yilin Zhang*

Main category: cs.CV

TL;DR: NTIRE 2025阴影去除挑战赛的结果分析，306名参与者中17支团队提交了解决方案，分为重建保真度和视觉感知两个评估轨道。

- Motivation: 研究阴影去除技术的性能，特别是在复杂场景中的自阴影和投射阴影处理。
- Method: 使用WSRD+数据集进行双轨道评估，分别关注重建保真度和用户视觉感知。
- Result: 17支团队提交了解决方案，数据集模拟了多样化的物体、纹理和材料交互。
- Conclusion: 挑战赛展示了阴影去除技术的进展，尤其是在复杂场景中的应用潜力。


### [50] [CLAIM: Clinically-Guided LGE Augmentation for Realistic and Diverse Myocardial Scar Synthesis and Segmentation](https://arxiv.org/abs/2506.15549)
*Farheen Ramzan,Yusuf Kiberu,Nikesh Jathanna,Shahnaz Jamil-Copley,Richard H. Clayton,Chen,Chen*

Main category: cs.CV

TL;DR: CLAIM框架通过临床引导的LGE增强和扩散生成技术，合成多样且解剖学一致的心肌瘢痕图像，并结合联合训练策略提升分割性能。

- Motivation: LGE心脏MRI图像的高质量瘢痕标签有限且多变，限制了稳健分割模型的开发。
- Method: 提出CLAIM框架，结合SMILE模块（基于临床知识的瘢痕掩模生成）和扩散生成器，合成解剖学一致的瘢痕图像，并采用联合训练策略优化分割网络。
- Result: CLAIM生成的瘢痕模式解剖学一致，与真实瘢痕分布的Dice相似度高于基线模型。
- Conclusion: CLAIM实现了可控且真实的心肌瘢痕合成，对下游医学影像任务具有实用价值。


### [51] [RaCalNet: Radar Calibration Network for Sparse-Supervised Metric Depth Estimation](https://arxiv.org/abs/2506.15560)
*Xingrui Qin,Wentao Zhao,Chuan Cao,Yihe Niu,Houcheng Jiang,Jingchuan Wang*

Main category: cs.CV

TL;DR: RaCalNet提出了一种无需密集监督的毫米波雷达深度估计框架，通过稀疏LiDAR监督实现高精度深度预测，显著降低数据需求。

- Motivation: 传统方法依赖密集LiDAR监督，成本高且数据密集。RaCalNet旨在通过稀疏监督实现高效深度估计。
- Method: RaCalNet通过重新校准和细化稀疏雷达点构建深度先验，作为单目深度预测的可靠锚点，避免密集监督。
- Result: 在ZJU-4DRadarCam数据集和实际场景中，RaCalNet显著优于密集监督方法，RMSE降低约35%。
- Conclusion: RaCalNet证明了稀疏监督的有效性，能够生成结构一致且细节丰富的深度图。


### [52] [Control and Realism: Best of Both Worlds in Layout-to-Image without Training](https://arxiv.org/abs/2506.15563)
*Bonan Li,Yinhan Hu,Songhua Liu,Xinchao Wang*

Main category: cs.CV

TL;DR: WinWinLay提出了一种无需训练的布局到图像生成方法，通过非局部注意力能量函数和自适应更新策略，提升控制精度和真实感。

- Motivation: 现有基于预训练文本到图像扩散模型的方法在布局控制上存在定位不精确和伪影问题，WinWinLay旨在解决这些问题。
- Method: 采用非局部注意力能量函数重新分配注意力分数，并引入基于Langevin动力学的自适应更新方案。
- Result: 实验表明，WinWinLay在元素布局控制和视觉真实感上优于现有方法。
- Conclusion: WinWinLay通过理论分析和创新策略，显著提升了布局到图像生成的质量。


### [53] [Show-o2: Improved Native Unified Multimodal Models](https://arxiv.org/abs/2506.15564)
*Jinheng Xie,Zhenheng Yang,Mike Zheng Shou*

Main category: cs.CV

TL;DR: Show-o2是一种改进的多模态模型，结合自回归建模和流匹配，支持图像和视频的多模态理解与生成。

- Motivation: 通过统一的多模态表示和双路径融合，提升跨模态（文本、图像、视频）的理解与生成能力。
- Method: 基于3D因果变分自编码器空间，通过双路径时空融合构建统一表示，并采用自回归建模和流匹配分别处理语言和流生成。
- Result: Show-o2模型在多种多模态任务中表现出色，支持文本、图像和视频的生成与理解。
- Conclusion: Show-o2展示了跨模态任务的通用性，并通过开源代码和模型推动多模态研究。


### [54] [Baltimore Atlas: FreqWeaver Adapter for Semi-supervised Ultra-high Spatial Resolution Land Cover Classification](https://arxiv.org/abs/2506.15565)
*Junhao Wu,Aboagye-Ntow Stephen,Chuyuan Wang,Gang Chen,Xin Huang*

Main category: cs.CV

TL;DR: 提出了一种参数高效的半监督分割框架，用于0.3米空间分辨率影像，结合SAM2知识和遥感专用FreqWeaver Adapter，在仅占模型总参数5.96%的情况下提升细粒度细节建模。

- Motivation: 超高空间分辨率土地覆盖分类对细粒度分析至关重要，但面临像素级标注成本高、尺度变化大及大规模视觉模型适应性有限等挑战。现有方法多依赖标注数据且适用于1米分辨率影像，而实际应用需在弱监督下处理更高分辨率影像。
- Method: 提出参数高效的半监督分割框架，结合SAM2知识并引入FreqWeaver Adapter，增强细粒度细节建模，同时保持轻量化设计。
- Result: 方法有效利用未标注数据且参数开销极小，分割结果具有优越的结构一致性，比现有参数高效调优策略提升1.78%，比最先进高分辨率遥感分割方法提升3.44%。
- Conclusion: 该方法在超高分辨率土地覆盖分类中表现出色，为弱监督条件下的细粒度分析提供了高效解决方案。


### [55] [A Unified Graph-based Framework for Scalable 3D Tree Reconstruction and Non-Destructive Biomass Estimation from Point Clouds](https://arxiv.org/abs/2506.15577)
*Di Wang,Shi Li*

Main category: cs.CV

TL;DR: 提出了一种基于图的新型端到端框架，用于大规模点云的森林地上生物量（AGB）估计，显著降低了预处理依赖并提升了可扩展性。

- Motivation: 现有QSM方法依赖高质量点云数据且预处理复杂，限制了其在大规模应用中的可行性。
- Method: 采用图操作（如路径和抽象）统一处理树分割、叶木分离和3D骨架重建，支持端到端处理。
- Result: 在多种条件下表现优异，如叶茂场景（~20%相对误差）和低密度ULS数据（~30%相对误差）。
- Conclusion: 该框架为大规模AGB估计提供了稳健且可扩展的解决方案，推动了QSM在森林调查和气候变化研究中的应用。


### [56] [One-Step Diffusion for Detail-Rich and Temporally Consistent Video Super-Resolution](https://arxiv.org/abs/2506.15591)
*Yujing Sun,Lingchen Sun,Shuaizheng Liu,Rongyuan Wu,Zhengqiang Zhang,Lei Zhang*

Main category: cs.CV

TL;DR: 论文提出了一种双LoRA学习（DLoRAL）范式，通过结合跨帧检索（CFR）模块和一致性-LoRA（C-LoRA）与细节-LoRA（D-LoRA），在视频超分辨率（Real-VSR）中同时实现细节增强和时间一致性。

- Motivation: 现有基于稳定扩散（SD）的Real-VSR方法在保持时间一致性时牺牲了空间细节，导致视觉质量不佳。论文旨在解决这一问题。
- Method: 提出DLoRAL范式，分两阶段训练：1）使用CFR和C-LoRA提取时间一致性先验；2）固定CFR和C-LoRA，训练D-LoRA增强细节。两阶段交替优化。
- Result: 实验表明DLoRAL在精度和速度上均表现优异，实现了细节丰富且时间一致的视频恢复。
- Conclusion: DLoRAL通过双LoRA学习范式，有效解决了Real-VSR中细节与时间一致性的平衡问题，为高效高质量视频恢复提供了新思路。


### [57] [Mono-Modalizing Extremely Heterogeneous Multi-Modal Medical Image Registration](https://arxiv.org/abs/2506.15596)
*Kyobin Choo,Hyunkyung Han,Jinyeong Kim,Chanyong Yoon,Seong Jae Hwang*

Main category: cs.CV

TL;DR: 提出了一种名为M2M-Reg的新框架，用于解决多模态图像配准中因模态差异大而导致的配准困难问题。通过仅使用单模态相似性训练模型，并结合GradCyCon正则化器，显著提高了配准效果。

- Motivation: 由于多模态图像（如PET和FA）与结构参考（如MRI、CT）的差异极大，传统的无监督配准方法难以学习可靠的空间映射，导致图像失真。
- Method: 提出M2M-Reg框架，仅使用单模态相似性训练多模态配准模型，并引入GradCyCon正则化器以促进微分同胚。框架还支持半监督设置，无需真实变换或分割掩码。
- Result: 在ADNI数据集上的实验表明，M2M-Reg在PET-MRI和FA-MRI配准中的DSC值比现有方法高2倍。
- Conclusion: M2M-Reg能有效处理高度异质的多模态配准问题，且易于集成到现有模型中。


### [58] [BoxFusion: Reconstruction-Free Open-Vocabulary 3D Object Detection via Real-Time Multi-View Box Fusion](https://arxiv.org/abs/2506.15610)
*Yuqing Lan,Chenyang Zhu,Zhirui Gao,Jiazhao Zhang,Yihan Cao,Renjiao Yi,Yijie Wang,Kai Xu*

Main category: cs.CV

TL;DR: 提出了一种无需重建的实时3D物体检测框架，结合预训练视觉基础模型和CLIP，实现高效内存和开放词汇语义检测。

- Motivation: 现有3D检测方法依赖密集点云重建，计算和内存开销大，难以实时部署。
- Method: 利用Cubify Anything和CLIP进行单视图检测，通过关联和优化模块融合多视图检测结果。
- Result: 在ScanNetV2和CA-1M数据集上达到SOTA性能，支持实时感知。
- Conclusion: 该方法无需重建，计算高效，适用于大场景实时检测。


### [59] [HOIDiNi: Human-Object Interaction through Diffusion Noise Optimization](https://arxiv.org/abs/2506.15625)
*Roey Ron,Guy Tevet,Haim Sawdayee,Amit H. Bermano*

Main category: cs.CV

TL;DR: HOIDiNi是一个基于文本驱动的扩散框架，用于生成真实且合理的人-物交互（HOI）。通过Diffusion Noise Optimization（DNO）直接在预训练扩散模型的噪声空间中进行优化，同时实现了真实性和物理正确性。

- Motivation: 当前的人-物交互生成方法在真实性和物理正确性之间存在权衡，HOIDiNi旨在通过结构化的两阶段方法（物体中心阶段和人体中心阶段）解决这一问题。
- Method: 采用Diffusion Noise Optimization（DNO）在预训练扩散模型的噪声空间中进行优化，分为物体中心阶段（选择手-物接触位置）和人体中心阶段（优化全身动作）。
- Result: 在GRAB数据集上的定量、定性和主观评估表明，HOIDiNi在接触准确性、物理有效性和整体质量上优于现有方法。
- Conclusion: HOIDiNi能够仅通过文本提示生成复杂且可控的交互动作，如抓取、放置和全身协调。


### [60] [FindingDory: A Benchmark to Evaluate Memory in Embodied Agents](https://arxiv.org/abs/2506.15635)
*Karmesh Yadav,Yusuf Ali,Gunshi Gupta,Yarin Gal,Zsolt Kira*

Main category: cs.CV

TL;DR: 论文提出了一种新的基准测试，用于评估大视觉语言模型在长期记忆和推理任务中的表现，特别是在机器人控制任务中。

- Motivation: 现有的大视觉语言模型在长期记忆处理能力上存在局限，难以应对多天收集的大量图像数据，且现有基准测试未充分体现机器人任务中的低层次技能需求。
- Method: 研究团队在Habitat模拟器中设计了一个包含60个任务的基准测试，这些任务需要长期记忆和上下文感知能力，并可扩展为更复杂的版本。
- Result: 提出了基线模型，结合了先进的视觉语言模型和低层次导航策略，评估了其在记忆密集型任务中的表现，并指出了改进方向。
- Conclusion: 新基准测试为评估和改进大视觉语言模型在长期记忆和推理任务中的能力提供了有效工具。


### [61] [Demystifying the Visual Quality Paradox in Multimodal Large Language Models](https://arxiv.org/abs/2506.15645)
*Shuo Xing,Lanqing Guo,Hongyuan Hua,Seoyoung Lee,Peiran Li,Yufei Wang,Zhangyang Wang,Zhengzhong Tu*

Main category: cs.CV

TL;DR: 研究发现，多模态大语言模型（MLLMs）在视觉质量与任务表现之间存在矛盾，提出了一种轻量级适配模块VQ-TTT，动态调整输入图像以提升性能。

- Motivation: 探讨视觉输入质量对MLLMs性能的影响，发现高人类感知质量未必带来更好的模型表现。
- Method: 通过控制图像退化和风格变化，提出VQ-TTT模块，动态调整输入图像以适应模型偏好。
- Result: VQ-TTT显著提升了MLLMs的平均准确率，无需外部模型或额外数据。
- Conclusion: 研究重新定义了MLLMs的“更好”视觉输入，强调需要适应性而非普遍“干净”的图像。


### [62] [Dual-Stage Value-Guided Inference with Margin-Based Reward Adjustment for Fast and Faithful VLM Captioning](https://arxiv.org/abs/2506.15649)
*Ankan Deria,Adinath Madhavrao Dukre,Feilong Tang,Sara Atito,Sudipta Roy,Muhammad Awais,Muhammad Haris Khan,Imran Razzak*

Main category: cs.CV

TL;DR: ViMaR是一个两阶段推理框架，通过结合时间差分价值模型和边缘感知奖励调整，提高视觉语言模型的效率和输出保真度。

- Motivation: 现有方法计算成本高且易产生低置信度生成，导致幻觉问题。
- Method: ViMaR分两阶段：首阶段筛选高价值候选，次阶段选择性优化弱视觉基础部分，并引入边缘惩罚。
- Result: ViMaR显著提升可靠性、准确性、细节和解释性，速度提升4倍以上，且能跨模型泛化。
- Conclusion: ViMaR具有灵活性、可扩展性，能自我提升视觉理解能力。


### [63] [UniRelight: Learning Joint Decomposition and Synthesis for Video Relighting](https://arxiv.org/abs/2506.15673)
*Kai He,Ruofan Liang,Jacob Munkberg,Jon Hasselgren,Nandita Vijaykumar,Alexander Keller,Sanja Fidler,Igor Gilitschenski,Zan Gojcic,Zian Wang*

Main category: cs.CV

TL;DR: 提出了一种联合估计反照率并生成重光照输出的单阶段方法，利用视频扩散模型的生成能力，解决了现有方法在数据稀缺和复杂光照条件下的局限性。

- Motivation: 现有端到端重光照模型因多光照配对数据稀缺而泛化能力受限，而两阶段流水线易产生误差累积且难以处理复杂光照或材质。
- Method: 采用单阶段联合估计反照率和生成重光照输出的方法，结合视频扩散模型的生成能力，提升场景理解和光照效果合成。
- Result: 模型在合成多光照数据和自动标注的真实视频上训练，表现出强泛化能力，在视觉保真度和时间一致性上优于先前方法。
- Conclusion: 该方法通过联合优化和生成模型的应用，显著提升了重光照任务的效果和泛化能力。


### [64] [Sekai: A Video Dataset towards World Exploration](https://arxiv.org/abs/2506.15675)
*Zhen Li,Chuanhao Li,Xiaofeng Mao,Shaoheng Lin,Ming Li,Shitian Zhao,Zhaopan Xu,Xinyue Li,Yukang Feng,Jianwen Sun,Zizhen Li,Fanrui Zhang,Jiaxin Ai,Zhixiang Wang,Yuwei Wu,Tong He,Jiangmiao Pang,Yu Qiao,Yunde Jia,Kaipeng Zhang*

Main category: cs.CV

TL;DR: 论文介绍了Sekai数据集，一个高质量的第一人称视角全球视频数据集，用于世界探索训练，包含丰富的标注信息。

- Motivation: 现有视频生成数据集不适合世界探索训练，存在地点有限、时长短、场景静态和缺乏探索标注等问题。
- Method: 开发了一个高效的工具箱，用于收集、预处理和标注视频，包括位置、场景、天气等信息。
- Result: Sekai数据集包含5000多小时视频，覆盖100多个国家和750个城市，实验验证了其质量。
- Conclusion: Sekai数据集将推动视频生成和世界探索领域的发展，并激发有价值的应用。


### [65] [Evolutionary Caching to Accelerate Your Off-the-Shelf Diffusion Model](https://arxiv.org/abs/2506.15682)
*Anirud Aggarwal,Abhinav Shrivastava,Matthew Gwilliam*

Main category: cs.CV

TL;DR: ECAD是一种基于遗传算法的缓存调度方法，显著加速扩散模型的推理速度，无需修改网络参数或参考图像，且能适应不同模型和分辨率。

- Motivation: 扩散模型生成高质量图像但推理速度慢且计算成本高，现有方法依赖固定启发式规则，效果有限且泛化性差。
- Method: 提出ECAD，利用遗传算法学习高效的缓存调度策略，形成帕累托前沿，仅需少量校准提示。
- Result: 在PixArt-alpha等模型上，ECAD显著提升推理速度（2.58x）并改善生成质量（COCO FID提升4.47）。
- Conclusion: ECAD是一种可扩展且泛化性强的扩散模型加速方法。
## cs.MM

### [66] [Omnidirectional Video Super-Resolution using Deep Learning](https://arxiv.org/abs/2506.14803)
*Arbind Agrahari Baniya,Tsz-Kwan Lee,Peter W. Eklund,Sunil Aryal*

Main category: cs.MM

TL;DR: 本文提出了一种针对360°视频的超分辨率方法S3PO，解决了传统VSR技术无法处理的球面失真问题，并创建了新的360VDS数据集。

- Motivation: 360°视频在VR中广泛应用，但分辨率不足影响视觉质量，且缺乏针对球面失真的超分辨率技术和数据集。
- Method: 提出S3PO模型，采用循环建模和注意力机制，结合专用特征提取器和新型损失函数处理球面失真。
- Result: S3PO在360°视频数据集上优于现有VSR和360°专用超分辨率模型。
- Conclusion: S3PO为360°视频超分辨率提供了有效解决方案，并通过消融研究验证了其组件的有效性。
## cs.SE

### [67] [An Empirical Study of Bugs in Data Visualization Libraries](https://arxiv.org/abs/2506.15084)
*Weiqi Lu,Yongqiang Tian,Xiaohan Zhong,Haoyang Ma,Zhenyang Xu,Shing-Chi Cheung,Chengnian Sun*

Main category: cs.SE

TL;DR: 本文首次全面分析了数据可视化库中的错误，研究了564个来自五个常用库的bug，系统分析了症状和根本原因，并提供了详细分类。研究发现错误/不准确的图表普遍存在，主要原因是图形计算错误，需要进一步自动化测试方法。此外，识别了触发bug的八个关键步骤和两个特定测试预言，为未来自动化测试技术设计提供启发。探索了视觉语言模型（VLMs）检测错误图表的可行性，结果显示其效果因提示而异。

- Motivation: 数据可视化库的准确性对用户体验和信息传达至关重要，错误可能导致误导性决策。理解这些bug的特性对检测和修复至关重要。
- Method: 收集并分析了564个来自五个常用数据可视化库的bug，系统分类其症状和根本原因，并探索了VLMs在检测错误图表中的应用。
- Result: 发现错误图表普遍存在，主要原因是图形计算错误；识别了触发bug的关键步骤和特定测试预言；VLMs检测效果因提示而异，效果在29%至57%之间。
- Conclusion: 研究为数据可视化库的自动化测试提供了重要见解，并探索了VLMs的应用潜力，但提示设计对其效果影响显著。
## cs.GR

### [68] [Human Motion Capture from Loose and Sparse Inertial Sensors with Garment-aware Diffusion Models](https://arxiv.org/abs/2506.15290)
*Andela Ilic,Jiaxi Jiang,Paul Streli,Xintong Liu,Christian Holz*

Main category: cs.GR

TL;DR: 提出了一种基于稀疏、松散附着IMU传感器的全身姿态估计方法，通过模拟数据和扩散模型解决实际问题。

- Motivation: 现有方法假设IMU传感器紧密附着于人体，但现实中常为松散附着，需解决这一挑战。
- Method: 利用现有服装感知运动数据集模拟IMU数据，开发基于Transformer的扩散模型合成松散IMU数据并估计姿态。
- Result: 实验表明，该方法在模拟和合成数据上优于现有技术，定量和定性表现更优。
- Conclusion: 该方法为未来研究提供了新方向，尤其在松散附着IMU场景下表现突出。


### [69] [One-shot Face Sketch Synthesis in the Wild via Generative Diffusion Prior and Instruction Tuning](https://arxiv.org/abs/2506.15312)
*Han Wu,Junyao Li,Kangbo Zhao,Sen Zhang,Yukai Shi,Liang Lin*

Main category: cs.GR

TL;DR: 提出一种基于扩散模型的一次性人脸素描合成方法，通过优化文本指令实现高效生成，并引入新基准数据集OS-Sketch。

- Motivation: 解决现有方法依赖大量训练数据、数据稀缺和高人力成本的问题。
- Method: 基于扩散模型，优化文本指令，利用梯度优化进行推理。
- Result: 在一次性场景下，能生成真实且高度一致的素描，具有更广泛的适用性。
- Conclusion: 该方法在数据稀缺场景下表现优异，优于现有方法，数据集将公开。


### [70] [Nabla-R2D3: Effective and Efficient 3D Diffusion Alignment with 2D Rewards](https://arxiv.org/abs/2506.15684)
*Qingming Liu,Zhen Liu,Dinghuai Zhang,Kui Jia*

Main category: cs.GR

TL;DR: Nabla-R2D3是一种基于强化学习的对齐框架，通过2D奖励信号优化3D扩散模型，显著提升生成质量。

- Motivation: 当前3D生成模型（如扩散模型）在遵循指令、对齐人类偏好及生成逼真纹理、几何和物理属性方面存在不足。
- Method: 提出Nabla-R2D3框架，基于Nabla-GFlowNet方法，利用2D奖励信号对3D扩散模型进行高效强化学习对齐。
- Result: 实验表明，Nabla-R2D3在少量微调步骤内即可实现更高奖励和减少先验遗忘，优于基线方法。
- Conclusion: Nabla-R2D3为3D生成模型提供了一种高效对齐方法，显著提升生成质量。
## cs.AI

### [71] [Embodied Web Agents: Bridging Physical-Digital Realms for Integrated Agent Intelligence](https://arxiv.org/abs/2506.15677)
*Yining Hong,Rui Sun,Bingxuan Li,Xingcheng Yao,Maxine Wu,Alexander Chien,Da Yin,Ying Nian Wu,Zhecan James Wang,Kai-Wei Chang*

Main category: cs.AI

TL;DR: 论文提出了一种新型AI代理范式——Embodied Web Agents，旨在结合物理世界交互与网络规模推理，解决跨领域任务。

- Motivation: 当前AI代理多为孤立系统，无法同时处理物理交互与网络知识，限制了其在需要跨领域智能的任务中的应用。
- Method: 开发了统一的仿真平台（Embodied Web Agents task environments）和基准测试（Embodied Web Agents Benchmark），涵盖烹饪、导航等任务。
- Result: 实验显示现有AI系统与人类能力存在显著差距，揭示了跨领域智能的挑战与机遇。
- Conclusion: 该研究为结合物理交互与网络推理的AI代理提供了新方向，相关资源已公开。
## eess.IV

### [72] [Empirical Studies of Large Scale Environment Scanning by Consumer Electronics](https://arxiv.org/abs/2506.14771)
*Mengyuan Wang,Yang Liu,Haopeng Wang,Haiwei Dong,Abdulmotaleb El Saddik*

Main category: eess.IV

TL;DR: 本文评估了Matterport Pro3在大型环境重建中的表现，对比iPhone，展示了其高密度点云和高对齐精度的优势。

- Motivation: 研究Matterport Pro3在大型建筑扫描中的实际效果，探索其性能提升和挑战解决方案。
- Method: 通过1,099个扫描点对六层建筑（17,567平方米）进行详细扫描，并与iPhone对比分析。
- Result: Pro3生成1,877,324个点云，RMSE为0.0118米，优于iPhone的506,961点和更高误差。
- Conclusion: Pro3适合大规模应用，结合LiDAR和先进对齐技术，能生成高质量3D模型。


### [73] [Deploying and Evaluating Multiple Deep Learning Models on Edge Devices for Diabetic Retinopathy Detection](https://arxiv.org/abs/2506.14834)
*Akwasi Asare,Dennis Agyemanh Nana Gookyi,Derrick Boateng,Fortunatus Aabangbio Wulnye*

Main category: eess.IV

TL;DR: 该研究提出了一种基于Edge Impulse的边缘设备实时糖尿病视网膜病变（DR）检测方法，使用多种深度学习模型，并在资源受限环境中表现出色。

- Motivation: 糖尿病视网膜病变（DR）是全球糖尿病患者的常见并发症，传统诊断方法耗时且资源密集，亟需高效、低成本的解决方案。
- Method: 研究通过预处理增强Kaggle EyePACS数据集，训练并优化多种CNN模型（如MobileNet、ShuffleNet等），并将其部署到边缘设备上。
- Result: MobileNet准确率达96.45%，SqueezeNet模型仅176 KB且延迟17 ms，适合实时检测；其他模型在资源效率上表现优异。
- Conclusion: 边缘AI技术为DR早期检测提供了可扩展、低成本的解决方案，尤其适用于资源受限的医疗环境。


### [74] [Improving Prostate Gland Segmenting Using Transformer based Architectures](https://arxiv.org/abs/2506.14844)
*Shatha Abudalou*

Main category: eess.IV

TL;DR: 研究比较了UNETR和SwinUNETR在T2加权MRI图像中前列腺分割的性能，发现SwinUNETR在多种训练策略下表现优于UNETR和基线3D UNet，尤其在处理标签噪声和类别不平衡时更具鲁棒性。

- Motivation: 解决T2加权MRI图像中前列腺分割的读者间变异性和跨站点域偏移问题，探索Transformer模型在此类异质性下的表现。
- Method: 使用546个MRI（T2加权）体积数据，比较UNETR、SwinUNETR和基线3D UNet的性能，采用三种训练策略（单队列、5折交叉验证混合队列、基于腺体大小的数据集），并通过Optuna调整超参数。
- Result: SwinUNETR在单读者训练中Dice分数为0.816（Reader#1）和0.860（Reader#2），在交叉验证混合训练中表现更优，尤其在基于腺体大小的数据集中达到0.902（Reader#1）和0.894（Reader#2）。
- Conclusion: SwinUNETR通过全局和移位窗口自注意力机制有效减少标签噪声和类别不平衡敏感性，比CNN模型提升高达5个Dice分数点，适合临床部署。


### [75] [Foundation Artificial Intelligence Models for Health Recognition Using Face Photographs (FAHR-Face)](https://arxiv.org/abs/2506.14909)
*Fridolin Haugg,Grace Lee,John He,Leonard Nürnberg,Dennis Bontempi,Danielle S. Bitterman,Paul Catalano,Vasco Prudente,Dmitrii Glubokov,Andrew Warrington,Suraj Pai,Dirk De Ruysscher,Christian Guthier,Benjamin H. Kann,Vadim N. Gladyshev,Hugo JWL Aerts,Raymond H. Mak*

Main category: eess.IV

TL;DR: FAHR-Face是一个基于4000万张面部图像训练的基础模型，用于生物年龄估计和生存风险预测，表现出色且具有临床实用性。

- Motivation: 通过面部外观非侵入性地评估健康和疾病风险。
- Method: 两阶段微调训练，分别在公开数据集和癌症患者数据上测试模型鲁棒性和独立性。
- Result: FAHR-FaceAge在年龄估计上误差最低（5.1年），FAHR-FaceSurvival能稳健预测死亡率，两者结合提高预后准确性。
- Conclusion: 单一基础模型可生成低成本、可扩展的面部生物标志物，捕捉生物衰老和疾病相关死亡风险。


### [76] [Recursive Variational Autoencoders for 3D Blood Vessel Generative Modeling](https://arxiv.org/abs/2506.14914)
*Paula Feldman,Miguel Fainstein,Viviana Siless,Claudio Delrieux,Emmanuel Iarussi*

Main category: eess.IV

TL;DR: 提出了一种递归变分神经网络（RvNN）用于生成多样化且准确的血管3D模型，解决了传统规则方法无法捕捉真实解剖数据复杂性的问题。

- Motivation: 解剖树在临床诊断和治疗规划中至关重要，但现有方法多为规则驱动，难以模拟真实血管的多样性和复杂性。
- Method: 开发了RvNN，利用血管的层次结构学习低维流形编码分支连接和几何特征，生成新的血管几何形状。
- Result: 生成的血管模型在半径、长度和弯曲度等方面与真实数据高度相似，适用于医学培训和血流模拟等。
- Conclusion: RvNN首次用于血管合成，生成的模型准确且多样，具有广泛的应用潜力。


### [77] [NeuroMoE: A Transformer-Based Mixture-of-Experts Framework for Multi-Modal Neurological Disorder Classification](https://arxiv.org/abs/2506.14970)
*Wajih Hassan Raza,Aamir Bader Shah,Yu Wen,Yidan Shen,Juan Diego Martinez Lemus,Mya Caryn Schiess,Timothy Michael Ellmore,Renjie Hu,Xin Fu*

Main category: eess.IV

TL;DR: 提出了一种基于Transformer的Mixture-of-Experts框架，结合多模态MRI和临床数据，显著提升了神经退行性疾病的诊断准确性。

- Motivation: 现有深度学习方法在多模态MRI和临床数据的整合上表现不佳，影响了神经退行性疾病的诊断效果。
- Method: 使用Transformer编码器捕捉MRI数据的空间关系，结合模态特定的专家模块进行特征提取，并通过自适应融合门控机制整合输出。
- Result: 验证准确率达到82.47%，比基线方法提升超过10%，尤其在区分重叠疾病状态上表现突出。
- Conclusion: 该框架通过多模态学习显著提升了神经退行性疾病的诊断性能，展示了在真实临床数据中的应用潜力。


### [78] [Classification of Multi-Parametric Body MRI Series Using Deep Learning](https://arxiv.org/abs/2506.15182)
*Boah Kim,Tejas Sudharshan Mathai,Kimberly Helm,Peter A. Pinto,Ronald M. Summers*

Main category: eess.IV

TL;DR: 提出一种基于深度学习的模型，用于分类8种不同的MRI序列类型，以提高放射科医生的工作效率。

- Motivation: 解决DICOM头部信息错误的问题，提高MRI序列分类的准确性。
- Method: 使用ResNet、EfficientNet和DenseNet等深度学习模型进行训练和比较，并研究不同训练数据量对性能的影响。
- Result: DenseNet-121模型表现最佳，F1分数和准确率分别为0.966和0.972，且在外部数据集上表现良好。
- Conclusion: DenseNet-121模型在内部和外部数据集上均表现出高准确性，适用于MRI序列分类任务。


### [79] [Privacy-Preserving Chest X-ray Classification in Latent Space with Homomorphically Encrypted Neural Inference](https://arxiv.org/abs/2506.15258)
*Jonghun Kim,Gyeongdeok Jo,Shinyoung Ra,Hyunjin Park*

Main category: eess.IV

TL;DR: 提出了一种基于VQGAN和HE的医疗图像隐私保护推理框架，通过压缩图像和多项式近似激活函数降低计算负担。

- Motivation: 医疗图像包含敏感信息，需要隐私保护，但HE推理计算成本高。
- Method: 使用VQGAN压缩图像，多项式近似激活函数，结合SE模块优化HE框架。
- Result: 在胸部X光数据集上测试，压缩因子为8时性能与计算成本最优。
- Conclusion: 方法在医疗图像隐私保护中具有实用潜力，尽管HE推理仍较慢。


### [80] [FedWSIDD: Federated Whole Slide Image Classification via Dataset Distillation](https://arxiv.org/abs/2506.15365)
*Haolong Jin,Shenglin Liu,Cong Cong,Qingmin Feng,Yongzhi Liu,Lina Huang,Yingzi Hu*

Main category: eess.IV

TL;DR: FedWSIDD是一种新颖的联邦学习范式，通过数据集蒸馏（DD）技术解决WSI分类中的计算资源异构性和隐私问题，显著提升分类性能并保护患者隐私。

- Motivation: 解决联邦学习在医学图像分析中面临的异构计算资源和隐私保护问题。
- Method: 提出FedWSIDD，利用数据集蒸馏生成合成切片，服务器聚合并分发这些切片，客户端结合本地任务使用。
- Result: 在CAMELYON16和CAMELYON17等任务中表现优异，提升分类性能并保护隐私。
- Conclusion: FedWSIDD是一种高效、灵活的解决方案，适用于复杂的WSI分类任务。


### [81] [A Real-time Endoscopic Image Denoising System](https://arxiv.org/abs/2506.15395)
*Yu Xing,Shishi Huang,Meng Lv,Guo Chen,Huailiang Wang,Lingzhi Sui*

Main category: eess.IV

TL;DR: 本文分析了微型内窥镜中模拟图像传感器的噪声问题，并提出了一种混合去噪系统，结合传统图像处理与学习技术，显著提升了图像质量。

- Motivation: 微型内窥镜虽提升了便携性和诊断能力，但小尺寸传感器导致光子捕获不足、动态范围受限及噪声问题，影响图像质量。
- Method: 开发了噪声模型，识别三种主要噪声类型，并提出混合去噪系统，结合传统算法与学习技术。
- Result: 实验显示，系统有效降噪且保留细节，PSNR从21.16提升至33.05，并在FPGA上实现实时性能。
- Conclusion: 混合去噪系统解决了微型内窥镜图像噪声问题，为医疗诊断提供了更高质量的图像支持。


### [82] [Advanced cervical cancer classification: enhancing pap smear images with hybrid PMD Filter-CLAHE](https://arxiv.org/abs/2506.15489)
*Ach Khozaimi,Isnani Darti,Syaiful Anam,Wuryansari Muharini Kusumawinahyu*

Main category: eess.IV

TL;DR: 研究探讨了图像预处理技术对CNN在宫颈癌分类中的性能影响，提出了一种混合PMD滤波器和CLAHE的方法，显著提升了分类性能。

- Motivation: 宫颈癌早期检测至关重要，但CNN性能受图像质量影响，因此研究预处理技术对性能的提升。
- Method: 评估了PMD滤波、CLAHE及混合方法对SIPaKMeD数据集的预处理效果，并在多个预训练模型上测试。
- Result: 混合方法显著提升了图像质量和CNN性能，最高提升13.62%准确率。
- Conclusion: 混合PMD-CLAHE方法为宫颈癌分类提供了新思路，显著改善了CNN性能。


### [83] [Automated MRI Tumor Segmentation using hybrid U-Net with Transformer and Efficient Attention](https://arxiv.org/abs/2506.15562)
*Syed Haider Ali,Asrar Ahmad,Muhammad Ali,Asifullah Khan,Muhammad Shahban,Nadeem Shaukat*

Main category: eess.IV

TL;DR: 该研究提出了一种基于混合UNet-Transformer模型的肿瘤分割方法，用于本地医院的MRI数据集，以提高放疗计划的准确性和效率。

- Motivation: 现有AI分割模型通常基于大型公共数据集，缺乏本地患者的异质性，因此需要开发适用于本地数据的模型以优化临床治疗。
- Method: 研究采用混合UNet-Transformer架构，结合多种注意力模块（如SE、CBAM等），并通过数据增强和预训练权重初始化提升性能。
- Result: 在本地MRI数据集上，模型达到了Dice系数0.764和IoU 0.736，表现优异。
- Conclusion: 研究表明，针对特定临床场景的模型开发对肿瘤分割的临床应用至关重要。
## cs.SD

### [84] [pycnet-audio: A Python package to support bioacoustics data processing](https://arxiv.org/abs/2506.14864)
*Zachary J. Ruff,Damon B. Lesmeister*

Main category: cs.SD

TL;DR: 论文介绍了被动声学监测技术及其自动化处理工具pycnet-audio，用于分析野生动物声音数据。

- Motivation: 解决大规模声学数据手动处理不切实际的问题，提供自动化检测方法。
- Method: 利用PNW-Cnet模型扩展功能，检测约80种森林野生动物声音及人为环境噪音。
- Result: pycnet-audio为声学数据提供实用处理流程，支持大规模数据分析。
- Conclusion: 自动化工具pycnet-audio显著提升了声学数据的处理效率和实用性。


### [85] [An accurate and revised version of optical character recognition-based speech synthesis using LabVIEW](https://arxiv.org/abs/2506.15029)
*Prateek Mehta,Anasuya Patil*

Main category: cs.SD

TL;DR: 开发了一种基于OCR的语音合成系统，帮助视障人士通过声音获取书籍内容。

- Motivation: 视障人士依赖盲文和音频书籍，但选择有限，语音是更有效的沟通方式。
- Method: 使用LabVIEW实现OCR系统，将文本转换为语音。
- Result: 系统准确、可靠、经济且用户友好。
- Conclusion: OCR语音合成系统为视障人士提供了更便捷的书籍访问方式。
## cs.LG

### [86] [PIPE: Physics-Informed Position Encoding for Alignment of Satellite Images and Time Series](https://arxiv.org/abs/2506.14786)
*Haobo Li,Eunseo Jung,Zixin Chen,Zhaowei Wang,Yueya Wang,Huamin Qu,Alexis Kai Hon Lau*

Main category: cs.LG

TL;DR: 论文提出了一种名为PIPE的轻量级方法，通过物理信息位置编码将物理信息嵌入视觉语言模型，显著提升了多模态对齐和预测精度。

- Motivation: 现有方法主要关注文本数据，忽略了视觉数据中的物理信息（如卫星图像的时间和地理空间背景），导致模型难以有效捕捉这些信息。
- Method: PIPE包含两个创新点：(1) 物理信息位置索引方案，将物理信息映射到位置ID；(2) 变频率位置编码机制，编码物理变量的频率信息和令牌的顺序信息。
- Result: 在最大开源卫星图像数据集上，PIPE在深度学习和气候领域方法中均达到最优性能，台风强度预测精度提升12%。
- Conclusion: PIPE通过嵌入物理信息，显著提升了多模态时间序列预测的准确性，尤其在处理视觉数据时表现出色。


### [87] [Reinforcing VLMs to Use Tools for Detailed Visual Reasoning Under Resource Constraints](https://arxiv.org/abs/2506.14821)
*Sunil Kumar,Bowen Zhao,Leo Dirac,Paulina Varshavskaya*

Main category: cs.LG

TL;DR: 小规模视觉语言模型通过GRPO学习和外部工具（如缩放）提升详细视觉推理能力，在有限计算资源下表现优于基线模型。

- Motivation: 尽管大模型推理能力进步显著，但视觉语言模型在详细视觉推理上仍有不足，尤其是在计算资源有限时。
- Method: 采用Group Relative Policy Optimization（GRPO）训练小规模模型，结合简单奖励结构、简化工具调用接口、为工具调用结果分配额外标记，以及侧重视觉困难样本的训练数据。
- Result: 在部分视觉问答任务中，该方法表现优于类似规模的基线模型，得益于从外部工具获取的详细视觉信息。
- Conclusion: GRPO结合外部工具可有效提升小规模视觉语言模型的详细视觉推理能力。


### [88] [CACTUS as a Reliable Tool for Early Classification of Age-related Macular Degeneration](https://arxiv.org/abs/2506.14843)
*Luca Gherardini,Imre Lengyel,Tunde Peto,Caroline C. W. Klaverd,Magda A. Meester-Smoord,Johanna Maria Colijnd,EYE-RISK Consortium,E3 Consortium,Jose Sousa*

Main category: cs.LG

TL;DR: CACTUS工具通过结合多因素数据提升AMD分类性能，提供可解释性和灵活性，优于传统ML模型。

- Motivation: 医疗数据通常不完整且有限，传统ML模型在透明度和可信度上存在问题，AMD早期诊断需求迫切。
- Method: 开发CACTUS工具，整合遗传、饮食、临床和人口统计学数据，优化分类并消除偏见。
- Result: CACTUS在AMD分类中表现优于标准ML模型，提供关键特征解释和结果可信度。
- Conclusion: CACTUS为临床决策提供支持，通过识别关键特征并与医学知识对比，减少偏见。


### [89] [Pixel-level Certified Explanations via Randomized Smoothing](https://arxiv.org/abs/2506.15499)
*Alaa Anani,Tobias Lorenz,Mario Fritz,Bernt Schiele*

Main category: cs.LG

TL;DR: Error

- Motivation: Error
- Method: Error
- Result: Error
- Conclusion: Error
## cs.RO

### [90] [Towards Perception-based Collision Avoidance for UAVs when Guiding the Visually Impaired](https://arxiv.org/abs/2506.14857)
*Suman Raj,Swapnil Padhi,Ruchi Bhoot,Prince Modi,Yogesh Simmhan*

Main category: cs.RO

TL;DR: 论文提出了一种基于感知的路径规划系统，结合无人机和机器学习，帮助视障人士在城市环境中导航。

- Motivation: 通过无人机和机器学习技术，解决视障人士在城市户外环境中的导航问题。
- Method: 提出了一种几何问题表示方法，结合多DNN框架进行无人机和视障人士的障碍物避障，并整合了基于GPS和地图的全局规划器。
- Result: 在校园环境中进行了无人机-人类系统测试，验证了算法在三种场景（人行道、停车区、拥挤街道）中的可行性。
- Conclusion: 研究证明了所提算法在视障人士导航中的有效性，为实际应用提供了基础。


### [91] [Robust Instant Policy: Leveraging Student's t-Regression Model for Robust In-context Imitation Learning of Robot Manipulation](https://arxiv.org/abs/2506.15157)
*Hanbit Oh,Andrea M. Salcedo-Vázquez,Ixchel G. Ramirez-Alpizar,Yukiyasu Domae*

Main category: cs.RO

TL;DR: 论文提出了一种鲁棒的上下文模仿学习算法RIP，通过使用Student's t回归模型减少LLM生成的幻觉轨迹，显著提高了任务成功率。

- Motivation: 解决基于LLM的即时策略在机器人领域中因幻觉问题导致的轨迹偏离问题。
- Method: 利用Student's t分布聚合LLM生成的多个候选轨迹，忽略异常值（幻觉），生成鲁棒轨迹。
- Result: 在模拟和真实环境中，RIP比现有IL方法任务成功率至少提高26%，尤其在低数据场景下表现优异。
- Conclusion: RIP通过鲁棒性设计有效解决了LLM幻觉问题，提升了模仿学习的可靠性。


### [92] [MCOO-SLAM: A Multi-Camera Omnidirectional Object SLAM System](https://arxiv.org/abs/2506.15402)
*Miaoxin Pan,Jinnan Li,Yaowen Zhang,Yi Yang,Yufeng Yue*

Main category: cs.RO

TL;DR: MCOO-SLAM是一种多相机全向物体SLAM系统，利用环绕视角相机配置在复杂户外场景中实现鲁棒、一致且语义丰富的建图。

- Motivation: 现有SLAM方法依赖RGB-D或单目相机，视野窄、易受遮挡且深度感知有限，导致物体建模不准确和数据关联不可靠。
- Method: 结合点特征和物体级地标，引入语义-几何-时间融合策略，设计全向闭环模块，构建分层3D场景图。
- Result: 实验表明MCOO-SLAM在真实场景中实现了精确定位和可扩展的物体级建图，对遮挡、姿态变化和环境复杂性具有更强鲁棒性。
- Conclusion: MCOO-SLAM通过多相机配置和语义增强，显著提升了复杂户外场景中的SLAM性能。


### [93] [Particle-Grid Neural Dynamics for Learning Deformable Object Models from RGB-D Videos](https://arxiv.org/abs/2506.15680)
*Kaifeng Zhang,Baoyu Li,Kris Hauser,Yunzhu Li*

Main category: cs.RO

TL;DR: 该论文提出了一种结合粒子与空间网格的神经动力学框架，用于建模可变形物体的动态行为，并通过实验验证了其优越性能。

- Motivation: 可变形物体的动态建模具有挑战性，尤其是从有限的视觉信息中估计状态。
- Method: 采用粒子-网格混合表示，结合高斯渲染技术，实现基于学习的数字孪生。
- Result: 模型能够从稀疏视角的RGB-D记录中学习多种物体的动态，并在类别级别泛化到未见实例。
- Conclusion: 该方法在有限视角下优于现有学习与物理模拟器，并展示了在目标驱动物体操作中的实用性。
