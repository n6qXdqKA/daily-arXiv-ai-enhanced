[[toc]]

## cs.CV

### [1] [GRAFNet: Multiscale Retinal Processing via Guided Cortical Attention Feedback for Enhancing Medical Image Polyp Segmentation](https://arxiv.org/abs/2602.15072)
*Abdul Joseph Fofanah,Lian Wen,Alpha Alimamy Kamara,Zhongyi Zhang,David Chen,Albert Patrick Sankoh*

Main category: cs.CV

TL;DR: GRAFNet是一种受生物视觉系统启发的息肉分割网络，通过模拟人类视觉层次结构，结合导向注意力、多尺度视网膜模块和皮层反馈机制，在多个公开数据集上实现了3-8%的Dice提升和10-20%的泛化能力提升。

- Motivation: 结肠镜息肉分割对癌症预防至关重要，但面临三大挑战：息肉形态高度可变（从扁平到突出病变）、与正常结构（褶皱和血管）视觉相似性强、需要鲁棒的多尺度检测。现有深度学习方法存在单向处理、多尺度融合弱、缺乏解剖约束等问题，导致假阳性（正常结构过分割）和假阴性（漏检扁平病变）。
- Method: 提出GRAFNet生物启发架构，模拟人类视觉系统层次结构：1) 导向非对称注意力模块(GAAM)模拟方向调谐皮层神经元，强调息肉边界；2) 多尺度视网膜模块(MSRM)复制视网膜神经节细胞通路，进行并行多特征分析；3) 导向皮层注意力反馈模块(GCAFM)应用预测编码进行迭代细化。这些模块通过息肉编码器-解码器模块(PEDM)统一，通过分辨率自适应反馈强制空间语义一致性。
- Result: 在五个公开基准测试（Kvasir-SEG、CVC-300、CVC-ColonDB、CVC-Clinic、PolypGen）上展示了一致的SOTA性能，相比领先方法实现了3-8%的Dice改进和10-20%的更高泛化能力，同时提供可解释的决策路径。
- Conclusion: 这项工作建立了一个范式，其中神经计算原理弥合了AI准确性与临床可信推理之间的差距，为医学图像分析提供了可解释且高性能的解决方案。


### [2] [Zero-shot HOI Detection with MLLM-based Detector-agnostic Interaction Recognition](https://arxiv.org/abs/2602.15124)
*Shiyu Xuan,Dongkai Wang,Zechao Li,Jinhui Tang*

Main category: cs.CV

TL;DR: 提出一种解耦的零样本人-物交互检测框架，将目标检测与交互识别分离，利用多模态大语言模型进行零样本交互识别，无需训练即可工作，也可通过微调提升性能。

- Motivation: 现有零样本人-物交互检测方法通常将交互识别与特定检测器紧密耦合，依赖粗粒度的视觉-语言模型特征，限制了未见交互的泛化能力。需要一种更灵活、泛化性更强的解决方案。
- Method: 1) 解耦框架：将目标检测与交互识别分离，可与任意目标检测器集成；2) 确定性生成方法：将交互识别建模为视觉问答任务，强制确定性输出，实现无需训练的零样本交互识别；3) 空间感知池化模块：整合外观特征和成对空间线索；4) 一次性确定性匹配方法：单次前向传播预测所有候选交互。
- Result: 在HICO-DET和V-COCO数据集上的广泛实验表明，该方法实现了优越的零样本性能、强大的跨数据集泛化能力，并且能够灵活集成任意目标检测器而无需重新训练。
- Conclusion: 提出的解耦框架通过分离目标检测与交互识别，利用多模态大语言模型进行零样本交互识别，实现了更好的泛化性、灵活性和性能，为开放词汇人-物交互检测提供了有效解决方案。


### [3] [MB-DSMIL-CL-PL: Scalable Weakly Supervised Ovarian Cancer Subtype Classification and Localisation Using Contrastive and Prototype Learning with Frozen Patch Features](https://arxiv.org/abs/2602.15138)
*Marcus Jenkins,Jasenka Mazibrada,Bogdan Leahu,Michal Mackiewicz*

Main category: cs.CV

TL;DR: 提出一种基于对比学习和原型学习的卵巢癌组织病理学分型方法，使用预计算冻结特征，在保持可扩展性的同时提升分类和定位性能。

- Motivation: 卵巢癌组织病理学分型对个性化治疗很重要，但诊断工作量增加给病理科带来挑战。传统方法依赖预计算特征，端到端方法虽提升准确性但训练可扩展性差且实验耗时。需要在保持预计算特征可扩展性的同时提升性能。
- Method: 提出基于对比学习和原型学习的方法，使用预计算冻结特征，通过特征空间增强技术进行子型分类和定位。
- Result: 相比DSMIL方法，在实例级分类F1分数提升70.4%，切片级分类F1分数提升15.3%，实例定位AUC提升16.9%，切片分类AUC提升2.3%，同时保持使用冻结特征。
- Conclusion: 该方法在保持预计算特征可扩展性优势的同时，显著提升了卵巢癌组织病理学分型分类和定位的性能，解决了传统方法与端到端方法之间的权衡问题。


### [4] [Loss Knows Best: Detecting Annotation Errors in Videos via Loss Trajectories](https://arxiv.org/abs/2602.15154)
*Praditha Alwis,Soumyadeep Chandra,Deepak Ravikumar,Kaushik Roy*

Main category: cs.CV

TL;DR: 提出基于累积样本损失(CSL)的视频标注错误检测方法，通过分析帧级损失轨迹识别错误标注和时序错乱

- Motivation: 现实世界视频数据集常存在标注错误（错误标签和时序错乱），这些错误在需要时序一致性的任务中特别有害，需要模型无关的检测方法
- Method: 提出累积样本损失(CSL)方法：训练视频分割模型并保存每个epoch的权重，用这些检查点评估测试视频中每帧的损失，将损失持续高的帧标记为可能的标注错误
- Result: 在EgoPER和Cholec80数据集上实验表明，该方法能有效检测错误标注和帧级时序错乱等细微不一致性
- Conclusion: 该方法为数据集审计和提升视频机器学习训练可靠性提供了强大工具，无需标注错误的地面真值，具有跨数据集通用性


### [5] [Distributional Deep Learning for Super-Resolution of 4D Flow MRI under Domain Shift](https://arxiv.org/abs/2602.15167)
*Xiaoyi Wen,Fei Jiang*

Main category: cs.CV

TL;DR: 提出一种分布深度学习框架，用于提升4D Flow MRI超分辨率性能，通过CFD模拟训练和小样本4D Flow MRI微调，解决临床真实场景中的域偏移问题。

- Motivation: 传统超分辨率方法依赖配对数据集（下采样和原始高分辨率图像），但在真实临床环境中，低分辨率数据通常来自与简单下采样不同的采集机制，导致输入数据超出训练域，模型泛化能力差。
- Method: 提出分布深度学习框架，先在CFD模拟的高分辨率数据及其下采样版本上训练，然后在少量配对的4D Flow MRI和CFD样本上进行微调，推导分布估计器的理论特性。
- Result: 框架显著优于传统深度学习方法，在真实数据应用中表现出色，证明分布学习能有效解决域偏移问题，提升临床真实场景中的超分辨率性能。
- Conclusion: 分布深度学习框架能有效解决医学成像超分辨率中的域偏移问题，提高模型鲁棒性和域泛化能力，在4D Flow MRI等临床应用中具有重要价值。


### [6] [Time-Archival Camera Virtualization for Sports and Visual Performances](https://arxiv.org/abs/2602.15181)
*Yunxiao Zhang,William Stone,Suryansh Kumar*

Main category: cs.CV

TL;DR: 提出基于神经体渲染的相机虚拟化方法，支持动态场景的高质量新视角合成和时间归档功能，特别适用于体育直播等应用。

- Motivation: 现有基于3D高斯泼溅的动态场景方法依赖准确点云且难以处理快速非刚性运动，而传统神经渲染方法缺乏时间归档能力，无法满足体育直播等应用的回放和分析需求。
- Method: 通过将动态场景建模为多个同步相机视图在特定时间的刚性变换，进行神经表示学习，实现高质量渲染和时间归档功能。
- Result: 方法在动态场景渲染质量上优于现有方法，支持用户回溯任意过去时间点进行新视角合成，实现回放、分析和归档功能。
- Conclusion: 神经体渲染方法为相机虚拟化提供了有效解决方案，特别适用于需要时间归档能力的体育直播和舞台表演等应用场景。


### [7] [How to Train Your Long-Context Visual Document Model](https://arxiv.org/abs/2602.15257)
*Austin Veselka*

Main category: cs.CV

TL;DR: 首个大规模长上下文视觉语言模型研究，训练上下文达344K，专注于长文档视觉问答，并在24B和32B参数模型上实现MMLongBenchDoc的SOTA性能。

- Motivation: 现有开源长上下文视觉语言模型（如Qwen3 VL和GLM 4.5/6V）的训练方法和数据流程不可复现，需要系统研究长上下文视觉语言模型的训练方法以填补这一空白。
- Method: 系统研究持续预训练、监督微调和偏好优化，使用合成数据管道，训练上下文长度达344K，并引入页面索引进行训练和评估。
- Result: 在24B和32B参数模型上实现了MMLongBenchDoc的最先进性能；发现匹配评估上下文长度的训练优于更长上下文的训练；页面索引显著提升长文档性能；视觉长上下文训练能迁移到长上下文文本性能。
- Conclusion: 该研究填补了长上下文视觉语言模型训练方法的空白，提供了可复现的训练方案和关键发现，并发布了修正版基准MMLBD-C以提升评估质量。


### [8] [Accelerating Large-Scale Dataset Distillation via Exploration-Exploitation Optimization](https://arxiv.org/abs/2602.15277)
*Muhammad J. Alahmadi,Peng Gao,Feiyi Wang,Dongkuan,Xu*

Main category: cs.CV

TL;DR: E^2D提出探索-利用蒸馏方法，通过两阶段优化策略减少冗余计算，在大规模数据集蒸馏中同时实现高精度和高效率。

- Motivation: 现有解耦式数据集蒸馏方法面临效率与精度的权衡：基于优化的方法精度高但计算密集，无优化的方法高效但精度低。需要克服这一矛盾。
- Method: E^2D采用全图像初始化保持语义完整性和特征多样性，然后进行两阶段优化：探索阶段执行均匀更新并识别高损失区域，利用阶段集中更新这些区域以加速收敛。
- Result: 在ImageNet-1K上超越SOTA且快18倍，在ImageNet-21K上显著提升精度且快4.3倍，证明针对性更新能有效平衡精度与效率。
- Conclusion: 通过减少冗余计算的针对性更新，而非暴力优化，能够在大规模数据集蒸馏中弥合精度与效率之间的差距。


### [9] [Visual Persuasion: What Influences Decisions of Vision-Language Models?](https://arxiv.org/abs/2602.15278)
*Manuel Cherep,Pranav M R,Pattie Maes,Nikhil Singh*

Main category: cs.CV

TL;DR: 提出一个框架来研究视觉语言模型(VLMs)的视觉偏好，通过系统编辑图像并观察模型选择来推断其潜在视觉效用函数，从而揭示AI代理的视觉偏好和潜在安全漏洞。

- Motivation: 随着网络图像越来越多地被视觉语言模型(VLMs)解释和决策，我们需要了解这些AI代理的视觉偏好结构，以发现潜在的视觉漏洞和安全问题。
- Method: 通过受控图像选择任务，系统性地扰动VLM的输入。采用视觉提示优化方法，使用图像生成模型对原始图像进行视觉上合理的修改(如构图、光照、背景等)，然后评估哪些编辑能提高选择概率。
- Result: 大规模实验表明，优化后的编辑显著改变了前沿VLM在头对头比较中的选择概率。开发了自动解释性管道来识别驱动选择的视觉主题。
- Conclusion: 该方法为揭示视觉漏洞提供了一种实用高效的方法，支持对基于图像的AI代理进行更主动的审计和治理，防止在真实环境中隐式发现安全问题。


### [10] [Consistency-Preserving Diverse Video Generation](https://arxiv.org/abs/2602.15287)
*Xinshuang Liu,Runfa Blark Li,Truong Nguyen*

Main category: cs.CV

TL;DR: 提出一种联合采样框架，用于提升文本到视频生成中的批次多样性，同时保持时间一致性，避免昂贵的视频解码和反向传播。

- Motivation: 文本到视频生成成本高昂，通常每个提示只能生成少量样本。在这种低样本情况下，最大化每批次的价值需要高跨视频多样性。现有方法虽然能提升图像生成的多样性，但在视频生成中往往会降低时间一致性，并且需要昂贵的视频解码器反向传播。
- Method: 提出联合采样框架，应用于流匹配视频生成器。方法包括：1）应用多样性驱动的更新；2）移除会降低时间一致性目标的分量；3）使用轻量级潜在空间模型计算目标函数，避免图像空间梯度和视频解码器反向传播。
- Result: 在最先进的文本到视频流匹配模型上的实验表明，该方法在保持与强联合采样基线相当的多样性的同时，显著提升了时间一致性和色彩自然度。
- Conclusion: 该方法能够在提升批次多样性的同时保持视频的时间一致性，且计算效率高，避免了昂贵的解码过程。


### [11] [Training-Free Zero-Shot Anomaly Detection in 3D Brain MRI with 2D Foundation Models](https://arxiv.org/abs/2602.15315)
*Tai Le-Gia,Jaehyun Ahn*

Main category: cs.CV

TL;DR: 提出一种无需训练、基于批量的零样本异常检测框架，将2D基础模型扩展到3D脑MRI，通过聚合多轴切片构建局部体积标记，实现体积异常检测。

- Motivation: 当前零样本异常检测主要局限于2D医学图像，扩展到3D体积图像面临挑战。现有方法依赖切片级特征和视觉语言模型，无法捕捉体积结构信息。
- Method: 构建局部体积标记：通过聚合多轴（冠状、矢状、轴向）切片，经2D基础模型处理，形成3D补丁标记。这些标记恢复立方空间上下文，直接与基于距离的批量级异常检测流程集成。
- Result: 无需训练、基于批量的零样本异常检测可以有效从2D编码器扩展到完整3D MRI体积，提供紧凑的3D表示，可在标准GPU上计算，无需微调、提示或监督。
- Conclusion: 该框架为体积异常检测提供了一种简单而稳健的方法，成功将训练免费的零样本异常检测从2D扩展到3D脑MRI，解决了现有方法无法捕捉体积结构的问题。


### [12] [Sparrow: Text-Anchored Window Attention with Visual-Semantic Glimpsing for Speculative Decoding in Video LLMs](https://arxiv.org/abs/2602.15318)
*Libo Zhang,Zhaoning Zhang,Wangyang Hong,Peng Qiao,Dongsheng Li*

Main category: cs.CV

TL;DR: Sparrow框架通过视觉感知文本锚定窗口注意力、中间层视觉状态桥接和多token预测策略，解决了视频大语言模型中推测解码的性能崩溃问题，在长序列下实现2.82倍加速。

- Motivation: 推测解码在视觉语言模型中广泛用于加速推理，但在视频大语言模型中面临严重的性能崩溃问题。草稿模型常因键值缓存爆炸和上下文窗口不匹配而陷入注意力稀释和负视觉增益的陷阱。
- Method: 1. 通过隐藏状态重用实现视觉感知文本锚定窗口注意力，将视觉计算完全卸载到目标模型；2. 利用中间层视觉状态桥接训练草稿模型，过滤低级视觉噪声；3. 引入多token预测策略弥合训练-推理分布偏移。
- Result: Sparrow在即使有25k视觉token的情况下也能实现平均2.82倍的加速，有效解决了长序列中的性能下降问题，为实时长视频任务提供了实用解决方案。
- Conclusion: Sparrow框架通过创新的视觉语义内部化利用方法，成功解决了视频大语言模型中推测解码的性能崩溃问题，实现了长视频任务的高效实时推理。


### [13] [EventMemAgent: Hierarchical Event-Centric Memory for Online Video Understanding with Adaptive Tool Use](https://arxiv.org/abs/2602.15329)
*Siwei Wen,Zhangcheng Wang,Xingjian Zhang,Lei Huang,Wenjun Wu*

Main category: cs.CV

TL;DR: EventMemAgent：基于分层记忆模块的主动在线视频理解框架，通过短期记忆检测事件边界、长期记忆结构化存档，结合多粒度感知工具包和Agentic RL实现端到端推理

- Motivation: 在线视频理解面临无限流媒体输入与MLLM有限上下文窗口的冲突。现有被动处理方法在保持长距离上下文与捕捉细粒度细节之间存在权衡，需要更主动的解决方案
- Method: 提出分层记忆模块：短期记忆动态检测事件边界并使用事件粒度水库采样处理流视频帧；长期记忆按事件结构化存档。结合多粒度感知工具包进行主动迭代证据捕获，并采用Agentic RL端到端内化推理和工具使用策略
- Result: 在在线视频基准测试中取得了有竞争力的结果
- Conclusion: EventMemAgent通过主动记忆管理和强化学习策略，有效解决了在线视频理解中的无限输入与有限上下文窗口的矛盾，为流媒体视频理解提供了新框架


### [14] [Effective and Robust Multimodal Medical Image Analysis](https://arxiv.org/abs/2602.15346)
*Joy Dhar,Nayyar Zaidi,Maryam Haghighat*

Main category: cs.CV

TL;DR: 提出MAIL和Robust-MAIL网络，解决多模态融合学习中的泛化性、计算效率和对抗鲁棒性问题，在20个公开数据集上表现优于现有方法

- Motivation: 现有多模态融合学习方法存在三个主要问题：1) 专注于特定模态，忽略跨模态的互补信息，限制多疾病分析的泛化能力；2) 依赖计算昂贵的模型，在资源有限环境中适用性差；3) 缺乏对抗攻击的鲁棒性，影响医疗AI应用的可靠性
- Method: 提出MAIL网络，包含两个关键组件：1) 高效残差学习注意力块，用于捕捉细化的模态特定多尺度模式；2) 高效多模态交叉注意力模块，用于学习跨模态的丰富互补共享表示。进一步扩展为Robust-MAIL，通过随机投影滤波器和调制注意力噪声增强对抗鲁棒性
- Result: 在20个公开数据集上的广泛评估显示，MAIL和Robust-MAIL均优于现有方法，性能提升高达9.34%，同时计算成本降低高达78.3%
- Conclusion: 提出的方法在泛化性、计算效率和对抗鲁棒性方面具有优势，能提供比顶级竞争对手更可靠的预测，适用于医疗AI应用


### [15] [CREMD: Crowd-Sourced Emotional Multimodal Dogs Dataset](https://arxiv.org/abs/2602.15349)
*Jinho Baek,Houwei Cao,Kate Blackwell*

Main category: cs.CV

TL;DR: CREMD数据集研究不同呈现模式（上下文、音频、视频）和标注者特征（养狗经验、性别、专业背景）如何影响狗情绪识别，发现视觉上下文显著提高标注一致性，音频增强标注者信心，但非养狗者和男性标注者表现出更高一致性。

- Motivation: 狗情绪识别对改善人-动物互动、兽医护理和自动化监控系统至关重要，但由于情绪评估的主观性和缺乏标准化方法，准确识别狗情绪具有挑战性。需要研究不同信息呈现方式和标注者特征如何影响情绪感知。
- Method: 创建CREMD数据集，包含923个视频片段，以三种模式呈现：无上下文无音频、有上下文无音频、有上下文有音频。收集来自不同背景参与者（养狗者、专业人士、不同人口统计特征）的标注，分析影响可靠狗情绪识别的因素。
- Result: 1) 视觉上下文显著提高标注一致性，音频效果因设计限制（缺少无上下文有音频条件、干净音频有限）而不确定；2) 非养狗者和男性标注者比养狗者和女性标注者一致性更高，专业人士一致性更高符合假设；3) 音频显著提高标注者对特定情绪（愤怒和恐惧）识别的信心。
- Conclusion: 狗情绪识别受呈现模式和标注者特征显著影响，视觉上下文是关键因素，音频增强标注信心，标注者背景差异影响识别一致性，这些发现对改进狗情绪识别系统和标注策略有重要启示。


### [16] [DAV-GSWT: Diffusion-Active-View Sampling for Data-Efficient Gaussian Splatting Wang Tiles](https://arxiv.org/abs/2602.15355)
*Rong Fu,Jiekai Wu,Haiyun Wei,Yee Tan Jia,Wenxin Zhang,Yang Li,Xiaowen Ma,Wangyu Wu,Simon Fong*

Main category: cs.CV

TL;DR: DAV-GSWT：基于扩散先验和主动视角采样的数据高效框架，用于从少量输入观测合成高质量的高斯泼溅Wang Tiles

- Motivation: 现有3D高斯泼溅方法虽然实现了高质量神经渲染，但生成大场景时依赖密集采样的示例重建，数据需求大。需要开发数据高效的方法来合成大规模虚拟环境。
- Method: 结合扩散先验和主动视角采样，通过分层不确定性量化机制识别信息最丰富的视角，利用生成扩散模型补全缺失的结构细节，确保瓦片间的无缝过渡。
- Result: 实验表明，该系统显著减少了所需数据量，同时保持了大规模虚拟环境所需的视觉完整性和交互性能。
- Conclusion: DAV-GSWT框架通过数据高效的方式实现了高质量的大规模场景合成，为大规模虚拟环境创建提供了实用解决方案。


### [17] [GMAIL: Generative Modality Alignment for generated Image Learning](https://arxiv.org/abs/2602.15368)
*Shentong Mo,Sukmin Yun*

Main category: cs.CV

TL;DR: GMAIL框架将生成图像视为与真实图像不同的模态，通过多模态学习方法在潜在空间中对齐两种模态，从而有效利用生成图像提升视觉语言任务的性能。

- Motivation: 生成模型能合成高度逼真的图像，为训练机器学习模型提供丰富数据源。但直接将生成图像当作真实图像使用会导致模态差异问题，甚至引发模式崩溃。需要一种能区分处理两种模态的方法。
- Method: 提出GMAIL框架：1) 将生成图像视为独立模态；2) 使用跨模态对齐损失在生成图像上微调模型；3) 用对齐后的模型结合生成图像训练各种视觉语言模型；4) 在潜在空间而非像素空间对齐两种模态。
- Result: 框架显著提升了图像描述、零样本图像检索、零样本图像分类和长描述检索等任务的性能。展示了生成数据的正向缩放趋势，并在LLaVA等大型多模态模型的描述性能上取得显著提升。
- Conclusion: 通过将生成图像视为独立模态并在潜在空间进行对齐，GMAIL框架能有效利用生成模型的优势，提升视觉语言任务的性能，且易于与各种视觉语言模型集成。


### [18] [Bridging Day and Night: Target-Class Hallucination Suppression in Unpaired Image Translation](https://arxiv.org/abs/2602.15383)
*Shuwei Li,Lei Tan,Robby T. Tan*

Main category: cs.CV

TL;DR: 提出一种用于无配对日间到夜间图像转换的新框架，通过检测和抑制目标类别特征的幻觉，提升下游任务性能。

- Motivation: 日间到夜间无配对图像转换由于外观差异大且缺乏像素级监督，现有方法常产生语义幻觉（如交通标志、车辆、人造灯光效果的错误合成），严重影响下游任务性能。
- Method: 1) 设计双头判别器，同时进行语义分割以识别背景区域的幻觉内容；2) 引入类别特定原型（通过聚合标注的目标域对象特征构建），作为每类的语义锚点；3) 基于Schrodinger Bridge的翻译模型进行迭代优化，将检测到的幻觉特征从类别原型推开。
- Result: 在BDD100K数据集上，日间到夜间域适应的mAP提升15.5%，对容易产生幻觉的类别（如交通灯）提升达31.7%，在定性和定量评估中均优于现有方法。
- Conclusion: 提出的框架能有效检测和抑制无配对图像转换中的语义幻觉，显著提升下游任务性能，特别是对容易产生幻觉的类别效果显著。


### [19] [Efficient Generative Modeling beyond Memoryless Diffusion via Adjoint Schrödinger Bridge Matching](https://arxiv.org/abs/2602.15396)
*Jeongwoo Shin,Jinhwan Sul,Joonseok Lee,Jaewong Choi,Jaemoo Choi*

Main category: cs.CV

TL;DR: ASBM是一种新的生成建模框架，通过两阶段方法学习最优轨迹：首先将Schrödinger Bridge前向动态视为耦合构建问题，通过数据到能量采样的视角学习；然后通过简单匹配损失学习后向生成动态，实现更直、更高效的采样路径。

- Motivation: 扩散模型通常产生高度弯曲的轨迹和嘈杂的得分目标，这是由于无信息、无记忆的前向过程导致独立的数据-噪声耦合。作者旨在恢复高维数据中的最优轨迹，提高采样效率和稳定性。
- Method: 提出Adjoint Schrödinger Bridge Matching (ASBM)框架，包含两个阶段：1）将SB前向动态视为耦合构建问题，通过数据到能量采样的视角学习，将数据传输到能量定义的先验分布；2）通过简单匹配损失学习后向生成动态，该损失由诱导的最优耦合监督。
- Result: ASBM在非无记忆机制下运行，产生显著更直、更高效的采样路径。相比先前工作，ASBM能够扩展到高维数据，具有显著改善的稳定性和效率。图像生成实验显示ASBM以更少的采样步骤提高了保真度，并通过蒸馏到一步生成器展示了最优轨迹的有效性。
- Conclusion: ASBM通过两阶段方法有效解决了扩散模型中轨迹弯曲和噪声问题，实现了更优的采样效率和生成质量，为高维生成建模提供了稳定且高效的解决方案。


### [20] [Emergent Morphing Attack Detection in Open Multi-modal Large Language Models](https://arxiv.org/abs/2602.15461)
*Marija Ivanovska,Vitomir Štruc*

Main category: cs.CV

TL;DR: 首次系统评估开源多模态大语言模型在零样本条件下的单图像人脸篡改检测能力，发现LLaVA1.6-Mistral-7B超越任务专用基线方法23%以上，表明多模态预训练能隐式编码面部不一致性特征。

- Motivation: 当前人脸篡改攻击检测系统大多需要任务特定训练且对未见攻击类型泛化能力差，而开源多模态大语言模型展现出强大的视觉-语言推理能力，但在生物特征取证领域的潜力尚未充分探索。
- Method: 首次对开源MLLMs进行系统性的零样本单图像人脸篡改检测评估，使用公开可得的权重和标准化、可复现的协议，测试多种篡改技术下的性能。
- Result: 许多MLLMs在没有微调或领域适应的情况下展现出非平凡的判别能力，LLaVA1.6-Mistral-7B达到最先进性能，在等错误率上超越高度竞争的任务特定基线至少23%。
- Conclusion: 多模态预训练能隐式编码指示篡改伪影的细粒度面部不一致性，使零样本取证敏感性成为可能。开源MLLMs可作为生物特征安全和取证图像分析的可复现、可解释、有竞争力的基础，为开发最先进MAD系统提供新机会。


### [21] [RPT-SR: Regional Prior attention Transformer for infrared image Super-Resolution](https://arxiv.org/abs/2602.15490)
*Youngwan Jin,Incheol Park,Yagiz Nalcakan,Hyeongjin Ju,Sanghyeop Yeo,Shiho Kim*

Main category: cs.CV

TL;DR: 提出RPT-SR模型，通过区域先验注意力Transformer解决固定视角红外图像超分辨率问题，利用场景布局先验提升性能

- Motivation: 现有通用超分辨率模型（特别是Vision Transformers）在固定视角的红外成像场景（如监控、自动驾驶）中存在效率问题，未能利用这些场景中固有的强空间先验，导致冗余学习和次优性能
- Method: 提出RPT-SR（区域先验注意力Transformer），采用双令牌框架：1）可学习的区域先验令牌作为场景全局结构的持久记忆；2）捕获当前输入帧特定内容的局部令牌。通过注意力机制让先验动态调制局部重建过程
- Result: 在涵盖长波（LWIR）和短波（SWIR）光谱的多样化数据集上建立了新的最先进性能，展示了模型的广泛适用性和多功能性
- Conclusion: RPT-SR通过显式编码场景布局信息到注意力机制中，有效解决了固定视角红外图像超分辨率问题，相比通用模型能更好地利用空间先验，在多个红外波段都取得了优异性能


### [22] [LEADER: Lightweight End-to-End Attention-Gated Dual Autoencoder for Robust Minutiae Extraction](https://arxiv.org/abs/2602.15493)
*Raffaele Cappelli,Matteo Ferrara*

Main category: cs.CV

TL;DR: LEADER是一个轻量级端到端指纹细节点提取网络，无需预处理和后处理，仅用0.9M参数实现从原始指纹图像到细节点描述符的完整映射。

- Motivation: 指纹识别中的细节点提取正转向深度学习，但真正消除独立预处理和后处理的端到端方法仍然稀缺。现有方法通常需要分离的处理步骤，限制了效率和泛化能力。
- Method: 提出LEADER架构：集成非极大值抑制和角度解码的轻量级网络；采用新颖的"城堡-护城河-城墙"真值编码和双自编码器结构，通过注意力门控机制相互连接；实现完全端到端推理。
- Result: 在普通指纹上达到最先进精度，在潜在指纹上具有强大跨域泛化能力：NIST SD27数据集上F1分数比专业潜在细节点提取器高34%；在47%样本中排名第一，是第二名的两倍多；GPU推理15ms，CPU推理322ms，计算效率优于商业软件。
- Conclusion: LEADER证明了轻量级端到端细节点提取的可行性，在精度、泛化能力和计算效率方面均表现优异，且学习到的内部表示与指纹领域特征一致。公开源代码和预训练权重促进可复现性。


### [23] [Semantic-Guided 3D Gaussian Splatting for Transient Object Removal](https://arxiv.org/abs/2602.15516)
*Aditi Prabakaran,Priyesh Shukla*

Main category: cs.CV

TL;DR: 提出基于语义过滤的框架，利用视觉语言模型进行类别感知的瞬态物体去除，解决3D高斯泼溅重建中的鬼影问题

- Motivation: 多视角捕捉中的瞬态物体（如行人、车辆）会在3D高斯泼溅重建中产生鬼影伪影。现有方法要么依赖场景分解导致内存成本高，要么基于运动启发式方法容易受到视差模糊的影响
- Method: 使用视觉语言模型（CLIP）进行语义过滤，通过计算渲染视图与干扰物文本提示之间的相似度得分，在训练迭代中为每个高斯累积得分。超过校准阈值的高斯进行透明度正则化和周期性剪枝
- Result: 在RobustNeRF基准测试中，相比原始3DGS在四个序列上重建质量持续提升，同时保持最小的内存开销和实时渲染性能
- Conclusion: 语义分类通过独立于运动模式识别物体类别，解决了视差模糊问题。阈值校准和基线比较验证了在可预测干扰物类别场景中，语义引导是瞬态物体去除的实用策略


### [24] [Advanced Acceptance Score: A Holistic Measure for Biometric Quantification](https://arxiv.org/abs/2602.15535)
*Aman Verma,Seshan Srirangarajan,Sumantra Dutta Roy*

Main category: cs.CV

TL;DR: 提出了一种全面的手势生物特征评分评估方法，通过考虑排名顺序、相关性、趋势对应和身份特征解耦等因素，构建了先进的接受分数作为整体评估指标。

- Motivation: 现有生物特征容量估计方法依赖错误率，但这些错误率无法评估评分质量的好坏。需要开发更全面的评估指标来衡量手势生物特征评分的质量。
- Method: 首先确定输出分数的排名顺序和相关性作为评估基础，考虑排名偏差以及奖励高排名手势的高分和低排名手势的低分。同时补偿输出分数与真实分数趋势的对应关系，并将手势身份特征的解耦作为折扣因子。整合这些元素并适当加权，构建了先进的接受分数作为整体评估指标。
- Result: 在三个数据集上对五个最先进模型进行了深入实验，结果显示使用该指标选择的最优分数比现有其他指标更合适。同时，提出的指标与现有指标存在相关性，进一步验证了其可靠性。
- Conclusion: 提出的评估指标能够全面评估手势生物特征评分质量，比现有方法更合适，并且与现有指标具有相关性，验证了其可靠性。代码已公开。


### [25] [Dynamic Training-Free Fusion of Subject and Style LoRAs](https://arxiv.org/abs/2602.15539)
*Qinglong Cao,Yuntian Chen,Chao Ma,Xiaokang Yang*

Main category: cs.CV

TL;DR: 提出动态免训练LoRA融合框架，通过特征级选择和指标引导的潜在调整，在扩散过程中动态融合主题和风格LoRA权重，实现连贯的主题-风格合成。

- Motivation: 现有LoRA融合方法大多使用静态统计启发式方法，偏离了LoRA学习自适应特征调整的初衷，且忽略了采样输入的随机性，需要更动态的融合机制。
- Method: 1. 前向传播时，在每个LoRA应用层动态计算基础模型原始特征与主题/风格LoRA生成特征的KL散度，自适应选择最合适的权重进行融合；2. 反向去噪阶段，基于CLIP和DINO等客观指标的梯度修正动态调整生成轨迹，提供连续的语义和风格指导。
- Result: 在多样化的主题-风格组合实验中，该方法在定性和定量上都一致优于最先进的LoRA融合方法，无需任何重新训练即可实现连贯的主题-风格合成。
- Conclusion: 通过在整个扩散时间线上集成特征级选择和指标引导的潜在调整这两个互补机制，提出的动态免训练框架能够有效实现高质量的主题-风格合成。


### [26] [Revealing and Enhancing Core Visual Regions: Harnessing Internal Attention Dynamics for Hallucination Mitigation in LVLMs](https://arxiv.org/abs/2602.15556)
*Guangtao Lyu,Qi Liu,Chenghao Xu,Jiexi Yan,Muli Yang,Xueting Li,Fen Fang,Cheng Deng*

Main category: cs.CV

TL;DR: 提出PADE方法，通过增强正注意力动态来减少LVLM的幻觉，无需额外训练，在多个基准测试中提升视觉基础能力

- Motivation: 大型视觉语言模型存在幻觉问题，现有训练无关方法要么计算开销大，要么易受注意力沉没现象影响。研究发现LVLM内部的正注意力动态能自然揭示语义核心视觉区域
- Method: 提出PADE方法：1) 构建PAD图识别语义核心视觉区域；2) 使用每头中位数绝对偏差缩放自适应控制干预强度；3) 利用系统令牌补偿保持对复杂指令的注意力并支持长期输出一致性
- Result: 在多个LVLM和基准测试上的实验表明，PADE能改善视觉基础能力并减少幻觉，验证了利用内部注意力动态进行可靠多模态推理的有效性
- Conclusion: 通过增强内部正注意力动态，PADE提供了一种无需训练的有效方法来减少LVLM的幻觉，提升多模态推理的可靠性


### [27] [Intracoronary Optical Coherence Tomography Image Processing and Vessel Classification Using Machine Learning](https://arxiv.org/abs/2602.15579)
*Amal Lahchim,Lambros Athanasiou*

Main category: cs.CV

TL;DR: 提出基于机器学习的全自动OCT图像血管分割与分类方法，实现高精度血管边界检测

- Motivation: 冠状动脉光学相干断层扫描（OCT）虽然能高分辨率显示血管解剖结构，但存在噪声、成像伪影和组织结构复杂等挑战，需要自动化分析解决方案
- Method: 集成图像预处理、导丝伪影去除、极坐标到笛卡尔坐标转换、无监督K-means聚类和局部特征提取，使用逻辑回归和支持向量机进行像素级血管分类
- Result: 实验结果显示优异性能，精确率、召回率和F1分数最高达1.00，总体分类准确率达99.68%，计算复杂度低且需要最少人工标注
- Conclusion: 该方法为自动化OCT图像分析提供了可靠高效的解决方案，在临床决策支持和实时医学图像处理方面具有应用潜力


### [28] [An Industrial Dataset for Scene Acquisitions and Functional Schematics Alignment](https://arxiv.org/abs/2602.15584)
*Flavien Armangeon,Thibaud Ehret,Enric Meinhardt-Llopis,Rafael Grompone von Gioi,Guillaume Thibault,Marc Petit,Gabriele Facciolo*

Main category: cs.CV

TL;DR: IRIS-v2数据集用于工业场景中2D/3D功能示意图对齐，解决老旧工业设施数字化建模难题

- Motivation: 老旧工业设施缺乏原生数字模型，现有手动对齐方法（图像+LiDAR）难以规模化，工业数据集稀缺且示意图与现实不一致
- Method: 提出IRIS-v2综合数据集，包含图像、点云、2D标注框和分割掩码、CAD模型、3D管道布线信息和P&ID图；通过分割和图匹配相结合的方法进行对齐实验
- Result: 建立了支持进一步研究的综合数据集，并在实际案例中验证了对齐方法
- Conclusion: IRIS-v2数据集填补了工业数字化对齐研究的空白，结合分割和图匹配的方法有望减少对齐任务所需时间


### [29] [Concept-Enhanced Multimodal RAG: Towards Interpretable and Accurate Radiology Report Generation](https://arxiv.org/abs/2602.15650)
*Marco Salmè,Federico Siciliano,Fabrizio Silvestri,Paolo Soda,Rosa Sicilia,Valerio Guarrasi*

Main category: cs.CV

TL;DR: CEMRAG框架通过将视觉表征分解为可解释的临床概念并与多模态RAG结合，同时提升放射报告生成的解释性和事实准确性，挑战了传统认为解释性与性能之间存在权衡的观点。

- Motivation: 当前基于视觉语言模型的放射报告生成系统存在两个主要问题：缺乏可解释性以及容易产生与影像证据不符的幻觉。现有研究通常将可解释性和准确性视为独立目标，分别通过基于概念的解释性技术和检索增强生成方法来处理，缺乏统一框架。
- Method: 提出概念增强多模态RAG（CEMRAG）框架，将视觉表征分解为可解释的临床概念，并将这些概念与多模态检索增强生成相结合。该框架采用模块化设计，将可解释性分解为视觉透明度和结构化语言模型条件。
- Result: 在MIMIC-CXR和IU X-Ray数据集上，跨多种VLM架构、训练机制和检索配置的实验表明，CEMRAG在临床准确性指标和标准NLP评估上均优于传统RAG和仅概念基线方法，实现了可解释性和性能的双重提升。
- Conclusion: 透明视觉概念不仅不会损害诊断准确性，反而可以增强医学VLM的性能，挑战了可解释性与性能之间存在权衡的传统假设。该框架为临床可信赖的AI辅助放射学提供了原则性路径。


### [30] [A Novel Public Dataset for Strawberry (Fragaria x ananassa) Ripeness Detection and Comparative Evaluation of YOLO-Based Models](https://arxiv.org/abs/2602.15656)
*Mustafa Yurdakul,Zeynep Sena Bastug,Ali Emre Gok,Sakir Taşdemir*

Main category: cs.CV

TL;DR: 提出一个新的公开草莓成熟度数据集，包含566张图像和1201个标注对象，在不同光照和温室条件下采集。使用YOLO系列模型进行测试，YOLOv8s在mAP@50指标上表现最佳（86.09%）。

- Motivation: 草莓成熟度检测对生产者和消费者都很重要，但传统视觉评估方法主观且误差大。现有研究缺乏公开可用的综合数据集，难以进行公平比较。
- Method: 创建了一个新的公开草莓成熟度数据集，包含566张图像和1201个标注对象，在土耳其两个不同温室的不同光照和环境条件下采集。使用YOLOv8、YOLOv9和YOLO11模型进行对比测试。
- Result: YOLOv9c模型获得最高精确度（90.94%），YOLO11s模型获得最高召回率（83.74%）。在综合性能指标mAP@50上，YOLOv8s表现最佳（86.09%）。
- Conclusion: 中小型模型在这类数据集上表现更平衡高效，为智能农业应用建立了基础参考点。公开数据集有助于促进该领域研究的公平比较。


### [31] [Bayesian Optimization for Design Parameters of 3D Image Data Analysis](https://arxiv.org/abs/2602.15660)
*David Exler,Joaquin Eduardo Urrutia Gómez,Martin Krüger,Maike Schliephake,John Jbeily,Mario Vitacolonna,Rüdiger Rudolf,Markus Reischl*

Main category: cs.CV

TL;DR: 提出3D数据优化分析流程，通过两阶段贝叶斯优化自动选择分割模型和分类器设计，减少人工调参负担

- Motivation: 3D生物医学图像分析中，手动选择模型和调参是主要瓶颈，需要自动化解决方案来降低实践中的困难
- Method: 采用两阶段贝叶斯优化：第一阶段优化分割模型和参数，使用领域适应的合成基准数据集和分割质量指标；第二阶段优化分类器设计，包括编码器架构、分类头、先验知识和预训练策略，并包含辅助类别标注工作流
- Result: 在四个案例研究中，该流程能高效识别适合单个数据集的有效模型和参数配置
- Conclusion: 提出的3D数据优化分析流程通过自动化模型选择和参数优化，解决了生物医学图像分析中的实践瓶颈，提高了分析效率


### [32] [Criteria-first, semantics-later: reproducible structure discovery in image-based sciences](https://arxiv.org/abs/2602.15712)
*Jan Bumberger*

Main category: cs.CV

TL;DR: 提出"标准优先、语义后置"的图像分析新范式，将结构提取与语义标注分离，以应对科学发现中的标签漂移和跨域可比性问题

- Motivation: 传统基于语义优先的图像分析范式在开放科学发现、跨传感器/跨站点可比性、长期监测等场景中系统性地失败，因为领域本体和标签集会随时间发生文化、制度和生态上的漂移
- Method: 引入统一框架，将标准定义的无语义结构提取与下游语义映射分离，结构发现基于明确的优化标准而非局部领域本体，语义作为从发现结构到领域本体的显式映射
- Result: 框架基于控制论、观察即区分和信息论的信息与意义分离原则，跨领域证据表明标准优先组件在标签无法扩展时反复出现
- Conclusion: 标准优先方法为可复现科学提供领域通用支架，支持多元解释和显式交叉映射，将结构产品视为FAIR、AI就绪的数字对象，适用于长期监测和数字孪生


### [33] [ToaSt: Token Channel Selection and Structured Pruning for Efficient ViT](https://arxiv.org/abs/2602.15720)
*Hyunchan Moon,Cheonjun Park,Steven L. Waslander*

Main category: cs.CV

TL;DR: ToaSt是一个解耦的ViT压缩框架，通过耦合头结构化剪枝处理注意力模块，通过令牌通道选择压缩FFN，在保持准确率的同时显著降低计算成本。

- Motivation: Vision Transformers在视觉任务中表现出色，但计算成本过高限制了部署。现有的结构化权重剪枝和令牌压缩方法分别存在重训练时间长和全局传播导致的优化问题。
- Method: 提出ToaSt解耦框架：1) 对多头自注意力模块采用耦合头结构化剪枝，利用注意力操作特性增强鲁棒性；2) 对FFN（占60%以上FLOPs）引入令牌通道选择，避免全局传播问题，有效过滤冗余噪声。
- Result: 在9个不同模型（包括DeiT、ViT-MAE、Swin Transformer）上评估，ToaSt在准确率和效率之间取得优越平衡。在ViT-MAE-Huge上实现88.52%准确率（+1.64%），同时减少39.4% FLOPs。在下游任务中，COCO目标检测达到52.2 mAP（vs 51.9）。
- Conclusion: ToaSt通过针对ViT不同组件采用专门策略，有效解决了现有压缩方法的局限性，实现了优越的准确率-效率权衡，并能有效迁移到下游任务。


### [34] [Learning to Retrieve Navigable Candidates for Efficient Vision-and-Language Navigation](https://arxiv.org/abs/2602.15724)
*Shutian Gu,Chengkai Huang,Ruoyu Wang,Lina Yao*

Main category: cs.CV

TL;DR: 提出检索增强框架提升基于LLM的视觉语言导航效率，通过指令级轨迹检索和候选方向剪枝减少重复推理

- Motivation: 基于提示的LLM导航存在决策效率低的问题，需要重复解释指令并在每个步骤处理大量嘈杂的导航候选，导致推理效率低下
- Method: 提出两级检索增强框架：1) 指令级嵌入检索器选择语义相似的导航轨迹作为上下文示例；2) 模仿学习的候选检索器在LLM推理前剪枝无关导航方向。两个模块轻量、模块化且独立于LLM训练
- Result: 在Room-to-Room基准测试中，在已见和未见环境中均显著提升了成功率、Oracle成功率和SPL指标。消融研究表明指令级示例检索和候选剪枝对全局指导和逐步决策效率有互补效益
- Conclusion: 检索增强的决策支持是提升基于LLM的视觉语言导航的有效且可扩展策略，无需修改或微调底层语言模型


### [35] [Spanning the Visual Analogy Space with a Weight Basis of LoRAs](https://arxiv.org/abs/2602.15727)
*Hila Manor,Rinon Gal,Haggai Maron,Tomer Michaeli,Gal Chechik*

Main category: cs.CV

TL;DR: LoRWeB：通过动态组合学习到的LoRA基模块来实现视觉类比学习，提升未见视觉变换的泛化能力

- Motivation: 现有方法使用单一LoRA模块来捕捉视觉变换，但固定模块限制了泛化能力。受限于LoRA在受限领域中可形成有意义、可插值语义空间的启发，需要更灵活的方法来处理多样化的视觉变换
- Method: 提出LoRWeB方法：1) 学习一组LoRA基模块，覆盖不同视觉变换空间；2) 轻量级编码器根据输入类比对动态选择和加权这些基LoRA，实现推理时的动态组合
- Result: 综合评估表明该方法达到最先进性能，显著提升对未见视觉变换的泛化能力
- Conclusion: LoRA基分解是实现灵活视觉操作的有前景方向，动态组合学习到的变换基元能有效提升视觉类比学习性能


### [36] [Language and Geometry Grounded Sparse Voxel Representations for Holistic Scene Understanding](https://arxiv.org/abs/2602.15734)
*Guile Wu,David Huang,Bingbing Liu,Dongfeng Bai*

Main category: cs.CV

TL;DR: 提出了一种基于语言和几何基础稀疏体素表示的统一框架，用于协同建模3D场景的外观、语义和几何，在整体场景理解和重建方面优于现有方法。

- Motivation: 现有3D开放词汇场景理解方法主要关注从2D基础模型蒸馏语言特征到3D特征场，但忽视了场景外观、语义和几何之间的协同作用，导致场景理解偏离几何结构并与重建过程脱节。
- Method: 使用3D稀疏体素作为基本单元，构建包含外观场、密度场、特征场和置信场的统一表示框架。通过特征调制模块促进各场之间的协同，从2D基础模型蒸馏语言特征，并通过深度相关正则化和模式一致性正则化从几何基础模型蒸馏几何知识。
- Result: 在整体场景理解和重建任务中，该方法相比最先进方法取得了优越的整体性能。
- Conclusion: 通过语言和几何基础稀疏体素表示的统一框架，能够协同建模3D场景的外观、语义和几何，实现了更好的场景理解和重建效果。


### [37] [RaCo: Ranking and Covariance for Practical Learned Keypoints](https://arxiv.org/abs/2602.15755)
*Abhiram Shenoi,Philipp Lindenberger,Paul-Edouard Sarlin,Marc Pollefeys*

Main category: cs.CV

TL;DR: RaCo是一个轻量级神经网络，通过可重复关键点检测器、可微分排序器和协方差估计器，无需共视图像对即可学习鲁棒的关键点，在旋转鲁棒性和匹配性能上达到SOTA。

- Motivation: 现有关键点检测方法通常需要共视图像对进行训练，且在处理大旋转时鲁棒性不足。RaCo旨在开发一种无需共视图像对、具有强旋转鲁棒性的轻量级关键点检测方法。
- Method: RaCo包含三个核心组件：1) 可重复关键点检测器；2) 可微分排序器，用于在有限关键点数量下最大化匹配；3) 协方差估计器，用于量化度量尺度下的空间不确定性。仅使用透视图像裁剪进行训练，无需共视图像对，通过大量数据增强实现旋转鲁棒性。
- Result: 在多个挑战性数据集上评估，RaCo在关键点可重复性和两视图匹配方面达到最先进性能，特别是在大平面旋转情况下表现优异。无需额外标签即可独立估计关键点排序和度量协方差。
- Conclusion: RaCo提供了一种有效且简单的策略，无需共视图像对即可学习鲁棒的关键点，具有强旋转鲁棒性和优异匹配性能，代码已开源。


### [38] [Understanding vs. Generation: Navigating Optimization Dilemma in Multimodal Models](https://arxiv.org/abs/2602.15772)
*Sen Ye,Mengde Xu,Shuyang Gu,Di He,Liwei Wang,Han Hu*

Main category: cs.CV

TL;DR: R3框架通过"生成-理解-再生成"的多步过程，解决了多模态模型中生成能力与理解能力之间的权衡问题，实现了两者同时提升。

- Motivation: 当前多模态模型面临一个关键挑战：提升生成能力往往以牺牲理解能力为代价，反之亦然。研究发现这种权衡的主要原因是生成与理解之间的潜在冲突，在模型内部形成了竞争动态。
- Method: 提出Reason-Reflect-Refine (R3)框架，将单步生成任务重构为"生成-理解-再生成"的多步过程。通过显式利用模型在生成过程中的理解能力，缓解优化困境。
- Result: 成功缓解了优化困境，实现了更强的生成结果和与生成过程相关的理解能力的提升。
- Conclusion: R3框架为设计下一代统一多模态模型提供了有价值的见解，通过多步生成过程有效解决了生成与理解之间的权衡问题。


### [39] [NeRFscopy: Neural Radiance Fields for in-vivo Time-Varying Tissues from Endoscopy](https://arxiv.org/abs/2602.15775)
*Laura Salort-Benejam,Antonio Agudo*

Main category: cs.CV

TL;DR: NeRFscopy：基于神经渲染的自监督管道，用于从单目内窥镜视频中合成新视角和重建可变形组织的3D模型

- Motivation: 内窥镜在医学成像中至关重要，但现有方法面临组织可变形、单目相机、光照变化、遮挡和未知相机轨迹等挑战。开发鲁棒的动态3D重建管道可以增强可视化、提高诊断准确性、辅助治疗规划和指导手术。
- Method: 提出NeRFscopy自监督管道，包含一个具有规范辐射场和时间相关变形场的可变形模型，变形场通过SE(3)变换参数化。引入复杂项有效利用彩色图像，仅从数据学习3D隐式模型，无需任何模板或预训练模型。
- Result: NeRFscopy在新视角合成方面取得准确结果，在各种具有挑战性的内窥镜场景中优于竞争方法。
- Conclusion: NeRFscopy为内窥镜视频中的可变形组织提供了一种有效的自监督3D重建和新视角合成方法，能够应对医学内窥镜场景中的多种挑战。


### [40] [Meteorological data and Sky Images meets Neural Models for Photovoltaic Power Forecasting](https://arxiv.org/abs/2602.15782)
*Ines Montoya-Espinagosa,Antonio Agudo*

Main category: cs.CV

TL;DR: 本文提出了一种结合天空图像、光伏历史数据和气象数据的多模态混合方法，用于短期和长期光伏预测，特别关注提高多云条件下爬坡事件预测的准确性和鲁棒性。

- Motivation: 随着可再生能源特别是太阳能的广泛应用，光伏发电的波动性给电网运行带来挑战。需要改进光伏预测方法，特别是在多云条件下提高爬坡事件预测的准确性，以支持电网更高效运行和太阳能波动性的更好管理。
- Method: 采用多模态混合方法，结合天空图像、光伏历史数据和气象数据。使用深度神经网络模型进行临近预报和预报，整合单个和多个气象变量以及太阳位置分析。特别关注表面长波辐射、向下辐射以及风与太阳位置的组合。
- Result: 结果表明，气象数据的加入，特别是表面长波辐射、向下辐射以及风与太阳位置的组合，显著改善了当前预测任务（包括临近预报和预报）的准确性，尤其是在多云天气条件下。
- Conclusion: 本研究强调了整合多样化数据源对于提高太阳能预测模型可靠性和可解释性的重要性，为光伏预测提供了更稳健的解决方案。


### [41] [Context-aware Skin Cancer Epithelial Cell Classification with Scalable Graph Transformers](https://arxiv.org/abs/2602.15783)
*Lucas Sancéré,Noémie Moreau,Katarzyna Bozek*

Main category: cs.CV

TL;DR: 提出使用可扩展的图变换器在全切片细胞图上进行分类，在皮肤鳞状细胞癌中区分健康与肿瘤上皮细胞，相比基于图像的方法获得更好的性能。

- Motivation: 全切片图像包含丰富的诊断信息，但现有深度学习方法依赖基于patch的表示，丢失了重要的组织级上下文。需要一种能利用完整组织上下文的方法来区分形态相似的健康与肿瘤细胞。
- Method: 使用可扩展的图变换器（SGFormer和DIFFormer）在全切片细胞图上进行分类。构建细胞图，结合形态、纹理特征以及非上皮细胞的细胞类别作为节点特征。在多个患者的多张WSI上训练时，从每个图像提取patch并转换为图。
- Result: 在单张WSI上，图变换器模型SGFormer和DIFFormer分别达到85.2±1.5%和85.1±2.5%的平衡准确率，优于最佳图像方法的81.2±3.0%。在多WSI设置中，DIFFormer达到83.6±1.9%，优于CellViT256的78.1±0.5%。
- Conclusion: 图变换器在全切片细胞图上能有效利用组织级上下文，在区分形态相似的健康与肿瘤上皮细胞方面优于基于图像的方法，证明了细胞周围环境信息的重要性。


### [42] [Task-Agnostic Continual Learning for Chest Radiograph Classification](https://arxiv.org/abs/2602.15811)
*Muthu Subash Kavitha,Anas Zafar,Amgad Muneer,Jia Wu*

Main category: cs.CV

TL;DR: CARL-XRay：一种用于胸部X光分类的持续学习方法，通过轻量级适配器和原型记忆实现任务增量学习，无需存储原始图像或重新训练历史数据。

- Motivation: 临床部署胸部X光分类器需要能够随着新数据集可用而更新的模型，而无需重新训练历史数据或降低已验证性能。现有方法在任务标识符不可用的情况下难以实现稳定更新。
- Method: 提出CARL-XRay方法：保持固定高容量主干网络，增量分配轻量级任务特定适配器和分类器头。使用潜在任务选择器基于任务适应特征，通过紧凑原型和特征级经验回放保留历史上下文，支持稳定任务识别和适应。
- Result: 在大规模公共胸部X光数据集上，CARL-XRay在任务未知部署下优于联合训练，路由准确率达75.0%（vs. 62.5%）。在oracle设置下AUROC为0.74，任务未知推理下为0.75，使用显著更少的可训练参数。
- Conclusion: 该框架为临床持续部署提供了实用的替代方案，避免了联合训练和重复完全重新训练，支持稳定任务识别和性能保持。


### [43] [VideoSketcher: Video Models Prior Enable Versatile Sequential Sketch Generation](https://arxiv.org/abs/2602.15819)
*Hui Ren,Yuval Alaluf,Omer Bar Tal,Alexander Schwing,Antonio Torralba,Yael Vinker*

Main category: cs.CV

TL;DR: 该论文提出了一种数据高效的方法，通过适配预训练的文本到视频扩散模型来生成顺序草图绘制过程，利用LLM进行语义规划和笔画排序，视频扩散模型作为渲染器生成高质量时序连贯的视觉效果。

- Motivation: 传统生成模型将草图视为静态图像，忽略了草图绘制过程中的时序结构，而草图本质上是顺序过程，笔画按有意义顺序绘制以探索和细化想法。
- Method: 采用两阶段微调策略：第一阶段使用具有受控时序结构的合成形状组合学习笔画排序；第二阶段仅用7个人工绘制的草图过程学习视觉外观，将草图表示为笔画在空白画布上逐步绘制的短视频。
- Result: 尽管使用极少的人类绘制草图数据，该方法能生成高质量的顺序草图，紧密遵循文本指定的笔画顺序，同时展现丰富的视觉细节，并支持笔刷风格条件和自回归草图生成等扩展功能。
- Conclusion: 通过结合LLM的语义规划和视频扩散模型的渲染能力，实现了数据高效的顺序草图生成，为交互式协作绘图提供了灵活可控的解决方案。
## cs.SD

### [44] [UniTAF: A Modular Framework for Joint Text-to-Speech and Audio-to-Face Modeling](https://arxiv.org/abs/2602.15651)
*Qiangong Zhou,Nagasaka Tomohiro*

Main category: cs.SD

TL;DR: 将独立的TTS（文本转语音）和A2F（音频转面部表情）模型合并为统一模型，通过内部特征传输提升文本生成的音频与面部表情一致性，并扩展情感控制机制。

- Motivation: 从系统设计角度验证TTS中间表征在语音与面部表情联合建模中的复用可行性，为后续语音表情协同设计提供工程实践参考，而非展示生成质量。
- Method: 将独立的TTS和A2F模型合并为统一模型，实现内部特征传输，并将TTS的情感控制机制扩展到联合模型中。
- Result: 验证了复用TTS中间表征进行语音与面部表情联合建模的可行性，项目代码已开源。
- Conclusion: 该工作为语音表情协同设计的系统架构提供了实践参考，证明了TTS中间表征在联合建模中的复用潜力。
## cs.IR

### [45] [Automatic Funny Scene Extraction from Long-form Cinematic Videos](https://arxiv.org/abs/2602.15381)
*Sibendu Paul,Haotian Jiang,Caren Chen*

Main category: cs.IR

TL;DR: 提出端到端系统自动从长视频中识别和排序幽默场景，通过多模态方法提升场景定位和幽默检测效果

- Motivation: 从电影长片中自动提取高质量幽默场景对创建吸引人的视频预览和短视频内容至关重要，可提升流媒体平台的用户参与度。但长视频的时长、复杂叙事以及幽默的多模态特性增加了场景定位的难度。
- Method: 端到端系统包含镜头检测、多模态场景定位和幽默标注。创新点包括：结合视觉和文本线索的场景分割方法、通过引导三元组挖掘改进镜头表示、利用音频和文本的多模态幽默标注框架。
- Result: 在OVSD数据集上场景检测AP提升18.3%，长文本幽默检测F1分数0.834。在五个电影标题上的评估显示，87%提取的剪辑是幽默的，98%的场景准确定位。系统成功泛化到预告片。
- Conclusion: 该系统能有效提升内容创作流程、改善用户参与度，并为多样化的电影媒体格式简化短视频内容生成，展示了实际应用潜力。
## cs.RO

### [46] [Dex4D: Task-Agnostic Point Track Policy for Sim-to-Real Dexterous Manipulation](https://arxiv.org/abs/2602.15828)
*Yuxuan Kuang,Sungjae Park,Katerina Fragkiadaki,Shubham Tulsiani*

Main category: cs.RO

TL;DR: Dex4D是一个学习任务无关灵巧操作技能框架，通过仿真训练3D点轨迹条件策略，实现零样本迁移到真实世界任务

- Motivation: 学习通用灵巧操作策略面临挑战：真实世界遥操作数据收集昂贵且难以扩展，而仿真学习需要设计大量任务特定环境和奖励函数
- Method: 提出Dex4D框架，在仿真中训练域无关的3D点轨迹条件策略（Anypose-to-Anypose策略），覆盖数千个物体和姿态配置，通过生成视频提取物体中心点轨迹作为提示
- Result: 方法支持零样本迁移到真实机器人任务，无需微调，在仿真和真实实验中优于现有基线，对新物体、场景布局、背景和轨迹表现出强泛化能力
- Conclusion: Dex4D框架通过任务无关技能学习和零样本迁移，为灵巧操作提供了鲁棒且可扩展的解决方案，展示了仿真到真实迁移的潜力
## cs.AI

### [47] [CARE Drive A Framework for Evaluating Reason-Responsiveness of Vision Language Models in Automated Driving](https://arxiv.org/abs/2602.15645)
*Lucas Elbert Suryana,Farah Bierenga,Sanne van Buuren,Pepijn Kooij,Elsefien Tulleners,Federico Scari,Simeon Calvert,Bart van Arem,Arkady Zgonnikov*

Main category: cs.AI

TL;DR: CARE Drive是一个评估自动驾驶中视觉语言模型推理响应性的框架，通过对比基线模型和推理增强模型在受控上下文变化下的决策，来评估人类推理是否真正影响模型行为。

- Motivation: 现有评估方法主要关注结果性能（如安全性、轨迹精度），但无法确定模型决策是否反映人类相关考量。这导致无法区分模型解释是真正的推理响应决策还是事后合理化，在安全关键领域可能造成虚假信心。
- Method: 提出CARE Drive框架：1) 提示校准确保稳定输出；2) 系统上下文扰动测量决策对人类推理（如安全裕度、社会压力、效率约束）的敏感性。通过对比基线模型和推理增强模型在受控上下文变化下的决策来评估推理响应性。
- Result: 在自行车超车场景中，显式的人类推理显著影响模型决策，改善了与专家推荐行为的一致性。但响应性随上下文因素变化，表明对不同类型推理的敏感性不均。
- Conclusion: CARE Drive提供了无需修改模型参数即可系统评估基础模型推理响应性的实证证据，有助于在安全关键应用中建立对模型决策过程的信任。
## eess.IV

### [48] [StrokeNeXt: A Siamese-encoder Approach for Brain Stroke Classification in Computed Tomography Imagery](https://arxiv.org/abs/2602.15087)
*Leo Thomas Ramos,Angel D. Sappa*

Main category: eess.IV

TL;DR: StrokeNeXt：基于双分支ConvNeXt编码器和轻量级卷积解码器的2D CT图像中风分类模型，在6774张CT图像数据集上表现优异，准确率和F1分数达0.988。

- Motivation: 开发高效准确的中风分类模型，解决2D CT图像中的中风检测和亚型分类（缺血性与出血性）问题，超越现有卷积和Transformer基线方法。
- Method: 采用双分支设计，两个ConvNeXt编码器提取特征，通过基于堆叠1D操作的轻量级卷积解码器进行特征融合，包括瓶颈投影和变换层，以及紧凑分类头。
- Result: 在6774张CT图像数据集上，StrokeNeXt在准确率和F1分数上达到0.988，显著优于卷积和Transformer基线。统计检验证实性能提升显著，各类别敏感性和特异性表现稳健，校准误差更低，误分类率低，推理时间短且收敛快。
- Conclusion: StrokeNeXt是一种高效准确的中风分类模型，在2D CT图像中表现出卓越性能，具有临床应用的潜力。


### [49] [Benchmarking Self-Supervised Models for Cardiac Ultrasound View Classification](https://arxiv.org/abs/2602.15339)
*Youssef Megahed,Salma I. Megahed,Robin Ducharme,Inok Lee,Adrian D. C. Chan,Mark C. Walker,Steven Hawken*

Main category: eess.IV

TL;DR: 本研究比较了两种自监督学习框架USF-MAE和MoCo v3在心脏超声图像分类任务上的表现，USF-MAE在各项指标上均显著优于MoCo v3。

- Motivation: 心脏超声图像的可靠解读对临床诊断至关重要。自监督学习能够利用大量未标记数据学习有意义的表示，但在心脏超声分类任务中不同框架的性能比较尚不明确。
- Method: 使用CACTUS数据集（37,736张图像）评估USF-MAE和MoCo v3两种自监督学习框架。采用5折交叉验证，统一训练协议（学习率0.0001，权重衰减0.01），比较ROC-AUC、准确率、F1分数和召回率等指标。
- Result: USF-MAE在所有指标上均优于MoCo v3：平均测试AUC为99.99%（±0.01%）vs 99.97%（±0.01%），平均测试准确率为99.33%（±0.18%）vs 98.99%（±0.28%）。F1分数和召回率也显示类似趋势，差异具有统计显著性（p=0.0048 < 0.01）。
- Conclusion: USF-MAE在心脏超声视图分类任务中比MoCo v3学习到更具判别性的特征，证明了其在自动化心脏超声分类中的潜力。
## cs.LG

### [50] [Refine Now, Query Fast: A Decoupled Refinement Paradigm for Implicit Neural Fields](https://arxiv.org/abs/2602.15155)
*Tianyu Xiong,Skylar Wurster,Han-Wei Shen*

Main category: cs.LG

TL;DR: DRR-Net通过解耦表示精炼架构，在保持高保真度的同时实现27倍推理加速，解决了INR的速度-精度困境。

- Motivation: 隐式神经表示（INR）作为3D科学模拟的代理模型面临关键的速度-精度困境：深度MLP推理成本高，而高效的嵌入模型表达能力不足。
- Method: 提出解耦表示精炼（DRR）架构范式：使用深度精炼网络和非参数变换在离线过程中将丰富表示编码到紧凑高效的嵌入结构中，将慢速神经网络与快速推理路径解耦。引入DRR-Net验证该范式，并提出变分对（VP）数据增强策略。
- Result: 在多个集合模拟数据集上实现最先进的保真度，推理速度比高保真基线快27倍，同时与最快模型保持竞争力。
- Conclusion: DRR范式为构建强大实用的神经场代理模型提供了有效策略，在速度和质量之间实现了最小妥协，可广泛应用于INR相关应用。


### [51] [Doubly Stochastic Mean-Shift Clustering](https://arxiv.org/abs/2602.15393)
*Tom Trigano,Yann Sepulcre,Itshak Lapidot*

Main category: cs.LG

TL;DR: DSMS通过随机化带宽和数据采样，改进了传统Mean-Shift算法对带宽超参数的敏感性，在稀疏聚类场景中表现更稳定。

- Motivation: 传统Mean-Shift算法对带宽超参数非常敏感，特别是在数据稀缺的情况下，固定尺度的密度估计会导致分割和虚假模式的问题。
- Method: 提出双重随机Mean-Shift（DSMS），在轨迹更新和核带宽中都引入随机性。每次迭代从连续均匀分布中抽取数据样本和半径，从而更好地探索密度景观。
- Result: 在合成高斯混合数据上的比较实验显示，DSMS显著优于标准和随机Mean-Shift基线，表现出卓越的稳定性，在稀疏聚类场景中防止过度分割，且没有其他性能下降。
- Conclusion: DSMS通过随机化带宽策略作为隐式正则化机制，有效解决了传统Mean-Shift算法对带宽敏感的问题，在稀疏数据聚类中表现更优。


### [52] [On the Out-of-Distribution Generalization of Reasoning in Multimodal LLMs for Simple Visual Planning Tasks](https://arxiv.org/abs/2602.15460)
*Yannic Neuhaus,Nicolas Flammarion,Matthias Hein,Francesco Croce*

Main category: cs.LG

TL;DR: 该研究评估了思维链（CoT）在简单规划任务中的泛化能力，发现CoT能改善分布内泛化，但对分布外泛化（如更大地图）效果有限，多文本格式组合的推理轨迹表现最佳，纯文本模型优于图像输入模型。

- Motivation: 虽然大语言模型和视觉语言模型中的推理能力有所提升，但推理模型的泛化能力仍定义模糊且理解不足。本研究旨在通过简单规划任务，系统评估思维链方法的泛化表现。
- Method: 采用基于网格的导航任务，模型接收地图并输出从起点到终点的移动序列（避开障碍）。通过不同输入表示（视觉和文本）和CoT推理策略微调模型变体，在分布内和分布外条件下系统评估。
- Result: CoT推理能改善所有表示形式的分布内泛化，但分布外泛化（如更大地图）在控制与ID数据的平凡匹配后仍非常有限。多文本格式组合的推理轨迹在OOD泛化中表现最佳且非平凡。纯文本模型始终优于图像输入模型。
- Conclusion: 思维链推理在分布内泛化中有效，但对分布外泛化能力有限，需要更复杂的推理策略。多格式文本组合能提升OOD泛化，纯文本表示优于视觉表示，这对未来推理模型设计有重要启示。


### [53] [Guided Diffusion by Optimized Loss Functions on Relaxed Parameters for Inverse Material Design](https://arxiv.org/abs/2602.15648)
*Jens U. Kreber,Christian Weißenfels,Joerg Stueckler*

Main category: cs.LG

TL;DR: 提出基于扩散模型的逆设计方法，通过连续网格表示和可微分仿真解决离散参数空间问题，在复合材料设计中实现高精度、多样化的设计生成。

- Motivation: 逆设计问题在工程和材料科学中很常见，但面临两大挑战：1）多个设计参数可能产生相同或相似的输出值，需要多模态概率方法获得多样化解决方案；2）离散参数或约束条件使得无法直接使用基于梯度的优化方法。
- Method: 提出基于扩散模型的逆设计框架：1）将原始设计空间松弛为连续网格表示，通过隐式微分计算梯度；2）在松弛参数空间上训练扩散模型作为先验；3）使用引导扩散采样，通过可微分仿真传播目标函数的梯度；4）通过反向投影获得原始参数空间的设计样本。
- Result: 在复合材料设计问题中（前向过程建模为线性FEM问题），该方法能够在2D和3D设置中，为中高目标体积模量生成相对误差在1%以内的多样化设计。同时，通过多目标损失函数可以最小化生成样本的材料密度。
- Conclusion: 该方法成功解决了离散参数空间的逆设计问题，通过扩散模型和可微分仿真的结合，实现了高精度、多样化的设计生成，并能同时优化多个目标，为工程和材料科学中的逆设计问题提供了有效的解决方案。
## cs.CL

### [54] [CGRA-DeBERTa Concept Guided Residual Augmentation Transformer for Theologically Islamic Understanding](https://arxiv.org/abs/2602.15139)
*Tahir Hussain,Saddam Hussain Khan*

Main category: cs.CL

TL;DR: 提出CGRA DeBERTa模型，通过概念引导残差域增强Transformer框架，显著提升伊斯兰圣训文本问答的准确性，在EM分数上比DeBERTa提升8.08分。

- Motivation: 伊斯兰经典文本问答面临领域特定语义、长上下文依赖和概念敏感推理的挑战，现有模型难以准确处理神学概念和语义细微差别。
- Method: 基于定制DeBERTa Transformer骨干，结合轻量级LoRA适配和残差概念感知门控机制，融入12个核心伊斯兰概念词典的神学先验知识，通过重要性加权注意力选择性增强关键语义标记。
- Result: 在42,591个圣训QA对数据集上，CGRA DeBERTa获得97.85的EM分数，显著超越BERT（75.87）和DeBERTa（89.77），仅增加约8%推理开销，在提取准确性和神学精确度方面表现优异。
- Conclusion: CGRA DeBERTa框架为伊斯兰圣训问答提供了高效、可解释且准确的解决方案，能够生成具有必要神学细微差别的教育材料，在保持计算效率的同时显著提升性能。


### [55] [The Vision Wormhole: Latent-Space Communication in Heterogeneous Multi-Agent Systems](https://arxiv.org/abs/2602.15382)
*Xiaoze Liu,Ruowang Zhang,Weichen Yu,Siheng Xiong,Liu He,Feijie Wu,Hoin Jung,Matt Fredrikson,Xiaoqian Wang,Jing Gao*

Main category: cs.CL

TL;DR: Vision Wormhole：利用视觉语言模型的视觉接口实现模型无关、无需文本的异构多智能体通信框架，通过通用视觉编解码器将推理轨迹映射到共享连续潜在空间，显著降低通信开销

- Motivation: 现有基于大语言模型的多智能体系统存在文本通信效率低的问题，包括运行时开销大和信息量化损失。而现有的潜在状态传输方法要么假设同构架构，要么依赖特定配对的学习翻译器，限制了在异构模型家族间的可扩展性和模块化
- Method: 提出Vision Wormhole框架，利用视觉语言模型的视觉接口作为通用通信端口。通过通用视觉编解码器将异构推理轨迹映射到共享连续潜在空间，采用中心辐射拓扑结构将配对对齐复杂度从O(N²)降至O(N)，使用无标签的师生蒸馏目标对齐高速视觉通道与文本推理模式
- Result: 在异构模型家族（如Qwen-VL、Gemma）上的实验表明，Vision Wormhole在受控比较中显著降低了端到端运行时间，同时保持了与标准基于文本的多智能体系统相当的推理保真度
- Conclusion: Vision Wormhole为异构多智能体系统提供了一种高效、模型无关的通信解决方案，通过视觉接口实现"心灵感应"式通信，解决了文本通信的效率瓶颈和异构模型间的兼容性问题
