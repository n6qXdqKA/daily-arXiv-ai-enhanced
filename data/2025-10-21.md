[[toc]]

## cs.CV

### [1] [ESCA: Contextualizing Embodied Agents via Scene-Graph Generation](https://arxiv.org/abs/2510.15963)
*Jiani Huang,Amish Sethi,Matthew Kuo,Mayank Keoliya,Neelay Velingker,JungHo Jung,Ser-Nam Lim,Ziyang Li,Mayur Naik*

Main category: cs.CV

TL;DR: 提出了ESCA框架和SGClip模型，通过结构化时空理解来增强多模态大语言模型，在无需人工标注的情况下实现场景图生成和动作定位，显著提升具身智能体的性能。

- Motivation: 当前多模态大语言模型主要依赖高层视觉-声音-文本配对，缺乏像素级视觉内容与文本语义的细粒度结构化对齐，限制了具身智能体的感知能力。
- Method: 开发了SGClip模型，基于CLIP架构，通过神经符号学习管道在8.7万+开放域视频上训练，利用模型驱动的自监督和结构化推理，无需人工标注的场景图数据。
- Result: SGClip在场景图生成和动作定位基准测试中表现出色，ESCA框架显著提升开源和商业MLLM性能，在两个具身环境中达到最先进水平，大幅减少感知错误。
- Conclusion: ESCA框架通过结构化空间-时间理解有效提升了具身智能体的感知能力，使开源模型能够超越专有基线，证明了细粒度视觉-文本对齐的重要性。


### [2] [CrossRay3D: Geometry and Distribution Guidance for Efficient Multimodal 3D Detection](https://arxiv.org/abs/2510.15991)
*Huiming Yang*

Main category: cs.CV

TL;DR: 提出CrossRay3D稀疏多模态检测器，通过Ray-Aware Supervision和Class-Balanced Supervision提升token表示质量，在nuScenes基准上达到SOTA性能，且运行速度更快、鲁棒性更强。

- Motivation: 现有稀疏检测器忽视了token表示质量，导致前景质量欠佳和性能受限。本文发现几何结构保持和类别分布是提升稀疏检测器性能的关键。
- Method: 提出Sparse Selector(SS)，包含Ray-Aware Supervision(RAS)保持几何信息，Class-Balanced Supervision自适应重加权类别语义显著性，以及Ray Positional Encoding解决LiDAR和图像模态分布差异。
- Result: 在nuScenes基准上达到72.4 mAP和74.7 NDS的SOTA性能，运行速度比其他领先方法快1.84倍，且在LiDAR或相机数据部分或完全缺失时仍保持强鲁棒性。
- Conclusion: CrossRay3D通过提升token表示质量，在稀疏多模态检测中实现了优越的性能、速度和鲁棒性。


### [3] [InfraGPT Smart Infrastructure: An End-to-End VLM-Based Framework for Detecting and Managing Urban Defects](https://arxiv.org/abs/2510.16017)
*Ibrahim Sheikh Mohamed,Abdullah Yahya Abdullah Omaisan*

Main category: cs.CV

TL;DR: 提出一个利用街景CCTV监控进行多缺陷检测和分割的综合管道，结合YOLO目标检测器和视觉语言模型，生成结构化的维护行动计划。

- Motivation: 智能城市基础设施监控需求增长，手动检查成本高且危险，现有自动系统通常只能处理单一缺陷类型或输出非结构化结果，无法直接指导维护工作。
- Method: 使用YOLO系列目标检测器进行多缺陷检测和分割，然后将检测结果传递给视觉语言模型进行场景感知总结，生成包含事件描述、推荐工具、尺寸、维修计划和紧急警报的JSON格式结构化行动计划。
- Result: 在公共数据集和捕获的CCTV片段上的实验评估表明，系统能准确识别多种缺陷并生成连贯的总结。
- Conclusion: 讨论了将系统扩展到城市范围部署的挑战和方向。


### [4] [IAD-GPT: Advancing Visual Knowledge in Multimodal Large Language Model for Industrial Anomaly Detection](https://arxiv.org/abs/2510.16036)
*Zewen Li,Zitong Yu,Qilang Ye,Weicheng Xie,Wei Zhuo,Linlin Shen*

Main category: cs.CV

TL;DR: IAD-GPT：基于多模态大语言模型的工业异常检测新范式，通过异常提示生成器、文本引导增强器和多掩码融合模块，在MVTec-AD和VisA数据集上实现最先进的异常检测和分割性能。

- Motivation: 传统工业异常检测方法缺乏多轮人机对话和详细描述能力，而基于大预训练模型的方法尚未充分发挥大模型在异常检测任务中的潜力。
- Method: 提出IAD-GPT框架：1）异常提示生成器生成特定对象异常提示；2）文本引导增强器通过文本提示交互增强视觉定位能力；3）多掩码融合模块引入掩码作为专家知识增强像素级异常感知。
- Result: 在MVTec-AD和VisA数据集上的实验表明，该方法在自监督和少样本异常检测与分割任务中达到最先进性能。
- Conclusion: IAD-GPT成功结合了文本语义与图像信息，为工业异常检测提供了新的多模态解决方案，代码已开源。


### [5] [Effect of Reporting Mode and Clinical Experience on Radiologists' Gaze and Image Analysis Behavior in Chest Radiography](https://arxiv.org/abs/2510.16070)
*Mahta Khoobi,Marc Sebastian von der Stueck,Felix Barajas Ordonez,Anca-Maria Iancu,Eric Corban,Julia Nowak,Aleksandar Kargaliev,Valeria Perelygina,Anna-Sophie Schott,Daniel Pinto dos Santos,Christiane Kuhl,Daniel Truhn,Sven Nebelung,Robert Siepmann*

Main category: cs.CV

TL;DR: 该研究比较了三种放射学报告模式：自由文本(FT)、结构化报告(SR)和AI辅助结构化报告(AI-SR)。AI-SR在诊断准确性和效率方面表现最佳，能显著减少报告时间并改善用户体验。

- Motivation: 评估结构化报告和人工智能如何改变放射科医生与影像研究的交互方式，比较不同报告模式对图像分析行为、诊断准确性、效率和用户体验的影响。
- Method: 前瞻性研究（2024年7-12月），8名参与者（4名新手和4名非新手）使用定制查看器和眼动追踪系统分析35张床旁胸片。比较FT、SR和AI-SR三种模式，评估诊断准确性、报告时间、眼动指标和用户体验问卷。
- Result: AI-SR诊断准确性最高(κ=0.71)，显著优于FT(κ=0.58)和SR(κ=0.60)。报告时间从FT的88秒降至AI-SR的25秒。眼动指标显示SR和AI-SR减少了放射影像区域的扫视次数和报告区域的注视时间。AI-SR是最受欢迎的模式。
- Conclusion: 结构化报告通过引导视觉注意力到图像来提高效率，而AI预填充的结构化报告进一步提升了诊断准确性和用户满意度。


### [6] [Data-Driven Analysis of Intersectional Bias in Image Classification: A Framework with Bias-Weighted Augmentation](https://arxiv.org/abs/2510.16072)
*Farjana Yesmin*

Main category: cs.CV

TL;DR: 提出了一个数据驱动的框架来分析和缓解图像分类中的交叉偏见，包括交叉公平性评估框架(IFEF)和基于偏见的加权增强(BWA)方法。

- Motivation: 在非平衡数据集上训练的机器学习模型经常表现出交叉偏见——由对象类别和环境条件等多个属性相互作用产生的系统性错误。
- Method: 引入交叉公平性评估框架(IFEF)结合定量公平性指标和可解释性工具来系统识别模型预测中的偏见模式；提出偏见加权增强(BWA)，一种基于子组分布统计自适应变换强度的数据增强策略。
- Result: 在Open Images V7数据集上的实验显示，BWA将代表性不足的类别-环境交叉的准确率提高了多达24个百分点，同时将公平性指标差异减少了35%。多个独立运行的统计分析证实了改进的显著性(p < 0.05)。
- Conclusion: 该方法为分析和解决图像分类系统中的交叉偏见提供了可复现的途径。


### [7] [Differentiable, Bit-shifting, and Scalable Quantization without training neural network from scratch](https://arxiv.org/abs/2510.16088)
*Zia Badar*

Main category: cs.CV

TL;DR: 本文提出了一种可微分的神经网络量化方法，支持多比特对数量化，在ImageNet数据集上使用ResNet18进行测试，仅权重量化时精度损失小于1%，权重和激活值量化时达到SOTA水平，仅需15个训练周期。

- Motivation: 现有量化方法存在两个主要问题：一是大多使用不可微分方法，在反向传播中手动设置导数，影响学习能力；二是移位/对数量化要么避免激活值量化，要么精度较低。本文旨在解决这些问题。
- Method: 提出可微分的量化方法，支持n比特对数量化（形式为2^n），提供收敛性证明。使用移位比特量化，不需要高精度乘法运算。
- Result: 在ImageNet数据集上测试：仅权重量化时精度损失小于1%；权重和激活值量化时达到SOTA精度水平；仅需15个训练周期；相比1比特量化有稍高的CPU指令开销。
- Conclusion: 该方法提供了一种可微分、收敛性可证明的量化方法，支持多比特对数量化，在保持高精度的同时显著减少计算和内存需求。


### [8] [StripRFNet: A Strip Receptive Field and Shape-Aware Network for Road Damage Detection](https://arxiv.org/abs/2510.16115)
*Jianhan Lin,Yuchu Qin,Shuai Gao,Yikang Rui,Jie Liu,Yanjie Lv*

Main category: cs.CV

TL;DR: 提出了StripRFNet网络用于道路表面损伤检测，通过形状感知、条状感受野和小尺度增强三个模块解决损伤形状多样、细长裂缝检测困难和微小损伤识别误差高的问题，在RDD2022基准测试中达到最先进性能。

- Motivation: 道路表面损伤威胁交通安全并阻碍可持续城市发展，但准确检测面临损伤形状多样、细长裂缝难以捕捉和小尺度损伤识别错误率高的挑战。
- Method: StripRFNet包含三个模块：形状感知模块（SPM）通过大分离核注意力增强形状判别；条状感受野模块（SRFM）使用大条状卷积和池化捕捉细长裂缝特征；小尺度增强模块（SSEM）利用高分辨率P2特征图、专用检测头和动态上采样改进小目标检测。
- Result: 在RDD2022基准测试中，StripRFNet超越现有方法。在中国子集上，F1分数、mAP50和mAP50:95分别比基线提高4.4、2.9和3.4个百分点。在全数据集上达到80.33%的最高F1分数，同时保持有竞争力的推理速度。
- Conclusion: StripRFNet实现了最先进的准确性和实时效率，为智能道路维护和可持续基础设施管理提供了有前景的工具。


### [9] [ObjectTransforms for Uncertainty Quantification and Reduction in Vision-Based Perception for Autonomous Vehicles](https://arxiv.org/abs/2510.16118)
*Nishad Sahu,Shounak Sural,Aditya Satish Patil,Ragunathan,Rajkumar*

Main category: cs.CV

TL;DR: 提出ObjectTransforms方法，通过对象特定变换在训练和推理时量化并减少基于视觉的目标检测中的不确定性，提高自动驾驶感知的可靠性。

- Motivation: 自动驾驶中可靠的感知对安全决策至关重要，但基于视觉的目标检测神经网络容易受到数据偏差和分布偏移等不确定性因素的影响。
- Method: 在训练时对单个对象进行颜色空间扰动，并使用扩散模型生成多样化的行人实例；在推理时对检测到的对象应用扰动，利用检测分数的方差实时量化预测不确定性。
- Result: 在NuImages 10K数据集上的实验表明，该方法在所有对象类别上都带来了显著的准确性提升和不确定性降低，在推理时对假阳性预测了比真阳性更高的不确定性值。
- Conclusion: ObjectTransforms作为一种轻量级但有效的机制，在训练和推理时分别减少和量化基于视觉的感知中的不确定性具有潜力。


### [10] [Aria Gen 2 Pilot Dataset](https://arxiv.org/abs/2510.16134)
*Chen Kong,James Fort,Aria Kang,Jonathan Wittmer,Simon Green,Tianwei Shen,Yipu Zhao,Cheng Peng,Gustavo Solaira,Andrew Berkovich,Nikhil Raina,Vijay Baiyya,Evgeniy Oleinik,Eric Huang,Fan Zhang,Julian Straub,Mark Schwesinger,Luis Pesqueira,Xiaqing Pan,Jakob Julian Engel,Carl Ren,Mingfei Yan,Richard Newcombe*

Main category: cs.CV

TL;DR: A2PD是一个使用Aria Gen 2眼镜采集的自我中心多模态开放数据集，包含清洁、烹饪、进食、玩耍和户外步行五种场景的原始传感器数据和机器感知算法输出。

- Motivation: 为了及时提供最先进的Aria Gen 2眼镜采集的自我中心多模态数据，促进相关研究的发展。
- Method: 使用Aria Gen 2眼镜采集主要受试者Dia'ane及其朋友的日常活动数据，涵盖五种主要场景，并提供原始传感器数据和机器感知算法输出。
- Result: 数据集展示了设备能够感知佩戴者、周围环境以及佩戴者与环境之间的互动，并在不同用户和条件下保持稳健性能。
- Conclusion: A2PD数据集已在projectaria.com公开提供，并附带开源工具和使用示例，可用于相关研究。


### [11] [GuideFlow3D: Optimization-Guided Rectified Flow For Appearance Transfer](https://arxiv.org/abs/2510.16136)
*Sayan Deb Sarkar,Sinisa Stekovic,Vincent Lepetit,Iro Armeni*

Main category: cs.CV

TL;DR: 提出了一种无需训练的方法，通过引导预训练的整流流模型，在采样过程中定期添加可微分损失函数指导，成功将外观从图像或文本转移到3D资产上，解决了几何差异大时的外观迁移问题。

- Motivation: 现有方法在输入和外观对象的几何形状差异较大时表现不佳，直接应用3D生成模型无法产生令人满意的结果，需要一种更有效的外观迁移方法。
- Method: 基于通用引导思想，在预训练的整流流模型采样过程中定期添加可微分损失函数作为指导，包括部分感知损失和自相似性损失。
- Result: 方法成功将纹理和几何细节转移到3D资产上，在定性和定量评估中都优于基线方法，并通过GPT评估系统和用户研究验证了效果。
- Conclusion: 该方法具有通用性，可扩展到不同类型的扩散模型和引导函数，为外观迁移任务提供了有效的解决方案。


### [12] [C-arm Guidance: A Self-supervised Approach To Automated Positioning During Stroke Thrombectomy](https://arxiv.org/abs/2510.16145)
*Ahmad Arrabi,Jay hwasung Jung,J Le,A Nguyen,J Reed,E Stahl,Nathan Franssen,Scott Raymond,Safwan Wshah*

Main category: cs.CV

TL;DR: 提出了一种基于自监督学习的框架，通过回归任务分类骨骼标志点，旨在自动化缺血性卒中血栓切除术的关键环节，提高效率和安全性。

- Motivation: 血栓切除术是缺血性卒中最有效的治疗方法之一，但需要大量资源和专业人员。通过深度学习自动化关键环节可以提升效率和安全性。
- Method: 采用自监督学习框架，使用基于回归的前置任务来分类各种骨骼标志点。
- Result: 实验表明该模型在回归和分类任务上均优于现有方法，位置前置任务显著提升了下游分类性能。
- Conclusion: 该框架为血栓切除术的自动化提供了有效方法，未来工作将扩展至完全自主的C臂控制，优化从骨盆到头部的轨迹规划。


### [13] [DuetMatch: Harmonizing Semi-Supervised Brain MRI Segmentation via Decoupled Branch Optimization](https://arxiv.org/abs/2510.16146)
*Thanh-Huy Nguyen,Hoang-Thien Nguyen,Vi Vu,Ba-Thinh Lam,Phat Huynh,Tianyang Wang,Xingjian Li,Ulas Bagci,Min Xu*

Main category: cs.CV

TL;DR: DuetMatch是一种新颖的双分支半监督医学图像分割框架，采用异步优化策略，通过解耦的dropout扰动和配对CutMix交叉引导来增强模型鲁棒性和多样性，在脑MRI分割任务上超越了现有方法。

- Motivation: 医学图像标注数据有限，而传统的师生框架联合优化整个网络会导致收敛困难和稳定性问题，特别是在具有挑战性的场景中。
- Method: 提出双分支异步优化框架，每个分支只优化编码器或解码器；引入解耦dropout扰动增强一致性；设计配对CutMix交叉引导交换伪标签；使用一致性匹配减少噪声伪标签的确认偏差。
- Result: 在ISLES2022和BraTS等脑MRI分割基准数据集上的广泛实验表明，DuetMatch始终优于最先进的方法。
- Conclusion: DuetMatch在半监督医学图像分割中表现出优异的有效性和鲁棒性，能够适应多样化的半监督分割场景。


### [14] [Automated C-Arm Positioning via Conformal Landmark Localization](https://arxiv.org/abs/2510.16160)
*Ahmad Arrabi,Jay Hwasung Jung,Jax Luo,Nathan Franssen,Scott Raymond,Safwan Wshah*

Main category: cs.CV

TL;DR: 提出了一种自主导航C臂到预定义解剖标志的管道，利用X射线图像预测3D位移向量，结合不确定度估计和保形预测确保可靠性。

- Motivation: 临床工作流程依赖手动对齐C臂，增加了辐射暴露和手术延迟，需要自动化解决方案来提高效率和安全性。
- Method: 使用X射线图像预测3D位移向量，结合概率损失和骨骼姿态正则化，采用保形预测校准不确定度，生成3D置信区域。
- Result: 在DeepDRR生成的合成X射线数据集上验证，显示强大的定位精度和良好校准的预测边界。
- Conclusion: 该管道有潜力作为安全可靠自主C臂系统的组成部分，代码已开源。


### [15] [Cost Savings from Automatic Quality Assessment of Generated Images](https://arxiv.org/abs/2510.16179)
*Xavier Giro-i-Nieto,Nefeli Andreou,Anqi Liang,Manel Baradad,Francesc Moreno-Noguer,Aleix Martinez*

Main category: cs.CV

TL;DR: 本文提出了一种自动图像质量评估预过滤方法，通过公式估算成本节约，在背景修复用例中实现了51.61%的成本节省。

- Motivation: 当前深度生成模型生成的图像质量尚无法达到传统摄影方法的标准，生产流程中需要人工进行图像质量评估，这个过程缓慢且昂贵，特别是因为自动生成图像通过质量标准的比例较低。
- Method: 引入自动预过滤阶段来提高发送给审核的图像整体质量，提出了一个估算通用IQA引擎精度和通过率对成本节约影响的公式，并在背景修复用例中应用简单的AutoML解决方案。
- Result: 在背景修复用例中，通过简单的AutoML解决方案实现了51.61%的显著成本节约。
- Conclusion: 自动预过滤阶段可以有效减少图像质量评估的工作量，降低获取高质量图像的平均成本，为生产流程带来显著的经济效益。


### [16] [Seeing Through the Brain: New Insights from Decoding Visual Stimuli with fMRI](https://arxiv.org/abs/2510.16196)
*Zheng Huang,Enpei Zhang,Yinghao Cai,Weikang Qiu,Carl Yang,Elynn Chen,Xiang Zhang,Rex Ying,Dawei Zhou,Yujun Yan*

Main category: cs.CV

TL;DR: 该论文提出PRISM模型，通过将fMRI信号投影到结构化文本空间作为中间表示来重建视觉刺激，利用文本空间比视觉空间更接近fMRI信号的特点，结合面向对象的扩散模块和属性关系搜索模块来提升图像重建质量。

- Motivation: 理解大脑如何编码视觉信息是神经科学和机器学习的重要挑战。当前从fMRI信号重建图像的方法依赖于将信号转换为潜在空间，但哪种潜在空间最适合这种转换以及如何有效组织该空间来表征视觉刺激仍不清楚。
- Method: 提出PRISM模型：1）将fMRI信号投影到结构化文本空间作为中间表示；2）使用面向对象的扩散模块通过组合单个对象来生成图像，减少对象检测错误；3）属性关系搜索模块自动识别与神经活动最匹配的关键属性和关系。
- Result: 在真实世界数据集上的广泛实验表明，该框架优于现有方法，感知损失减少了高达8%。
- Conclusion: 研究结果表明，使用结构化文本作为中间空间来桥接fMRI信号和图像重建具有重要意义，fMRI信号与语言模型的文本空间比基于视觉的空间或联合文本图像空间更相似。


### [17] [Data-Centric AI for Tropical Agricultural Mapping: Challenges, Strategies and Scalable Solutions](https://arxiv.org/abs/2510.16207)
*Mateus Pinto da Silva,Sabrina P. L. P. Correa,Hugo N. Oliveira,Ian M. Nunes,Jefersson A. dos Santos*

Main category: cs.CV

TL;DR: 该论文提出采用数据为中心的人工智能方法来应对热带农业遥感制图的挑战，强调数据质量的重要性，并推荐了25种数据策略，其中9种最成熟的方法可用于大规模热带农业制图项目。

- Motivation: 热带地区农业遥感制图面临缺乏高质量标注数据、标注成本高、数据变异性大和区域泛化能力差等独特挑战，传统以模型为中心的方法受到限制。
- Method: 采用数据为中心的人工智能视角和流程，重点应用置信学习、核心集选择、数据增强和主动学习等技术，强调数据质量和数据管理。
- Result: 确定了25种适用于大规模农业制图流程的数据策略，其中9种最成熟和直接的方法可实际应用于热带农业制图项目。
- Conclusion: 数据为中心的方法能够更好地适应热带农业的动态现实，为热带农业遥感制图提供了实用的解决方案和可操作的流程。


### [18] [StretchySnake: Flexible SSM Training Unlocks Action Recognition Across Spatio-Temporal Scales](https://arxiv.org/abs/2510.16209)
*Nyle Siddiqui,Rohit Gupta,Sirnam Swetha,Mubarak Shah*

Main category: cs.CV

TL;DR: 提出了一种名为StretchySnake的灵活训练方法，通过动态采样不同时空分辨率的视频并插值模型权重，使状态空间模型(SSM)能够无缝处理从短片段到长活动的各种视频，在动作识别任务中表现优于transformer和SSM基线。

- Motivation: 当前视频理解训练方法主要针对transformer设计，未能充分利用SSM的独特属性。固定分辨率和视频长度的训练导致模型在面对训练时未见过的时空分辨率时性能下降，即时空不灵活性，限制了模型在短长视频中的性能保持能力。
- Method: 提出灵活训练方法：在训练过程中采样不同时空分辨率的视频，并动态插值模型权重以适应任意时空尺度。比较了五种不同的灵活训练变体，确定了最适合视频SSM的策略。
- Result: 在短动作(UCF-101、HMDB-51)和长动作(COIN、Breakfast)基准测试中，StretchySnake比transformer和SSM基线性能提升高达28%，在细粒度动作(SSV2、Diving-48)上表现出强大的适应性。
- Conclusion: 该方法提供了一个简单的即插即用训练方案，使视频SSM在各种动作识别场景中更加鲁棒、分辨率无关且高效。


### [19] [VM-BeautyNet: A Synergistic Ensemble of Vision Transformer and Mamba for Facial Beauty Prediction](https://arxiv.org/abs/2510.16220)
*Djamel Eddine Boukhari*

Main category: cs.CV

TL;DR: 提出VM-BeautyNet，一种融合Vision Transformer和Mamba视觉模型的异构集成架构，用于面部美观度预测，在SCUT-FBP5500数据集上达到SOTA性能。

- Motivation: 现有CNN模型难以捕捉全局面部特征，ViT能建模长距离空间关系但计算复杂度高，需要结合两者优势解决面部美观度预测问题。
- Method: 使用异构集成架构，ViT主干捕捉全局面部结构和对称性，Mamba主干以线性复杂度建模长距离依赖关系，关注序列特征和纹理。
- Result: 在SCUT-FBP5500数据集上取得PC=0.9212、MAE=0.2085、RMSE=0.2698的SOTA性能，并通过Grad-CAM可视化验证了两个主干网络的互补特征提取。
- Conclusion: VM-BeautyNet为计算美学提供了强大的新架构范式，通过融合ViT和Mamba的优势，有效解决了面部美观度预测中的全局特征捕捉问题。


### [20] [Designing a Convolutional Neural Network for High-Accuracy Oral Cavity Squamous Cell Carcinoma (OCSCC) Detection](https://arxiv.org/abs/2510.16235)
*Vishal Manikanden,Aniketh Bandlamudi,Daniel Haehn*

Main category: cs.CV

TL;DR: 使用卷积神经网络(CNN)结合图像采集硬件系统，开发口腔鳞状细胞癌(OCSCC)早期检测方法，研究图像分辨率对检测精度的影响。

- Motivation: 口腔鳞状细胞癌是头颈部最常见的癌症，早期症状隐蔽且生长缓慢，常被忽视导致可预防的死亡。需要开发有效的早期检测方法。
- Method: 训练CNN模型识别OCSCC，使用4293张训练图像（良性/恶性肿瘤及阴性样本），设计图像采集硬件系统，测试不同分辨率图像对检测精度的影响。
- Result: 图像分辨率提高时，预测准确率呈对数增长，显示高像素数带来的收益递减。开发了应用软件便于测试和开放访问CNN模型。
- Conclusion: CNN结合图像采集硬件能有效检测OCSCC，图像分辨率对检测精度有重要影响但存在收益递减效应。


### [21] [Embody 3D: A Large-scale Multimodal Motion and Behavior Dataset](https://arxiv.org/abs/2510.16258)
*Claire McLean,Makenzie Meendering,Tristan Swartz,Orri Gabbay,Alexandra Olsen,Rachel Jacobs,Nicholas Rosen,Philippe de Bree,Tony Garcia,Gadsden Merrill,Jake Sandakly,Julia Buffalini,Neham Jain,Steven Krenn,Moneish Kumar,Dejan Markovic,Evonne Ng,Fabian Prada,Andrew Saba,Siwei Zhang,Vasu Agrawal,Tim Godisart,Alexander Richard,Michael Zollhoefer*

Main category: cs.CV

TL;DR: Embody 3D是一个包含500小时3D运动数据的多模态数据集，来自439名参与者，包含单人和多人行为数据。

- Motivation: 创建大规模、多模态的3D人体运动数据集，为研究人类行为和交互提供丰富资源。
- Method: 在多相机采集环境中收集500小时的3D运动数据，包括身体追踪、手势追踪、音频和文本标注。
- Result: 构建了包含54百万帧3D追踪运动的数据集，涵盖广泛的人类行为和交互场景。
- Conclusion: Embody 3D数据集为研究人类运动、行为和社交互动提供了宝贵的多模态资源。


### [22] [Proactive Scene Decomposition and Reconstruction](https://arxiv.org/abs/2510.16272)
*Baicheng Li,Zike Yan,Dong Wu,Hongbin Zha*

Main category: cs.CV

TL;DR: 提出主动场景分解与重建任务，利用人-物交互动态解构和重建环境，解决静态物体级重建的模糊性问题。

- Motivation: 人类行为是场景动态的主要成因，包含丰富的动态线索。传统静态物体级重建方法存在固有模糊性，需要利用人类有意图的交互来动态优化分解和重建过程。
- Method: 基于人-物交互的在线方法，迭代分解和重建环境。集成相机和物体姿态估计、实例分解、在线地图更新等任务，利用高斯泼溅技术实现准确一致的动态场景建模。
- Result: 在多个真实场景中验证了有效性，实现了逼真高效的可视化渲染，展现出有前景的优势。
- Conclusion: 该方法为传统物体级重建方法提供了灵活、渐进的替代方案，能够有效利用人-物交互线索进行动态场景建模。


### [23] [Cerberus: Real-Time Video Anomaly Detection via Cascaded Vision-Language Models](https://arxiv.org/abs/2510.16290)
*Yue Zheng,Xiufang Shi,Jiming Chen,Yuanchao Shu*

Main category: cs.CV

TL;DR: Cerberus是一个用于实时视频异常检测的两级级联系统，通过运动掩码提示和基于规则的偏差检测，在保持高精度的同时实现151.79倍加速

- Motivation: 解决基于视觉语言模型的视频异常检测方法计算成本高、视觉定位性能不稳定的问题，实现实时部署
- Method: 采用两级级联系统：离线学习正常行为规则，在线推理时结合轻量级过滤和细粒度VLM推理；创新包括运动掩码提示和基于规则的偏差检测
- Result: 在四个数据集上的评估显示，平均达到57.68 fps（151.79倍加速）和97.2%的准确率，性能与最先进的VLM-based VAD方法相当
- Conclusion: Cerberus是实时视频分析的实用解决方案，在保持高精度的同时显著提升了推理速度


### [24] [OpenLVLM-MIA: A Controlled Benchmark Revealing the Limits of Membership Inference Attacks on Large Vision-Language Models](https://arxiv.org/abs/2510.16295)
*Ryoto Miyamoto,Xin Fan,Fuyuko Kido,Tsuneo Matsumoto,Hayato Yamana*

Main category: cs.CV

TL;DR: OpenLVLM-MIA是一个新的基准测试，揭示了评估大型视觉语言模型成员推理攻击时的基本挑战，指出先前的高成功率主要源于数据集构建中的分布偏差，而非真实成员身份识别。

- Motivation: 现有评估方法存在分布偏差问题，导致成员推理攻击结果被高估，需要建立无偏基准来准确评估攻击效果。
- Method: 构建包含6000张图像的受控基准，平衡成员和非成员样本分布，提供三个不同训练阶段的真实成员标签。
- Result: 在无偏条件下，最先进的MIA方法性能收敛到随机猜测水平。
- Conclusion: OpenLVLM-MIA为LVLM隐私保护技术发展提供了可靠基础，澄清了当前MIA研究的局限性。


### [25] [Stroke2Sketch: Harnessing Stroke Attributes for Training-Free Sketch Generation](https://arxiv.org/abs/2510.16319)
*Rui Yang,Huining Li,Yiyi Long,Xiaojun Wu,Shengfeng He*

Main category: cs.CV

TL;DR: Stroke2Sketch是一个无需训练的新框架，通过跨图像笔画注意力机制实现参考风格到内容图像的精确笔画属性迁移，同时保持语义结构完整性。

- Motivation: 生成具有参考风格的草图需要精确迁移笔画属性（如线条粗细、变形和纹理稀疏度），同时保持语义结构和内容保真度。
- Method: 提出跨图像笔画注意力机制，嵌入自注意力层中建立细粒度语义对应关系；开发自适应对比度增强和语义聚焦注意力来强化内容保持和前景强调。
- Result: Stroke2Sketch能有效合成风格忠实的草图，与手工绘制结果高度相似，在表达性笔画控制和语义连贯性方面优于现有方法。
- Conclusion: 该框架无需训练即可实现精确的笔画属性迁移，在保持结构完整性的同时生成风格一致的草图。


### [26] [Scaling Laws for Deepfake Detection](https://arxiv.org/abs/2510.16320)
*Wenhao Wang,Longqi Cai,Taihong Xiao,Yuxiao Wang,Ming-Hsuan Yang*

Main category: cs.CV

TL;DR: 本文系统研究了深度伪造检测的缩放定律，发现检测错误率随真实图像域数量和深度伪造方法数量增加呈幂律衰减，类似大语言模型的缩放规律。

- Motivation: 由于现有数据集无法满足研究需求，作者构建了ScaleDF数据集来系统分析深度伪造检测任务中的缩放规律。
- Method: 构建ScaleDF数据集（包含580万真实图像和880万伪造图像），分析模型性能随真实域数量、伪造方法和训练图像数量的变化规律。
- Result: 观察到检测错误率随真实域数量和伪造方法数量增加呈幂律衰减，可以预测达到目标性能所需的额外资源。
- Conclusion: 缩放定律可用于预测深度伪造检测性能，为对抗不断发展的深度伪造技术提供了数据中心的解决方案。


### [27] [Scale-DiT: Ultra-High-Resolution Image Generation with Hierarchical Local Attention](https://arxiv.org/abs/2510.16325)
*Yuyao Zhang,Yu-Wing Tai*

Main category: cs.CV

TL;DR: Scale-DiT是一个新的扩散框架，通过分层局部注意力和低分辨率全局引导，实现了高效、可扩展的超高分辨率图像生成，能够在4K分辨率下保持语义一致性且无需额外高分辨率训练数据。

- Motivation: 当前扩散模型受限于注意力机制的二次复杂性和原生4K训练数据的稀缺，无法实现超高分辨率文本到图像生成。需要一种既能合成细粒度纹理又能保持全局结构一致性的方法。
- Method: 提出分层局部注意力机制，将高分辨率潜在空间划分为固定大小的局部窗口以降低注意力复杂度；使用低分辨率潜在空间提供全局语义引导；通过轻量级LoRA适配器连接全局和局部路径；采用Hilbert曲线重排token序列和融合内核优化推理效率。
- Result: Scale-DiT相比密集注意力基线实现了2倍以上的推理加速和更低的内存使用，可靠扩展到4K×4K分辨率，在定量指标（FID、IS、CLIP Score）和定性比较中均表现出优越的全局一致性和更清晰的局部细节。
- Conclusion: 分层局部注意力配合引导性低分辨率锚点是一种有前景且有效的方法，可推动超高分辨率图像生成的发展。


### [28] [DiffusionX: Efficient Edge-Cloud Collaborative Image Generation with Multi-Round Prompt Evolution](https://arxiv.org/abs/2510.16326)
*Yi Wei,Shunpu Tang,Liang Zhao,Qiangian Yang*

Main category: cs.CV

TL;DR: DiffusionX是一个云边协同框架，通过轻量级设备端扩散模型快速生成预览图像，高性能云端模型进行最终优化，实现高效的多轮提示生成。

- Motivation: 扩散模型生成过程计算密集，用户需要多次迭代优化提示，增加了延迟和云资源负担。
- Method: 提出云边协作框架，设备端轻量模型快速预览，云端高性能模型最终优化；引入噪声水平预测器动态平衡计算负载。
- Result: 相比Stable Diffusion v1.5减少15.8%平均生成时间，图像质量相当；仅比Tiny-SD慢0.9%但图像质量显著提升。
- Conclusion: DiffusionX在最小开销下展示了效率和可扩展性，有效平衡延迟和云工作负载。


### [29] [TokenAR: Multiple Subject Generation via Autoregressive Token-level enhancement](https://arxiv.org/abs/2510.16332)
*Haiyue Sun,Qingdong He,Jinlong Peng,Peng Tang,Jiangning Zhang,Junwei Zhu,Xiaobin Hu,Shuicheng Yan*

Main category: cs.CV

TL;DR: TokenAR框架通过token级增强机制解决多参考图像生成中的身份混淆问题，包含token索引嵌入、指导token注入和身份token解耦策略，显著提升了自回归模型在多主体生成中的身份一致性和背景重建质量。

- Motivation: 现有的自回归模型在多参考图像生成中难以解耦不同参考身份，导致身份混淆问题。
- Method: 提出TokenAR框架，包含三个token级增强组件：Token索引嵌入、指导token注入和身份token解耦策略，并构建了InstructAR数据集用于训练和评估。
- Result: 实验验证该方法在多参考图像生成任务中超越了当前最先进模型，实现了良好的身份一致性和高质量背景重建。
- Conclusion: TokenAR框架有效解决了多参考图像生成中的身份混淆问题，为自回归模型在多主体生成任务中提供了新的解决方案。


### [30] [RL makes MLLMs see better than SFT](https://arxiv.org/abs/2510.16333)
*Junha Song,Sangdoo Yun,Dongyoon Han,Jaegul Choo,Byeongho Heo*

Main category: cs.CV

TL;DR: 该论文挑战了多模态语言模型性能主要继承自LLM骨干网络的假设，重点分析了视觉编码器在RL训练范式下的重塑作用，并提出了PIVOT方法显著提升视觉编码器性能。

- Motivation: 当前MLLM研究过度关注LLM骨干网络而忽视视觉编码器的作用，特别是在从SFT转向RL的训练范式转变中，缺乏对视觉编码器如何被重塑的分析。
- Method: 通过多种深度实验分析视觉编码器，包括ImageNet分类、分割和梯度可视化，比较SFT和RL训练策略对视觉表示的影响，并开发了PIVOT优化方法。
- Result: RL相比SFT能产生更强且更精确定位的视觉表示，PIVOT训练的视觉编码器性能优于更大规模预训练的对手，且计算成本不到标准视觉预训练的1%。
- Conclusion: RL训练范式能从根本上重塑MLLM的视觉表示，PIVOT方法为MLLM视觉骨干网络的发展提供了高效路径，挑战了传统对MLLM性能来源的认知。


### [31] [On the Provable Importance of Gradients for Language-Assisted Image Clustering](https://arxiv.org/abs/2510.16335)
*Bo Peng,Jie Lu,Guangquan Zhang,Zhen Fang*

Main category: cs.CV

TL;DR: 提出GradNorm框架，通过梯度范数来筛选与图像语义相关的名词，用于语言辅助图像聚类，在理论和实验上都优于现有方法

- Motivation: 现有的语言辅助图像聚类方法主要基于CLIP特征空间筛选相关名词，但缺乏严格的理论基础
- Method: 提出基于梯度范数的框架GradNorm，通过反向传播交叉熵损失的梯度大小来衡量名词与图像语义的相关性
- Result: 理论分析证明GradNorm具有严格误差界，且包含现有方法作为特例；实验表明在多个基准测试中达到最先进的聚类性能
- Conclusion: GradNorm为语言辅助图像聚类提供了理论保证的解决方案，显著提升了聚类效果


### [32] [MIRAD - A comprehensive real-world robust anomaly detection dataset for Mass Individualization](https://arxiv.org/abs/2510.16370)
*Pulin Li,Guocheng Wu,Li Yin,Yuxin Zheng,Wei Zhang,Yanjie Zhou*

Main category: cs.CV

TL;DR: 提出了首个专门为社交制造场景设计的异常检测基准数据集MIRAD，包含高度定制化产品、分布式制造节点和成像环境异质性三个关键维度，评估显示现有SOTA方法在该数据集上性能显著下降。

- Motivation: 社交制造模式带来了质量控制的重大挑战，主要困难包括：产品高度定制化、生产订单碎片化小批量、分布式站点成像环境差异大。缺乏真实世界数据集和针对性算法。
- Method: 构建MIRAD数据集，包含三个关键维度：(1)多样化个性化产品的大类内差异，(2)来自六个地理分散制造节点的数据，(3)显著的成像异质性（光照、背景、运动条件变化）。在数据集上广泛评估了SOTA异常检测方法。
- Result: 所有模型在MIRAD数据集上的性能相比传统基准都显著下降，突显了真实世界个性化生产中缺陷检测的未解决复杂性。
- Conclusion: MIRAD通过连接工业需求和学术研究，为开发工业5.0所需的稳健质量控制解决方案提供了现实基础。数据集已公开可用。


### [33] [Cataract-LMM: Large-Scale, Multi-Source, Multi-Task Benchmark for Deep Learning in Surgical Video Analysis](https://arxiv.org/abs/2510.16371)
*Mohammad Javad Ahmadi,Iman Gandomi,Parisa Abdi,Seyed-Farzad Mohammadi,Amirhossein Taslimi,Mehdi Khodaparast,Hassan Hashemi,Mahdi Tavakoli,Hamid D. Taghirad*

Main category: cs.CV

TL;DR: 提出了一个包含3000个白内障超声乳化手术视频的数据集，包含四个注释层：手术阶段、实例分割、器械-组织交互追踪和技能评分，并进行了基准测试。

- Motivation: 当前白内障手术数据集缺乏多样性和深度注释，无法训练泛化性强的深度学习模型。
- Method: 收集来自两个手术中心的3000个手术视频，添加四个注释层，并进行基准实验验证数据集质量。
- Result: 建立了高质量的手术数据集，支持工作流识别、场景分割和自动技能评估等关键手术AI任务。
- Conclusion: 该数据集填补了白内障手术AI研究的资源空白，为开发计算机辅助手术系统提供了重要基础。


### [34] [iWatchRoadv2: Pothole Detection, Geospatial Mapping, and Intelligent Road Governance](https://arxiv.org/abs/2510.16375)
*Rishi Raj Sahoo,Surbhi Saswati Mohanty,Subhankar Mishra*

Main category: cs.CV

TL;DR: iWatchRoadv2是一个用于实时道路坑洼检测、GPS地理标记和动态道路健康可视化的端到端自动化平台，专门针对印度多样化的道路网络设计。

- Motivation: 印度道路网络复杂且维护不足，道路坑洼带来严重安全隐患和维护挑战，需要自动化解决方案来改善道路基础设施管理。
- Method: 使用自标注的7000多张印度道路仪表盘摄像头图像数据集微调Ultralytics YOLO模型进行坑洼检测，结合OCR提取的时间戳和外部GPS日志进行精确定位，并通过优化的后端数据库管理道路段和承包商信息。
- Result: 开发了一个完整的自动化平台，能够实时检测坑洼、精确定位、发送警报给相关方，并提供直观的Web界面进行数据分析，支持证据驱动的维修规划和质量管理。
- Conclusion: iWatchRoadv2通过自动化完整的坑洼监测生命周期，实现了数据驱动的智慧城市管理、透明治理和可持续的道路基础设施维护改进，为城市和农村部署提供了经济高效的解决方案。


### [35] [Demeter: A Parametric Model of Crop Plant Morphology from the Real World](https://arxiv.org/abs/2510.16377)
*Tianhang Cheng,Albert J. Zhai,Evan Z. Chen,Rui Zhou,Yawen Deng,Zitong Li,Kejie Zhao,Janice Shiu,Qianyu Zhao,Yide Xu,Xinlei Wang,Yuan Shen,Sheng Wang,Lisa Ainsworth,Kaiyu Guan,Shenlong Wang*

Main category: cs.CV

TL;DR: Demeter是一个数据驱动的参数化植物形态模型，能够编码植物的拓扑结构、形状、关节运动和变形，支持不同物种的拓扑变化，并模拟三种形状变化来源。

- Motivation: 虽然现有模型对人类和动物建模很强大，但缺乏对植物同样表达力的建模方法，特别是在作物植物建模方面存在空白。
- Method: 收集大规模大豆农场数据集，开发参数化模型编码植物形态的关键因素，包括拓扑、形状、关节运动和变形。
- Result: Demeter能有效合成形状、重建结构并模拟生物物理过程，在作物植物建模方面表现出色。
- Conclusion: Demeter为植物建模提供了强大的参数化表示，在3D重建、生成、理解和模拟方面具有广泛应用前景。


### [36] [SPLite Hand: Sparsity-Aware Lightweight 3D Hand Pose Estimation](https://arxiv.org/abs/2510.16396)
*Yeh Keng Hao,Hsu Tzu Wei,Sun Min*

Main category: cs.CV

TL;DR: 设计了一个轻量级框架，采用编码器-解码器架构，通过稀疏卷积、SPLite解码器和量化感知训练，在保持精度的同时显著提升AR/VR设备上的推理效率。

- Motivation: 随着AR/VR设备的普及，边缘设备需要实时推理、低功耗和低延迟，但现有方法在效率和性能之间难以平衡。
- Method: 使用ResNet-18骨干网络应用稀疏卷积，提出SPLite解码器架构，并采用量化感知训练来优化性能。
- Result: 在Raspberry Pi 5上实现2.98倍加速，端到端效率提升42%，解码帧率提升3.1倍，精度损失极小（PA-MPJPE仅从9.0mm增加到9.1mm）。
- Conclusion: 该方法在保持与最先进方法相当精度的同时，显著提升了计算效率，适用于AR/VR边缘设备部署。


### [37] [REALM: An MLLM-Agent Framework for Open World 3D Reasoning Segmentation and Editing on Gaussian Splatting](https://arxiv.org/abs/2510.16410)
*Changyue Shi,Minghao Chen,Yiping Mao,Chuxiao Yang,Xinyuan Hu,Jiajun Ding,Zhou Yu*

Main category: cs.CV

TL;DR: REALM是一个创新的MLLM智能体框架，通过3D高斯溅射表示实现基于开放世界推理的分割，无需大量3D特定后训练。

- Motivation: 弥合复杂人类指令与精确3D对象定位之间的差距是视觉和机器人领域的重大挑战。现有3D分割方法难以解释模糊的基于推理的指令，而擅长此类推理的2D视觉语言模型缺乏内在的3D空间理解。
- Method: 直接在3D高斯溅射表示上执行分割，利用其渲染逼真新视图的能力。提出全局到局部空间定位策略：首先并行输入多个全局视图到MLLM进行粗粒度定位，然后合成多个对象特写视图进行细粒度局部分割。
- Result: 在LERF、3D-OVS和新引入的REALM3D基准测试中，REALM在解释显式和隐式指令方面表现出色。该框架还无缝支持一系列3D交互任务，包括对象移除、替换和风格转换。
- Conclusion: REALM展示了其实际效用和多功能性，为3D视觉推理和交互任务提供了有效的解决方案。


### [38] [SSL4RL: Revisiting Self-supervised Learning as Intrinsic Reward for Visual-Language Reasoning](https://arxiv.org/abs/2510.16416)
*Xiaojun Guo,Runyu Zhou,Yifei Wang,Qi Zhang,Chenheng Zhang,Stefanie Jegelka,Xiaohan Wang,Jiajun Chai,Guojun Yin,Wei Lin,Yisen Wang*

Main category: cs.CV

TL;DR: SSL4RL是一个利用自监督学习任务作为可验证奖励的强化学习框架，用于优化视觉语言模型，解决其依赖语言先验或文本捷径的问题。

- Motivation: 视觉语言模型在视觉中心任务中过度依赖语言先验，在推理中使用文本捷径，且缺乏可扩展可靠的奖励机制来应用强化学习进行对齐。
- Method: 将自监督学习目标（如图像旋转预测、掩码补丁重建）转化为密集的自动奖励信号，无需人工偏好数据或不可靠的AI评估器。
- Result: SSL4RL显著提升了视觉中心和视觉语言推理基准的性能，并在图学习中也显示出通用性。
- Conclusion: SSL4RL建立了一个使用可验证自监督目标对齐多模态模型的通用有效范式。


### [39] [LightGlueStick: a Fast and Robust Glue for Joint Point-Line Matching](https://arxiv.org/abs/2510.16438)
*Aidyn Ubingazhibov,Rémi Pautrat,Iago Suárez,Shaohui Liu,Marc Pollefeys,Viktor Larsson*

Main category: cs.CV

TL;DR: LightGlueStick是一种轻量级的点和线段匹配器，通过注意力线消息传递机制实现高效的点线联合匹配，在多个基准测试中达到最先进性能。

- Motivation: 传统方法将点和线匹配视为独立任务，而GlueStick虽然实现了联合匹配但架构过重，无法满足实时应用和边缘设备部署需求。
- Method: 提出注意力线消息传递机制，显式地将线段连通性暴露给网络，实现节点间高效通信。
- Result: 在多个基准测试中建立了新的最先进性能，代码已开源。
- Conclusion: LightGlueStick通过轻量化设计实现了高效的点线联合匹配，适合实时应用和边缘设备部署。


### [40] [EDVD-LLaMA: Explainable Deepfake Video Detection via Multimodal Large Language Model Reasoning](https://arxiv.org/abs/2510.16442)
*Haoran Sun,Chen Cai,Huiping Zhuang,Kong Aik Lee,Lap-Pui Chau,Yi Wang*

Main category: cs.CV

TL;DR: 提出了可解释深度伪造视频检测任务和EDVD-LLaMA多模态大语言模型推理框架，通过时空特征提取和细粒度思维链机制，在准确检测的同时提供可追溯的推理过程和可信解释。

- Motivation: 传统深度伪造视频检测方法缺乏透明度且泛化能力不足，需要既能识别伪造内容又能提供可验证推理解释的检测器。
- Method: 使用时空细微信息标记化提取全局和局部跨帧深度伪造特征，构建细粒度多模态思维链机制，引入面部特征数据作为硬约束实现像素级时空定位。
- Result: 实验表明EDVD-LLaMA在检测精度、可解释性以及跨伪造方法和跨数据集场景处理方面表现出色，具有优秀的鲁棒性。
- Conclusion: 相比传统方法，EDVD-LLaMA提供了更可解释且优越的解决方案，代码和数据集将公开。


### [41] [RefAtomNet++: Advancing Referring Atomic Video Action Recognition using Semantic Retrieval based Multi-Trajectory Mamba](https://arxiv.org/abs/2510.16444)
*Kunyu Peng,Di Wen,Jia Fu,Jiamin Wu,Kailun Yang,Junwei Zheng,Ruiping Liu,Yufan Chen,Yuqian Fu,Danda Pani Paudel,Luc Van Gool,Rainer Stiefelhagen*

Main category: cs.CV

TL;DR: 该论文提出了RefAtomNet++框架，用于解决Referring Atomic Video Action Recognition (RAVAR)任务，通过多层级语义对齐交叉注意力和多轨迹Mamba建模，在RefAVA++数据集上实现了最先进的性能。

- Motivation: 现有的RefAtomNet模型在跨模态信息对齐和检索方面存在局限，导致在定位目标人物和预测细粒度动作时表现不佳。需要开发更有效的跨模态交互机制来提升RAVAR任务的性能。
- Method: 提出RefAtomNet++框架，采用多层级语义对齐交叉注意力机制，结合在部分关键词、场景属性和整体句子层面的多轨迹Mamba建模。通过动态选择最近视觉空间token构建扫描轨迹，实现更有效的时空token聚合。
- Result: 实验表明RefAtomNet++在RefAVA++数据集上建立了新的最先进结果，超越了包括RefAtomNet在内的多个基线模型。
- Conclusion: RefAtomNet++通过创新的多层级跨模态交互机制，显著提升了语言引导的原子级视频动作识别性能，为复杂多人场景中的交互式人类动作分析提供了有效解决方案。


### [42] [Enhancing Rotated Object Detection via Anisotropic Gaussian Bounding Box and Bhattacharyya Distance](https://arxiv.org/abs/2510.16445)
*Chien Thai,Mai Xuan Trang,Huong Ninh,Hoang Hiep Ly,Anh Son Le*

Main category: cs.CV

TL;DR: 提出了一种改进的损失函数，利用高斯边界框表示和巴氏距离来提升旋转目标检测的准确性和鲁棒性，解决了传统方法在旋转目标检测中的局限性。

- Motivation: 传统目标检测框架在处理旋转目标时表现不佳，因为它们难以捕捉方向变化。在航空影像、遥感和自动驾驶等应用中，准确检测旋转目标是一个重要挑战。
- Method: 采用高斯边界框表示和巴氏距离，提出各向异性高斯表示来解决类正方形物体的各向同性方差问题，并集成旋转不变损失函数来捕捉旋转目标的几何特性。
- Result: 在先进的深度学习旋转目标检测器中集成该损失函数后，平均精度均值指标相比现有方法有显著提升。
- Conclusion: 该方法为旋转目标检测建立了新的基准，对需要精确可靠目标定位的应用具有广泛意义。


### [43] [VIPAMIN: Visual Prompt Initialization via Embedding Selection and Subspace Expansion](https://arxiv.org/abs/2510.16446)
*Jaekyun Park,Hye Won Chung*

Main category: cs.CV

TL;DR: VIPAMIN是一种视觉提示初始化策略，通过将提示与嵌入空间中的语义信息区域对齐并注入新的表示方向，显著提升了自监督模型的适应性能。

- Motivation: 在基础模型时代，完全微调预训练网络对每个下游任务来说资源消耗巨大。现有的视觉提示调优方法在自监督骨干网络上往往无法有效专业化提示或丰富表示空间，特别是在具有挑战性的任务和数据稀缺场景中。
- Method: VIPAMIN通过两个关键步骤增强自监督模型的适应能力：(1)将提示与嵌入空间中的语义信息区域对齐；(2)在预训练子空间之外注入新的表示方向。该方法只需单次前向传播和轻量级操作。
- Result: VIPAMIN在各种任务和数据集规模下都一致地提升了性能，在视觉提示调优领域达到了新的最先进水平。
- Conclusion: VIPAMIN作为一种简单而有效的视觉提示初始化策略，显著改善了自监督模型在下游任务中的适应能力，特别是在挑战性任务和数据稀缺场景中表现突出。


### [44] [Instance-Aware Pseudo-Labeling and Class-Focused Contrastive Learning for Weakly Supervised Domain Adaptive Segmentation of Electron Microscopy](https://arxiv.org/abs/2510.16450)
*Shan Xiong,Jiabao Chen,Ye Wang,Jialin Peng*

Main category: cs.CV

TL;DR: 提出了一种弱监督域自适应方法，利用稀疏点标注进行线粒体分割，通过多任务学习和跨教学机制提升性能

- Motivation: 解决电子显微镜图像中线粒体实例分割的标注效率问题，传统无监督域自适应方法在实际应用中性能较低
- Method: 多任务学习框架结合分割和中心检测任务，使用跨教学机制和类聚焦跨域对比学习，提出实例感知伪标签选择策略
- Result: 在挑战性数据集上超越现有UDA和WDA方法，显著缩小与监督上界的性能差距
- Conclusion: 该方法在弱监督和无监督设置下均取得显著改进，为生物医学图像分析提供了高效的解决方案


### [45] [NavQ: Learning a Q-Model for Foresighted Vision-and-Language Navigation](https://arxiv.org/abs/2510.16457)
*Peiran Xu,Xicheng Gong,Yadong MU*

Main category: cs.CV

TL;DR: 提出一种具有前瞻性的视觉语言导航方法，通过Q学习从大规模无标签轨迹数据中学习场景布局和物体关系知识，结合未来信息进行A*式搜索。

- Motivation: 现有方法主要基于历史信息决策，忽略了行动的未来影响和长期结果，需要开发具有前瞻性的导航智能体。
- Method: 使用Q学习训练Q模型生成Q特征描述潜在未来信息，通过跨模态未来编码器将任务无关的Q特征与导航指令结合，产生反映未来前景的行动分数，结合历史分数进行A*式搜索。
- Result: 在广泛使用的目标导向VLN数据集上进行的广泛实验验证了所提方法的有效性。
- Conclusion: 该方法通过整合未来信息显著提升了目标导向视觉语言导航的性能。


### [46] [HGC-Avatar: Hierarchical Gaussian Compression for Streamable Dynamic 3D Avatars](https://arxiv.org/abs/2510.16463)
*Haocheng Tang,Ruoke Yan,Xinhui Yin,Qi Zhang,Xinfeng Zhang,Siwei Ma,Wen Gao,Chuanmin Jia*

Main category: cs.CV

TL;DR: HGC-Avatar是一个用于动态3D虚拟人高效传输和高质量渲染的分层高斯压缩框架，通过结构层和运动层解耦表示，支持分层压缩和渐进解码。

- Motivation: 现有的基于3D高斯泼溅的压缩方法缺乏人体先验知识，导致解码端的比特率效率和重建质量不理想，阻碍了其在可流式3D虚拟人系统中的应用。
- Method: 将高斯表示解耦为结构层（通过StyleUNet生成器将姿态映射到高斯）和运动层（利用SMPL-X模型紧凑表示时序姿态变化），采用分层设计和面部注意力机制。
- Result: 实验结果表明HGC-Avatar为快速3D虚拟人渲染提供了可流式解决方案，在视觉质量和压缩效率方面显著优于现有方法。
- Conclusion: HGC-Avatar通过分层高斯压缩框架成功解决了动态虚拟人传输中的压缩效率和质量问题，支持从视频序列或文本等多种姿态输入进行可控渲染。


### [47] [PRISMM-Bench: A Benchmark of Peer-Review Grounded Multimodal Inconsistencies](https://arxiv.org/abs/2510.16505)
*Lukas Selch,Yufang Hou,M. Jehanzeb Mirza,Sivan Doveh,James Glass,Rogerio Feris,Wei Lin*

Main category: cs.CV

TL;DR: PRISMM-Bench是首个基于真实科学论文中审稿人标记的不一致性的多模态基准测试，包含262个来自242篇论文的不一致案例，评估模型在跨模态不一致性检测、修正和推理方面的能力。

- Motivation: 现有基准测试要么孤立单一模态，要么依赖合成错误，无法捕捉真实世界科学论文中跨文本、图表、方程的多模态不一致性复杂性。
- Method: 通过多阶段流程（审稿挖掘、LLM辅助过滤、人工验证）构建基准，设计三个任务：不一致性识别、修正和配对匹配，并引入结构化JSON答案表示以减少语言偏见。
- Result: 对21个领先LMM的基准测试显示性能极低（26.1-54.2%），包括大型开源模型和专有模型。
- Conclusion: 多模态科学推理具有挑战性，需要开发更可靠的科学助手。


### [48] [OOS-DSD: Improving Out-of-stock Detection in Retail Images using Auxiliary Tasks](https://arxiv.org/abs/2510.16508)
*Franko Šikić,Sven Lončarić*

Main category: cs.CV

TL;DR: 提出OOS-DSD方法，通过辅助学习提升缺货检测性能，在YOLOv8基础上增加产品分割和深度估计分支，使用伪标签深度数据进行训练，性能超越现有最佳方法1.8% mAP。

- Motivation: 缺货检测是零售验证的重要过程，现有方法性能有待提升，希望通过多任务学习利用深度信息来改进检测效果。
- Method: 基于YOLOv8架构，增加卷积分支同时进行缺货检测、产品分割和场景深度估计，深度分支使用Depth Anything V2生成的伪标签训练，并提出了深度归一化方法。
- Result: 实验结果表明，该方法在mAP指标上超越了当前最佳方法1.8%，消融研究证实辅助学习提升3.7% mAP，深度归一化提升4.2% mAP。
- Conclusion: OOS-DSD通过辅助学习和深度归一化有效提升了缺货检测性能，证明了多任务学习和深度信息在零售场景中的价值。


### [49] [Image Categorization and Search via a GAT Autoencoder and Representative Models](https://arxiv.org/abs/2510.16514)
*Duygu Sap,Martin Lotz,Connor Mattinson*

Main category: cs.CV

TL;DR: 提出了一种基于图注意力网络(GAT)自编码器的图像分类和检索方法，通过构建图像和类别的代表性模型来执行分类和检索任务。

- Motivation: 开发一种代表性中心的图像分类和检索方法，利用图结构捕捉图像间的相似性关系，通过GAT突出重要特征和关系，构建上下文感知的潜在表示。
- Method: 使用图结构表示图像及其代表，节点代表图像或其代表，边捕捉相似关系。采用GAT自编码器构建上下文感知的潜在表示，从这些嵌入中获得类别代表，通过比较查询图像代表与类别代表进行分类，并在识别类别内检索最相似图像。
- Result: 通过GAT自编码器和标准基于特征技术的实验验证了该代表性中心方法的有效性。
- Conclusion: 基于GAT自编码器的代表性中心方法在图像分类和检索任务中表现出良好效果，能够有效捕捉图像的关键特征和邻域关系。


### [50] [Enhancing Compositional Reasoning in CLIP via Reconstruction and Alignment of Text Descriptions](https://arxiv.org/abs/2510.16540)
*Jihoon Kwon,Kyle Min,Jy-yong Sohn*

Main category: cs.CV

TL;DR: READ是一种微调方法，通过添加重构和对齐两个辅助目标来增强视觉语言模型的组合推理能力，在多个基准测试中达到最先进性能。

- Motivation: 现有的视觉语言模型在组合推理方面表现不佳，主要是因为文本编码器倾向于关注单个词汇而非它们之间的关系，这种局限性被对比训练进一步强化。
- Method: READ方法在对比学习基础上添加两个辅助目标：(1) 基于原始标题嵌入重构替代标题的token级重构目标；(2) 在嵌入空间中对齐改写句子的句子级对齐目标。
- Result: READ-CLIP在五个主要组合推理基准测试中达到最先进性能，比最强的传统微调基线提升高达4.1%。应用READ到现有CLIP变体也能提升这些基准测试的性能。
- Conclusion: 重构和对齐目标提供互补优势：重构鼓励编码器捕捉标题中词汇间的关系，而对齐确保不同措辞的改写句子具有一致的表示。


### [51] [Watch Where You Move: Region-aware Dynamic Aggregation and Excitation for Gait Recognition](https://arxiv.org/abs/2510.16541)
*Binyuan Huang,Yongdong Luo,Xianda Guo,Xiawu Zheng,Zheng Zhu,Jiahui Pan,Chengju Zhou*

Main category: cs.CV

TL;DR: GaitRDAE框架通过动态搜索运动区域和自适应时间尺度分配，解决了现有步态识别方法在动态变化区域建模上的不足。

- Motivation: 现有步态识别方法使用预定义区域和固定时间尺度，难以建模随时间动态变化的运动区域和适应其特定模式。
- Method: 提出区域感知动态聚合与激励框架(GaitRDAE)，包含RDA模块动态搜索各区域最优时间感受野，RDE模块强调稳定行为模式区域学习并抑制静态区域注意力。
- Result: 在多个基准数据集上实现了最先进的性能。
- Conclusion: GaitRDAE通过动态区域感知机制有效提升了步态识别的准确性。


### [52] [Fit for Purpose? Deepfake Detection in the Real World](https://arxiv.org/abs/2510.16556)
*Guangyu Lin,Li Lin,Christina P. Walker,Daniel S. Schiff,Shu Hu*

Main category: cs.CV

TL;DR: 本文提出了首个基于真实世界政治深度伪造事件的系统基准测试，发现现有检测器在真实政治深度伪造内容上泛化能力不足，呼吁开发更具政治情境化的检测框架。

- Motivation: AI生成内容的快速扩散增加了虚假信息风险，特别是政治深度伪造会扭曲真相并破坏对政治机构的信任。现有检测模型大多在实验室合成数据集上训练，难以泛化到社交媒体上传播的真实政治深度伪造内容。
- Method: 基于政治深度伪造事件数据库构建系统基准，对学术界、政府和工业界的最先进深度伪造检测器进行系统评估。
- Result: 学术界和政府检测器表现相对较差，付费检测工具性能相对较高但所有检测器都难以有效泛化到真实政治深度伪造内容，且易受简单操作攻击，特别是在视频领域。
- Conclusion: 需要开发更具政治情境化的深度伪造检测框架，以在真实世界环境中更好地保护公众。


### [53] [SHIELD: Suppressing Hallucinations In LVLM Encoders via Bias and Vulnerability Defense](https://arxiv.org/abs/2510.16596)
*Yiyang Huang,Liang Shi,Yitian Zhang,Yi Xu,Yun Fu*

Main category: cs.CV

TL;DR: SHIELD是一个无需训练的框架，通过重新加权视觉标记、引入噪声衍生标记和应用对抗攻击来缓解大型视觉语言模型中的物体幻觉问题。

- Motivation: 大型视觉语言模型在跨模态任务中表现出色，但物体幻觉问题（模型产生看似合理但不准确的物体描述）仍然是一个重大挑战。本文首次将LVLM幻觉追溯到视觉编码器，并识别出三个关键问题：统计偏差、固有偏差和脆弱性。
- Method: 提出SHIELD框架，采用三种策略：重新加权视觉标记以减少统计偏差，引入噪声衍生标记以对抗固有偏差，应用对抗攻击和对比解码来解决脆弱性问题。
- Result: 实验表明SHIELD能有效缓解各种基准测试和LVLM家族中的物体幻觉问题，并在通用LVLM基准上表现出色，显示出其广泛适用性。
- Conclusion: SHIELD是一个有效的训练免费框架，能够显著减少LVLM中的物体幻觉，同时保持良好的通用性能。


### [54] [VisionSelector: End-to-End Learnable Visual Token Compression for Efficient Multimodal LLMs](https://arxiv.org/abs/2510.16598)
*Jiaying Zhu,Yurui Zhu,Xin Lu,Wenrui Yan,Dong Li,Kunlin Liu,Xueyang Fu,Zheng-Jun Zha*

Main category: cs.CV

TL;DR: VisionSelector是一个轻量级可插拔框架，通过端到端可学习的决策过程解决MLLMs中视觉令牌压缩问题，使用解耦的评分器和可微分Top-K机制，在保持性能的同时显著提升计算效率。

- Motivation: 多模态大语言模型在处理高分辨率图像或多图像输入时面临大量视觉令牌带来的计算和内存瓶颈，现有令牌压缩技术受限于启发式规则，可能丢弃关键信息或存在注意力偏差。
- Method: 提出VisionSelector框架，包含解耦的评分器模块，采用可微分Top-K机制和课程退火策略，实现端到端可学习的令牌选择，支持任意压缩率。
- Result: 仅需12.85M可训练参数，在MME基准上保持100%准确率（30%保留预算），在10%保留预算下比先前方法提升12.14%，预填充速度翻倍。
- Conclusion: VisionSelector提供了一种高效、自适应的令牌压缩解决方案，在不同压缩预算下均表现出优越性能，具有良好的泛化能力。


### [55] [A Deep Learning Framework for Real-Time Image Processing in Medical Diagnostics: Enhancing Accuracy and Speed in Clinical Applications](https://arxiv.org/abs/2510.16611)
*Melika Filvantorkaman,Maral Filvan Torkaman*

Main category: cs.CV

TL;DR: 提出一种用于实时医学图像分析的深度学习框架，集成U-Net、EfficientNet和Transformer等先进神经网络架构，通过模型剪枝、量化和GPU加速实现高效部署，在多个医学影像模态上达到SOTA性能。

- Motivation: 传统医学图像处理技术缺乏实时临床使用所需的精度、鲁棒性和速度，且高分辨率放射学数据解读耗时且存在临床医生间差异，需要更高效的解决方案。
- Method: 集成U-Net、EfficientNet和Transformer等神经网络架构，结合模型剪枝、量化和GPU加速等实时优化策略，支持在边缘设备、本地服务器和云基础设施上的灵活部署。
- Result: 在公开基准数据集上实现分类准确率超过92%，分割Dice分数超过91%，推理时间低于80毫秒，并通过Grad-CAM和分割叠加等可视化工具增强临床可解释性。
- Conclusion: 该框架能显著加速诊断工作流程，减少临床医生工作量，在时间关键的医疗环境中支持可信赖的AI集成。


### [56] [Self-Supervised Learning to Fly using Efficient Semantic Segmentation and Metric Depth Estimation for Low-Cost Autonomous UAVs](https://arxiv.org/abs/2510.16624)
*Sebastian Mocanu,Emil Slusanschi,Marius Leordeanu*

Main category: cs.CV

TL;DR: 提出一种仅使用视觉的小型无人机自主飞行系统，结合语义分割和单目深度估计，在室内环境中实现避障、场景探索和自主安全着陆，无需GPS或昂贵传感器。

- Motivation: 解决资源受限平台上视觉导航的挑战，特别是度量深度估计和计算效率问题，使无人机能在无GPS的室内环境中自主飞行。
- Method: 使用知识蒸馏框架，SVM教师生成训练数据训练轻量级U-Net学生网络进行实时语义分割；开发自适应尺度因子算法将非度量单目深度预测转换为准确度量距离；通过端到端学习训练紧凑神经网络学习完整飞行策略。
- Result: 在5x4米实验室环境中测试，平均距离误差14.4厘米；30次真实环境飞行测试和100次数字孪生环境测试显示，结合分割和深度的方法增加了监视距离，减少了任务时间，保持100%成功率；端到端学习实现87.5%自主任务成功率。
- Conclusion: 该工作推进了结构化环境中实用的基于视觉的无人机导航，展示了在资源受限平台上部署的解决方案，解决了度量深度估计和计算效率挑战。


### [57] [MultiVerse: A Multi-Turn Conversation Benchmark for Evaluating Large Vision and Language Models](https://arxiv.org/abs/2510.16641)
*Young-Jun Lee,Byung-Kwan Lee,Jianshu Zhang,Yechan Hwang,Byungsoo Ko,Han-Gyu Kim,Dongyu Yao,Xuankun Rong,Eojin Joo,Seung-Ho Han,Bowon Ko,Ho-Jin Choi*

Main category: cs.CV

TL;DR: MultiVerse是一个新颖的多轮对话基准测试，包含647个对话，涵盖12个流行VLM评估基准的484个任务，使用GPT-4o作为自动评估器，评估18个VLM模型在37个关键方面的表现。

- Motivation: 现有多轮对话数据集仅部分覆盖用户遇到的各种对话场景，需要更全面的基准来评估视觉语言模型在复杂多轮对话中的能力。
- Method: 从12个流行VLM评估基准中提取647个对话，提出基于检查表的评估方法，使用GPT-4o作为自动评估器，测量37个关键方面的性能。
- Result: 评估18个VLM模型发现，即使最强模型（如GPT-4o）在复杂多轮对话中仅达到50%成功率，提供完整对话上下文显著提升较小或较弱模型的性能。
- Conclusion: MultiVerse是评估VLM多轮交互能力的全面基准，揭示了当前模型在复杂对话中的局限性，并强调了上下文学习的重要性。


### [58] [Structured Interfaces for Automated Reasoning with 3D Scene Graphs](https://arxiv.org/abs/2510.16643)
*Aaron Ray,Jacob Arkin,Harel Biggie,Chuchu Fan,Luca Carlone,Nicholas Roy*

Main category: cs.CV

TL;DR: 使用检索增强生成方法，通过图数据库和Cypher查询语言接口让LLM能够高效检索3D场景图中的相关数据，解决大规模3D场景图的语言接地问题。

- Motivation: 现有方法将3D场景图序列化为文本放入LLM上下文窗口，但这种方法无法扩展到大型或丰富的3D场景图。需要一种更高效的方法来连接自然语言与机器人的世界表示。
- Method: 提出使用检索增强生成方法，将3D场景图编码到图数据库中，为LLM提供Cypher查询语言接口作为工具，使其能够检索与任务相关的数据。
- Result: 在指令跟随和场景问答任务上的评估显示，使用Cypher接口的方法在本地和云端模型上都能显著扩展到大型、丰富的图结构，性能大幅提升，同时大幅减少场景图内容的token数量。
- Conclusion: Cypher作为3D场景图的接口，在接地语言任务中表现出更好的可扩展性和性能，同时有效减少了计算开销。


### [59] [Universal and Transferable Attacks on Pathology Foundation Models](https://arxiv.org/abs/2510.16660)
*Yuntian Wang,Xilin Yang,Che-Yung Shen,Nir Pillar,Aydogan Ozcan*

Main category: cs.CV

TL;DR: 提出了针对病理学基础模型的通用可迁移对抗扰动(UTAP)，这是一种固定的弱噪声模式，能够系统性地破坏多个病理学基础模型的特征表示能力，导致下游任务性能下降。

- Motivation: 揭示病理学基础模型的关键脆弱性，为模型鲁棒性评估建立高标准基准，推动防御机制发展，确保AI在病理学中的安全可靠部署。
- Method: 使用深度学习优化生成固定的弱噪声模式UTAP，该扰动具有通用性和可迁移性，能够应用于不同视野范围的数据集，并成功影响未见过的黑盒病理学基础模型。
- Result: UTAP在多个最先进的病理学基础模型和数据集上进行了系统评估，通过视觉不可察觉的固定噪声模式显著降低了模型性能。
- Conclusion: UTAP构成了对各种新兴病理学基础模型及其应用的广泛威胁，强调了推进防御机制和对抗训练的必要性，为模型鲁棒性评估提供了关键基准。


### [60] [HYDRA: HYbrid knowledge Distillation and spectral Reconstruction Algorithm for high channel hyperspectral camera applications](https://arxiv.org/abs/2510.16664)
*Christopher Thirgood,Oscar Mendez,Erin Ling,Jon Storey,Simon Hadfield*

Main category: cs.CV

TL;DR: 提出HYDRA方法，通过师生知识蒸馏架构实现从三通道彩色图像到高光谱图像的高质量重建，在精度和推理速度上都达到SOTA水平

- Motivation: 现有多尺度注意力方法只能处理稀疏光谱，而现代高光谱传感器包含数百个通道，需要更通用的光谱重建方法
- Method: 使用教师模型封装潜在高光谱数据，学生模型学习从自然图像到教师编码域的映射，结合新颖的训练方法
- Result: 在所有指标上达到SOTA性能，精度提升18%，在不同通道深度下推理速度均优于当前SOTA模型
- Conclusion: HYDRA方法成功解决了先前光谱重建模型的关键限制，实现了高质量的光谱重建


### [61] [Pursuing Minimal Sufficiency in Spatial Reasoning](https://arxiv.org/abs/2510.16688)
*Yejie Guo,Yunzhong Hou,Wufei Ma,Meng Tang,Ming-Hsuan Yang*

Main category: cs.CV

TL;DR: MSSR是一个双智能体框架，通过构建最小充分信息集来解决VLMs在3D空间推理中的瓶颈问题，显著提升了准确性和可解释性。

- Motivation: 解决VLMs在3D空间推理中的两个基本瓶颈：基于2D预训练导致的3D理解能力不足，以及冗余3D信息引发的推理失败。
- Method: 提出双智能体框架：感知智能体使用感知工具箱程序化查询3D场景提取充分信息（包括新颖的SOG模块），推理智能体迭代精炼信息追求最小化，通过闭环修剪冗余和补充缺失信息直到构建最小充分集。
- Result: 在两个具有挑战性的基准测试中显著提高了准确性，达到了最先进的性能水平，并产生了可解释的推理路径。
- Conclusion: 通过明确追求充分性和最小化，该方法有效解决了3D空间推理问题，为未来模型提供了高质量训练数据来源。


### [62] [SDPA++: A General Framework for Self-Supervised Denoising with Patch Aggregation](https://arxiv.org/abs/2510.16702)
*Huy Minh Nhat Nguyen,Triet Hoang Minh Dao,Chau Vinh Hoang Truong,Cuong Tuan Nguyen*

Main category: cs.CV

TL;DR: 提出SDPA++框架，仅使用噪声OCT图像进行自监督去噪，通过自融合生成伪真值图像，再训练集成去噪模型提升图像质量。

- Motivation: OCT图像分析对眼科疾病诊断至关重要，但获取配对的干净和噪声图像数据集存在困难，因为固有的散斑噪声和临床成像环境的实际限制。
- Method: 自监督去噪框架，仅使用噪声OCT图像，通过自融合生成伪真值图像，然后使用基于块的策略训练集成去噪模型。
- Result: 在IEEE SPS VIP Cup真实世界数据集上验证，通过CNR、MSR、TP和EP等指标显示性能提升，该数据集仅包含真实噪声OCT图像而无干净参考。
- Conclusion: 该方法在临床实践中具有改善图像质量和诊断结果的潜力，特别是在缺乏干净参考图像的情况下。


### [63] [Connecting Domains and Contrasting Samples: A Ladder for Domain Generalization](https://arxiv.org/abs/2510.16704)
*Tianxin Wei,Yifan Chen,Xinrui He,Wenxuan Bao,Jingrui He*

Main category: cs.CV

TL;DR: 提出了一种新的域连接对比学习（DCCL）方法来解决域泛化问题，通过增强跨域的概念连接性来提高模型在未见目标域上的泛化性能。

- Motivation: 在域泛化（DG）场景中，直接应用对比学习（CL）会降低性能，因为缺乏类内连接性。研究发现CL理论中的类内连接性不足是导致这一问题的原因。
- Method: 提出了DCCL方法：在数据层面使用更激进的数据增强和跨域正样本；在模型层面提出模型锚定技术，利用预训练表示中的类内连接性，并结合生成变换损失。
- Result: 在五个标准DG基准测试上的实验表明，DCCL在无需域监督的情况下优于现有最先进方法。
- Conclusion: DCCL通过增强跨域概念连接性，有效解决了域泛化中对比学习性能下降的问题，获得了更好的泛化表示。


### [64] [HumanCM: One Step Human Motion Prediction](https://arxiv.org/abs/2510.16709)
*Liu Haojie,Gao Suixiang*

Main category: cs.CV

TL;DR: HumanCM是一个基于一致性模型的一步式人体运动预测框架，通过单步生成实现高效预测，性能媲美扩散模型但推理速度提升两个数量级。

- Motivation: 现有扩散模型需要多步去噪过程，导致推理效率低下。本文旨在开发一种高效的单步生成方法，减少推理步骤同时保持预测质量。
- Method: 采用基于Transformer的时空架构，结合时间嵌入来建模长程依赖关系并保持运动连贯性，学习噪声与干净运动状态之间的自一致映射。
- Result: 在Human3.6M和HumanEva-I数据集上的实验表明，HumanCM实现了与最先进扩散模型相当或更优的精度，同时将推理步骤减少了两个数量级。
- Conclusion: HumanCM证明了通过一致性模型实现高效单步人体运动预测的可行性，在保持高质量预测的同时显著提升了推理效率。


### [65] [Eliciting Grounded Chain-of-Thought Reasoning in 3D Scenes](https://arxiv.org/abs/2510.16714)
*Xiongkun Linghu,Jiangyong Huang,Ziyu Zhu,Baoxiong Jia,Siyuan Huang*

Main category: cs.CV

TL;DR: 提出了SCENECOT框架，首次将思维链推理应用于3D场景理解，通过解耦复杂推理任务并构建视觉线索，实现了基于多模态专家模块的渐进式推理。

- Motivation: 现有3D大语言模型在基于场景的问答方面表现不佳，主要原因是缺乏对人类场景-对象关联推理机制的研究。
- Method: 提出了基于3D场景的思维链推理方法(SCENECOT)，将复杂任务分解为简单问题，并构建了包含18.5万高质量实例的大规模数据集SCENECOT-185K。
- Result: 在多个复杂3D场景推理基准测试中表现出色，实现了高水平的问答一致性。
- Conclusion: 这是首次成功将CoT推理应用于3D场景理解，展示了逐步推理的潜力，并有望扩展到更广泛的3D场景理解场景。


### [66] [Vision-Centric 4D Occupancy Forecasting and Planning via Implicit Residual World Models](https://arxiv.org/abs/2510.16729)
*Jianbiao Mei,Yu Yang,Xuemeng Yang,Licheng Wen,Jiajun Lv,Botian Shi,Yong Liu*

Main category: cs.CV

TL;DR: Error

- Motivation: Error
- Method: Error
- Result: Error
- Conclusion: Error


### [67] [UKANFormer: Noise-Robust Semantic Segmentation for Coral Reef Mapping via a Kolmogorov-Arnold Network-Transformer Hybrid](https://arxiv.org/abs/2510.16730)
*Tianyang Dou,Ming Li,Jiangying Qin,Xuan Liao,Jiageng Zhong,Armin Gruen,Mengyi Deng*

Main category: cs.CV

TL;DR: UKANFormer是一种新颖的语义分割模型，利用来自Allen Coral Atlas的噪声监督实现高精度珊瑚礁制图，通过架构设计缓解标签噪声问题。

- Motivation: 全球珊瑚礁产品如Allen Coral Atlas虽然覆盖范围广，但其预测在空间精度和语义一致性方面存在局限，特别是在需要精细边界划分的区域。
- Method: 基于UKAN架构，在解码器中引入全局-局部Transformer(GL-Trans)模块，能够同时提取全局语义结构和局部边界细节。
- Result: 在实验中，UKANFormer实现了珊瑚类IoU 67.00%和像素精度83.98%，在相同噪声标签设置下优于传统基线方法。
- Conclusion: 模型架构设计可以缓解标签噪声，支持在非完美监督下进行可扩展制图，为生态监测提供了基础，特别是在可靠标签稀缺的情况下。


### [68] [A Comprehensive Survey on World Models for Embodied AI](https://arxiv.org/abs/2510.16732)
*Xinqing Li,Xin He,Le Zhang,Yun Liu*

Main category: cs.CV

TL;DR: 该论文提出了一个用于具身AI中世界模型的统一框架，包括问题形式化、学习目标和三轴分类法，系统化数据资源和评估指标，并进行定量比较和挑战分析。

- Motivation: 具身AI需要能够感知、行动并预测行动如何重塑未来世界状态的智能体。世界模型作为内部模拟器，能够捕捉环境动态，支持感知、预测和决策。
- Method: 提出了三轴分类法：(1)功能性：决策耦合vs通用目的；(2)时间建模：序列模拟推理vs全局差异预测；(3)空间表示：全局潜在向量、令牌特征序列、空间潜在网格和分解渲染表示。
- Result: 系统化整理了机器人学、自动驾驶和通用视频设置中的数据资源和评估指标，包括像素预测质量、状态级理解和任务性能，并对最先进模型进行了定量比较。
- Conclusion: 总结了关键开放挑战：统一数据集的稀缺性、需要评估物理一致性而非像素保真度的指标、模型性能与实时控制计算效率的权衡，以及实现长期时间一致性同时减轻误差累积的核心建模难点。


### [69] [Visual Autoregressive Models Beat Diffusion Models on Inference Time Scaling](https://arxiv.org/abs/2510.16751)
*Erik Riise,Mehmet Onurcan Kaya,Dim P. Papadopoulos*

Main category: cs.CV

TL;DR: 研究表明，离散的自回归视觉模型比连续扩散模型更适合推理时搜索优化，束搜索能让2B参数的自回归模型在文本到图像生成任务中超越12B参数的扩散模型。

- Motivation: 虽然推理时搜索在大型语言模型中取得了革命性进展，但在图像生成领域应用类似策略却面临困难，特别是连续扩散模型中的搜索策略效果有限。
- Method: 利用离散自回归视觉模型的序列特性，应用束搜索进行图像生成，通过早期剪枝和计算重用来优化推理过程。
- Result: 束搜索显著提升了文本到图像生成质量，2B参数的自回归模型在多个基准测试中超越了12B参数的扩散模型。
- Conclusion: 模型架构（而非仅规模）对于视觉生成中的推理时优化至关重要，离散token空间为有效搜索提供了关键优势。


### [70] [Prominence-Aware Artifact Detection and Dataset for Image Super-Resolution](https://arxiv.org/abs/2510.16752)
*Ivan Molodetskikh,Kirill Malyshev,Mark Mirgaleev,Nikita Zagainov,Evgeney Bogatyrev,Dmitriy Vatolin*

Main category: cs.CV

TL;DR: 提出了一个包含1302个SR方法生成图像中伪影的数据集，每个伪影都有人工标注的显著度分数，并训练了一个轻量级回归器来生成空间显著度热图。

- Motivation: 随着生成式图像超分辨率模型能力的增强，它们产生伪影的趋势也在增加。这些伪影对人类观察者的影响程度不同，应该根据其显著度而非统一视为二进制缺陷来表征。
- Method: 构建了一个包含11种当代图像SR方法产生的1302个伪影示例的数据集，每个伪影都配有众包显著度评分。基于此数据集训练了一个轻量级回归器来生成空间显著度热图。
- Result: 训练的回归器在检测显著伪影方面优于现有方法，能够生成空间显著度热图来可视化伪影的突出程度。
- Conclusion: 该研究为SR伪影的显著度感知评估和缓解提供了数据集和工具，强调了根据伪影对人类观察者的显著度来表征的重要性。


### [71] [WaMaIR: Image Restoration via Multiscale Wavelet Convolutions and Mamba-based Channel Modeling with Texture Enhancement](https://arxiv.org/abs/2510.16765)
*Shengyu Zhu,Fan,Fuxuan Zhang*

Main category: cs.CV

TL;DR: 提出WaMaIR框架，通过全局多尺度小波变换卷积扩大感受野，结合Mamba通道感知模块捕获长距离依赖关系，并使用多尺度纹理增强损失函数，显著提升图像恢复中的纹理细节重建效果。

- Motivation: 现有CNN方法在图像恢复中面临感受野小和缺乏通道特征建模的问题，导致难以充分恢复精细纹理细节。
- Method: 1. 全局多尺度小波变换卷积(GMWTConvs)扩大感受野；2. Mamba通道感知模块(MCAM)捕获通道间长距离依赖；3. 多尺度纹理增强损失(MTELoss)指导纹理结构保持。
- Result: 大量实验证实WaMaIR优于现有最先进方法，在图像恢复效果和计算效率方面均表现优异。
- Conclusion: WaMaIR通过扩大感受野和增强通道特征建模，有效解决了图像恢复中的纹理细节重建问题，实现了更好的恢复效果和计算性能。


### [72] [Region in Context: Text-condition Image editing with Human-like semantic reasoning](https://arxiv.org/abs/2510.16772)
*Thuy Phuong Vu,Dinh-Cuong Hoang,Minhhuy Le,Phan Xuan Tan*

Main category: cs.CV

TL;DR: 提出了Region in Context框架，通过多层级语义对齐实现文本条件图像编辑，确保局部编辑与全局场景的一致性。

- Motivation: 现有方法在处理图像区域时往往孤立考虑，仅依赖局部线索而不考虑各部分如何贡献于整体视觉和语义构成，导致编辑不一致、过渡不自然或图像连贯性丧失。
- Method: 引入双层级引导机制：区域在完整图像上下文中表示并与详细区域级描述对齐，同时整个图像与大型视觉语言模型生成的全面场景级描述匹配，作为明确的语言参考指导局部修改和全局结构。
- Result: 实验表明该方法能产生更连贯且与指令对齐的结果。
- Conclusion: Region in Context框架通过多层级语义对齐，使每个区域理解其在全局图像上下文中的作用，实现了精确和协调的图像编辑。


### [73] [EMRRG: Efficient Fine-Tuning Pre-trained X-ray Mamba Networks for Radiology Report Generation](https://arxiv.org/abs/2510.16776)
*Mingzheng Zhang,Jinfeng Gao,Dan Xu,Jiangrui Yu,Yuhan Qiao,Lan Chen,Jin Tang,Xiao Wang*

Main category: cs.CV

TL;DR: 提出了EMRRG框架，利用参数高效方法微调预训练的Mamba网络进行X射线医疗报告生成，在基准数据集上取得优异性能。

- Motivation: 现有医疗报告生成模型主要依赖大语言模型，对预训练视觉基础模型和先进微调技术探索有限，且忽视了非Transformer架构的潜力。
- Method: 将X射线图像分块、标记化，使用SSM视觉骨干提取特征，采用Partial LoRA进行参数高效微调，结合混合解码器LLM生成报告。
- Result: 在三个广泛使用的基准数据集上验证了所提策略的有效性，取得了强劲结果。
- Conclusion: EMRRG框架展示了在医疗报告生成任务中应用Mamba网络和参数高效微调方法的潜力。


### [74] [GS2POSE: Marry Gaussian Splatting to 6D Object Pose Estimation](https://arxiv.org/abs/2510.16777)
*Junbo Li,Weimin Yuan,Yinuo Wang,Yue Zeng,Shihao Shu,Cai Meng,Xiangzhi Bai*

Main category: cs.CV

TL;DR: GS2POSE是一种基于3D高斯散射和束调整原理的6D物体姿态估计新方法，通过可微渲染管道迭代优化姿态，在纹理缺失和光照变化场景下表现优异。

- Motivation: 传统6D姿态估计方法依赖2D-3D特征对应关系，在纹理缺失物体和变化光照条件下表现不佳，需要更鲁棒的解决方案。
- Method: 结合束调整原理和Lie代数，开发基于3D高斯散射的姿态可微渲染管道，通过比较输入图像与渲染图像迭代优化姿态，并更新3DGS模型中的颜色参数以适应光照变化。
- Result: 在T-LESS、LineMod-Occlusion和LineMod数据集上分别实现1.4%、2.8%和2.5%的精度提升。
- Conclusion: GS2POSE通过可微渲染和光照自适应机制，有效解决了纹理缺失和光照变化下的6D姿态估计问题，性能优于现有方法。


### [75] [Xiaoice: Training-Free Video Understanding via Self-Supervised Spatio-Temporal Clustering of Semantic Features](https://arxiv.org/abs/2510.16781)
*Shihao Ji,Zihui Song*

Main category: cs.CV

TL;DR: 提出了一种无需训练的视频理解框架，通过结合预训练视觉语言模型的语义先验和传统机器学习算法，将视频理解重新定义为高维语义特征空间中的自监督时空聚类问题。

- Motivation: 现有视频理解模型依赖大量标注数据和任务特定训练，成本高且扩展性差。本文旨在开发无需端到端训练的零样本视频理解方法。
- Method: 使用预训练VLM的冻结视觉编码器将视频转换为语义特征轨迹，然后使用核时间分割(KTS)算法将连续特征流分割为语义连贯的事件片段，最后通过无监督密度聚类识别重复的宏观场景和主题。
- Result: 该方法能够自动生成结构化的多模态视频内容摘要，从每个发现的聚类中选择代表性关键帧，并利用VLM的生成能力进行文本描述。
- Conclusion: 该框架为零样本、自动化的视频内容结构分析提供了一条有效、可解释且模型无关的途径。


### [76] [Segmentation as A Plug-and-Play Capability for Frozen Multimodal LLMs](https://arxiv.org/abs/2510.16785)
*Jiazhen Liu,Long Chen*

Main category: cs.CV

TL;DR: LENS是一种新颖的即插即用方法，通过添加轻量级可训练头部到冻结的多模态大语言模型，利用注意力图中的空间线索提取关键点，实现像素级分割，同时完全保留模型的泛化能力。

- Motivation: 现有方法需要微调模型以产生与掩码解码器兼容的特定输出，这会改变模型的输出空间并损害其内在泛化能力，违背了构建统一模型的目标。
- Method: 在完全冻结的MLLM上附加轻量级可训练头部，通过精炼注意力图中嵌入的空间线索来提取关键点，并将其描述为与掩码解码器直接兼容的点级特征。
- Result: LENS实现了与基于重新训练方法相当或更优的分割性能，同时完全保留了MLLM的泛化能力，而微调方法会显著降低这种能力。
- Conclusion: LENS的可附加设计为扩展MLLM建立了一个高效且强大的范式，为构建真正多才多艺的统一模型铺平了道路。


### [77] [Unsupervised Monocular Road Segmentation for Autonomous Driving via Scene Geometry](https://arxiv.org/abs/2510.16790)
*Sara Hatami Rostami,Behrooz Nasihatkon*

Main category: cs.CV

TL;DR: 提出了一种完全无监督的二元道路分割方法，利用场景几何和时间线索区分道路与非道路区域，无需人工标注数据。

- Motivation: 消除对昂贵人工标注数据集的依赖，为自动驾驶提供可扩展的无监督道路分割方案。
- Method: 首先基于几何先验生成弱标签（地平线以上为非道路，车辆前方四边形为道路），然后通过跨帧跟踪局部特征点并利用互信息最大化来增强时间一致性。
- Result: 在Cityscapes数据集上实现了0.82的交并比(IoU)，表现出高精度和简单设计。
- Conclusion: 结合几何约束和时间一致性为自动驾驶中的可扩展无监督道路分割展示了巨大潜力。


### [78] [Personalized Image Filter: Mastering Your Photographic Style](https://arxiv.org/abs/2510.16791)
*Chengxuan Zhu,Shuchen Weng,Jiacong Fang,Peixuan Zhang,Si Li,Chao Xu,Boxin Shi*

Main category: cs.CV

TL;DR: 提出个性化图像滤镜(PIF)，基于预训练扩散模型和文本反演技术，能够从参考图像中学习摄影风格概念并有效迁移到内容图像上。

- Motivation: 摄影风格作为摄影概念的组合，是著名摄影师魅力的来源。但现有方法要么无法从参考图像中学习有意义的摄影概念，要么无法保持内容图像的原始内容。
- Method: 基于预训练文本到图像扩散模型，使用文本反演技术优化摄影概念的提示词，学习参考图像的摄影风格。
- Result: PIF在提取和迁移各种摄影风格方面表现出色。
- Conclusion: PIF能够有效学习摄影风格概念并实现高质量的摄影风格迁移。


### [79] [An RGB-D Image Dataset for Lychee Detection and Maturity Classification for Robotic Harvesting](https://arxiv.org/abs/2510.16800)
*Zhenpeng Zhang,Yi Wang,Shanglei Chai,Yingying Liu,Zekai Xie,Wenhao Huang,Pengyu Li,Zipei Luo,Dajiang Lu,Yibin Tian*

Main category: cs.CV

TL;DR: 构建了一个荔枝检测和成熟度分类的数据集，包含11,414张图像和9,658对标注，涵盖不同品种、天气条件和成熟阶段。

- Motivation: 目前缺乏在自然生长环境中一致且全面标注的荔枝开源数据集，这对于开发基于视觉的荔枝采摘机器人至关重要。
- Method: 采集了多种荔枝品种在不同天气条件和时间的RGB图像，通过数据增强扩展数据集，并由多人独立标注后统一验证。
- Result: 数据集包含878张原始RGB图像、8,780张增强RGB图像和1,756张深度图像，标注了9,658对检测和成熟度分类标签。
- Conclusion: 该数据集为荔枝检测和成熟度分类研究提供了高质量资源，并通过三个深度学习模型验证了其有效性，已公开供学术使用。


### [80] [ReefNet: A Large scale, Taxonomically Enriched Dataset and Benchmark for Hard Coral Classification](https://arxiv.org/abs/2510.16822)
*Yahia Battach,Abdulwahab Felemban,Faizan Farooq Khan,Yousef A. Radwan,Xiang Li,Fabio Marchese,Sara Beery,Burton H. Jones,Francesca Benzoni,Mohamed Elhoseiny*

Main category: cs.CV

TL;DR: ReefNet是一个大型公共珊瑚礁图像数据集，包含约92.5万个属级硬珊瑚标注，旨在推动自动化珊瑚礁监测和领域泛化研究。

- Motivation: 由于气候变化等人为压力导致珊瑚礁快速衰退，迫切需要可扩展的自动化监测方法。现有数据集在规模、地理覆盖范围和标注粒度方面存在局限。
- Method: 整合了76个CoralNet来源和红海Al Wajh站点的图像，提供细粒度、分类学映射的标注。提出两种评估设置：源内基准和跨源基准。
- Result: 监督学习在源内表现良好，但在跨域时性能急剧下降；零样本模型在所有情况下表现均不佳，特别是对于稀有和视觉相似属。
- Conclusion: ReefNet为领域泛化和细粒度珊瑚分类提供了一个具有挑战性的基准，旨在推动稳健、领域自适应的全球珊瑚礁监测和保护。


### [81] [Robust Cross-Domain Adaptation in Texture Features Transferring for Wood Chip Moisture Content Prediction](https://arxiv.org/abs/2510.16832)
*Abdur Rahman,Mohammad Marufuzzaman,Jason Street,Haifeng Wang,Veera G. Gude,Randy Buchanan*

Main category: cs.CV

TL;DR: 提出AdaptMoist域适应方法，利用纹理特征预测木屑水分含量，解决不同来源木屑数据分布变化问题，准确率提升23%达到80%。

- Motivation: 现有直接方法（烘箱干燥）处理时间长且破坏样本，间接方法在不同来源木屑上准确性不足，需要能有效应对来源变异性的稳健方法。
- Method: 综合分析五种纹理特征，提出AdaptMoist域适应方法，利用纹理特征在不同域间传递知识，并基于调整互信息提出模型保存标准。
- Result: 组合五种纹理特征达到95%准确率；AdaptMoist方法使跨域预测准确率从57%提升至80%，提高23%。
- Conclusion: AdaptMoist是跨域木屑水分含量估计的有效稳健解决方案，对依赖木屑的行业具有应用潜力。


### [82] [From Mannequin to Human: A Pose-Aware and Identity-Preserving Video Generation Framework for Lifelike Clothing Display](https://arxiv.org/abs/2510.16833)
*Xiangyu Mu,Dongliang Zhou,Jie Hou,Haijun Zhang,Weili Guan*

Main category: cs.CV

TL;DR: 提出M2HVideo框架，将人台视频转换为身份可控、逼真的人类视频，解决头部身体运动不对齐和身份漂移问题

- Motivation: 人台服装展示成本低但缺乏真实感和细节表现力，需要开发从人台到真实人类视频的生成方法
- Method: 使用动态姿态感知头部编码器融合面部语义和身体姿态，引入镜像损失和分布感知适配器，基于DDIM的单步去噪
- Result: 在多个数据集上验证，在服装一致性、身份保持和视频保真度方面优于现有方法
- Conclusion: M2HVideo能够有效生成身份可控、逼真的人类视频，解决了人台展示的局限性


### [83] [2DGS-R: Revisiting the Normal Consistency Regularization in 2D Gaussian Splatting](https://arxiv.org/abs/2510.16837)
*Haofan Ren,Qingsong Yan,Ming Lu,Rongfeng Lu,Zunjie Zhu*

Main category: cs.CV

TL;DR: 提出了2DGS-R方法，通过分层训练策略在保持几何精度的同时提升渲染质量，仅需1%额外存储和少量训练时间即可实现高质量渲染。

- Motivation: 3D高斯泼溅技术难以准确表示表面，而2DGS虽然几何保真度有所提升但渲染质量仍受影响，目前无法在单次训练中同时优化几何和渲染质量。
- Method: 采用分层训练：首先用法向一致性正则化训练原始2D高斯；然后选择渲染质量不足的2D高斯进行原地克隆操作；最后冻结不透明度微调模型。
- Result: 相比原始2DGS仅需1%额外存储和少量训练时间，即可实现高质量渲染结果，同时保留精细几何结构。
- Conclusion: 该方法有效平衡了效率与性能，在视觉保真度和几何重建精度方面均有提升。


### [84] [ArmFormer: Lightweight Transformer Architecture for Real-Time Multi-Class Weapon Segmentation and Classification](https://arxiv.org/abs/2510.16854)
*Akhila Kambhatla,Taminul Islam,Khaled R Ahmed*

Main category: cs.CV

TL;DR: ArmFormer是一个轻量级基于transformer的语义分割框架，结合CBAM注意力模块和MixVisionTransformer架构，在保持计算效率的同时实现武器像素级分割，适用于边缘设备部署。

- Motivation: 传统武器检测方法只能提供粗略的边界框定位，缺乏像素级精度；现有语义分割模型要么牺牲精度追求效率，要么计算资源需求过高，不适合边缘部署场景。
- Method: 将CBAM增强的编码器主干与注意力集成的hamburger解码器相结合，实现五类武器（手枪、步枪、刀具、左轮手枪、人类）的语义分割。
- Result: 在80.64% mIoU和89.13% mFscore下达到最先进性能，同时保持82.26 FPS的实时推理速度，仅需4.886G FLOPs和3.66M参数。
- Conclusion: ArmFormer是部署在便携安全摄像头、监控无人机和嵌入式AI加速器上的最优解决方案，计算效率比重量级模型高48倍。


### [85] [BARL: Bilateral Alignment in Representation and Label Spaces for Semi-Supervised Volumetric Medical Image Segmentation](https://arxiv.org/abs/2510.16863)
*Shujian Gao,Yuan Wang,Zekuan Yu*

Main category: cs.CV

TL;DR: 提出BARL框架，通过标签空间和表示空间的双边对齐，提升半监督医学图像分割性能

- Motivation: 现有半监督医学图像分割方法主要依赖标签空间一致性，忽略了表示空间对齐的重要性，导致模型难以学习具有区分性和空间一致性的表示
- Method: BARL框架包含两个协作分支，在标签空间使用双路径正则化和渐进认知偏差校正，在表示空间进行区域级和病变实例级匹配
- Result: 在四个公共基准数据集和一个私有CBCT数据集上的实验表明，BARL持续超越最先进的半监督医学图像分割方法
- Conclusion: BARL通过双边对齐策略有效提升了半监督医学图像分割性能，消融研究验证了各组件的重要性


### [86] [Registration is a Powerful Rotation-Invariance Learner for 3D Anomaly Detection](https://arxiv.org/abs/2510.16865)
*Yuyang Yu,Zhengwei Chen,Xuemiao Xu,Lei Zhang,Haoxin Yang,Yongwei Nie,Shengfeng He*

Main category: cs.CV

TL;DR: 提出了一种基于配准的旋转不变特征提取框架，将点云配准与基于内存库的异常检测相结合，解决了现有方法在特征变换不一致性和局部几何细节捕捉方面的局限性。

- Motivation: 当前基于内存库的3D异常检测方法存在特征变换不一致和判别能力有限的问题，特别是在捕捉局部几何细节和实现旋转不变性方面。当配准失败时，这些局限性会导致不可靠的检测结果。
- Method: 提出配准诱导的旋转不变特征提取框架，将点云配准与异常检测目标集成。通过将特征提取嵌入到配准学习过程中，联合优化对齐和表示学习，获得对旋转鲁棒且对异常检测有效的特征。
- Result: 在Anomaly-ShapeNet和Real3D-AD数据集上的大量实验表明，该方法在有效性和泛化性方面持续优于现有方法。
- Conclusion: 点云配准在引导特征提取朝向旋转不变和局部判别表示方面起着关键作用，提出的集成框架显著提升了3D异常检测的性能。


### [87] [Uncovering Brain-Like Hierarchical Patterns in Vision-Language Models through fMRI-Based Neural Encoding](https://arxiv.org/abs/2510.16870)
*Yudan Ren,Xinlong Wang,Kexin Wang,Tian Xia,Zihan Ma,Zhaowei Li,Xiangrong Bi,Xiao Li,Xiaowei He*

Main category: cs.CV

TL;DR: 提出了一种神经元级别的分析框架，通过结合人工神经元分析和fMRI体素编码，研究视觉语言模型与人类大脑在多模态信息处理机制上的相似性。

- Motivation: 当前对人工神经网络与人类大脑处理机制的理解存在局限：单模态ANN研究无法捕捉大脑固有的多模态处理能力，而多模态ANN研究主要关注高层模型输出，忽视了单个神经元的关键作用。
- Method: 结合细粒度人工神经元分析和基于fMRI的体素编码，研究了CLIP和METER两种架构不同的视觉语言模型，分析其神经元活动与大脑神经元活动的对应关系。
- Result: 发现四个关键结果：1) ANs能成功预测多个功能网络中的BNs活动；2) ANs和BNs都表现出功能冗余；3) ANs表现出与BNs相似的极性模式；4) CLIP和METER的架构驱动不同的BNs激活模式。
- Conclusion: 这些结果为视觉语言模型在神经元级别上存在类似大脑的层次处理提供了有力证据。


### [88] [Class-N-Diff: Classification-Induced Diffusion Model Can Make Fair Skin Cancer Diagnosis](https://arxiv.org/abs/2510.16887)
*Nusrat Munia,Abdullah Imran*

Main category: cs.CV

TL;DR: 提出Class-N-Diff模型，将分类器集成到扩散模型中，同时生成和分类皮肤镜图像，提高生成图像的质量和多样性。

- Motivation: 传统类别条件生成模型难以准确生成特定医疗类别图像，限制了在皮肤癌诊断等应用中的实用性。
- Method: 在扩散模型中集成分类器，基于类别条件引导图像生成，实现更好的类别控制。
- Result: 模型能够生成更真实和多样化的图像，同时分类器性能也得到提升。
- Conclusion: Class-N-Diff是增强基于扩散模型的合成皮肤镜图像质量和实用性的强大工具。


### [89] [Uniworld-V2: Reinforce Image Editing with Diffusion Negative-aware Finetuning and MLLM Implicit Feedback](https://arxiv.org/abs/2510.16888)
*Zongjian Li,Zheyuan Liu,Qihui Zhang,Bin Lin,Shenghai Yuan,Zhiyuan Yan,Yang Ye,Wangbo Yu,Yuwei Niu,Li Yuan*

Main category: cs.CV

TL;DR: Edit-R1是一个基于策略优化的指令图像编辑后训练框架，通过DiffusionNFT方法和MLLM奖励模型解决监督微调过拟合问题，在多个基准测试中取得SOTA结果。

- Motivation: 监督微调训练的模型容易过拟合到标注模式，限制了在训练分布之外的泛化能力。
- Method: 使用Diffusion Negative-aware Finetuning策略优化方法，结合多模态大语言模型作为训练无关的统一奖励模型，并设计低方差组过滤机制减少评分噪声。
- Result: UniWorld-V2在ImgEdit和GEdit-Bench基准测试中分别获得4.49和7.83的SOTA分数，该框架可应用于多种基础模型。
- Conclusion: Edit-R1是一个模型无关的通用框架，能显著提升指令图像编辑模型的性能，具有广泛适用性。


### [90] [Contrail-to-Flight Attribution Using Ground Visible Cameras and Flight Surveillance Data](https://arxiv.org/abs/2510.16891)
*Ramon Dalmau,Gabriel Jarry,Philippe Very*

Main category: cs.CV

TL;DR: 本文提出了一种使用地面相机进行凝结尾迹到航班归因的模块化框架，通过结合飞机监视和气象数据来识别产生凝结尾迹的源航班。

- Motivation: 航空业的非CO2效应，特别是凝结尾迹，对其气候影响显著。验证和校准凝结尾迹物理模型需要将观测到的凝结尾迹与其产生的航班关联起来，而基于卫星的归因方法受限于空间和时间分辨率。
- Method: 利用地面可见相机凝结尾迹序列(GVCCS)数据集，开发模块化框架，结合多种几何表示和距离度量，包含时间平滑处理，支持基于概率的灵活分配策略。
- Result: 建立了凝结尾迹到航班归因的强基线，为未来研究提供了模块化框架。
- Conclusion: 地面相机方法能在凝结尾迹形成后不久以高时空分辨率捕捉它们，此时凝结尾迹仍保持细长、线性和视觉上可区分的特征，为凝结尾迹归因提供了有效替代方案。


### [91] [Beyond RGB: Leveraging Vision Transformers for Thermal Weapon Segmentation](https://arxiv.org/abs/2510.16913)
*Akhila Kambhatla,Ahmed R Khaled*

Main category: cs.CV

TL;DR: 该论文评估了四种基于Transformer的架构在热成像武器分割任务上的性能，发现SegFormer-b5在分割精度上表现最佳，而SegFormer-b0在推理速度上最优，为实时安全应用提供了灵活的精度-速度权衡方案。

- Motivation: 热成像武器分割在低光照和视觉遮挡条件下对监控和安全应用至关重要。传统CNN方法在捕获长距离依赖和精细结构细节方面存在局限，而Vision Transformers在RGB分割任务中表现出色，但在热成像武器分割领域的潜力尚未充分探索。
- Method: 使用包含9,711张从真实世界监控视频收集并利用SAM2自动标注的热成像图像数据集，在MMSegmentation框架下采用标准数据增强策略，评估了四种基于Transformer的架构：SegFormer、DeepLabV3+、SegNeXt和Swin Transformer。
- Result: 实验结果显示显著的分割性能提升：SegFormer-b5达到最高mIoU（94.15%）和像素精度（97.04%），SegFormer-b0提供最快的推理速度（98.32 FPS）且mIoU保持竞争力（90.84%）。SegNeXt-mscans提供平衡性能（85.12 FPS和92.24% mIoU），DeepLabV3+ R101-D8达到92.76% mIoU（29.86 FPS）。
- Conclusion: Transformer架构在低光照和遮挡热成像环境下的武器检测中展现出强大的泛化能力，为多样化的实时安全应用提供了灵活的精度-速度权衡选择。


### [92] [Res-Bench: Benchmarking the Robustness of Multimodal Large Language Models to Dynamic Resolution Input](https://arxiv.org/abs/2510.16926)
*Chenxu Li,Zhicai Wang,Yuan Sheng,Xingyu Zhu,Yanbin Hao,Xiang Wang*

Main category: cs.CV

TL;DR: 提出了Res-Bench基准测试，评估多模态大语言模型在不同输入分辨率下的性能稳定性，引入新的鲁棒性指标来衡量模型在分辨率变化时的表现一致性。

- Motivation: 当前多模态大语言模型支持动态图像分辨率，但现有评估主要关注语义性能，忽视了分辨率鲁棒性这一关键问题。
- Method: 构建包含14,400个样本的Res-Bench基准，涵盖12个分辨率级别和6个核心能力维度。设计了包含Spearman相关性和绝对/相对连续误差等鲁棒性指标的新评估框架。
- Result: 对领先的MLLMs进行了大规模评估，包括模型中心和任务中心的鲁棒性分析、预处理策略（填充和超分辨率）研究以及稳定性增强的微调探索。
- Conclusion: 提出了一个全面的分辨率鲁棒性评估框架，填补了当前MLLM评估在分辨率稳定性方面的空白。


### [93] [Foundation Models in Medical Image Analysis: A Systematic Review and Meta-Analysis](https://arxiv.org/abs/2510.16973)
*Praveenbalaji Rajendran,Mojtaba Safari,Wenfeng He,Mingzhe Hu,Shansong Wang,Jun Zhou,Xiaofeng Yang*

Main category: cs.CV

TL;DR: 这篇综述文章系统分析了医学图像分析中的基础模型，包括视觉专用和视觉语言基础模型的架构、训练策略和临床应用，并讨论了领域适应、高效微调等挑战及解决方案。

- Motivation: 尽管基础模型在医学图像分析领域快速发展，但该领域仍缺乏对架构演变、训练范式和临床应用的系统性综述，需要统一的综合分析来指导未来研究。
- Method: 将研究系统分类为视觉专用和视觉语言基础模型，分析其架构基础、训练策略和下游临床任务，并进行定量元分析以描述数据集使用和应用领域的时间趋势。
- Result: 通过系统性分类和定量分析，揭示了基础模型在医学图像分析中的发展趋势，识别了不同架构和训练策略的应用特点。
- Conclusion: 文章识别了增强基础模型鲁棒性、可解释性和临床整合的关键未来研究方向，以加速其在真实医疗实践中的转化应用。


### [94] [One-step Diffusion Models with Bregman Density Ratio Matching](https://arxiv.org/abs/2510.16983)
*Yuanzhi Zhu,Eleftherios Tsonis,Lucas Degeorge,Vicky Kalogeiton*

Main category: cs.CV

TL;DR: 提出Di-Bregman框架，通过Bregman散度密度比匹配来加速扩散模型采样，实现高效的一步生成。

- Motivation: 扩散和流模型生成质量高但计算昂贵，现有蒸馏方法缺乏统一的理论基础。
- Method: 将扩散蒸馏表述为基于Bregman散度的密度比匹配问题，提供凸分析视角。
- Result: 在CIFAR-10和文本到图像生成任务上，相比反向KL蒸馏获得更好的一步FID，保持高视觉保真度。
- Conclusion: Bregman密度比匹配是通向高效一步扩散生成的实际且有理论基础的途径。


### [95] [CARE: Contrastive Alignment for ADL Recognition from Event-Triggered Sensor Streams](https://arxiv.org/abs/2510.16988)
*Junhao Zhao,Zishuai Liu,Ruili Fang,Jin Lu,Linghan Zhang,Fei Dou*

Main category: cs.CV

TL;DR: 提出CARE框架，通过序列-图像对比对齐方法解决ADL识别中序列和图像表示之间的对齐问题，在三个CASAS数据集上达到最先进性能。

- Motivation: 现有ADL识别方法存在表示级限制：序列方法保持时间顺序但对噪声敏感且缺乏空间感知，图像方法捕获全局模式但压缩时间动态并扭曲传感器布局，简单融合方法无法有效对齐两种表示视图。
- Method: 提出CARE端到端框架，集成时间感知的序列编码和空间感知的图像表示，使用序列-图像对比对齐(SICA)联合优化表示学习和分类，通过对比-分类联合目标学习对齐且可区分的嵌入。
- Result: 在三个CASAS数据集上达到最先进性能：米兰89.8%、开罗88.9%、京都73.3%，并展示了对传感器故障和布局变化的鲁棒性。
- Conclusion: CARE框架通过对比对齐有效利用序列和图像表示的互补优势，为智能家居中可靠的ADL识别提供了潜力。


### [96] [Training-free Online Video Step Grounding](https://arxiv.org/abs/2510.16989)
*Luca Zanella,Massimiliano Mancini,Yiming Wang,Alessio Tonioni,Elisa Ricci*

Main category: cs.CV

TL;DR: 本文提出BaGLM方法，利用大型多模态模型的零样本能力实现无训练的在线视频步骤定位，通过贝叶斯滤波整合历史帧信息，在三个数据集上超越基于训练的离线方法。

- Motivation: 传统视频步骤定位方法需要带标注的训练数据和离线处理整个视频，成本高且无法实时应用。本文探索无需训练、在线处理的方法。
- Method: 使用大型多模态模型预测有限帧的步骤，结合贝叶斯滤波原理，通过LLM提取的依赖矩阵和步骤进度估计来建模步骤转换。
- Result: BaGLM在三个数据集上表现优于最先进的基于训练的离线方法，证明了无训练在线策略的有效性。
- Conclusion: 利用大型多模态模型的零样本能力和贝叶斯滤波可以实现在线、无训练的视频步骤定位，性能超越传统方法。


### [97] [An empirical study of the effect of video encoders on Temporal Video Grounding](https://arxiv.org/abs/2510.17007)
*Ignacio M. De la Jara,Cristian Rodriguez-Opazo,Edison Marrese-Taylor,Felipe Bravo-Marquez*

Main category: cs.CV

TL;DR: 本文通过实证研究探讨了不同视频特征对时序视频定位任务的影响，发现在经典架构中仅改变视频编码器就能带来显著性能差异，并揭示了特征互补的潜力。

- Motivation: 当前时序视频定位研究过于集中在少数视频表示方法上，可能导致长期架构过拟合。需要研究不同视频特征对模型性能的影响。
- Method: 在三个基准数据集(Charades-STA、ActivityNet-Captions、YouCookII)上，使用基于CNN、时序推理和Transformer的不同视频编码器提取特征，并在经典架构中比较其性能。
- Result: 结果显示仅改变视频编码器就能导致模型性能显著差异，同时揭示了使用特定特征时的清晰模式和错误，表明特征间存在互补潜力。
- Conclusion: 视频特征选择对时序视频定位任务至关重要，不同特征编码器带来不同性能表现，特征互补性值得进一步探索。


### [98] [Do Satellite Tasks Need Special Pretraining?](https://arxiv.org/abs/2510.17014)
*Ani Vanyan,Alvard Barseghyan,Hakob Tamazyan,Tigran Galstyan,Vahan Huroyan,Naira Hovakimyan,Hrant Khachatrian*

Main category: cs.CV

TL;DR: 该研究挑战了遥感专用基础模型比通用视觉基础模型更有用的观点，通过实验证明在ViT-B规模下，遥感专用预训练模型并未带来一致的性能提升。

- Motivation: 研究动机是验证遥感专用基础模型是否真的比通用视觉基础模型更有优势，特别是在小规模设置下。
- Method: 设计了衡量遥感模型向低分辨率图像泛化能力的基准测试，并在MillionAID数据集上训练了iBOT自监督视觉编码器，并针对遥感进行了特定修改。
- Result: 实验结果显示，在ViT-B规模下，所有预训练的遥感专用模型都没有比通用基线模型带来一致的改进。
- Conclusion: 结论表明，至少在ViT-B规模下，遥感专用基础模型并不比通用视觉基础模型更有用。


### [99] [Enrich and Detect: Video Temporal Grounding with Multimodal LLMs](https://arxiv.org/abs/2510.17023)
*Shraman Pramanick,Effrosyni Mavroudi,Yale Song,Rama Chellappa,Lorenzo Torresani,Triantafyllos Afouras*

Main category: cs.CV

TL;DR: ED-VTG是一种利用多模态大语言模型进行细粒度视频时序定位的方法，通过两阶段处理将语言查询转换为增强句子并使用轻量级解码器进行定位，在多个基准测试中取得最先进结果。

- Motivation: 利用多模态大语言模型的能力来联合处理文本和视频，以有效定位视频中的自然语言查询，解决直接定位的局限性。
- Method: 采用两阶段过程：首先将语言查询转换为包含缺失细节和线索的增强句子，然后使用轻量级解码器基于增强查询的上下文表示预测准确边界，并通过多实例学习目标动态选择最佳查询版本。
- Result: 在视频时序定位和段落定位设置中，该方法显著优于所有先前提出的基于LLM的时序定位方法，在零样本评估场景中保持明显优势。
- Conclusion: ED-VTG方法在视频时序定位任务中表现出色，既优于或与专用模型相当，又在零样本评估中具有明显优势，证明了多模态LLM在该领域的有效性。


### [100] [Where, Not What: Compelling Video LLMs to Learn Geometric Causality for 3D-Grounding](https://arxiv.org/abs/2510.17034)
*Yutong Zhong*

Main category: cs.CV

TL;DR: 提出W2R2训练框架，通过解耦表示学习和针对性捷径抑制来解决多模态3D定位中的2D语义偏差问题，显著提升定位精度和鲁棒性。

- Motivation: 当前多模态3D定位模型存在严重的"2D语义偏差"，过度依赖2D图像特征进行粗略定位，忽视了3D几何输入，导致融合性能不佳。
- Method: W2R2框架将2D特征作为"What"识别的语义信标，3D特征作为"Where"定位的空间锚点，采用双目标损失函数（对齐损失和伪标签损失）进行解耦表示学习。
- Result: 在ScanRefer和ScanQA数据集上的实验表明，W2R2在定位精度和鲁棒性方面取得显著提升，特别是在复杂室外场景中。
- Conclusion: W2R2通过重新塑造模型内部表示空间，在不改变推理架构的情况下实现了精确的3D定位，有效解决了2D语义偏差问题。


### [101] [Conditional Synthetic Live and Spoof Fingerprint Generation](https://arxiv.org/abs/2510.17035)
*Syed Konain Abbas,Sandip Purnapatra,M. G. Sarwar Murshed,Conor Miller-Lynch,Lambert Igene,Soumyabrata Dey,Stephanie Schuckers,Faraz Hussain*

Main category: cs.CV

TL;DR: 本文提出了一种使用条件StyleGAN2-ADA和StyleGAN3生成高分辨率合成活体指纹，并通过CycleGAN转换为逼真假指纹的方法，创建了两个包含1500张指纹图像的数据集，在隐私保护和性能方面表现优异。

- Motivation: 解决真实指纹数据集收集耗时、昂贵且需要严格隐私保护的问题，探索使用合成指纹数据来应对隐私、成本和可访问性方面的挑战。
- Method: 使用条件StyleGAN2-ADA和StyleGAN3架构生成特定手指身份的高分辨率合成活体指纹，然后利用CycleGAN将这些指纹转换为模拟各种攻击材料（如EcoFlex、Play-Doh）的逼真假指纹。
- Result: StyleGAN3模型实现了低至5的FID分数，生成的指纹在0.01%错误接受率下达到99.47%的真实接受率。StyleGAN2-ADA模型在相同条件下达到98.67%的真实接受率。指纹质量评估和匹配实验证实了强大的隐私保护特性，无显著身份泄露证据。
- Conclusion: 该方法成功生成了高质量的合成指纹数据集，在保持优异识别性能的同时有效保护隐私，为开发鲁棒的假指纹检测系统提供了重要数据支持。


### [102] [Click, Predict, Trust: Clinician-in-the-Loop AI Segmentation for Lung Cancer CT-Based Prognosis within the Knowledge-to-Action Framework](https://arxiv.org/abs/2510.17039)
*Mohammad R. Salmanpour,Sonya Falahati,Amir Hossein Pouria,Amin Mousavi,Somayeh Sadat Mehrnia,Morteza Alizadeh,Arman Gorji,Zeinab Farsangi,Alireza Safarian,Mehdi Maghsudi,Carlos Uribe,Arman Rahmim,Ren Yuan*

Main category: cs.CV

TL;DR: 本研究开发了一个临床医生参与的深度学习管道，用于肺癌CT图像分割和预后预测。VNet模型在分割性能、放射组学稳定性和预测准确性方面表现最佳，半监督学习优于监督学习，放射科医生更倾向于使用AI生成的初始掩模进行精修。

- Motivation: 肺癌是癌症死亡的主要原因，CT成像在筛查、预后和治疗中至关重要。手动分割存在变异性且耗时，而深度学习虽然提供自动化，但在临床应用中面临障碍。本研究旨在通过临床医生参与的深度学习管道提高可重复性、预后准确性和临床信任度。
- Method: 使用来自12个公共数据集的999名患者的多中心CT数据，使用5种深度学习模型（3D Attention U-Net、ResUNet、VNet、ReconNet、SAM-Med3D）进行分析，并与专家轮廓进行基准测试。通过497个PySERA提取的放射组学特征评估分割可重复性，同时比较监督学习和半监督学习在38种降维策略和24种分类器下的预后建模。6名医生在7个领域对掩模进行定性评估。
- Result: VNet实现了最佳性能（Dice = 0.83，IoU = 0.71）、放射组学稳定性（平均相关性 = 0.76，ICC = 0.65）和半监督学习下的预测准确性（准确率 = 0.88，F1 = 0.83）。半监督学习在所有模型中始终优于监督学习。放射科医生更青睐VNet的瘤周表现和平滑边界，偏好使用AI生成的初始掩模进行精修而非完全替换。
- Conclusion: 将VNet与半监督学习相结合，能够产生准确、可重复且临床信任的基于CT的肺癌预后结果，突显了实现以医生为中心的AI转化的可行路径。


### [103] [Person Re-Identification via Generalized Class Prototypes](https://arxiv.org/abs/2510.17043)
*Md Ahmed Al Muzaddid,William J. Beksi*

Main category: cs.CV

TL;DR: 提出了一种广义选择方法，通过选择不限于类质心的表示来改进行人重识别性能，在准确率和平均精度均值之间取得平衡，超越了现有技术水平。

- Motivation: 虽然先进的特征提取方法和目标函数改进已显著提升行人重识别性能，但选择更好的类代表是一个研究不足的领域。现有方法主要使用图库图像类的质心，但这种方法在重识别指标上表现次优。
- Method: 提出广义选择方法，选择不限于类质心的表示，可根据具体应用需求调整每类的实际表示数量。该方法应用于多种重识别嵌入之上。
- Result: 在所有情况下，该方法都显著改进了当代结果，在准确率和平均精度均值之间取得了更好的平衡。
- Conclusion: 广义选择方法能够超越现有技术水平，通过灵活选择类表示来提升行人重识别性能，且可根据应用需求进行调整。


### [104] [Video Reasoning without Training](https://arxiv.org/abs/2510.17045)
*Deepak Sridhar,Kartikeya Bhardwaj,Jeya Pradha Jeyaraj,Nuno Vasconcelos,Ankita Nayak,Harris Teague*

Main category: cs.CV

TL;DR: 提出V-Reason方法，通过基于熵的优化调整LMM在推理时的值缓存，改善模型的微观探索和利用行为，无需额外训练即可显著提升视频推理性能。

- Motivation: 现有视频推理LMM依赖昂贵的强化学习和冗长的思维链，计算开销大且思维过程控制机制有限。
- Method: 使用模型输出熵作为信号，通过小型可训练控制器对LMM值缓存进行基于熵目标的优化，调整推理时的微观探索和利用行为。
- Result: 在多个视频推理数据集上显著超越基础指令调优模型，与RL训练模型差距缩小至0.6%平均准确率，同时输出token减少58.6%。
- Conclusion: 基于熵的推理时优化可有效提升LMM的视频推理能力，无需额外训练即可获得接近RL模型的性能，且效率更高。


### [105] [How Universal Are SAM2 Features?](https://arxiv.org/abs/2510.17051)
*Masoud Khairi Atani,Alon Harell,Hyomin Choi,Runyu Yang,Fabien Racape,Ivan V. Bajic*

Main category: cs.CV

TL;DR: 比较通用视觉模型Hiera和专用分割模型SAM2的特征通用性，发现专用化虽然提升空间相关任务性能，但会损失语义信息，造成表示瓶颈

- Motivation: 研究通用基础视觉模型与专用模型之间的权衡关系，为高效特征编码设计提供理论基础
- Method: 使用轻量可训练neck模块探测冻结特征适应性，通过信息论成本量化专用化代价，并进行跨neck分析
- Result: SAM2在深度估计等空间任务上表现优异，但在姿态估计和图像描述等语义任务上不如Hiera，显示专用化导致语义信息损失
- Conclusion: 专用化存在特征通用性权衡，为下游应用的特征编码和适应策略设计提供了量化基础


### [106] [ProDAT: Progressive Density-Aware Tail-Drop for Point Cloud Coding](https://arxiv.org/abs/2510.17068)
*Zhe Luo,Wenjing Jia,Stuart Perry*

Main category: cs.CV

TL;DR: 提出了ProDAT方法，一种基于密度感知的渐进式点云编码机制，能够在单一模型中实现多比特率下的渐进解码，显著提升编码效率。

- Motivation: 三维点云在自动驾驶、增强现实等应用中需要实时处理和低延迟，但大数据量和带宽限制阻碍了高质量服务的部署。现有学习型编码方法的固定潜在表示不支持渐进解码。
- Method: 提出密度感知的尾丢弃机制，利用密度信息作为指导信号，根据重要性自适应解码潜在特征和坐标，实现单一模型下的多比特率渐进解码。
- Result: 在基准数据集上的实验表明，ProDAT不仅实现了渐进编码，还在编码效率上优于最先进的学习型编码技术，在SemanticKITTI上PSNR-D2的BD-rate提升超过28.6%，在ShapeNet上提升超过18.15%。
- Conclusion: ProDAT方法有效解决了点云渐进编码问题，在保持编码效率的同时实现了灵活的渐进解码能力。


### [107] [Towards a Generalizable Fusion Architecture for Multimodal Object Detection](https://arxiv.org/abs/2510.17078)
*Jad Berjawi,Yoann Dupas,Christophe C'erin*

Main category: cs.CV

TL;DR: 提出了FMCAF预处理架构，通过频域滤波和跨注意力融合来增强RGB和红外图像的多模态目标检测性能，在多个数据集上表现优于传统融合方法。

- Motivation: 多模态目标检测在挑战性条件下通过利用多个传感器模态的互补线索来提高鲁棒性，但现有方法往往针对特定数据集设计，缺乏通用性。
- Method: FMCAF结合频域滤波块(Freq-Filter)来抑制冗余频谱特征，以及基于跨注意力的融合模块(MCAF)来改进模态间特征共享。
- Result: 在LLVIP(低光行人检测)和VEDAI(航空车辆检测)数据集上，FMCAF优于传统拼接融合方法，在VEDAI上mAP@50提升13.9%，在LLVIP上提升1.1%。
- Conclusion: FMCAF作为灵活的多模态融合基础架构，在未来的检测流程中具有潜力，能够在不需数据集特定调优的情况下提升不同多模态挑战的性能。


### [108] [GSPlane: Concise and Accurate Planar Reconstruction via Structured Representation](https://arxiv.org/abs/2510.17095)
*Ruitong Gan,Junran Peng,Yang Liu,Chuanchen Luo,Qing Li,Zhaoxiang Zhang*

Main category: cs.CV

TL;DR: GSPlane通过引入平面先验来改进高斯泼溅的几何重建，特别针对平面区域提供更平滑精确的网格重建，同时保持渲染质量。

- Motivation: 高斯泼溅在3D场景重建中表现出色，但在平面区域的重建往往不够平滑和精确，这限制了其在场景编辑和物理仿真等下游应用中的使用。
- Method: 利用现成的分割和法向预测模型提取平面先验，建立结构化表示；引入动态高斯重分类器自适应重新分类高梯度平面高斯；使用优化的平面先验优化网格布局。
- Result: 在各种基准测试中，引入平面先验显著提高了提取网格的几何精度，同时没有牺牲渲染质量，减少了顶点和面的数量。
- Conclusion: GSPlane通过平面先验有效提升了高斯泼溅在平面区域的几何重建质量，为场景编辑和物理仿真提供了更好的结构化表示。


### [109] [Boosting Fidelity for Pre-Trained-Diffusion-Based Low-Light Image Enhancement via Condition Refinement](https://arxiv.org/abs/2510.17105)
*Xiaogang Xu,Jian Wang,Yunfan Lu,Ruihang Chu,Ruixing Wang,Jiafei Wu,Bei Yu,Liang Lin*

Main category: cs.CV

TL;DR: 提出一种优化策略，通过改进条件潜在建模和双向交互机制，解决预训练扩散模型在低光场景下保真度损失的问题。

- Motivation: 预训练扩散模型在低光视觉任务中往往牺牲内容保真度来追求感知真实性，主要原因是缺乏合适的条件潜在建模和双向交互机制。
- Method: 引入潜在细化管道恢复VAE编码中丢失的空间细节，并建立条件潜在与噪声潜在之间的动态交互机制。
- Result: 实验证明该方法能显著提升预训练扩散模型的保真度表现。
- Conclusion: 该优化策略可无缝集成到现有扩散网络中，有效提升控制效果，同时保持真实性和美学质量。


### [110] [Towards Imperceptible Watermarking Via Environment Illumination for Consumer Cameras](https://arxiv.org/abs/2510.17114)
*Hodaka Kawachi,Tomoya Nakamura,Hiroaki Santo,SaiKiran Kumar Tedla,Trevor Dalton Canham,Yasushi Yagi,Michael S. Brown*

Main category: cs.CV

TL;DR: 提出一种使用LED环境照明为消费级相机生成视觉不可见水印的方法，通过优化LED光源的光谱特性，使其对人眼几乎不可见但对相机高度可检测。

- Motivation: 开发一种在标准视频帧率下工作的不可见水印技术，用于隐私保护和内容验证，避免传统可见光通信需要高速帧率的限制。
- Method: 联合考虑人眼视觉系统敏感性、相机传感器光谱响应和窄带LED产生白光的能力，采用光谱调制而非强度调制来确保不可感知性。
- Result: 能够在30-60fps标准帧率下提取水印，在10秒视频片段中嵌入128位信息，足以支持基本的元数据需求。
- Conclusion: 该方法为消费级相机提供了一种实用的不可见水印解决方案，适用于隐私保护和内容验证应用，且无需高速摄像设备。


### [111] [GOOD: Training-Free Guided Diffusion Sampling for Out-of-Distribution Detection](https://arxiv.org/abs/2510.17131)
*Xin Gao,Jiyao Liu,Guanghao Li,Yueming Lyu,Jianxiong Gao,Weichen Yu,Ningsheng Xu,Liang Wang,Caifeng Shan,Ziwei Liu,Chenyang Si*

Main category: cs.CV

TL;DR: GOOD是一个新颖的OOD样本生成框架，通过双重引导机制（图像级和特征级）直接指导扩散采样轨迹，生成更可控和多样化的OOD样本，显著提升OOD检测性能。

- Motivation: 现有方法通常通过扰动文本条件嵌入来生成OOD样本，存在语义不稳定和偏移多样性不足的问题，限制了在真实OOD场景中的泛化能力。
- Method: 提出GOOD框架，利用现成的ID分类器直接指导扩散采样轨迹：1）图像级引导基于对数分割梯度减少输入似然；2）特征级引导基于k-NN距离在分类器潜在空间中促进特征稀疏区域的采样。
- Result: 通过GOOD生成的样本进行训练可以显著提升OOD检测性能，进行了全面的定量和定性分析验证其有效性。
- Conclusion: GOOD框架通过双重引导设计实现了更可控和多样化的OOD样本生成，提出的统一OOD评分自适应结合图像和特征差异，增强了检测鲁棒性。


### [112] [KineDiff3D: Kinematic-Aware Diffusion for Category-Level Articulated Object Shape Reconstruction and Generation](https://arxiv.org/abs/2510.17137)
*WenBo Xu,Liu Liu,Li Zhang,Ran Zhang,Hao Wu,Dan Guo,Meng Wang*

Main category: cs.CV

TL;DR: KineDiff3D是一个统一的框架，通过运动学感知扩散模型从单视图输入重建多样化的铰接物体形状并估计姿态。

- Motivation: 铰接物体（如笔记本电脑和抽屉）由于其多部件几何结构和可变关节配置，在3D重建和姿态估计方面面临显著挑战，这些配置在不同状态下引入了结构多样性。
- Method: 首先通过运动学感知VAE将完整几何、关节角度和部件分割编码到结构化潜在空间；然后使用两个条件扩散模型分别回归全局姿态和关节参数，以及从部分观测生成运动学感知潜在代码；最后通过迭代优化模块双向优化重建精度和运动学参数。
- Result: 在合成、半合成和真实世界数据集上的实验结果表明，该方法能够准确重建铰接物体并估计其运动学特性。
- Conclusion: KineDiff3D框架有效解决了铰接物体的3D重建和姿态估计问题，通过运动学感知的扩散模型实现了准确的重建和参数估计。


### [113] [GACO-CAD: Geometry-Augmented and Conciseness-Optimized CAD Model Generation from Single Image](https://arxiv.org/abs/2510.17157)
*Yinghui Wang,Xinyu Zhang,Peng Du*

Main category: cs.CV

TL;DR: GACO-CAD是一个两阶段后训练框架，通过深度和法线图作为几何先验，结合强化学习中的组长度奖励，从单张图像生成可编辑的CAD模型，在几何精度和建模简洁性方面达到最优性能。

- Motivation: 解决多模态大语言模型从2D图像准确推断3D几何形状的局限性，降低工业概念设计的门槛。
- Method: 两阶段框架：监督微调阶段使用深度和法线图作为多通道输入提供几何先验；强化学习阶段引入组长度奖励促进简洁建模序列，采用动态加权策略稳定训练。
- Result: 在DeepCAD和Fusion360数据集上达到最先进性能，在代码有效性、几何精度和建模简洁性方面优于现有方法。
- Conclusion: GACO-CAD通过几何先验和简洁建模奖励，有效提升了从单张图像生成CAD模型的几何准确性和建模效率。


### [114] [Investigating Adversarial Robustness against Preprocessing used in Blackbox Face Recognition](https://arxiv.org/abs/2510.17169)
*Roland Croft,Brian Du,Darcy Joseph,Sharath Kumar*

Main category: cs.CV

TL;DR: 本文研究了人脸识别系统中预处理对对抗攻击可迁移性的影响，发现人脸检测模型选择可降低攻击成功率达78%，并提出预处理不变方法提升攻击可迁移性27%。

- Motivation: 人脸识别系统容易受到对抗样本攻击，但现有研究往往忽视了预处理环节在对抗攻击中的重要性，特别是在黑盒设置下。
- Method: 研究了多种现成的最先进对抗攻击在不同预处理技术下的可迁移性，分析了人脸检测模型和降采样插值方法的影响，并提出了基于输入变换的预处理不变方法。
- Result: 人脸检测模型选择可使攻击成功率降低78%，而插值方法影响较小。预处理要求即使在白盒设置下也会降低攻击强度。提出的预处理不变方法可将攻击可迁移性提升27%。
- Conclusion: 预处理在人脸识别系统中至关重要，考虑预处理因素有助于提高面部对抗样本的对抗泛化能力。


### [115] [Generation then Reconstruction: Accelerating Masked Autoregressive Models via Two-Stage Sampling](https://arxiv.org/abs/2510.17171)
*Feihong Yan,Peiru Wang,Yao Zhu,Kaiyu Pang,Qingyan Wei,Huiqi Li,Linfeng Zhang*

Main category: cs.CV

TL;DR: GtR是一种无需训练的分层采样策略，通过将图像生成分解为结构生成和细节重建两个阶段，在保持生成质量的同时实现3.72倍加速。

- Motivation: 解决MAR模型在并行生成时由于空间相关视觉令牌建模复杂导致的加速潜力受限问题。
- Method: 提出GtR分层采样策略：第一阶段缓慢生成全局语义结构，第二阶段快速重建剩余令牌细节。同时提出FTS方法，基于高频信息能量为图像细节区域分配更多计算资源。
- Result: 在ImageNet类条件生成和文本到图像生成任务中实现3.72倍加速，同时保持可比质量（FID: 1.59, IS: 304.4 vs 原始1.59, 299.1）。
- Conclusion: GtR方法显著优于现有加速方法，在不同模型规模和生成任务上均表现出色，为MAR模型提供了有效的加速解决方案。


### [116] [Benchmarking Out-of-Distribution Detection for Plankton Recognition: A Systematic Evaluation of Advanced Methods in Marine Ecological Monitoring](https://arxiv.org/abs/2510.17179)
*Yingzi Han,Jiakai He,Chuanlong Xie,Jianping Li*

Main category: cs.CV

TL;DR: 本文针对浮游生物识别中的分布偏移问题，首次系统性地构建了OoD基准并评估了22种检测方法，发现ViM方法在远OoD场景中表现最佳。

- Motivation: 浮游生物识别模型在真实部署中面临分布偏移挑战，源于其复杂形态、物种多样性和新物种的持续发现，导致推理时出现不可预测错误。该领域缺乏最新计算机视觉技术的系统整合和大规模评估基准。
- Method: 基于DYB-PlanktonNet数据集精心设计了一系列模拟不同分布偏移场景的OoD基准，并系统评估了22种OoD检测方法。
- Result: 实验结果表明ViM方法在构建的基准中显著优于其他方法，特别是在远OoD场景中关键指标有大幅提升。
- Conclusion: 这项研究为自动浮游生物识别中的算法选择提供了可靠参考，并为浮游生物OoD检测的未来研究奠定了坚实基础，是该领域的首次大规模系统性评估。


### [117] [Capturing Head Avatar with Hand Contacts from a Monocular Video](https://arxiv.org/abs/2510.17181)
*Haonan He,Yufeng Zheng,Jie Song*

Main category: cs.CV

TL;DR: 提出一个联合学习详细头部化身和手-脸交互引起的非刚性变形的框架，解决了现有方法忽略手脸交互的问题。

- Motivation: 现有方法主要关注面部区域，忽略了传达认知状态的自然手-脸交互（如手托下巴、手指轻触脸颊等），这些交互对于真实感3D头部化身至关重要。
- Method: 结合深度顺序损失和接触正则化进行姿态跟踪；从手脸交互数据集中学习手引起面部变形的PCA基；引入基于物理模拟的接触损失减少穿透伪影。
- Result: 在iPhone拍摄的RGB(D)视频上评估，并构建合成数据集验证。相比SOTA表面重建方法，能捕捉更好的外观和更准确的面部变形几何。
- Conclusion: 该方法能够有效捕捉手-脸交互引起的面部变形，生成更真实和物理合理的3D头部化身。


### [118] [HIDISC: A Hyperbolic Framework for Domain Generalization with Generalized Category Discovery](https://arxiv.org/abs/2510.17188)
*Vaibhav Rathore,Divyam Gupta,Biplab Banerjee*

Main category: cs.CV

TL;DR: HIDISC是一个双曲表示学习框架，用于解决域泛化与广义类别发现问题，无需模拟训练且计算高效。

- Motivation: 现有GCD方法假设训练和测试数据来自同一域，限制了在开放世界场景中的适用性。DG-GCD要求模型泛化到包含新类别的未见域，而现有方法DG2CD-Net计算成本高且存在误差累积。
- Method: 使用GPT引导的扩散增强源域数据；提出切向CutMix进行曲率感知插值；结合惩罚Busemann对齐、混合双曲对比正则化和自适应异常值排斥的统一损失；可学习的曲率参数适应数据集复杂度。
- Result: 在PACS、Office-Home和DomainNet数据集上达到最先进水平，持续优于现有的欧几里得和双曲(DG)-GCD基线方法。
- Conclusion: HIDISC通过双曲表示学习有效解决了域泛化与广义类别发现问题，在多个基准数据集上表现出色，为开放世界场景提供了高效解决方案。


### [119] [ZSPAPrune: Zero-Shot Prompt-Aware Token Pruning for Vision-Language Models](https://arxiv.org/abs/2510.17197)
*Pu Zhang,Yuwei Li,Xingyuan Xian,Guoming Tang*

Main category: cs.CV

TL;DR: 提出一种零样本的视觉token剪枝方法，通过平衡任务相关性和信息多样性，在保持性能的同时显著降低推理成本。

- Motivation: 随着视觉语言模型处理能力增强，视觉token冗余导致推理成本急剧上升，现有方法缺乏文本提示的指导，无法优先考虑任务相关性。
- Method: 采用分层方法：首先选择任务相关的核心视觉token，然后补充多样性token以保留更广泛的上下文信息。
- Result: 在多个模型和基准测试中，即使剪枝90%的token，性能仍能匹配或超越现有最优方法，同时显著减少GPU内存占用和推理延迟。
- Conclusion: 提出的提示感知视觉token剪枝方法在保持模型性能的同时，有效解决了视觉token冗余导致的推理成本问题。


### [120] [From Pixels to People: Satellite-Based Mapping and Quantification of Riverbank Erosion and Lost Villages in Bangladesh](https://arxiv.org/abs/2510.17198)
*M Saifuzzaman Rafat,Mohd Ruhul Ameen,Akif Islam,Abu Saleh Musa Miah,Jungpil Shin*

Main category: cs.CV

TL;DR: 使用Segment Anything Model (SAM)开发了一个专门用于检测孟加拉国河流侵蚀的AI模型，通过颜色通道分析和微调SAM的掩码解码器，实现了对河岸侵蚀的高精度识别。

- Motivation: 孟加拉国的河流既是商业和生计的动脉，也是无情的破坏者，每年吞噬整个村庄和大片农田，导致数千家庭流离失所。传统的人工分析难以有效追踪这种缓慢的灾难。
- Method: 首先使用简单的颜色通道分析进行粗略的土地和水域分割，然后微调SAM的掩码解码器来识别河岸侵蚀的细微特征。创建了包含2003-2025年Google Earth影像的新数据集，首次包含消失定居点的手动标注数据。
- Result: 模型在河流侵蚀检测方面表现出色，平均交并比达到86.30%，Dice分数达到92.60%，显著优于传统方法和现成的深度学习模型。
- Conclusion: 这项工作提供了三个关键贡献：首个包含因河流侵蚀而消失定居点的标注数据集；专门为此关键任务微调的AI模型；以及通过视觉证据量化土地损失的方法。这些工具为政策制定者和灾害管理机构提供了监控侵蚀、预测其轨迹并保护脆弱社区的新能力。


### [121] [Round Outcome Prediction in VALORANT Using Tactical Features from Video Analysis](https://arxiv.org/abs/2510.17199)
*Nirai Hayakawa,Kazumasa Shimari,Kazuma Yamasaki,Hirotatsu Hoshikawa,Rikuto Tsuchida,Kenichi Matsumoto*

Main category: cs.CV

TL;DR: 基于TimeSformer视频识别模型，通过分析VALORANT游戏小地图中的战术特征（角色位置和游戏事件）来预测回合结果，在增强战术事件标签的数据集上达到约81%的预测准确率。

- Motivation: 现有电竞比赛结果预测研究多基于比赛日志和统计数据，但VALORANT这类需要复杂策略的FPS游戏需要更深入分析比赛录像中的战术信息。
- Method: 使用TimeSformer视频识别模型，从小地图信息中提取详细的战术特征，包括角色位置信息和其他游戏内事件，构建回合结果预测模型。
- Result: 在增强战术事件标签的数据集上训练的模型达到约81%的预测准确率，特别是在回合中后期阶段，显著优于仅使用小地图信息本身训练的模型。
- Conclusion: 利用比赛录像中的战术特征对于预测VALORANT回合结果非常有效，表明战术事件分析比单纯的小地图信息更具预测价值。


### [122] [EndoCIL: A Class-Incremental Learning Framework for Endoscopic Image Classification](https://arxiv.org/abs/2510.17200)
*Bingrong Liu,Jun Shi,Yushan Zheng*

Main category: cs.CV

TL;DR: EndoCIL是一个专为内窥镜图像诊断设计的类增量学习框架，通过分布对齐重放、先验正则化类别平衡损失和全连接层梯度校准三个关键组件，有效缓解灾难性遗忘和类别不平衡问题。

- Motivation: 内窥镜图像分析在临床应用中需要持续适应新数据，同时保持对已学知识的性能。现有重放式类增量学习方法由于内窥镜图像严重的领域差异和类别不平衡问题，难以有效缓解灾难性遗忘。
- Method: EndoCIL包含三个核心组件：基于最大均值差异的重放策略（MDBR）选择多样化和代表性样本；先验正则化类别平衡损失（PRCBL）缓解阶段间和阶段内类别不平衡；全连接层梯度校准（CFG）调整分类器梯度以减少对新类别的偏置。
- Result: 在四个公开内窥镜数据集上的广泛实验表明，EndoCIL在不同缓冲区大小和评估指标下普遍优于最先进的类增量学习方法。
- Conclusion: 该框架在终身内窥镜诊断中有效平衡了稳定性和可塑性，显示出良好的临床可扩展性和部署潜力。


### [123] [Optimizing DINOv2 with Registers for Face Anti-Spoofing](https://arxiv.org/abs/2510.17201)
*Mika Feng,Pierre Gallin-Martel,Koichi Ito,Takafumi Aoki*

Main category: cs.CV

TL;DR: 提出基于DINOv2的活体检测方法，通过注册机制提取泛化特征并抑制注意力扰动，有效区分真实人脸和欺骗攻击图像。

- Motivation: 人脸识别系统易受欺骗攻击，攻击者可能使用注册用户的照片绕过认证，因此需要在人脸识别前检测此类欺骗攻击。
- Method: 使用带注册机制的DINOv2模型提取泛化特征，抑制注意力机制中的扰动，专注于关键微小特征。
- Result: 在ICCV2025第六届人脸反欺骗研讨会数据集和SiW数据集上的实验证明了该方法的有效性。
- Conclusion: 提出的DINOv2基活体检测方法能够有效检测欺骗攻击，提升人脸识别系统的安全性。


### [124] [$\mathcal{V}isi\mathcal{P}runer$: Decoding Discontinuous Cross-Modal Dynamics for Efficient Multimodal LLMs](https://arxiv.org/abs/2510.17205)
*Yingqi Fan,Anhao Zhao,Jinlan Fu,Junlong Tong,Hui Su,Yijie Pan,Wei Zhang,Xiaoyu Shen*

Main category: cs.CV

TL;DR: 本文提出了VisiPruner框架，通过分析MLLMs的三阶段跨模态交互过程，实现了训练无关的视觉token剪枝，显著减少了计算开销。

- Motivation: 多模态大语言模型在视觉语言任务中表现优异，但由于注意力计算的二次增长导致计算开销巨大。现有方法缺乏对MLLMs处理多模态信息机制的根本理解。
- Method: 通过系统分析发现MLLMs存在三阶段跨模态交互过程，基于此提出VisiPruner训练无关剪枝框架，在浅层识别任务意图、中层进行跨模态融合、深层专注语言精炼的不同阶段针对性剪枝。
- Result: 在LLaVA-v1.5 7B上减少了99%的视觉相关注意力计算和53.9%的FLOPs，显著优于现有token剪枝方法，并在多种MLLMs上具有良好泛化性。
- Conclusion: 研究不仅提供了有效的剪枝方案，还为训练高效MLLMs提供了可操作的指导原则，即模型架构应与内在的分层处理动态对齐。


### [125] [When One Moment Isn't Enough: Multi-Moment Retrieval with Cross-Moment Interactions](https://arxiv.org/abs/2510.17218)
*Zhuo Cao,Heming Du,Bingqing Zhang,Xin Yu,Xue Li,Sen Wang*

Main category: cs.CV

TL;DR: 该论文提出了多时刻检索（MMR）任务，构建了QV-M²数据集和FlashMMR框架，解决了现有单时刻检索方法在现实应用中的不足。

- Motivation: 现有时刻检索方法主要关注单时刻检索，但现实应用中一个查询可能对应多个相关时刻，这使得现有数据集和方法在视频时序定位中不够充分。
- Method: 提出了FlashMMR框架，包含多时刻后验证模块来精炼时刻边界，采用约束时序调整和验证模块重新评估候选片段，通过精细过滤管道修剪低置信度提议并实现鲁棒的多时刻对齐。
- Result: 在QV-M²数据集上，FlashMMR相比之前的最优方法在G-mAP上提升了3.00%，在mAP@3+tgt上提升了2.70%，在mR@3上提升了2.56%。
- Conclusion: QV-M²数据集和FlashMMR方法为推进更现实和具有挑战性的视频时序定位场景研究奠定了基础。


### [126] [Fair and Interpretable Deepfake Detection in Videos](https://arxiv.org/abs/2510.17264)
*Akihito Yoshii,Ryosuke Sonoda,Ramya Srinivasan*

Main category: cs.CV

TL;DR: 提出公平感知的深度伪造检测框架，整合时序特征学习和人口统计感知数据增强，提升公平性和可解释性。

- Motivation: 现有深度伪造检测方法存在偏见、缺乏透明度且无法捕捉时序信息，导致不同人口统计群体的决策偏差和结果不可靠。
- Method: 使用时序特征学习进行深度伪造视频建模，结合概念提取提升检测可靠性；引入人口统计感知数据增强方法平衡少数群体，应用频域变换保留伪造伪影。
- Result: 在FaceForensics++、DFD、Celeb-DF和DFDC数据集上的实验表明，该方法在公平性和准确性之间取得了最佳平衡。
- Conclusion: 所提框架能有效缓解深度伪造检测中的偏见问题，同时保持高检测性能，为公平AI检测提供了可行方案。


### [127] [FineVision: Open Data Is All You Need](https://arxiv.org/abs/2510.17269)
*Luis Wiedmann,Orr Zohar,Amir Mahla,Xiaohan Wang,Rui Li,Thibaud Frere,Leandro von Werra,Aritra Roy Gosthipaty,Andrés Marafioti*

Main category: cs.CV

TL;DR: FineVision是一个精心收集、整理和统一的大规模视觉语言数据集，包含2400万个样本，是同类中最大的开放资源。通过半自动化流程整合了200多个数据源，并进行严格的去重和去污染处理。

- Motivation: 当前视觉语言模型的发展受到碎片化、不一致和受污染公共数据集的阻碍，需要构建一个高质量、统一的大规模数据集来推动研究。
- Method: 采用半自动化、人机协作的流程：自动化处理批量摄入和模式映射，人工审核员检查映射质量、样本多样性和安全性，并进行严格的跨源去重和基准去污染。
- Result: 在FineVision上训练的模型在广泛评估套件中持续优于现有开放混合数据集训练的模型，证明了规模、数据清洁度和人机协作平衡的优势。
- Conclusion: FineVision数据集及其整理工具将加速以数据为中心的视觉语言模型研究，强调了高质量数据收集和整理的重要性。


### [128] [Enhanced Motion Forecasting with Plug-and-Play Multimodal Large Language Models](https://arxiv.org/abs/2510.17274)
*Katie Luo,Jingwei Ji,Tong He,Runsheng Xu,Yichen Xie,Dragomir Anguelov,Mingxing Tan*

Main category: cs.CV

TL;DR: 提出Plug-and-Forecast方法，通过多模态大语言模型增强现有运动预测模型，无需微调即可提升性能

- Motivation: 现有自动驾驶系统在标准条件下表现可靠，但难以经济高效地泛化到多样化现实场景
- Method: 设计提示从MLLMs提取结构化场景理解，将其蒸馏为可学习嵌入来增强行为预测模型
- Result: 在Waymo和nuScenes数据集上验证，两个最先进的运动预测模型均获得一致性能提升
- Conclusion: PnF方法利用MLLMs的零样本推理能力显著改进运动预测性能，且无需微调，实用性强


### [129] [SG-CLDFF: A Novel Framework for Automated White Blood Cell Classification and Segmentation](https://arxiv.org/abs/2510.17278)
*Mehdi Zekriyapanah Gashti,Mostafa Mohammadpour,Ghasem Farjamnia*

Main category: cs.CV

TL;DR: 提出SG-CLDFF框架，通过显著性引导的预处理和多尺度深度特征融合，改进白细胞图像的分割和分类性能，提高鲁棒性和可解释性。

- Motivation: 白细胞显微图像分析对血液疾病诊断至关重要，但面临染色变异、复杂背景和类别不平衡等挑战，需要更鲁棒和可解释的自动化方法。
- Method: 使用显著性先验突出白细胞区域，采用轻量级混合骨干网络生成多分辨率特征表示，通过跨层融合模块整合浅层和深层互补信息，多任务训练结合类别加权损失和显著性对齐正则化。
- Result: 在标准公开数据集上验证，相比CNN和Transformer基线，在IoU、F1和分类准确率上获得一致提升，消融研究证实了显著性预处理和跨层融合的独立贡献。
- Conclusion: SG-CLDFF为临床工作流程提供了实用且可解释的可靠白细胞自动化分析路径。


### [130] [Machine Vision-Based Surgical Lighting System:Design and Implementation](https://arxiv.org/abs/2510.17287)
*Amir Gharghabi,Mahdi Hakiminezhad,Maryam Shafaei,Shaghayegh Gharghabi*

Main category: cs.CV

TL;DR: 提出基于YOLOv11目标检测算法的自动手术照明系统，通过识别蓝色标记自动调整LED光源位置，减少外科医生疲劳并改善照明一致性。

- Motivation: 传统手术照明系统依赖手动调整，导致外科医生疲劳、颈部劳损以及由于漂移和阴影造成的不一致照明问题。
- Method: 使用YOLOv11算法识别手术区域上方的蓝色标记，通过两个伺服电机配合倾斜-平移支架将高功率LED光源对准识别位置。
- Result: YOLO模型在验证集上达到96.7% mAP@50，验证集包含带有蓝色球形标记的模拟手术场景注释图像。
- Conclusion: 这种基于机器视觉的自动化照明解决方案减少了外科医生的身体负担，提高了照明一致性，有助于改善手术效果。


### [131] [Exploring Structural Degradation in Dense Representations for Self-supervised Learning](https://arxiv.org/abs/2510.17299)
*Siran Dai,Qianqian Xu,Peisong Wen,Yang Liu,Qingming Huang*

Main category: cs.CV

TL;DR: 该论文发现自监督学习中存在一个反直觉现象：更长的训练时间反而会损害密集预测任务的性能，称为自监督密集退化(SDD)。作者提出了密集表示结构估计器(DSE)来无监督评估密集任务性能，并基于此提出了模型选择策略和正则化方法。

- Motivation: 观察到自监督学习(SSL)中一个反直觉现象：训练时间越长，密集预测任务(如语义分割)的性能反而下降。这种现象在16种最先进的SSL方法中普遍存在，但缺乏有效的无监督评估方法来检测这种退化。
- Method: 提出了密集表示结构估计器(DSE)，包含类相关性度量和有效维度度量。基于DSE开发了模型选择策略和正则化方法，用于缓解自监督密集退化问题。
- Result: 在16种SSL方法和4个基准测试上的实验表明，模型选择策略平均提升mIoU 3.0%，计算成本可忽略。DSE正则化方法能持续缓解密集退化效应。
- Conclusion: 自监督密集退化是SSL中普遍存在的现象，提出的DSE方法能有效评估密集任务性能并缓解退化问题，为自监督学习在密集预测任务中的应用提供了重要指导。


### [132] [LongInsightBench: A Comprehensive Benchmark for Evaluating Omni-Modal Models on Human-Centric Long-Video Understanding](https://arxiv.org/abs/2510.17305)
*ZhaoYang Han,Qihan Lin,Hao Liang,Bowen Chen,Zhou Liu,Wentao Zhang*

Main category: cs.CV

TL;DR: LongInsightBench是首个专注于评估模型理解长视频能力的基准测试，整合视觉、音频和文本多模态，包含约1000个信息密集的长视频和6个挑战性任务场景。

- Motivation: 现有基准测试在评估模型理解长视频中的人类语言、观点、动作和其他上下文元素方面存在不足，需要开发专门针对长视频多模态理解的基准。
- Method: 从FineVideo数据集中精选约1000个长视频，设计6个挑战性任务场景（包括事件内和事件间任务），并开发三步半自动化数据质量保证流程。
- Result: 实验结果显示全模态模型在需要精确定位和长距离因果推理的任务中仍面临挑战，扩展实验揭示了全模态模型在多模态融合中存在信息丢失和处理偏差。
- Conclusion: LongInsightBench为评估长视频理解能力提供了有效基准，揭示了当前全模态模型在复杂长视频理解任务中的局限性，特别是在时间定位和因果推理方面。


### [133] [CausalMamba: Scalable Conditional State Space Models for Neural Causal Inference](https://arxiv.org/abs/2510.17318)
*Sangyoon Bae,Jiook Cha*

Main category: cs.CV

TL;DR: CausalMamba是一个可扩展的fMRI因果推断框架，通过两阶段方法解决BOLD信号失真和计算复杂性问题，在模拟数据上比DCM准确率高37%，在真实数据中能恢复88%的已知神经通路。

- Motivation: 解决fMRI因果推断中的两个基本限制：从血氧动力学失真的BOLD信号推断神经因果关系的病态性质，以及现有方法（如动态因果建模DCM）的计算不可行性。
- Method: 将复杂逆问题分解为两个可处理阶段：BOLD反卷积恢复潜在神经活动，然后使用新颖的条件Mamba架构进行因果图推断。
- Result: 在模拟数据上比DCM准确率高37%；在真实任务fMRI数据中恢复88%的已知神经通路，而传统方法在99%以上的受试者中无法识别这些典型回路；工作记忆数据的网络分析显示大脑根据刺激策略性地转移其主要因果枢纽。
- Conclusion: 为神经科学家提供了一个实用的工具，用于大规模因果推断，能够捕捉认知功能背后的基本回路模式和灵活网络动态。


### [134] [A Single Set of Adversarial Clothes Breaks Multiple Defense Methods in the Physical World](https://arxiv.org/abs/2510.17322)
*Wei Zhang,Zhanhao Hu,Xiao Li,Xiaopei Zhu,Xiaolin Hu*

Main category: cs.CV

TL;DR: 本文评估了现有对抗防御方法在对抗衣物攻击下的表现，发现这些防御方法在面对大尺寸、自然的对抗衣物时效果不佳，揭示了现有防御方法的共同漏洞。

- Motivation: 实验表明，简单地增大对抗补丁的尺寸就能使现有防御方法失效。对抗衣物不仅尺寸大，而且在人体上看起来更自然，为评估对抗防御方法提供了良好的测试案例。
- Method: 通过制作对抗衣物来测试各种防御方法，包括在数字世界和物理世界中的实验，并制作了一套能够突破多个防御方法的对抗衣物。
- Result: 所有防御方法在对抗衣物攻击下表现都很差。制作的一套对抗衣物在物理世界中，对未防御的检测器实现了96.06%的攻击成功率，对九个防御模型实现了超过64.84%的攻击成功率。
- Conclusion: 现有对抗防御方法在面对对抗衣物时存在共同漏洞，需要开发更有效的防御策略来应对这种大尺寸、自然的物理世界攻击。


### [135] [CharDiff: A Diffusion Model with Character-Level Guidance for License Plate Image Restoration](https://arxiv.org/abs/2510.17330)
*Gyuhwan Park,Kihyun Na,Injung Kim*

Main category: cs.CV

TL;DR: 提出了CharDiff框架，通过字符级引导的扩散模型有效恢复和识别严重退化的车牌图像，在恢复质量和识别准确率上显著优于基线模型。

- Motivation: 车牌图像恢复不仅对LPR系统预处理重要，还能提高证据价值、增强视觉界面清晰度和促进车牌图像的进一步利用。
- Method: 使用基于扩散的框架，通过外部分割和OCR模块提取细粒度字符级先验，并引入CHARM模块确保每个字符的引导仅限于自身区域。
- Result: 在Roboflow-LP数据集上，相比最佳基线模型，CER相对降低了28%，在恢复质量和识别准确率上均显著优于基线模型。
- Conclusion: 结构化字符引导条件化有效增强了基于扩散的车牌恢复和识别在实际部署场景中的鲁棒性。


### [136] [iDETEX: Empowering MLLMs for Intelligent DETailed EXplainable IQA](https://arxiv.org/abs/2510.17332)
*Zhaoran Zhao,Xinli Yue,Jianhui Sun,Yuhao Xie,Tao Shao,Liangchao Yao,Fan Xia,Yuetang Deng*

Main category: cs.CV

TL;DR: 提出了iDETEX，一个统一的多模态大语言模型，能够同时执行质量定位、感知和描述三个关键任务，在ViDA-UGC基准测试中达到最先进性能。

- Motivation: 解决图像质量评估从标量质量预测向更可解释、与人类对齐的评估范式发展的挑战，实现详细且可解释的图像质量评估。
- Method: 设计任务特定的离线增强模块和数据混合策略，辅以在线增强策略充分利用多源监督，构建统一的多模态大语言模型。
- Result: 在ViDA-UGC基准测试中达到最先进性能，在ICCV MIPI 2025详细图像质量评估挑战赛中排名第一。
- Conclusion: iDETEX模型在提供准确且可解释的质量评估方面表现出有效性和鲁棒性。


### [137] [Nearest-Class Mean and Logits Agreement for Wildlife Open-Set Recognition](https://arxiv.org/abs/2510.17338)
*Jiahao Huo,Mufhumudzi Muthivhi,Terence L. van Zyl,Fredrik Gustafsson*

Main category: cs.CV

TL;DR: 提出了一种基于后处理的开放集识别方法，通过比较特征空间中的最近类均值分布和logit空间的softmax概率来衡量模型一致性，无需重新训练预训练模型。

- Motivation: 当前野生动物分类模型在封闭世界设定下训练，面对未知类别时预测过于自信。现有OSR方法大多需要重新训练模型，这限制了其应用。
- Method: 使用后处理策略，基于输入特征到最近类均值的距离构建概率分布，然后与logit空间的softmax概率进行比较来衡量NCM与分类头之间的一致性。
- Result: 在两个数据集上均排名前三，AUROC分别达到93.41（非洲动物）和95.35（瑞典动物），表现稳定优于仅在单一数据集上表现好的现有方法。
- Conclusion: 提出的后处理OSR方法在无需重新训练的情况下实现了稳定且优异的开放集识别性能，为实际应用提供了便利。


### [138] [Exploring The Missing Semantics In Event Modality](https://arxiv.org/abs/2510.17347)
*Jingqian Wu,Shengpeng Xu,Yunbo Jia,Edmund Y. Lam*

Main category: cs.CV

TL;DR: 提出Semantic-E2VID框架，通过跨模态特征对齐和语义感知特征融合，将视觉语义知识从SAM模型迁移到事件编码器，显著提升事件到视频重建的质量。

- Motivation: 事件相机仅捕捉强度变化，忽略静态对象和背景，导致捕获的事件模态缺乏语义信息。现有E2V方法往往忽视语义信息在视频重建中的重要作用。
- Method: 引入跨模态特征对齐模块将SAM的视觉语义知识迁移到事件编码器；提出语义感知特征融合块集成学习到的语义特征；设计语义感知E2V监督利用SAM生成的类别标签。
- Result: 在多个基准测试中显著提升帧质量，优于最先进的E2V方法。
- Conclusion: Semantic-E2VID通过有效利用视觉语义知识，成功解决了事件到视频重建中语义信息缺失的问题，实现了更高质量的视频重建。


### [139] [M2H: Multi-Task Learning with Efficient Window-Based Cross-Task Attention for Monocular Spatial Perception](https://arxiv.org/abs/2510.17363)
*U. V. B. L Udugama,George Vosselman,Francesco Nex*

Main category: cs.CV

TL;DR: M2H是一个多任务学习框架，用于从单目图像同时进行语义分割、深度、边缘和表面法线估计，采用基于窗口的跨任务注意力模块实现高效特征交换，在保持计算效率的同时提升多任务性能。

- Motivation: 在边缘设备上部署实时空间感知需要高效的多任务模型，能够利用互补任务信息同时最小化计算开销。
- Method: 提出Window-Based Cross-Task Attention Module，在轻量级ViT-based DINOv2骨干网络上实现结构化特征交换，保留任务特定细节。
- Result: 在NYUDv2数据集上超越最先进的多任务模型，在Hypersim上超过单任务深度和语义基线，在Cityscapes上表现优异，且在笔记本电脑硬件上保持计算效率。
- Conclusion: M2H作为单目空间感知系统的基础，支持动态环境中的3D场景图构建，并在真实世界数据验证中展现实用性。


### [140] [Recurrent Attention-based Token Selection for Efficient Streaming Video-LLMs](https://arxiv.org/abs/2510.17364)
*Vaggelis Dorovatas,Soroush Seifi,Gunshi Gupta,Rahaf Aljundi*

Main category: cs.CV

TL;DR: 提出一种无需训练的方法，使标准视频大语言模型能够处理流式视频，通过注意力机制选择重要视觉标记、递归处理历史标记和基于描述的问答，在保持性能的同时大幅提升效率。

- Motivation: 现有视频大语言模型需要完整访问视频才能回答问题，但在流式场景下处理小时级长视频时面临实时性挑战，需要一种高效处理流式视频的方法。
- Method: 1) 基于LLM注意力选择重要视觉标记，可丢弃约95%不重要标记；2) 递归处理历史选定标记以保持时序连贯性；3) 基于描述的轻量级问答机制。
- Result: 在流式视频基准测试中达到最先进性能，在效率和效果之间取得良好平衡。
- Conclusion: 该方法为视频大语言模型在流式场景下的应用提供了有效的解决方案，显著提升了处理效率而不牺牲性能。


### [141] [Beyond Real Faces: Synthetic Datasets Can Achieve Reliable Recognition Performance without Privacy Compromise](https://arxiv.org/abs/2510.17372)
*Paweł Borsukiewicz,Fadi Boutros,Iyiola E. Olatunji,Charles Beumier,Wendkûuni C. Ouedraogo,Jacques Klein,Tegawendé F. Bissyandé*

Main category: cs.CV

TL;DR: 该研究首次全面评估合成人脸数据在面部识别中的可行性，发现最佳合成数据集(VariFace、VIGFace)准确率超过真实数据集，同时具备隐私保护、偏见控制等优势。

- Motivation: 解决面部识别系统中使用真实人脸数据带来的隐私和伦理问题，缺乏合成数据可行性的实证证据。
- Method: 系统文献回顾识别25个合成人脸数据集，通过实验验证7个隐私保护关键要求，涉及超过1000万合成样本和5个标准基准测试。
- Result: 最佳合成数据集准确率达95.67%和94.91%，超过CASIA-WebFace(94.70%)等真实数据集，同时保持身份分离性和类内变异性。
- Conclusion: 合成人脸数据是面部识别研究中科学可行且伦理必要的替代方案，提供前所未有的偏见控制能力。


### [142] [Facial Expression-based Parkinson's Disease Severity Diagnosis via Feature Fusion and Adaptive Class Balancing](https://arxiv.org/abs/2510.17373)
*Yintao Zhou,Wei Huang,Zhengyu Li,Jing Huang,Meng Pang*

Main category: cs.CV

TL;DR: 提出了一种基于多表情特征融合和自适应类别平衡的帕金森病严重程度诊断方法，解决了现有方法依赖单一表情和类别不平衡的问题。

- Motivation: 现有基于面部表情的PD诊断方法依赖单一表情类型易导致误诊，且忽略不同PD阶段的类别不平衡问题，大多仅进行二元分类而非严重程度诊断。
- Method: 通过注意力机制融合多种面部表情特征，并采用自适应类别平衡策略动态调整训练样本的贡献度。
- Result: 实验结果表明该方法在PD严重程度诊断方面表现优异，注意力特征融合和自适应类别平衡策略均有效。
- Conclusion: 所提出的多表情特征融合和自适应类别平衡方法能够有效提升PD严重程度诊断的性能。


### [143] [Closed-Loop Transfer for Weakly-supervised Affordance Grounding](https://arxiv.org/abs/2510.17384)
*Jiajin Tang,Zhengxuan Wei,Ge Zheng,Sibei Yang*

Main category: cs.CV

TL;DR: LoopTrans是一个闭环框架，通过双向知识转移（从外中心到自我中心，再返回）来增强可负担性定位，解决了传统单向转移在复杂交互场景中的局限性。

- Motivation: 人类通过观察他人与物体的互动就能理解如何与新颖物体互动，但现有方法仅从外中心图像单向转移到自我中心图像，限制了在复杂交互场景中的应用。
- Method: 提出LoopTrans闭环框架，包含统一跨模态定位和去噪知识蒸馏机制，实现外中心与自我中心图像间的双向知识转移。
- Result: 实验表明LoopTrans在所有图像和视频基准测试指标上均取得一致改进，甚至能处理人体完全遮挡物体交互区域的挑战性场景。
- Conclusion: LoopTrans通过闭环双向知识转移有效解决了可负担性定位中的领域差距问题，在复杂交互场景中表现出色。


### [144] [Monitoring Horses in Stalls: From Object to Event Detection](https://arxiv.org/abs/2510.17409)
*Dmitrii Galimzianov,Viacheslav Vyshegorodtsev,Ivan Nezhivykh*

Main category: cs.CV

TL;DR: 开发了一个基于视觉的自动化系统，用于监测马厩中马匹和人的行为，使用YOLOv11和BoT-SORT进行目标检测和跟踪，能识别五种事件类型并处理摄像头盲区问题。

- Motivation: 传统马匹行为监测方法劳动密集且耗时，需要自动化系统来早期发现健康福利问题。
- Method: 使用YOLOv11进行目标检测，BoT-SORT进行多目标跟踪，基于目标轨迹和空间关系推断事件状态，利用CLIP和GroundingDINO构建自定义数据集。
- Result: 定性评估显示系统在马匹相关事件检测上表现可靠，但人员检测因数据稀缺存在局限性。
- Conclusion: 该工作为马场实时行为监测奠定了基础，对动物福利和厩舍管理具有重要意义。


### [145] [DeepDetect: Learning All-in-One Dense Keypoints](https://arxiv.org/abs/2510.17422)
*Shaharyar Ahmed Khan Tareen,Filza Khan Tareen*

Main category: cs.CV

TL;DR: DeepDetect是一个智能、一体化的密集关键点检测器，通过融合多种传统检测器的输出创建真实标签，训练轻量级ESPNet模型，在关键点密度、重复性和匹配数量方面超越现有方法。

- Motivation: 现有关键点检测方法（传统和基于学习的）存在对光度变化敏感、关键点密度和重复性低、对挑战性场景适应性有限、缺乏语义理解等问题，无法优先处理视觉重要区域。
- Method: 融合7种关键点检测器和2种边缘检测器的输出创建真实标签掩码，提取多样视觉特征，然后使用这些掩码作为标签训练轻量高效的ESPNet模型。
- Result: 在Oxford Affine Covariant Regions数据集上的评估显示，DeepDetect在关键点密度（0.5143）、重复性（0.9582）和正确匹配数量（59,003）方面均达到最大值，超越其他检测器。
- Conclusion: DeepDetect通过深度学习统一传统检测器的优势，能够语义地聚焦图像，产生高密度关键点，并适应多样化和视觉退化条件。


### [146] [Leveraging AV1 motion vectors for Fast and Dense Feature Matching](https://arxiv.org/abs/2510.17434)
*Julien Zouein,Hossein Javidnia,François Pitié,Anil Kokaram*

Main category: cs.CV

TL;DR: 利用AV1运动向量生成密集亚像素对应关系和经过余弦一致性过滤的短轨迹，在压缩域中实现高效的图像匹配前端

- Motivation: 探索压缩域对应关系作为资源高效的前端解决方案，为完整视觉流水线提供可扩展路径
- Method: 重新利用AV1运动向量生成密集亚像素对应关系，并通过余弦一致性过滤短轨迹
- Result: 在短视频上运行性能与顺序SIFT相当但CPU使用更少，产生更密集的匹配和具有竞争力的成对几何；在117帧片段上重建46-62万点，重投影误差0.51-0.53像素
- Conclusion: 压缩域对应关系是实用且资源高效的前端，具有在完整流水线中扩展的清晰路径


### [147] [Rethinking Nighttime Image Deraining via Learnable Color Space Transformation](https://arxiv.org/abs/2510.17440)
*Qiyuan Guan,Xiang Chen,Guiyue Jin,Jiyu Jin,Shumin Fan,Tianyu Song,Jinshan Pan*

Main category: cs.CV

TL;DR: 提出了一个新的高质量夜间图像去雨基准数据集HQ-NightRain，并开发了颜色空间转换网络CST-Net，通过可学习的颜色空间转换器和隐式光照引导来更好地去除夜间复杂雨纹。

- Motivation: 夜间图像去雨相比白天更具挑战性，因为夜间场景的固有复杂性以及缺乏准确表示雨和光照耦合效应的高质量数据集。
- Method: 开发了颜色空间转换网络CST-Net，包含可学习的颜色空间转换器在Y通道进行雨纹去除，并引入隐式光照引导来捕获光照信息。
- Result: 广泛的实验证明了所提出数据集的价值和方法的有效性。
- Conclusion: 提出的HQ-NightRain数据集和CST-Net方法为夜间图像去雨任务提供了更好的解决方案，在复杂夜间场景中表现出更强的鲁棒性。


### [148] [Initialize to Generalize: A Stronger Initialization Pipeline for Sparse-View 3DGS](https://arxiv.org/abs/2510.17479)
*Feng Zhou,Wenkai Guo,Pu Cao,Zhicheng Zhang,Jianqin Yin*

Main category: cs.CV

TL;DR: 本文提出了一种改进稀疏视图3D高斯泼溅(3DGS)初始化的方法，通过频率感知SfM、3DGS自初始化和点云正则化来提升稀疏视图下的3D重建质量。

- Motivation: 稀疏视图3DGS容易过拟合训练视图，导致新视角渲染出现模糊等伪影。现有方法通过增强初始化或添加训练约束来解决，但实验表明初始化是决定性因素，决定了性能上限，而训练约束只能带来有限的改进。
- Method: 1. 频率感知SfM：通过低频视图增强和宽松的多视图对应关系改善低纹理区域的覆盖；2. 3DGS自初始化：利用光度监督生成额外点，补偿SfM稀疏区域；3. 点云正则化：通过几何/可见性先验强制多视图一致性和均匀空间覆盖。
- Result: 在LLFF和Mip-NeRF360数据集上的实验表明，该方法在稀疏视图设置下取得了持续的性能提升，证明了其作为更强初始化策略的有效性。
- Conclusion: 初始化是稀疏视图3DGS的关键因素，提出的方法通过改进SfM初始化、自初始化和点云正则化，显著提升了稀疏视图下的3D重建质量。


### [149] [SparseWorld: A Flexible, Adaptive, and Efficient 4D Occupancy World Model Powered by Sparse and Dynamic Queries](https://arxiv.org/abs/2510.17482)
*Chenxu Dang,Haiyan Liu,Guangjun Bao,Pei An,Xinyue Tang,Jie Ma,Bingchuan Sun,Yan Wang*

Main category: cs.CV

TL;DR: SparseWorld是一个基于稀疏动态查询的4D占用世界模型，通过范围自适应感知和状态条件预测模块，解决了现有占用模型固定嵌入和网格分类的限制，实现了灵活、自适应和高效的场景理解。

- Motivation: 现有占用世界模型依赖静态固定嵌入或网格，限制了感知的灵活性，且其网格分类方法与真实场景的动态连续性存在潜在不匹配。
- Method: 提出范围自适应感知模块，通过可学习查询结合车辆状态调制和时空关联实现扩展范围感知；设计状态条件预测模块，用回归引导的预测替代基于分类的预测；开发时间感知自调度训练策略。
- Result: 在感知、预测和规划任务上达到最先进性能，验证了模型在灵活性、适应性和效率方面的优势。
- Conclusion: SparseWorld通过稀疏动态查询成功解决了现有占用模型的局限性，为4D环境理解提供了更灵活、自适应和高效的解决方案。


### [150] [Split-Fuse-Transport: Annotation-Free Saliency via Dual Clustering and Optimal Transport Alignment](https://arxiv.org/abs/2510.17484)
*Muhammad Umer Ramzan,Ali Zia,Abdelwahed Khamis,Noman Ali,Usman Ali,Wei Xiang*

Main category: cs.CV

TL;DR: POTNet通过熵引导的双聚类头和最优传输技术生成高质量伪掩码，AutoSOD基于此构建了无需像素级标注的端到端显著目标检测系统，性能接近全监督方法。

- Motivation: 显著目标检测作为计算机视觉基础任务，需要大量像素级标注。作者认为当有可靠伪掩码时，无监督方法可以达到接近全监督的精度。
- Method: 提出POTNet，用熵引导的双聚类头替代传统k-means：高熵像素用谱聚类，低熵像素用k-means，然后通过最优传输对齐两个原型集，生成更清晰的伪掩码。
- Result: AutoSOD在五个基准测试中，F-measure比无监督方法提升26%，比弱监督方法提升36%，显著缩小了与全监督模型的差距。
- Conclusion: 通过改进原型质量和全局一致性约束，无监督显著目标检测可以达到接近全监督的性能，无需像素级标注。


### [151] [Context-Aware Pseudo-Label Scoring for Zero-Shot Video Summarization](https://arxiv.org/abs/2510.17501)
*Yuanli Wu,Long Zhang,Yue Du,Bin Li*

Main category: cs.CV

TL;DR: 提出了一种基于评分标准引导的伪标签提示框架，将少量真实标注转化为高置信度伪标签，构建结构化、数据集自适应的评分标准来指导可解释的场景评估。

- Motivation: 现有监督方法标注成本高且跨数据集泛化能力有限，无监督方法难以捕捉高层次语义和细粒度叙事线索，零样本提示方法对人工提示模板敏感且依赖数据集特定分数归一化。
- Method: 使用评分标准引导的伪标签提示框架，将少量真实标注转化为伪标签并聚合为评分标准。推理时，首尾片段仅基于描述评分，中间片段结合相邻场景的上下文摘要来评估叙事进展和冗余度。
- Result: 在SumMe和TVSum数据集上分别达到57.58和63.05的F1分数，超越了无监督和先前的零样本基线方法，接近监督方法的性能。
- Conclusion: 评分标准引导的伪标签方法有效稳定了基于LLM的评分，为视频摘要建立了一个通用、可解释的零样本范式。


### [152] [MUG-V 10B: High-efficiency Training Pipeline for Large Video Generation Models](https://arxiv.org/abs/2510.17519)
*Yongshun Zhang,Zhongyi Fan,Yonghang Zhang,Zhangzikang Li,Weifeng Chen,Zhongwei Feng,Chaoyue Wang,Peng Hou,Anxiang Zeng*

Main category: cs.CV

TL;DR: 提出了一个优化视频生成模型训练的框架，涵盖数据处理、模型架构、训练策略和基础设施四个支柱，实现了MUG-V 10B模型，在电商视频生成任务上超越开源基线，并开源了完整技术栈。

- Motivation: 解决大规模视频生成模型训练面临的挑战，包括跨模态文本-视频对齐、长序列处理和复杂时空依赖，这些因素导致训练特别困难和资源密集。
- Method: 通过优化四个支柱：数据处理、模型架构、训练策略和基础设施，具体包括数据预处理、视频压缩、参数缩放、基于课程学习的预训练和对齐导向的后训练。
- Result: MUG-V 10B模型在整体性能上匹配最新的SOTA视频生成器，在电商视频生成任务上通过人工评估超越了领先的开源基线。
- Conclusion: 成功开发了高效的大规模视频生成训练框架，实现了性能提升和效率增益，并开源了完整技术栈，包括模型权重、基于Megatron-Core的大规模训练代码和推理流水线。


### [153] [MambaX-Net: Dual-Input Mamba-Enhanced Cross-Attention Network for Longitudinal MRI Segmentation](https://arxiv.org/abs/2510.17529)
*Yovin Yahathugoda,Davide Prezzi,Piyalitt Ittichaiwong,Vicky Goh,Sebastien Ourselin,Michela Antonelli*

Main category: cs.CV

TL;DR: 提出了MambaX-Net，一种用于前列腺癌主动监测的半监督双扫描3D分割架构，利用时间序列MRI数据改进前列腺区域分割。

- Motivation: 解决主动监测中纵向分析面临的挑战：现有模型基于单时间点训练，无法有效处理多时间点数据，且专家标注稀缺。
- Method: 使用Mamba增强的交叉注意力模块捕获时间演化和长距离空间依赖；形状提取器模块编码先前分割掩码；结合半监督自训练策略利用伪标签。
- Result: 在纵向主动监测数据集上显著优于最先进的U-Net和Transformer模型，即使在有限和噪声数据下也能实现优越的前列腺区域分割。
- Conclusion: MambaX-Net为前列腺癌主动监测提供了一种有效的纵向分割解决方案，能够利用时间序列信息改进分割性能。


### [154] [WP-CrackNet: A Collaborative Adversarial Learning Framework for End-to-End Weakly-Supervised Road Crack Detection](https://arxiv.org/abs/2510.17566)
*Nachuan Ma,Zhengfei Song,Qiang Hu,Xiaoyu Tang,Chengxi Zhang,Rui Fan,Lihua Xie*

Main category: cs.CV

TL;DR: WP-CrackNet是一种弱监督的道路裂缝检测方法，仅使用图像级标签就能实现像素级检测，通过分类器、重建器和检测器的对抗学习机制提升检测性能。

- Motivation: 为了减少对昂贵像素级标注的依赖，开发一种仅需图像级标签的弱监督道路裂缝检测方法，以支持智能城市基础设施维护的可扩展性。
- Method: 集成三个组件：分类器生成类激活图（CAMs），重建器测量特征可推断性，检测器生成像素级结果。通过对抗学习和路径感知注意力模块（PAAM）融合高低层特征，使用中心增强CAM一致性模块（CECCM）优化伪标签生成。
- Result: 在三个自建数据集上的实验表明，WP-CrackNet达到与监督方法相当的结果，优于现有弱监督方法，显著推进了可扩展道路检测。
- Conclusion: WP-CrackNet通过弱监督学习有效解决了道路裂缝检测问题，在减少标注成本的同时保持了高检测精度，为智能基础设施维护提供了实用解决方案。


### [155] [PAGE-4D: Disentangled Pose and Geometry Estimation for 4D Perception](https://arxiv.org/abs/2510.17568)
*Kaichen Zhou,Yuhan Wang,Grace Chen,Xinhai Chang,Gaspard Beaudouin,Fangneng Zhan,Paul Pu Liang,Mengyu Wang*

Main category: cs.CV

TL;DR: PAGE-4D是一个前馈模型，将VGGT扩展到动态场景，能够同时进行相机姿态估计、深度预测和点云重建，无需后处理。

- Motivation: 现有的3D前馈模型（如VGGT）在静态数据集上训练，难以处理真实世界中复杂的动态元素，如移动的人类或可变形物体。
- Method: 提出动态感知聚合器，通过预测动态感知掩码来解耦静态和动态信息：抑制运动线索用于姿态估计，增强运动线索用于几何重建。
- Result: 在动态场景中，PAGE-4D始终优于原始VGGT，在相机姿态估计、单目和视频深度估计以及密集点图重建方面取得更优结果。
- Conclusion: PAGE-4D成功解决了多任务4D重建中的任务冲突问题，在动态场景下表现出色。


### [156] [Expose Camouflage in the Water: Underwater Camouflaged Instance Segmentation and Dataset](https://arxiv.org/abs/2510.17585)
*Chuhong Wang,Hua Li,Chongyi Li,Huazhong Liu,Xiongxin Tang,Sam Kwong*

Main category: cs.CV

TL;DR: 提出了首个水下伪装实例分割数据集UCIS4K和基于SAM的UCIS-SAM网络，通过三个关键模块解决水下环境中的颜色失真、低对比度和模糊问题，在伪装实例分割任务上优于现有方法。

- Motivation: 传统伪装实例分割方法在陆地数据集上训练，对水下环境的颜色失真、低对比度和模糊问题处理不足，导致在水下场景中性能不佳。
- Method: 提出UCIS-SAM网络，包含三个模块：通道平衡优化模块(CBOM)增强水下特征学习，频率域真值整合模块(FDTIM)强调内在物体特征减少伪装干扰，多尺度特征频率聚合模块(MFFAM)强化低对比度伪装实例边界。
- Result: 在提出的UCIS4K数据集和公共基准测试上的广泛实验表明，UCIS-SAM优于最先进的方法。
- Conclusion: UCIS-SAM网络通过专门设计的水下特征增强和频率域处理模块，有效解决了水下伪装实例分割的挑战，取得了优越的性能。


### [157] [ShapeCraft: LLM Agents for Structured, Textured and Interactive 3D Modeling](https://arxiv.org/abs/2510.17603)
*Shuyuan Zhang,Chenhan Jiang,Zuoou Li,Jiankang Deng*

Main category: cs.CV

TL;DR: ShapeCraft是一个多智能体框架，将3D资产表示为形状程序，通过图结构分解复杂自然语言，生成结构化、可交互的3D模型。

- Motivation: 解决现有文本到3D生成方法产生非结构化网格和交互性差的问题，使其更适合艺术工作流程。
- Method: 提出基于图的程序形状表示，使用LLM智能体分层解析用户输入，迭代优化程序建模和绘制过程。
- Result: 在定性和定量实验中表现出色，能生成几何精确且语义丰富的3D资产，支持动画和用户自定义编辑。
- Conclusion: ShapeCraft展示了在交互应用中的潜力，为文本到3D生成提供了更实用的解决方案。


### [158] [Integrating BIM and UAV-based photogrammetry for Automated 3D Structure Model Segmentation](https://arxiv.org/abs/2510.17609)
*Siqi Chen,Shanyue Guan*

Main category: cs.CV

TL;DR: 提出基于机器学习的框架，利用无人机扫描点云和BIM合成数据的互补优势，实现3D点云自动分割，解决基础设施结构健康监测中手动标注耗时且易错的问题。

- Motivation: 无人机技术结合摄影测量能够高效获取基础设施高分辨率3D模型，但传统手动分割结构组件的方法耗时且易出错，需要自动化解决方案。
- Method: 使用真实无人机扫描点云与BIM生成的合成数据相结合，利用机器学习框架进行3D点云自动分割，通过小规模数据集和BIM数据补充减少训练时间。
- Result: 在铁路轨道数据集验证中，框架能高精度识别和分割主要组件（如铁轨和枕木），使用小规模数据集和BIM数据补充时显著减少训练时间，同时保持合理的分割精度。
- Conclusion: 该自动化方法提高了3D基础设施模型分割的精度和效率，推动了无人机与BIM技术在结构健康监测和基础设施管理中的集成应用。


### [159] [One Dinomaly2 Detect Them All: A Unified Framework for Full-Spectrum Unsupervised Anomaly Detection](https://arxiv.org/abs/2510.17611)
*Jia Guo,Shuai Lu,Lei Fan,Zelin Li,Donglin Di,Yang Song,Weihang Zhang,Wenbing Zhu,Hong Yan,Fang Chen,Huiqi Li,Hongen Liao*

Main category: cs.CV

TL;DR: Dinomaly2是一个统一的图像异常检测框架，通过五个简单元素的组合在标准重建框架中实现卓越性能，在多个基准测试中表现出全谱优势。

- Motivation: 解决现有多类异常检测模型性能不足的问题，以及该领域方法碎片化导致的部署障碍，需要一个统一的解决方案。
- Method: 基于"少即是多"理念，在标准重建框架中协调五个简单元素，实现方法论的极简主义，无需修改即可自然扩展到各种任务。
- Result: 在12个异常检测基准测试中表现出全谱优势，多类模型在MVTec-AD和VisA上分别达到99.9%和99.3%的图像级AUROC，少样本情况下仅用8个正常样本就超越了之前的全样本模型。
- Conclusion: Dinomaly2通过极简设计、计算可扩展性和通用适用性，成为现实世界异常检测应用的统一解决方案。


### [160] [CaMiT: A Time-Aware Car Model Dataset for Classification and Generation](https://arxiv.org/abs/2510.17626)
*Frédéric LIN,Biruk Abere Ambaw,Adrian Popescu,Hejer Ammar,Romaric Audigier,Hervé Le Borgne*

Main category: cs.CV

TL;DR: CaMiT是一个细粒度数据集，捕捉汽车模型随时间演变的过程，支持监督和自监督学习。研究表明静态预训练在跨年测试时准确性下降，提出了时间增量分类设置和两种策略来提升时间鲁棒性，并探索了时间感知图像生成。

- Motivation: AI系统需要适应不断变化的视觉环境，特别是在物体外观随时间变化的领域。汽车模型作为技术产品的代表类别，其演变过程需要被研究。
- Method: 构建CaMiT数据集（787K标注样本和5.1M未标注样本），采用静态预训练和时间增量分类设置，评估时间增量预训练和时间增量分类器学习两种策略，并探索时间感知图像生成。
- Result: 静态预训练在领域内数据上能达到与大规模通用模型竞争的性能且更高效，但跨年测试时准确性下降。时间增量策略能改善时间鲁棒性，时间感知图像生成能产生更真实的输出。
- Conclusion: CaMiT为研究细粒度视觉识别和生成中的时间适应问题提供了丰富的基准，提出的时间增量方法能有效提升模型在动态环境中的适应性。


### [161] [Self-supervised Pre-training for Mapping of Archaeological Stone Wall in Historic Landscapes Using High-Resolution DEM Derivatives](https://arxiv.org/abs/2510.17644)
*Zexian Huang,Mashnoon Islam,Brian Armstrong,Kourosh Khoshelham,Martin Tomko*

Main category: cs.CV

TL;DR: 提出DINO-CV框架，使用高分辨率LiDAR DEM和自监督跨视图预训练策略，自动映射植被遮挡下的干石墙，在数据稀缺情况下实现高效分割。

- Motivation: 干石墙具有重要遗产和环境价值，但传统方法难以识别被植被遮挡的低矮墙体，且标注数据有限，需要开发可扩展的自动映射解决方案。
- Method: 使用LiDAR DEM克服植被遮挡，提出基于知识蒸馏的自监督跨视图预训练策略，学习多DEM衍生物的视觉和几何表示，支持多种视觉骨干网络。
- Result: 在Budj Bim UNESCO遗产地测试，达到68.6% mIoU，仅用10%标注数据微调后仍保持63.8% mIoU，成功识别澳大利亚最密集的殖民时期干石墙。
- Conclusion: 自监督学习结合高分辨率DEM衍生物在植被覆盖和标注稀缺的遗产环境中具有自动映射干石墙的巨大潜力。


### [162] [Frugal Federated Learning for Violence Detection: A Comparison of LoRA-Tuned VLMs and Personalized CNNs](https://arxiv.org/abs/2510.17651)
*Sébastien Thuau,Siba Haidar,Ayush Bajracharya,Rachid Chelouah*

Main category: cs.CV

TL;DR: 该论文比较了两种节俭的联邦学习方法用于暴力检测：基于视觉语言模型(VLM)的零样本/联邦微调，以及紧凑3D卷积神经网络(CNN3D)的个性化训练。两种方法准确率均超过90%，CNN3D在ROC AUC和能量效率方面略优，而VLM在上下文推理方面更佳。

- Motivation: 研究旨在开发资源高效、环境友好的暴力检测方法，在非独立同分布数据设置下比较不同方法的性能、校准和能耗，为视频监控提供负责任的人工智能解决方案。
- Method: 使用LLaVA-7B视觉语言模型和65.8M参数CNN3D，分别采用零样本/联邦微调(LoRA)和个性化训练策略，在联邦学习框架下评估准确率、校准、能耗和二氧化碳排放。
- Result: 两种方法准确率均超过90%，CNN3D在ROC AUC和log loss方面略优于LoRA调优的VLM，且能耗更低。VLM在上下文推理和多模态推理方面保持优势。
- Conclusion: 建议采用混合模型：轻量级CNN用于常规分类，选择性激活VLM处理复杂场景。该框架为视频监控提供了可复现的、资源感知的AI基准，支持实时、多模态和生命周期感知系统。


### [163] [4DSegStreamer: Streaming 4D Panoptic Segmentation via Dual Threads](https://arxiv.org/abs/2510.17664)
*Ling Liu,Jun Tian,Li Yi*

Main category: cs.CV

TL;DR: 4DSegStreamer是一个用于4D全景分割的流式处理框架，采用双线程系统在受限时间预算内实现实时细粒度感知，特别适用于高动态环境。

- Motivation: 解决高动态环境（如密集人群疏散、复杂自动驾驶场景）中需要实时、细粒度感知的问题，现有方法在实时性和鲁棒性方面存在不足。
- Method: 采用双线程系统：预测线程利用历史运动和几何信息提取特征并预测未来动态；推理线程通过对齐最新记忆并补偿自运动和动态物体移动来确保对输入帧的及时预测。
- Result: 在室内HOI4D数据集和室外SemanticKITTI、nuScenes数据集上的实验表明，该方法有效提升了实时性能，特别是在高FPS条件下表现出优越的鲁棒性，能准确预测复杂场景中的动态物体。
- Conclusion: 4DSegStreamer是一个通用框架，可无缝集成到现有3D和4D分割方法中实现实时能力，在动态物体预测方面表现优异。


### [164] [PICABench: How Far Are We from Physically Realistic Image Editing?](https://arxiv.org/abs/2510.17681)
*Yuandong Pu,Le Zhuo,Songhao Han,Jinbo Xing,Kaiwen Zhu,Shuo Cao,Bin Fu,Si Liu,Hongsheng Li,Yu Qiao,Wenlong Zhang,Xi Chen,Yihao Liu*

Main category: cs.CV

TL;DR: PICABench是一个评估图像编辑物理真实性的基准，涵盖光学、力学和状态转换等8个子维度，并提出了可靠的评估协议PICAEval。研究发现当前主流模型在物理真实性方面仍有很大提升空间。

- Motivation: 现有图像编辑模型主要关注指令完成度，但忽略了伴随的物理效应（如阴影、反射、物体间相互作用），这对生成的真实性至关重要。
- Method: 提出了PICABench基准系统评估物理真实性，使用PICAEval评估协议（基于VLM-as-a-judge和人工标注），并构建了PICA-100K训练数据集从视频中学习物理知识。
- Result: 评估主流模型后发现，物理真实性仍然是一个具有挑战性的问题，存在很大的改进空间。
- Conclusion: 该研究为从简单内容编辑向物理一致的真实性转变提供了基准和解决方案基础，推动了图像编辑向更高真实感发展。


### [165] [Intelligent Communication Mixture-of-Experts Boosted-Medical Image Segmentation Foundation Model](https://arxiv.org/abs/2510.17684)
*Xinwei Zhang,Hu Chen,Zhe Yuan,Sukun Tian,Peng Feng*

Main category: cs.CV

TL;DR: 提出IC-MoE模型，通过混合专家架构和语义引导对比学习解决医学图像分割中高层特征表示不足和预训练权重结构完整性破坏的问题。

- Motivation: 现有医学图像分割基础模型微调方法存在两个关键问题：高层特征表示不足，以及微调过程破坏预训练权重的结构完整性。
- Method: 1) 构建基础专家、语义专家和自适应专家，采用像素概率自适应投票策略进行专家选择和融合；2) 提出语义引导对比学习方法解决对比学习中弱监督问题。
- Result: 在三个公共医学图像分割数据集上的实验表明，IC-MoE优于其他最先进模型，并在不同医学图像分割场景中展现出优异的泛化能力。
- Conclusion: IC-MoE有效补充了基础医学图像分割模型的高层特征表示能力，同时保持了预训练权重的结构完整性。


### [166] [Multilingual Text-to-Image Person Retrieval via Bidirectional Relation Reasoning and Aligning](https://arxiv.org/abs/2510.17685)
*Min Cao,Xinyu Zhou,Ding Jiang,Bo Du,Mang Ye,Min Zhang*

Main category: cs.CV

TL;DR: 本文提出了多语言文本到图像行人检索任务，开发了Bi-IRRA框架，通过双向隐式关系推理和多维全局对齐来解决模态异质性问题，在多语言TIPR数据集上取得了最先进的结果。

- Motivation: 现有文本到图像行人检索方法存在模态异质性挑战，全局方法忽略细粒度差异，局部方法需要先验信息，且当前方法主要针对英语，限制了在多语言环境中的应用。
- Method: 提出Bi-IRRA框架：包含双向隐式关系推理模块（通过双向掩码预测增强跨语言和跨模态的局部关系建模）和多维全局对齐模块（解决模态异质性）。
- Result: 在所有多语言TIPR数据集上都取得了新的最先进结果。
- Conclusion: Bi-IRRA框架有效解决了多语言文本到图像行人检索中的模态异质性问题，为多语言环境下的行人检索提供了有效解决方案。


### [167] [Towards 3D Objectness Learning in an Open World](https://arxiv.org/abs/2510.17686)
*Taichi Liu,Zhenyu Wang,Ruofeng Liu,Guang Wang,Desheng Zhang*

Main category: cs.CV

TL;DR: OP3Det是一个无需文本提示的开放世界3D检测器，通过结合2D语义先验和3D几何先验，利用跨模态专家混合动态路由特征，实现通用3D物体检测。

- Motivation: 传统闭集3D检测器难以泛化到开放世界场景，而直接引入3D开放词汇模型又面临词汇扩展和语义重叠问题，需要研究学习通用3D物体性的方法。
- Method: 提出OP3Det，利用2D基础模型的强泛化能力，结合2D语义先验和3D几何先验生成类别无关建议，通过跨模态专家混合动态路由单模态和多模态特征。
- Result: 在广泛实验中，OP3Det显著超越现有开放世界3D检测器达16.0%的AR提升，相比闭集3D检测器也有13.5%的改进。
- Conclusion: OP3Det通过结合2D和3D先验以及跨模态特征路由，成功实现了开放世界3D物体检测，在检测新颖物体方面表现出色。


### [168] [GAS: Improving Discretization of Diffusion ODEs via Generalized Adversarial Solver](https://arxiv.org/abs/2510.17699)
*Aleksandr Oganov,Ilya Bykov,Eva Neudachina,Mishan Aliev,Alexander Tolmachev,Alexander Sidorov,Aleksandr Zuev,Andrey Okhotin,Denis Rakitin,Aibek Alanov*

Main category: cs.CV

TL;DR: 提出了广义对抗求解器（GAS），一种结合蒸馏损失和对抗训练的ODE求解器参数化方法，在保持简单性的同时提升细节保真度和生成质量。

- Motivation: 扩散模型虽然生成质量优秀，但采样计算成本高昂。现有方法依赖复杂训练技巧且未显式关注细节保真度。
- Method: 提出广义求解器参数化ODE采样器，无需额外训练技巧；结合蒸馏损失与对抗训练以减轻伪影并增强细节保真度。
- Result: 在相似资源约束下，相比现有求解器训练方法表现出更优越的性能。
- Conclusion: 广义对抗求解器在保持简单性的同时，有效提升了扩散模型采样效率和质量。


### [169] [Elastic ViTs from Pretrained Models without Retraining](https://arxiv.org/abs/2510.17700)
*Walter Simoncini,Michael Dorkenwald,Tijmen Blankevoort,Cees G. M. Snoek,Yuki M. Asano*

Main category: cs.CV

TL;DR: SnapViT是一种后预训练结构化剪枝方法，能在不同计算预算下实现弹性推理，无需重训练或标签数据，5分钟内生成可调整的弹性模型。

- Motivation: 现有视觉基础模型只有有限的预定义尺寸，无法灵活适应实际部署中的计算约束，需要一种能生成连续计算预算模型的剪枝方法。
- Method: 结合梯度信息与跨网络结构相关性（通过进化算法近似），使用自监督重要性评分机制，无需分类头即可通用化，且无需重训练。
- Result: 在DINO、SigLIPv2、DeIT和AugReg模型上验证，在各种稀疏度下优于现有方法，单A100 GPU不到5分钟生成弹性模型。
- Conclusion: 提出了一种高效的视觉Transformer剪枝策略，包括新颖的Hessian非对角结构进化近似和自监督重要性评分，无需重训练或标签即可保持强性能。


### [170] [Improving Cross-Patient Generalization in Parkinson's Disease Detection through Chunk-Based Analysis of Hand-Drawn Patterns](https://arxiv.org/abs/2510.17703)
*Mhd Adnan Albani,Riad Sonbol*

Main category: cs.CV

TL;DR: 提出一种两阶段方法检测帕金森病，通过图像分块和集成学习提高对未见患者数据的鲁棒性，在NewHandPD数据集上达到97.08%的准确率（已知患者）和94.91%（未知患者）。

- Motivation: 现有帕金森病早期检测方法存在两个主要局限：数据集不足和对未见患者数据的鲁棒性差。
- Method: 两阶段方法：第一阶段按绘图类型分类（圆形、波浪线、螺旋），第二阶段将图像分为2x2块，分别提取特征并检测帕金森病指标，最后使用集成方法合并各块决策。
- Result: 在NewHandPD数据集上，已知患者准确率97.08%，未知患者94.91%，性能差距仅2.17个百分点，优于现有方法的4.76个百分点下降。
- Conclusion: 提出的分块策略和集成方法有效提高了帕金森病检测的鲁棒性，特别是在处理未见患者数据时表现优异。


### [171] [Automatic Classification of Circulating Blood Cell Clusters based on Multi-channel Flow Cytometry Imaging](https://arxiv.org/abs/2510.17716)
*Suqiang Ma,Subhadeep Sengupta,Yao Lee,Beikang Gu,Xianyan Chen,Xianqiao Wang,Yang Liu,Mengjia Xu,Galit H. Frydman,He Li*

Main category: cs.CV

TL;DR: 开发了一个自动分析循环血细胞簇图像的计算框架，通过YOLOv11模型分类细胞簇，并结合多通道荧光染色识别细胞类型，准确率超过95%。

- Motivation: 现有机器学习方法主要针对单细胞流式细胞术图像分析，缺乏自动分析不规则形状和异质性细胞簇的工具，而细胞簇是血栓、感染和炎症的重要生物标志物。
- Method: 采用两步分析策略：首先微调YOLOv11模型将图像分类为细胞簇和非细胞簇，然后通过叠加簇轮廓与多通道荧光染色区域来识别细胞类型。
- Result: 在细胞簇分类和表型识别方面均达到超过95%的准确率，优于传统CNN和ViT模型。
- Conclusion: 该自动化框架有效分析流式细胞术中的细胞簇图像，利用明场和荧光数据，具有扩展到免疫和肿瘤细胞簇分析的潜力。


### [172] [Raindrop GS: A Benchmark for 3D Gaussian Splatting under Raindrop Conditions](https://arxiv.org/abs/2510.17719)
*Zhiqiang Teng,Beibei Lin,Tingting Chen,Zifeng Yuan,Xuanyi Li,Xuanyu Zhang,Shunli Zhang*

Main category: cs.CV

TL;DR: RaindropGS是一个用于评估3D高斯溅射在雨滴条件下性能的综合基准，包含真实世界雨滴重建数据集，揭示了现有方法在无约束雨滴图像上的局限性。

- Motivation: 解决3D高斯溅射在雨滴条件下因镜头污染导致的严重遮挡和光学畸变问题，现有基准通常使用合成雨滴图像且假设理想条件，无法反映真实场景中雨滴对相机姿态估计和点云初始化的干扰。
- Method: 提出RaindropGS基准，包含数据准备、数据处理和雨滴感知3DGS评估三个部分，收集真实世界雨滴重建数据集，包含雨滴聚焦、背景聚焦和无雨地面实况三种对齐图像集。
- Result: 通过综合实验揭示了现有3DGS方法在无约束雨滴图像上的性能限制，以及不同管道组件的影响：相机焦点位置对重建性能的影响，不准确的姿态和点云初始化对重建的干扰。
- Conclusion: 这些发现为开发在雨滴条件下更鲁棒的3DGS方法提供了明确方向，建立了全面的评估基准来应对真实世界雨滴干扰问题。


### [173] [MT-Video-Bench: A Holistic Video Understanding Benchmark for Evaluating Multimodal LLMs in Multi-Turn Dialogues](https://arxiv.org/abs/2510.17722)
*Yaning Pan,Zekun Wang,Qianqian Xie,Yongqian Wen,Yuanxing Zhang,Guohui Zhang,Haoxuan Hu,Zhiyu Pan,Yibing Huang,Zhidong Gan,Yonghong Lin,An Ping,Tianhao Peng,Jiaheng Liu*

Main category: cs.CV

TL;DR: 提出了MT-Video-Bench，一个用于评估多模态大语言模型在多轮视频对话中理解能力的基准测试，包含987个精心策划的多轮对话，涵盖六个核心能力。

- Motivation: 现有评估基准仅限于单轮问答，忽视了现实场景中多轮对话的复杂性，需要开发更全面的评估方法。
- Method: 构建MT-Video-Bench基准，主要评估六个核心能力（感知性和交互性），涵盖987个多轮对话，这些对话来自不同领域并与实际应用严格对齐。
- Result: 广泛评估了各种开源和闭源的最先进MLLMs，揭示了它们在处理多轮视频对话时存在显著的性能差异和局限性。
- Conclusion: MT-Video-Bench将公开可用，以促进未来研究，填补了多轮视频对话评估的空白。


### [174] [Signature Forgery Detection: Improving Cross-Dataset Generalization](https://arxiv.org/abs/2510.17724)
*Matheus Ramos Parracho*

Main category: cs.CV

TL;DR: 本研究比较了基于原始签名图像和壳预处理两种方法在签名伪造检测中的跨数据集泛化能力，发现原始图像模型在基准测试中表现更好，而壳预处理方法显示出未来改进的潜力。

- Motivation: 尽管深度学习在离线签名验证方面取得了进展，但大多数方法在跨数据集泛化方面仍存在困难，因为笔迹风格和采集协议的差异会降低性能。本研究旨在提高签名伪造检测的跨数据集泛化能力。
- Method: 使用CEDAR、ICDAR和GPDS Synthetic三个公共基准数据集，开发了两个实验流程：一个基于原始签名图像，另一个采用壳预处理方法。分析并比较了两种方法的性能表现。
- Result: 原始图像模型在基准测试中取得了更高的性能，而壳预处理模型显示出未来改进的潜力，但两种方法之间没有确立明确的优越性。
- Conclusion: 原始图像方法在跨数据集签名验证中表现更好，但壳预处理方法具有进一步发展的潜力，可用于构建更稳健的跨域签名验证系统。


### [175] [Can Image-To-Video Models Simulate Pedestrian Dynamics?](https://arxiv.org/abs/2510.17731)
*Aaron Appelle,Jerome P. Lynch*

Main category: cs.CV

TL;DR: 研究基于扩散变换器（DiT）的图像到视频（I2V）模型是否能够生成拥挤公共场景中真实的行人运动模式。

- Motivation: 探索高性能I2V模型在大型视频数据集训练后表现出的内在世界建模能力，特别是能否应用于行人轨迹预测任务。
- Method: 通过从行人轨迹基准中提取关键帧来条件化I2V模型，然后使用行人动力学的定量指标评估其轨迹预测性能。
- Result: 论文未提供具体的实验结果数据，但提出了评估框架。
- Conclusion: 该研究为利用I2V模型进行行人运动模式生成提供了新的评估方法框架。


### [176] [Joint Multi-Condition Representation Modelling via Matrix Factorisation for Visual Place Recognition](https://arxiv.org/abs/2510.17739)
*Timur Ismagilov,Shakaiba Majeed,Michael Milford,Tan Viet Tuyen Nguyen,Sarvapali D. Ramchurn,Shoaib Ehsan*

Main category: cs.CV

TL;DR: 提出一种无需训练的描述符无关方法，通过矩阵分解将多个参考描述符联合建模为基表示，实现基于投影的残差匹配，在多参考视觉地点识别中显著提升性能。

- Motivation: 解决多参考视觉地点识别中，在保持轻量化的同时提升在复杂外观和视角变化下的定位性能，避免传统方法需要大量训练或依赖启发式策略的局限性。
- Method: 使用矩阵分解将多个参考描述符分解为基表示，然后通过投影残差匹配进行地点识别，该方法无需训练且与具体描述符类型无关。
- Result: 在多外观数据上，Recall@1提升约18%，在非结构化数据上提升约5%，在多种外观和视角变化下均优于单参考和多参考基线方法。
- Conclusion: 该方法在保持轻量化的同时，在复杂视觉条件下展现出强大的泛化能力，为多参考视觉地点识别提供了有效的训练免费解决方案。


### [177] [Towards Explainable Skin Cancer Classification: A Dual-Network Attention Model with Lesion Segmentation and Clinical Metadata Fusion](https://arxiv.org/abs/2510.17773)
*Md. Enamul Atiq,Shaikh Anowarul Fattah*

Main category: cs.CV

TL;DR: 提出基于双编码器注意力框架的皮肤病变分类方法，结合分割病灶和临床元数据，提高分类准确性和可解释性。

- Motivation: 皮肤癌早期检测对患者预后至关重要，但现有深度学习模型多为"黑箱"，缺乏临床信任，且存在类内差异大、类间差异小的问题。
- Method: 使用带双注意力门和空洞空间金字塔池化的Deep-UNet进行病灶分割，分类阶段采用两个DenseNet201编码器分别处理原始图像和分割病灶，通过多头交叉注意力融合特征，并加入基于transformer的模块整合患者元数据。
- Result: 在HAM10000数据集和ISIC 2018、2019挑战中取得最先进的分割性能，显著提升分类准确率和平均AUC，Grad-CAM热图验证模型关注病灶区域而非背景特征。
- Conclusion: 整合精确病灶分割、临床数据和注意力融合机制可构建更准确、可解释的皮肤癌分类模型。


### [178] [SparseVILA: Decoupling Visual Sparsity for Efficient VLM Inference](https://arxiv.org/abs/2510.17777)
*Samir Khaki,Junxian Guo,Jiaming Tang,Shang Yang,Yukang Chen,Konstantinos N. Plataniotis,Yao Lu,Song Han,Zhijian Liu*

Main category: cs.CV

TL;DR: SparseVILA是一种高效的视觉语言模型推理范式，通过在预填充阶段剪枝冗余视觉令牌和在解码阶段仅检索查询相关令牌，实现了视觉稀疏性的解耦，显著提升推理速度而不牺牲性能。

- Motivation: 视觉语言模型的推理可扩展性受到视觉令牌数量增长的制约，这些令牌主导了推理延迟。需要一种方法在保持多轮对话保真度的同时加速推理。
- Method: 提出解耦的视觉稀疏性方法：预填充阶段进行查询无关的令牌剪枝，解码阶段进行查询感知的令牌检索。基于AWQ优化的推理流水线实现。
- Result: 在长上下文视频任务上实现4.0倍预填充加速、2.5倍解码加速和2.6倍端到端加速，同时在文档理解和推理任务上提高准确性。
- Conclusion: SparseVILA通过解耦查询无关剪枝和查询感知检索，为高效多模态推理提供了无需训练、架构无关的框架，在不牺牲能力的前提下加速大型视觉语言模型。


### [179] [UltraCUA: A Foundation Model for Computer Use Agents with Hybrid Action](https://arxiv.org/abs/2510.17790)
*Yuhao Yang,Zhen Yang,Zi-Yi Dou,Anh Nguyen,Keen You,Omar Attia,Andrew Szot,Michael Feng,Ram Ramrakhya,Alexander Toshev,Chao Huang,Yinfei Yang,Zhe Gan*

Main category: cs.CV

TL;DR: UltraCUA是一个基础模型，通过混合动作将GUI基本操作与高级程序化工具调用无缝集成，显著提升了计算机使用代理的性能和效率。

- Motivation: 现有的计算机使用代理仅依赖基本操作（点击、输入、滚动），需要精确的视觉定位和冗长的执行链，导致级联失败和性能瓶颈。这些代理与丰富的程序化接口（API、MCP服务器、工具）隔离，无法利用这些能力。
- Method: 方法包括四个关键组件：(1)从软件文档、开源仓库和代码生成中扩展程序化工具的自动化流水线；(2)生成超过17,000个可验证任务的合成数据引擎；(3)大规模高质量混合动作轨迹收集；(4)结合监督微调和在线强化学习的两阶段训练流程。
- Result: 在OSWorld上，UltraCUA模型相比基础模型平均相对提升22%，步骤速度提升11%。在WindowsAgentArena的域外评估中，模型达到21.7%的成功率，优于在Windows数据上训练的基线模型。
- Conclusion: 混合动作机制至关重要，减少了错误传播同时保持了执行效率。UltraCUA成功弥合了计算机使用代理与程序化工具之间的鸿沟。


### [180] [Glyph: Scaling Context Windows via Visual-Text Compression](https://arxiv.org/abs/2510.17800)
*Jiale Cheng,Yusen Liu,Xinyu Zhang,Yulin Fei,Wenyi Hong,Ruiliang Lyu,Weihan Wang,Zhe Su,Xiaotao Gu,Xiao Liu,Yushi Bai,Jie Tang,Hongning Wang,Minlie Huang*

Main category: cs.CV

TL;DR: Glyph框架通过将长文本渲染为图像，使用视觉语言模型处理，实现3-4倍文本压缩，在保持准确性的同时显著提升计算效率。

- Motivation: 解决大语言模型在处理百万级token长上下文时面临的计算和内存成本过高的问题。
- Method: 提出Glyph框架，将长文本渲染为图像，使用视觉语言模型处理，并设计基于LLM的遗传搜索来优化视觉渲染配置。
- Result: 实现3-4倍token压缩，准确性与Qwen3-8B相当，预填充和解码速度提升约4倍，SFT训练速度提升约2倍，128K上下文VLM可处理1M token任务。
- Conclusion: 视觉上下文扩展是解决长上下文建模挑战的有效方法，在保持性能的同时显著提升效率，并有益于文档理解等多模态任务。


### [181] [ConsistEdit: Highly Consistent and Precise Training-free Visual Editing](https://arxiv.org/abs/2510.17803)
*Zixin Yin,Ling-Hao Chen,Lionel Ni,Xili Dai*

Main category: cs.CV

TL;DR: 提出ConsistEdit方法，针对MM-DiT架构设计注意力控制机制，解决现有训练自由编辑方法在编辑强度与一致性之间的平衡问题，支持多轮和视频编辑。

- Motivation: 现有训练自由注意力控制方法难以同时实现强编辑能力和保持与源图像的一致性，特别是在多轮和视频编辑中视觉错误会累积。MM-DiT架构的进步为解决这些问题提供了新机会。
- Method: 基于对MM-DiT注意力机制的深入分析，提出ConsistEdit方法，包含视觉专用注意力控制、掩码引导预注意力融合，以及对查询、键、值令牌的差异化操作。
- Result: 在广泛的图像和视频编辑任务中实现最先进性能，支持结构一致和不一致场景，是首个无需手工调整即可在所有推理步骤和注意力层进行编辑的方法。
- Conclusion: ConsistEdit显著提升了可靠性和一致性，支持稳健的多轮和多区域编辑，并能渐进调整结构一致性，提供更精细的控制。
## cs.AI

### [182] [Beyond Fixed Anchors: Precisely Erasing Concepts with Sibling Exclusive Counterparts](https://arxiv.org/abs/2510.16342)
*Tong Zhang,Ru Zhang,Jianyi Liu,Zhen Yang,Gongshen Liu*

Main category: cs.AI

TL;DR: 提出了SELECT框架，通过动态锚点选择解决文本到图像扩散模型中概念擦除的锚点敏感性问题，避免概念重现和侵蚀问题

- Motivation: 现有概念擦除方法依赖固定锚点策略，导致概念重现和侵蚀等关键问题，需要更智能的锚点选择方法
- Method: 基于因果追踪分析擦除对锚点选择的敏感性，定义兄弟排他概念作为优质锚点类别，提出两阶段评估机制自动发现最优锚点并识别边界锚点
- Result: SELECT作为通用锚点解决方案，能高效适配多种擦除框架，在关键性能指标上持续优于现有基线，单个概念锚点挖掘仅需4秒
- Conclusion: 动态锚点选择框架SELECT有效解决了固定锚点策略的局限性，实现了更精确的概念擦除


### [183] [End-to-end Listen, Look, Speak and Act](https://arxiv.org/abs/2510.16756)
*Siyin Wang,Wenyi Yu,Xianzhao Chen,Xiaohai Tian,Jun Zhang,Lu Lu,Chao Zhang*

Main category: cs.AI

TL;DR: ELLSA是首个全双工、端到端的多模态模型，能够同时感知和生成视觉、文本、语音和动作，实现更自然的人机交互。

- Motivation: 人类交互本质上是多模态和全双工的，需要同时感知和生成多种模态信息。现有模型难以实现这种自然的交互模式。
- Method: 采用新颖的SA-MoE架构，将各模态路由到专用专家模块，通过统一的注意力骨干网络进行融合，实现联合多模态感知和并发生成。
- Result: 在语音交互和机器人操作基准测试中，ELLSA与特定模态基线相当，同时支持高级多模态和全双工行为，如对话和动作轮转、缺陷指令拒绝、边说边做等。
- Conclusion: ELLSA朝着更自然和通用的交互智能迈出了一步，有助于实现更广泛的人工通用智能目标。


### [184] [MIRAGE: Agentic Framework for Multimodal Misinformation Detection with Web-Grounded Reasoning](https://arxiv.org/abs/2510.17590)
*Mir Nafis Sharear Shopnil,Sharad Duwal,Abhishek Tyagi,Adiba Mahbub Proma*

Main category: cs.AI

TL;DR: MIRAGE是一个推理时、模型可插拔的代理框架，通过分解多模态验证为四个模块来检测网络虚假信息，无需领域特定训练数据即可达到监督检测器性能。

- Motivation: 网络平台上每天有数十亿结合文本和图像的多模态帖子传播虚假信息，超出了人工事实核查能力。监督检测模型需要领域特定训练数据，且无法泛化到不同的操纵策略。
- Method: MIRAGE将多模态验证分解为四个顺序模块：视觉真实性评估检测AI生成图像，跨模态一致性分析识别上下文不当使用，检索增强的事实核查通过迭代问题生成将声明基于网络证据，校准判断模块整合所有信号。
- Result: 在MMFakeBench验证集上，MIRAGE使用GPT-4o-mini达到81.65% F1和75.1%准确率，比最强零样本基线提升7.65 F1点，同时保持34.3%假阳性率。测试集结果确认泛化能力，达到81.44% F1和75.08%准确率。
- Conclusion: 分解的代理推理与网络检索相结合，可以在没有领域特定训练的情况下匹配监督检测器性能，在标记数据稀缺的多模态场景中实现虚假信息检测。


### [185] [Seeing but Not Believing: Probing the Disconnect Between Visual Attention and Answer Correctness in VLMs](https://arxiv.org/abs/2510.17771)
*Zhining Liu,Ziyi Chen,Hui Liu,Chen Luo,Xianfeng Tang,Suhang Wang,Joy Zeng,Zhenwei Dai,Zhan Shi,Tianxin Wei,Benoit Dumoulin,Hanghang Tong*

Main category: cs.AI

TL;DR: 研究发现视觉语言模型在输出错误答案时仍能感知视觉证据，这种现象被称为"看见但不相信"。通过选择性注意力掩码的推理时干预，无需训练即可提高多个VLM家族的准确性。

- Motivation: 系统研究视觉语言模型失败的原因：是未能感知视觉证据还是未能有效利用证据。发现模型在深层能可靠地关注局部证据区域，但未能充分利用这些信息。
- Method: 通过层间注意力动态分析，发现浅层主要关注文本，深层稀疏但可靠地关注局部证据区域。提出推理时干预方法，通过选择性注意力掩码突出深层证据区域。
- Result: 干预方法在LLaVA、Qwen、Gemma和InternVL等多个VLM家族中一致提高准确性，证明模型内部编码了可靠证据但未充分利用。
- Conclusion: 视觉语言模型内部编码了可靠证据但利用不足，使这些信号显式化可以弥合感知与推理之间的差距，推进VLM的诊断理解和可靠性。
## cs.RO

### [186] [NEBULA: Do We Evaluate Vision-Language-Action Agents Correctly?](https://arxiv.org/abs/2510.16263)
*Jierui Peng,Yanyan Zhang,Yicheng Duan,Tuo Liang,Vipin Chaudhary,Yu Yin*

Main category: cs.RO

TL;DR: NEBULA是一个用于单臂操作任务的统一评估生态系统，通过细粒度能力测试和系统性压力测试来解决VLA智能体评估中的问题。

- Motivation: 当前VLA智能体的评估受限于粗糙的最终任务成功率指标，无法提供精确的技能诊断或测量对现实世界扰动的鲁棒性，且分散的数据环境阻碍了可复现研究和通用模型的发展。
- Method: 引入双轴评估协议：细粒度能力测试用于精确技能诊断，系统性压力测试用于测量鲁棒性；提供标准化API和大规模聚合数据集。
- Result: 使用NEBULA发现顶级VLA智能体在空间推理和动态适应等关键能力上表现不佳，这些缺陷被传统最终任务成功率指标所掩盖。
- Conclusion: NEBULA通过测量智能体能做什么以及何时可靠地执行，为构建鲁棒、通用的具身智能体提供了实用基础。


### [187] [DINO-CVA: A Multimodal Goal-Conditioned Vision-to-Action Model for Autonomous Catheter Navigation](https://arxiv.org/abs/2510.17038)
*Pedram Fekri,Majid Roshanfar,Samuel Barbeau,Seyedfarzad Famouri,Thomas Looi,Dale Podolsky,Mehrdad Zadeh,Javad Dargahi*

Main category: cs.RO

TL;DR: 提出DINO-CVA多模态目标条件行为克隆框架，实现自主导管导航，融合视觉观察和操纵杆运动学，减少对操作者的依赖。

- Motivation: 当前导管介入手术主要依赖手动操作，现有机器人系统缺乏智能自主性，导致操作者疲劳、辐射暴露增加和手术结果不一致。
- Method: 开发多模态目标条件行为克隆框架，融合视觉观察和操纵杆运动学到联合嵌入空间，通过专家演示自回归预测动作，目标条件引导导航到指定目的地。
- Result: DINO-CVA在预测动作方面达到高精度，与仅运动学基线性能相当，同时将预测基于解剖环境，验证了多模态目标条件架构的可行性。
- Conclusion: 该研究为导管导航提供了可行的多模态目标条件架构，是减少操作者依赖、提高导管治疗可靠性的重要一步。


### [188] [DiffVLA++: Bridging Cognitive Reasoning and End-to-End Driving through Metric-Guided Alignment](https://arxiv.org/abs/2510.17148)
*Yu Gao,Yiru Wang,Anqing Jiang,Heng Yuwen,Wang Shuo,Sun Hao,Wang Jijun*

Main category: cs.RO

TL;DR: DiffVLA++是一个增强的自动驾驶框架，通过度量引导对齐显式桥接认知推理和端到端规划，结合VLA模型的世界知识和E2E模型的物理可行性。

- Motivation: 传统E2E驾驶模型能生成物理上合理的轨迹但缺乏世界知识处理长尾场景，而VLA模型有世界知识但3D推理能力有限导致物理不可行动作。
- Method: 构建VLA模块生成语义接地驾驶轨迹，设计E2E模块确保物理可行性，引入度量引导轨迹评分器对齐两个模块输出。
- Result: 在ICCV 2025自动驾驶大挑战排行榜上达到EPDMS 49.12。
- Conclusion: DiffVLA++成功整合了VLA和E2E模型的互补优势，通过度量引导对齐实现了认知推理与物理可行性的平衡。


### [189] [From Spatial to Actions: Grounding Vision-Language-Action Model in Spatial Foundation Priors](https://arxiv.org/abs/2510.17439)
*Zhengshen Zhang,Hao Li,Yalun Dai,Zhengbang Zhu,Lei Zhou,Chenchen Liu,Dong Wang,Francis E. H. Tay,Sijin Chen,Ziwei Liu,Yuxiao Liu,Xinghang Li,Pan Zhou*

Main category: cs.RO

TL;DR: FALCON通过将丰富的3D空间令牌注入到动作头中，解决了现有VLA模型在3D空间推理方面的局限性，无需重新训练即可融合深度或姿态信息，在模拟和现实任务中实现最先进性能。

- Motivation: 现有基于2D编码器的VLA模型存在空间推理差距，限制了泛化能力和适应性。现有的3D集成技术要么需要专用传感器且跨模态迁移能力差，要么注入缺乏几何信息的弱线索并损害视觉-语言对齐。
- Method: FALCON利用空间基础模型从RGB图像中提取强几何先验，通过空间增强动作头处理空间令牌而非将其连接到视觉-语言骨干网络，可选融合深度或姿态信息而无需重新训练。
- Result: 在三个模拟基准和十一个现实世界任务的综合评估中，FALCON实现了最先进的性能，始终超越竞争基线，并在杂乱环境、空间提示条件以及物体尺度和高度变化下保持鲁棒性。
- Conclusion: FALCON通过创新的空间令牌注入范式有效解决了空间表示、模态可迁移性和对齐方面的限制，为3D真实世界中的视觉-语言-动作模型提供了强大的解决方案。


### [190] [Botany-Bot: Digital Twin Monitoring of Occluded and Underleaf Plant Structures with Gaussian Splats](https://arxiv.org/abs/2510.17783)
*Simeon Adebola,Chung Min Kim,Justin Kerr,Shuangyu Xie,Prithvi Akella,Jose Luis Susa Rincon,Eugen Solowjow,Ken Goldberg*

Main category: cs.RO

TL;DR: Botany-Bot是一个使用立体相机、数字转台、工业机器人臂和3D分割高斯溅射模型构建植物详细"注释数字孪生"的系统，能够通过操纵叶片拍摄被遮挡细节的高分辨率图像。

- Motivation: 商用植物表型系统使用固定相机无法感知许多植物细节，因为叶片遮挡问题严重。
- Method: 使用两个立体相机、数字转台、工业机器人臂和3D分割高斯溅射模型，开发了操纵叶片拍摄被遮挡细节的机器人算法。
- Result: Botany-Bot能够以90.8%的准确率分割叶片，86.2%的准确率检测叶片，77.9%的准确率提升/推动叶片，77.3%的准确率拍摄详细的上下表面图像。
- Conclusion: 该系统能够构建植物的详细注释数字孪生，代码、视频和数据集已公开。
## cs.CR

### [191] [ISO/IEC-Compliant Match-on-Card Face Verification with Short Binary Templates](https://arxiv.org/abs/2510.16078)
*Abdelilah Ganmati,Karim Afdel,Lahcen Koutti*

Main category: cs.CR

TL;DR: 提出了一种实用的卡上人脸验证匹配设计，使用紧凑的64/128位模板，通过PCA-ITQ离线生成并在卡上通过恒定时间汉明距离比较，满足ISO/IEC标准约束。

- Motivation: 开发一种符合ISO/IEC 7816-4和14443-4标准的卡上人脸验证系统，使用紧凑的二进制模板，避免分数泄露，实现快速且安全的身份验证。
- Method: 使用PCA-ITQ生成64/128位紧凑模板，在卡上通过恒定时间汉明距离进行比较，采用固定长度的APDU负载和仅决策状态字，最小化EEPROM存储需求。
- Result: 在CelebA数据集（55个身份，412张图像）上，64位和128位模板在FAR=1%时达到TPR=0.836，验证时间在9.6 kbps下分别为43.9ms和52.3ms，在38.4 kbps下均小于14ms。
- Conclusion: 短二进制模板、固定负载的仅决策APDU和恒定时间匹配满足了ISO/IEC传输约束，具有宽裕的时间余量，并符合ISO/IEC 24745隐私目标。局限性包括单数据集评估和设计级时序分析。


### [192] [Patronus: Safeguarding Text-to-Image Models against White-Box Adversaries](https://arxiv.org/abs/2510.16581)
*Xinfeng Li,Shengyuan Pang,Jialin Wu,Jiangyi Deng,Huanlong Zhong,Yanjiao Chen,Jie Zhang,Wenyuan Xu*

Main category: cs.CR

TL;DR: Patronus是一个保护文本到图像模型免受白盒攻击的防御框架，通过内部调节器和非微调学习机制来防止恶意内容生成。

- Motivation: 现有的内容审核和模型对齐方法在面对知道模型参数并能调整的白盒攻击者时容易失效，需要一种更强大的防御机制。
- Method: 设计内部调节器将不安全输入特征解码为零向量，同时保持良性输入的生成性能；采用非微调学习机制加强模型对齐，防止恶意微调。
- Result: 实验验证了Patronus在安全内容生成上的完整性，能有效拒绝不安全内容生成，并对各种白盒微调攻击具有韧性。
- Conclusion: Patronus框架为T2I模型提供了全面的白盒攻击防护，在保持正常生成能力的同时有效抵御恶意内容生成。


### [193] [VERA-V: Variational Inference Framework for Jailbreaking Vision-Language Models](https://arxiv.org/abs/2510.17759)
*Qilin Liao,Anamika Lochab,Ruqi Zhang*

Main category: cs.CR

TL;DR: VERA-V是一个基于变分推理的多模态越狱发现框架，通过联合后验分布学习生成配对的文本-图像对抗提示，在HarmBench和HADES基准测试中显著优于现有方法。

- Motivation: 现有的多模态红队方法依赖脆弱的模板，专注于单攻击设置，仅暴露有限的漏洞。需要更全面、隐蔽的越狱发现方法。
- Method: 使用变分推理框架将多模态越狱发现转化为学习配对文本-图像提示的联合后验分布，训练轻量级攻击器近似后验，结合三种策略：基于排版的文本提示、基于扩散的图像合成和结构化干扰器。
- Result: 在GPT-4o上攻击成功率比最佳基线提高53.75%，在开源和前沿VLM上一致优于现有方法。
- Conclusion: VERA-V通过概率建模和多样化攻击策略，有效揭示了VLM的新漏洞，为模型安全评估提供了有力工具。
## cs.MM

### [194] [Taming Modality Entanglement in Continual Audio-Visual Segmentation](https://arxiv.org/abs/2510.17234)
*Yuyang Hong,Qi Yang,Tao Zhang,Zili Wang,Zhaojin Fu,Kun Ding,Bin Fan,Shiming Xiang*

Main category: cs.MM

TL;DR: 提出了持续音频-视觉分割任务，设计了基于碰撞的多模态回放框架来解决多模态语义漂移和共现混淆问题

- Motivation: 现有方法主要关注粗粒度任务，在细粒度持续学习设置中处理模态纠缠存在局限性
- Method: 提出多模态样本选择策略选择模态一致性高的样本进行回放，设计基于碰撞的样本回放机制增加易混淆类别的回放频率
- Result: 在三个音频-视觉增量场景上的实验表明，该方法显著优于单模态持续学习方法
- Conclusion: 该方法有效解决了多模态语义漂移和共现混淆问题，在持续音频-视觉分割任务中表现出色
## astro-ph.IM

### [195] [Detecting streaks in smart telescopes images with Deep Learning](https://arxiv.org/abs/2510.17540)
*Olivier Parisot,Mahmoud Jaziri*

Main category: astro-ph.IM

TL;DR: 测试和调整多种深度学习方法，用于在2022年3月至2023年2月期间使用智能望远镜拍摄的原始天文数据中检测卫星条纹

- Motivation: 卫星在夜空的可见性对天文学和天文摄影产生负面影响，会在天文观测图像中引入条纹，需要进行额外的后处理来减轻这种不良影响
- Method: 测试和调整各种深度学习方法
- Result: 未在摘要中明确说明
- Conclusion: 未在摘要中明确说明
## cs.LG

### [196] [FedPURIN: Programmed Update and Reduced INformation for Sparse Personalized Federated Learning](https://arxiv.org/abs/2510.16065)
*Lunchen Xie,Zehua He,Qingjiang Shi*

Main category: cs.LG

TL;DR: 提出FedPURIN框架，通过整数规划识别关键参数进行传输，结合稀疏聚合显著减少通信开销，同时保持个性化联邦学习性能。

- Motivation: 解决个性化联邦学习中通信效率低下的问题，现有方法通信负担重，阻碍实际部署。
- Method: 使用整数规划策略识别关键参数，结合稀疏聚合方案，实现通信效率优化。
- Result: 在标准图像分类基准测试中，在不同非独立同分布条件下表现出与最先进方法相当的性能，并通过稀疏聚合实现可量化的通信减少。
- Conclusion: FedPURIN为通信高效的个性化联邦学习建立了新范式，特别适用于具有异构数据源的边缘智能系统。


### [197] [Needles in the Landscape: Semi-Supervised Pseudolabeling for Archaeological Site Discovery under Label Scarcity](https://arxiv.org/abs/2510.16814)
*Simon Jaxy,Anton Theys,Patrick Willett,W. Chris Carleton,Ralf Vandam,Pieter Libin*

Main category: cs.LG

TL;DR: 本文提出了一种基于深度学习的半监督正-未标记学习策略，用于考古预测建模，通过动态伪标签和条件随机场处理标签稀缺问题，在DEM和卫星影像数据集上表现优异。

- Motivation: 解决考古学中存在的结构性标签稀缺问题——正样本稀少且大多数位置未标记，需要开发能够处理严重类别不平衡的方法来预测未发现遗址的位置。
- Method: 采用半监督正-未标记学习策略，实现为语义分割模型，使用动态伪标签并结合通过RNN实现的条件随机场来增强标签置信度。
- Result: 在DEM数据集上性能与最先进的LAMAP相当但Dice分数更高；在原始卫星影像上通过分层k折交叉验证保持性能，并产生具有更好可解释性的预测表面。
- Conclusion: 半监督学习为在大规模稀疏标注景观中识别未发现遗址提供了一种有前景的方法。


### [198] [Fly-CL: A Fly-Inspired Framework for Enhancing Efficient Decorrelation and Reduced Training Time in Pre-trained Model-based Continual Representation Learning](https://arxiv.org/abs/2510.16877)
*Heming Zou,Yunliang Zang,Wutong Xu,Xiangyang Ji*

Main category: cs.LG

TL;DR: Fly-CL是一个受苍蝇嗅觉电路启发的持续表示学习框架，通过解决相似性匹配中的多重共线性问题，显著减少训练时间，同时达到或超越现有最先进方法的性能。

- Motivation: 现有的持续表示学习方法在相似性匹配阶段存在多重共线性问题，且先进方法计算成本高，难以满足实时低延迟应用需求。
- Method: 提出Fly-CL框架，利用生物启发的设计解决多重共线性问题，支持多种预训练骨干网络，具有低时间复杂度。
- Result: 在各种网络架构和数据机制下的广泛模拟实验验证了Fly-CL的有效性，显著减少训练时间的同时保持或超越现有方法性能。
- Conclusion: Fly-CL通过生物启发设计有效解决了持续表示学习中的多重共线性挑战，为实时低延迟应用提供了可行解决方案。


### [199] [Domain Generalizable Continual Learning](https://arxiv.org/abs/2510.16914)
*Hongwei Yan,Guanglong Sun,Zhiqi Kang,Yi Zhong,Liyuan Wang*

Main category: cs.LG

TL;DR: 本文提出了领域泛化持续学习(DGCL)新设定，并开发了自适应领域变换(DoT)方法，通过解耦语义和领域信息来实现跨任务的稳健泛化。

- Motivation: 现有持续学习方法假设训练和测试领域相同，无法适应现实世界中动态变化的环境，需要同时处理新技能学习和跨领域泛化问题。
- Method: 提出自适应领域变换(DoT)方法，基于人脑分布式加枢纽理论，解耦语义和领域相关信息，自适应变换任务表示以实现输出对齐。
- Result: DoT作为插件策略显著提升了现有持续学习基线方法在DGCL设定下的性能，验证了其领域泛化知识积累能力和资源效率。
- Conclusion: DoT方法有效解决了领域泛化持续学习问题，实现了语义和领域信息的解耦学习，为动态环境下的智能系统提供了实用解决方案。


### [200] [Matricial Free Energy as a Gaussianizing Regularizer: Enhancing Autoencoders for Gaussian Code Generation](https://arxiv.org/abs/2510.17120)
*Rishi Sonthalia,Raj Rao Nadakuditi*

Main category: cs.LG

TL;DR: 提出了一种基于矩阵自由能的自动编码器正则化方法，通过优化代码矩阵的奇异值分布来获得高斯化编码。

- Motivation: 为了在自动编码器中获得具有高斯分布特性的编码，提高模型的泛化能力。
- Method: 基于矩阵自由能定义可微损失函数，通过随机矩阵理论优化代码矩阵的奇异值分布，使其接近独立同分布高斯随机矩阵的分布。
- Result: 经验模拟显示该方法能产生高斯化编码，并在训练和测试集上具有良好的泛化性能。
- Conclusion: 该方法能可靠地生成高斯编码，适用于欠定逆问题等应用场景。


### [201] [Latent Spaces Beyond Synthesis: From GANs to Diffusion Models](https://arxiv.org/abs/2510.17383)
*Ludovica Schaerf*

Main category: cs.LG

TL;DR: 本文分析了生成视觉模型中内部表征的演变，从GANs和VAEs到扩散模型，提出了严格合成与广义合成的区分，并论证生成AI应被视为专门过程的涌现配置而非直接内容合成。

- Motivation: 研究生成视觉模型内部表征的演变，特别是从GANs和VAEs到扩散模型的转变，挑战统一内部空间的假设，重新思考生成AI的本质。
- Method: 通过模型架构的详细分析和针对层间表征的实验干预，展示扩散模型如何分散表征负担，并结合媒体理论框架和隐喻批判。
- Result: 发现扩散模型将表征负担分散到不同层，挑战了统一潜在空间的假设，支持广义合成的概念。
- Conclusion: 生成AI应被理解为专门过程的涌现配置，而非直接内容合成，需要对潜在空间和柏拉图表征假说等隐喻进行重新定位。


### [202] [MILES: Modality-Informed Learning Rate Scheduler for Balancing Multimodal Learning](https://arxiv.org/abs/2510.17394)
*Alejandro Guerra-Manzanares,Farah E. Shamout*

Main category: cs.LG

TL;DR: 提出MILES方法，通过动态调整学习率来平衡多模态学习，解决模态过拟合问题，提升多模态和单模态预测性能。

- Motivation: 多模态神经网络训练中存在模态过拟合问题，即网络过度依赖某个模态，导致性能不佳，未能充分发挥多模态学习的潜力。
- Method: 提出MILES（Modality-Informed Learning ratE Scheduler），利用训练过程中模态条件利用率差异动态调整学习率，平衡各模态的学习速度。
- Result: 在四个多模态联合融合任务中，MILES优于七个最先进的基线方法，有效平衡模态使用，提升多模态性能并产生更强的模态编码器。
- Conclusion: 平衡多模态学习对提升模型性能具有重要影响，MILES方法能有效解决模态过拟合问题，提升整体性能。


### [203] [ZACH-ViT: A Zero-Token Vision Transformer with ShuffleStrides Data Augmentation for Robust Lung Ultrasound Classification](https://arxiv.org/abs/2510.17650)
*Athanasios Angelakis,Amne Mousa,Micah L. A. Heldeweg,Laurens A. Biesheuvel,Mark A. Haaksma,Jasper M. Smit,Pieter R. Tuinman,Paul W. G. Elbers*

Main category: cs.LG

TL;DR: ZACH-ViT是一种轻量级视觉Transformer，用于区分心源性肺水肿与非心源性肺部疾病，在肺超声视频分类中表现优异，参数仅0.25M，训练速度快且具有置换不变性。

- Motivation: 由于非心源性炎症模式、间质性肺病和健康肺部在肺超声中视觉变异大，且B线和胸膜伪影重叠，使得自动分类心源性肺水肿变得困难。
- Method: 提出ZACH-ViT模型，移除位置嵌入和[CLS]标记，实现完全置换不变性；采用ShuffleStrides数据增强方法，在保持解剖有效性的同时置换探头视角序列和帧顺序。
- Result: 在380个肺超声视频上评估，ZACH-ViT获得最高验证和测试ROC-AUC（0.80和0.79），平衡灵敏度（0.60）和特异性（0.91），而其他模型均失效。
- Conclusion: 将架构设计与数据结构对齐可以在小数据医学成像中超越规模效应，支持实时临床部署。
## cs.CL

### [204] [From Preferences to Prejudice: The Role of Alignment Tuning in Shaping Social Bias in Video Diffusion Models](https://arxiv.org/abs/2510.17247)
*Zefan Cai,Haoyi Qiu,Haozhe Zhao,Ke Wan,Jiachen Li,Jiuxiang Gu,Wen Xiao,Nanyun Peng,Junjie Hu*

Main category: cs.CL

TL;DR: 该论文提出了VideoBiasEval框架，用于评估视频生成模型中的社会偏见，发现对齐调优会放大并稳定化社会偏见。

- Motivation: 视频扩散模型通过基于人类偏好的奖励模型进行对齐调优，虽然提升了视觉质量，但可能无意中编码并放大了社会偏见。
- Method: 引入VideoBiasEval诊断框架，基于社会偏见分类学，采用基于事件的提示策略，分离语义内容和演员属性，并引入多粒度指标评估偏见。
- Result: 对齐调优不仅强化了代表性偏见，还使其在时间上更稳定，产生更平滑但更刻板的描述。
- Conclusion: 需要在对齐过程中进行偏见感知评估和缓解，以确保公平和负责任的视频生成。
## cs.HC

### [205] [Conveying Meaning through Gestures: An Investigation into Semantic Co-Speech Gesture Generation](https://arxiv.org/abs/2510.17599)
*Hendric Voss,Lisa Michelle Bohnenkamp,Stefan Kopp*

Main category: cs.HC

TL;DR: 本研究比较了两种语音伴随手势生成框架AQ-GT和AQ-GT-a，发现无显式语义输入的AQ-GT在训练领域内概念传达更有效，而语义增强的AQ-GT-a在泛化能力上表现更好，特别是在新语境中表示形状和大小。

- Motivation: 评估不同手势生成框架传达意义的能力以及人类对生成手势的感知，探索语义标注与性能之间的复杂关系。
- Method: 使用SAGA空间通信语料库中的句子、上下文相似句子和新的动作焦点句子，进行以用户为中心的概念识别和拟人化评估。
- Result: AQ-GT框架在训练领域内更有效地传达概念，AQ-GT-a框架在泛化能力上表现更好；参与者认为AQ-GT-a手势更具表现力和帮助性，但不认为更拟人。
- Conclusion: 显式语义增强不能保证手势生成的改进，其有效性高度依赖于上下文，表明在专业化和泛化之间存在权衡。


### [206] [ImaGGen: Zero-Shot Generation of Co-Speech Semantic Gestures Grounded in Language and Image Input](https://arxiv.org/abs/2510.17617)
*Hendric Voss,Stefan Kopp*

Main category: cs.HC

TL;DR: 该论文提出了一种从语言输入和图像信息生成语义连贯的图标手势和指示手势的零样本系统，通过图像分析提取物体属性并与语音文本语义匹配，结合逆运动学生成自然的多模态手势。

- Motivation: 当前手势生成方法仅限于简单的节拍手势，无法传达语义含义。该研究旨在解决语音手势合成的核心挑战：生成与语言表达语义一致的图标或指示手势。
- Method: 集成图像分析管道提取物体形状、对称性等关键属性，通过语义匹配模块将视觉细节与语音文本关联，使用逆运动学生成图标和指示手势，并与节拍手势结合。
- Result: 用户研究表明，在语音表达模糊的场景中，系统生成的手势显著提高了参与者识别物体属性的能力，证实了手势的可解释性和沟通价值。
- Conclusion: 虽然复杂形状表示仍存在挑战，但研究强调了上下文感知语义手势对于创建表达性和协作性虚拟代理的重要性，为高效、稳健的具身人机交互迈出了重要一步。
## cs.IT

### [207] [Unlocking Off-the-Grid Sparse Recovery with Unlimited Sensing: Simultaneous Super-Resolution in Time and Amplitude](https://arxiv.org/abs/2510.16948)
*Ruiming Guo,Ayush Bhandari*

Main category: cs.IT

TL;DR: 本文提出了一种基于无限制传感框架(USF)的数字超分辨率方法，通过模数编码增强测量精度，突破传统量化限制，实现幅度和时间的超分辨率恢复。

- Motivation: 传统数字采集在处理强弱幅度差异大的脉冲信号时，会出现强分量削波或弱分量被量化噪声淹没的问题。在固定比特预算下，这种信息损失是不可避免的。
- Method: 采用无限制传感框架(USF)中的模数编码技术，开发了适用于非带限核的鲁棒算法，用于离网格稀疏恢复。
- Result: 数值模拟和硬件实验验证了该方法在低比特量化下的有效性，能够实现幅度和时间维度的超分辨率。
- Conclusion: 无限制传感框架能够克服传统数字采集的基本限制，通过模数编码实现超越常规极限的时间超分辨率。
## eess.IV

### [208] [Lung Cancer Classification from CT Images Using ResNet](https://arxiv.org/abs/2510.16310)
*Olajumoke O. Adekunle,Joseph D. Akinyemi,Khadijat T. Ladoja,Olufade F. W. Onifade*

Main category: eess.IV

TL;DR: 提出基于ResNet的深度学习模型，用于从CT图像中进行肺癌多分类，准确率达到98.8%，显著优于现有方法。

- Motivation: 现有肺癌分类方法主要关注恶性与良性结节的二分类，且预测效果未达到临床应用标准，需要改进多分类性能。
- Method: 使用预训练的ResNet50模型，在LC25000数据集上训练，添加自定义层并进行超参数调优，实现三类分类（两种恶性类型和一种良性）。
- Result: 在2,250张测试图像上达到98.8%的准确率，相比之前模型有显著提升。
- Conclusion: 该方法在肺癌多分类任务中表现出色，为临床诊断提供了更可靠的自动化工具。


### [209] [Time-Embedded Algorithm Unrolling for Computational MRI](https://arxiv.org/abs/2510.16321)
*Junno Yun,Yaşar Utku Alçalar,Mehmet Akçakaya*

Main category: eess.IV

TL;DR: 提出了一种时间嵌入的算法展开方案，通过将迭代相关的近端操作和数据保真度操作中的参数设计为时间依赖的可学习参数，有效减少伪影和噪声放大，在MRI重建中实现最先进性能。

- Motivation: 传统算法展开方法中，近端算子网络在迭代间共享会导致伪影或模糊，而使用不同网络又会导致参数过多和过拟合问题。受AMP中变化阈值近端算子和扩散模型中时间嵌入成功的启发，希望开发更有效的算法展开方案。
- Method: 将向量AMP中的迭代相关近端操作和Onsager修正重新解释为时间嵌入神经网络，将数据保真度操作中的标量权重设计为时间依赖的可学习参数，提出时间嵌入的算法展开方案。
- Result: 在fastMRI数据集上的广泛实验表明，该方法能有效减少混叠伪影和缓解噪声放大，在不同加速率和数据集上都实现了最先进的性能。
- Conclusion: 时间嵌入策略能有效提升现有算法展开方法的重建质量，且不会显著增加计算复杂度，为逆问题求解提供了新的有效方案。
## cs.GR

### [210] [Filtering of Small Components for Isosurface Generation](https://arxiv.org/abs/2510.16684)
*Devin Zhao,Rephael Wenger*

Main category: cs.GR

TL;DR: 该论文研究了如何通过简单的预过滤方法去除等值面中的微小干扰组件，以改善从扫描数据（如CT或MRI）构建的等值面可视化效果。

- Motivation: 从扫描数据构建的等值面通常包含许多极小的干扰组件，这些组件会分散可视化注意力，且不构成任何几何模型的一部分。
- Method: 使用简单的数据预过滤方法来移除等值面中的微小组件，同时不影响构成可视化主体的大型组件。
- Result: 实验结果表明该方法能有效过滤掉等值面中的微小干扰组件。
- Conclusion: 简单的预过滤方法可以有效改善等值面可视化质量，去除微小干扰组件而不影响主要结构。


### [211] [Shape-aware Inertial Poser: Motion Tracking for Humans with Diverse Shapes Using Sparse Inertial Sensors](https://arxiv.org/abs/2510.17101)
*Lu Yin,Ziying Shi,Yinghao Wu,Xinyu Yi,Feng Xu,Shihui Guo*

Main category: cs.GR

TL;DR: SAIP是首个考虑身体形状差异的稀疏惯性运动捕捉方法，通过分解传感器测量值中的形状和姿态成分，实现对不同体型（包括儿童）的准确运动捕捉。

- Motivation: 现有方法主要依赖标准成人身体形状模板，难以泛化到体型差异大的个体（如儿童），主要原因是身体形状变化会导致IMU测量的加速度发生变化。
- Method: 1. 训练回归模型将真实身体的IMU加速度转换到匹配模板成人身体模型；2. 使用现有方法估计模板形状身体的全身运动；3. 使用第二个回归模型将关节速度映射回真实身体，结合形状感知的物理优化策略计算全局运动。
- Result: 提出了首个包含不同体型个体的IMU运动捕捉数据集（10名儿童和10名成人，身高110-190cm，共400分钟配对IMU-运动样本），实验证明SAIP能有效处理不同体型的运动捕捉任务。
- Conclusion: SAIP通过形状感知的方法成功解决了惯性运动捕捉中的体型泛化问题，是首个考虑身体形状差异的稀疏惯性运动捕捉解决方案。
