[[toc]]

## cs.CV

### [1] [2COOOL: 2nd Workshop on the Challenge Of Out-Of-Label Hazards in Autonomous Driving](https://arxiv.org/abs/2508.21080)
*Ali K. AlShami,Ryan Rabinowitz,Maged Shoman,Jianwu Fang,Lukas Picek,Shao-Yuan Lo,Steve Cruz,Khang Nhut Lam,Nachiket Kamod,Lei-Lei Li,Jugal Kalita,Terrance E. Boult*

Main category: cs.CV

TL;DR: 这是一个关于自动驾驶中处理新颖场景和异常危险检测的研讨会摘要，重点讨论如何提高自动驾驶系统在未知情况下的安全性

- Motivation: 当前自动驾驶技术尚未完全安全的关键原因在于处理新颖场景的能力不足，需要专门解决分布外危险检测和异常情况处理
- Method: 通过举办研讨会汇集学术界和工业界专家，推动异常检测、开放集识别、开放词汇建模、领域适应等相关领域的新算法开发
- Result: 在WACV 2025成功举办首届研讨会的基础上，将在ICCV 2025举办第二届研讨会，为研究人员提供专门的交流平台
- Conclusion: 通过跨领域合作和新技术开发，可以显著提升自动驾驶系统处理新颖危险场景的能力，推动更安全的自动驾驶技术发展


### [2] [Advanced Deep Learning Techniques for Classifying Dental Conditions Using Panoramic X-Ray Images](https://arxiv.org/abs/2508.21088)
*Alireza Golkarieh,Kiana Kiashemshaki,Sajjad Rezvani Boroujeni*

Main category: cs.CV

TL;DR: 本研究评估了三种深度学习方法来分类全景X射线图像中的牙齿状况，发现CNN与随机森林的混合模型表现最佳，准确率达到85.4%

- Motivation: 开发自动化牙齿状况分类系统，为牙科诊断提供可靠支持，提高诊断效率和准确性
- Method: 使用1,512张全景X射线图像数据集，评估三种方法：自定义CNN、CNN特征提取与传统分类器混合模型、预训练架构微调，采用5折交叉验证
- Result: 混合CNN随机森林模型准确率最高（85.4%），优于自定义CNN基线（74.3%）；预训练模型中VGG16表现最好（82.3%）
- Conclusion: CNN特征提取与集成分类器结合是自动化牙科诊断支持的实用路径，但需要更大数据集和进一步临床验证


### [3] [Q-Align: Alleviating Attention Leakage in Zero-Shot Appearance Transfer via Query-Query Alignment](https://arxiv.org/abs/2508.21090)
*Namu Kim,Wonbin Kweon,Minsoo Kim,Hwanjo Yu*

Main category: cs.CV

TL;DR: Q-Align通过Query-Query对齐解决大尺度图像生成模型中的注意力泄漏问题，在零样本外观迁移中实现了更好的语义对齐和外观保真度。

- Motivation: 大规模图像生成模型在零样本外观迁移中存在注意力泄漏问题，这是由于图像间的语义映射被Query-Key对齐捕获所导致的，需要新的方法来改善语义对齐效果。
- Method: 提出Q-Align方法，包含三个核心贡献：1) Query-Query对齐实现精细的空间语义映射；2) Key-Value重排增强特征对应；3) 使用重排后的keys和values进行注意力精化以保持语义一致性。
- Result: 通过大量实验验证，Q-Align在外观保真度方面优于最先进方法，同时保持了有竞争力的结构保持能力。
- Conclusion: Q-Align有效解决了注意力泄漏问题，为零样本外观迁移提供了更好的语义对齐解决方案，在保持结构的同时显著提升了外观迁移质量。


### [4] [ERTACache: Error Rectification and Timesteps Adjustment for Efficient Diffusion](https://arxiv.org/abs/2508.21091)
*Xurui Peng,Hong Liu,Chenqian Yan,Rui Ma,Fangmin Chen,Xing Wang,Zhihua Wu,Songwei Liu,Mingbao Lin*

Main category: cs.CV

TL;DR: ERTACache是一个针对扩散模型的缓存加速框架，通过分析缓存累积误差的两个主要来源（特征偏移误差和步长放大误差），采用离线残差分析、轨迹感知校正和残差线性化模型，实现了2倍推理加速且保持甚至提升视觉质量。

- Motivation: 扩散模型由于迭代推理过程导致计算开销巨大，特征缓存虽然是有前景的加速策略，但简单的重用会导致明显的质量下降。需要解决缓存引入的累积误差问题。
- Method: 提出ERTACache框架：1）离线残差分析识别可重用步骤；2）通过轨迹感知校正系数动态调整积分间隔；3）使用闭式残差线性化模型近似缓存引起的误差。
- Result: 在标准图像和视频生成基准测试中，ERTACache实现了高达2倍的推理加速，同时保持甚至改善了视觉质量。在Wan2.1视频扩散模型上，2倍加速下VBench退化最小，有效保持了基准保真度。
- Conclusion: ERTACache通过系统性地解决缓存误差问题，为扩散模型提供了准确高效的采样方法，显著提高了效率同时保持了生成质量。


### [5] [Video-LLMs with Temporal Visual Screening](https://arxiv.org/abs/2508.21094)
*Zheyu Fan,Jiateng Liu,Yuji Zhang,Zihan Wang,Yi R.,Fung,Manling Li,Heng Ji*

Main category: cs.CV

TL;DR: 提出Temporal Visual Screening (TVS)任务，通过保留关键视频片段和重构查询来改善视频大语言模型的时序语义理解能力，在训练和推理阶段分别带来7.33%和34.6%的性能提升

- Motivation: 当前视频大语言模型由于稀疏帧采样和缺乏帧间推理监督，难以捕捉细粒度时序语义，而人类自然具备通过拖动进度条聚焦关键时间段的时序筛选能力
- Method: 提出TVS任务，包含三个核心步骤：(1)保留焦点关键视频片段，(2)同步重构查询为最直接形式同时保持答案一致性，(3)保持任何可能答案的不变性和一致性。TVS作为模块化前端适配器任务，可无缝集成到视频指令调优和视频问答流程中
- Result: 构建了首个TVS基准测试，提出的ReSimplifyIt基线方法在视频修剪任务上F-1分数比先前方法提高0.47，在查询重写任务上达到竞争性性能。实验显示TVS在训练阶段带来7.33%相对增益，推理阶段带来34.6%相对增益
- Conclusion: TVS通过优化推理负担和认知负载分布，有效改善了视频语言理解能力，证明了时序信息筛选对于提升视频大语言模型性能的重要性


### [6] [ROBUST-MIPS: A Combined Skeletal Pose and Instance Segmentation Dataset for Laparoscopic Surgical Instruments](https://arxiv.org/abs/2508.21096)
*Zhe Han,Charlie Budd,Gongyu Zhang,Huanyu Tian,Christos Bergeles,Tom Vercauteren*

Main category: cs.CV

TL;DR: 该论文提出使用骨骼姿态标注作为手术工具定位的更高效标注方法，并发布了ROBUST-MIPS数据集来促进这种标注方式的采用。

- Motivation: 传统基于深度学习的手术工具分割方法受限于标注数据的多样性，骨骼姿态标注在语义信息丰富度和标注效率之间取得了更好平衡，可以加速标注数据的增长。
- Method: 从现有ROBUST-MIS数据集衍生出包含工具姿态和实例分割标注的ROBUST-MIPS数据集，使用流行的姿态估计方法建立简单基准测试。
- Result: 观察到使用姿态标注进行手术工具定位可以获得高质量结果，证明了这种标注方式的充分性。
- Conclusion: 骨骼姿态标注是手术工具定位的有效方法，通过发布数据集、基准模型和标注软件来促进该标注方式的广泛采用。


### [7] [Safe-Control: A Safety Patch for Mitigating Unsafe Content in Text-to-Image Generation Models](https://arxiv.org/abs/2508.21099)
*Xiangtao Meng,Yingkai Dong,Ning Yu,Li Wang,Zheng Li,Shanqing Guo*

Main category: cs.CV

TL;DR: Safe-Control是一个即插即用的安全补丁，通过数据驱动策略和安全感知条件，在锁定T2I模型中注入安全控制信号，有效减少不安全内容生成，同时保持良性图像质量和文本对齐。

- Motivation: 现有的T2I生成模型安全机制容易受到分布偏移的规避攻击，或需要大量模型特定调整，存在局限性。
- Method: 使用数据驱动策略和安全感知条件，以补丁方式向锁定的T2I模型注入安全控制信号，支持构建多种安全补丁并灵活合并。
- Result: 在6个不同T2I模型上评估显示，Safe-Control将不安全内容生成概率降至7%，显著优于其他7种最先进的安全机制（约20%）。
- Conclusion: Safe-Control是一种有效的即插即用安全解决方案，能显著降低T2I模型的不安全内容生成，同时保持图像质量和文本对齐性能。


### [8] [GENNAV: Polygon Mask Generation for Generalized Referring Navigable Regions](https://arxiv.org/abs/2508.21102)
*Kei Katsumata,Yui Iioka,Naoki Hosomi,Teruhisa Misu,Kentaro Yamada,Komei Sugiura*

Main category: cs.CV

TL;DR: GENNAV是一个用于从自然语言指令和前置摄像头图像中识别目标区域位置的系统，特别擅长处理边界模糊的stuff-type目标区域，并在多目标和无目标情况下表现优异。

- Motivation: 现有方法在处理stuff-type目标区域（边界模糊）以及无目标或多目标情况时表现不佳，需要开发一个能够同时预测目标存在性和生成分割掩码的系统。
- Method: 提出GENNAV系统，能够预测目标存在性并为多个stuff-type目标区域生成分割掩码。构建了GRiN-Drive基准数据集，包含无目标、单目标和多目标三种样本类型。
- Result: GENNAV在标准评估指标上优于基线方法。在四个汽车、五个不同地理区域的真实世界实验中，展现了优异的零样本迁移性能和跨环境鲁棒性。
- Conclusion: GENNAV成功解决了stuff-type目标区域识别难题，在复杂真实环境中表现出色，为自动驾驶导航提供了有效的视觉语言理解解决方案。


### [9] [R-4B: Incentivizing General-Purpose Auto-Thinking Capability in MLLMs via Bi-Mode Annealing and Reinforce Learning](https://arxiv.org/abs/2508.21113)
*Jie Jiang,Qi Yang,Bolin Ni,Shiming Xiang,Han Hu,Houwen Peng*

Main category: cs.CV

TL;DR: R-4B是一个自适应思维的多模态大语言模型，能够根据问题复杂度智能决定是否启动思维过程，在保持高性能的同时降低计算成本

- Motivation: 现有的多模态大语言模型在处理简单问题时也会进行冗余的逐步思维过程，导致计算效率低下，需要一种能够自适应决定是否启动思维的方法
- Method: 采用双模式退火训练，结合双模式策略优化(BPO)，通过精心策划的数据集训练模型同时具备思维和非思维能力，并在改进的GRPO框架下进行第二阶段训练
- Result: 在25个具有挑战性的基准测试中达到最先进性能，在大多数任务中超越Qwen2.5-VL-7B，在推理密集型基准上与更大的16B模型性能相当但计算成本更低
- Conclusion: R-4B通过自适应思维机制成功解决了多模态大语言模型在处理简单问题时的计算效率问题，实现了性能与效率的平衡


### [10] [HiddenObject: Modality-Agnostic Fusion for Multimodal Hidden Object Detection](https://arxiv.org/abs/2508.21135)
*Harris Song,Tuan-Anh Vu,Sanjith Menon,Sriram Narasimhan,M. Khalid Jawed*

Main category: cs.CV

TL;DR: HiddenObject是一个基于Mamba的多模态融合框架，整合RGB、热成像和深度数据，用于检测遮挡或伪装目标，在多个基准数据集上达到先进性能。

- Motivation: 传统RGB检测方法在遮挡、伪装和光照变化等恶劣条件下性能受限，需要更鲁棒的模态无关方法来解决隐藏或部分遮蔽物体的检测挑战。
- Method: 提出Mamba-based融合机制，整合RGB、热成像和深度数据，识别模态特定特征并在统一表示中进行融合，适用于各种挑战性场景。
- Result: 在多个基准数据集上验证，相比现有方法达到state-of-the-art或竞争性性能，证明了融合设计的有效性。
- Conclusion: 基于Mamba的融合架构能显著推进多模态目标检测领域发展，特别是在视觉退化或复杂条件下，暴露了当前单模态和简单融合策略的关键局限性。


### [11] [RadGS-Reg: Registering Spine CT with Biplanar X-rays via Joint 3D Radiative Gaussians Reconstruction and 3D/3D Registration](https://arxiv.org/abs/2508.21154)
*Ao Shen,Xueming Fu,Junfeng Jiang,Qiang Zeng,Ye Tang,Zhengming Chen,Luming Nong,Feng Wang,S. Kevin Zhou*

Main category: cs.CV

TL;DR: RadGS-Reg是一个新颖的框架，通过联合3D辐射高斯重建和3D/3D配准，实现椎体级别的CT/X射线配准，解决了传统方法的空间信息丢失和域差距问题。

- Motivation: 传统"渲染和比较"方法在CT/X射线配准中存在空间信息丢失和域差距问题，而现有的双平面X射线3D重建方法受限于密集视图要求和噪声X射线的处理困难。
- Method: 提出RadGS-Reg框架，包含双平面X射线椎体辐射高斯重建模块，采用基于学习的辐射高斯重建方法，结合反事实注意力学习机制，专注于噪声X射线中的椎体区域。采用患者特定的预训练策略，从模拟数据逐步适应到真实数据。
- Result: 在内部数据集上的实验表明，该方法在两个任务上都达到了最先进的性能，超越了现有方法。
- Conclusion: RadGS-Reg通过联合重建和配准的方法，有效解决了CT/X射线配准中的挑战，为图像引导导航提供了高精度和实时性能的解决方案。


### [12] [SYNBUILD-3D: A large, multi-modal, and semantically rich synthetic dataset of 3D building models at Level of Detail 4](https://arxiv.org/abs/2508.21169)
*Kevin Mayer,Alex Vesel,Xinyi Zhao,Martin Fischer*

Main category: cs.CV

TL;DR: SYNBUILD-3D是一个包含620万个合成3D住宅建筑的大型多模态数据集，提供LoD 4级别的语义标注，支持三种数据模态：3D线框图、平面图图像和LiDAR式屋顶点云。

- Motivation: 由于缺乏大规模标注的3D建筑数据集，自动生成准确且语义丰富的3D建筑模型面临重大挑战。受计算机视觉中合成数据成功的启发，需要创建大规模合成数据集来推动3D建筑生成算法的发展。
- Method: 创建包含620万个合成3D住宅建筑的数据集，每个建筑通过三种模态表示：LoD 4级别的语义增强3D线框图、对应的平面图图像和LiDAR式屋顶点云。语义标注从平面图图像中提取，包含房间、门窗信息。
- Result: 成功构建了SYNBUILD-3D数据集，包含超过620万个合成3D建筑，提供三种数据模态和详细的语义标注。数据集和代码样本已公开可用。
- Conclusion: SYNBUILD-3D数据集为开发新型生成式AI算法提供了基础，能够自动化创建LoD 4级别的3D建筑模型，同时保持语义-几何一致性，推动3D建筑建模领域的发展。


### [13] [Radially Distorted Homographies, Revisited](https://arxiv.org/abs/2508.21190)
*Mårten Wadenbäck,Marcus Valtonen Örnhag,Johan Edstedt*

Main category: cs.CV

TL;DR: 提出了一种统一的方法来同时估计单应性和径向畸变，适用于三种不同的畸变配置情况，并开发了新的快速、稳定的最小求解器。

- Motivation: 在真实图像中，相机镜头引起的几何畸变（特别是径向畸变）会影响单应性估计的准确性，需要同时估计单应性和畸变参数。现有方法分别处理不同的畸变配置，缺乏统一的方法。
- Method: 提出了一种新颖的统一方法来解决三种径向畸变配置：（i）仅一个图像有畸变，（ii）两个图像有相同畸变，（iii）两个图像有独立畸变。基于该方法构建了快速、稳定、准确的最小求解器。
- Result: 在所有三种情况下，提出的求解器比现有最先进求解器更快，同时保持相似的精度。在包括鱼眼相机图像在内的标准基准测试中表现良好。
- Conclusion: 该方法提供了一个统一的框架来处理不同畸变配置的单应性估计问题，所开发的求解器在速度和精度方面都具有优势，适用于实际计算机视觉应用。


### [14] [GCAV: A Global Concept Activation Vector Framework for Cross-Layer Consistency in Interpretability](https://arxiv.org/abs/2508.21197)
*Zhenghao He,Sanchit Sinha,Guangzhi Xiong,Aidong Zhang*

Main category: cs.CV

TL;DR: 提出了全局概念激活向量(GCAV)框架，通过对比学习和注意力融合机制统一不同层的CAV表示，解决跨层概念不一致问题，提高概念归因的稳定性和可靠性。

- Motivation: 独立计算的不同层CAV存在不一致性，导致跨层比较不可靠，需要一种统一的概念表示方法来确保概念归因的稳定性。
- Method: 使用对比学习对齐跨层概念表示，采用基于注意力的融合机制构建全局集成的CAV，并提出了TGCAV测试方法。
- Result: 实验表明GCAV显著降低了TCAV分数的方差，保持了概念相关性，有效缓解了跨层概念不一致性，增强了概念定位能力，提高了对抗扰动的鲁棒性。
- Conclusion: GCAV通过整合跨层信息提供了一个更全面、可解释的深度神经网络概念编码理解框架，代码和模型已开源。


### [15] [Generalizable Object Re-Identification via Visual In-Context Prompting](https://arxiv.org/abs/2508.21222)
*Zhizhong Huang,Xiaoming Liu*

Main category: cs.CV

TL;DR: VICP是一个无需参数调整的视觉上下文提示框架，通过结合LLM和视觉基础模型，使模型能够仅使用上下文示例直接泛化到未见过的物体重识别类别。

- Motivation: 当前物体重识别方法需要为每个特定领域训练模型，缺乏泛化能力且需要大量标注数据。自监督学习虽然减少了标注需求，但难以捕捉对重识别至关重要的身份敏感特征。
- Method: VICP框架利用LLM从少量正负样本对中推断语义身份规则，通过任务特定的提示指导视觉基础模型（如DINO）提取身份判别特征。通过将LLM衍生的语义概念与VFM的预训练先验对齐，实现对新类别的泛化。
- Result: 在ShopID10K数据集和多个重识别基准测试中，VICP在未见类别上的性能明显优于基线方法。
- Conclusion: VICP通过视觉上下文提示实现了跨类别的零样本泛化，消除了数据集特定的重新训练需求，为物体重识别提供了新的解决方案。


### [16] [Lightweight MRI-Based Automated Segmentation of Pancreatic Cancer with Auto3DSeg](https://arxiv.org/abs/2508.21227)
*Keshav Jha,William Sharp,Dominic LaBella*

Main category: cs.CV

TL;DR: 本研究使用SegResNet模型在PANTHER挑战赛的两个MRI胰腺肿瘤分割任务上进行评估，结果显示T1加权MRI任务DSC为0.56，T2加权MRI任务性能下降至DSC 0.33，表明小数据集下MRI序列差异对胰腺肿瘤分割的挑战性。

- Motivation: 胰腺肿瘤的精确分割对诊断、治疗规划和结果评估至关重要，但由于解剖结构变异性和数据集有限，自动化分割仍然具有挑战性。
- Method: 采用SegResNet模型作为Auto3DSeg架构的一部分，在91例T1加权动脉对比增强MRI和50例T2加权MR-Linac病例上进行5折交叉验证，使用STAPLE集成方法，并聚焦解剖相关感兴趣区域。
- Result: 任务1（T1加权MRI）获得DSC 0.56、5 mm DSC 0.73、HD95 41.1mm；任务2（T2加权MRI）性能下降，DSC 0.33、5 mm DSC 0.50、HD95 20.1mm，显示不同MRI序列引入的变异性。
- Conclusion: 尽管性能一般，结果显示了自动化分割的潜力，强调需要更大、标准化的MRI数据集来提高模型鲁棒性和临床实用性。


### [17] [Reverse Imaging for Wide-spectrum Generalization of Cardiac MRI Segmentation](https://arxiv.org/abs/2508.21254)
*Yidong Zhao,Peter Kellman,Hui Xue,Tongyun Yang,Yi Zhang,Yuchi Han,Orlando Simonetti,Qian Tao*

Main category: cs.CV

TL;DR: Reverse Imaging是一种基于物理原理的心脏MRI数据增强方法，通过逆向推断基础自旋属性来解决不同成像序列间的泛化问题，显著提升分割模型在不同对比度图像上的准确性。

- Motivation: 预训练的心脏MRI分割模型在不同成像序列间泛化能力差，主要原因是图像对比度的显著差异。虽然成像协议不同，但所有图像都由相同的基础自旋属性（质子密度、T1、T2值）控制。
- Method: 提出Reverse Imaging方法：1）通过解决非线性逆问题从观测图像逆向推断基础自旋属性；2）使用扩散模型学习mSASHA数据集中的自旋属性先验分布；3）基于推断的自旋属性合成任意新序列的图像。
- Result: 该方法能够从MR图像获得有意义的自旋属性估计，作为可解释的潜在变量，实现高度灵活的图像合成，使分割模型在完全不同图像对比度和成像协议上实现高度准确的分割。
- Conclusion: Reverse Imaging从根本上解决了心脏MRI分割的泛化问题，实现了跨广泛光谱的泛化能力，为医学图像分析提供了物理驱动的数据增强和域适应新范式。


### [18] [PHD: Personalized 3D Human Body Fitting with Point Diffusion](https://arxiv.org/abs/2508.21257)
*Hsuan-I Ho,Chen Guo,Po-Chen Wu,Ivan Shugurov,Chengcheng Tang,Abhay Mittal,Sizhe An,Manuel Kaufmann,Linguang Zhang*

Main category: cs.CV

TL;DR: PHD是一种新颖的个性化3D人体网格恢复方法，通过用户特定的形状信息来提高视频姿态估计精度，使用点扩散变换器作为形状条件3D姿态先验，显著提升了绝对姿态准确性。

- Motivation: 传统HMR方法为了泛化性而设计为与用户无关，虽然通过2D图像约束优化姿态对齐，但牺牲了3D精度，未能同时考虑个性化身体形状和3D姿态的合理性。
- Method: 首先校准用户身体形状，然后基于该形状进行个性化姿态拟合。开发了身体形状条件3D姿态先验（Point Diffusion Transformer），通过点蒸馏采样损失迭代指导姿态拟合。
- Result: 不仅提高了骨盆对齐的姿态精度，还显著改善了绝对姿态精度——这是先前工作经常忽视的重要指标。方法数据效率高，仅需合成数据训练。
- Conclusion: PHD作为一个即插即用模块，可以无缝集成到现有3D姿态估计器中提升性能，有效减轻了对2D约束的过度依赖问题。


### [19] [Efficient Diffusion-Based 3D Human Pose Estimation with Hierarchical Temporal Pruning](https://arxiv.org/abs/2508.21363)
*Yuquan Bi,Hongsong Wang,Xinli Shi,Zhipeng Gui,Jie Gui,Yuan Yan Tang*

Main category: cs.CV

TL;DR: 提出了一种高效的基于扩散模型的3D人体姿态估计框架，采用分层时序剪枝策略(HTP)，在保持运动动态的同时大幅降低计算成本

- Motivation: 扩散模型虽然能生成高质量3D人体姿态，但其迭代特性和多假设需求导致计算成本过高，需要提高效率
- Method: 分层时序剪枝(HTP)策略：1)时序相关性增强剪枝(TCEP)分析帧间运动相关性识别关键帧；2)稀疏聚焦时序多头注意力(SFT MHSA)利用帧级稀疏性减少注意力计算；3)掩码引导姿态令牌剪枝器(MGPTP)通过聚类进行细粒度语义剪枝
- Result: 在Human3.6M和MPI-INF-3DHP数据集上，HTP减少训练MACs 38.5%，推理MACs 56.8%，推理速度平均提升81.1%，同时达到最先进性能
- Conclusion: 提出的HTP策略有效解决了扩散模型在3D人体姿态估计中的计算效率问题，在显著降低计算成本的同时保持了优异的性能表现


### [20] [Print2Volume: Generating Synthetic OCT-based 3D Fingerprint Volume from 2D Fingerprint Image](https://arxiv.org/abs/2508.21371)
*Qingran Miao,Haixia Wang,Haohao Sun,Yilong Zhang*

Main category: cs.CV

TL;DR: Print2Volume是一个从2D指纹图像生成逼真合成OCT 3D指纹的新框架，通过解决OCT数据稀缺问题显著提升了生物识别性能

- Motivation: OCT技术能获取高分辨率3D指纹数据，但数据采集成本高、耗时长，导致大规模公开数据集稀缺，阻碍了深度学习模型的发展
- Method: 三阶段框架：1）2D风格转换模块将二值指纹转为灰度图像；2）3D结构扩展网络将2D图像外推为3D解剖体积；3）基于3D GAN的OCT真实感细化器添加纹理和噪声特征
- Result: 生成了42万个合成样本，预训练识别模型后在小型真实数据集上微调，将等错误率从15.62%显著降低到2.50%
- Conclusion: Print2Volume有效解决了OCT指纹数据稀缺问题，合成数据质量高，能显著提升生物识别性能，为深度学习模型发展提供了重要数据支持


### [21] [GLENDA: Gynecologic Laparoscopy Endometriosis Dataset](https://arxiv.org/abs/2508.21398)
*Andreas Leibetseder,Sabrina Kletz,Klaus Schoeffmann,Simon Keckstein,Jörg Keckstein*

Main category: cs.CV

TL;DR: 发布了首个妇科腹腔镜子宫内膜异位症数据集GLENDA，包含子宫内膜异位症的区域标注，旨在解决医学影像分析中样本数据稀缺的问题。

- Motivation: 妇科腹腔镜手术视频的手动分析过程耗时且繁琐，而现有的计算机视觉和机器学习方法严重依赖样本数据，但在医学领域样本数据稀缺。
- Method: 与领先医学专家合作创建了包含子宫内膜异位症区域标注的图像数据集GLENDA，这是该领域的首个此类数据集。
- Result: 成功发布了GLENDA数据集，为妇科腹腔镜手术的计算机视觉分析提供了宝贵的标注数据资源。
- Conclusion: GLENDA数据集的发布将促进妇科腹腔镜手术的自动化分析技术发展，支持治疗规划、病例记录和教育等术后活动。


### [22] [Identifying Surgical Instruments in Laparoscopy Using Deep Learning Instance Segmentation](https://arxiv.org/abs/2508.21399)
*Sabrina Kletz,Klaus Schoeffmann,Jenny Benois-Pineau,Heinrich Husslein*

Main category: cs.CV

TL;DR: 该研究评估了使用基于区域的完全卷积网络在腹腔镜妇科手术视频中进行手术器械实例分割和识别的性能，结果显示器械分割准确率较高，但器械类型识别仍具挑战性。

- Motivation: 手术视频记录已成为医学内窥镜领域的重要信息源，但自动内容索引（基于内容搜索的基础）由于特殊的视频内容而面临巨大挑战。
- Method: 使用基于区域的完全卷积网络进行实例感知的(1)器械分割（二值分割）和(2)器械识别（多类别识别）。
- Result: 即使训练样本数量适中，也能以较高准确率定位和分割器械区域；但确定具体器械类型仍然非常困难，因为手术器械具有固有的高度相似性。
- Conclusion: 手术器械分割技术已经相当成熟，但器械类型识别仍是一个需要进一步研究的挑战性任务，主要受限于器械间的高度相似性。


### [23] [SatDINO: A Deep Dive into Self-Supervised Pretraining for Remote Sensing](https://arxiv.org/abs/2508.21402)
*Jakub Straka,Ivan Gruber*

Main category: cs.CV

TL;DR: SatDINO是一个基于DINO对比自监督学习的卫星图像表示学习模型，在多个数据集和测试设置中超越了基于掩码自编码器的方法，并提出了新的GSD编码和自适应视图采样增强技术。

- Motivation: 遥感领域存在大量未标记数据，自监督学习为此提供了强大工具。研究旨在探索DINO对比自监督方法在遥感图像预训练中的应用，开发专门针对卫星图像的表示学习模型。
- Method: 提出了SatDINO模型，基于DINO对比自监督学习方法，专门为卫星图像设计。引入了新的地面采样距离(GSD)编码方式和自适应视图采样技术，这些增强技术可以独立应用于模型。
- Result: 在多个数据集和测试设置中，SatDINO显著优于基于掩码自编码器(MAE)的最先进方法，在多个基准测试中取得了有竞争力的结果。通过严格的消融研究评估了各个组件的贡献。
- Conclusion: SatDINO证明了对比自监督学习在遥感图像表示学习中的有效性，提出的GSD编码和自适应视图采样等新颖增强技术可以提升模型性能，代码和训练模型已开源。


### [24] [Standardized Multi-Layer Tissue Maps for Enhanced Artificial Intelligence Integration and Search in Large-Scale Whole Slide Image Archives](https://arxiv.org/abs/2508.21418)
*Gernot Fiala,Markus Plass,Robert Harb,Peter Regitnig,Kristijan Skok,Wael Al Zoughbi,Carmen Zerner,Paul Torke,Michaela Kargl,Heimo Müller,Tomas Brazdil,Matej Gallo,Jaroslav Kubín,Roman Stoklasa,Rudolf Nenutil,Norman Zerbe,Andreas Holzinger,Petr Holub*

Main category: cs.CV

TL;DR: 提出了一种为全屋正床切片图像(WSI)生成2D索引地图的标准化框架，通过三层组织结构提供细粒度的组织类型和病理变化信息，解决了大规模WSI集合中手动选择的效率问题。

- Motivation: 由于目前缺乏标准化的WSI元数据，在构建AI算法训练或验证集时，需要通过手动检查来确定WSI内容，这对包含数百万对象的大规模集合来说效率极低。
- Method: 提出了一个通用框架，为WSI生成2D索引地图和特定应用域的配置机制。组织成三个层次：来源层、组织类型层和病理变化层，每个层都将WSI的区域分配给特定类别。使用通用语法和语义来实现不同目录之间的互操性。
- Result: 在临床病理学领域进行了实践应用，通过具体例子展示了该标准在WSI目录、机器学习和基于图的WSI表示中的优势和适用性。
- Conclusion: 该方法为大规模WSI集合提供了一种标准化的元数据生成方案，有效解决了手动选择的效率问题，对于推动AI算法在医学图像分析领域的发展具有重要意义。


### [25] [Unsupervised Incremental Learning Using Confidence-Based Pseudo-Labels](https://arxiv.org/abs/2508.21424)
*Lucas Rakotoarivony*

Main category: cs.CV

TL;DR: 提出了一种基于置信度伪标签的无监督增量学习方法ICPL，能够在无标注数据集上进行增量学习，性能接近有监督方法并优于现有class-iNCD方法5%以上

- Motivation: 现实世界中经常出现训练时未见的新类别，需要模型增量学习新知识。现有类增量学习方法假设增量数据集完全标注，这在实践中不现实
- Method: 使用置信度伪标签替代人工标注，将伪标签集成到各种CIL方法中，通过置信度选择机制，在无标注数据集上实现增量学习
- Result: 在CIFAR100和ImageNet100上评估性能下降，相比有监督方法获得竞争性结果，比最先进的class-iNCD方法最终准确率高5%以上
- Conclusion: ICPL方法证明了在无标注数据上进行增量学习的可行性，在细粒度数据集上展示实际应用价值，计算复杂度验证了其在资源受限环境中的适用性


### [26] [MedShift: Implicit Conditional Transport for X-Ray Domain Adaptation](https://arxiv.org/abs/2508.21435)
*Francisco Caetano,Christiaan Viviers,Peter H. H. de With,Fons van der Sommen*

Main category: cs.CV

TL;DR: MedShift是一个基于Flow Matching和Schrodinger Bridges的统一类条件生成模型，用于解决合成与真实X射线图像之间的跨域转换问题，在保持较小模型规模的同时实现高保真度图像翻译。

- Motivation: 合成医疗数据虽然可扩展，但与真实临床数据存在显著域差距，限制了模型在真实世界中的泛化能力。需要解决合成和真实X射线图像在衰减行为、噪声特征和软组织表示等方面的差异。
- Method: 提出MedShift模型，基于Flow Matching和Schrodinger Bridges构建统一类条件生成模型。学习共享的域无关潜在空间，支持训练期间见过的任意域对之间的无缝转换。引入X-DigiSkull数据集进行基准测试。
- Result: 实验结果表明，尽管相比基于扩散的方法模型规模更小，MedShift表现出强大性能，在推理时保持灵活性，可以调整以优先考虑感知保真度或结构一致性。
- Conclusion: MedShift为医学成像中的域适应提供了一个可扩展和可泛化的解决方案，能够有效桥接合成与真实医疗图像之间的域差距。


### [27] [Trees as Gaussians: Large-Scale Individual Tree Mapping](https://arxiv.org/abs/2508.21437)
*Dimitri Gominski,Martin Brandt,Xiaoye Tong,Siyu Liu,Maurice Mugabowindekwe,Sizhuo Li,Florian Reiner,Andrew Davies,Rasmus Fensholt*

Main category: cs.CV

TL;DR: 本研究提出了一种基于深度学习的全球尺度个体大树检测方法，使用3米分辨率PlanetScope影像和高斯核模拟树冠，通过从机载激光雷达自动提取的数十亿个点进行训练，实现了在森林内外的高精度树木检测。

- Motivation: 现有全球产品主要关注二元树冠覆盖或冠层高度，无法在个体水平上识别树木，限制了大规模树木监测的能力。
- Method: 使用深度学习方法和高斯核模拟可扩展大小的树冠，从机载激光雷达数据自动提取数十亿个点进行训练，能够提取树冠中心并生成二元树冠覆盖图。
- Result: 与现有树冠覆盖图和机载激光雷达相比达到最先进性能（与航空激光雷达的分数覆盖R²=0.81），在不同生物群落中报告了平衡的检测指标，并通过手动标签微调进一步提高了检测精度。
- Conclusion: 该方法为全球高分辨率树木监测提供了一个可扩展的框架，并能适应未来提供改进影像的卫星任务。


### [28] [Scale-GS: Efficient Scalable Gaussian Splatting via Redundancy-filtering Training on Streaming Content](https://arxiv.org/abs/2508.21444)
*Jiayu Yang,Weijian Su,Songqian Zhang,Yuqi Han,Jinli Suo,Qiang Zhang*

Main category: cs.CV

TL;DR: M框架通过分层高斯球结构和混合变形生成策略，显著降低了动态3D高斯溅射的训练时间和数据量，同时保持高质量渲染效果。

- Motivation: 3D高斯溅射(3DGS)虽然能实现高保真实时渲染，但在动态场景中存在高斯数据量大和训练时间长的限制，需要更高效的训练框架。
- Method: 采用基于锚点的分层高斯球结构，粗粒度高斯表示场景低分辨率结构，细粒度高斯负责细节渲染；引入混合变形和生成策略处理帧间运动；使用双向自适应掩码机制提升训练效率。
- Result: 大量实验表明，M框架在显著减少训练时间的同时，实现了优于现有方法的视觉质量。
- Conclusion: 该框架为动态场景的高斯溅射提供了一种可扩展且高效的解决方案，在训练效率和渲染质量方面都有显著提升。


### [29] [One More Glance with Sharp Eyes: Rethinking Lightweight Captioning as a Practical Visual Specialist](https://arxiv.org/abs/2508.21451)
*Junha Song,Yongsik Jo,So Yeon Min,Quanting Xie,Taehwan Kim,Yonatan Bisk,Jaegul Choo*

Main category: cs.CV

TL;DR: 本文提出了一种轻量级图像描述模型，参数量仅为125M（比LLaMA-7B小56倍），性能可与大型多模态通用模型相媲美，并开发了Sharp-Eyed Refinement框架来解决视觉盲区问题。

- Motivation: 多模态大语言模型计算需求高，难以在本地设备部署。需要探索轻量级但性能相当的图像描述解决方案。
- Method: 基于125M参数语言模型构建专家模型，并提出Sharp-Eyed Refinement框架，通过DeepLens组件提取详细视觉表示，专注于信息丰富的区域。
- Result: 模型在单句和详细描述任务上表现优异，性能接近大型多模态通用模型，且新框架有效提升了描述质量。
- Conclusion: 轻量级专家模型可作为设备端应用的强大视觉专家，Sharp-Eyed Refinement框架成功解决了视觉盲区问题，为本地部署提供了可行方案。


### [30] [Federated Fine-tuning of SAM-Med3D for MRI-based Dementia Classification](https://arxiv.org/abs/2508.21458)
*Kaouther Mouheb,Marawan Elbatel,Janne Papma,Geert Jan Biessels,Jurgen Claassen,Huub Middelkoop,Barbara van Munster,Wiesje van der Flier,Inez Ramakers,Stefan Klein,Esther E. Bron*

Main category: cs.CV

TL;DR: 这篇论文通过系统化对比评估，探索了基础模型在联邦学习环境下对失智症诊断的关键设计选择，包括分类头结构、微调策略和聚合方法的影响。

- Motivation: 基础模型在AI失智症诊断中具有强大潜力，但其在联邦学习系统中的集成研究仍少有深入探索。需要系统性评估关键设计选择对性能和效率的影响。
- Method: 使用大规模多中心脑部MRI数据集，通过对比实验评估三个关键因素：分类头结构设计、微调策略（全部微调vs冻结编码器）、聚合方法（标准联邦平均vs高级聚合方法）。
- Result: 发现分类头结构对性能有显著影响，冻结FM编码器可以达到与全部微调相似的效果，高级聚合方法超过标准联邦平均方法。
- Conclusion: 研究结果为在去中心化临床环境中部署基础模型提供了实用指导，并指出了需要在方法开发中考虑的交易抹选择。


### [31] [Multi-Method Ensemble for Out-of-Distribution Detection](https://arxiv.org/abs/2508.21463)
*Lucas Rakotoarivony*

Main category: cs.CV

TL;DR: 提出了Multi-Method Ensemble (MME)评分方法，通过结合特征截断和多种评分函数来提升OOD检测性能，在多个基准测试中显著优于现有方法。

- Motivation: 现有OOD检测方法通常只关注单一技术家族或在特定类型OOD数据集上评估，忽略了结合多种现有解决方案的潜力。
- Method: 理论分析和实证证明可以有效地结合最先进的特征截断和评分函数，并提出MME评分方法统一多个最先进的OOD检测器。
- Result: 在大型和小型基准测试中，MME在所有基准上都显著优于最近的最先进方法，在ImageNet-1K基准上FPR95达到27.57%，比最佳基线提升6%。
- Conclusion: 通过集成多种OOD检测技术可以显著提高检测性能，MME方法为开放世界环境中的神经网络提供了更有效的OOD样本检测解决方案。


### [32] [Adversarial Patch Attack for Ship Detection via Localized Augmentation](https://arxiv.org/abs/2508.21472)
*Chun Liu,Panpan Ding,Zheng Zheng,Hailong Wang,Bingqian Zhu,Tao Xu,Zhigang Han,Jiayao Wang*

Main category: cs.CV

TL;DR: 本文提出了一种局部数据增强方法，只对目标区域进行增强，避免背景干扰，提高对船舶检测模型的对抗表示例攻击成功率和转移性。

- Motivation: 当前基于深度神经网络的船舶检测技术容易受到对抗补丁攻击的影响，而传统的全局数据增强方法可能引入背景干扰，导致假检测。
- Method: 提出局部增强方法，仅对目标区域进行数据增强，避免影响非目标区域，使损失函数更聚焦于对抗补丁对检测模型的影响。
- Result: 在HRSC2016数据集上的实验表明，该方法有效提高了对抗补丁攻击的成功率，并增强了攻击的转移性。
- Conclusion: 局部增强方法通过减少背景干扰，能够更有效地提高对抗补丁攻击的效果，为远感图像船舶检测的安全防护提供了新思路。


### [33] [ELV-Halluc: Benchmarking Semantic Aggregation Hallucinations in Long Video Understanding](https://arxiv.org/abs/2508.21496)
*Hao Lu,Jiahao Wang,Yaolun Zhang,Ruohui Wang,Xuanyu Zheng,Yepeng Tang,Dahua Lin,Lewei Lu*

Main category: cs.CV

TL;DR: 这篇论文提出了专门针对长视频的幻觉出现问题的ELV-Halluc标准化测试集，重点研究了语义聚合幻觉（SAH）现象，并提出了通过位置编码策略和DPO训练来减少这种幻觉。

- Motivation: 当前视频多模态大语言模型存在幻觉问题，而现有的短视频幻觉测试集过于简化了幻觉原因。特别是在长视频中，语义聚合幻觉（SAH）问题更为严重，需要专门的标准化测试集来系统研究。
- Method: 构建ELV-Halluc标准化测试集，定义了语义聚合幻觉（SAH）的概念，并通过实验验证SAH的存在和特征。提出使用位置编码策略和DPO（对待策略优化）来减少SAH，并构建了8K对抗数据对进行训练。
- Result: 实验证明SAH确实存在，且随着语义复杂性增加而增加。模型在语义快速变化时更容易出现SAH。通过位置编码和DPO策略，在ELV-Halluc和Video-MME上都取得了改善，SAH比率减少27.7%。
- Conclusion: 这项研究系统地研究了长视频中的语义聚合幻觉问题，提供了专门的标准化测试集和有效的减少幻觉的方法，为视频多模态模型的可靠性提升提供了重要支撑。


### [34] [Maybe you don't need a U-Net: convolutional feature upsampling for materials micrograph segmentation](https://arxiv.org/abs/2508.21529)
*Ronan Docherty,Antonis Vamvakeros,Samuel J. Cooper*

Main category: cs.CV

TL;DR: 提出一种卷积神经网络上采样器，用于提升基础模型在显微图像中的特征分辨率，实现高效准确的图像分割

- Motivation: 现有的基于patch的基础模型在处理显微图像时面临两个问题：1) 无法捕捉细微特征 2) 难以处理大尺寸图像。需要一种方法来提升特征分辨率以支持精确分割
- Method: 训练卷积神经网络，参考输入图像对低分辨率基础模型特征进行上采样，无需额外训练即可应用于多种显微图像
- Result: 该方法能够有效分离难以分割的相（如发丝裂纹），交互式分割所需标签数量显著减少，分割质量高且速度快
- Conclusion: 基于深度特征上采样的方法在显微图像分割中表现出色，相比传统卷积网络需要更少的标签和训练时间，实现了高效准确的分割


### [35] [HCCM: Hierarchical Cross-Granularity Contrastive and Matching Learning for Natural Language-Guided Drones](https://arxiv.org/abs/2508.21539)
*Hao Ruan,Jinliang Lin,Yingxin Lai,Zhiming Luo,Shaozi Li*

Main category: cs.CV

TL;DR: 提出HCCM框架解决无人机场景中视觉语言理解的挑战，通过区域-全局对比学习和匹配机制，在GeoText-1652数据集上达到SOTA性能，并在未见数据集上展现强大零样本泛化能力

- Motivation: 无人机场景中宽视场和复杂组合语义对视觉语言理解构成挑战，主流VLM缺乏细粒度语义，现有分层方法依赖精确实体分割和严格包含关系，在动态环境中效果有限
- Method: 提出HCCM框架：1）RG-ITC区域-全局图像文本对比学习，避免精确场景分割；2）RG-ITM区域-全局图像文本匹配，评估局部语义一致性；3）MCD动量对比和蒸馏机制提高鲁棒性
- Result: 在GeoText-1652数据集上达到28.8%（图像检索）和14.7%（文本检索）的Recall@1；在未见ERA数据集上达到39.93%的平均召回率，优于微调基线
- Conclusion: HCCM框架有效解决了无人机场景中的视觉语言理解挑战，通过分层跨粒度对比和匹配学习，在标准数据集和零样本泛化方面都表现出优异性能


### [36] [Complete Gaussian Splats from a Single Image with Denoising Diffusion Models](https://arxiv.org/abs/2508.21542)
*Ziwei Liao,Mohamed Sayed,Steven L. Waslander,Sara Vicente,Daniyar Turmukhambetov,Michael Firman*

Main category: cs.CV

TL;DR: 提出基于潜在扩散模型的单图像3D高斯溅射场景重建方法，能够从单张图像生成完整的3D场景（包括遮挡部分），解决了传统方法在遮挡区域重建中的模糊和单一模式问题。

- Motivation: 传统高斯溅射方法需要密集观测，无法重建遮挡和未观测区域，且回归方法只能预测单一模式，导致模糊和不合理的结果。需要一种能够从单张图像生成完整3D场景并处理遮挡区域多样性的方法。
- Method: 使用变分自重构器从2D图像自监督学习潜在空间，然后在该潜在空间上训练扩散模型，以学习条件于单张输入图像的3D高斯溅射表示分布。
- Result: 方法能够生成忠实重建和多样化样本，成功完成遮挡表面重建，实现高质量的360度渲染。
- Conclusion: 提出的生成式方法能够从单张图像有效重建完整3D场景，解决了遮挡区域重建的挑战，相比传统方法在完整性和多样性方面表现更优。


### [37] [EZ-Sort: Efficient Pairwise Comparison via Zero-Shot CLIP-Based Pre-Ordering and Human-in-the-Loop Sorting](https://arxiv.org/abs/2508.21550)
*Yujin Park,Haejun Chung,Ikbeom Jang*

Main category: cs.CV

TL;DR: EZ-Sort通过CLIP零样本预排序和不确定性引导的合并排序，将成对比较的标注成本从O(n²)降低到接近O(n log n)，相比现有方法减少19.8%人工标注，同时保持评分一致性。

- Motivation: 成对比较虽然比绝对评分更可靠，但穷举比较需要O(n²)次标注，成本过高。现有方法使用排序算法将标注次数降到O(n log n)，但仍需进一步降低人工标注负担。
- Method: 提出EZ-Sort方法：1) 使用CLIP模型进行分层零样本预排序；2) 用自动化比较替代明显的人类比较；3) 初始化桶感知Elo分数；4) 运行不确定性引导的人类参与合并排序。
- Result: 在多个数据集上验证：人脸年龄估计(FGNET)、历史图像年代学(DHCI)、视网膜图像质量评估(EyePACS)。相比穷举比较减少90.5%人工标注，相比现有方法减少19.8%(n=100时)，同时保持或提高了评分者间一致性。
- Conclusion: 结合CLIP先验知识和不确定性感知采样，为成对排序提供了高效且可扩展的解决方案，显著降低了人工标注成本。


### [38] [ECHO: Ego-Centric modeling of Human-Object interactions](https://arxiv.org/abs/2508.21556)
*Ilya A. Petrov,Vladimir Guzov,Riccardo Marin,Emre Aksan,Xu Chen,Daniel Cremers,Thabo Beeler,Gerard Pons-Moll*

Main category: cs.CV

TL;DR: ECHO是一个从头部和手腕追踪数据中恢复人-物交互的统一框架，使用扩散Transformer架构和三变量扩散过程，能够同时重建人体姿态、物体运动和接触信息。

- Motivation: 随着可穿戴设备的普及，从第一人称视角建模人-物交互是一个重要但未被充分探索的问题。研究旨在探索仅通过头部和手腕追踪能恢复多少交互信息。
- Method: 采用扩散Transformer架构和独特的三变量扩散过程，在头部中心规范空间中操作，提出基于传送带的推理方法，可以处理任意长度的序列。
- Result: 通过广泛评估表明，ECHO在自我中心人-物交互重建方面优于现有方法，达到了最先进的性能。
- Conclusion: ECHO首次提出了一个统一的框架，能够从最小化的观测数据中恢复三种模态信息，为可穿戴设备的人-物交互建模提供了有效的解决方案。


### [39] [How Well Do Vision--Language Models Understand Cities? A Comparative Study on Spatial Reasoning from Street-View Images](https://arxiv.org/abs/2508.21565)
*Juneyoung Ro,Namwoo Kim,Yoonjin Yoon*

Main category: cs.CV

TL;DR: 本文研究现有视觉-语言模型在城市场景空间推理能力，通过构建合成VQA数据集并精调提升了模型在具体城市场景中的表现。

- Motivation: 当前视觉-语言模型在通用场景上领域训练，但在城市场景空间推理能力上的转移效果仍不明确，需要系统性评估和提升。
- Method: 构建基于街景图像分割、深度和物体检测的合成VQA数据集，包含LLM生成的链式思绪答案，对BLIP-2、InstructBLIP和LLaVA-1.5三款模型进行零样本测试和精调对比。
- Result: 零样本情况下VLMs表现良好，但使用合成CoT监督数据集精调后性能显著提升，特别是在否定和反事实问题类型上。
- Conclusion: 城市空间推理是VLMs的新挑战，通过合成数据集构建可以有效地将通用模型适配到专业领域。


### [40] [Temporal Flow Matching for Learning Spatio-Temporal Trajectories in 4D Longitudinal Medical Imaging](https://arxiv.org/abs/2508.21580)
*Nico Albert Disch,Yannick Kirchhoff,Robin Peretzke,Maximilian Rokuss,Saikat Roy,Constantin Ulrich,David Zimmerer,Klaus Maier-Hein*

Main category: cs.CV

TL;DR: 提出了Temporal Flow Matching (TFM)方法，用于4D医学图像预测，通过学习时间分布来生成精细的空间预测，在三个公共纵向数据集上达到了最先进的性能。

- Motivation: 现有深度学习方法要么只考虑单一时间上下文，要么局限于分类或回归任务，无法进行细粒度空间预测，且现有方法通常局限于单时间点、特定疾病或有其他技术限制。
- Method: Temporal Flow Matching (TFM)是一种统一的生成轨迹方法，能够学习底层时间分布，支持3D体积、多个先验扫描和不规则采样，并能回退到最近图像预测器作为特殊情况。
- Result: 在三个公共纵向数据集上的广泛基准测试表明，TFM始终超越自然成像中的时空方法，为4D医学图像预测建立了新的最先进和鲁棒的基线。
- Conclusion: TFM解决了医学成像中时间动态建模的根本性差距，为疾病进展建模、治疗规划和解剖发育跟踪等应用提供了强大的统一框架。


### [41] [Integrating Pathology and CT Imaging for Personalized Recurrence Risk Prediction in Renal Cancer](https://arxiv.org/abs/2508.21581)
*Daniël Boeke,Cedrik Blommestijn,Rebecca N. Wray,Kalina Chupetlovska,Shangqi Gao,Zeyu Gao,Regina G. H. Beets-Tan,Mireia Crispin-Ortuzar,James O. Jones,Wilson Silva,Ines P. Machado*

Main category: cs.CV

TL;DR: 该研究开发了一个多模态深度学习框架，整合术前CT和术后病理切片图像，用于透明细胞肾癌的复发风险预测，发现病理图像比CT图像具有更强的预后价值，中间融合策略能进一步提升性能。

- Motivation: Leibovich评分系统在透明细胞肾癌复发风险分层中应用广泛，但存在患者层面分辨率有限和缺乏影像信息的局限性，需要开发更精准的多模态预测方法。
- Method: 采用模块化深度学习框架，使用预训练编码器和基于Cox的生存模型，测试了单模态、晚期融合和中间融合三种设置，比较了CT和病理切片图像的表现。
- Result: 病理切片模型始终优于CT模型，中间融合策略（TITAN-CONCH with ResNet-18）表现最佳，接近调整后的Leibovich评分，放射学信息通过融合提供附加价值。
- Conclusion: 证明了基于基础模型的多模态整合在个性化ccRCC风险预测中的可行性，未来需要探索更具表现力的融合策略、更大的多模态数据集和通用CT编码器。


### [42] [Unfolding Framework with Complex-Valued Deformable Attention for High-Quality Computer-Generated Hologram Generation](https://arxiv.org/abs/2508.21657)
*Haomiao Zhang,Zhangyuan Li,Yanling Piao,Zhi Li,Xiaodong Wang,Miao Cao,Xiongfei Su,Qiang Song,Xin Yuan*

Main category: cs.CV

TL;DR: 本文提出一种深度展开网络(DUN)，通过将梯度下降分解为适应带宽保持模型(ABPM)和相位域复数去噪器(PCD)，解决了计算机生成全息术(CGH)中的几个关键挑战，包括黑盒模型、受限感受野和有限距离限制问题。

- Motivation: 解决当前深学习基于CGH算法存在的三个主要问题：1)端到端网络忽略物理关系，导致可解释性和灵活性下降；2)CNN算法感受野有限，无法捐捕长程依赖；3)ASM基模型受限于有限近场范围。
- Method: 提出深度展开网络(DUN)，将梯度下降过程分解为两个模块：适应带宽保持模型(ABPM)和相位域复数去噪器(PCD)。ABPM提供更宽的工作距离，PCD利用复数变形自注意力模块捐捕全局特征。
- Result: 在模拟和实际数据上达到了状态上最优结果，实现了超过35dB的PSNR。ABPM模块提供了比ASM基方法更宽的工作距离范围。
- Conclusion: 该方法通过结合物理模型和深度学习的深度展开网络，有效解决了CGH重建中的几个关键挑战，提供了更好的可解释性、灵活性和性能。


### [43] [Towards Interactive Lesion Segmentation in Whole-Body PET/CT with Promptable Models](https://arxiv.org/abs/2508.21680)
*Maximilian Rokuss,Yannick Kirchhoff,Fabian Isensee,Klaus H. Maier-Hein*

Main category: cs.CV

TL;DR: 基于autoPET III nnU-Net框架，通过添加用户点击提示作为额外输入通道，开发了可提示的PET/CT病灶分割模型，使用欧几里得距离变换编码优于高斯核，在交互式分割任务中表现最佳。

- Motivation: 解决全身PET/CT中由于示踪剂异质性、生理性摄取和多中心变异性导致的准确病灶分割挑战，开发保持人类在环的高效交互式分割方法。
- Method: 扩展autoPET III nnU-Net框架，将用户提供的前景和背景点击编码为额外输入通道，系统研究空间提示表示方法，提出在线模拟用户交互和自定义点采样策略。
- Result: 基于EDT的集成模型在交叉验证中表现最强，相比基线模型减少了假阳性和假阴性，在真实提示条件下具有更好的鲁棒性。
- Conclusion: 可提示模型在多示踪剂、多中心PET/CT中具有实现高效用户引导分割工作流程的潜力，代码已公开。


### [44] [Mapping like a Skeptic: Probabilistic BEV Projection for Online HD Mapping](https://arxiv.org/abs/2508.21689)
*Fatih Erdoğan,Merve Rabia Barın,Fatma Güney*

Main category: cs.CV

TL;DR: 提出了一种新的概率投影机制，通过置信度分数优化BEV空间映射，提高HD地图构建的准确性和泛化能力

- Motivation: 现有HD地图构建方法使用标准映射技术存在泛化问题，容易产生虚假道路元素，需要更精确的几何映射方法
- Method: 基于相机参数的几何映射，结合概率投影机制和置信度分数来细化映射并过滤无关元素，改进时间处理通过选择性积累可靠信息
- Result: 在nuScenes和Argoverse2数据集的新划分上表现优于现有最先进方法，特别是在nuScenes和长感知范围场景中改进显著
- Conclusion: 提出的概率投影机制有效提高了HD地图构建的准确性和泛化性能，特别是在挑战性场景中表现优异


### [45] [Why Stop at Words? Unveiling the Bigger Picture through Line-Level OCR](https://arxiv.org/abs/2508.21693)
*Shashank Vempati,Nishit Anand,Gaurav Talebailkar,Arpan Garai,Chetan Arora*

Main category: cs.CV

TL;DR: 这篇论文提出了从单词级到行级OCR的转变，通过绕过单词分割错误和提供更大语境上下文来提高识别准确性和效率。

- Motivation: 传统单词级OCR存在单词分割粒度的粒度瓶颈，导致分割错误和语言模型利用不充分。需要绕过这些限制来提升性能。
- Method: 提出行级OCR方法，直接将整行文本作为输入，利用序列到序列模型进行字符序列输出。同时构建了包含251张英语页面图像的行级注释数据集。
- Result: 实验结果显示端到端准确性提高5.4%，效率提高了4倍，证明了行级OCR在准确性和效率方面的优势。
- Conclusion: 行级OCR是一种有效的进步方法，能够绕过单词分割错误，提供更好的语言模型利用，并且与大语言模型的发展保持兼容性。


### [46] [FLORA: Efficient Synthetic Data Generation for Object Detection in Low-Data Regimes via finetuning Flux LoRA](https://arxiv.org/abs/2508.21712)
*Alvaro Patricio,Atabak Dehban,Rodrigo Ventura*

Main category: cs.CV

TL;DR: FLORA是一种轻量级合成数据生成方法，使用LoRA微调Flux扩散模型，仅需消费级GPU和500张合成图像就能在目标检测任务中超越需要5000张图像和V100 GPU的基线方法。

- Motivation: 解决现有基于扩散模型的合成数据生成方法计算资源需求高、需要企业级GPU和大量合成图像的问题，使合成数据生成更加实用和普及。
- Method: 使用Flux 1.1 Dev扩散模型，通过低秩适应（LoRA）进行微调，构建轻量级合成数据生成流水线，大幅降低计算需求。
- Result: 在7个不同目标检测数据集上，仅用500张合成图像训练的检测器性能优于使用5000张合成图像的ODGEN基线，mAP@.50:.95提升高达21.3%。
- Conclusion: FLORA证明了质量和效率导向的方法比暴力生成更有效，仅用10%的数据和少量计算成本就能达到最先进性能，使高级合成数据生成更加实用和普及。


### [47] [Entropy-Based Non-Invasive Reliability Monitoring of Convolutional Neural Networks](https://arxiv.org/abs/2508.21715)
*Amirhossein Nazeri,Wael Hafez*

Main category: cs.CV

TL;DR: 本文发现对抗性扰动会在CNN激活中产生可检测的熵特征，无需模型修改即可实现90%的检测准确率，假阳性和假阴性率低于20%。

- Motivation: 现有对抗性攻击检测方法需要昂贵的重新训练、修改网络架构或降低干净输入的性能，需要一种无需修改模型即可实时检测的方法。
- Method: 通过在VGG-16上并行监控激活熵，发现对抗性输入在早期卷积层中使激活熵产生7%的偏移。
- Result: 对抗性输入与干净输入的熵分布完全分离，实现了90%的检测准确率，假阳性和假阴性率均低于20%。
- Conclusion: CNN的可靠性可以通过激活熵单独评估，实现了无需影响原始模型性能的实时自诊断视觉系统部署。


### [48] [CAD2DMD-SET: Synthetic Generation Tool of Digital Measurement Device CAD Model Datasets for fine-tuning Large Vision-Language Models](https://arxiv.org/abs/2508.21732)
*João Valente,Atabak Dehban,Rodrigo Ventura*

Main category: cs.CV

TL;DR: 这篇论文提出了CAD2DMD-SET合成数据生成工具，通过使用3D CAD模型和高保真渲染来改善大型视觉-语言模型在数字测量设备读数任务中的表现。

- Motivation: 现有的大型视觉-语言模型在实际场景中读取数字测量设备值时表现异常差劳，特别是在杂乱、遮挡、极端视角和运动模糊等具有挑战性的实际条件下。
- Method: 开发CAD2DMD-SET合成数据生成工具，利用3D CAD模型、高级渲染技术和高保真图像合成来生成多样化的视觉问答标注合成数据集，用于小规模细调LVLMs。同时提供DMDBench验证集评估模型性能。
- Result: 对三种最新LVLMs进行测试和使用CAD2DMD-SET数据进行LoRA细调后，模型表现获得显著提升，其中InternVL的得分增长了200%，且不会降低其他任务的性能。
- Conclusion: CAD2DMD-SET训练数据集能够显著提升LVLMs在具有挑战性条件下的稳健性和性能，工具将作为开源项目发布，以支持社区生成自己的数据集。


### [49] [Learning from Silence and Noise for Visual Sound Source Localization](https://arxiv.org/abs/2508.21761)
*Xavier Juanola,Giovana Morais,Magdalena Fuentes,Gloria Haro*

Main category: cs.CV

TL;DR: 本文提出SSL-SaN自监督模型，通过引入静默和噪声训练策略，改进声音源定位在负音频情况下的鲁棒性，同时提出了新的评估指标和扩展数据集IS3+。

- Motivation: 当前视觉声音源定位方法在低音频-视觉语义对应情况下（如静默、噪声、屏幕外声音）表现不佳，且现有评估主要局限于单一可见声源的正面场景。
- Method: 提出包含静默和噪声的新训练策略，开发自监督模型SSL-SaN；设计新的度量标准量化正负音频-视觉对的特征对齐和可分离性；创建扩展数据集IS3+。
- Result: SSL-SaN模型在声音定位和跨模态检索方面达到最先进的性能，对负音频具有更好的鲁棒性，同时在正面案例中性能也有所提升。
- Conclusion: 该方法有效解决了负音频场景下的声音源定位问题，提出的新指标和数据集为更全面的评估提供了基础，推动了该领域的发展。


### [50] [UItron: Foundational GUI Agent with Advanced Perception and Planning](https://arxiv.org/abs/2508.21767)
*Zhixiong Zeng,Jing Huang,Liming Zheng,Wenkang Han,Yufeng Zhong,Lei Chen,Longrong Yang,Yingjie Chu,Yuzhi He,Lin Ma*

Main category: cs.CV

TL;DR: UItron是一个开源的GUI代理基础模型，具有先进的GUI感知、定位和规划能力，通过系统数据工程和交互基础设施显著提升了中文移动应用场景的交互性能。

- Motivation: 构建GUI代理面临操作轨迹稀缺、交互基础设施不足以及基础模型初始能力有限等挑战，需要开发一个能够处理移动和PC设备自动操作的基础模型。
- Method: 采用监督微调处理各种GUI场景的感知和规划任务，然后开发课程强化学习框架支持复杂推理和在线环境探索，并建立了连接移动和PC设备的交互环境。
- Result: UItron在GUI感知、定位和规划基准测试中表现优异，特别是在中文移动应用场景中取得显著进展，收集了超过100万步操作轨迹并构建了评估环境。
- Conclusion: UItron通过系统数据工程和交互基础设施的建立，推动了GUI代理向实际应用迈进一步，解决了现有解决方案在中文能力方面的普遍不足。


### [51] [Domain Generalization in-the-Wild: Disentangling Classification from Domain-Aware Representations](https://arxiv.org/abs/2508.21769)
*Ha Min Son,Zhe Zhao,Shahbaz Rezaei,Xin Liu*

Main category: cs.CV

TL;DR: 本文提出CLIP-DCA方法，通过增强域感知表示和分离分类来解决CLIP在域泛化评估中的性能下降问题，在33个多样化数据集上验证了有效性。

- Motivation: 现有域泛化评估对基础模型如CLIP可能不够挑战性，因为其预训练数据可能已覆盖现有基准。需要更好评估CLIP在真实未见数据场景下的性能。
- Method: CLIP-DCA方法：1）使用单独域头识别和增强CLIP编码器中的域感知表示；2）通过合成多样化域数据增强域感知；3）鼓励从域特征中解耦实现域不变分类。
- Result: CLIP在更OOD的数据集上性能显著下降。CLIP-DCA相比现有方法显示出显著改进，特别是在更OOD的数据集上表现优异。
- Conclusion: 增强域感知是基础模型中实现有效域不变分类的前提条件，CLIP-DCA通过解耦分类和域感知表示的方法成功提升了域泛化性能。


### [52] [What Can We Learn from Harry Potter? An Exploratory Study of Visual Representation Learning from Atypical Videos](https://arxiv.org/abs/2508.21770)
*Qiyue Sun,Qiming Huang,Yang Yang,Hongjun Wang,Jianbo Jiao*

Main category: cs.CV

TL;DR: 本文研究了在视频学习中引入非典型异常数据对开放世界学习的益处，发现即使简单地将异常数据加入训练过程也能在OOD检测、新类别发现和零样本动作识别等任务中提升性能。

- Motivation: 人类在开放世界中面对罕见新概念时表现出卓越的泛化和发现能力，而现有研究主要关注封闭集中的典型数据。本文旨在探索非典型异常视频数据如何促进开放世界学习。
- Method: 收集包含各种非典型异常视频（如科幻、动画等）的新数据集，将其加入模型训练过程进行表征学习，并在三个关键任务上进行评估：OOD检测、新类别发现和零样本动作识别。
- Result: 实验表明：1）加入异常数据能持续提升各任务性能；2）增加异常样本的类别多样性可进一步提升OOD检测性能；3）在新类别发现任务中，使用更小但语义更多样的异常数据集比使用更大但更典型的数据集效果更好；4）在零样本动作识别中，异常视频的语义多样性有助于模型更好地泛化到未见动作类别。
- Conclusion: 非典型视频数据对开放世界视觉表征学习具有显著益处，新提出的数据集和发现鼓励该方向的进一步研究。


### [53] [Unsupervised Video Continual Learning via Non-Parametric Deep Embedded Clustering](https://arxiv.org/abs/2508.21773)
*Nattapong Kurpukdee,Adrian G. Bors*

Main category: cs.CV

TL;DR: 提出无监督视频持续学习(uVCL)新场景，无需任务边界和标签，使用非参数化核密度估计和动态内存扩展方法，在三个标准视频数据集上验证有效性

- Motivation: 视频数据具有丰富的时空信息，但在无监督持续学习领域研究不足。现有方法依赖标签和任务边界，成本高且不实用，需要解决无标签视频持续学习的挑战
- Method: 使用无监督视频transformer提取深度特征，采用核密度估计(KDE)作为非参数概率表示，引入新颖性检测准则动态扩展内存簇，利用迁移学习进行知识传递
- Result: 在UCF101、HMDB51和Something-to-Something V2三个标准视频动作识别数据集上，该方法显著提升了模型在连续学习多个任务时的性能
- Conclusion: 提出的无监督视频持续学习方法有效解决了视频数据处理的计算和内存挑战，为非参数化视频持续学习提供了可行的解决方案


### [54] [A Multi-Stage Fine-Tuning and Ensembling Strategy for Pancreatic Tumor Segmentation in Diagnostic and Therapeutic MRI](https://arxiv.org/abs/2508.21775)
*Omer Faruk Durugol,Maximilian Rokuss,Yannick Kirchhoff,Klaus H. Maier-Hein*

Main category: cs.CV

TL;DR: 基于nnU-Net框架，采用多阶段级联预训练策略，通过数据增强和模型集成方法，在胰腺导管腺癌MRI分割任务中取得了优异性能

- Motivation: 胰腺导管腺癌MRI自动分割面临肿瘤组织对比度差和标注数据稀缺的挑战，需要开发在有限数据下高性能的专门化模型
- Method: 使用nnU-Net框架，采用深度多阶段级联预训练策略：从通用解剖基础模型开始，依次在CT胰腺病变数据集和目标MRI模态上微调。通过五折交叉验证系统评估数据增强方案和训练计划，并构建定制化的异构专家模型集成
- Result: Task 1获得0.661的顶级交叉验证肿瘤Dice分数，Task 2获得0.523的分数。Task 1实现了最先进的MASD 5.46 mm和HD95 17.33 mm边界精度
- Conclusion: 提出了一种在有限数据和复杂医学成像任务背景下开发专门化高性能模型的稳健方法，证明了度量感知集成策略的有效性


### [55] [Benchmarking GPT-5 in Radiation Oncology: Measurable Gains, but Persistent Need for Expert Oversight](https://arxiv.org/abs/2508.21777)
*Ugur Dinc,Jibak Sarkar,Philipp Schubert,Sabine Semrau,Thomas Weissmann,Andre Karius,Johann Brand,Bernd-Niklas Axer,Ahmed Gomaa,Pluvio Stephan,Ishita Sheth,Sogand Beirami,Annette Schwarz,Udo Gaipl,Benjamin Frey,Christoph Bert,Stefanie Corradini,Rainer Fietkau,Florian Putz*

Main category: cs.CV

TL;DR: GPT-5在放射肿瘤学领域表现优异，在多项选择题测试中准确率达92.8%，显著优于GPT-4和GPT-3.5，在真实病例治疗建议生成中也展现出良好的正确性和全面性，但专家监督仍是必要的。

- Motivation: 评估专门针对肿瘤学优化的GPT-5大语言模型在临床决策支持中的表现，特别是在放射肿瘤学这一专业领域的应用潜力。
- Method: 使用两个基准测试：300道多项选择题的ACR放射肿瘤学培训考试，以及60个真实放射肿瘤病例的治疗计划生成。由4名认证放射肿瘤学家评估正确性、全面性和幻觉现象。
- Result: GPT-5在多项选择题测试中准确率92.8%，显著优于GPT-4(78.8%)和GPT-3.5(62.1%)。在病例评估中，正确性评分3.24/4，全面性评分3.59/4，幻觉现象罕见。但在复杂场景中仍存在错误。
- Conclusion: GPT-5在放射肿瘤学领域表现出色，但生成的建议仍需专家严格监督，特别是在需要精确试验知识和详细临床适应的复杂情况下。


### [56] [TMUAD: Enhancing Logical Capabilities in Unified Anomaly Detection Models with a Text Memory Bank](https://arxiv.org/abs/2508.21795)
*Jiawei Liu,Jiahe Hou,Wei Wang,Jinsong Du,Yang Cong,Huijie Fan*

Main category: cs.CV

TL;DR: TMUAD是一个三记忆库框架，通过文本记忆库、对象级图像记忆库和补丁级记忆库的统一协作，实现了结构和逻辑异常检测的最先进性能。

- Motivation: 现有异常检测方法主要依赖精心设计的图像特征提取器和记忆库来捕获对象间的逻辑关系，但在逻辑异常检测方面存在局限，且正常数据量有限。
- Method: 提出三记忆库框架：1) 类级文本记忆库用于逻辑异常检测；2) 对象级图像记忆库保持完整对象轮廓；3) 补丁级记忆库用于结构异常检测。通过多级检索比较和分数融合实现统一检测。
- Result: 在涉及工业和医疗领域的七个公开数据集上实现了最先进的性能。
- Conclusion: 通过协作记忆库统一结构和逻辑异常检测是有效的，TMUAD框架在多个领域表现出色，模型和代码已开源。


### [57] [VoCap: Video Object Captioning and Segmentation from Any Prompt](https://arxiv.org/abs/2508.21809)
*Jasper Uijlings,Xingyi Zhou,Xiuye Gu,Arsha Nagrani,Anurag Arnab,Alireza Fathi,David Ross,Cordelia Schmid*

Main category: cs.CV

TL;DR: VoCap是一个多模态视频理解模型，能够通过文本、框或掩码提示生成时空掩码和对象描述，在视频对象分割和字幕生成任务上达到先进水平。

- Motivation: 视频中对象的细粒度定位和语义理解是视频理解的基础任务，但获取标注数据成本高昂，需要开发高效的多任务解决方案。
- Method: 提出VoCap模型，使用多模态提示（文本、框、掩码）生成时空掩码和对象描述；通过预处理视频并使用大型视觉语言模型为现有分割数据集SAV生成伪标注字幕，创建SAV-Caption数据集。
- Result: 在参考表达式视频对象分割任务上达到最先进水平，在半监督视频对象分割上具有竞争力，并为视频对象字幕生成建立了基准。
- Conclusion: VoCap提供了一个统一的多任务视频理解框架，通过创新的伪标注方法解决了数据稀缺问题，在多个视频分析任务上表现出色。


### [58] [The Demon is in Ambiguity: Revisiting Situation Recognition with Single Positive Multi-Label Learning](https://arxiv.org/abs/2508.21816)
*Yiming Lin,Yuchen Niu,Shang Wang,Kaizhu Huang,Qiufeng Wang,Xiao-Bo Jin*

Main category: cs.CV

TL;DR: 本文发现场景识别中的动词分类本质上是多标签问题，提出了单正例多标签学习框架和GE-VerbMLP模型，在保持传统指标竞争力的同时实现了3%以上的MAP提升。

- Motivation: 现有方法将动词分类视为单标签问题，但视觉事件识别存在固有歧义性，同一图像可能被多个动词类别合理描述，需要重新审视这一设定。
- Method: 将动词分类重新定义为单正例多标签学习(SPMLL)问题，提出Graph Enhanced Verb MLP模型，结合图神经网络捕捉标签相关性和对抗训练优化决策边界。
- Result: 在真实数据集上的实验表明，该方法在保持传统top-1和top-5准确率竞争力的同时，实现了超过3%的MAP提升。
- Conclusion: 动词分类本质上是多标签问题，提出的SPMLL框架和GE-VerbMLP模型有效解决了语义重叠问题，为场景识别提供了更准确的动词分类方案。


### [59] [DriveQA: Passing the Driving Knowledge Test](https://arxiv.org/abs/2508.21824)
*Maolin Wei,Wanzhou Liu,Eshed Ohn-Bar*

Main category: cs.CV

TL;DR: DriveQA是一个全面的开源文本和视觉基准测试，用于评估LLM和MLLM在驾驶知识测试中的表现，发现现有模型在数值推理、复杂路权场景等方面存在显著弱点，但通过微调和预训练可以显著提升性能。

- Motivation: 当前自动驾驶基准测试主要关注空间和视觉问答任务，但缺乏对交通规则、标志和路权原则的全面理解。人类驾驶员需要识别现实数据集中罕见的边缘案例，因此需要开发一个全面的驾驶知识测试基准。
- Method: 提出了DriveQA基准测试，包含文本和视觉版本(DriveQA-V)，涵盖交通法规和场景的各个方面。通过实验评估最先进的LLM和MLLM模型，并进行微调和预训练研究。
- Result: 1) 现有模型在基本交通规则上表现良好，但在数值推理、复杂路权场景、交通标志变体和空间布局方面存在显著弱点
2) 在DriveQA上微调可提高多个类别的准确性，特别是在监管标志识别和交叉口决策方面
3) DriveQA-V的环境变化分析揭示了模型对光照、视角、距离和天气条件的敏感性
4) 在DriveQA上预训练可提升下游驾驶任务性能，在nuScenes和BDD等真实数据集上取得更好结果
- Conclusion: DriveQA提供了一个全面的驾驶知识评估基准，揭示了当前模型的局限性，同时证明了通过适当的训练可以显著提升模型对交通规则的理解和泛化能力，为自动驾驶系统的发展提供了重要参考。
## cs.HC

### [60] [Morae: Proactively Pausing UI Agents for User Choices](https://arxiv.org/abs/2508.21456)
*Yi-Hao Peng,Dingzeyu Li,Jeffrey P. Bigham,Amy Pavel*

Main category: cs.HC

TL;DR: Morae是一个UI代理系统，通过识别任务执行中的决策点并暂停让用户选择，解决了现有UI代理在自动化过程中忽视用户偏好的问题，特别为盲人和低视力用户设计。

- Motivation: 现有UI代理通常端到端执行任务，不涉及用户在关键选择中的参与，也不告知重要上下文信息，这降低了用户自主权。研究发现BLV用户在购买决策中希望了解替代产品和更多信息。
- Method: Morae使用大型多模态模型解释用户查询、UI代码和屏幕截图，在需要决策时自动识别决策点并暂停，提示用户澄清选择。
- Result: 在真实网页任务研究中，与基线代理（包括OpenAI Operator）相比，Morae帮助用户完成更多任务，并选择更符合偏好的选项。
- Conclusion: 这项工作展示了混合主动方法，用户既能受益于UI代理的自动化，又能表达个人偏好，提高了BLV用户的使用体验和自主权。
## cs.CL

### [61] [Can Multimodal LLMs Solve the Basic Perception Problems of Percept-V?](https://arxiv.org/abs/2508.21143)
*Samrajnee Ghosh,Naman Agarwal,Hemanshu Garg,Chinmay Mittal,Mausam,Parag Singla*

Main category: cs.CL

TL;DR: Percept-V数据集评估MLLMs在基本视觉感知任务上的表现，发现模型性能随问题复杂度增加而显著下降，与复杂任务中的优异表现形成对比。

- Motivation: 当前MLLMs在编码、数学和科学等复杂推理任务上表现优异，但在基本视觉感知任务上的性能缺乏系统评估，需要构建专门的测试数据集。
- Method: 创建Percept-V数据集，包含7200张程序生成的图像，分为30个类别测试不同视觉感知技能，并在GPT-4o、Gemini、Claude等先进MLLMs和LRMs上进行测试。
- Result: 实验显示所有测试模型在基本感知任务上表现不佳，性能随问题复杂度增加而显著下降，不同模型在各类别中表现出相似的趋势，某些认知技能比其他技能更难。
- Conclusion: MLLMs在复杂任务中的优异表现并不能代表其在基本视觉感知任务上的能力，需要更多关注模型在基础感知技能方面的表现和提升。


### [62] [Med-RewardBench: Benchmarking Reward Models and Judges for Medical Multimodal Large Language Models](https://arxiv.org/abs/2508.21430)
*Meidan Ding,Jipeng Zhang,Wenxuan Wang,Cheng-Yi Li,Wei-Chieh Fang,Hsin-Yu Wu,Haiqin Zhong,Wenting Chen,Linlin Shen*

Main category: cs.CL

TL;DR: 提出了首个专门评估医疗奖励模型和评判器的基准Med-RewardBench，包含1026个专家标注的多模态医疗案例，覆盖13个器官系统和8个临床科室，在6个关键临床维度上评估了32个先进MLLM模型。

- Motivation: 医疗MLLM需要高度准确、上下文敏感且专业对齐的响应，但现有基准主要关注通用能力或模型作为求解器的评估，缺乏专门的医疗奖励模型评估基准。
- Method: 构建Med-RewardBench基准，采用三步严格流程创建高质量评估数据，涵盖13个器官系统和8个临床科室的1026个专家标注案例，在6个临床关键维度上进行评估。
- Result: 评估了32个先进MLLM模型（开源、专有和医疗专用模型），发现模型输出与专家判断之间存在显著对齐挑战，同时开发的基线模型通过微调显示出显著性能提升。
- Conclusion: Med-RewardBench填补了医疗奖励模型评估的空白，揭示了当前MLLM在医疗场景中的对齐挑战，为医疗AI的可靠评估提供了重要基准。


### [63] [Is this chart lying to me? Automating the detection of misleading visualizations](https://arxiv.org/abs/2508.21675)
*Jonathan Tonglet,Jan Zimny,Tinne Tuytelaars,Iryna Gurevych*

Main category: cs.CL

TL;DR: 提出了Misviz基准数据集和Misviz-synth合成数据集，用于检测误导性可视化图表，包含真实和合成的图表样本，并评估了多种AI模型在此任务上的表现。

- Motivation: 社交媒体和网络上误导性可视化图表是错误信息的重要来源，违反图表设计原则会扭曲数据并导致读者得出错误结论。现有AI模型训练和评估缺乏大规模、多样化、公开可用的数据集。
- Method: 创建了包含2,604个真实世界可视化图表的Misviz基准数据集（标注12种误导类型）和81,814个基于真实数据表使用Matplotlib生成的合成数据集Misviz-synth。使用最先进的多模态大语言模型、基于规则的系统以及微调分类器进行综合评估。
- Result: 研究结果显示，检测误导性可视化图表的任务仍然极具挑战性，现有模型在此任务上表现有限。
- Conclusion: 发布了Misviz、Misviz-synth数据集及相关代码，为检测误导性可视化图表和减少错误信息传播提供了重要的数据集资源，但该领域仍需进一步研究。
## cs.LG

### [64] [Activation Subspaces for Out-of-Distribution Detection](https://arxiv.org/abs/2508.21695)
*Barış Zöngür,Robin Hesse,Stefan Roth*

Main category: cs.LG

TL;DR: 提出ActSub方法，利用分类头权重矩阵的奇异值分解将激活分解为决定性和非显著性分量，分别处理远分布偏移和近分布偏移的OOD检测问题

- Motivation: 确保深度学习模型在真实应用中的可靠性，需要有效区分训练分布内(ID)和分布外(OOD)样本，特别是在不同分布偏移程度下的检测挑战
- Method: 使用分类头权重矩阵的奇异值分解，将模型激活分解为对分类输出贡献最大的决定性分量和贡献最小的非显著性分量。远OOD时利用非显著性子空间，近OOD时专注于决定性子空间
- Result: 在各种标准OOD基准测试中取得了最先进的结果
- Conclusion: 通过结合决定性分量和非显著性分量的优势，ActSub方法能够有效处理不同分布偏移程度的OOD检测问题，提升检测性能


### [65] [Learning Unified Representations from Heterogeneous Data for Robust Heart Rate Modeling](https://arxiv.org/abs/2508.21785)
*Peng Yang,Zhengdong Huang,Zicheng Xie,Wentao Tian,Jingyu Liu,Lunhong Dong*

Main category: cs.LG

TL;DR: 这篇论文提出了一种处理心率预测中数据异质性问题的框架，通过随机特征丢弃和对比学习技术，在新的ParroTao数据集上较现有方法提升17%性能。

- Motivation: 心率预测在真实世界部署时面临数据异质性挑战，包括来自不同设备的源异质性和不同用户生物特征的用户异质性。现有方法要么丢弃设备特定信息，要么无法模型用户特定差异，限制了实际性能。
- Method: 提出了一个学习不受两种异质性影响的潜在表征的框架。使用随机特征丢弃策略处理源异质性，使模型适应不同特征集；采用时间感知注意力模块捕捉长期生物特征，并使用对比学习目标构建区分性表征空间来处理用户异质性。
- Result: 在新的ParroTao数据集和公开的FitRec数据集上，模型分别较现有基线方法提升了17%和15%的性能。学习到的表征显示出强大的区分能力，下游应用任务也证明了模型的实际价值。
- Conclusion: 该框架有效地解决了心率预测中的数据异质性问题，通过合理的技术组合实现了在异质数据模式下的稳定性能。公开的ParroTao数据集为预测任务提供了新的标准化评测平台。
## cs.RO

### [66] [QuadKAN: KAN-Enhanced Quadruped Motion Control via End-to-End Reinforcement Learning](https://arxiv.org/abs/2508.19153)
*Allen Wang,Gavin Tao*

Main category: cs.RO

TL;DR: QuadKAN：基于样条参数化和KAN网络的视觉引导四足运动控制框架，通过结合本体感觉和视觉输入，实现了更鲁棒、高效且可解释的运动控制

- Motivation: 解决视觉引导四足运动控制中需要结合本体感觉和视觉信息以实现鲁棒控制的问题，传统方法在处理步态的片段平滑特性时存在效率低下和动作抖动等问题
- Method: 提出QuadKAN框架，使用样条参数化的跨模态策略，采用Kolmogorov-Arnold Networks (KANs)实现。包含样条编码器处理本体感觉输入，样条融合头处理本体感觉-视觉输入。采用多模态延迟随机化(MMDR)和PPO算法进行端到端训练
- Result: 在多样化地形（平坦/不平坦表面、静态/动态障碍物）上的评估显示，QuadKAN相比SOTA基线方法获得了更高的回报、更长的移动距离和更少的碰撞，同时降低了能量消耗和动作抖动
- Conclusion: 样条参数化策略为鲁棒的视觉引导运动控制提供了简单、有效且可解释的替代方案，证明了结合本体感觉与视觉信息对于四足机器人运动控制的重要性


### [67] [Mini Autonomous Car Driving based on 3D Convolutional Neural Networks](https://arxiv.org/abs/2508.21271)
*Pablo Moraes,Monica Rodriguez,Kristofer S. Kappel,Hiago Sodre,Santiago Fernandez,Igor Nunes,Bruna Guterres,Ricardo Grando*

Main category: cs.RO

TL;DR: 本文提出基于RGB-D信息和3D CNN的自动驾驶方法，在模拟环境中测试小型自动驾驶汽车，相比RNN取得了更好的性能表现。

- Motivation: 自动驾驶系统开发面临高复杂性、长训练周期和不确定性等挑战，需要简化的测试环境来快速评估机器学习模型。
- Method: 使用RGB-D信息和三维卷积神经网络(3D CNN)的方法，在模拟环境中对小型自动驾驶汽车进行训练和测试，并与循环神经网络(RNN)进行对比。
- Result: 3D CNN在任务完成成功率、圈速指标和驾驶一致性方面表现出色，架构修改和赛道复杂性显著影响模型的泛化能力和车辆控制性能。
- Conclusion: 提出的3D CNN方法相比RNN展现出有前景的结果，为自动驾驶算法的快速评估提供了有效的解决方案。


### [68] [The Rosario Dataset v2: Multimodal Dataset for Agricultural Robotics](https://arxiv.org/abs/2508.21635)
*Nicolas Soncini,Javier Cremona,Erica Vidal,Maximiliano García,Gastón Castro,Taihú Pire*

Main category: cs.RO

TL;DR: 提出了一个在豆田环境中收集的多模态数据集，包含立体红外相机、彩色相机、IMU、GNSS等多种传感器数据，用于农业机器人定位、建图和导航算法的开发与评估。

- Motivation: 农业环境中的机器人技术面临自然光照变化、运动模糊、粗糙地形和长距离感知混淆等挑战，需要专门的数据集来支持相关算法的开发和基准测试。
- Method: 使用配备多种同步传感器的平台在豆田中收集超过两小时的数据，包括立体红外相机、彩色相机、加速度计、陀螺仪、磁力计、多种GNSS模式和轮式里程计。
- Result: 数据集捕获了农业环境的关键挑战，并在现有最先进的多模态SLAM方法上进行了测试，展示了这些方法在农业环境中的应用局限性。
- Conclusion: 该数据集为农业机器人技术的多模态SLAM系统评估提供了重要资源，有助于推动农业环境中的定位、建图和导航算法发展。
## cs.GR

### [69] [ScanMove: Motion Prediction and Transfer for Unregistered Body Meshes](https://arxiv.org/abs/2508.21095)
*Thomas Besnier,Sylvain Arguillère,Mohamed Daoudi*

Main category: cs.GR

TL;DR: 提出了一种无需骨架的数据驱动框架，用于处理未注册表面网格的运动预测和迁移，通过运动嵌入网络和顶点特征场生成时空变形场。

- Motivation: 未注册表面网格（特别是原始3D扫描）由于缺乏点对点对应关系和存在数据噪声，给自动计算合理变形带来了重大挑战。
- Method: 耦合鲁棒的运动嵌入网络和学习的每顶点特征场，生成时空变形场来驱动网格变形。
- Result: 在行走和跑步等任务上的广泛评估（包括定量基准和定性可视化）证明了该方法在挑战性未注册网格上的有效性和多功能性。
- Conclusion: 该方法为处理未注册身体网格提供了一种有效的无骨架运动预测和迁移解决方案。


### [70] [ARGS: Advanced Regularization on Aligning Gaussians over the Surface](https://arxiv.org/abs/2508.21344)
*Jeong Uk Lee,Sung Hee Choi*

Main category: cs.GR

TL;DR: 通过两种正则化策略（有效秩正则化和神经SDF正则化）改善了3D高斯散点的网格重建质量和场景一致性

- Motivation: 虽然现有模型如SuGaR在渲染方面提供了有效解决方案，但在视觉保真度和场景一致性方面仍有改进空间
- Method: 1）使用有效秩正则化控制高斯原语的形状，避免极端各异性；2）集成神经签名距离函数（SDF）并使用Eikonal损失进行正则化，提供全局表面前知
- Result: 提高了个体高斯原语的保真度和集体表面行为的一致性
- Conclusion: 该模型能够从3DGS数据生成更准确和一致的视觉效果
## cs.CY

### [71] [From Drone Imagery to Livability Mapping: AI-powered Environment Perception in Rural China](https://arxiv.org/abs/2508.21738)
*Weihuan Deng,Yaofu Huang,Luan Chen,Xun Li,Yao Yao*

Main category: cs.CY

TL;DR: 本研究提出基于无人机影像和多模态大语言模型的农村宜居性评估框架，通过大规模数据收集和智能算法，揭示了中国农村宜居性的空间格局和影响因素。

- Motivation: 当前农村宜居性评估方法存在局限：问卷调查难以规模化，城市导向的视觉感知方法不适用于农村场景。需要开发专门针对农村环境的科学评估体系。
- Method: 采用自上而下方法收集1766个村庄的无人机影像，开发高效的图像对比机制和二进制搜索插值算法，构建基于专家知识的思维链提示，从生活质量和生态宜居性双维度评估。
- Result: 发现中国农村宜居性呈现以四川和浙江为核心的双核-边缘空间格局；政府财政支出是核心影响因素，每增加1个单位可使宜居性提升3.9-4.9个单位。
- Conclusion: 该框架为农村宜居性评估提供了可靠的技术方案，研究结果可为乡村振兴政策制定提供科学依据，政府财政投入对改善农村人居环境具有关键作用。
