[[toc]]

## cs.CV

### [1] [CellPainTR: Generalizable Representation Learning for Cross-Dataset Cell Painting Analysis](https://arxiv.org/abs/2509.06986)
*Cedric Caruzzo,Jong Chul Ye*

Main category: cs.CV

TL;DR: CellPainTR是一个基于Transformer的架构，用于学习对批次效应鲁棒的细胞形态学基础表征，能够在无需微调的情况下有效泛化到未见数据集。

- Motivation: 大规模生物发现需要整合海量异构数据集，但技术批次效应和缺乏可泛化模型是关键障碍。
- Method: 采用Transformer架构，设计源特定上下文标记，实现无需重新训练即可有效处理分布外泛化。
- Result: 在JUMP数据集上优于ComBat和Harmony等现有方法，在未见Bray数据集上保持高性能。
- Conclusion: 这项工作代表了创建真正基于图像的细胞分析基础模型的重要一步，实现了更可靠和可扩展的跨研究生物分析。


### [2] [FusWay: Multimodal hybrid fusion approach. Application to Railway Defect Detection](https://arxiv.org/abs/2509.06987)
*Alexey Zhukov,Jenny Benois-Pineau,Amira Youssef,Akka Zemmari,Mohamed Mosbah,Virginie Taillandier*

Main category: cs.CV

TL;DR: 这篇论文提出了一种基于领域规则的多模态融合架构，结合YOLOv8n和Vision Transformer，通过融合视觉和音频信息来提高铁路缺陷检测的准确性。

- Motivation: 单一视觉模态在铁路缺陷检测中存在过检测问题，当正常结构元件外观类似缺陷时容易出现误检。音频信息虽然不含高级语义，但可以补充视觉信息的不足。
- Method: 构建基于YOLOv8n和Vision Transformer的多模态融合架构，从多个层（7、16、19）提取特征图，并与合成的音频表征进行融合，重点检测铁路断裂和表面缺陷两类问题。
- Result: 在真实铁路数据集上证明，多模态融合方法比单一视觉方法在精度和总体准确性上提高0.2个百分点，并通过学生t检验确认了统计显著性。
- Conclusion: 多模态融合技术能够有效提升铁路缺陷检测的性能，通过结合视觉和音频信息减少了误检率，为工业检测应用提供了更加准确可靠的解决方案。


### [3] [Frustratingly Easy Feature Reconstruction for Out-of-Distribution Detection](https://arxiv.org/abs/2509.06988)
*Yingsheng Wang,Shuo Lu,Jian Liang,Aihua Zheng,Ran He*

Main category: cs.CV

TL;DR: 提出了一种无需训练数据的后处理OOD检测方法ClaFR，通过分类器权重正交分解获得类别已知子空间，计算特征重构误差来识别分布外数据。

- Motivation: 现有的基于特征的后处理方法需要访问训练数据，这在数据隐私保护场景下不适用，因此需要开发不依赖训练数据的OOD检测方法。
- Method: ClaFR方法：1）对分类器权重进行正交分解提取类别已知子空间；2）将原始特征映射到该子空间获得新表示；3）计算子空间内的特征重构误差作为OOD分数。
- Result: 在多个OOD基准测试中取得了领先性能，且无需访问训练数据。
- Conclusion: ClaFR是一种简单有效的后处理OOD检测方法，解决了数据隐私场景下的限制，性能优越。


### [4] [DIET-CP: Lightweight and Data Efficient Self Supervised Continued Pretraining](https://arxiv.org/abs/2509.06990)
*Bryan Rodas,Natalie Montesino,Jakob Ambsdorf,David Klindt,Randall Balestriero*

Main category: cs.CV

TL;DR: DIET-CP是一种简单的持续预训练策略，能够在小型专业领域数据集上有效调整基础模型，无需标签和额外超参数，仅用1000张图像就能显著提升DINOv3等先进模型的性能。

- Motivation: 解决专业领域中数据集小、SSL方法不适用、预训练模型缺乏重要信息等问题，使基础模型能够适应新的数据分布。
- Method: 使用简单的目标函数，无需标签，不引入比监督微调更多的超参数，通过持续预训练将基础模型引导到目标数据分布。
- Result: 该方法在不同数据模态和骨干网络选择下表现稳定，仅用1000张图像就能显著提升DINOv3等先进模型的性能。
- Conclusion: DIET-CP提供了一种简单有效的持续预训练解决方案，特别适用于小规模专业领域数据集的模型适配问题。


### [5] [FedAPT: Federated Adversarial Prompt Tuning for Vision-Language Models](https://arxiv.org/abs/2509.06992)
*Kun Zhai,Siheng Chen,Xingjun Ma,Yu-Gang Jiang*

Main category: cs.CV

TL;DR: FedAPT是一种增强联邦提示调优对抗鲁棒性的新方法，通过类别感知提示生成器和跨层生成器共享策略解决非IID设置下的类别信息差距问题

- Motivation: 联邦提示调优(FPT)方法训练的模型容易受到对抗攻击，导致下游任务错误分类，特别是在非独立同分布(non-IID)设置下存在客户端与全局模型之间的类别信息差距
- Method: 提出类别感知提示生成器，利用全局标签嵌入作为引导生成视觉提示；采用跨层生成器共享策略增强不同层间的提示耦合
- Result: 在多个图像分类数据集上的实验表明，FedAPT在提升对抗鲁棒性方面显著优于现有方法，并在跨域和跨数据集场景中表现出优异的泛化能力
- Conclusion: FedAPT有效解决了联邦提示调优中的对抗鲁棒性问题，具有实际应用价值


### [6] [Geospatial Foundational Embedder: Top-1 Winning Solution on EarthVision Embed2Scale Challenge (CVPR 2025)](https://arxiv.org/abs/2509.06993)
*Zirui Xu,Raphael Tang,Mike Bianco,Qi Zhang,Rishi Madhok,Nikolaos Karianakis,Fuxun Yu*

Main category: cs.CV

TL;DR: 本文介绍了CVPR 2025 EarthVision Embed2Scale挑战赛的冠军解决方案，该挑战赛旨在开发基础地理空间模型，将SSL4EO-S12高光谱地理空间数据立方体嵌入到向量中，以支持分类、回归等下游任务。

- Motivation: 开发能够有效处理高光谱地理空间数据的基础模型，为各种下游地理空间分析任务提供高质量的嵌入表示。
- Method: 技术报告中提出的Top-1获胜解决方案方法（具体方法细节需要更多信息）
- Result: 在Embed2Scale挑战赛中获得了第一名
- Conclusion: 提出的方法在嵌入高光谱地理空间数据方面表现优异，为后续的下游任务提供了有效的特征表示基础


### [7] [VLMs-in-the-Wild: Bridging the Gap Between Academic Benchmarks and Enterprise Reality](https://arxiv.org/abs/2509.06994)
*Srihari Bandraupalli,Anupam Purwar*

Main category: cs.CV

TL;DR: ViLD框架填补了学术评估与企业部署需求之间的差距，通过10个关键业务任务和创新的BlockWeaver算法，在真实数据集上评估开源视觉语言模型。

- Motivation: 当前基于选择题和合成数据的基准测试无法反映企业实际应用需求，需要建立更贴近真实业务场景的评估框架。
- Method: 提出ViLD框架，定义10个企业关键任务，开发BlockWeaver算法用于OCR输出比较，构建包含7500个真实样本的基准数据集，结合语义匹配、传统指标和新方法进行评估。
- Result: 在Qwen、MIMO和InternVL等开源VLM与专有基线的对比评估中，提供了业界首个基于任务的VLM能力评估，为企业部署提供可行见解。
- Conclusion: ViLD框架成功连接了学术研究与企业应用需求，为开源视觉语言模型在企业环境中的实际部署提供了有效的评估标准和实用指导。


### [8] [The Protocol Genome A Self Supervised Learning Framework from DICOM Headers](https://arxiv.org/abs/2509.06995)
*Jimmy Joseph*

Main category: cs.CV

TL;DR: Protocol Genome是一个自监督学习系统，通过分析DICOM头部信息来学习协议相关性，在外部验证中达到AUROC 0.901（基线0.847）和ECE 0.036（基线0.058），提高了跨模态和厂商的校准性和鲁棒性。

- Motivation: 临床影像通过PACS/DICOM系统处理，其中扫描协议选择（扫描仪型号、序列、参数等）会影响图像对比度、噪声和伪影。这些潜在混杂因素阻碍了仅基于图像的神经网络在不同站点间的泛化能力。
- Method: 将结构化DICOM头部作为标签，通过三种方式学习协议感知但临床鲁棒的图像表示：(1)协议-图像对比学习，(2)掩码协议预测，(3)协议-协议转换。使用126万项研究数据进行实验。
- Result: 在三个临床任务上表现优异：肺栓塞CT分诊（+0.046 AUROC）、脑胶质瘤MRI分级（+0.058 AUROC）、心胸比X光检测（+0.041 AUROC），获得25-37%的校准改进，且在10-20%标注数据下仍保持优势。
- Conclusion: Protocol Genome能减少协议边界处的假阳性，适用于PACS系统，提供了模型卡和部署指南，包括去标识化和偏倚审计，展示了在临床环境中的实际应用价值。


### [9] [Visible Yet Unreadable: A Systematic Blind Spot of Vision Language Models Across Writing Systems](https://arxiv.org/abs/2509.06996)
*Jie Zhang,Ting Xu,Gelei Deng,Runyi Hu,Han Qiu,Tianwei Zhang,Qing Guo,Ivor Tsang*

Main category: cs.CV

TL;DR: 视觉语言模型在激烈文字干扰下显示出严重的识别弱点，缺乏人类的符号组合性认知能力

- Motivation: 研究高级视觉语言模型是否与人类一样具有对突破性文字干扰的识别强锐性
- Method: 构建两个受心理物理学启发的测试标准，通过切割、重组和叠加字形来创造"可见但不可读"的刺激物，测试中文象形文字和英语字母词汇
- Result: 当代VLMs在清晰文本上表现强劲，但在这些干扰下性能严重下降，经常产生无关或不连贯的输出
- Conclusion: 模型存在结构性限制，过于依赖通用视觉不变性而较少使用组合性先验知识，需要编码符号分割、组合和绑定的新架构和训练策略


### [10] [K-Syn: K-space Data Synthesis in Ultra Low-data Regimes](https://arxiv.org/abs/2509.06997)
*Guan Yu,Zhang Jianhua,Liang Dong,Liu Qiegen*

Main category: cs.CV

TL;DR: 该论文提出了一种在频域进行特征级学习的方法，通过时间融合策略合成k空间数据，用于动态心脏MRI重建，在低数据条件下表现出强大的生成能力。

- Motivation: 由于心脏磁共振成像的动态性和复杂性，高质量且多样化的k空间数据在实践中很少可用，这阻碍了动态心脏MRI的稳健重建。
- Method: 在频域进行特征级学习，利用傅里叶变换的全局表示能力，将频域视为自然全局特征空间。采用时间融合策略整合跨时间帧的k空间数据，引导和优化生成轨迹。
- Result: 实验结果表明，该方法在低数据条件下具有强大的生成能力，表明其在缓解动态MRI重建中数据稀缺问题方面具有实际潜力。
- Conclusion: 频域特征级建模结合时间融合策略能够有效解决动态心脏MRI数据稀缺问题，为低数据条件下的稳健重建提供了实用解决方案。


### [11] [Not All Splits Are Equal: Rethinking Attribute Generalization Across Unrelated Categories](https://arxiv.org/abs/2509.06998)
*Liviu Nicolae Fircă,Antonio Bărbălau,Dan Oneata,Elena Burceanu*

Main category: cs.CV

TL;DR: 这篇论文首次明确评估模型在语义和感知差异过大的类别间的属性知识推广能力，发现模型表现随训练测试集相关性降低而急剧下降

- Motivation: 评估模型是否能够将属性知评推广到语义和感知上差异过大的类别之间，如从"狗"推理"椅子"也有四条腿
- Method: 通过LLM语义分组、嵌入相似度阈值、嵌入聚类和超类分区等四种方法逐步降低训练测试集相关性
- Result: 随着训练测试集相关性降低，模型性能急剧下降，聚类方法在降低隐藏相关性和保持可学习性方面表现最佳
- Conclusion: 当前表示学习方法在属性推理任务中对分区设计敏感，需要更好的基准来评估模型的真正推广能力


### [12] [Human-in-the-Loop: Quantitative Evaluation of 3D Models Generation by Large Language Models](https://arxiv.org/abs/2509.07010)
*Ahmed R. Sadik,Mariusz Bujny*

Main category: cs.CV

TL;DR: 提出了一个人类参与的量化评估框架，用于评估LLM生成的3D模型，通过多模态输入比较生成质量，发现代码级提示能实现完美重建。

- Motivation: 当前缺乏评估LLM生成3D模型几何和结构保真度的稳健方法，需要开发量化评估框架来支持CAD设计民主化、逆向工程和快速原型等应用。
- Method: 提出了一套全面的相似性和复杂性度量标准（体积精度、表面对齐、尺寸保真度、拓扑复杂性），使用L型支架作为案例研究，比较四种输入模态（2D正交视图、等距草图、几何结构树、代码修正提示）的性能。
- Result: 研究发现语义丰富度越高生成保真度越好，代码级提示在所有度量标准上都实现了完美重建，量化评估方法相比传统定性方法能显著加快向真实值的收敛速度。
- Conclusion: 这项工作不仅推进了对AI辅助形状合成的理解，还为验证和优化生成模型提供了可扩展的方法论，适用于各种CAD应用。


### [13] [MEGS$^{2}$: Memory-Efficient Gaussian Splatting via Spherical Gaussians and Unified Pruning](https://arxiv.org/abs/2509.07021)
*Jiarui Chen,Yikeng Chen,Yingshuang Zou,Ye Huang,Peng Wang,Yuan Liu,Yujing Sun,Wenping Wang*

Main category: cs.CV

TL;DR: MEGS²是一个内存高效的3D高斯泼溅框架，通过联合优化基元数量和每个基元的参数，实现了前所未有的内存压缩，在保持渲染质量的同时显著降低了VRAM使用。

- Motivation: 3D高斯泼溅技术虽然在新视角合成方面表现出色，但其高内存消耗限制了在边缘设备上的应用。现有压缩方法大多只关注存储压缩，未能解决渲染内存的关键瓶颈。
- Method: 使用轻量级的任意方向球面高斯瓣替代内存密集的球谐函数作为颜色表示，并提出统一的软剪枝框架，将基元数量和瓣数量剪枝建模为单一约束优化问题。
- Result: 相比现有方法，MEGS²实现了50%的静态VRAM减少和40%的渲染VRAM减少，同时保持了相当的渲染质量。
- Conclusion: MEGS²通过创新的内存优化策略，成功解决了3D高斯泼溅技术在边缘设备应用中的内存瓶颈问题，为实际部署提供了可行的解决方案。


### [14] [Moment- and Power-Spectrum-Based Gaussianity Regularization for Text-to-Image Models](https://arxiv.org/abs/2509.07027)
*Jisung Hwang,Jaihoon Kim,Minhyuk Sung*

Main category: cs.CV

TL;DR: 通过空间域矩阵和频域力谱的组合正则化损失，促使文本到图像模型的潜在空间符合标准正态分布，提升下游任务性能

- Motivation: 解决现有正态性正则化方法的局限性，通过统一框架提供更有效的潜在空间优化支持
- Method: 组合空间域矩阵正则化和频域力谱正则化，利用分析知道的期望值作为目标，通过随机排列保证排列不变性
- Result: 在生成式模型中应用时，该正则化方法在美学质量和文本对齐任务上超过以往正态性正则化，有效防止奖励欺骗并加快收敛速度
- Conclusion: 该统一框架为正态性正则化提供了更有效的解决方案，在下游优化任务中显示出优异性能


### [15] [SAM$^{*}$: Task-Adaptive SAM with Physics-Guided Rewards](https://arxiv.org/abs/2509.07047)
*Kamyar Barakati,Utkarsh Pratiush,Sheryl L. Sanchez,Aditya Raghavan,Delia J. Milliron,Mahshid Ahmadi,Philip D. Rack,Sergei V. Kalinin*

Main category: cs.CV

TL;DR: 基础分割模型如SAM存在调参复杂问题，本文提出奖励函数优化方法来精调模型，实现实时数据分割

- Motivation: 解决基础分割模型在显微镜影像分析中的调参复杂性问题，特别是对实时流数捬分析的限制
- Method: 使用奖励函数基于物理特性（如粒子大小分布、形状）来优化SAM模型，发展出SAM*
- Result: 提高了SAM模型在微观影像分割中的适应性和性能，支持实时流数据分析
- Conclusion: 奖励函数优化方法有效提升了基础分割模型在领域特定应用中的性能和可用性


### [16] [Enhancing Classification of Streaming Data with Image Distillation](https://arxiv.org/abs/2509.07049)
*Rwad Khatib,Yehudit Aperstein*

Main category: cs.CV

TL;DR: 该研究提出了一种基于数据蒸馏的流数据分类方法(DBC)，在有限计算资源环境下显著提升了流式图像数据分类的准确率，达到73.1%的准确率，优于传统方法。

- Motivation: 解决在内存和计算资源有限环境下高效分类流式数据的挑战，通过数据蒸馏技术提取关键特征来降低计算需求同时保持分类准确性。
- Method: 采用数据蒸馏方法从数据流中提取本质特征，并与传统算法（Hoeffding Trees和Adaptive Random Forest）以及Reservoir Sampling Based Classification (RBC)技术进行比较。
- Result: DBC方法表现出卓越性能，达到73.1%的准确率，超越了传统方法和RBC技术，在流数据分类领域实现了显著进步。
- Conclusion: 该方法在处理复杂数据流方面展示了有效性，为流数据分类的准确性和效率设立了新标准，证明了数据蒸馏在资源受限环境中的优势。


### [17] [Automated Evaluation of Gender Bias Across 13 Large Multimodal Models](https://arxiv.org/abs/2509.07050)
*Juan Manuel Contreras*

Main category: cs.CV

TL;DR: 本研究开发了Aymara图像公平性评估基准，对13个商业大型多模态模型进行性别偏见测试，发现这些模型不仅复制还放大了职业性别刻板印象，存在显著的默认男性偏见，但不同模型间偏见程度差异很大，表明高偏见并非不可避免。

- Motivation: 现有研究虽然识别了大型多模态模型中的性别偏见，但方法学限制阻碍了大规模、可比较的跨模型分析。为了填补这一空白，需要开发标准化的评估工具来系统评估AI生成图像中的社会偏见。
- Method: 使用75个程序生成的性别中性提示词，让13个商业LMM生成在刻板男性、刻板女性和非刻板职业中的人物图像，然后使用经过验证的LLM-as-a-judge系统对965张生成图像进行性别代表性评分。
- Result: 1) LMM系统性放大职业性别刻板印象，在男性刻板职业中生成93.0%男性图像，女性刻板职业中仅22.5%男性图像；2) 存在强烈默认男性偏见，非刻板职业中68.3%生成男性；3) 不同模型偏见程度差异显著(46.7%-73.3%)，表现最佳的模型接近性别平等。
- Conclusion: 研究提供了迄今为止最全面的跨模型性别偏见基准，强调了标准化自动化评估工具对于促进AI开发问责制和公平性的必要性，表明高偏见是设计选择的结果而非必然结局。


### [18] [Faster VGGT with Block-Sparse Global Attention](https://arxiv.org/abs/2509.07120)
*Chung-Shien Brian Wang,Christian Schmidt,Jens Piekenbrinck,Bastian Leibe*

Main category: cs.CV

TL;DR: 本文提出了一种基于块稀疏核的注意力机制替代方案，用于解决多视图重建中transformer模型的二次复杂度瓶颈问题，实现了4倍加速且保持性能。

- Motivation: 现有的transformer-based多视图重建模型（如VGGT和π³）存在全局注意力层的二次复杂度瓶颈，限制了在大规模图像集上的可扩展性。研究发现注意力矩阵的概率质量集中在少数与跨视图几何匹配相关的patch-patch交互上。
- Method: 基于结构化注意力的观察，受大语言模型最新进展启发，提出使用高度优化的块稀疏核来替代密集的全局注意力操作，无需重新训练主干网络。
- Result: 在多个多视图基准测试上的评估表明，该方法实现了最高4倍的推理加速，同时保持了可比较的任务性能，支持大规模图像集合。
- Conclusion: 提出的块稀疏注意力机制有效解决了多视图重建中transformer模型的运行时瓶颈问题，为VGGT和π³等模型提供了高效的可扩展解决方案。


### [19] [Detection and Recovery of Adversarial Slow-Pose Drift in Offloaded Visual-Inertial Odometry](https://arxiv.org/abs/2509.07130)
*Soruya Saha,Md Nurul Absur,Saptarshi Debroy*

Main category: cs.CV

TL;DR: 本文提出了一种无监督的视觉惯性里程计(VIO)攻击检测和恢复机制，通过训练学习运动的时间规律性来检测运行时偏差并恢复姿态一致性，在真实环境中显著减少了轨迹和姿态误差。

- Motivation: 当前将VIO卸载到边缘服务器的趋势会导致服务器端威胁，微小的姿态欺骗可能累积成显著漂移，同时逃避启发式检查。
- Method: 提出无监督、无标签的检测和恢复机制，在无攻击会话上训练模型学习运动的时间规律性，检测运行时偏差并启动恢复以恢复姿态一致性。
- Result: 在ILLIXR测试平台上使用多种欺骗强度进行评估，实验结果显示相比无防御基线，轨迹和姿态误差显著减少。
- Conclusion: 该方法能有效检测和恢复VIO系统中的姿态欺骗攻击，提高系统的安全性和鲁棒性。


### [20] [Realism to Deception: Investigating Deepfake Detectors Against Face Enhancement](https://arxiv.org/abs/2509.07178)
*Muhammad Saad Saeed,Ijaz Ul Haq,Khalid Malik*

Main category: cs.CV

TL;DR: 人脸增强技术虽然能改善面部外观，但会扭曲生物特征，显著降低深度伪造检测器的准确率，最高攻击成功率可达75.12%。

- Motivation: 研究假设人脸增强技术在提升感知质量的同时，可能会降低深度伪造检测器的性能，因此系统评估这些技术是否可以作为反取证工具使用。
- Method: 使用传统图像处理方法和先进的基于GAN的增强技术，评估对朴素、空间和基于频率的检测方法的影响，并进行对抗训练实验来评估模型鲁棒性。
- Result: 实验表明，即使是基础增强滤镜也能显著降低检测准确率（ASR达64.63%），而GAN-based技术进一步利用这些漏洞（ASR达75.12%）。
- Conclusion: 人脸增强方法可以有效作为反取证工具，强调了需要更具弹性和适应性的取证方法。


### [21] [Dimensionally Reduced Open-World Clustering: DROWCULA](https://arxiv.org/abs/2509.07184)
*Erencem Ozbey,Dimitrios I. Diochnos*

Main category: cs.CV

TL;DR: 这篇论文提出了一种全无监督的方法，利用Vision Transformer和流形学习技术来发现图像数据中的新类别，在多个标准数据集上创造了新的SOTA结果。

- Motivation: 在开放世界环境中，虽然有监督学习需要大量标签数据，但人工标注耐力要求高，而且新类别可能会不断出现。但现有研究多举中于半监督方法，本文想要探索全无监督方法来解决这个问题。
- Method: 采用Vision Transformer生成向量嵌入，利用关注机制来估计聚类数量。同时结合流形学习技术来精炼嵌入表征，利用数据的内在几何结构来提升图像聚类性能。
- Result: 在CIFAR-10、CIFAR-100、ImageNet-100和Tiny ImageNet数据集上创造了单模态聚类和新类发现的新的State-of-the-Art结果，无论聚类数量是否事先知道。
- Conclusion: 该方法提供了一种有效的全无监督方案来处理开放世界中的新类发现问题，通过结合Vision Transformer和流形学习技术实现了突破性的性能收益。


### [22] [XBusNet: Text-Guided Breast Ultrasound Segmentation via Multimodal Vision-Language Learning](https://arxiv.org/abs/2509.07213)
*Raja Mallina,Bryar Shareef*

Main category: cs.CV

TL;DR: XBusNet是一种新颖的双提示双分支多模态模型，结合图像特征和临床文本提示，通过全局语义路径和局部边界路径实现精确的乳腺超声分割，在BLU数据集上达到最先进性能。

- Motivation: 乳腺超声精确分割对可靠测量和定量分析至关重要，但小尺寸、低对比度病变和斑点噪声使其具有挑战性。现有基于文本提示的方法往往产生粗糙的分割结果，需要额外机制恢复精细边界。
- Method: 提出XBusNet双提示双分支模型：全局路径基于CLIP Vision Transformer编码整图语义，局部U-Net路径强调精确边界。使用从结构化元数据自动组装的文本提示描述形状、边缘和BI-RADS术语。
- Result: 在BLU数据集上达到平均Dice 0.8765和IoU 0.8149，优于六个强基线。小病变提升最显著，减少了漏检区域和虚假激活。消融研究显示全局上下文、局部边界建模和提示调制的互补贡献。
- Conclusion: 融合全局语义和局部精度的双提示双分支多模态设计能够产生准确的乳腺超声分割掩码，并提高对小尺寸、低对比度病变的鲁棒性。


### [23] [Breast Cancer Detection in Thermographic Images via Diffusion-Based Augmentation and Nonlinear Feature Fusion](https://arxiv.org/abs/2509.07277)
*Sepehr Salem,M. Moein Esfahani,Jingyu Liu,Vince Calhoun*

Main category: cs.CV

TL;DR: 通过使用扩散概率模型(DPM)进行数据增帿，结合ResNet-50深度特征与手工特征融合，在乳腺癌热成像分类中达到98%准确率

- Motivation: 解决医学形象领域深度学习数据稀缺问题，提高乳腺癌热成像分类性能
- Method: 使用DPM模型进行数据增帿，融合ResNet-50深度特征与U-Net分割胎瘤提取的非线性手工特征(如分形维数)，使用XGBoost分类器
- Result: 达到98.0%准确率和98.1%敏感度，DPM增帿和非线性特征融合都具有统计显著性
- Conclusion: 高级生成模型与可解释特征的协同作用能构建高准确医学诊断工具


### [24] [Reconstruction Alignment Improves Unified Multimodal Models](https://arxiv.org/abs/2509.07295)
*Ji Xie,Trevor Darrell,Luke Zettlemoyer,XuDong Wang*

Main category: cs.CV

TL;DR: RecA是一种资源高效的后训练方法，通过视觉理解编码器嵌入作为密集文本提示，无需标注即可提供丰富监督，显著提升多模态模型的生成和编辑能力

- Motivation: 传统多模态模型训练依赖图像-文本对，但文本标注通常稀疏且缺乏细粒度视觉细节，导致理解与生成之间存在偏差
- Method: RecA利用模型自身的视觉理解嵌入作为条件，通过自监督重建损失优化图像重建，实现理解与生成的对齐
- Result: 仅用27 GPU小时，在GenEval(0.73→0.90)和DPGBench(80.93→88.15)上显著提升生成性能，编辑基准也有明显改善(ImgEdit 3.38→3.75, GEdit 6.94→7.25)
- Conclusion: RecA是一种高效通用的后训练对齐策略，适用于多种UMM架构，性能超越更大的开源模型


### [25] [DEPF: A UAV Multispectral Object Detector with Dual-Domain Enhancement and Priority-Guided Mamba Fusion](https://arxiv.org/abs/2509.07327)
*Shucong Li,Zhenyu Liu,Zijie Hong,Zhiheng Zhou,Xianghai Cao*

Main category: cs.CV

TL;DR: 提出DEPF方法，通过双域增强和优先级引导的Mamba融合解决无人机多光谱目标检测中的低光照图像质量差、局部小目标建模干扰和计算复杂度高的问题

- Motivation: 解决无人机多光谱目标检测面临的三个挑战：低光照遥感图像降低多模态融合互补性、融合阶段冗余信息干扰局部小目标建模、基于transformer的方法二次计算复杂度难以在无人机平台应用
- Method: 设计双域增强模块(DDE)包含跨尺度小波Mamba(CSWM)和傅里叶细节恢复块(FDR)来增强低光照图像；设计优先级引导Mamba融合模块(PGMF)引入优先级扫描概念，从局部目标特征开始融合
- Result: 在DroneVehicle和VEDAI数据集上的实验表明，DEPF在目标检测方面表现优于最先进方法
- Conclusion: 基于线性复杂度Mamba的DEPF方法有效解决了无人机多光谱目标检测的关键挑战，在低光照图像增强和目标检测性能方面取得了显著改进


### [26] [G3CN: Gaussian Topology Refinement Gated Graph Convolutional Network for Skeleton-Based Action Recognition](https://arxiv.org/abs/2509.07335)
*Haiqing Ren,Zhongkai Luo,Heng Fan,Xiaohui Yuan,Guanchen Wang,Libo Zhang*

Main category: cs.CV

TL;DR: 提出G$^{3}$CN方法，通过高斯滤波优化骨架拓扑图结构，结合GRU增强信息传播，有效提升骨架动作识别中模糊动作的区分能力

- Motivation: 传统GCN在骨架动作识别中虽然有效，但在区分模糊动作方面存在局限，主要由于学习到的拓扑和空间特征表示不足
- Method: G$^{3}$CN方法：1）使用高斯滤波器精炼骨架拓扑图结构 2）在GCN框架中集成门控循环单元(GRU)来增强骨架点间的信息传播
- Result: 在NTU RGB+D、NTU RGB+D 120和NW-UCLA基准测试上取得显著效果，特别是在模糊样本上表现优异，且具有良好的泛化能力
- Conclusion: G$^{3}$CN通过拓扑图精炼和增强信息传播，有效解决了骨架动作识别中模糊动作区分困难的问题，提升了整体识别性能


### [27] [Parse Graph-Based Visual-Language Interaction for Human Pose Estimation](https://arxiv.org/abs/2509.07385)
*Shibang Liu,Xuemei Xie,Guangming Shi*

Main category: cs.CV

TL;DR: 提出了基于解析图的视觉-语言交互模型PGVL，通过引导模块实现多模态融合，解决遮挡场景下人体姿态估计问题

- Motivation: 现有解析图方法主要关注单模态建模，忽略了多模态融合的潜力。语言提供了丰富的空间关系先验，但现有视觉-语言融合方法通过全局特征集成会削弱遮挡区域响应并导致对齐和定位失败
- Method: 提出PGVL模型，包含引导模块(GM)。低层节点关注局部特征以保持遮挡区域响应，高层节点集成全局特征推断遮挡部分。GM使高语义节点引导低语义节点的特征更新，确保信息有效融合。包含自上而下分解和自下而上组合两阶段
- Result: 在主要姿态估计数据集上验证了PGVL和网络的有效性
- Conclusion: PGVL通过多模态融合和引导机制有效提升了遮挡场景下的人体姿态估计性能


### [28] [DreamLifting: A Plug-in Module Lifting MV Diffusion Models for 3D Asset Generation](https://arxiv.org/abs/2509.07435)
*Ze-Xin Yin,Jiaxiong Qiu,Liu Liu,Xinjie Wang,Wei Sui,Zhizhong Su,Jian Yang,Jin Xie*

Main category: cs.CV

TL;DR: LGAA是一个轻量级高斯资产适配器框架，通过利用多视角扩散先验，统一建模几何和PBR材质，实现端到端的PBR就绪3D资产生成。

- Motivation: 现有的3D生成方法主要关注几何建模，将纹理烘焙为简单顶点颜色或依赖后处理的图像扩散模型，缺乏端到端的PBR材质生成能力。
- Method: 采用模块化设计：LGAA Wrapper重用多视角扩散模型层；LGAA Switcher对齐多个扩散先验；LGAA Decoder预测带PBR通道的2D高斯泼溅；专用后处理提取可重光照网格资产。
- Result: 在文本和图像条件多视角扩散模型上表现出优越性能，仅需69k多视角实例即可高效收敛，支持灵活集成多个扩散先验。
- Conclusion: LGAA框架成功实现了端到端的PBR就绪3D资产生成，通过知识保留方案和模块化设计，在数据效率和高品质资产生成方面表现优异。


### [29] [In the Eye of MLLM: Benchmarking Egocentric Video Intent Understanding with Gaze-Guided Prompting](https://arxiv.org/abs/2509.07447)
*Taiying Peng,Jiacheng Hua,Miao Liu,Feng Lu*

Main category: cs.CV

TL;DR: 提出了EgoGazeVQA基准，利用注视信息提升多模态大语言模型在自我中心视频问答中的表现，通过注视引导的意图提示方法显著改善用户意图理解。

- Motivation: 现有基准忽略了注视作为用户意图指示器的重要作用，自我中心视频通过统一坐标系捕捉用户焦点、动作和上下文，为个性化AI体验提供了机会。
- Method: 构建了基于注视的QA对数据集，采用注视引导的意图提示方法整合空间、时间和意图相关线索，并进行注视相关的微调实验。
- Result: 现有MLLMs难以准确解释用户意图，而注视引导方法显著提升了性能，注视估计准确性影响提示效果。
- Conclusion: 注视信息对于在自我中心设置中实现更个性化和有效的AI助手具有重要价值。


### [30] [GLEAM: Learning to Match and Explain in Cross-View Geo-Localization](https://arxiv.org/abs/2509.07450)
*Xudong Lu,Zhi Zheng,Yi Wan,Yongxiang Yao,Annan Wang,Renrui Zhang,Panwang Xia,Qiong Wu,Qingyun Li,Weifeng Lin,Xiangyu Zhao,Xue Yang,Hongsheng Li*

Main category: cs.CV

TL;DR: 该文章提出GLEAM-C和GLEAM-X两个模型，统一多视角多模态地理定位并提供可解释的跨视角匹配理由。GLEAM-C通过两阶段训练实现高效多模态对齐，GLEAM-X利用MLLM进行可解释的跨视角推理。

- Motivation: 解决现有跨视角地理定位方法存在的问题：限制于单一视角/模态、缺乏解释性、直接视觉匹配方式不可解释匹配理由。
- Method: GLEAM-C：通过两阶段训练策略，优化实现多模态多视角与卫星图像对齐。GLEAM-X：利用多模态大语言模型的推理能力，构建双语标准数据集支持可解释的跨视角匹配理由分析。
- Result: 实现了多模态多视角的统一对齐，训练效率得到优化，精度与之前模态特定方法相当。构建了高质量的可解释性评测标准数据集。
- Conclusion: 该研究构建了一个统一准确匹配与可解释性推理的完整CVGL流程，推进了地理定位的透明性和可扩展性，为地理定位领域提供了更好的解释能力。


### [31] [XOCT: Enhancing OCT to OCTA Translation via Cross-Dimensional Supervised Multi-Scale Feature Learning](https://arxiv.org/abs/2509.07455)
*Pooya Khosravi,Kun Han,Anthony T. Wu,Arghavan Rezvani,Zexin Feng,Xiaohui Xie*

Main category: cs.CV

TL;DR: XOCT是一个深度学习框架，通过跨维度监督和多尺度特征融合实现视网膜层感知的血管重建，从OCT图像生成高质量OCTA图像

- Motivation: 传统OCTA图像获取困难且成本高，现有深度学习方法忽略视网膜层间血管差异，难以重建诊断所需的精细血管细节
- Method: 结合跨维度监督(CDS)模块和多尺度特征融合(MSFF)网络，使用2D分层投影作为监督信号，通过多尺度特征提取和通道重加权策略增强血管描绘
- Result: 在OCTA-500数据集上表现优异，特别是在临床评估关键的en-face投影方面有显著改进
- Conclusion: XOCT有潜力提高OCTA的可及性、可靠性和诊断价值，增强眼科疾病检测和监测能力


### [32] [Bias-Aware Machine Unlearning: Towards Fairer Vision Models via Controllable Forgetting](https://arxiv.org/abs/2509.07456)
*Sai Siddhartha Chary Aylapuram,Veeraraju Elluru,Shivang Agarwal*

Main category: cs.CV

TL;DR: 该论文提出了Bias-Aware Machine Unlearning方法，通过选择性移除有偏样本或特征表示来减少视觉模型中的偏见，在多个数据集上显著改善了公平性指标，且准确率损失最小。

- Motivation: 深度神经网络在训练数据中经常依赖虚假相关性，导致在医疗和自动驾驶等安全关键领域产生有偏见或不公平的预测。传统偏见缓解方法需要从头重新训练或重新设计数据管道，而机器遗忘技术提供了一种有前景的后处理模型校正替代方案。
- Method: 基于隐私保护遗忘技术，评估了多种策略包括梯度上升、LoRA和师生蒸馏方法。在三个基准数据集（CUB-200-2011的姿态偏见、CIFAR-10的合成补丁偏见、CelebA的微笑检测中的性别偏见）上进行实证分析。
- Result: 后处理遗忘方法显著减少了子群体差异，在CUB-200上人口统计公平性改善达94.86%，CIFAR-10上30.28%，CelebA上97.37%。这些改进以最小的准确率损失实现，在效用、公平性、质量和隐私的联合评估中平均得分0.62。
- Conclusion: 研究结果表明机器遗忘是一个实用的框架，可以在不需要完全重新训练的情况下增强已部署视觉系统的公平性。


### [33] [ANYPORTAL: Zero-Shot Consistent Video Background Replacement](https://arxiv.org/abs/2509.07472)
*Wenshuo Gao,Xicheng Lan,Shuai Yang*

Main category: cs.CV

TL;DR: ANYPORTAL是一个零样本视频背景替换框架，利用预训练扩散模型实现高质量视频编辑，无需训练即可保持前景一致性和时间连贯性

- Motivation: 现有视频生成技术在精确控制视频细节方面存在不足，难以实现细粒度的用户意图对齐，限制了实际应用价值
- Method: 提出零样本框架，协同整合视频扩散模型的时间先验和图像扩散模型的重新光照能力，采用精炼投影算法实现像素级细节操作以确保前景一致性
- Result: 实验结果表明ANYPORTAL在消费级GPU上实现了高质量结果，为视频内容创作和编辑提供了实用高效的解决方案
- Conclusion: 该框架成功解决了前景一致性和时间连贯重新光照的挑战，无需训练即可实现精确的视频背景替换


### [34] [MedicalPatchNet: A Patch-Based Self-Explainable AI Architecture for Chest X-ray Classification](https://arxiv.org/abs/2509.07477)
*Patrick Wienholt,Christiane Kuhl,Jakob Nikolas Kather,Sven Nebelung,Daniel Truhn*

Main category: cs.CV

TL;DR: MedicalPatchNet是一种自解释性胸部X光分类架构，通过将图像分割成独立分类的补丁来提供透明决策依据，在保持分类性能的同时显著提升了解释性和病理定位准确性。

- Motivation: 深度神经网络在放射图像分类中表现优异但可解释性差，限制了临床接受度。需要开发能够透明展示决策依据的自解释模型来提高临床信任。
- Method: 将图像分割成不重叠的补丁，独立分类每个补丁，然后聚合预测结果。无需后处理技术即可直观可视化每个补丁的诊断贡献。
- Result: 在CheXpert数据集上达到与EfficientNet-B0相当的分类性能（AUROC 0.907 vs 0.908），在CheXlocalize数据集上病理定位准确率显著提高（平均命中率0.485 vs Grad-CAM的0.376）。
- Conclusion: MedicalPatchNet通过提供明确可靠的可视化解释，减轻了捷径学习的风险，提高了临床信任度，为医学影像领域提供了更安全、可解释的AI辅助诊断方案。


### [35] [LINR Bridge: Vector Graphic Animation via Neural Implicits and Video Diffusion Priors](https://arxiv.org/abs/2509.07484)
*Wenshuo Gao,Xicheng Lan,Luyao Zhang,Shuai Yang*

Main category: cs.CV

TL;DR: 通过结合隐式神经表示和文本到视频水印模型的新方法，自动生成高质量的向量图形动画，充分保留向量图形的无限分辨率特性。

- Motivation: 向量图形动画能提高可理解性和可控性，但手动制作耗时耗力，需要自动化方法来解决这一问题。
- Method: 采用分层隐式神经表示重建向量图形，保留其无限分辨率等特性；通过视频评分蒐取核心技术优化神经表示，利用预训练文本到视频模型的运动先验知识；最后将向量图形变形以匹配神经表示生成平滑动画。
- Result: 实验结果证明该方法能够生成生动自然的向量图形动画，在灵活性和动画质量方面显著改善了现有技术的不足。
- Conclusion: 该研究提出的新题方法有效地解决了向量图形动画自动化的挑战，为生成高质量向量动画提供了有效的技术路径。


### [36] [Fine-Tuning Vision-Language Models for Visual Navigation Assistance](https://arxiv.org/abs/2509.07488)
*Xiao Li,Bharat Gandhi,Ming Zhan,Mohit Nehra,Zhicheng Zhang,Yuchen Sun,Meijia Song,Naisheng Zhang,Xi Wang*

Main category: cs.CV

TL;DR: 通过细调BLIP-2模型使用LoRA技术，给出视觉障碍人士提供基于图像和自然语言的室内导航指令，解决传统导航系统在室内精确度不足的问题。

- Motivation: 传统导航系统在室内环境中效果差，因为缺乏精确位置数据。需要为视力障碍人士提供更有效的室内导航帮助，提高他们的可访问性和独立性。
- Method: 集成视觉和语言模型，使用Low Rank Adaptation (LoRA)技术对BLIP-2模型进行细调，基于手动注释的室内导航数据集进行训练，生成步骤式导航指令。
- Result: 应用LoRA后，模型在生成方向性指令方面显著提升，克服了原始BLIP-2模型的限制。提出了一种改进的评估指标，通过强调方向性和序列变量来精炼BERT F1分数，提供更全面的导航性能测量。
- Conclusion: 该方法有效地解决了室内导航的挑战，为视力障碍人士提供了更准确的导航指引，在方向性指令生成方面取得了显著进步。


### [37] [DiGS: Accurate and Complete Surface Reconstruction from 3D Gaussians via Direct SDF Learning](https://arxiv.org/abs/2509.07493)
*Wenzhi Guo,Bing Wang*

Main category: cs.CV

TL;DR: DiGS将符号距离场(SDF)学习嵌入到3D高斯泼溅框架中，通过为每个高斯基元关联可学习的SDF值来增强几何一致性，并设计了几何引导的网格增长策略来改善表面重建质量。

- Motivation: 3D高斯泼溅在渲染方面表现出色，但由于表示的非结构化和缺乏显式几何监督，在实现准确完整的表面重建方面仍面临挑战。
- Method: 提出统一框架DiGS，将SDF学习直接嵌入3DGS流程，为每个高斯基元关联可学习SDF值，并设计几何引导的多尺度网格增长策略来自适应分布高斯基元。
- Result: 在DTU、Mip-NeRF 360和Tanks&Temples等标准基准测试中，DiGS在保持高渲染保真度的同时， consistently提高了重建准确性和完整性。
- Conclusion: DiGS通过结合SDF学习成功解决了3DGS的表面重建问题，在多个基准测试中展现出优越的重建质量和渲染性能。


### [38] [Generating Transferrable Adversarial Examples via Local Mixing and Logits Optimization for Remote Sensing Object Recognition](https://arxiv.org/abs/2509.07495)
*Chun Liu,Hailong Wang,Bingqian Zhu,Panpan Ding,Zheng Zheng,Tao Xu,Zhigang Han,Jiayao Wang*

Main category: cs.CV

TL;DR: 本文提出一种通过局部混合和logits优化的新框架，用于提高深度神经网络对抗性攻击的转移性，在遥感图像数据集上表现优异。

- Motivation: 当前的混合基深度学习攻击策略存在两个主要问题：全局混合可能破坏语义特征，以及交叉熵损失导致的梯度消失问题。
- Method: 提出三个核心技术：1)局部混合策略产生语义一致的多样化输入；2)将logit损失适配到非目标攻击场景；3)应用波动平滑损失控到高频噪声。
- Result: 在FGSCR-42和MTARSI数据集上进行了涉及12种最新方法和6个代理模型的广泛实验，在MTARSI数据集上使用ResNet作为代理模型时，黑盒攻击成功率平均提高17.28%。
- Conclusion: 该方法通过保持全局语义特征和解决梯度消失问题，显著提高了对抗性攻击的转移性，为遥感应用中的DNN安全部署提供了有效解决方案。


### [39] [MVAT: Multi-View Aware Teacher for Weakly Supervised 3D Object Detection](https://arxiv.org/abs/2509.07507)
*Saad Lahlali,Alexandre Fournier Montgieux,Nicolas Granger,Hervé Le Borgne,Quoc Cuong Pham*

Main category: cs.CV

TL;DR: MVAT是一个弱监督3D目标检测框架，利用时序多视图信息解决2D标注投影模糊性问题，通过师生蒸馏范式实现高质量伪标签生成，无需3D标注即可达到接近全监督方法的性能

- Motivation: 3D数据标注成本高昂，而仅依赖2D框标注存在投影模糊性和部分可见性问题，需要开发能够利用时序多视图信息的弱监督方法
- Method: 提出MVAT框架：1）跨时间聚合目标点云构建完整3D表示；2）采用师生蒸馏范式，教师网络从单视图学习但目标来自时序聚合的静态对象；3）引入多视图2D投影损失确保3D框预测与所有可用2D标注的一致性
- Result: 在nuScenes和Waymo Open数据集上达到最先进的弱监督3D目标检测性能，显著缩小了与全监督方法的差距
- Conclusion: MVAT通过有效利用时序多视图信息解决了弱监督3D检测的关键挑战，证明了无需3D标注也能实现高质量3D目标检测的可行性


### [40] [EHWGesture -- A dataset for multimodal understanding of clinical gestures](https://arxiv.org/abs/2509.07525)
*Gianluca Amprimo,Alberto Ancilotto,Alessandro Savino,Fabio Quazzolo,Claudia Ferraris,Gabriella Olmo,Elisabetta Farella,Stefano Di Carlo*

Main category: cs.CV

TL;DR: EHWGesture是一个多模态手势理解数据集，包含1100多个记录，使用RGB-Depth相机和事件相机捕获，提供精确的手部关键点跟踪和动作质量评估。

- Motivation: 动态手势理解在临床手部灵活性评估中很重要，但现有数据集缺乏多模态多样性、精确跟踪和动作质量评估组件。
- Method: 收集25名健康受试者的5种临床相关手势数据，使用两个高分辨率RGB-Depth相机和事件相机，通过运动捕捉系统提供精确手部地标跟踪，所有设备空间校准和同步。
- Result: 数据集包含6小时记录，支持手势分类、手势触发检测和动作质量评估的基线实验。
- Conclusion: EHWGesture可作为推进多模态临床手势理解的综合基准数据集。


### [41] [Universal Few-Shot Spatial Control for Diffusion Models](https://arxiv.org/abs/2509.07530)
*Kiet T. Nguyen,Chanhuyk Lee,Donggyun Kim,Dong Hoon Lee,Seunghoon Hong*

Main category: cs.CV

TL;DR: UFC是一个通用的少样本控制适配器，能够在少量样本下泛化到新的空间控制条件，仅需30个标注样本即可实现精细控制，性能与全监督基线相当。

- Motivation: 现有的控制适配器在面对与训练任务差异较大的新空间控制条件时，适应能力有限且训练成本高，需要解决这一限制。
- Method: 提出UFC方法，通过查询条件和支持条件之间的类比来构建任务特定的控制特征，使用匹配机制和小型任务特定参数更新来实现。
- Result: 在6个新空间控制任务上的实验表明，UFC仅用30个标注样本就能实现与空间条件一致的精细控制，使用0.1%的全训练数据即可达到与全监督基线竞争的性能。
- Conclusion: UFC是一个通用的少样本控制适配器，能够有效泛化到新的空间控制任务，适用于不同的扩散模型架构（UNet和DiT），具有很好的实用性。


### [42] [HU-based Foreground Masking for 3D Medical Masked Image Modeling](https://arxiv.org/abs/2509.07534)
*Jin Lee,Vu Dang,Gwang-Hyun Yu,Anh Le,Zahid Rahman,Jin-Ho Jang,Heonzoo Lee,Kun-Yung Kim,Jin-Sul Kim,Jin-Young Kim*

Main category: cs.CV

TL;DR: 该论文提出了一种基于Hounsfield Unit的前景掩码策略，用于改进3D医学图像中的掩码图像建模，通过关注内脏器官强度分布来提升分割性能。

- Motivation: 传统的随机掩码策略在3D医学图像计算中忽视了解剖对象的密度特征，无法充分利用医学图像中诊断相关的组织区域。
- Method: 利用Hounsfield Unit测量值实现基于HU的前景掩码，专注于内脏器官的强度分布，排除空气和液体等非组织区域。
- Result: 在五个公开3D医学影像数据集上取得显著性能提升，分割质量和Dice分数均有改善（BTCV:84.64%, Flare22:92.43%, MM-WHS:90.67%, Amos22:88.64%, BraTS:78.55%）。
- Conclusion: 基于领域特性的掩码图像建模对医学图像分割表示学习具有重要意义，为医学图像分析提供了有前景的研究方向。


### [43] [TextlessRAG: End-to-End Visual Document RAG by Speech Without Text](https://arxiv.org/abs/2509.07538)
*Peijin Xie,Shun Qian,Bingquan Liu,Dexin Wang,Lin Sun,Xiangzheng Zhang*

Main category: cs.CV

TL;DR: TextlessRAG是首个端到端的语音问答框架，可直接处理语音查询，在文档图像中检索知识并生成答案，无需ASR、TTS和OCR，显著提升了效率和准确性。

- Motivation: 文档图像包含丰富知识，语音查询具有便携性和灵活性，但之前没有工作探索过直接在语音查询下对视觉文档图像进行知识库问答。
- Method: 提出TextlessRAG端到端框架，消除ASR、TTS和OCR，直接解释语音、检索相关视觉知识并生成答案；集成布局感知重排序机制来优化检索。
- Result: 实验证明在效率和准确性方面都有显著提升，并发布了首个双语语音-文档RAG数据集（中英文语音查询与多模态文档内容配对）。
- Conclusion: TextlessRAG为语音驱动的文档图像问答提供了有效的端到端解决方案，推动了该方向的研究发展。


### [44] [PanoLAM: Large Avatar Model for Gaussian Full-Head Synthesis from One-shot Unposed Image](https://arxiv.org/abs/2509.07552)
*Peng Li,Yisheng He,Yingdong Hu,Yuan Dong,Weihao Yuan,Yuan Liu,Zilong Dong,Yike Guo*

Main category: cs.CV

TL;DR: 提出了一种从单张无姿态图像进行高斯全头合成的前馈框架，无需耗时GAN反演和测试时优化，实现快速重建和渲染。

- Motivation: 现有方法依赖耗时的GAN反演和测试时优化，无法实现快速重建。同时缺乏大规模3D头部数据集。
- Method: 使用3D GAN生成大规模合成数据集；采用粗到细的高斯头生成管道，通过FLAME模型稀疏点与图像特征交互；提出双分支框架聚合结构化球面三平面特征和非结构化点基特征。
- Result: 实验结果表明该框架相比现有工作具有更好的效果，能够实现快速的高保真头部重建。
- Conclusion: 该前馈框架能够从单张无姿态图像高效重建高斯全头模型，为快速3D头部合成提供了有效解决方案。


### [45] [Attention Maps in 3D Shape Classification for Dental Stage Estimation with Class Node Graph Attention Networks](https://arxiv.org/abs/2509.07581)
*Barkin Buyukcakir,Rocharles Cavalcante Fontenele,Reinhilde Jacobs,Jannick De Tobel,Patrick Thevissen,Dirk Vandermeulen,Peter Claes*

Main category: cs.CV

TL;DR: 本文提出了Class Node Graph Attention Network (CGAT)架构，用于3D形状识别任务的可解释深度学习，通过在牙齿CBCT图像上进行Demirjian分期评估，结合注意力机制提供可视化解释。

- Motivation: 深度学习在黑盒性质限制了其在高风险应用中的采用，特别是在需要信任和问责制的医学和法医学领域。为了解决3D形状识别任务的可解释性问题，需要开发能够提供决策过程透明度的模型。
- Method: 使用CGAT架构，应用图注意力卷积和内在注意力机制，通过注意力rollout可视化决策过程。评估了局部平均曲率和到质心距离的节点特征，以及模型深度，并研究了包含指向全局CLS节点的有向边的影响。
- Result: 结合局部平均曲率和到质心距离作为节点特征的模型获得了0.76的加权F1分数，性能略有提升，并产生更全面的注意力可视化。包含指向全局CLS节点有向边的模型产生了更直观的注意力图，同时保持了良好的分类性能。
- Conclusion: CGAT架构能够生成人类可理解的注意力图，增强信任并促进专家对模型决策的验证。虽然是在牙科数据上演示，但CGAT广泛适用于基于图的分类和回归任务，有助于在高风险环境中推广透明且具有竞争力的深度学习模型。


### [46] [Temporal Image Forensics: A Review and Critical Evaluation](https://arxiv.org/abs/2509.07591)
*Robert Jöchl,Andreas Uhl*

Main category: cs.CV

TL;DR: 这是一篇关于时间图像司法定学的综述性论文，主要研究利用图像获取流程中的时间依赖迹迹来估计数字图像的年龄，并重点分析内地传感器缺陷和传感器尘均等年龄迹迹的特性。

- Motivation: 提供对时间图像司法定学领域的全面概述，重点关注时间依赖迹迹的特性和技术，并强调内容偏差问题以及可解释人工智能方法在验证时间图像司法定技术可靠性中的重要性。
- Method: 通过分析、重新实现和实验来评估现有方法：提出新的司法定设置、验证内地传感器缺陷的增长速率和空间分布、分析神经网络学习的特征，以及展示神经网络如何容易被分散注意力而无法学习年龄迹迹。
- Result: 证实了一些方法实际上利用的是其他迹迹（很可能是内容偏差）而非内地传感器缺陷；进一步研究了神经网络在掌纹图像年龄识别中学习的特征；展示了神经网络容易被分散注意力的问题。
- Conclusion: 该综述不仅总结了现有时间图像司法定技术，还提出了更现实的司法定设置，并强调了内容偏差的重要性以及需要可解释的AI方法来确保技术的可靠性。


### [47] [Bias in Gender Bias Benchmarks: How Spurious Features Distort Evaluation](https://arxiv.org/abs/2509.07596)
*Yusuke Hirota,Ryo Hachiuma,Boyi Li,Ximing Lu,Michael Ross Boone,Boris Ivanovic,Yejin Choi,Marco Pavone,Yu-Chiang Frank Wang,Noa Garcia,Yuta Nakashima,Chao-Han Huck Yang*

Main category: cs.CV

TL;DR: 研究发现视觉语言基础模型中的性别偏见评估容易受到非性别特征（如物体和背景）的干扰，即使微小扰动也会显著改变偏见分数，建议在报告偏见指标时同时报告特征敏感性测量

- Motivation: 当前基于真实图像的性别偏见评估基准存在性别与非性别特征之间的虚假相关性，需要研究这些虚假特征是否扭曲了性别偏见评估的可靠性
- Method: 系统性地扰动四个广泛使用的基准（COCO-gender、FACET、MIAP、PHASE）和各种VLM中的非性别特征，量化它们对偏见评估的影响
- Result: 即使最小扰动（如仅遮蔽10%物体或轻微模糊背景）也能显著改变偏见分数，生成式VLM指标变化高达175%，CLIP变体变化达43%
- Conclusion: 当前偏见评估往往反映模型对虚假特征而非性别偏见的响应，建议报告偏见指标时同时报告特征敏感性测量以实现更可靠的偏见评估


### [48] [Data-Efficient Fine-Tuning of Vision-Language Models for Diagnosis of Alzheimer's Disease](https://arxiv.org/abs/2509.07613)
*Fangqi Cheng,Surajit Ray,Xiaochen Yang*

Main category: cs.CV

TL;DR: 通过数据高效微调流水线，将3D CT基础的医学视觉-语言模型适配到3D MRI，并在阿尔茫海默病诊断中达到独创性能。

- Motivation: 现有医学视觉-语言模型存在三个主要问题：患者元数据利用不充分，缺乏临床诊断知识集成，以3D医学形慈处理效果有限。
- Method: 1. 将结构化元数据转换为合成报告以丰富文本输入；2. 添加预测MMSE评分的辅助token提供辅助监督；3. 采用轻量级prompt tuning方法。
- Result: 在仅使用1,500张训练图像的情况下，在两个AD数据集上达到独创性能，超过了使用10,000张图像微调的现有方法。
- Conclusion: 该方法通过创新地利用元数据和临床评分指标，实现了高效的3D医学形慈处理，为医学AI模型的数据效率和临床集成提供了新思路。


### [49] [Self-Supervised Cross-Encoder for Neurodegenerative Disease Diagnosis](https://arxiv.org/abs/2509.07623)
*Fangqi Cheng,Yingying Zhao,Xiaochen Yang*

Main category: cs.CV

TL;DR: 自监督跨编码器框架，通过结构化表征学习提升MRI诊断神经退行性疾病的准确性和可解释性，并具有良好的转移学习能力

- Motivation: 解决现有深度学习方法对大量标签数据的依赖性和表征可解释性不足的问题
- Method: 提出自监督跨编码器框架，利用纵向MRI扫描的时间连续性进行监督，将表征解构为静态结构表征（通过对比学习约束）和动态变化表征（通过输入梯度正则化指导）
- Result: 在ADNI数据集上达到优异的分类准确性和改善的可解释性，在OASIS数据集上显示出强劲的零样本转移能力，在PPMI数据集上显示跨任务转移能力
- Conclusion: 该方法有效解决了标签数据依赖和可解释性问题，为神经退行性疾病诊断提供了更加准确、可解释且具有良好转移性的解决方案


### [50] [Semantic Watermarking Reinvented: Enhancing Robustness and Generation Quality with Fourier Integrity](https://arxiv.org/abs/2509.07647)
*Sung Ju Lee,Nam Ik Cho*

Main category: cs.CV

TL;DR: 提出Hermitian对称傅里叶水印(SFW)方法，通过保持频率完整性来增强潜在扩散模型语义水印的鲁棒性和检测性能。

- Motivation: 现有语义水印技术对再生攻击具有鲁棒性，但由于频率完整性损失导致检测性能下降，需要解决这一问题。
- Method: 提出SFW方法通过强制Hermitian对称性保持频率完整性，并引入中心感知嵌入策略来抵御裁剪攻击。
- Result: 实验表明该方法在多种攻击场景下达到最先进的验证和识别性能，同时保持优异的图像保真度。
- Conclusion: SFW是平衡鲁棒性和图像保真度的有效框架，解决了语义水印中的固有权衡问题。


### [51] [Beyond Motion Cues and Structural Sparsity: Revisiting Small Moving Target Detection](https://arxiv.org/abs/2509.07654)
*Guoyi Zhang,Siyang Chen,Guangsheng Xu,Zhihua Shen,Han Wang,Xiaohu Zhang*

Main category: cs.CV

TL;DR: 提出TenRPCANet深度学习框架，通过张量低秩稀疏分解和自注意力机制实现小目标检测，在红外小目标和空间目标检测任务上达到最先进性能

- Motivation: 小运动目标检测在国防应用中至关重要，但现有方法依赖目标特定特征或运动线索，在复杂环境中缺乏鲁棒性。背景的低秩结构可作为检测的稳定先验
- Method: 将任务重构为基于张量的低秩稀疏分解问题，提出TenRPCANet网络，使用tokenization策略通过自注意力机制隐式强制执行多阶张量低秩先验，并设计特征细化模块增强目标显著性
- Result: 在两个高度不同的挑战性任务（多帧红外小目标检测和空间目标检测）上实现了最先进的性能
- Conclusion: 该方法证明了在小目标检测中的有效性和泛化能力，无需对目标特征做过多假设


### [52] [EDFFDNet: Towards Accurate and Efficient Unsupervised Multi-Grid Image Registration](https://arxiv.org/abs/2509.07662)
*Haokai Zhu,Bo Qu,Si-Yuan Cao,Runmin Zhang,Shujie Chen,Bailin Yang,Hui-Liang Shen*

Main category: cs.CV

TL;DR: 提出EDFFDNet网络，使用指数衰减基函数的自由形变，在深度差异场景中表现优异，参数和计算量大幅减少，性能优于现有方法

- Motivation: 解决现有深度图像配准方法（单应性、多网格单应性、薄板样条）在包含深度差异的真实场景中的局限性
- Method: 1. 指数衰减自由形变网络(EDFFDNet)使用指数衰减基函数；2. 自适应稀疏运动聚合器(ASMA)替代MLP聚合器；3. 渐进式相关性细化策略进行粗到细运动估计
- Result: 参数减少70.5%，内存减少32.6%，总运行时间减少33.7%，PSNR提升0.5dB；EDFFDNet-2进一步提升PSNR 1.06dB，同时保持较低计算成本
- Conclusion: 该方法在深度差异场景中表现优异，具有强泛化能力，计算效率高，性能优于现有深度学习方法


### [53] [Nearest Neighbor Projection Removal Adversarial Training](https://arxiv.org/abs/2509.07673)
*Himanshu Singh,A. V. Subramanyam,Shivank Rajput,Mohan Kankanhalli*

Main category: cs.CV

TL;DR: 提出了一种新的对抗训练框架，通过消除特征空间中的类间依赖关系来增强深度神经网络的对抗鲁棒性，在多个基准数据集上取得了优异的鲁棒性和干净准确率。

- Motivation: 深度神经网络在图像分类中表现出色但易受对抗样本攻击。标准对抗训练虽然增强鲁棒性，但未能显式处理类间特征重叠这一导致对抗脆弱性的重要因素。
- Method: 引入新颖的对抗训练框架，通过在特征空间中投影消除对抗样本和干净样本的类间依赖关系。具体方法包括识别每个对抗样本的最近类间邻居，并移除在这些邻居上的投影以增强特征可分性。
- Result: 在CIFAR-10、CIFAR-100和SVHN等标准基准测试上的广泛实验表明，该方法在鲁棒准确率和干净准确率方面都取得了显著成就，与领先的对抗训练技术具有竞争力。
- Conclusion: 研究结果表明，显式处理类间特征邻近性对于增强深度神经网络的对抗鲁棒性至关重要，理论分析表明该方法通过降低Lipschitz常数和Rademacher复杂度来改善泛化和鲁棒性。


### [54] [CAViAR: Critic-Augmented Video Agentic Reasoning](https://arxiv.org/abs/2509.07680)
*Sachit Menon,Ahmet Iscen,Arsha Nagrani,Tobias Weyand,Carl Vondrick,Cordelia Schmid*

Main category: cs.CV

TL;DR: 本文提出了一种基于大型语言模型的视频推理代理系统，通过调用视频处理模块作为子代理或工具，结合批判器来评估执行序列的成功与否，在复杂视频推理任务上取得了优异性能。

- Motivation: 现有视频理解模型在短片段感知方面表现良好，但在需要复杂推理的长视频任务上性能下降。本文旨在探索如何利用现有的感知能力来进行更复杂的视频推理。
- Method: 开发了一个大型语言模型代理，可以访问视频处理模块作为子代理或工具。代理根据每个模块调用的结果决定后续步骤，而不是遵循固定程序。引入了批判器来区分成功和不成功的执行序列。
- Result: 该方法在LVBench、Neptune和ActivityNet-RTL等多个基准测试中表现出色，证明了其在复杂视频推理任务上的有效性。
- Conclusion: 通过结合语言模型代理和批判器机制，可以有效地利用现有视频感知能力来处理复杂的视频推理任务，为视频理解领域提供了新的解决方案。


### [55] [SEEC: Segmentation-Assisted Multi-Entropy Models for Learned Lossless Image Compression](https://arxiv.org/abs/2509.07704)
*Chunhang Zheng,Zichang Ren,Dou Li*

Main category: cs.CV

TL;DR: SEEC提出了一种基于语义分割的多熵模型无损图像压缩方法，通过为不同语义区域分配专用熵模型来提升压缩性能

- Motivation: 传统学习方法使用单一熵模型估计整个图像的概率分布，无法有效捕捉不同语义区域的多样化统计特征
- Method: 利用语义分割识别不同区域，为每个区域分配专用熵模型，采用多通道离散逻辑混合似然建模像素值分布
- Result: 在基准数据集上实现了最先进的压缩比，同时仅引入最小的编码和解码延迟
- Conclusion: SEEC框架通过语义分割指导的多熵模型选择，显著提升了无损图像压缩性能，并支持基于分割掩码的感兴趣区域编码


### [56] [XSRD-Net: EXplainable Stroke Relapse Detection](https://arxiv.org/abs/2509.07772)
*Christian Gapp,Elias Tappeiner,Martin Welk,Karl Fritscher,Stephanie Mangesius,Constantin Eisenschink,Philipp Deisl,Michael Knoflach,Astrid E. Grams,Elke R. Gizewski,Rainer Schubert*

Main category: cs.CV

TL;DR: 通过多模态深度学习模型预测脑衰复发风险，结合CTA图像和临床数据达到了较好的预测效果，发现心脏疾病和颈动脉是关键因素。

- Motivation: 脑衰是全球第二大死因，复发率高且死亡率极高(40%)，需要早期识别高风险患者以进行适当治疗。
- Method: 收集3D脑部CTA图像数据和临床数据(心脏疾病、年龄、性别)，训练单模态和多模态深度学习模型，进行二分类复发检测(Task 1)和复发免疑生存时间预测(Task 2)。
- Result: 二分类任务AUC达0.84，多模态模型在图像: 表格数据比例0.68:0.32下，c-index达0.68，AUC为0.71。解释性分析显示心脏疾病和颈动脉是关键因素。
- Conclusion: 多模态深度学习模型能够有效预测脑衰复发风险，心脏疾病和颈动脉异常是重要预测指标，需要持续收集数据以优化模型。


### [57] [HairGS: Hair Strand Reconstruction based on 3D Gaussian Splatting](https://arxiv.org/abs/2509.07774)
*Yimin Pan,Matthias Nießner,Tobias Kirschstein*

Main category: cs.CV

TL;DR: 基于3D高斯泼溅技术，提出了一种从多视角图像重建发丝级头发几何的方法，通过多阶段管道实现高效重建，并提出了评估拓扑准确性的新指标。

- Motivation: 虚拟现实和数字人建模中对高质量头发重建的需求日益增长，现有方法往往忽视发丝的连通性和拓扑结构。
- Method: 多阶段管道：首先使用可微分高斯光栅化器重建详细几何，然后通过新颖的合并方案将高斯段合并为连贯发丝，最后在光度监督下精炼和生长发丝。
- Result: 在合成和真实数据集上的广泛实验表明，该方法能稳健处理各种发型，通常在1小时内完成高效重建。
- Conclusion: 该方法成功扩展了3DGS框架，实现了发丝级头发重建，并提出了评估拓扑准确性的新指标，为头发重建领域提供了重要贡献。


### [58] [RayGaussX: Accelerating Gaussian-Based Ray Marching for Real-Time and High-Quality Novel View Synthesis](https://arxiv.org/abs/2509.07782)
*Hugo Blanc,Jean-Emmanuel Deschaud,Alexis Paljic*

Main category: cs.CV

TL;DR: RayGaussX是基于RayGauss的加速版本，通过引入体积渲染加速策略、增强光线连贯性和尺度正则化等技术，在保持高质量渲染的同时实现了5-12倍训练加速和50-80倍渲染速度提升。

- Motivation: RayGauss虽然在合成和室内场景的新视角合成中达到了最先进的渲染质量，但其计算成本过高，无法在真实世界场景中实现实时渲染。
- Method: 引入体积渲染加速策略（空域跳过和自适应采样）、增强光线连贯性、尺度正则化减少误报交集，并提出新的致密化准则改善远距离区域密度分布。
- Result: 在真实世界数据集上实现5-12倍训练加速、50-80倍渲染速度提升（FPS），视觉质量提升高达+0.56 dB PSNR。
- Conclusion: RayGaussX成功解决了RayGauss的计算效率问题，在保持甚至提升渲染质量的同时实现了显著的性能提升，适用于更大规模的场景渲染。


### [59] [Faster, Self-Supervised Super-Resolution for Anisotropic Multi-View MRI Using a Sparse Coordinate Loss](https://arxiv.org/abs/2509.07798)
*Maja Schlereth,Moritz Schillinger,Katharina Breininger*

Main category: cs.CV

TL;DR: 这篇论文提出了一种自监督的多视角神经网络方法，用于融合两个正交各异性低分辨率碱共振成像，以重建统一的高分辨率解剖细节。该方法无需高分辨率数据训练，并通过病人无关的离线和病人特异的在线阶段实现了超过10倍的重建速度提升。

- Motivation: 在医学碱共振成像中，高分辨率成像面临执行时间长、病人不适等挑战。常见解决方案是获取两个不同方向的低分辨率扫描，但医生需要分别分析这些图像，时间消耗大且容易导致误判。因此需要一种能够融合这些各异性低分辨率图像并重建统一高分辨率表示的方法。
- Method: 论文提出了一种多视角神经网络方法，采用自监督方式训练，无需对应的高分辨率数据。方法中引入了稀疏坐标基损失，使得能够集成任意缩放比例的低分辨率图像。该方法组合了病人无关的离线阶段和病人特异的在线阶段。
- Result: 在两个独立的碱共振图像数据集上评估，结果显示该方法在不同的上采样缩放下，超分辨率性能与现有自监督超分辨率方法相比较为可比或更优。通过离线-在线组合，实现了较类似SR质量的情况下，病人特异重建速度提升达10倍。
- Conclusion: 该研究提出的自监督多视角融合方法能够有效地从两个正交各异性低分辨率碱共振图像中重建高分辨率解剖细节。该方法不依赖高分辨率数据，并通过划分离线和在线阶段实现了显著的速度提升，为医学碱共振成像提供了一种高效的超分辨率重建解决方案。


### [60] [SplatFill: 3D Scene Inpainting via Depth-Guided Gaussian Splatting](https://arxiv.org/abs/2509.07809)
*Mahtab Dahaghin,Milind G. Padalkar,Matteo Toso,Alessio Del Bue*

Main category: cs.CV

TL;DR: SplatFill是一种基于深度引导的3D高斯溅射场景修复方法，通过联合深度监督和一致性感知细化，实现了最先进的感知质量和更高的效率

- Motivation: 3D高斯溅射(3DGS)虽然能从多视角图像创建逼真的3D场景表示，但在修复缺失区域（遮挡或场景编辑导致）时仍存在挑战，往往导致模糊细节、伪影和几何不一致
- Method: 结合两种关键思想：(1)联合深度基和对象基监督，确保修复的高斯在3D空间中准确定位并与周围几何对齐；(2)提出一致性感知细化方案，选择性识别和纠正不一致区域而不破坏场景其他部分
- Result: 在SPIn-NeRF数据集上的评估显示，SplatFill不仅在视觉保真度上超越了现有的NeRF基和3DGS基修复方法，还将训练时间减少了24.5%，定性结果显示该方法能提供更清晰的细节、更少的伪影和跨挑战性视角的更好一致性
- Conclusion: SplatFill通过深度引导和一致性感知细化，为3DGS场景修复提供了高效且高质量的解决方案，在感知质量和计算效率方面都达到了最先进水平


### [61] [Point Linguist Model: Segment Any Object via Bridged Large 3D-Language Model](https://arxiv.org/abs/2509.07825)
*Zhuoxu Huang,Mingqi Gao,Jungong Han*

Main category: cs.CV

TL;DR: PLM框架通过对象中心判别表示和几何重激活解码器，解决了LLM与3D点云之间的表示对齐问题，在多个3D分割任务上取得显著性能提升

- Motivation: 现有基于LLM的3D分割方法存在表示对齐问题：LLM处理高层语义token而点云只有密集几何结构，导致输入需要繁重预对齐且输出缺乏几何线索
- Method: 提出Point Linguist Model (PLM)：1) Object-centric Discriminative Representation (OcDR)学习对象中心token捕获目标语义和场景关系；2) Geometric Reactivation Decoder (GRD)结合OcDR token和密集特征进行精确分割
- Result: 在ScanNetv2上提升+7.3 mIoU，在Multi3DRefer上提升+6.0 mIoU，在7个基准测试的4个不同任务中均取得一致性能提升
- Conclusion: PLM通过全面的对象中心推理实现了鲁棒的3D理解，有效解决了LLM与3D点云之间的表示对齐问题


### [62] [Deep Learning-Based Burned Area Mapping Using Bi-Temporal Siamese Networks and AlphaEarth Foundation Datasets](https://arxiv.org/abs/2509.07852)
*Seyd Teymoor Seydi*

Main category: cs.CV

TL;DR: 使用AlphaEArth数据集和Siamese U-Net深度学习架构的自动化燃烧区域制图方法，在测试集上达到95%的整体准确度和0.6 IoU。

- Motivation: 准确及时的燃烧区域制图对环境监测、灾害管理和气候变化评估至关重要，需要一种可扩展的全球监测解决方案。
- Method: 结合AlphaEArth高分辨率光学和热红外图像数据集，使用Siamese U-Net深度学习架构进行训练，在美国MTBS数据集训练后在欧洲17个区域进行评估。
- Result: 模型在测试集上达到95%的整体准确度、0.6 IoU和74% F1分数，能够有效识别不同生态系统中的燃烧区域，特别是部分燃烧植被和火热边界。
- Conclusion: 该研究为自动化火灾损失评估提供了重要进展，通过AlphaEarth数据集提供了可扩展的全球燃烧区域监测解决方案。


### [63] [D-LEAF: Localizing and Correcting Hallucinations in Multimodal LLMs via Layer-to-head Attention Diagnostics](https://arxiv.org/abs/2509.07864)
*Tiancheng Yang,Lin Zhang,Jiaye Lin,Guimin Hu,Di Wang,Lijie Hu*

Main category: cs.CV

TL;DR: 本文提出了D-LEAF方法，通过动态定位和修正注意力机制中的错误，有效减少多模态大语言模型的幻觉问题，在图像描述任务上实现53%的相对改进，VQA任务准确率和F1分数提升约4%。

- Motivation: 现有MLLM模型存在幻觉问题，生成的文本与视觉输入冲突。先前工作采用统一的注意力调整方法，无法准确定位错误来源层和头。
- Method: 提出两种诊断工具：LIAE（层图像注意力熵）用于识别异常层，IAF（图像注意力聚焦）用于评分注意力头。基于这些信号开发D-LEAF方法，动态定位和修正推理过程中的错误。
- Result: 在标准图像描述基准上实现53%的相对改进，VQA任务准确率和F1分数均提升约4%，显著抑制幻觉同时保持效率。
- Conclusion: D-LEAF方法能够有效定位和修正MLLM中的注意力错误，大幅减少幻觉现象，且具有任务无关性和低计算开销的优点。


### [64] [Active Membership Inference Test (aMINT): Enhancing Model Auditability with Multi-Task Learning](https://arxiv.org/abs/2509.07879)
*Daniel DeAlcala,Aythami Morales,Julian Fierrez,Gonzalo Mancera,Ruben Tolosana,Javier Ortega-Garcia*

Main category: cs.CV

TL;DR: Active MINT是一种多任务学习方法，通过同时训练原始模型和MINT模型来检测训练数据的使用情况，在多个基准测试中达到80%以上的准确率。

- Motivation: 提高AI模型的透明度，为AI部署提供更强的安全保障，实现适当的安全性、隐私性和版权保护。
- Method: 提出新颖的多任务学习过程，同时训练原始模型（Audited Model）和辅助模型（MINT Model），利用中间激活图作为MINT层的输入来增强训练数据检测能力。
- Result: 在5个公共基准测试中，从MobileNet到Vision Transformers等多种神经网络架构上，Active MINT达到超过80%的训练数据检测准确率，显著优于现有方法。
- Conclusion: Active MINT方法有效提升了AI模型训练数据使用的可审计性，为AI系统的安全部署和版权保护提供了重要技术支撑。


### [65] [Object-level Correlation for Few-Shot Segmentation](https://arxiv.org/abs/2509.07917)
*Chunlin Wen,Yu Zhang,Jie Fan,Hongyuan Zhu,Xiu-Shen Wei,Yijun Wang,Zhiqiang Kou,Shuzhou Sun*

Main category: cs.CV

TL;DR: OCNet通过建立支持目标对象与查询通用对象之间的对象级相关性来解决少样本语义分割中的背景噪声问题，在PASCAL-5i和COCO-20i上达到了最先进的性能。

- Motivation: 现有的少样本语义分割方法主要建立在支持目标对象与整个查询图像之间的图像级相关性上，但这种相关性包含难以追踪和抑制的硬像素噪声（无关背景对象），导致背景过拟合。
- Method: 设计对象级相关网络（OCNet），包括通用对象挖掘模块（GOMM）和相关构建模块（CCM）。GOMM通过学习显著性和高层相似性线索构建查询通用对象特征，CCM通过分配目标原型来匹配通用对象特征建立对象级相关性。
- Result: 在PASCAL-5i和COCO-20i数据集上的大量实验表明，该模型达到了最先进的性能。
- Conclusion: 通过模仿生物视觉过程建立对象级相关性，能够有效挖掘查询目标特征并抑制硬像素噪声，在少样本语义分割任务中取得了优异效果。


### [66] [ScoreHOI: Physically Plausible Reconstruction of Human-Object Interaction via Score-Guided Diffusion](https://arxiv.org/abs/2509.07920)
*Ao Li,Jinpeng Liu,Yixuan Zhu,Yansong Tang*

Main category: cs.CV

TL;DR: ScoreHOI是一个基于扩散模型的优化器，利用扩散先验和物理约束来精确重建人-物交互，通过接触驱动的迭代细化方法提升接触合理性和重建精度。

- Motivation: 传统优化方法由于缺乏人-物交互的先验知识，难以实现物理上合理的重建结果。
- Method: 利用分数引导采样的可控性，扩散模型重建给定图像观测和物体特征条件下的人体和物体姿态条件分布；在推理时通过特定物理约束引导去噪过程；提出接触驱动的迭代细化方法。
- Result: 在标准基准测试上表现出优于最先进方法的性能，实现了精确和稳健的人-物交互联合重建改进。
- Conclusion: ScoreHOI通过引入扩散先验和物理约束，有效解决了人-物交互重建中的物理合理性问题，展现了优越的重建性能。


### [67] [Multimodal Contrastive Pretraining of CBCT and IOS for Enhanced Tooth Segmentation](https://arxiv.org/abs/2509.07923)
*Moo Hyun Son,Juyoung Bae,Zelin Qiu,Jiale Peng,Kai Xin Li,Yifan Lin,Hao Chen*

Main category: cs.CV

TL;DR: 提出了首个多模态预训练框架ToothMCL，通过CBCT和IOS数据的对比学习实现精确牙齿分割和编号识别，在多个数据集上达到SOTA性能

- Motivation: 现有牙齿分割方法缺乏严格验证，性能和临床适用性有限，需要更准确的多模态数字牙科表示方法
- Method: ToothMCL多模态对比学习框架，整合体积(CBCT)和表面(IOS)模态，捕获模态不变表示，实现精确多类分割和FDI编号识别
- Result: 在内部和外部测试中均达到最先进性能，CBCT分割DSC提升12%，IOS分割提升8%，构建了最大的配对CBCT-IOS数据集(3,867患者)
- Conclusion: ToothMCL框架在牙齿分割任务中表现出卓越性能和强大泛化能力，为数字牙科提供了有效的多模态预训练解决方案


### [68] [Accelerating Local AI on Consumer GPUs: A Hardware-Aware Dynamic Strategy for YOLOv10s](https://arxiv.org/abs/2509.07928)
*Mahmudul Islam Masum,Miad Islam,Arif I. Sarwat*

Main category: cs.CV

TL;DR: 通过两次适配性推理算法解决消费级硬件上对象检测的系统级性能瓶颈，在RTX 4060等设备上实现1.85x加速，mAP仅下降5.51%

- Motivation: 当前本地AI模型在消费级硬件上存在系统级性能瓶颈，而非计算能力限制，需要重新思考硬件感知的推理策略
- Method: 提出两次适配性推理算法：先使用快速低分辨率模型进行检测，仅在检测信心度低时才升级到高分辨率模型，无需模型结构改动
- Result: 在5000张COCO图片上，方法比PyTorch Early-Exit基准提高1.85倍速度，mAP仅下降5.51%，在RTX 4060等消费级GPU上实现高性能实时推理
- Conclusion: 通过从纯粹模型优化转向硬件感知的推理策略，可以在消费级设备上部署高性能实时AI，提供了可复现的实践蓝图


### [69] [Dynamic Scene 3D Reconstruction of an Uncooperative Resident Space Object](https://arxiv.org/abs/2509.07932)
*Bala Prenith Reddy Gopu,Timothy Jacob Huber,George M. Nehma,Patrick Quinn,Madhur Tiwari,Matt Ueckermann,David Hinckley,Christopher McKenna*

Main category: cs.CV

TL;DR: 这篇论文评估了现有动态场景3D重建算法在重建无人控空间物体的性能，通过Isaac Sim模拟环境生成物理准确的图像序列，并使用Neuralangelo算法在静态场景中得到了高精度的重建结果。

- Motivation: 为了支持轨道服务和游击废弃物清除任务，需要准确重建无人控空间物体的几何和运动特性，特别是处于漫游状态的目标。
- Method: 使用Isaac Sim模拟环境生成物理准确的2D图像序列，在实际轨道光照条件下模拟漫游卫星。采用Neuralangelo算法进行静态场景的3D重建，并使用Cloud Compare进行误差分析。
- Result: 在静态场景中，Neuralangelo算法生成的3D网格与原始CAD模型协调一致，误差和伪影最小。重建模型能够捐捕到关键细节，满足任务规划需求。
- Conclusion: 研究为动态场景重建的进一步评估提供了基准，静态场景下的成功重建表明方法的可行性。


### [70] [Feature Space Analysis by Guided Diffusion Model](https://arxiv.org/abs/2509.07936)
*Kimiaki Shirahama,Miki Yanobu,Kaduki Yamashita,Miho Ohsaki*

Main category: cs.CV

TL;DR: 通过导向潜变模型实现反向图像生成，保证生成图像的特征与指定特征高度相似，用于解释DNN黑盒特征空间

- Motivation: 解决深度神经网络特征提取过程的黑盒性问题，分析DNN特征空间中编码的图像属性
- Method: 使用导向潜变模型，在预训练潜变模型的反向图像生成过程中最小化每步清漏图像估计特征与用户指定特征的欧几里得距离
- Result: 生成的图像特征与指定特征高度相似，为CLIP图像编码器、ResNet-50和视觉Transformer提供了价值进展的特征空间见解
- Conclusion: 该解码器无需额外训练即可分析不同DNN的特征空间，在单台COTS GPU上运行，为解释DNN黑盒提供了有效工具


### [71] [Visual-TableQA: Open-Domain Benchmark for Reasoning over Table Images](https://arxiv.org/abs/2509.07966)
*Boammani Aser Lompo,Marc Haraoui*

Main category: cs.CV

TL;DR: Visual-TableQA是一个大规模开放域多模态数据集，包含2.5k个LaTeX渲染表格和6k个推理密集型QA对，用于评估和增强视觉语言模型在表格数据上的视觉推理能力。

- Motivation: 当前基准测试在规模、多样性和推理深度方面存在局限，特别是在渲染表格图像方面，需要构建更全面的视觉表格推理评估数据集。
- Method: 采用模块化、可扩展的全自动生成流水线，使用多个推理LLM在生成、验证和启发三个角色上协作，通过跨模型提示和LLM评审过滤实现多模型协作数据生成。
- Result: 实验结果表明，在Visual-TableQA上微调的模型能够稳健地泛化到外部基准测试，优于多个专有模型，尽管数据集是合成的。
- Conclusion: Visual-TableQA填补了视觉表格推理评估的空白，提供了一个低成本、高质量的数据集生成框架，促进了多模态表格理解研究的发展。


### [72] [Mini-o3: Scaling Up Reasoning Patterns and Interaction Turns for Visual Search](https://arxiv.org/abs/2509.07969)
*Xin Lai,Junyi Li,Wei Li,Tao Liu,Tianjian Li,Hengshuang Zhao*

Main category: cs.CV

TL;DR: Mini-o3是一个多模态模型系统，通过大规模工具交互和深度多轮推理（可达数十步）来解决复杂视觉搜索任务，在有限的训练轮次下实现了推理时的可扩展性。

- Motivation: 现有开源多模态模型存在推理模式单调、交互轮次有限的问题，无法处理需要试错探索的困难视觉任务。
- Method: 构建Visual Probe数据集、开发迭代数据收集管道获取多样化推理轨迹、提出超轮次掩码策略平衡训练效率和测试可扩展性。
- Result: 模型在仅6轮训练限制下，推理时可自然扩展到数十轮，准确率随轮次增加而提升，在挑战性视觉搜索任务上达到state-of-the-art性能。
- Conclusion: Mini-o3能够产生丰富的推理模式和深度思考路径，有效解决复杂视觉搜索问题，展示了深度多轮推理在视觉任务中的重要性。


### [73] [One View, Many Worlds: Single-Image to 3D Object Meets Generative Domain Randomization for One-Shot 6D Pose Estimation](https://arxiv.org/abs/2509.07978)
*Zheng Geng,Nan Wang,Shaocong Xu,Chongjie Ye,Bohan Li,Zhaoxi Chen,Sida Peng,Hao Zhao*

Main category: cs.CV

TL;DR: OnePoseViaGen是一个用于从单张参考图像估计任意未见物体6D位姿的先进方法，通过粗到精的对齐模块和文本引导的生成域随机化策略，在多个基准测试中达到最先进性能。

- Motivation: 解决机器人操作中从单张参考图像估计任意未见物体6D位姿的挑战，包括3D模型稀缺、单视图重建缺乏度量尺度以及生成模型与真实图像之间的域差距问题。
- Method: 提出包含两个关键组件的流程：1）粗到精对齐模块，通过多视图特征匹配和渲染比较细化联合优化尺度和位姿；2）文本引导生成域随机化策略，多样化纹理以有效微调位姿估计器。
- Result: 在YCBInEOAT、Toyota-Light、LM-O等挑战性基准测试中达到最先进性能，远超先前方法，并在真实机器人手上展示了稳健的灵巧抓取能力。
- Conclusion: 该方法通过高保真单视图3D生成支持可靠的一次性6D位姿估计，验证了在真实世界操作中的实用性。


### [74] [Visual Representation Alignment for Multimodal Large Language Models](https://arxiv.org/abs/2509.07979)
*Heeji Yoon,Jaewoo Jung,Junwan Kim,Hyungyu Choi,Heeseong Shin,Sangbeom Lim,Honggyu An,Chaehyun Kim,Jisang Han,Donghyun Kim,Chanho Eom,Sunghwan Hong,Seungryong Kim*

Main category: cs.CV

TL;DR: VIRAL通过视觉表示对齐策略，将MLLMs的内部视觉表示与预训练视觉基础模型对齐，解决了MLLMs在视觉中心任务中的性能限制问题。

- Motivation: 现有的多模态大语言模型在视觉中心任务（如目标计数、空间推理）上表现有限，主要原因是文本监督范式只能提供视觉通路的间接指导，导致模型在训练过程中丢失细粒度视觉细节。
- Method: 提出VIRAL（视觉表示对齐）正则化策略，将MLLMs的内部视觉表示与预训练视觉基础模型（VFMs）的表示进行显式对齐，使模型既能保留输入视觉编码器的关键视觉细节，又能补充VFMs的额外视觉知识。
- Result: 实验表明该方法在广泛采用的多模态基准测试的所有任务上都取得了持续改进，并通过全面的消融研究验证了关键设计选择。
- Conclusion: 这一简单发现为在MLLMs训练中有效整合视觉信息开辟了重要方向。
## cs.HC

### [75] [Enhancing Online Learning by Integrating Biosensors and Multimodal Learning Analytics for Detecting and Predicting Student Behavior: A Review](https://arxiv.org/abs/2509.07742)
*Alvaro Becerra,Ruth Cobos,Charles Lang*

Main category: cs.HC

TL;DR: 系统综述探讨生物传感器和多模态学习分析在计算机学习环境中预测学生行为的应用，分析了54项研究的方法、挑战和发展趋势。

- Motivation: 现代在线学习需要深入理解学生行为以提升参与度和优化教育成果，生物传感器和多模态数据分析为此提供了新的技术途径。
- Method: 通过系统综述54项关键研究，分析生理信号（心率、脑电、眼动追踪）与传统交互数据、自我报告的多模态融合方法，使用机器学习算法和数据预处理技术。
- Result: 研究发现多模态数据整合能够更深入洞察学生的认知状态和参与水平，为个性化学习体验、实时反馈和智能教育干预提供支持。
- Conclusion: 生物传感器驱动的自适应学习系统具有变革性潜力，多模态数据整合将推动在线学习向更加个性化和自适应的方向发展。
## cs.GR

### [76] [SVGauge: Towards Human-Aligned Evaluation for SVG Generation](https://arxiv.org/abs/2509.07127)
*Leonardo Zini,Elia Frigieri,Sebastiano Aloscari,Marcello Generali,Lorenzo Dodi,Robert Dosen,Lorenzo Baraldi*

Main category: cs.GR

TL;DR: SVGauge是第一个针对文本到SVG生成的人类对齐参考指标，通过联合测量视觉保真度和语义一致性，在SVG评估中达到最高的人类判断相关性。

- Motivation: 现有的图像评估指标（如FID、LPIPS、CLIPScore）无法满足SVG图像的符号化和矢量特性需求，需要专门针对SVG的评估标准。
- Method: SVGauge联合测量：(1)视觉保真度：通过提取SigLIP图像嵌入，使用PCA和白化进行域对齐；(2)语义一致性：在SBERT和TF-IDF组合空间中比较BLIP-2生成的SVG标题与原始提示。
- Result: 在SHE基准测试中，SVGauge获得了最高的人类判断相关性，比现有指标更准确地复现了八个零样本LLM生成器的系统级排名。
- Conclusion: 研究强调了矢量特定评估的必要性，并为未来文本到SVG生成模型的基准测试提供了实用工具。


### [77] [Neural Cone Radiosity for Interactive Global Illumination with Glossy Materials](https://arxiv.org/abs/2509.07522)
*Jierui Ren,Haojie Jin,Bo Pang,Yisong Chen,Guoping Wang,Sheng Li*

Main category: cs.GR

TL;DR: 通过反射感知的光线锥编码改进神经热辐射方法，高效渲染高频激光材质的观点依赖辐射分布

- Motivation: 现有神经热辐射方法主要依靠位置特征编码，在模拟高频率、强视点依赖的辐射分布时存在显著限制
- Method: 提出神经锥热辐射方法，采用预筛波的多分辨率哈希网格近似激光BSDF缘，通过连续空间聚合将观点依赖反射特性嵌入编码过程
- Result: 方法显著提升了网络模拟高频反射分布的能力，能够处理从高光泽到低光泽的各种表面，减轻了网络拟合复杂辐射分布的负担
- Conclusion: 综合实验结果证明，该方法在各种光泽条件下都能实时生成高质量、无噪声的渲染结果，与基线方法相比具有更高的保真度和现实感
## cs.SD

### [78] [Adversarial Attacks on Audio Deepfake Detection: A Benchmark and Comparative Study](https://arxiv.org/abs/2509.07132)
*Kutub Uddin,Muhammad Umar Farooq,Awais Khan,Khalid Mahmood Malik*

Main category: cs.SD

TL;DR: 这篇论文评估了当前最先进的音频深度伪造检测方法，分析了它们在反司法攻击下的脏强性，为开发更稳健的检测器提供指导。

- Motivation: 随着生成式AI的普及，高保真度的深度伪造音频对语音识别等应用构成了严重威胁，而反司法攻击还能隐藏生成式签名，很多检测方法效果大打折扣。
- Method: 对五个深度伪造标准数据集进行了涉广法评估，从原始音频和谱图基于两种方法分类测试，测试包括统计修改和优化攻击等多种反司法攻击技术。
- Result: 识别了当前最先进检测方法的脏强性和弱点，揭示了它们在应对多样化反司法攻击时的性能差异。
- Conclusion: 这份分析不仅揭示了检测方法的脏强性，还为设计更稳健、通用性更强的检测器提供了指导，并将推动未来发展适应性防御策略。


### [79] [Spectral and Rhythm Feature Performance Evaluation for Category and Class Level Audio Classification with Deep Convolutional Neural Networks](https://arxiv.org/abs/2509.07756)
*Friedrich Wolf-Monheim*

Main category: cs.SD

TL;DR: 这篇论文研究了多种谱和节奏特征在深度卷积神经网络音频分类中的性能对比，发现Mel标度谱图和MFCC特征表现最优

- Motivation: 识别哪些谱和节奏特征在深度卷积神经网络音频分类任务中表现最好，以提高分类准确性
- Method: 使用ESC-50数据集（2,000个标签环境音频录音），构建端到端深度学习流水线，对比多种谱和节奏特征包括Mel标度谱图、MFCC、循环节奏图、STFT音阶图、CQT音阶图和CENS音阶图
- Result: 多类分类评估指标（准确率、精度、召回率、F1分数）显示Mel标度谱图和MFCC特征的表现显著优于其他谱和节奏特征
- Conclusion: 在深度卷积神经网络音频分类任务中，Mel标度谱图和MFCC是最有效的特征提取方法，建议在实际应用中优先采用
## stat.ML

### [80] [Kernel VICReg for Self-Supervised Learning in Reproducing Kernel Hilbert Space](https://arxiv.org/abs/2509.07289)
*M. Hadi Sepanj,Benyamin Ghojogh,Paul Fieguth*

Main category: stat.ML

TL;DR: 提出了Kernel VICReg方法，将自监督学习的VICReg目标核化到再生核希尔伯特空间中，实现非线性特征学习，在多个数据集上优于欧几里得版本的VICReg。

- Motivation: 现有的自监督学习方法主要在欧几里得空间中操作，限制了其捕捉非线性依赖和几何结构的能力。需要将自监督学习目标扩展到非线性空间。
- Method: 通过将VICReg损失函数中的方差、不变性和协方差项核化，在再生核希尔伯特空间中使用双中心核矩阵和希尔伯特-施密特范数进行操作，无需显式映射即可实现非线性特征学习。
- Result: 在MNIST、CIFAR-10、STL-10、TinyImageNet和ImageNet100等数据集上均取得一致性能提升，特别是在非线性结构明显的数据集上改进显著。UMAP可视化显示核化嵌入具有更好的等距性和类别分离性。
- Conclusion: 将自监督学习目标核化是连接经典核方法和现代表示学习的有前景方向，能够避免表示崩溃并在复杂或小规模数据任务中提升性能。
## eess.SY

### [81] [A smart fridge with AI-enabled food computing](https://arxiv.org/abs/2509.07400)
*Khue Nong Thuc,Khoa Tran Nguyen Anh,Tai Nguyen Huy,Du Nguyen Hao Hong,Khanh Dinh Ba*

Main category: eess.SY

TL;DR: 基于ESP32-CAM的智能冰箱系统，通过计算机视觉和物联网技术实现食物检测、库存追踪和温度监控，采用改进的focal loss解决高密度库存条件下的检测挑战。

- Motivation: 解决智能家居中食物管理效率问题，特别是在高密度库存条件下物品重叠和遮挡导致的检测困难，旨在减少食物浪费并优化家庭消费。
- Method: 系统分为三个核心模块：数据预处理、物体检测管理和基于Web的可视化。采用改进的focal loss变体，通过温度缩放实现自适应类别误差校准，解决模型过度自信预测问题。
- Result: 鲁棒的功能校准显著提高了在不同光照条件和可扩展性挑战下的检测可靠性，系统表现出更好的多类别分类性能。
- Conclusion: 该系统为现代食物管理提供了实用、以用户为中心的方法，通过减少浪费和更明智的消费推进可持续生活目标，在智能家居领域具有重要应用价值。
## cs.LG

### [82] [Benchmarking Vision Transformers and CNNs for Thermal Photovoltaic Fault Detection with Explainable AI Validation](https://arxiv.org/abs/2509.07039)
*Serra Aksoy*

Main category: cs.LG

TL;DR: 这篇论文系统比较了CNN和Vision Transformer在光伏热故障检测中的性能，通过XRAI显性分析验证模型决策与热物理原理的一致性，为AI在能源监测中的可解释性提供了方法论基础。

- Motivation: 解决人工智能在光伏监测中遇到的可解释性障碍，随着深度学习在热故障检测中趋于高准确性，但模型决策是否符合热物理原理仍缺乏验证，导致在需要理解模型思维过程的能源基础设施中部署犹豫。
- Method: 使用XRAI显性分析对卷积神经网络(ResNet-18, EfficientNet-B0)和视觉Transformer(ViT-Tiny, Swin-Tiny)进行系统比较，评估其在2万张红外图像(正常运行和11种故障类别)上的热物理原理对齐性。
- Result: Swin Transformer达到最高性能(94%二元准确率；73%多类别准确率)，XRAI分析显示模型学习到了物理意义特征(如局部热点、线性热路径等)。但故障检测性能差异显著：电气故障(F1分数>0.90)表现优异，而环境因素(如污染)F1分数仅0.20-0.33。
- Conclusion: 热物理导向的可解释性方法为验证AI在能源监测中的决策提供了方法论支撑，有助于充分解决可再生能源基础设施中的部署障碍。


### [83] [GCond: Gradient Conflict Resolution via Accumulation-based Stabilization for Large-Scale Multi-Task Learning](https://arxiv.org/abs/2509.07252)
*Evgeny Alves Limarenko,Anastasiia Alexandrovna Studenikina*

Main category: cs.LG

TL;DR: GCond是一种基于PCGrad原理的多任务学习梯度冲突解决方法，通过梯度累积和自适应仲裁机制实现计算加速，在保持优化质量的同时获得两倍速度提升。

- Motivation: 现有梯度冲突解决方法(如PCGrad、CAGrad、GradNorm)计算成本高，限制了其在大模型和transformer中的应用，需要开发更高效的方法。
- Method: 结合PCGrad原理与梯度累积和自适应仲裁机制，构建Gradient Conductor (GCond)方法，支持随机模式实现计算加速。
- Result: 在ImageNet 1K和头颈CT数据集上，GCond在所有评估指标上表现优异，L1和SSIM损失更低，成功应用于从紧凑模型到大型架构的各种规模模型。
- Conclusion: GCond为多任务学习中的梯度冲突问题提供了可扩展且高效的解决方案，与现代优化器兼容性好。


### [84] [EfficientNet in Digital Twin-based Cardiac Arrest Prediction and Analysis](https://arxiv.org/abs/2509.07388)
*Qasim Zia,Avais Jan,Zafar Iqbal,Muhammad Mumtaz Ali,Mukarram Ali,Murray Patterson*

Main category: cs.LG

TL;DR: 基于EfficientNet深度学习模型与数字双生系统的新框架，用于心脏停搏的早期检测和分析

- Motivation: 心脏停搏是全球重大健康问题，早期识别和管理对改善患者预后至关重要
- Method: 结合EfficientNet深度学习模型和数字双生系统，使用复合缩放技术学习心血管图像特征，通过IoT设备获取数据构建个体化心血管模型
- Result: 实验结果显示系统预测准确性高且效率良好
- Conclusion: 深度学习与数字双生技术的结合为心脏疾病预测提供了主动个体化的新方法
## eess.IV

### [85] [Evaluation of Machine Learning Reconstruction Techniques for Accelerated Brain MRI Scans](https://arxiv.org/abs/2509.07193)
*Jonathan I. Mandel,Shivaprakash Hiremath,Hedyeh Keshtgar,Timothy Scholl,Sadegh Raeisi*

Main category: eess.IV

TL;DR: 深度学习MRI重建算法DeepFoqus-Accelerate可以在4倍加速下保持脑部MRI诊断质量，扩展公共和临床数据集验证

- Motivation: 解决MRI扫描时间过长问题，通过深度学习重建算法实现高倍数加速而不丢失诊断质量
- Method: 使用DeepFoqus-Accelerate算法重建4倍相位编码下采样的2D/3D T1、T2和FLAIR序列，包括18名健康志愿者和fastMRI公共数据集，通过专业评分和数据质量指标进行评估
- Result: 95%的AI重建扫描评分≥4分，平均SSIM 0.95±0.03，PSNR >41.0 dB，HaarPSI >0.94，罕见人工产物且不影响诊断
- Conclusion: DeepFoqus-Accelerate能够实现稳健的4倍脑部MRI加速，扫描时间减少75%，同时保持诊断图像质量和改善工作流效率


### [86] [Enhanced SegNet with Integrated Grad-CAM for Interpretable Retinal Layer Segmentation in OCT Images](https://arxiv.org/abs/2509.07795)
*S M Asiful Islam Saky,Ugyen Tshering*

Main category: eess.IV

TL;DR: 改进SegNet框架用于视网膜层自动分割，结合混合损失函数和Grad-CAM可解释性，在Duke OCT数据集上达到95.77%准确度

- Motivation: 手工视网膜层分割耗时且变异性高，传统深度学习模型缺乏可解释性，需要既准确又可解释的自动化分割方案
- Method: 改进SegNet框架，包括修改池化策略、混合切片损失和切片Dice损失函数，集成Grad-CAM提供视觉解释
- Result: 在Duke OCT数据集上达到95.77%验证准确度，Dice系数0.9446，IoU指0.8951，类别结果表现稳健，Grad-CAM可视化显示解剖学相关区域
- Conclusion: 该方案结合了准确性和可解释性，为标准化OCT分析、提高诊断效率和建立临床对AI工具的信任提供了强大潜力
## physics.ao-ph

### [87] [Understanding Ice Crystal Habit Diversity with Self-Supervised Learning](https://arxiv.org/abs/2509.07688)
*Joseph Ko,Hariprasath Govindarajan,Fredrik Lindsten,Vanessa Przybylo,Kara Sulia,Marcus van Lier-Walqui,Kara Lamb*

Main category: physics.ao-ph

TL;DR: 使用自盛盛学习技术学习冰晶形态表征，通过视觉Transformer预训练处理云粒子图像，提高冰晶形态多样性定量分析能力

- Motivation: 含冰云层对气候有重要影响，但冰晶形状的多样性使得模型建立困难，需要更好的表征学习方法来描述冰晶形态
- Method: 采用自盛盛学习(SSL)方法，使用视觉Transformer模型进行预训练，从大量云粒子图像中学习冰晶形态的潜在表征
- Result: 验证了SSL方法能够学习到有意义的表征，并成功实现了冰晶多样性定量分析的应用案例
- Conclusion: 自盛盛学习驱动的表征学习方法能够显著改善冰晶特征化的描述，为明确冰晶在地球气候系统中的作用提供了更好的约束条件
## cs.RO

### [88] [DepthVision: Robust Vision-Language Understanding through GAN-Based LiDAR-to-RGB Synthesis](https://arxiv.org/abs/2509.07463)
*Sven Kirchner,Nils Purschke,Ross Greer,Alois C. Knoll*

Main category: cs.RO

TL;DR: DepthVision是一个多模态场景理解框架，通过LiDAR点云生成RGB图像并与真实RGB数据融合，提升在视觉输入退化条件下的机器人操作可靠性。

- Motivation: 解决机器人视觉输入退化（如黑暗、运动模糊）时的可靠操作问题，现有视觉语言模型仅使用相机视觉输入，无法应对传感器退化情况。
- Method: 使用条件生成对抗网络（GAN）从稀疏LiDAR点云合成RGB图像，通过亮度感知模态适应（LAMA）动态融合合成视图和真实RGB数据，无需微调下游视觉语言模型。
- Result: 在真实和模拟数据集上的评估显示，DepthVision在低光照条件下显著提升性能，相比仅使用RGB的基线有实质性改进，同时保持与冻结VLMs的兼容性。
- Conclusion: LiDAR引导的RGB合成方法在现实环境中具有实现鲁棒机器人操作的潜力，能够补偿传感器退化而不影响下游模型性能。


### [89] [Can SSD-Mamba2 Unlock Reinforcement Learning for End-to-End Motion Control?](https://arxiv.org/abs/2509.07593)
*Gavin Tao,Yinuo Wang,Jinzhao Zhou*

Main category: cs.RO

TL;DR: 提出了基于SSD-Mamba2的视觉驱动跨模态强化学习框架，用于端到端运动控制，在计算效率和性能方面超越现有方法

- Motivation: 现有端到端运动控制方法存在计算内存权衡不佳、长时程信用分配困难、Transformer二次计算成本高等问题，需要更高效的融合架构
- Method: 使用SSD-Mamba2选择性状态空间骨干网络，结合循环和卷积扫描，对本体感知和外部感知观察进行紧凑编码和融合，采用课程学习和状态中心奖励函数
- Result: 在多样化运动控制场景中，在回报、安全性、样本效率方面超越强基线方法，收敛更快且计算预算相同
- Conclusion: SSD-Mamba2为可扩展、有前瞻性和高效的端到端运动控制提供了实用的融合骨干网络
