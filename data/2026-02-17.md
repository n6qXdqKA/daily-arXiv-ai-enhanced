[[toc]]

## cs.CV

### [1] [Beyond Ground: Map-Free LiDAR Relocalization for UAVs](https://arxiv.org/abs/2602.13267)
*Hengyu Mu,Jianshi Wu,Yuxin Guo,XianLian Lin,Qingyong Hu,Chenglu Wen,Cheng Wang*

Main category: cs.CV

TL;DR: MAILS是一个针对无人机的无地图LiDAR重定位框架，通过局部保持滑动窗口注意力、坐标无关特征初始化和局部不变位置编码，解决了现有方法在无人机场景下精度下降的问题，并构建了专门的无人机LiDAR定位数据集。

- Motivation: 现有LiDAR重定位方法主要针对自动驾驶场景，在无人机应用中精度显著下降。无人机飞行具有大角度偏航旋转和高度变化等特点，现有方法无法有效处理。同时缺乏真实反映无人机飞行特性的数据集。
- Method: 1. 局部保持滑动窗口注意力模块：从稀疏点云中提取局部判别性几何特征
2. 坐标无关特征初始化模块：处理无人机的大偏航旋转
3. 局部不变位置编码机制：处理高度变化
4. 构建大规模无人机LiDAR定位数据集：包含四个场景和多种飞行轨迹
- Result: 实验表明MAILS方法实现了满意的定位精度，并显著优于现有技术。代码和数据集将公开发布。
- Conclusion: MAILS框架有效解决了无人机LiDAR重定位问题，通过专门设计的特征提取模块和真实场景数据集，显著提升了无人机在弱GNSS信号环境下的定位性能。


### [2] [Explanatory Interactive Machine Learning for Bias Mitigation in Visual Gender Classification](https://arxiv.org/abs/2602.13286)
*Nathanya Satriani,Djordje Slijepčević,Markus Schedl,Matthias Zeppelzauer*

Main category: cs.CV

TL;DR: XIL方法通过用户对模型解释的反馈来引导训练，能有效减少视觉分类器中的偏见和虚假相关性，特别是在性别分类任务中。CAIPI、RRR及其混合方法都能提升模型对相关特征的关注并降低偏见，其中CAIPI表现最佳，甚至可能提高分类准确率。

- Motivation: 研究动机是探索解释性交互学习(XIL)在缓解机器学习模型偏见和虚假相关性方面的能力，特别是在容易产生数据偏见的场景如性别分类中。传统模型可能依赖虚假特征进行预测，XIL通过用户反馈引导模型关注人类认为相关的特征。
- Method: 研究比较了三种XIL策略：1) CAIPI方法；2) Right for the Right Reasons (RRR)方法；3) 结合两者的新型混合方法。使用GradCAM和Bounded Logit Attention (BLA)生成解释，通过比较分割掩码来定量评估结果。
- Result: 实验结果显示：1) XIL方法能有效引导模型关注相关图像特征，CAIPI表现最佳；2) 能减少模型偏见，平衡男性和女性预测的误分类率；3) CAIPI有潜力提高分类准确率，而其他方法在提升透明度和公平性的同时会导致轻微性能下降。
- Conclusion: XIL方法通过用户对解释的反馈，不仅能提高模型透明度，还能有效改善性别分类器的公平性。CAIPI方法尤其有前景，能在减少偏见的同时维持甚至提升分类性能，为构建更公平、更可靠的机器学习系统提供了有效途径。


### [3] [COOPERTRIM: Adaptive Data Selection for Uncertainty-Aware Cooperative Perception](https://arxiv.org/abs/2602.13287)
*Shilpa Mukhopadhyay,Amit Roy-Chowdhury,Hang Qiu*

Main category: cs.CV

TL;DR: COOPERTRIM：一种自适应特征选择框架，利用时间连续性识别环境动态特征，减少静态信息重复传输，显著降低协同感知带宽需求

- Motivation: 协同感知中有限通信带宽与丰富传感器信息之间的矛盾阻碍了实际部署。现有方法虽然选择部分特征共享，但带宽需求仍然对当前无线技术构成压力。
- Method: 提出COOPERTRIM自适应选择框架：1）引入符合时间不确定性度量来评估特征相关性；2）采用数据驱动机制动态确定共享数量；3）利用时间连续性识别环境动态特征，避免静态信息重复传输。
- Result: 在语义分割和3D检测任务中，COOPERTRIM分别实现高达80.28%和72.52%的带宽减少，同时保持可比精度。相比其他选择策略，IoU提升高达45.54%，带宽减少达72%。结合压缩策略，带宽使用可降至1.46%而不影响IoU性能。
- Conclusion: COOPERTRIM能够优雅适应环境动态、定位误差和通信延迟，展示了灵活性，为实际部署铺平了道路。通过利用时间连续性，从根本上缓解了带宽与信息丰富度之间的矛盾。


### [4] [Evaluating the Impact of Post-Training Quantization on Reliable VQA with Multimodal LLMs](https://arxiv.org/abs/2602.13289)
*Paul Jonas Kurz,Tobias Jan Wieczorek,Mohamed A. Abdelsalam,Rahaf Aljundi,Marcus Rohrbach*

Main category: cs.CV

TL;DR: 量化压缩会降低MLLM的准确性和可靠性，但数据感知量化方法能缓解此影响，结合Selector置信度估计器可在保持效率的同时提升可靠性。

- Motivation: 当前MLLM存在过度自信问题（输出高度确定但错误的答案），同时模型尺寸过大限制了边缘设备部署。需要研究量化压缩如何影响MLLM的准确性和可靠性，并寻找缓解可靠性下降的方法。
- Method: 研究后训练量化（PTQ）对视觉问答（VQA）中MLLM准确性和可靠性的影响。评估Qwen2-VL-7B和Idefics3-8B模型，使用数据无关（HQQ）和数据感知（MBQ）量化方法在不同比特宽度下测试。为应对量化导致的可靠性下降，将Selector置信度估计器适配到量化多模态设置中，并在不同量化级别和分布外（OOD）场景测试其鲁棒性。
- Result: PTQ会同时降低准确性和可靠性；数据感知量化方法能缓解这种影响；Selector能显著减轻可靠性影响；int4 MBQ量化结合Selector实现了最佳效率-可靠性权衡，接近未压缩性能的同时减少约75%内存需求。
- Conclusion: 这是首个系统研究量化与多模态设置中可靠性关联的工作，展示了通过数据感知量化和置信度估计器的组合，可以在保持效率的同时维持可靠性，为边缘设备部署MLLM提供了实用解决方案。


### [5] [NutVLM: A Self-Adaptive Defense Framework against Full-Dimension Attacks for Vision Language Models in Autonomous Driving](https://arxiv.org/abs/2602.13293)
*Xiaoxu Peng,Dong Zhou,Jianwen Zhang,Guanghui Sun,Anh Tu Ngo,Anupam Chattopadhyay*

Main category: cs.CV

TL;DR: NutVLM是一个针对自动驾驶中视觉语言模型的全面自适应防御框架，通过NutNet++三路分类检测威胁，结合灰度掩码和专家引导的对抗提示调优来保护感知-决策全流程，在Dolphins基准上实现4.89%的整体性能提升。

- Motivation: 视觉语言模型在自动驾驶中面临从局部物理补丁到全局不可察觉扰动的对抗威胁，现有防御方法有限且难以平衡鲁棒性与干净样本性能。
- Method: 提出NutVLM框架：1) NutNet++作为哨兵，通过三路分类识别良性样本、局部补丁和全局扰动；2) 局部威胁通过高效灰度掩码净化；3) 全局扰动触发专家引导对抗提示调优，通过梯度潜空间优化和离散投影生成"纠正驾驶提示"而不需要全模型微调。
- Result: 在Dolphins基准测试中，NutVLM在准确率、语言评分和GPT评分等整体指标上实现了4.89%的提升。
- Conclusion: NutVLM为智能交通提供了一个可扩展的安全解决方案，有效保护视觉语言模型的整个感知-决策生命周期。


### [6] [VisPhyWorld: Probing Physical Reasoning via Code-Driven Video Reconstruction](https://arxiv.org/abs/2602.13294)
*Jiarong Liang,Max Ku,Ka-Hei Hui,Ping Nie,Wenhu Chen*

Main category: cs.CV

TL;DR: 提出VisPhyWorld框架，通过让多模态大语言模型生成可执行的模拟器代码来评估物理推理能力，并创建VisPhyBench基准测试

- Motivation: 现有评估多模态大语言模型物理推理能力的方法（如视觉问答和期望违背）存在缺陷，模型可能无需真正理解物理规律就能回答问题，需要更严格的评估框架
- Method: 提出VisPhyWorld执行框架，要求模型从视觉观察生成可执行的模拟器代码，从而分离物理推理与渲染；创建VisPhyBench基准，包含209个场景和系统化评估协议
- Result: 框架在基准测试上能生成97.7%的有效重建视频；实验显示当前最先进的MLLMs在语义场景理解方面表现良好，但在准确推断物理参数和模拟一致的物理动态方面存在困难
- Conclusion: VisPhyWorld提供了一种可检验、可编辑、可证伪的物理推理评估方法，揭示了MLLMs在物理推理方面的局限性，为未来研究提供了更严格的评估标准


### [7] [MFN Decomposition and Related Metrics for High-Resolution Range Profiles Generative Models](https://arxiv.org/abs/2602.13296)
*Edwyn Brient,Santiago Velasco-Forero,Rami Kassab*

Main category: cs.CV

TL;DR: 该论文提出了一种新的HRRP生成数据评估方法，通过将HRRP数据分解为掩码、特征和噪声三个组件，并基于物理解释设计两个评估指标，解决了现有基于分类模型的"黑盒"评估方法缺乏可解释性和多级评估能力的问题。

- Motivation: HRRP数据在雷达自动目标识别中应用广泛，使用生成模型填补数据集空白是当前研究热点。然而，现有HRRP生成数据的评估方法主要依赖分类模型，这些"黑盒"模型既无法解释生成数据的质量，也不能进行多级评估，存在明显局限性。
- Method: 将HRRP数据分解为三个物理组件：掩码、特征和噪声。基于这种分解，提出了两个基于数据物理解释的评估指标。使用一个昂贵的数据集在具有挑战性的任务上验证这些指标的判别能力。
- Result: 提出的两个基于物理解释的评估指标在挑战性任务上表现出良好的判别能力，能够有效评估HRRP生成数据的质量，相比现有的基于分类模型的评估方法具有更好的可解释性和多级评估能力。
- Conclusion: 通过将HRRP数据分解为掩码、特征和噪声三个物理组件，提出的评估指标为HRRP生成数据提供了具有物理可解释性的多级评估框架，解决了现有"黑盒"评估方法的局限性，为HRRP生成模型的评估提供了新思路。


### [8] [Conditional Generative Models for High-Resolution Range Profiles: Capturing Geometry-Driven Trends in a Large-Scale Maritime Dataset](https://arxiv.org/abs/2602.13297)
*Edwyn Brient,Santiago Velasco-Forero,Rami Kassab*

Main category: cs.CV

TL;DR: 该论文研究大规模海上雷达高分辨率距离像（HRRP）合成，发现几何因素（船舶尺寸和方位角）是影响HRRP的关键场景驱动因素，通过基于这些变量训练生成模型，能够复现真实数据中的几何趋势。

- Motivation: HRRP虽然能实现快速机载雷达自动目标识别处理，但其对采集条件的高度敏感性限制了在不同操作场景下的鲁棒性。现有研究受限于小型、特定数据集，需要在大规模代表性海上数据库上研究HRRP合成。
- Method: 在代表沿海监视变化性的大规模海上数据库上研究HRRP合成，识别几何因素（船舶尺寸和期望方位角）为关键场景驱动变量，基于这些变量训练生成模型。
- Result: 分析表明几何因素是HRRP的主要场景驱动因素，训练后的生成模型合成的特征能够复现实数据中观察到的视线几何趋势。
- Conclusion: 采集几何在鲁棒HRRP生成中起着核心作用，基于几何变量（船舶尺寸和方位角）的生成模型能够有效合成具有代表性的HRRP特征。


### [9] [Effect of Convolutional Depth on Image Recognition Performance: VGG vs. ResNet vs. GoogLeNet](https://arxiv.org/abs/2602.13298)
*Manfred M. Fischer,Joshua Pitts*

Main category: cs.CV

TL;DR: 深度卷积网络的有效性取决于架构机制而非名义深度，残差和Inception架构通过降低有效深度实现更好的精度-计算权衡。

- Motivation: 研究深度对卷积神经网络性能的影响，解释为什么更深网络并不总是带来更高精度、稳定优化或高效计算，需要区分名义深度和有效深度。
- Method: 对VGG、ResNet和GoogLeNet三种经典架构进行对照研究，标准化训练协议，明确区分名义深度和有效深度，分析深度如何影响分类性能、收敛行为和计算效率。
- Result: 普通深度网络出现早期精度饱和和优化不稳定，而残差和Inception架构能够将额外深度转化为更高的精度，同时保持较低的有效深度和更好的精度-计算权衡。
- Conclusion: 有效深度而非名义深度是决定深度作为卷积网络可扩展维度的关键因素，架构机制对约束训练期间的有效深度至关重要。


### [10] [KidMesh: Computational Mesh Reconstruction for Pediatric Congenital Hydronephrosis Using Deep Neural Networks](https://arxiv.org/abs/2602.13299)
*Haoran Sun,Zhanpeng Zhu,Anguo Zhang,Bo Liu,Zhaohua Lin,Liqin Huang,Mingjing Yang,Lei Liu,Shan Lin,Wangbin Ding*

Main category: cs.CV

TL;DR: KidMesh：一种基于深度神经网络的端到端方法，可直接从磁共振尿路造影图像自动重建小儿先天性肾积水网格，无需后处理即可用于尿动力学模拟。

- Motivation: 现有体素分割方法主要关注形态特征，需要进行复杂的后处理才能转换为网格表示以进行功能评估（如尿动力学模拟）。由于MRU切片稀疏采样，准确的网格级标注难以获取。
- Method: KidMesh从MRU图像提取特征图，通过网格采样转换为特征顶点，然后根据这些特征顶点变形模板网格以生成特定CH网格。开发了无需准确网格级标注的训练方案。
- Result: KidMesh平均0.4秒重建CH网格，性能与传统方法相当且无需后处理。重建网格无自相交，仅3.7%和0.2%的顶点误差超过3.2mm和6.4mm。光栅化后与手动分割掩模的Dice分数达0.86。
- Conclusion: KidMesh能高效自动重建CH网格，可直接用于肾尿流模拟，为临床实践提供有价值的尿动力学信息，解决了现有方法需要复杂后处理的问题。


### [11] [DriveMamba: Task-Centric Scalable State Space Model for Efficient End-to-End Autonomous Driving](https://arxiv.org/abs/2602.13301)
*Haisheng Su,Wei Wu,Feixiang Song,Junjie Zhang,Zhenjie Yang,Junchi Yan*

Main category: cs.CV

TL;DR: DriveMamba提出了一种任务中心化的可扩展端到端自动驾驶范式，使用统一Mamba解码器实现动态任务关系建模、隐式视图对应学习和长时序融合，相比传统顺序范式更高效灵活。

- Motivation: 当前端到端自动驾驶系统通常采用顺序范式（感知-预测-规划），基于可分离的Transformer解码器和密集BEV特征，这种手动顺序设计会导致信息损失和累积误差，缺乏模块间灵活多样的关系建模。同时，图像骨干网络训练不足和注意力机制的二次复杂度也限制了系统的可扩展性和效率。
- Method: 提出DriveMamba框架：1）将提取的图像特征和预期任务输出转换为token级稀疏表示；2）按3D空间中的实例化位置排序；3）使用线性复杂度算子进行高效长上下文序列token建模，同时捕获任务相关互依赖性；4）设计双向轨迹引导的"局部到全局"扫描方法，从自我视角保留空间局部性以促进自我规划。
- Result: 在nuScenes和Bench2Drive数据集上的广泛实验证明了DriveMamba的优越性、泛化能力和高效性。
- Conclusion: DriveMamba通过统一Mamba解码器实现了动态任务关系建模、隐式视图对应学习和长时序融合，为端到端自动驾驶提供了一种高效、可扩展的任务中心化范式，解决了传统顺序设计的信息损失和效率问题。


### [12] [Spectral Collapse in Diffusion Inversion](https://arxiv.org/abs/2602.13303)
*Nicolas Bourriez,Alexandre Verine,Auguste Genovesio*

Main category: cs.CV

TL;DR: 论文提出正交方差引导(OVG)方法，解决条件扩散反演中源域频谱稀疏时的"频谱塌缩"问题，在保持结构保真度的同时恢复逼真纹理。

- Motivation: 当源域频谱稀疏时（如超分辨率、草图转图像），标准确定性反演方法（如DDIM）会导致频谱塌缩，使恢复的潜在表示偏离各向同性高斯分布，导致生成结果过度平滑、纹理贫乏。而随机方法虽然尝试恢复噪声方差，却会破坏与输入的结构语义联系。
- Method: 提出正交方差引导(OVG)，一种推理时方法，通过修正ODE动态来在结构梯度的零空间内强制执行理论高斯噪声幅度，从而解决结构-纹理权衡问题。
- Result: 在显微镜超分辨率(BBBC021)和草图转图像(Edges2Shoes)上的广泛实验表明，OVG能有效恢复逼真纹理，同时保持结构保真度。
- Conclusion: OVG解决了条件扩散反演中的频谱塌缩问题，在源域频谱稀疏的场景下实现了结构保真度和纹理质量的平衡，为无配对图像转换提供了有效解决方案。


### [13] [Progressive Contrast Registration for High-Fidelity Bidirectional Photoacoustic Microscopy Alignment](https://arxiv.org/abs/2602.13304)
*Jiahao Qin*

Main category: cs.CV

TL;DR: 提出PCReg-Net框架，解决高速光学分辨率光声显微镜双向扫描中的域偏移和几何错位问题，通过渐进式对比引导配准实现高精度对齐

- Motivation: 高速光学分辨率光声显微镜（OR-PAM）双向扫描虽然能提高成像速度，但会引入前向和后向扫描线之间的域偏移和几何错位。现有方法受限于亮度恒定假设，对齐质量有限（NCC≤0.96）
- Method: 提出PCReg-Net，一个渐进式对比引导配准框架，包含四个轻量级模块：1）用于粗对齐的配准U-Net；2）捕获多尺度结构线索的参考特征提取器；3）通过比较粗配准特征和参考特征来识别残余错位的对比模块；4）具有特征注入功能的高保真输出细化U-Net。还提出了无参考评估指标TNCC和TNCG
- Result: 在OR-PAM-Reg-4K数据集（432个测试样本）上，PCReg-Net实现了NCC 0.983、SSIM 0.982、PSNR 46.96 dB，以实时速度超越现有技术超过14 dB
- Conclusion: PCReg-Net通过渐进式对比引导配准有效解决了高速OR-PAM双向扫描中的对齐问题，实现了高质量、实时的图像配准，为高速光声显微镜成像提供了实用解决方案


### [14] [WildfireVLM: AI-powered Analysis for Early Wildfire Detection and Risk Assessment Using Satellite Imagery](https://arxiv.org/abs/2602.13305)
*Aydin Ayanzadeh,Prakhar Dixit,Sadia Kamal,Milton Halem*

Main category: cs.CV

TL;DR: WildfireVLM：结合卫星图像野火检测与语言驱动风险评估的AI框架，用于实时大规模野火监测

- Motivation: 野火对生态系统、人类生命和基础设施的威胁日益增加，由于气候变化和人类活动，其频率和强度不断上升。卫星监测面临微弱烟雾信号、动态天气条件和需要实时分析大范围区域的挑战。
- Method: 1. 使用Landsat-8/9、GOES-16等公开地球观测数据构建标记的野火和烟雾数据集；2. 采用YOLOv12检测卫星图像中的火区和烟雾羽流；3. 集成多模态大语言模型将检测结果转化为情境化风险评估和优先响应建议；4. 使用LLM-as-judge评估方法验证风险推理质量；5. 采用面向服务的架构进行部署，支持实时处理、可视化风险仪表板和长期野火跟踪。
- Result: 开发了WildfireVLM框架，展示了计算机视觉与基于语言推理相结合在大规模野火监测中的价值。系统能够检测卫星图像中的小规模复杂模式，并提供情境化风险评估和优先响应建议。
- Conclusion: WildfireVLM框架通过结合计算机视觉检测和语言驱动风险评估，为可扩展的野火监测提供了有效解决方案，有助于改善灾害管理和应急响应。


### [15] [Fine-Tuning a Large Vision-Language Model for Artwork's Scoring and Critique](https://arxiv.org/abs/2602.13306)
*Zhehan Zhang,Meihua Qian,Li Luo,Siyu Huang,Chaoyi Zhou,Ripon Saha,Xinxin Song*

Main category: cs.CV

TL;DR: 提出一个基于Qwen2-VL-7B视觉语言模型的多任务学习框架，用于自动评估人类绘画的创造力，能同时预测分数和生成符合评分标准的反馈。

- Motivation: 艺术创造力评估对创造力研究和艺术教育至关重要，但传统的人工评分（如托兰斯创造力测验）在大规模应用时劳动强度大。现有的机器学习方法主要依赖图像特征，缺乏解释性反馈。
- Method: 使用Qwen2-VL-7B视觉语言模型进行微调，采用多任务学习。数据集包含1000幅人类创作的绘画作品（1-100分），配有简短描述。在视觉编码器输出上添加轻量级回归头，使模型能同时预测数值分数和生成符合五维评分标准（原创性、色彩、纹理、构图、内容）的反馈。
- Result: 模型在100分制上达到皮尔逊相关系数>0.97，平均绝对误差约3.95。生成的反馈与专家评语语义相似度高（平均SBERT余弦相似度=0.798）。
- Conclusion: 该方法连接了计算机视觉和艺术评估，为创造力研究和课堂反馈提供了可扩展的工具，能同时提供定量评分和解释性反馈。


### [16] [Visual Para-Thinker: Divide-and-Conquer Reasoning for Visual Comprehension](https://arxiv.org/abs/2602.13310)
*Haoran Xu,Hongyu Wang,Jiaze Li,Shunpeng Chen,Zizhao Tong,Jianzhong Ju,Zhenbo Luo,Jian Luan*

Main category: cs.CV

TL;DR: 提出首个面向多模态大语言模型的并行推理框架Visual Para-Thinker，通过视觉分区和并行注意力机制解决传统深度扩展中的探索瓶颈问题。

- Motivation: 现有LLM测试时扩展定律强调通过延长推理长度来激发自反思行为，但这种垂直扩展策略容易陷入特定思维模式的探索瓶颈。虽然并行思维通过从深度转向并行性缓解了探索范围收窄的问题，但如何将这一范式扩展到视觉领域仍是一个开放的研究问题。
- Method: 首先研究视觉分区在并行推理中的作用，提出两种不同的策略。在此基础上引入Visual Para-Thinker框架，集成并行注意力机制和LPRoPE以保持路径独立性和促进推理多样性。基于vLLM框架开发原生多模态实现，支持高效并行处理。
- Result: 在V*、CountBench、RefCOCO和HallusionBench等基准数据集上的实证结果表明，Visual Para-Thinker成功将并行推理的优势扩展到视觉领域。
- Conclusion: Visual Para-Thinker是首个用于多模态大语言模型的并行推理框架，通过视觉分区和并行处理机制有效解决了传统深度扩展中的探索瓶颈，为视觉领域的并行推理提供了新的解决方案。


### [17] [Agentic Spatio-Temporal Grounding via Collaborative Reasoning](https://arxiv.org/abs/2602.13313)
*Heng Zhao,Yew-Soon Ong,Joey Tianyi Zhou*

Main category: cs.CV

TL;DR: 提出ASTG框架，利用多模态大语言模型构建空间推理代理和时间推理代理，以无训练、开放世界的方式解决时空视频定位问题，实现自主、自引导的目标管状区域检索。

- Motivation: 现有时空视频定位方法存在计算冗余、监督需求强、泛化能力有限的问题，弱监督方法虽降低标注成本但性能较差。需要开发开放世界、无需训练的方法来解决这些挑战。
- Method: 提出ASTG框架，构建两个专门代理：空间推理代理(SRA)和时间推理代理(TRA)，基于多模态大语言模型协同工作。采用提议-评估范式，解耦时空推理，自动化管状区域提取、验证和时间定位过程，配备专用视觉记忆和对话上下文提升检索效率。
- Result: 在流行基准测试中表现出优越性，显著优于现有弱监督和零样本方法，与部分全监督方法性能相当。
- Conclusion: ASTG框架为时空视频定位任务提供了一种开放世界、无需训练的有效解决方案，通过代理协作和自主推理机制解决了现有方法的局限性。


### [18] [Sim2Radar: Toward Bridging the Radar Sim-to-Real Gap with VLM-Guided Scene Reconstruction](https://arxiv.org/abs/2602.13314)
*Emily Bejerano,Federico Tondolo,Aayan Qayyum,Xiaofan Yu,Xiaofan Jiang*

Main category: cs.CV

TL;DR: Sim2Radar：从单视图RGB图像合成毫米波雷达数据的端到端框架，通过物理仿真生成训练数据，提升雷达感知性能

- Motivation: 毫米波雷达在视觉退化环境（烟雾、灰尘、低光）中提供可靠感知，但基于学习的雷达感知受限于大规模雷达数据收集和标注的成本与稀缺性
- Method: 结合单目深度估计、分割和视觉语言推理重建材料感知的3D场景，使用基于Fresnel反射模型的物理射线追踪器模拟毫米波传播
- Result: 在真实室内场景评估中，通过合成数据预训练和真实数据微调，雷达点云物体检测模型的3D AP（IoU 0.3）提升高达+3.7，主要改进来自空间定位
- Conclusion: 基于物理的视觉驱动雷达仿真能为雷达学习提供有效的几何先验，在有限真实数据监督下显著提升性能


### [19] [IDPruner: Harmonizing Importance and Diversity in Visual Token Pruning for MLLMs](https://arxiv.org/abs/2602.13315)
*Yifan Tan,Yifu Sun,Shirui Huang,Hong Liu,Guanghua Yu,Jianchen Zhu,Yangdong Deng*

Main category: cs.CV

TL;DR: IDPruner是一种基于最大边际相关性的视觉token剪枝方法，在保持MLLM性能的同时显著减少计算量，无需注意力图且兼容FlashAttention。

- Motivation: 现有MLLM视觉token剪枝方法缺乏系统框架来平衡token重要性和语义多样性，导致性能受限。需要一种原则性的方法来优化这两个目标的权衡。
- Method: 提出IDPruner，使用最大边际相关性算法在token重要性和语义多样性之间实现帕累托最优平衡，无需注意力图，支持一次性剪枝和FlashAttention兼容部署。
- Result: 在各种模型架构和多模态基准测试中达到SOTA性能，Qwen2.5-VL-7B-Instruct在剪枝75%token时保持95.18%性能，90%极端剪枝时仍保持86.40%性能。
- Conclusion: IDPruner通过系统平衡token重要性和多样性，实现了高效且通用的MLLM加速方法，具有优异的泛化能力和部署效率。


### [20] [Diagnostic Benchmarks for Invariant Learning Dynamics: Empirical Validation of the Eidos Architecture](https://arxiv.org/abs/2602.13322)
*Datorien L. Anderson*

Main category: cs.CV

TL;DR: PSI数据集通过三个诊断测试验证了Eidos架构在拓扑不变性上的优异表现，支持"形式优先"假设

- Motivation: 现有视觉基准主要依赖纹理相关性，难以分离拓扑不变性（结构在仿射变换下的保持能力）的评估，需要专门的诊断基准
- Method: 创建PolyShapes-Ideal (PSI)数据集，包含三个诊断测试：噪声下的多边形分类、MNIST零样本字体迁移、渐进变形下的几何崩溃映射
- Result: Eidos架构在PSI上达到>99%准确率，在30种未见字体上实现81.67%零样本迁移，无需预训练
- Conclusion: 结果验证了"形式优先"假设：结构约束架构的泛化能力源于几何完整性，而非统计规模


### [21] [Synthesizing the Kill Chain: A Zero-Shot Framework for Target Verification and Tactical Reasoning on the Edge](https://arxiv.org/abs/2602.13324)
*Jesse Barkley,Abraham George,Amir Barati Farimani*

Main category: cs.CV

TL;DR: 提出分层零样本框架，结合轻量级目标检测与紧凑型视觉语言模型，用于军事边缘机器人自主部署，在合成战场视频中验证了虚假阳性过滤、损伤评估和细粒度车辆分类等任务的有效性。

- Motivation: 军事动态环境中部署自主边缘机器人面临两大挑战：领域特定训练数据稀缺和边缘硬件计算能力有限。需要开发能在有限数据下工作且适应边缘计算约束的解决方案。
- Method: 采用分层零样本框架：1) Grounding DINO作为高召回率、文本可提示的区域提议器；2) 检测置信度高的帧传递给边缘级视觉语言模型（Qwen和Gemma家族，4B-12B参数）进行语义验证；3) 扩展为侦察-指挥官智能工作流；4) 引入"受控输入"方法解耦感知与推理。
- Result: 在55个高保真合成战场视频上评估：虚假阳性过滤准确率高达100%，损伤评估达97.5%，细粒度车辆分类55-90%。侦察-指挥官工作流实现100%正确资产部署，推理得分9.8/10（GPT-4o评分），延迟低于75秒。发现不同模型的失败模式差异。
- Conclusion: 分层零样本架构适用于边缘自主系统，为安全关键应用中视觉语言模型的认证提供了诊断框架。不同规模模型在感知与推理能力上存在权衡，需要根据应用需求选择合适模型。


### [22] [MotionWeaver: Holistic 4D-Anchored Framework for Multi-Humanoid Image Animation](https://arxiv.org/abs/2602.13326)
*Xirui Hu,Yanbo Ding,Jiahao Wang,Tingting Shi,Yali Wang,Guo Zhi Zhi,Weizhan Zhang*

Main category: cs.CV

TL;DR: MotionWeaver：首个用于多人形图像动画的端到端框架，通过统一运动表示和4D锚定范式处理多样人形、复杂交互和遮挡问题

- Motivation: 现有字符图像动画方法主要局限于单人物场景，难以泛化到多人形场景，因为涉及多样人形形式、复杂交互和频繁遮挡
- Method: 1) 引入统一运动表示，提取身份无关的运动并显式绑定到对应角色；2) 提出整体4D锚定范式，构建共享4D空间融合运动表示与视频潜在特征，并通过分层4D级监督增强处理交互和遮挡
- Result: 在构建的300视频基准测试中达到最先进效果，能有效泛化到多样人形形式、复杂交互和具有挑战性的多人形场景
- Conclusion: MotionWeaver是首个端到端的多人形图像动画框架，通过创新的运动表示和4D空间建模成功解决了多人形场景中的关键挑战


### [23] [HiST-VLA: A Hierarchical Spatio-Temporal Vision-Language-Action Model for End-to-End Autonomous Driving](https://arxiv.org/abs/2602.13329)
*Yiru Wang,Zichong Gu,Yu Gao,Anqing Jiang,Zhigang Sun,Shuo Wang,Yuwen Heng,Hao Sun*

Main category: cs.CV

TL;DR: HiST-VLA是一个用于自动驾驶的分层时空视觉-语言-动作模型，通过几何感知、动态令牌稀疏化和分层规划器来提升轨迹生成的可靠性和计算效率。

- Motivation: 当前VLA模型在自动驾驶应用中存在数值推理不精确、3D空间感知弱、对上下文敏感等限制，难以在安全关键场景中可靠使用。
- Method: 1) 集成几何感知与细粒度驾驶命令和状态历史提示来增强3D时空推理；2) 采用动态令牌稀疏化融合冗余令牌而非过滤，减少计算量；3) 使用分层transformer规划器逐步细化粗粒度VLA路径点为细粒度轨迹；4) 通过动态潜在正则化整合语言命令确保空间基础和时间一致性。
- Result: 在NAVSIM v2基准测试中取得SOTA性能：Navtest上EPDMS达到88.6，伪闭环Navhard基准上EPDMS达到50.9。
- Conclusion: HiST-VLA通过分层时空架构有效解决了VLA模型在自动驾驶中的局限性，实现了可靠高效的轨迹生成，在基准测试中表现出优越性能。


### [24] [Zwitscherkasten -- DIY Audiovisual bird monitoring](https://arxiv.org/abs/2602.13330)
*Dominik Blum,Elias Häring,Fabian Jirges,Martin Schäffer,David Schick,Florian Schulenberg,Torsten Schön*

Main category: cs.CV

TL;DR: Zwitscherkasten是一个DIY多模态系统，在边缘设备上使用音频和视觉数据进行鸟类物种监测，实现实时、非侵入式监测

- Motivation: 开发一个在资源受限硬件上运行的鸟类监测系统，支持可扩展的生物多样性监测和公民科学应用
- Method: 在边缘设备上部署生物声学和图像分类深度学习模型，使用声学活动检测器降低能耗，采用细粒度检测和分类管道进行视觉识别
- Result: 在嵌入式平台上实现准确的鸟类物种识别是可行的
- Conclusion: 该系统支持可扩展的生物多样性监测和公民科学应用，为资源受限环境下的实时鸟类监测提供了有效解决方案


### [25] [MedScope: Incentivizing "Think with Videos" for Clinical Reasoning via Coarse-to-Fine Tool Calling](https://arxiv.org/abs/2602.13332)
*Wenjie Li,Yujie Zhang,Haoran Sun,Xingqi He,Hongcheng Gao,Chenglong Ma,Ming Hu,Guankun Wang,Shiyi Yao,Renhao Yang,Hongliang Ren,Lei Wang,Junjun He,Yankai Jiang*

Main category: cs.CV

TL;DR: MedScope：一种基于工具使用的临床视频推理模型，通过粗到细的证据搜索处理长视频，实现更准确、可信的预测，并在临床视频理解基准上达到SOTA性能。

- Motivation: 当前多模态大语言模型处理临床视频时通常采用被动采样或弱基础检查，限制了它们迭代定位、验证和基于时间定位证据进行预测的能力。需要解决长视频中证据定位和验证的问题。
- Method: 提出MedScope模型，通过工具使用进行临床视频推理，采用粗到细的证据搜索策略。构建ClinVideoSuite数据集，并使用Grounding-Aware Group Relative Policy Optimization (GA-GRPO)进行优化，该算法通过基础对齐奖励和证据加权优势直接强化工具使用。
- Result: 在完整和细粒度视频理解基准测试中，MedScope在领域内和领域外评估中都达到了最先进的性能。
- Conclusion: 该方法为医疗AI代理提供了一条通过工具集成推理真正"用视频思考"的路径，将发布代码、模型和数据。


### [26] [Ask the Expert: Collaborative Inference for Vision Transformers with Near-Edge Accelerators](https://arxiv.org/abs/2602.13334)
*Hao Liu,Suhaib A. Fahmy*

Main category: cs.CV

TL;DR: 提出了一种协作推理框架，在边缘设备部署轻量级通用ViT，在近边缘加速器部署多个中型专家ViT，通过路由机制动态选择专家，显著降低延迟和能耗。

- Motivation: 在边缘设备上部署视觉Transformer面临计算复杂度高的问题，而完全卸载到云端则带来显著的延迟开销，需要一种平衡边缘计算和云端计算的解决方案。
- Method: 1) 在边缘设备部署轻量级通用ViT，在近边缘加速器部署多个中型专家ViT；2) 设计路由机制，利用边缘模型的Top-k预测动态选择低置信度样本的相关专家；3) 提出渐进式专家训练策略，增强专家在数据集子集上的准确性。
- Result: 在CIFAR-100数据集上的实验表明：1) 训练策略使专家在目标子集上的准确率提升4.12%；2) 整体准确率比静态专家提升2.76%；3) 相比边缘执行，延迟降低45%；4) 相比仅近边缘卸载，能耗降低46%。
- Conclusion: 提出的协作推理框架有效解决了边缘设备上ViT部署的挑战，通过智能路由和专家训练策略，在保持准确性的同时显著降低了延迟和能耗。


### [27] [Meningioma Analysis and Diagnosis using Limited Labeled Samples](https://arxiv.org/abs/2602.13335)
*Jiamiao Lu,Wei Wu,Ke Gao,Ping Mao,Weichuan Zhang,Tuo Wang,Lingkun Ma,Jiapan Guo,Zanyi Wu,Yuqing Hu,Changming Sun*

Main category: cs.CV

TL;DR: 提出一种自适应多尺度特征融合网络（AMSF-Net），通过自适应加权融合空间域和频域特征，用于少样本脑膜瘤分类任务。

- Motivation: 脑膜瘤的生物学行为和治疗反应取决于其分级，准确诊断对治疗计划和预后评估至关重要。研究发现空间-频域特征的加权融合对脑膜瘤分类性能有显著影响，且不同图像中离散小波变换获得的特定频段贡献差异很大。
- Method: 提出一种自适应权重特征融合架构，用于少样本脑膜瘤学习。该方法自适应地融合不同频段信息和空间域信息，利用离散小波变换提取频域特征，并通过自适应权重机制优化特征融合。
- Result: 在三个数据集上的实验结果表明，该方法优于现有的最先进方法。为验证有效性，还引入了一个新的脑膜瘤MRI数据集。
- Conclusion: 提出的自适应多尺度特征融合方法在脑膜瘤分类任务中表现出优越性能，特别是在少样本学习场景下，为脑膜瘤的准确诊断提供了有效工具。


### [28] [An Integrated Causal Inference Framework for Traffic Safety Modeling with Semantic Street-View Visual Features](https://arxiv.org/abs/2602.13339)
*Lishan Sun,Yujia Cheng,Pengfei Cui,Lei Han,Mohamed Abdel-Aty,Yunhan Zheng,Xingchen Zhang*

Main category: cs.CV

TL;DR: 该研究使用街景图像和双重机器学习框架，量化了视觉环境特征（特别是绿化比例）对交通事故的因果影响，发现绿化对交通事故具有显著的负向因果效应。

- Motivation: 现有宏观交通安全模型主要依赖静态的社会人口和基础设施指标，忽视了驾驶员视觉感知环境的影响。虽然视觉环境特征已被发现影响驾驶和交通事故，但现有证据多为观察性研究，无法在复杂空间环境下建立稳健的因果关系用于交通政策评估。
- Method: 1) 对Google街景图像进行语义分割提取视觉环境特征；2) 提出双重机器学习框架量化视觉环境特征对区域事故的因果效应；3) 使用SHAP值表征模型中混杂变量的非线性影响机制；4) 应用因果森林估计条件平均处理效应；5) 基于佛罗里达州迈阿密大都市区的22万张街景图像和事故记录进行分析。
- Result: 绿化比例对交通事故具有显著且稳健的负向因果效应（平均处理效应 = -6.38，p = 0.005）。这种保护效应存在空间异质性，在人口密集和社会脆弱性高的城市核心区最为明显。绿化显著减轻了角度碰撞和追尾事故，但对弱势道路使用者的保护效果有限。
- Conclusion: 研究为绿化作为潜在安全干预措施提供了因果证据，建议优先改善危险视觉环境，同时强调需要针对弱势道路使用者进行专门的设计优化。绿化政策应针对高风险区域实施，并考虑不同事故类型的差异化保护效果。


### [29] [FireRed-Image-Edit-1.0 Techinical Report](https://arxiv.org/abs/2602.13344)
*Super Intelligence Team,Changhao Qiao,Chao Hui,Chen Li,Cunzheng Wang,Dejia Song,Jiale Zhang,Jing Li,Qiang Xiang,Runqi Wang,Shuang Sun,Wei Zhu,Xu Tang,Yao Hu,Yibo Chen,Yuhao Huang,Yuxuan Duan,Zhiyi Chen,Ziyuan Guo*

Main category: cs.CV

TL;DR: FireRed-Image-Edit是一个基于扩散变换器的指令图像编辑系统，通过数据优化、训练方法改进和评估设计，在多个基准测试中达到最先进性能。

- Motivation: 当前指令图像编辑系统在数据质量、训练效率和评估全面性方面存在不足，需要构建更系统化的解决方案来提升编辑能力和可控性。
- Method: 构建1.6B样本训练语料库，经过严格清洗和筛选保留100M高质量样本；采用多阶段训练流程（预训练、监督微调、强化学习）；引入多项创新技术包括多条件感知桶采样器、随机指令对齐、非对称梯度优化、DiffusionNFT和一致性损失。
- Result: 在REDEdit-Bench（15个编辑类别）和公共基准测试（ImgEdit和GEdit）上表现出色，与开源和专有系统相比具有竞争力或更优性能。
- Conclusion: FireRed-Image-Edit通过系统化的数据、训练和评估优化，实现了指令图像编辑的显著进步，为未来研究提供了代码、模型和基准套件。


### [30] [Visual Foresight for Robotic Stow: A Diffusion-Based World Model from Sparse Snapshots](https://arxiv.org/abs/2602.13347)
*Lijun Zhang,Nikhil Chacko,Petter Nilsson,Ruinian Xu,Shantanu Thakar,Bai Lou,Harpreet Sawhney,Zhebin Zhang,Mudit Agrawal,Bhavana Chandrashekhar,Aaron Parness*

Main category: cs.CV

TL;DR: FOREST是一个基于潜在扩散变换器的仓库存储意图预测模型，能够根据当前观察和计划存储行为预测存储箱的最终配置状态。

- Motivation: 自动化仓库执行数百万次存储操作，机器人将物品放入存储箱。在真实执行前，根据当前观察和计划存储行为预测存储箱的最终状态对系统非常有价值。
- Method: FOREST是一个存储意图条件化的世界模型，将存储箱状态表示为物品对齐的实例掩码，并使用潜在扩散变换器从观察上下文中预测存储后的配置。
- Result: 评估显示，FOREST在预测和真实存储后布局的几何一致性方面显著优于启发式基线。在下游任务中，用FOREST预测替换真实存储后掩码仅在负载质量评估和多存储推理中造成轻微性能损失。
- Conclusion: FOREST能够为仓库规划提供有用的前瞻信号，表明该模型在实际应用中具有实用价值。


### [31] [From Prompt to Production:Automating Brand-Safe Marketing Imagery with Text-to-Image Models](https://arxiv.org/abs/2602.13349)
*Parmida Atighehchian,Henry Wang,Andrei Kapustin,Boris Lerner,Tiancheng Jiang,Taylor Jensen,Negin Sokhandan*

Main category: cs.CV

TL;DR: 提出一个结合自动化和人工监督的可扩展文本到图像生成管道，用于商业产品营销图像生成，在保真度和人类偏好方面取得显著提升。

- Motivation: 文本到图像模型虽然取得了显著进展，但在生产环境中部署这些模型的可扩展管道仍然是一个挑战。需要在自动化和人工反馈之间找到平衡，以同时保持规模和质量。
- Method: 提出一个新的管道，为使用文本到图像模型生成商业产品营销图像提供完全自动化的可扩展解决方案。该系统在保持图像质量和保真度的同时，引入足够的创意变化以符合营销指南。
- Result: 使用DINOV2实现了30.77%的营销对象保真度提升，并在生成结果上获得了52.00%的人类偏好提升。
- Conclusion: 通过优化这一过程，实现了效率和人工监督的无缝结合，为商业产品营销图像生成提供了有效的解决方案。


### [32] [Detecting Brick Kiln Infrastructure at Scale: Graph, Foundation, and Remote Sensing Models for Satellite Imagery Data](https://arxiv.org/abs/2602.13350)
*Usman Nazir,Xidong Chen,Hafiz Muhammad Abubakar,Hadia Abu Bakar,Raahim Arbaz,Fezan Rasool,Bin Chen,Sara Khalid*

Main category: cs.CV

TL;DR: 利用高分辨率卫星图像检测南亚砖窑，提出ClimateGraph图模型，比较图学习、基础模型和遥感方法，为规模化监测提供指导

- Motivation: 砖窑是南亚空气污染和强迫劳动的主要来源，但大规模监测受限于稀疏过时的地面数据，需要开发基于卫星图像的规模化检测方法
- Method: 收集5个地区130万张高分辨率卫星图像，提出ClimateGraph区域自适应图模型捕捉窑炉空间和方向结构，同时评估遥感检测流程和卫星图像基础模型
- Result: 图模型、基础模型和遥感方法各有优势，提供了互补的检测能力，为卫星图像规模化砖窑监测提供实用指导
- Conclusion: 结合图学习、基础模型和遥感方法可以实现南亚砖窑的大规模监测，为解决空气污染和强迫劳动问题提供技术支持


### [33] [Using Deep Learning to Generate Semantically Correct Hindi Captions](https://arxiv.org/abs/2602.13352)
*Wasim Akram Khan,Anil Kumar Vuppala*

Main category: cs.CV

TL;DR: 该研究开发了一个将英文图像描述自动翻译成印地语的系统，使用预训练CNN提取图像特征，结合注意力机制和双向LSTM生成印地语字幕，在BLEU评分上取得良好效果。

- Motivation: 现有图像描述研究主要集中在英语，而印地语作为世界第四大语言缺乏相关研究。该研究旨在填补这一空白，为印地语用户提供自动图像描述功能。
- Method: 使用Flickr8k数据集，通过Google Cloud Translator生成印地语描述。采用VGG16、ResNet50、Inception V3等预训练CNN提取图像特征，结合注意力机制和双向LSTM进行文本编码，生成印地语字幕。
- Result: 基于注意力机制的双向LSTM与VGG16组合在BLEU-1和BLEU-4评分上分别获得0.59和0.19的最佳结果，表明系统能够生成相关且语义准确的印地语图像描述。
- Conclusion: 该研究成功实现了英文到印地语的图像描述翻译，为多语言图像描述研究提供了有效模型，可作为未来相关研究的基准。


### [34] [AdaCorrection: Adaptive Offset Cache Correction for Accurate Diffusion Transformers](https://arxiv.org/abs/2602.13357)
*Dong Liu,Yanxuan Yu,Ben Lengerich,Ying Nian Wu*

Main category: cs.CV

TL;DR: AdaCorrection是一种自适应偏移缓存校正框架，用于在扩散模型推理中高效重用Transformer层缓存，在保持高质量生成的同时减少计算开销。

- Motivation: 扩散Transformer（DiTs）在高质量图像和视频生成方面表现出色，但其迭代去噪结构导致推理成本高昂。现有加速方法通过缓存中间特征，但依赖静态重用计划或粗粒度启发式方法，常导致时间漂移和缓存不对齐，严重降低生成质量。
- Method: 提出AdaCorrection自适应偏移缓存校正框架，在每个时间步使用轻量级时空信号估计缓存有效性，并自适应混合缓存和新鲜激活。该校正无需额外监督或重新训练即可在线计算。
- Result: 在图像和视频扩散基准测试中，AdaCorrection在保持接近原始FID的同时提供适度加速，显著提升生成性能，计算开销最小。
- Conclusion: AdaCorrection通过自适应缓存校正有效解决了扩散Transformer推理加速中的质量退化问题，实现了高质量生成与计算效率的良好平衡。


### [35] [The Diffusion Duet: Harmonizing Dual Channels with Wavelet Suppression for Image Separation](https://arxiv.org/abs/2602.13361)
*Jingwei Li,Wei Pu*

Main category: cs.CV

TL;DR: 该论文提出了一种基于扩散模型的双通道盲图像分离方法DCDSM，通过小波抑制模块增强细节分离能力，在雨雪去除和复杂混合图像分离任务中取得了SOTA性能。

- Motivation: 传统盲图像分离方法基于统计独立性假设或CNN/GAN变体，难以刻画真实场景中复杂的特征分布，在强噪声和非线性混合条件下存在估计偏差、纹理失真和伪影残留等问题。需要更强大的生成模型来学习源图像特征分布并有效重建特征结构。
- Method: 创新性地将扩散模型引入双通道盲图像分离，提出DCDSM模型。利用扩散模型的强大生成能力学习源图像特征分布；在双分支反向去噪过程中设计小波抑制模块(WSM)，形成交互式分离网络，利用源图像间的互耦合噪声特性增强细节分离。
- Result: 在包含雨/雪和复杂混合的合成数据集上取得SOTA性能：1) 图像恢复任务中，雨雪去除分别获得PSNR/SSIM为35.0023 dB/0.9549和29.8108 dB/0.9243，平均优于Histoformer和LDRCNet 1.2570 dB/0.9272 dB(PSNR)和0.0262/0.0289(SSIM)；2) 复杂混合分离中，恢复的双源图像平均PSNR/SSIM为25.0049 dB/0.7997，优于对比方法4.1249 dB/0.0926。
- Conclusion: DCDSM在解决雨雪残留去除和细节保留挑战方面表现出优越性，扩散模型在盲图像分离任务中具有强大潜力，小波抑制模块有效提升了分离性能。


### [36] [An Online Reference-Free Evaluation Framework for Flowchart Image-to-Code Generation](https://arxiv.org/abs/2602.13376)
*Giang Son Nguyen,Zi Pong Lim,Sarthak Ketanbhai Modi,Yon Shin Teo,Wenya Wang*

Main category: cs.CV

TL;DR: 提出一个无需参考的评估框架，用于监控流程图图像到代码生成的质量，使用OCR召回率和视觉蕴含精确度两个指标。

- Motivation: 在生产环境中，视觉语言模型处理流程图图像生成代码时，由于缺乏真实参考代码，难以评估输出质量，需要一种无需参考的实时质量监控方法。
- Method: 提出参考无关的评估框架，包含两个自动化指标：1) Recall_OCR：通过OCR从输入图像提取文本作为代理参考，评估内容覆盖率；2) Precision_VE：通过视觉蕴含检测幻觉元素。两者的调和平均F1_OCR-VE提供统一质量分数。
- Result: 在FlowVQA数据集上验证，与真实指标有强相关性（召回率、精确度、F1的Pearson相关系数分别为0.97、0.91、0.94），证实了框架作为生产环境中连续质量监控的实用替代方案的可靠性。
- Conclusion: 该参考无关评估框架为流程图图像到代码生成系统提供了实用的质量监控方案，可在缺乏真实参考的生产环境中可靠评估输出质量。


### [37] [LAF-YOLOv10 with Partial Convolution Backbone, Attention-Guided Feature Pyramid, Auxiliary P2 Head, and Wise-IoU Loss for Small Object Detection in Drone Aerial Imagery](https://arxiv.org/abs/2602.13378)
*Sohail Ali Farooqui,Zuhair Ahmed Khan Taha,Mohammed Mudassir Uddin,Shahnawaz Alam*

Main category: cs.CV

TL;DR: LAF-YOLOv10是基于YOLOv10n改进的无人机图像小目标检测模型，通过四个互补技术模块提升检测性能，在VisDrone数据集上达到35.1% mAP，参数量仅2.3M，适合嵌入式无人机部署。

- Motivation: 当前检测器在无人机应用中面临特殊挑战：目标像素极少、背景杂乱、严重遮挡以及严格的计算资源限制。需要专门针对无人机图像的小目标检测进行优化。
- Method: 基于YOLOv10n框架集成四个互补技术：1) PC-C2f模块限制空间卷积以减少冗余计算；2) AG-FPN网络改进多尺度特征融合；3) 增加P2检测头提升小目标检测能力；4) 使用Wise-IoU v3替代CIoU以稳定边界框回归。
- Result: 在VisDrone-DET2019数据集上达到35.1±0.3% mAP@0.5，比YOLOv10n提升3.3个百分点；在UAVDT数据集上达到35.8±0.4% mAP@0.5；在NVIDIA Jetson Orin Nano上实现24.3 FPS（FP16精度）。
- Conclusion: LAF-YOLOv10通过四个互补模块的系统集成，有效解决了无人机图像小目标检测的多个瓶颈问题，在保持轻量化的同时显著提升了检测性能，适合嵌入式无人机平台部署。


### [38] [Handling Supervision Scarcity in Chest X-ray Classification: Long-Tailed and Zero-Shot Learning](https://arxiv.org/abs/2602.13430)
*Ha-Hieu Pham,Hai-Dang Nguyen,Thanh-Huy Nguyen,Min Xu,Ulas Bagci,Trung-Nghia Le,Huy-Hieu Pham*

Main category: cs.CV

TL;DR: 提出针对胸部X光长尾多标签分类和零样本OOD识别的任务特定解决方案，在CXR-LT 2026挑战赛中取得领先表现

- Motivation: 临床实践中胸部X光分类面临两个主要挑战：极端长尾多标签疾病分布，以及罕见或未见病变的标注缺失问题
- Method: 针对任务1采用不平衡感知的多标签学习策略；针对任务2提出无需OOD类监督标签或示例的零样本预测方法
- Result: 在CXR-LT 2026挑战赛开发阶段公共排行榜上排名第一，在两个任务上都取得了强劲性能
- Conclusion: 提出的任务特定解决方案能有效处理胸部X光分类中的长尾分布和零样本OOD识别问题，代码和预训练模型已开源


### [39] [Learning on the Fly: Replay-Based Continual Object Perception for Indoor Drones](https://arxiv.org/abs/2602.13440)
*Sebastian-Ion Nae,Mihai-Eugen Barbu,Sebastian Mocanu,Marius Leordeanu*

Main category: cs.CV

TL;DR: 提出室内无人机数据集并评估三种基于回放的类增量学习方法，在有限内存预算下FAR方法表现最佳

- Motivation: 室内无人机等自主代理需要实时学习新物体类别同时限制灾难性遗忘，但现有无人机数据集主要关注室外场景且缺乏时间连贯的室内视频
- Method: 引入包含14,400帧的室内无人机数据集，采用半自动标注流程；使用YOLOv11-nano作为资源高效检测器，基准测试三种基于回放的CIL策略：ER、MIR和FAR
- Result: 在5-10%回放内存预算下，FAR表现最佳，5%回放下平均准确率达82.96%；Grad-CAM分析显示混合场景中注意力转移与无人机定位质量下降相关
- Conclusion: 基于回放的持续学习可有效应用于边缘空中系统，贡献了具有时间连贯性的室内无人机视频数据集及有限回放预算下的CIL评估


### [40] [GLIMPSE : Real-Time Text Recognition and Contextual Understanding for VQA in Wearables](https://arxiv.org/abs/2602.13479)
*Akhil Ramachandran,Ankit Arun,Ashish Shenoy,Abhay Harpale,Srihari Jayakumar,Debojeet Chatterjee,Mohsen Moslehpour,Pierce Chuang,Yichao Lu,Vikas Bhardwaj,Peyman Heidari*

Main category: cs.CV

TL;DR: 提出了一种用于可穿戴设备的混合架构视频大语言模型，通过选择性高分辨率OCR和低分辨率视频流，在降低功耗的同时保持文本理解质量。

- Motivation: 可穿戴设备上部署文本视觉问答面临根本矛盾：文本识别需要高分辨率视频，但流式传输高质量视频会耗尽电池并导致热节流。现有模型在处理实时流中的多帧文本时难以保持连贯的时间上下文。
- Method: 利用文本识别和视觉推理的不对称分辨率需求，采用混合架构：在设备上执行选择性高分辨率OCR，同时流式传输低分辨率视频用于视觉上下文。
- Result: 在五个任务类别的文本VQA基准测试中，系统达到72%准确率，功耗仅为全分辨率流传输的0.49倍，能够在资源受限的可穿戴设备上实现持续的VQA会话而不牺牲文本理解质量。
- Conclusion: 通过利用视觉任务的不对称分辨率需求，提出的混合架构有效解决了可穿戴设备上文本VQA的功耗与性能平衡问题，为资源受限设备上的视频理解应用提供了实用解决方案。


### [41] [Benchmarking Video Foundation Models for Remote Parkinson's Disease Screening](https://arxiv.org/abs/2602.13507)
*Md Saiful Islam,Ekram Hossain,Abdelrahman Abdelkader,Tariq Adnan,Fazla Rabbi Mashrur,Sooyong Park,Praveen Kumar,Qasim Sudais,Natalia Chunga,Nami Shah,Jan Freyberg,Christopher Kanan,Ruth Schneider,Ehsan Hoque*

Main category: cs.CV

TL;DR: 该研究系统评估了7种视频基础模型在帕金森病筛查中的表现，使用32,847个视频数据发现不同模型在不同临床任务中表现各异，为远程神经监测提供了架构选择指导。

- Motivation: 远程视频评估为帕金森病筛查提供了可扩展途径，但不同视频基础模型架构在不同临床任务中的比较效果尚不清楚，需要进行系统性研究。
- Method: 使用来自1,888名参与者（727名帕金森患者）的32,847个视频，涵盖16个标准化临床任务，评估7种最先进的视频基础模型（VideoPrism、V-JEPA、ViViT、VideoMAE等），通过冻结嵌入和线性分类头评估模型性能。
- Result: 不同模型在不同任务中表现各异：VideoPrism在视觉语音运动学和面部表情任务中表现最佳，V-JEPA在上肢运动任务中表现最优，TimeSformer在节奏性任务（如手指敲击）中保持竞争力。AUC为76.4-85.3%，准确率为71.5-80.6%，特异性高达90.3%，但敏感性较低（43.2-57.3%）。
- Conclusion: 该研究为基于视频基础模型的帕金森病筛查建立了严格基准，提供了远程神经监测中任务和架构选择的路线图，强调需要任务感知校准和多任务多模态整合以提高敏感性。


### [42] [SpargeAttention2: Trainable Sparse Attention via Hybrid Top-k+Top-p Masking and Distillation Fine-Tuning](https://arxiv.org/abs/2602.13515)
*Jintao Zhang,Kai Jiang,Chendong Xiang,Weiqi Feng,Yuezhou Hu,Haocheng Xi,Jianfei Chen,Jun Zhu*

Main category: cs.CV

TL;DR: SpargeAttention2是一种可训练的稀疏注意力方法，通过混合掩码规则和蒸馏式微调目标，在视频扩散模型中实现95%的注意力稀疏度和16.2倍的注意力加速，同时保持生成质量。

- Motivation: 现有训练免费稀疏注意力方法虽然有效，但可训练稀疏注意力可以进一步提高稀疏度。然而，当前方法存在三个关键问题：Top-k和Top-p掩码规则的失效情况、可训练方法能达到更高稀疏度的原因、以及使用扩散损失微调稀疏注意力的局限性。
- Method: 提出SpargeAttention2方法，包含三个核心组件：(1) 结合Top-k和Top-p的混合掩码规则，在高稀疏度下实现更鲁棒的掩码；(2) 高效的可训练稀疏注意力实现；(3) 蒸馏启发的微调目标，在稀疏注意力微调过程中更好地保持生成质量。
- Result: 在视频扩散模型实验中，SpargeAttention2达到95%的注意力稀疏度和16.2倍的注意力加速，同时保持生成质量，持续优于先前的稀疏注意力方法。
- Conclusion: SpargeAttention2通过解决现有可训练稀疏注意力的关键问题，实现了高稀疏度下的高效加速，为扩散模型的加速提供了有效的可训练稀疏注意力解决方案。


### [43] [Nighttime Autonomous Driving Scene Reconstruction with Physically-Based Gaussian Splatting](https://arxiv.org/abs/2602.13549)
*Tae-Kyeong Kim,Xingxin Chen,Guile Wu,Chengjie Huang,Dongfeng Bai,Bingbing Liu*

Main category: cs.CV

TL;DR: 该论文提出了一种将基于物理的渲染集成到3D高斯泼溅中的方法，用于增强自动驾驶夜间场景重建，通过联合优化BRDF材质属性来改善低光条件下的重建质量。

- Motivation: 现有基于NeRF和3DGS的方法主要关注正常光照条件下的自动驾驶场景重建，但在夜间低光条件下，复杂的照明和外观条件导致现有方法性能下降，需要专门解决夜间场景重建的挑战。
- Method: 将基于物理的渲染集成到复合场景高斯表示中，联合优化基于BRDF的材质属性。通过全局照明模块显式建模漫反射分量，通过各向异性球面高斯建模镜面反射分量。
- Result: 在nuScenes和Waymo两个真实世界自动驾驶数据集上的广泛实验表明，该方法在定量和定性评估上都优于现有最先进方法，同时保持实时渲染能力。
- Conclusion: 该方法成功提升了室外夜间驾驶场景的重建质量，为自动驾驶模拟中的低光条件场景重建提供了有效的解决方案。


### [44] [Privacy-Concealing Cooperative Perception for BEV Scene Segmentation](https://arxiv.org/abs/2602.13555)
*Song Wang,Lingling Li,Marcus Santos,Guanghui Wang*

Main category: cs.CV

TL;DR: 提出PCC框架，通过对抗学习隐藏BEV特征中的视觉线索，防止图像重建，保护自动驾驶协同感知中的隐私

- Motivation: 自动驾驶协同感知系统通过共享感知信息提升性能，但存在隐私泄露风险，共享数据可能被重建为敏感视觉内容
- Method: 设计隐藏网络防止从共享BEV特征重建输入图像，采用对抗学习机制训练，隐藏网络与重建网络对抗，感知网络与隐藏网络集成进行端到端优化
- Result: PCC框架有效降低重建图像质量，对分割性能影响最小，为协同车辆提供隐私保护
- Conclusion: 提出的PCC框架在保持BEV语义分割性能的同时，有效保护协同感知中的视觉隐私


### [45] [Diff-Aid: Inference-time Adaptive Interaction Denoising for Rectified Text-to-Image Generation](https://arxiv.org/abs/2602.13585)
*Binglei Li,Mengping Yang,Zhiyu Tan,Junping Zhang,Hao Li*

Main category: cs.CV

TL;DR: Diff-Aid：轻量级推理时方法，通过自适应调整每个token的文本-图像交互来提升文本到图像生成的质量和语义对齐

- Motivation: 现有文本到图像扩散模型在处理复杂文本描述时存在文本和视觉特征交互不足的问题。先前方法通过架构设计或手工调整文本条件权重，但缺乏灵活性，忽视了不同transformer块和去噪阶段之间的动态交互。
- Method: 提出Diff-Aid，一种轻量级推理时方法，自适应调整每个token的文本和图像交互，跨transformer块和去噪时间步。作为即插即用模块，可无缝集成到下游应用中。
- Result: 在SD 3.5和FLUX等强基线模型上，Diff-Aid在提示遵循、视觉质量和人类偏好等各项指标上均取得一致改进，同时产生可解释的调制模式。
- Conclusion: Diff-Aid提供了一种灵活高效的解决方案，通过自适应调整文本-图像交互来提升文本到图像生成的质量和语义对齐，具有可解释性和广泛的下游应用潜力。


### [46] [Two-Stream Interactive Joint Learning of Scene Parsing and Geometric Vision Tasks](https://arxiv.org/abs/2602.13588)
*Guanfeng Tang,Hongbo Zhao,Ziwei Long,Jiayao Li,Bohong Xiao,Wei Ye,Hanli Wang,Rui Fan*

Main category: cs.CV

TL;DR: TwInS是一个受人类视觉系统启发的双流联合学习框架，可同时执行场景解析和几何视觉任务，通过双向特征交互和半监督训练实现高性能。

- Motivation: 受人类视觉系统中并行处理上下文和空间信息的双流机制启发，旨在开发一个能够同时处理场景解析和几何视觉任务的统一框架，减少对人工标注数据的依赖。
- Method: 采用统一的双流架构：场景解析流的多层次上下文特征注入几何视觉流进行迭代优化；几何特征通过跨任务适配器投影到上下文特征空间进行选择性异质特征融合；设计了半监督训练策略，利用大规模多视角数据实现自进化。
- Result: 在三个公开数据集上的广泛实验验证了TwInS核心组件的有效性，并展示了其优于现有最先进方法的性能表现。
- Conclusion: TwInS成功实现了场景解析和几何视觉任务的联合学习，通过双向特征交互和半监督训练策略，在减少人工标注依赖的同时取得了优异的性能，为多任务视觉系统提供了新的设计思路。


### [47] [AdaVBoost: Mitigating Hallucinations in LVLMs via Token-Level Adaptive Visual Attention Boosting](https://arxiv.org/abs/2602.13600)
*Jiacheng Zhang,Feng Liu,Chao Du,Tianyu Pang*

Main category: cs.CV

TL;DR: AdaVBoost：一种基于视觉基础熵的自适应视觉注意力增强框架，通过token级别的自适应干预来减少大视觉语言模型的幻觉问题。

- Motivation: 现有视觉注意力增强方法使用预定义缩放因子，但在不同生成步骤中存在权衡：缩放因子在某些步骤可能太弱无法解决幻觉，在其他步骤可能太强导致新幻觉。
- Method: 提出AdaVBoost框架，引入视觉基础熵(VGE)来估计幻觉风险，利用视觉基础作为补充信号捕捉证据不匹配。根据VGE指导，对高风险token应用更强的视觉注意力增强，对低风险token应用较弱的增强。
- Result: 在多个LVLMs和幻觉基准测试上的广泛实验表明，AdaVBoost显著优于基线方法。
- Conclusion: AdaVBoost通过token级别的自适应视觉注意力增强，有效解决了现有方法中预定义缩放因子的局限性，显著减少了大视觉语言模型的幻觉问题。


### [48] [Towards Sparse Video Understanding and Reasoning](https://arxiv.org/abs/2602.13602)
*Chenwei Xu,Zhen Ye,Shang Wu,Weijian Li,Zihan Wang,Zhuofan Xia,Lie Lu,Pranav Maneriker,Fan Du,Manling Li,Han Liu*

Main category: cs.CV

TL;DR: REVISE是一个用于视频问答的多轮代理系统，通过智能选择信息帧、维护摘要状态和提前停止机制，在减少计算成本的同时提高准确性

- Motivation: 传统视频问答系统通常均匀采样帧，计算成本高且效率低。需要一种能够智能选择关键帧、减少冗余计算，同时保持或提高准确性的方法
- Method: 1) 选择少量信息丰富的帧而非均匀采样；2) 在多轮对话中维护摘要状态；3) 当置信度高时提前停止；4) 支持专有视觉语言模型的即插即用；5) 为开源模型引入EAGER强化微调方法，包含置信度增益、摘要充分性和正确提前停止三个奖励项
- Result: 在多个视频问答基准测试中，REVISE提高了准确性，同时减少了帧数、轮次和提示词数量，实现了实用的稀疏视频推理
- Conclusion: REVISE通过智能帧选择、状态维护和提前停止机制，在视频问答中实现了效率与准确性的平衡，为稀疏视频推理提供了实用解决方案


### [49] [A generalizable foundation model for intraoperative understanding across surgical procedures](https://arxiv.org/abs/2602.13633)
*Kanggil Park,Yongjun Jeon,Soyoung Lim,Seonmin Park,Jongmin Shin,Jung Yong Kim,Sehyeon An,Jinsoo Rhu,Jongman Kim,Gyu-Seong Choi,Namkee Oh,Kyu-Hwan Jung*

Main category: cs.CV

TL;DR: ZEN是一个用于术中手术视频理解的通用基础模型，通过自监督多教师蒸馏框架训练，在20个下游任务中表现出色并具有跨手术泛化能力。

- Motivation: 微创手术中，实时视觉解读存在外科医生和手术间的显著差异，限制了评估、培训和AI系统开发。现有手术AI模型通常针对特定任务设计，缺乏跨手术和机构的泛化能力。
- Method: 使用自监督多教师蒸馏框架，在超过21种手术的400万帧视频数据上训练ZEN基础模型，构建大规模多样化数据集并系统评估多种表征学习策略。
- Result: 在20个下游任务中，无论是全微调、冻结骨干网络、少样本还是零样本设置，ZEN都优于现有手术基础模型，展现出强大的跨手术泛化能力。
- Conclusion: ZEN为手术场景理解提供了统一表征，支持未来在术中辅助和手术培训评估中的应用，是迈向通用手术视频理解的重要一步。


### [50] [Layer-Guided UAV Tracking: Enhancing Efficiency and Occlusion Robustness](https://arxiv.org/abs/2602.13636)
*Yang Zhou,Derui Ding,Ran Sun,Ying Sun,Haohua Zhang*

Main category: cs.CV

TL;DR: LGTrack是一个用于无人机视觉目标跟踪的统一框架，通过动态层选择、高效特征增强和鲁棒表示学习，在保持高精度的同时实现实时跟踪速度（258.7 FPS）

- Motivation: 无人机视觉目标跟踪需要在准确性和效率之间取得平衡，特别是在遮挡等挑战性条件下。现有方法难以同时满足高精度和实时性要求，尤其是在处理不可预测的遮挡时。
- Method: 提出LGTrack框架，包含：1) 轻量级全局分组坐标注意力模块(GGCA)，捕获长距离依赖和全局上下文；2) 轻量级相似性引导层适应模块(SGLA)，替代知识蒸馏，实现跟踪精度和推理效率的最佳平衡；3) 集成动态层选择、高效特征增强和鲁棒表示学习。
- Result: 在三个数据集上的实验表明，LGTrack在UAVDT数据集上达到258.7 FPS的实时速度，同时保持82.8%的跟踪精度，在准确性和效率方面都达到最先进水平。
- Conclusion: LGTrack通过创新的注意力机制和层适应策略，成功解决了无人机视觉目标跟踪中准确性与效率的权衡问题，特别是在遮挡条件下，实现了实时高性能跟踪。


### [51] [DCDM: Divide-and-Conquer Diffusion Models for Consistency-Preserving Video Generation](https://arxiv.org/abs/2602.13637)
*Haoyu Zhao,Yuang Zhang,Junqi Cheng,Jiaxi Gu,Zenghui Lu,Peng Shu,Zuxuan Wu,Yu-Gang Jiang*

Main category: cs.CV

TL;DR: DCDM是一个系统级框架，通过三个专用组件解决视频生成中的语义、几何和身份一致性问题，包括：1) 利用大语言模型实现片段内世界知识一致性；2) 通过噪声空间时间相机表示控制片段间相机一致性；3) 采用窗口化交叉注意力和稀疏片段间自注意力确保片段间元素一致性。

- Motivation: 当前视频生成模型虽然视觉保真度高，但在语义、几何和身份一致性方面存在不足。具体面临三个关键挑战：片段内世界知识一致性、片段间相机一致性、以及片段间元素一致性。需要系统级框架来同时解决这些多维度的一致性难题。
- Method: DCDM框架包含三个专用组件：1) 利用大语言模型解析输入提示为结构化语义表示，通过扩散变换器生成一致视频内容；2) 提出噪声空间时间相机表示实现精确稳定的相机运动控制，结合文本到图像初始化增强可控性；3) 采用整体场景生成范式，结合窗口化交叉注意力和稀疏片段间自注意力，确保长程叙事连贯性同时保持计算效率。
- Result: 在AAAI'26 CVM竞赛测试集上验证，结果表明所提出的策略能有效解决视频生成中的一致性挑战，证明了DCDM框架在提升语义、几何和身份一致性方面的有效性。
- Conclusion: DCDM通过分而治之的方法，将复杂的视频一致性建模分解为三个专门组件，同时共享统一的视频生成主干，为解决视频生成中的多维度一致性问题提供了有效的系统级解决方案。


### [52] [KorMedMCQA-V: A Multimodal Benchmark for Evaluating Vision-Language Models on the Korean Medical Licensing Examination](https://arxiv.org/abs/2602.13650)
*Byungjin Choi,Seongsu Bae,Sunjun Kweon,Edward Choi*

Main category: cs.CV

TL;DR: KorMedMCQA-V是韩国医学执照考试风格的多模态选择题基准，包含1534个问题和2043张医学图像，用于评估视觉语言模型在韩国医学领域的表现。

- Motivation: 现有医学视觉语言模型评估主要针对英文环境，缺乏针对韩国医学领域的多模态评估基准。韩国医学执照考试包含大量医学图像（如X光、CT、心电图等），需要专门的基准来评估模型在韩国医学多模态推理上的能力。
- Method: 从2012-2023年韩国医学执照考试中收集1534个问题和2043张相关图像，其中约30%包含多张图像需要跨图像证据整合。图像涵盖X光、CT、心电图、超声、内窥镜等多种医学影像。在统一零样本评估协议下，对50多个专有和开源视觉语言模型进行基准测试。
- Result: 最佳专有模型（Gemini-3.0-Pro）准确率达96.9%，最佳开源模型（Qwen3-VL-32B-Thinking）83.7%，最佳韩国专用模型（VARCO-VISION-2.0-14B）仅43.2%。推理导向模型变体比指令调优模型提升高达20个百分点，医学领域专业化对强通用基线的增益不一致，所有模型在多图像问题上表现下降，不同成像模态间性能差异显著。
- Conclusion: KorMedMCQA-V填补了韩国医学多模态评估的空白，与纯文本基准KorMedMCQA共同形成完整的韩国医学推理评估套件。研究发现推理能力对医学多模态任务至关重要，医学领域专业化不一定带来显著优势，多图像推理仍是挑战。数据集已在Hugging Face发布。


### [53] [Optimizing Point-of-Care Ultrasound Video Acquisition for Probabilistic Multi-Task Heart Failure Detection](https://arxiv.org/abs/2602.13658)
*Armin Saadat,Nima Hashemi,Bahar Khodabakhshian,Michael Y. Tsang,Christina Luong,Teresa S. M. Tsang,Purang Abolmaesumi*

Main category: cs.CV

TL;DR: 提出基于强化学习的个性化超声心动图采集策略，通过智能选择视图或终止采集来优化心衰评估，在减少32%视频采集量的情况下保持诊断性能

- Motivation: 床旁超声(POCUS)需要在有限时间和操作者精力下支持临床决策，需要开发能平衡诊断性能与采集成本的个性化数据采集策略
- Method: 将POCUS建模为顺序采集问题：强化学习代理根据部分观察的多视图研究选择下一个视图或终止采集；终止时，共享多视图transformer进行多任务推理（主动脉瓣狭窄分类和左心室射血分数回归），输出不确定性以平衡诊断收益与采集成本
- Result: 在1,820个测试研究中，方法在减少32%视频采集量的情况下匹配完整研究性能，实现77.2%的平均平衡准确率，展示了在采集预算下的稳健多任务性能
- Conclusion: 患者定制、成本感知的采集策略可以简化POCUS工作流程同时保持决策质量，产生适合床旁使用的可解释扫描路径，框架可扩展到其他心脏终点并值得进行前瞻性临床评估


### [54] [LeafNet: A Large-Scale Dataset and Comprehensive Benchmark for Foundational Vision-Language Understanding of Plant Diseases](https://arxiv.org/abs/2602.13662)
*Khang Nguyen Quoc,Phuong D. Dao,Luyl-Da Quach*

Main category: cs.CV

TL;DR: 本文介绍了LeafNet数据集和LeafBench基准测试，用于评估视觉语言模型在植物病理学任务中的表现，发现现有模型在细粒度疾病识别方面存在显著不足。

- Motivation: 尽管基础模型和视觉语言预训练技术取得了显著进展，但在农业领域特别是植物病理学任务中的应用仍然有限，主要原因是缺乏大规模、全面的多模态图像-文本数据集和基准测试。
- Method: 作者构建了包含186,000张叶片数字图像（涵盖97种疾病类别）的LeafNet数据集，并开发了包含13,950个问答对的LeafBench视觉问答基准测试，涵盖六个关键农业任务。对12个最先进的视觉语言模型进行了系统评估。
- Result: 评估结果显示：二元健康-患病分类准确率超过90%，但细粒度病原体和物种识别准确率低于65%。多模态架构相比纯视觉模型具有显著优势，经过微调的视觉语言模型优于传统视觉模型。
- Conclusion: 当前视觉语言模型在植物病理学应用中存在重要差距，LeafBench为方法学进步和进展评估提供了严谨框架，对开发可靠的AI辅助植物疾病诊断系统至关重要。


### [55] [EchoTorrent: Towards Swift, Sustained, and Streaming Multi-Modal Video Generation](https://arxiv.org/abs/2602.13669)
*Rang Meng,Weipeng Wu,Yingjie Yin,Yuming Li,Chenguang Ma*

Main category: cs.CV

TL;DR: EchoTorrent是一个用于实时多模态视频生成的创新框架，通过多教师训练、自适应CFG校准、混合长尾强制和VAE解码器优化，解决了现有模型在流式推理中的延迟、时空稳定性和唇音同步问题。

- Motivation: 当前多模态视频生成模型虽然视觉质量高，但存在严重的延迟问题和有限的时序稳定性，阻碍了实时部署。流式推理会加剧这些问题，导致空间模糊、时序漂移和唇音不同步等多模态退化，形成了未解决的效率-性能权衡问题。
- Method: 提出了四重设计：1) 多教师训练：在特定偏好领域微调预训练模型获得领域专家，顺序传递领域知识给学生模型；2) 自适应CFG校准(ACC-DMD)：通过分阶段时空调度校准DMD中的音频CFG增强误差，消除冗余CFG计算，实现每步单次推理；3) 混合长尾强制：在长时程自展开训练中通过因果-双向混合架构专门强制尾部帧对齐，缓解流式模式中的时空退化；4) VAE解码器优化：通过像素域优化VAE解码器恢复高频细节，避免潜在空间歧义。
- Result: 广泛的实验和分析表明，EchoTorrent实现了少次自回归生成，显著扩展了时序一致性、身份保持和音频-唇音同步能力。
- Conclusion: EchoTorrent通过创新的四重设计有效解决了多模态视频生成在流式推理中的效率-性能权衡问题，实现了高质量的实时视频生成，具有更好的时空稳定性和唇音同步效果。


### [56] [An Ensemble Learning Approach towards Waste Segmentation in Cluttered Environment](https://arxiv.org/abs/2602.13681)
*Maimoona Jafar,Syed Imran Ali,Ahsan Saadat,Muhammad Bilal,Shah Khalid*

Main category: cs.CV

TL;DR: 提出集成学习方法EL-4，结合U-Net和FPN模型提升垃圾分割精度，在模拟真实垃圾场景的数据集上取得IoU 0.8306的改进效果。

- Motivation: 环境污染物处理需求日益增长，回收是关键解决方案。垃圾分选是回收过程中的重要环节，需要准确的分割掩码供机器人定位和拾取。真实垃圾环境复杂，物品变形、无固定模式且相互重叠，增加了分割难度。
- Method: 采用集成学习方法，结合U-Net和FPN两种高性能分割模型，使用加权平均方法融合它们的预测结果。U-Net擅长捕捉细节和边界，FPN有效处理尺度变化和复杂环境上下文，两者结合产生更精确的预测。
- Result: 集成模型EL-4在IoU指标上达到0.8306，优于U-Net的0.8065；Dice损失降至0.09019，优于FPN的0.1183。数据集模拟真实垃圾场景，并应用预处理技术增强深度学习模型的特征学习能力。
- Conclusion: 该研究可提高材料回收设施的垃圾分选效率，以最少的人工干预促进更好的原材料获取，提升整体处理能力。集成学习方法在复杂垃圾分割任务中显示出有效性。


### [57] [A WDLoRA-Based Multimodal Generative Framework for Clinically Guided Corneal Confocal Microscopy Image Synthesis in Diabetic Neuropathy](https://arxiv.org/abs/2602.13693)
*Xin Zhang,Liangxiu Han,Yue Shi,Yalin Zheng,Uazman Alam,Maryam Ferdousi,Rayaz Malik*

Main category: cs.CV

TL;DR: 提出基于WDLoRA的多模态生成框架，用于临床引导的角膜共聚焦显微镜图像合成，解决糖尿病周围神经病变诊断中的数据稀缺问题。

- Motivation: 角膜共聚焦显微镜是评估糖尿病周围神经病变的重要工具，但深度学习诊断模型面临标记数据稀缺和神经形态细微变化的挑战。现有AI生成模型在医学图像合成中常因领域特定训练不足而缺乏解剖保真度。
- Method: 提出基于权重分解低秩适应的多模态生成框架，通过解耦幅度和方向权重更新，使基础生成模型能独立学习神经拓扑和基质对比度。联合神经分割掩码和疾病特异性临床提示作为条件输入。
- Result: 在视觉保真度（FID: 5.18）和结构完整性（SSIM: 0.630）方面达到最先进水平，显著优于GAN和标准扩散基线。合成图像保留了临床生物标志物，与真实患者数据统计等效。用于训练诊断模型时，诊断准确率提高2.1%，分割性能提高2.2%。
- Conclusion: WDLoRA框架能有效合成解剖学上一致的角膜共聚焦显微镜图像，缓解医学AI中的数据瓶颈问题，为糖尿病周围神经病变的自动化诊断提供高质量合成数据。


### [58] [Fine-tuned Vision Language Model for Localization of Parasitic Eggs in Microscopic Images](https://arxiv.org/abs/2602.13712)
*Chan Hao Sien,Hezerul Abdul Karim,Nouar AlDahoul*

Main category: cs.CV

TL;DR: 利用微调的视觉语言模型Florence定位显微镜图像中的寄生虫卵，性能优于传统目标检测方法，为自动化寄生虫诊断提供可扩展方案

- Motivation: 土壤传播蠕虫感染在热带和亚热带地区广泛流行，但传统显微镜诊断方法劳动密集、耗时且易出错，需要自动化解决方案来应对专业诊断资源有限的挑战
- Method: 使用微软Florence视觉语言模型进行微调，专门用于定位显微镜图像中的所有寄生虫卵，并与EfficientDet等传统目标检测方法进行对比
- Result: 定位VLM在性能上优于其他目标检测方法，mIOU达到0.94，显示出卓越的寄生虫卵识别和定位能力
- Conclusion: 该视觉语言模型有潜力作为自动化寄生虫诊断框架的核心组件，为智能寄生虫学诊断提供可扩展的工程解决方案


### [59] [RGA-Net: A Vision Enhancement Framework for Robotic Surgical Systems Using Reciprocal Attention Mechanisms](https://arxiv.org/abs/2602.13726)
*Quanjun Li,Weixuan Li,Han Xia,Junhua Zhou,Chi-Man Pun,Xuhang Chen*

Main category: cs.CV

TL;DR: RGA-Net：用于机器人手术烟雾去除的新型深度学习框架，通过双流混合注意力和轴分解注意力模块，在手术烟雾去除任务上取得优越性能。

- Motivation: 机器人手术系统依赖高质量视觉反馈进行精确遥操作，但能量设备产生的手术烟雾会显著降低内窥镜视频质量，损害人机界面和手术效果。
- Method: 提出RGA-Net（互惠门控和注意力融合网络），采用分层编码器-解码器架构，包含两个关键创新：1）双流混合注意力模块结合移位窗口注意力和频域处理；2）轴分解注意力模块通过分解注意力机制处理多尺度特征。这些组件通过互惠交叉门控块连接。
- Result: 在DesmokeData和LSD3K手术数据集上的广泛实验表明，RGA-Net在恢复机器人手术集成所需的视觉清晰度方面取得优越性能。
- Conclusion: 该框架通过提供持续清晰的视觉化，增强了外科医生-机器人界面，为减轻外科医生认知负担、优化手术流程和减少微创手术中的医源性损伤风险奠定了技术基础。


### [60] [Explore Intrinsic Geometry for Query-based Tiny and Oriented Object Detector with Momentum-based Bipartite Matching](https://arxiv.org/abs/2602.13728)
*Junpeng Zhang,Zewei Yang,Jie Feng,Yuhui Zheng,Ronghua Shang,Mengxuan Zhang*

Main category: cs.CV

TL;DR: IGOFormer：一种新颖的基于查询的定向目标检测器，通过显式整合内在几何特征到特征解码中，并增强阶段间匹配稳定性，显著提升航空定向目标检测性能。

- Motivation: 现有基于查询的检测器在处理任意方向目标（特别是纹理信息有限的小目标）时性能受限，主要原因是像素级特征解码中内在几何特征利用不足，以及阶段间二分匹配不一致导致的监督信号冲突。
- Method: 1. 内在几何感知解码器：通过从目标查询相关性中推断互补几何嵌入，注入几何信息来增强目标相关特征，捕获目标的几何布局和方向信息。2. 基于动量的二分匹配方案：通过使用查询特定平滑因子构建指数移动平均，自适应聚合历史匹配成本，防止阶段间匹配不一致导致的冲突监督信号。
- Result: 在DOTA-V1.0数据集上，使用Swin-T骨干网络在单尺度设置下达到78.00%的AP50分数，证明了IGOFormer在航空定向目标检测中的优越性。
- Conclusion: IGOFormer通过显式整合内在几何特征和增强阶段间匹配稳定性，有效解决了现有基于查询检测器在定向目标检测中的局限性，为航空目标检测提供了更强大的解决方案。


### [61] [Generative Latent Representations of 3D Brain MRI for Multi-Task Downstream Analysis in Down Syndrome](https://arxiv.org/abs/2602.13731)
*Jordi Malé,Juan Fortea,Mateus Rozalem-Aranha,Neus Martínez-Abadías,Xavier Sevillano*

Main category: cs.CV

TL;DR: 该研究开发了多个变分自编码器(VAE)来编码3D脑部MRI扫描，系统评估了潜在表示在重建质量、潜在空间结构和唐氏综合征分类任务中的有效性。

- Motivation: 尽管生成模型在医学影像中显示出强大潜力，但其潜在表示的结构、信息内容和临床任务适用性仍未被充分探索。研究这些表示对于推进生成模型在神经影像研究和临床决策中的应用至关重要。
- Method: 开发多个变分自编码器(VAEs)来编码3D脑部MRI扫描为紧凑的潜在空间表示，通过三个关键分析系统评估：1) MRI重建质量的定量和定性评估；2) 使用主成分分析可视化潜在空间结构；3) 在唐氏综合征与正常个体脑部MRI扫描数据集上进行下游分类任务。
- Result: VAE成功捕获了重要的脑部特征并保持了高重建保真度。潜在空间显示出清晰的聚类模式，特别是在区分唐氏综合征个体与正常对照方面。
- Conclusion: 该研究证明了VAE在脑部MRI分析中的有效性，其潜在表示不仅能够高质量重建，还能有效区分临床相关群体，为生成模型在神经影像研究和临床应用中的进一步发展提供了基础。


### [62] [T2MBench: A Benchmark for Out-of-Distribution Text-to-Motion Generation](https://arxiv.org/abs/2602.13751)
*Bin Yang,Rong Ou,Weisheng Xu,Jiaqi Xiong,Xintao Li,Taowen Wang,Luyu Zhu,Xu Jiang,Jing Tan,Renjing Xu*

Main category: cs.CV

TL;DR: 提出了一个专门用于评估文本到动作生成模型在分布外（OOD）文本条件下的基准测试，包含1025个OOD文本描述和统一的评估框架，发现现有模型在细粒度准确性评估方面表现不佳。

- Motivation: 现有文本到动作生成评估主要关注分布内文本输入和有限评估标准，无法系统评估模型在复杂分布外文本条件下的泛化能力和动作生成能力。
- Method: 构建包含1025个文本描述的OOD提示数据集，并提出统一的评估框架，整合基于LLM的评估、多因素动作评估和细粒度准确性评估。
- Result: 评估了14个代表性基线模型，发现不同模型在文本-动作语义对齐、动作泛化性和物理质量等方面各有优势，但大多数模型在细粒度准确性评估方面表现不佳。
- Conclusion: 该研究揭示了现有方法在OOD场景下的局限性，为未来生产级文本到动作模型的设计和评估提供了实用指导。


### [63] [OmniScience: A Large-scale Multi-modal Dataset for Scientific Image Understanding](https://arxiv.org/abs/2602.13758)
*Haoyi Tao,Chaozheng Huang,Nan Wang,Han Lyu,Linfeng Zhang,Guolin Ke,Xi Fang*

Main category: cs.CV

TL;DR: OmniScience是一个大规模、高质量的多模态数据集，包含150万个图-标题-上下文三元组，覆盖10多个科学领域，通过动态模型路由重标注流程提升科学图像理解能力。

- Motivation: 现有的多模态大语言模型在自然图像理解上表现良好，但在科学图像（如示意图、实验表征图、分析图表）理解上能力有限，特别是开源模型。这种差距主要源于现有数据集领域覆盖有限、结构标注粗糙、语义基础薄弱。
- Method: 开发了动态模型路由重标注流程，利用最先进的多模态大语言模型，结合视觉特征、原始图标题和文本参考文献，生成密集、自包含的描述。通过严格的质量过滤和与人类专家判断对齐来确保事实准确性和语义完整性。
- Result: 将图像-文本多模态相似度得分从0.769提升到0.956。在OmniScience上微调的Qwen2.5-VL-3B模型相比基线有显著提升，在MM-MT-Bench上获得0.378增益，在MMMU上获得0.140增益。
- Conclusion: OmniScience数据集通过高质量标注和严格的质量控制，显著提升了多模态大语言模型对科学图像的理解能力，填补了现有数据集的不足，为科学图像理解提供了重要资源。


### [64] [SAM4Dcap: Training-free Biomechanical Twin System from Monocular Video](https://arxiv.org/abs/2602.13760)
*Li Wang,HaoYu Wang,Xi Chen,ZeKun Jiang,Kang Li,Jian Li*

Main category: cs.CV

TL;DR: SAM4Dcap是一个开源框架，可从单目视频估计生物力学指标，无需额外训练，结合了4D人体网格重建与生物力学求解器。

- Motivation: 传统的定量生物力学分析通常受限于实验室环境，因为光学运动捕捉系统成本高昂。虽然多视角视频方法降低了门槛，但仍不适用于需要单目捕捉的家庭场景。
- Method: SAM4Dcap整合了SAM-Body4D的时序一致4D人体网格恢复与OpenSim生物力学求解器。该流程将重建的网格转换为与多种肌肉骨骼模型兼容的轨迹文件，并引入了自动化提示策略和Linux原生构建。
- Result: 初步评估显示，SAM4Dcap在行走和跳落任务中，膝关节运动学预测有潜力达到与多视角系统相当的水平，尽管在髋关节屈曲和残余抖动方面仍存在一些差异。
- Conclusion: 通过将先进的计算机视觉技术与成熟的生物力学模拟相结合，SAM4Dcap为非实验室运动分析提供了一个灵活、可访问的基础框架。


### [65] [Offline-Poly: A Polyhedral Framework For Offline 3D Multi-Object Tracking](https://arxiv.org/abs/2602.13772)
*Xiaoyu Li,Yitao Wu,Xian Wu,Haolin Zhuo,Lijun Zhao,Lining Sun*

Main category: cs.CV

TL;DR: Offline-Poly：基于跟踪中心设计的通用离线3D多目标跟踪方法，通过标准化TBT范式处理任意现成跟踪输出，实现离线优化的轨迹片段，在nuScenes和KITTI数据集上达到SOTA性能。

- Motivation: 现有离线3D MOT方法直接扩展在线框架，未能充分利用离线设置的优势，且依赖固定上游和定制化架构，限制了适应性。需要一种更通用的离线跟踪方法。
- Method: 提出Tracking-by-Tracking（TBT）标准化范式，仅处理任意现成跟踪输出并生成离线优化轨迹片段。Offline-Poly包含预处理、分层匹配与融合、轨迹片段优化三个模块，充分利用离线跟踪的资源无约束性和未来可观测性。
- Result: 在nuScenes上达到77.6% AMOTA的SOTA性能，在KITTI上达到83.00% HOTA的领先结果。实验验证了方法的灵活性、泛化性和模块有效性。
- Conclusion: Offline-Poly通过跟踪中心设计和TBT范式，解决了现有离线3D MOT方法的局限性，实现了高性能、灵活且通用的离线跟踪解决方案。


### [66] [Skeleton2Stage: Reward-Guided Fine-Tuning for Physically Plausible Dance Generation](https://arxiv.org/abs/2602.13778)
*Jidong Jia,Youjian Zhang,Huan Fu,Dacheng Tao*

Main category: cs.CV

TL;DR: 提出Skeleton2Stage方法，通过基于物理的奖励和强化学习微调，解决舞蹈生成中骨骼到网格的物理约束问题，减少身体自穿透和足地接触异常

- Motivation: 现有舞蹈生成方法主要在骨骼域训练，忽略了网格级别的物理约束，导致生成的舞蹈在网格可视化时出现身体自穿透和足地接触异常，影响美观和实际应用
- Method: 1) 从身体网格推导基于物理的奖励；2) 应用强化学习微调引导扩散模型生成物理合理的运动；3) 奖励设计包括模仿奖励（衡量运动一般合理性）和足地偏差奖励（捕捉足地动态交互）；4) 提出抗冻结奖励防止模型生成冻结运动
- Result: 在多个舞蹈数据集上的实验表明，该方法能显著提高生成运动的物理合理性，产生更真实美观的舞蹈
- Conclusion: 通过结合基于物理的奖励和强化学习微调，成功弥合了骨骼到网格的差距，提高了舞蹈生成的物理合理性和美观性


### [67] [Foundation Model-Driven Semantic Change Detection in Remote Sensing Imagery](https://arxiv.org/abs/2602.13780)
*Hengtong Shen,Li Yan,Hong Xie,Yaxuan Wei,Xinhao Li,Wenfei Shen,Peixian Lv,Fei Tan*

Main category: cs.CV

TL;DR: 提出PerASCD方法，利用遥感基础模型PerA增强多尺度语义理解，通过级联门控解码器和软语义一致性损失简化SCD范式并提升性能

- Motivation: 现有语义变化检测方法面临模型语义理解能力有限和任务复杂性带来的挑战，在性能和范式复杂度方面存在显著问题
- Method: 基于遥感基础模型PerA的SCD方法，引入模块化级联门控解码器简化复杂解码流程，提出软语义一致性损失缓解训练数值不稳定问题
- Result: 在两个公共基准数据集上达到最先进性能，解码器能有效简化SCD范式并实现跨多种视觉编码器的无缝适配
- Conclusion: PerASCD方法通过增强多尺度语义理解和简化解码流程，有效提升了语义变化检测的性能和实用性


### [68] [Joint Orientation and Weight Optimization for Robust Watertight Surface Reconstruction via Dirichlet-Regularized Winding Fields](https://arxiv.org/abs/2602.13801)
*Jiaze Li,Daisheng Jin,Fei Hou,Junhui Hou,Zheng Liu,Shiqing Xin,Wenping Wang,Ying He*

Main category: cs.CV

TL;DR: DiWR是一种从无定向点云重建水密表面的鲁棒方法，通过联合优化点方向、面积权重和置信系数，能处理非均匀采样、噪声和离群点。

- Motivation: 现有的点云重建方法在处理非均匀采样、噪声和离群点时效果不佳，需要复杂的预处理流程。需要一种能直接处理这些挑战性输入的端到端方法。
- Method: 使用广义环绕数场作为隐式表示，在单一流程中联合优化点方向、每点面积权重和置信系数。通过最小化诱导环绕数场的Dirichlet能量和基于GWN的约束来实现。
- Result: DiWR在3D高斯泼溅、计算机视觉流程和受损图形基准测试的点云上都能产生合理的水密表面，优于传统多阶段流程和最近的联合定向重建方法。
- Conclusion: DiWR提供了一种鲁棒的端到端解决方案，能够补偿非均匀采样、减少噪声影响、降低离群点权重，无需依赖单独的预处理步骤。


### [69] [Gaussian Sequences with Multi-Scale Dynamics for 4D Reconstruction from Monocular Casual Videos](https://arxiv.org/abs/2602.13806)
*Can Li,Jie Gu,Jingmin Chen,Fangzhou Qiu,Lei Sun*

Main category: cs.CV

TL;DR: 提出一种多尺度动力学机制，通过分解复杂运动场来解决单目视频中4D重建的模糊性问题，结合高斯序列表示和多模态先验，实现准确一致的动态场景重建。

- Motivation: 从单目视频理解动态场景对机器人学习至关重要，但在严格单目设置下的4D重建高度不适定。真实世界动力学从物体到粒子层面表现出多尺度规律性，这为解决重建模糊性提供了机会。
- Method: 设计多尺度动力学机制分解复杂运动场，提出具有多尺度动力学的高斯序列表示，通过多级运动组合构建动态3D高斯。结合视觉基础模型的多模态先验建立互补监督，约束解空间。
- Result: 在基准和真实世界操作数据集上的动态新视角合成实验显示，相比现有方法有显著改进，能够从单目随意视频实现准确且全局一致的4D重建。
- Conclusion: 通过多尺度动力学分解和多模态先验监督，有效解决了单目4D重建的模糊性问题，实现了高质量动态场景重建，为机器人学习提供了可扩展的解决方案。


### [70] [VAR-3D: View-aware Auto-Regressive Model for Text-to-3D Generation via a 3D Tokenizer](https://arxiv.org/abs/2602.13818)
*Zongcheng Han,Dongyan Cao,Haoran Sun,Yu Hong*

Main category: cs.CV

TL;DR: VAR-3D提出了一种用于文本到3D生成的新方法，通过视图感知的3D VQ-VAE和渲染监督训练策略，解决了现有方法中的信息损失和几何一致性退化问题。

- Motivation: 现有文本到3D生成方法存在两个主要问题：1）编码过程中的信息损失导致表示失真，向量量化进一步放大了这种失真，降低了几何一致性；2）传统的两阶段训练范式在重建和文本条件自回归生成之间存在目标不匹配。
- Method: 提出了VAR-3D框架，包含两个核心组件：1）视图感知的3D VQ-VAE，将复杂3D几何结构转换为离散标记；2）渲染监督训练策略，将离散标记预测与视觉重建耦合，鼓励生成过程更好地保持视觉保真度和结构一致性。
- Result: 实验表明，VAR-3D在生成质量和文本-3D对齐方面显著优于现有方法。
- Conclusion: VAR-3D通过创新的视图感知编码和渲染监督训练，有效解决了文本到3D生成中的信息损失和几何一致性退化问题，实现了更高质量的3D生成结果。


### [71] [Embed-RL: Reinforcement Learning for Reasoning-Driven Multimodal Embeddings](https://arxiv.org/abs/2602.13823)
*Haonan Jiang,Yuji Wang,Yongjie Zhu,Xin Lu,Wenyu Qin,Meng Wang,Pengfei Wan,Yansong Tang*

Main category: cs.CV

TL;DR: 提出一种基于嵌入器引导强化学习（EG-RL）的推理驱动通用多模态嵌入框架，通过生成可追溯的推理链（T-CoT）来增强多模态检索性能。

- Motivation: 现有生成式嵌入方法的推理链仅限于文本分析，与检索目标无关，无法有效指导多模态嵌入学习。需要一种能够生成与嵌入任务对齐、包含多模态证据的推理方法。
- Method: 提出EG-RL框架：嵌入器为推理器提供显式监督，确保生成的T-CoT与嵌入任务对齐；T-CoT提取关键多模态线索，聚焦检索相关元素，为嵌入器提供多模态输入。
- Result: 在有限计算资源下，在MMEB-V2和UVRB基准测试中超越了领先的嵌入模型。通过多模态证据的结构化推理和检索导向的对齐，增强了跨模态语义一致性和细粒度匹配能力。
- Conclusion: 目标推理优化能显著提升多模态嵌入质量，为推理驱动的通用多模态嵌入开发提供了实用高效的解决方案。


### [72] [Prior-guided Hierarchical Instance-pixel Contrastive Learning for Ultrasound Speckle Noise Suppression](https://arxiv.org/abs/2602.13831)
*Zhenyu Bu,Yuanxin Xie,Guang-Quan Zhou*

Main category: cs.CV

TL;DR: 提出一种先验引导的层次化实例-像素对比学习模型用于超声去噪，通过像素级和实例级对比学习增强噪声不变性和结构感知特征表示，结合Transformer-CNN混合架构，在公开数据集上优于现有方法。

- Motivation: 超声去噪对提升图像质量和诊断可靠性至关重要，但由于斑点噪声同时包含纹理和精细解剖细节，在抑制噪声的同时保持结构保真度仍然是一个重大挑战。
- Method: 提出先验引导的层次化实例-像素对比学习模型：1）统计引导的像素级对比学习增强噪声与干净像素的分布差异；2）使用记忆库进行实例级对比学习；3）采用Transformer-CNN混合架构，Transformer编码器建模全局上下文，CNN解码器恢复精细解剖结构。
- Result: 在两个公开超声数据集上的广泛评估表明，所提模型持续优于现有方法，证实了其有效性和优越性。
- Conclusion: 该研究提出的先验引导层次化对比学习模型能够有效解决超声去噪中噪声抑制与结构保真的平衡问题，通过多级对比学习和混合架构实现了优异的去噪性能。


### [73] [High-Fidelity Causal Video Diffusion Models for Real-Time Ultra-Low-Bitrate Semantic Communication](https://arxiv.org/abs/2602.13837)
*Cem Eteke,Batuhan Tosun,Alexander Griessel,Wolfgang Kellerer,Eckehard Steinbach*

Main category: cs.CV

TL;DR: 提出一种用于超低比特率语义通信的视频扩散模型，通过语义场景结构和压缩低分辨率帧实现高保真、因果、实时视频生成

- Motivation: 在超低比特率语义通信约束下，需要实现高保真、因果、实时的视频生成，传统方法难以在极低比特率下保持视频质量和时间一致性
- Method: 使用有损语义视频编码传输语义场景结构，配合高度压缩的低分辨率帧提供纹理信息；提出模块化视频扩散模型，包含语义控制、恢复适配器和时间适配器；引入高效时间蒸馏方法实现实时因果合成
- Result: 在超低比特率（<0.0003 bpp）下实现强感知质量、语义保真度和时间一致性，在定量、定性和主观评估中优于传统、神经和生成基线方法
- Conclusion: 该框架在超低比特率语义通信约束下实现了高质量视频生成，通过模块化设计和时间蒸馏显著降低了参数量和训练时间，为实时视频通信提供了有效解决方案


### [74] [Automated Prediction of Paravalvular Regurgitation before Transcatheter Aortic Valve Implantation](https://arxiv.org/abs/2602.13842)
*Michele Cannito,Riccardo Renzulli,Adson Duarte,Farzad Nikfam,Carlo Alberto Barbano,Enrico Chiesa,Francesco Bruno,Federico Giacobbe,Wojciech Wanha,Arturo Giordano,Marco Grangetto,Fabrizio D'Ascenzo*

Main category: cs.CV

TL;DR: 使用深度学习从术前心脏CT预测TAVI术后瓣周漏的研究，通过3D卷积神经网络分析CT体积数据，能够捕捉细微解剖特征用于个性化风险评估

- Motivation: 主动脉瓣狭窄是老年患者的常见致命疾病，TAVI是主要治疗方法，但术后瓣周漏(PVR)是最常见的并发症之一，对长期预后有显著影响，需要术前预测方法
- Method: 收集TAVI术前患者数据集，使用3D卷积神经网络在等向性CT体积数据上进行训练，从术前影像中学习预测PVR发生
- Result: 结果表明，体积深度学习能够从术前TAVI影像中捕捉细微的解剖特征，为个性化风险评估和手术优化提供了新视角
- Conclusion: 深度学习在预测TAVI术后瓣周漏方面具有潜力，能够从术前CT中提取有价值的信息，有助于改善患者预后和手术规划，源代码已公开


### [75] [Synthetic Dataset Generation and Validation for Robotic Surgery Instrument Segmentation](https://arxiv.org/abs/2602.13844)
*Giorgio Chiesa,Rossella Borra,Vittorio Lauro,Sabrina De Cillis,Daniele Amparore,Cristian Fiori,Riccardo Renzulli,Marco Grangetto*

Main category: cs.CV

TL;DR: 提出一个用于机器人手术器械分割的合成数据集生成与验证工作流，通过3D重建和自动化流程生成带标注的视频序列，验证显示真实与合成数据平衡使用能提升模型泛化能力。

- Motivation: 机器人手术中的器械分割需要大量标注数据，但真实手术数据获取困难且标注成本高，需要一种可扩展的合成数据生成方法来支持手术计算机视觉研究。
- Method: 使用达芬奇机器人手臂的3D重建模型，通过基于Python的自动化流程在Autodesk Maya中生成包含随机运动、光照变化和合成血液纹理的光真实感标注视频序列。
- Result: 实验表明，真实与合成数据的平衡组合相比仅使用真实数据能显著提升分割模型的泛化能力，但过度依赖合成数据会导致可测量的领域偏移。
- Conclusion: 该框架为手术计算机视觉提供了一个可重复、可扩展的工具，支持数据增强、领域适应和基于模拟的预训练研究，代码和数据已开源。


### [76] [Cardiac Output Prediction from Echocardiograms: Self-Supervised Learning with Limited Data](https://arxiv.org/abs/2602.13846)
*Adson Duarte,Davide Vitturini,Emanuele Milillo,Andrea Bragagnolo,Carlo Alberto Barbano,Riccardo Renzulli,Michele Cannito,Federico Giacobbe,Francesco Bruno,Ovidio de Filippo,Fabrizio D'Ascenzo,Marco Grangetto*

Main category: cs.CV

TL;DR: 使用SimCLR自监督学习预训练策略，从心尖四腔超声心动图视频中改进心输出量预测，即使在数据有限的情况下也能提升性能

- Motivation: 心输出量是心血管疾病诊断和管理的关键参数，但准确测量需要侵入性的右心导管检查，因此需要开发可靠的基于超声心动图的非侵入性替代方法
- Method: 提出基于SimCLR的自监督学习预训练策略，使用与下游任务相同的有限数据集进行预训练，然后用于心尖四腔超声心动图视频的心输出量预测
- Result: 自监督学习减轻了过拟合并改善了表示学习，在测试集上实现了平均0.41的皮尔逊相关系数，优于在超过一百万次超声心动图检查上训练的PanEcho模型
- Conclusion: 自监督学习即使在数据稀缺的情况下也能有效提升心输出量预测性能，展示了在有限医疗数据场景下的应用潜力


### [77] [Low-Pass Filtering Improves Behavioral Alignment of Vision Models](https://arxiv.org/abs/2602.13859)
*Max Wolff,Thomas Klein,Evgenia Rusak,Felix Wichmann,Wieland Brendel*

Main category: cs.CV

TL;DR: 研究发现，生成模型与人类视觉行为对齐度的提升主要源于图像缩放操作的低通滤波效应，而非生成机制本身。通过在测试时简单模糊图像，判别模型就能大幅提升对齐度，甚至达到新的SOTA。

- Motivation: 尽管深度神经网络在计算机视觉基准测试中表现出色，但在模拟人类视觉行为方面仍有不足。最近研究假设生成式分类器能显著改善行为对齐，但本文旨在探究这种对齐提升是否主要源于图像预处理中的低通滤波效应。
- Method: 通过一系列对照实验：1）从判别模型中移除高频空间信息；2）在测试时简单模糊图像；3）直接优化滤波器以最大化对齐度；4）计算所有可能的帕累托最优解前沿；5）将最优高斯滤波器频谱与人类视觉系统的带通滤波器频谱进行比较。
- Result: 1）移除高频信息显著提升了判别模型的行为对齐度；2）仅测试时模糊图像就在模型vs人类基准测试中达到了新的SOTA，将DNN与人类观察者的对齐差距减半；3）低通滤波器可能是最优的；4）最优高斯滤波器的频谱与人类视觉系统的对比敏感度函数匹配良好。
- Conclusion: 生成模型与人类视觉行为对齐度的提升主要源于图像缩放操作的低通滤波效应，而非生成机制本身。人类视觉系统的对比敏感度函数可以通过特定宽度的高斯滤波器近似，这种滤波器也能最大化错误一致性。


### [78] [Human-Aligned Evaluation of a Pixel-wise DNN Color Constancy Model](https://arxiv.org/abs/2602.13887)
*Hamed Heidari-Gorji,Raquel Gil Rodriguez,Karl R. Gegenfurtner*

Main category: cs.CV

TL;DR: 比较VR环境中人类与DNN模型在颜色恒常性任务上的表现，发现两者行为高度一致

- Motivation: 研究深度学习模型是否能模拟人类颜色恒常性机制，通过比较模型与人类在相同任务中的表现来验证
- Method: 使用预训练的ResNet U-Net模型预测表面反射率，通过迁移学习在VR基准条件下微调解码器，让模型执行与人类实验相同的无色物体选择任务
- Result: 模型与人类行为高度一致：两者在基准条件下都表现出高颜色恒常性，当移除局部环绕或空间平均颜色线索时，都出现相似的条件依赖性性能下降
- Conclusion: 深度学习模型能够有效模拟人类颜色恒常性机制，为理解视觉感知提供了计算模型验证


### [79] [Parameter-Efficient Fine-Tuning of DINOv2 for Large-Scale Font Classification](https://arxiv.org/abs/2602.13889)
*Daniel Chen,Zaria Zinn,Marcus Lowe*

Main category: cs.CV

TL;DR: 基于DINOv2视觉Transformer，使用LoRA微调实现394种字体分类，准确率约86%，仅训练模型0.1%参数，并提供开源数据集和训练管道

- Motivation: 开发一个能够从渲染文本图像中准确识别大量字体家族的系统，解决字体分类在实际应用中的需求，并提供开源资源促进相关研究
- Method: 使用LoRA微调DINOv2视觉Transformer，构建合成数据集生成管道（渲染Google Fonts并添加多种数据增强），内置预处理确保训练推理一致性，部署为HuggingFace推理端点
- Result: 在394种字体分类任务上达到约86%的top-1准确率，仅训练了87.2M参数中的不到1%（约0.1%），模型、数据集和训练管道均已开源
- Conclusion: LoRA微调结合大规模合成数据增强能有效实现高效字体分类，该方法参数效率高且能泛化到真实世界样本，开源资源将推动字体识别领域发展


### [80] [RPGD: RANSAC-P3P Gradient Descent for Extrinsic Calibration in 3D Human Pose Estimation](https://arxiv.org/abs/2602.13901)
*Zhanyu Tuo*

Main category: cs.CV

TL;DR: RPGD是一个基于人体姿态的外参标定框架，通过结合RANSAC-P3P的全局鲁棒性和梯度下降优化，仅使用自然人体运动就能将MoCap 3D骨骼数据与单目或多视角RGB相机对齐。

- Motivation: 解决大规模3D人体姿态估计数据集采集中的外参标定问题，传统方法需要人工标记或特殊设备，而RPGD旨在仅通过自然人体运动实现自动、可靠的外参标定。
- Method: 采用粗到精的策略：首先使用RANSAC-P3P进行全局鲁棒性初始估计，然后通过梯度下降进行精细化优化，专门针对人体姿态特性设计。
- Result: 在三个大规模公开3D HPE数据集和自采集的真实场景数据集上评估，RPGD能够恢复与真实值精度相当的外参，即使在具有挑战性的噪声环境下也能达到亚像素级的MPJPE重投影误差。
- Conclusion: RPGD为大规模3D人体姿态估计数据集采集提供了一个实用、自动的外参标定解决方案，能够可靠地进行相机外参校准。


### [81] [MamaDino: A Hybrid Vision Model for Breast Cancer 3-Year Risk Prediction](https://arxiv.org/abs/2602.13930)
*Ruggiero Santeramo,Igor Zubarev,Florian Jug*

Main category: cs.CV

TL;DR: MamaDino模型通过结合卷积和Transformer架构，并显式建模双侧乳房不对称性，在低分辨率乳腺X光片上实现了与当前最佳模型Mirai相当的3年乳腺癌风险预测性能。

- Motivation: 当前乳腺癌筛查正从统一间隔转向风险适应和个性化策略。现有深度学习模型（如Mirai）通常使用卷积网络、高分辨率输入和简单的多视图融合，对双侧乳房不对称性的显式建模有限。作者假设结合互补的归纳偏置（卷积和Transformer）并显式建模双侧不对称性，可以在更低分辨率图像上达到SOTA性能。
- Method: 提出MamaDino模型：融合冻结的自监督DINOv3 ViT-S特征与可训练的CNN编码器（512x512分辨率），通过BilateralMixer聚合双侧乳房信息，输出3年乳腺癌风险评分。在OPTIMAM数据集（53,883名女性）上训练，在匹配的3年病例对照队列中评估。
- Result: 在乳房层面，MamaDino在内部和外部测试中均与Mirai性能相当，但输入像素减少约13倍。添加BilateralMixer将内部测试的AUC从0.713提升到0.736，外部测试从0.666提升到0.677。性能在不同年龄、种族、扫描仪、肿瘤类型和分级中表现一致。
- Conclusion: 显式的双侧建模和互补的归纳偏置使得模型能够在显著更低分辨率的乳腺X光片上实现与Mirai相当的预测性能，表明以更结构化的方式使用较少细节的图像可以恢复SOTA准确性。


### [82] [Fusing Pixels and Genes: Spatially-Aware Learning in Computational Pathology](https://arxiv.org/abs/2602.13944)
*Minghao Han,Dingkang Yang,Linhao Qu,Zizhi Chen,Gang Li,Han Wang,Jiacong Wang,Lihua Zhang*

Main category: cs.CV

TL;DR: STAMP是一个空间转录组增强的多模态病理学表示学习框架，通过整合空间分辨的基因表达谱，实现病理图像与转录组数据的分子引导联合嵌入，在多个下游任务中表现优异。

- Motivation: 现有病理学多模态学习主要依赖视觉和语言模态，但语言缺乏分子特异性且病理监督有限，导致表示瓶颈。需要整合空间分辨的分子信息来提升模型性能。
- Method: 提出STAMP框架，整合空间转录组数据；构建SpaVis-6M数据集（最大的Visium空间转录组数据集）；训练空间感知基因编码器；采用分层多尺度对比对齐和跨尺度斑块定位机制，对齐空间转录组与病理图像。
- Result: 在6个数据集和4个下游任务中验证，STAMP均取得优异性能，证明自监督的基因引导训练能为病理图像表示学习提供鲁棒且任务无关的信号。
- Conclusion: 整合空间分辨的分子监督对于推进计算病理学的多模态学习具有重要价值和必要性，STAMP框架为此提供了有效解决方案。


### [83] [MarsRetrieval: Benchmarking Vision-Language Models for Planetary-Scale Geospatial Retrieval on Mars](https://arxiv.org/abs/2602.13961)
*Shuoyuan Wang,Yiran Wang,Hongxin Wei*

Main category: cs.CV

TL;DR: 提出MarsRetrieval基准，用于评估火星地理发现的视觉语言模型，包含三个检索任务，显示现有基础模型难以捕捉领域特定的地貌特征

- Motivation: 现有火星探索的深度学习基准大多局限于封闭集监督视觉任务，缺乏支持文本引导检索的地理发现能力，需要专门的评估基准来推动行星科学中的多模态模型发展
- Method: 提出MarsRetrieval检索基准，包含三个任务：配对图像-文本检索、地貌检索和全球地理定位；设计统一的检索中心协议，评估对比双塔编码器和生成式视觉语言模型
- Result: MarsRetrieval具有挑战性，即使是强大的基础模型也经常无法捕捉领域特定的地貌区分；领域特定的微调对于行星环境中的可泛化地理发现至关重要
- Conclusion: MarsRetrieval为火星地理发现提供了重要的评估基准，揭示了现有视觉语言模型在行星科学应用中的局限性，强调了领域适应的重要性


### [84] [Elastic Diffusion Transformer](https://arxiv.org/abs/2602.13993)
*Jiangshan Wang,Zeqiang Lai,Jiarui Chen,Jiayi Guo,Hang Guo,Xiu Li,Xiangyu Yue,Chunchao Guo*

Main category: cs.CV

TL;DR: E-DiT提出了一种自适应加速框架，通过轻量级路由器动态识别样本稀疏性，实现Diffusion Transformer的弹性计算，在保持生成质量的同时达到约2倍加速。

- Motivation: 现有Diffusion Transformer加速方法（如剪枝和蒸馏）通常依赖固定计算容量，导致加速不足且生成质量下降。作者观察到DiT生成过程存在显著稀疏性，且这种稀疏性在不同样本间差异很大，因此需要一种自适应加速方法。
- Method: E-DiT为每个DiT块配备轻量级路由器，动态识别输入潜变量的样本依赖稀疏性。路由器自适应决定是否跳过对应块，如果不跳过则预测块内MLP的最佳宽度缩减比例。推理时引入块级特征缓存机制，利用路由器预测以训练无关的方式消除冗余计算。
- Result: 在2D图像（Qwen-Image和FLUX）和3D资产（Hunyuan3D-3.0）上的广泛实验证明E-DiT的有效性，实现了高达约2倍的加速，同时生成质量损失可忽略不计。
- Conclusion: E-DiT通过自适应稀疏性识别和弹性计算，成功解决了DiT计算效率问题，在保持高质量生成的同时显著提升推理速度，为大规模扩散模型的实际部署提供了有效解决方案。


### [85] [Inject Where It Matters: Training-Free Spatially-Adaptive Identity Preservation for Text-to-Image Personalization](https://arxiv.org/abs/2602.13994)
*Guandong Li,Mengxia Ye*

Main category: cs.CV

TL;DR: SpatialID：无需训练的空间自适应身份调制框架，通过空间掩码提取器和时空调度策略，在文本到图像生成中实现身份特征与背景的解耦，避免身份污染非面部区域。

- Motivation: 现有免调优方法采用空间均匀的视觉注入，导致身份特征污染非面部区域（如背景和光照），降低文本遵循能力。需要在不进行昂贵微调的情况下解决此问题。
- Method: 提出SpatialID框架：1）使用基于交叉注意力响应的空间掩码提取器，将身份注入解耦为面部相关区域和上下文无关区域；2）引入时空调度策略，动态调整空间约束（从高斯先验到注意力掩码再到自适应松弛），以对齐扩散生成动态。
- Result: 在IBench上的实验表明，SpatialID在文本遵循（CLIP-T: 0.281）、视觉一致性（CLIP-I: 0.827）和图像质量（IQ: 0.523）方面达到最先进性能，显著消除背景污染同时保持稳健的身份保留。
- Conclusion: SpatialID通过空间自适应身份调制，有效解决了免调优个性化文本到图像生成中的身份污染问题，在保持身份一致性的同时提升了文本遵循能力和图像质量。


### [86] [A Deployment-Friendly Foundational Framework for Efficient Computational Pathology](https://arxiv.org/abs/2602.14010)
*Yu Cai,Cheng Jin,Jiabo Ma,Fengtao Zhou,Yingxue Xu,Zhengrui Guo,Yihui Wang,Zhengyu Zhang,Ling Liang,Yonghao Tan,Pingcheng Dong,Du Cai,On Ki Tang,Chenglong Zhao,Xi Wang,Can Yang,Yali Xu,Jing Cui,Zhenhui Li,Ronald Cheong Kin Chan,Yueping Liu,Feng Gao,Xiuming Zhang,Li Liang,Hao Chen,Kwang-Ting Cheng*

Main category: cs.CV

TL;DR: LitePath是一个部署友好的病理学基础框架，通过模型压缩和自适应补丁选择，在保持高精度的同时大幅降低计算成本和能耗，可在边缘设备上高效运行。

- Motivation: 现有的病理学基础模型（PFMs）虽然泛化能力强，但计算成本高昂，特别是在处理千兆像素的全切片图像时，限制了临床可及性和可扩展性。需要开发更高效的部署方案。
- Method: 提出LitePath框架，包含两个核心组件：1) LiteFM - 从三个大型PFMs（Virchow2、H-Optimus-1和UNI2）蒸馏出的紧凑模型，使用1.9亿个补丁训练；2) 自适应补丁选择器（APS）- 轻量级组件，用于任务特定的补丁选择。
- Result: 相比Virchow2，参数减少28倍，FLOPs降低403.5倍；在NVIDIA Jetson Orin Nano Super上每小时处理208张切片，速度提升104.5倍；能耗降低171倍；在37个队列、26个任务上验证，平均保留Virchow2 99.71%的AUC，在19个模型中排名第二。
- Conclusion: LitePath实现了在可访问硬件上快速、经济、节能的病理图像分析，同时保持与最先进PFMs相当的准确性，显著降低了AI部署的碳足迹，并通过提出的部署性评分（D-Score）证明了在精度与效率之间的最佳平衡。


### [87] [Flow4R: Unifying 4D Reconstruction and Tracking with Scene Flow](https://arxiv.org/abs/2602.14021)
*Shenhan Qian,Ganlin Zhang,Shangzhe Wu,Daniel Cremers*

Main category: cs.CV

TL;DR: Flow4R：一个统一的动态3D场景重建框架，将相机空间场景流作为核心表示，连接3D结构、物体运动和相机运动，从两视图输入预测最小像素属性集。

- Motivation: 现有方法通常将几何与运动解耦：多视图重建方法假设静态场景，而动态跟踪框架依赖显式相机姿态估计或单独的运动模型。需要一种统一的方法来同时处理3D结构、物体运动和相机运动。
- Method: Flow4R将相机空间场景流作为核心表示，使用Vision Transformer从两视图输入预测每个像素的最小属性集（3D点位置、场景流、姿态权重和置信度）。这种以流为中心的表述允许通过共享解码器在单次前向传递中对称推断局部几何和双向运动，无需显式姿态回归器或束调整。
- Result: 在静态和动态数据集上联合训练的Flow4R在4D重建和跟踪任务上达到了最先进的性能，证明了流中心表示在时空场景理解中的有效性。
- Conclusion: Flow4R展示了将场景流作为统一表示连接3D结构、物体运动和相机运动的有效性，为动态3D场景重建和跟踪提供了一个简洁而强大的框架。


### [88] [Train Short, Inference Long: Training-free Horizon Extension for Autoregressive Video Generation](https://arxiv.org/abs/2602.14027)
*Jia Li,Xiaomeng Fu,Xurui Peng,Weifeng Chen,Youwei Zheng,Tianyu Zhao,Jiexi Wang,Fangmin Chen,Xing Wang,Hayden Kwok-Hay So*

Main category: cs.CV

TL;DR: FLEX是一个无需训练的视频生成推理框架，通过频率感知位置编码调制和反相噪声采样，解决自回归视频扩散模型在长视频生成中的外推失败问题。

- Motivation: 自回归视频扩散模型在长视频生成中存在严重的外推失败问题，当生成超出训练时长时，误差累积导致时间退化。主要原因是3D位置嵌入的频谱偏差和噪声采样缺乏动态先验。
- Method: 提出FLEX框架：1) 频率感知RoPE调制，自适应插值未充分训练的低频分量并外推高频分量；2) 反相噪声采样注入高频动态先验；3) 仅推理注意力锚点保持全局结构。这是一个即插即用的推理增强方法。
- Result: 在VBench评估中，FLEX在6倍外推（30秒时长）显著优于SOTA模型，在12倍尺度（60秒时长）与长视频微调基线性能相当。能够支持LongLive等模型生成4分钟尺度的一致动态视频。
- Conclusion: FLEX有效解决了自回归视频扩散模型的长视频生成外推问题，通过频率感知调制和动态先验注入，无需额外训练即可显著扩展生成时长，为现有推理管线提供即插即用的增强方案。


### [89] [Explainability-Inspired Layer-Wise Pruning of Deep Neural Networks for Efficient Object Detection](https://arxiv.org/abs/2602.14040)
*Abhinav Shukla,Nachiket Tapas*

Main category: cs.CV

TL;DR: 提出基于可解释性启发的层剪枝框架，通过梯度-激活归因评估层重要性，相比传统L1范数剪枝在目标检测任务上实现更好的精度-效率权衡。

- Motivation: 深度神经网络在目标检测任务中表现出色，但模型复杂度高难以部署在资源受限平台。传统基于权重大小的剪枝方法不能准确反映网络组件对任务性能的功能贡献，需要更智能的剪枝策略。
- Method: 提出基于可解释性的层剪枝框架，采用SHAP启发的梯度-激活归因方法来评估层重要性，作为功能贡献的数据驱动代理，而非仅依赖静态权重大小。该方法针对目标检测任务进行了专门设计。
- Result: 在多种目标检测架构（ResNet-50、MobileNetV2、ShuffleNetV2、Faster R-CNN、RetinaNet、YOLOv8）和COCO 2017验证集上的实验表明：1）提出的归因剪枝方法识别出与L1范数剪枝不同的最不重要层；2）ShuffleNetV2上实现10%推理速度提升，而L1剪枝导致13.7%性能下降；3）RetinaNet上保持基线mAP(0.151)且推理速度影响可忽略，而L1剪枝以1.3% mAP下降换取6.2%速度提升。
- Conclusion: 数据驱动的层重要性评估对于模型压缩至关重要，可解释性启发的压缩为在边缘和资源受限平台上部署深度神经网络提供了有原则的方向，能够在保持性能和可解释性的同时提高效率。


### [90] [BitDance: Scaling Autoregressive Generative Models with Binary Tokens](https://arxiv.org/abs/2602.14041)
*Yuang Ai,Jiaming Han,Shaobin Zhuang,Weijia Mao,Xuefeng Hu,Ziyan Yang,Zhenheng Yang,Huaibo Huang,Xiangyu Yue,Hao Chen*

Main category: cs.CV

TL;DR: BitDance是一个可扩展的自回归图像生成器，使用二进制视觉标记而非码本索引，通过二进制扩散头和下一块扩散技术实现高效高质量图像生成。

- Motivation: 传统自回归图像生成器使用码本索引，表达能力有限且采样效率低。需要一种更紧凑、表达能力更强的离散表示方法，同时解决大规模标记空间采样难题。
- Method: 1) 使用高熵二进制潜在表示，每个标记可表示2^256种状态；2) 采用二进制扩散头替代softmax分类，通过连续空间扩散生成二进制标记；3) 提出下一块扩散解码方法，并行预测多个标记以加速推理。
- Result: 在ImageNet 256x256上达到FID 1.24，是自回归模型中的最佳结果。相比使用14亿参数的并行AR模型，BitDance仅用2.6亿参数（减少5.4倍）且推理速度提升8.7倍。在1024x1024图像生成上，相比先前AR模型速度提升超过30倍。
- Conclusion: BitDance通过二进制视觉标记和创新的扩散解码方法，实现了高效、高质量的自回归图像生成，在参数效率和推理速度方面显著优于现有方法，为AR基础模型研究提供了新方向。


### [91] [Restoration Adaptation for Semantic Segmentation on Low Quality Images](https://arxiv.org/abs/2602.14042)
*Kai Guan,Rongyuan Wu,Shuai Li,Wentao Zhu,Wenjun Zeng,Lei Zhang*

Main category: cs.CV

TL;DR: 提出RASS框架，通过语义约束的恢复模型和知识迁移，解决低质量图像语义分割性能下降问题

- Motivation: 现实场景中，低质量图像缺乏清晰语义结构和高频细节，导致语义分割性能下降。传统图像恢复模型只关注像素级保真度，无法恢复任务相关的语义线索；而现有分割模型对真实世界退化缺乏鲁棒性。
- Method: 提出RASS框架：1) 语义约束恢复模型(SCR)，通过将交叉注意力图与分割掩码对齐，将分割先验注入恢复模型；2) 通过LoRA模块合并和任务特定微调，将语义恢复知识迁移到分割中。
- Result: 在合成和真实世界低质量基准测试上，SCR和RASS在分割和恢复任务上显著优于最先进方法。构建了带高质量标注的真实世界低质量图像分割数据集。
- Conclusion: RASS框架有效整合语义图像恢复到分割过程中，直接对低质量图像实现高质量语义分割，解决了传统恢复模型缺乏语义保真度和分割模型对退化缺乏鲁棒性的问题。


### [92] [CoCoEdit: Content-Consistent Image Editing via Region Regularized Reinforcement Learning](https://arxiv.org/abs/2602.14068)
*Yuhui Wu,Chenxi Xie,Ruibin Li,Liyi Chen,Qiaosi Yi,Lei Zhang*

Main category: cs.CV

TL;DR: CoCoEdit是一个通过区域正则化强化学习实现内容一致性图像编辑的后训练框架，在保持非编辑区域不变的同时提升编辑质量。

- Motivation: 现有图像编辑模型主要关注目标对象的编辑效果，但往往会导致非编辑区域发生不必要的变化，缺乏内容一致性。
- Method: 1) 构建包含4万样本的高质量训练集；2) 引入像素级相似度奖励补充MLLM奖励；3) 提出基于区域的正则化器，对高奖励样本保护非编辑区域，对低奖励样本鼓励编辑效果。
- Result: 在Qwen-Image-Edit和FLUX-Kontext上应用CoCoEdit，不仅获得了与SOTA模型竞争的编辑分数，而且在PSNR/SSIM指标和人类主观评分上显著提升了内容一致性。
- Conclusion: CoCoEdit框架通过区域正则化强化学习有效解决了图像编辑中的内容一致性问题，在保持编辑质量的同时显著减少了非编辑区域的不必要变化。


### [93] [ForgeryVCR: Visual-Centric Reasoning via Efficient Forensic Tools in MLLMs for Image Forgery Detection and Localization](https://arxiv.org/abs/2602.14098)
*Youqi Wang,Shen Chen,Haowei Wang,Rongxuan Peng,Taiping Yao,Shunquan Tan,Changsheng Chen,Bin Li,Shouhong Ding*

Main category: cs.CV

TL;DR: 提出ForgeryVCR框架，通过视觉中心推理将不可见的篡改痕迹转化为显式视觉中间表示，结合战略工具学习范式，使MLLM能够主动调用多视角分析工具，在图像伪造检测和定位任务中达到SOTA性能。

- Motivation: 现有基于文本中心思维链的MLLM在图像伪造检测中存在幻觉问题，因为语言模态无法充分捕捉像素级的细微篡改痕迹。需要将不可见的篡改痕迹转化为显式视觉表示来解决这一问题。
- Method: 1) 引入法证工具箱将不可见痕迹转化为显式视觉中间表示；2) 提出战略工具学习后训练范式，包括增益驱动的监督微调轨迹构建和基于工具效用奖励的强化学习优化；3) 使MLLM能够主动调用多视角推理路径，包括局部放大、压缩历史分析、噪声残差和频域分析。
- Result: ForgeryVCR在检测和定位任务中均达到最先进性能，表现出优异的泛化能力和鲁棒性，同时工具冗余最小。
- Conclusion: 通过视觉中心推理和战略工具学习，ForgeryVCR成功解决了MLLM在图像伪造检测中的幻觉问题，实现了更准确可靠的伪造痕迹分析。


### [94] [GeoFusionLRM: Geometry-Aware Self-Correction for Consistent 3D Reconstruction](https://arxiv.org/abs/2602.14119)
*Ahmet Burak Yildirim,Tuna Saygin,Duygu Ceylan,Aysegul Dundar*

Main category: cs.CV

TL;DR: GeoFusionLRM：一种几何感知自校正框架，利用模型自身的法线和深度预测来改进单图像3D重建的结构准确性，无需额外监督。

- Motivation: 现有大型重建模型（LRMs）在单图像3D重建中常出现几何不一致和细节错位问题，限制了重建的保真度。
- Method: 引入几何感知自校正框架，利用模型自身的法线和深度预测，通过专用transformer和融合模块反馈几何线索，纠正错误并强制与条件图像的一致性。
- Result: 实验表明GeoFusionLRM相比现有LRM基线实现了更锐利的几何、更一致的法线和更高的保真度。
- Conclusion: GeoFusionLRM通过几何感知自校正有效提升了单图像3D重建的质量，无需额外监督或外部信号。


### [95] [EgoSound: Benchmarking Sound Understanding in Egocentric Videos](https://arxiv.org/abs/2602.14122)
*Bingwen Zhu,Yuqian Fu,Qiaole Dong,Guolei Sun,Tianwen Qian,Yuzheng Wu,Danda Pani Paudel,Xiangyang Xue,Yanwei Fu*

Main category: cs.CV

TL;DR: EgoSound是首个用于系统评估多模态大语言模型在自我中心声音理解能力的基准测试，包含7315个经过验证的问答对，涵盖7个任务类别，揭示了当前模型在细粒度空间和因果理解方面的局限性。

- Motivation: 人类感知本质上是多感官的，整合视觉、听觉和运动来理解世界。在自我中心场景中，声音提供了关于空间布局、屏幕外事件和因果交互的关键线索，而现有MLLMs主要关注视觉-语言理解，缺乏对声音模态的系统评估。
- Method: 作者构建了EgoSound基准测试，整合了Ego4D和EgoBlind数据集，涵盖有视觉和依赖声音的体验。通过多阶段自动生成流程，定义了7个任务分类：内在声音感知、空间定位、因果推理和跨模态推理，最终包含7315个经过验证的问答对，覆盖900个视频。
- Result: 对9个最先进的MLLMs进行综合实验表明，当前模型展现出初步的听觉推理能力，但在细粒度的空间和因果理解方面仍然有限。EgoSound为推进多感官自我中心智能建立了具有挑战性的基础。
- Conclusion: EgoSound填补了MLLMs在自我中心声音理解方面的评估空白，揭示了当前模型的局限性，为弥合"看到"和"真正听到"世界之间的差距提供了重要基准，推动了多感官智能的发展。


### [96] [DenseMLLM: Standard Multimodal LLMs are Intrinsic Dense Predictors](https://arxiv.org/abs/2602.14134)
*Yi Li,Hongze Shen,Lexiang Tang,Xin Li,Xinpeng Ding,Yinsong Liu,Deqiang Jiang,Xing Sun,Xiaomeng Li*

Main category: cs.CV

TL;DR: DenseMLLM：无需任务特定解码器，让标准多模态大语言模型直接执行密集预测任务（如语义分割、深度估计）

- Motivation: 当前多模态大语言模型在高层视觉理解表现出色，但扩展到细粒度密集预测任务通常需要复杂的任务特定解码器，导致架构碎片化、增加模型复杂性，偏离了MLLM的通才设计理念，限制了实用性
- Method: 提出DenseMLLM模型，基于标准架构，采用新颖的视觉token监督策略来处理多标签和多任务，无需额外任务特定解码器
- Result: 在广泛的密集预测和视觉语言基准测试中实现了高度竞争力的性能
- Conclusion: 标准、通用的多模态大语言模型可以有效支持密集感知任务，无需架构专业化


### [97] [Detection of On-Ground Chestnuts Using Artificial Intelligence Toward Automated Picking](https://arxiv.org/abs/2602.14140)
*Kaixuan Fang,Yuzhen Lu,Xinyang Mu*

Main category: cs.CV

TL;DR: 本研究系统评估了29种实时目标检测模型（14种YOLO和15种RT-DETR）用于果园地面板栗检测，发现YOLOv12m在mAP@0.5上表现最佳（95.1%），YOLOv11x在mAP@[0.5:0.95]上最优（80.1%），YOLO模型整体优于RT-DETR，适合实时部署。

- Motivation: 传统机械化板栗收获成本高、非选择性且易损伤坚果。开发低成本、视觉引导的自动化收获技术需要准确可靠的板栗检测系统，但复杂果园环境（阴影、光照变化、杂草、落叶、石块等干扰）给检测带来挑战。
- Method: 收集319张果园地面板栗图像（含6524个标注板栗），系统评估29种最先进的实时目标检测器（包括14种YOLO v11-13系列和15种RT-DETR v1-v4系列不同规模模型），通过重复建模实验进行板栗检测性能比较。
- Result: YOLOv12m模型在所有评估模型中达到最佳mAP@0.5（95.1%），RT-DETRv2-R101是RT-DETR模型中最准确的变体（mAP@0.5为91.1%）。YOLOv11x在mAP@[0.5:0.95]上获得最高精度（80.1%）。所有模型都显示出实时板栗检测的潜力，YOLO模型在检测精度和推理速度上均优于RT-DETR模型。
- Conclusion: YOLO模型更适合板载部署，为低成本自动化板栗收获技术提供了有效的视觉检测解决方案。研究数据集和软件程序已公开，促进相关研究发展。


### [98] [LaViDa-R1: Advancing Reasoning for Unified Multimodal Diffusion Language Models](https://arxiv.org/abs/2602.14147)
*Shufan Li,Yuchen Zhu,Jiuxiang Gu,Kangning Liu,Zhe Lin,Yongxin Chen,Molei Tao,Aditya Grover,Jason Kuen*

Main category: cs.CV

TL;DR: LaViDa-R1是一个多模态通用推理扩散语言模型，通过统一的监督微调和多任务强化学习框架，在视觉数学推理、密集推理的grounding和图像编辑等任务上表现出色。

- Motivation: 扩散语言模型作为自回归LLM的有前景替代方案出现，现有工作已扩展到多模态理解与生成任务。但现有推理dLLM主要通过任务特定的强化学习构建，缺乏统一的多模态任务整合方式。
- Method: 提出统一的后训练框架，无缝整合监督微调(SFT)和多任务强化学习(RL)。采用多种新颖训练技术：答案强制(answer-forcing)、树搜索(tree search)和互补似然估计(complementary likelihood estimation)，以提升效果和可扩展性。
- Result: 大量实验证明LaViDa-R1在多种多模态任务上表现强劲，包括视觉数学推理、推理密集的grounding任务和图像编辑。
- Conclusion: LaViDa-R1展示了通过统一框架整合多模态理解与生成任务的可行性，为构建通用多模态推理扩散语言模型提供了有效方法。


### [99] [ARport: An Augmented Reality System for Markerless Image-Guided Port Placement in Robotic Surgery](https://arxiv.org/abs/2602.14153)
*Zheng Han,Zixin Yang,Yonghao Long,Lin Zhang,Peter Kazanzides,Qi Dou*

Main category: cs.CV

TL;DR: ARport：基于增强现实的标记物自由手术端口规划系统，通过头戴式显示器将术前规划的套管布局映射到患者体表

- Motivation: 在机器人辅助手术中，精确的端口放置至关重要，但术前规划与术中执行之间存在差距。需要一种直观的空间引导系统来简化手术准备流程
- Method: 使用光学透视头戴式显示器，无需外部传感器或标记物。通过RGB、深度和姿态数据重建手术场景，利用基础模型提取患者体表，进行基于表面的无标记配准，将术前解剖模型对齐到患者体表
- Result: 在全尺寸人体模型实验中，ARport能够准确地将术前规划的套管位置叠加到物理模型上，实现虚拟规划与真实解剖结构之间一致的空间对应关系
- Conclusion: ARport提供了一个完全无标记、硬件需求最小的解决方案，用于直接在患者体表可视化术前套管规划。该系统促进了高效的术中设置，并展示了无缝集成到常规临床工作流程的潜力


### [100] [When Test-Time Guidance Is Enough: Fast Image and Video Editing with Diffusion Guidance](https://arxiv.org/abs/2602.14157)
*Ahmed Ghorbel,Badr Moufad,Navid Bagheri Shouraki,Alain Oliviero Durmus,Thomas Hirtz,Eric Moulines,Jimmy Olsson,Yazid Janati*

Main category: cs.CV

TL;DR: 基于测试时引导的图像视频编辑方法，无需VJP计算，性能媲美训练方法

- Motivation: 现有基于测试时引导的编辑方法依赖昂贵的VJP计算，限制了实际应用
- Method: 基于Moufad等人的VJP-free近似方法，扩展到大规模图像视频编辑基准
- Result: 测试时引导方法性能可比甚至超越训练方法
- Conclusion: 测试时引导是有效的图像视频编辑方法，无需训练即可获得高质量结果


### [101] [Towards Spatial Transcriptomics-driven Pathology Foundation Models](https://arxiv.org/abs/2602.14177)
*Konstantin Hemker,Andrew H. Song,Cristina Almagro-Pérez,Guillaume Jaume,Sophia J. Wagner,Anurag Vaidya,Nikola Simidjievski,Mateja Jamnik,Faisal Mahmood*

Main category: cs.CV

TL;DR: SEAL是一个空间转录组学引导的病理学基础模型微调框架，通过将局部分子信息注入视觉编码器，提升病理图像表示能力

- Motivation: 空间转录组学提供了基因表达的空间解析测量，但如何系统地将形态学与分子信息耦合以改进病理学视觉表示仍是一个挑战。现有病理学基础模型主要基于视觉模态，缺乏局部分子信息的指导。
- Method: SEAL是一个参数高效的视觉-组学自监督学习框架，通过700,000多个配对的基因表达点-组织区域样本进行训练，采用微调而非从头训练的方式，可灵活应用于现有病理学基础模型。
- Result: 在38个切片级和15个斑块级下游任务中，SEAL相比纯视觉和空间转录组学预测基线表现更优，包括分子状态、通路活性、治疗反应预测和基因表达预测。同时展现出强大的领域泛化能力和跨模态检索能力。
- Conclusion: SEAL为病理学基础模型的空间转录组学引导微调提供了一个通用框架，表明用局部分子监督增强现有模型是改进视觉表示和扩展跨模态效用的有效实用方法。


### [102] [UniWeTok: An Unified Binary Tokenizer with Codebook Size $\mathit{2^{128}}$ for Unified Multimodal Large Language Model](https://arxiv.org/abs/2602.14178)
*Shaobin Zhuang,Yuang Ai,Jiaming Han,Weijia Mao,Xiaohui Li,Fangyikang Wang,Xiao Wang,Yan Li,Shanchuan Lin,Kun Xu,Zhenheng Yang,Huaibo Huang,Xiangyu Yue,Hao Chen,Yali Wang*

Main category: cs.CV

TL;DR: UniWeTok：一个统一的离散视觉分词器，使用大规模二进制码本（2^128）同时支持高保真重建、复杂语义提取和生成适应性，在图像生成、理解和编辑任务上达到SOTA性能。

- Motivation: 现有的多模态大语言模型需要视觉表示同时支持高保真重建、复杂语义提取和生成适应性，但现有视觉分词器难以在单一框架内满足这些冲突目标。
- Method: 1. 使用大规模二进制码本（2^128）构建统一离散分词器；2. 提出Pre-Post Distillation和Generative-Aware Prior增强语义提取和生成先验；3. 采用卷积-注意力混合架构和SigLu激活函数；4. 设计三阶段训练框架适应不同图像分辨率和感知敏感场景。
- Result: 1. ImageNet图像生成达到SOTA（FID: 1.38 vs REPA 1.42），训练计算量极低（训练token：33B vs 262B）；2. 通用领域多模态理解、图像生成（DPG Score: 86.63 vs FLUX.1 83.84）和编辑（GEdit Overall Score: 5.09 vs OmniGen 5.06）表现优异。
- Conclusion: UniWeTok成功解决了现有视觉分词器的局限性，在单一框架内实现了重建、语义提取和生成能力的平衡，为统一多模态大语言模型提供了高效的视觉表示基础。


### [103] [UniRef-Image-Edit: Towards Scalable and Consistent Multi-Reference Image Editing](https://arxiv.org/abs/2602.14186)
*Hongyang Wei,Bin Wen,Yancheng Long,Yankai Yang,Yuhang Hu,Tianke Zhang,Wei Chen,Haonan Fan,Kaiyu Jiang,Jiankang Chen,Changyi Liu,Kaiyu Tang,Haojie Ding,Xiao Yang,Jia Sun,Huaiqing Wang,Zhenyu Yang,Xinyu Wei,Xianglong He,Yangguang Li,Fan Yang,Tingting Gao,Lei Zhang,Guorui Zhou,Han Li*

Main category: cs.CV

TL;DR: UniRef-Image-Edit：统一单图编辑与多图合成的多模态生成系统，通过序列化潜在融合和两阶段训练实现跨参考图像的一致性

- Motivation: 现有基于扩散的编辑方法在处理多个参考图像时，由于参考输入之间交互有限，难以保持跨条件的一致性
- Method: 提出序列扩展潜在融合（SELF）统一输入表示，将多参考图像动态序列化为连贯的潜在序列；采用两阶段训练框架：监督微调（SFT）和强化学习（RL），其中SFT阶段使用渐进序列长度训练策略，RL阶段引入多源GRPO（MSGRPO）优化模型
- Result: 系统能够显著提升视觉保真度和跨参考一致性，有效调和冲突的视觉约束，增强合成一致性
- Conclusion: UniRef-Image-Edit为多参考图像生成提供了统一的解决方案，通过创新的序列化表示和训练策略解决了跨条件一致性问题，并将开源代码、模型和训练数据


### [104] [GeoEyes: On-Demand Visual Focusing for Evidence-Grounded Understanding of Ultra-High-Resolution Remote Sensing Imagery](https://arxiv.org/abs/2602.14201)
*Fengxiang Wang,Mingshuo Chen,Yueying Li,Yajie Yang,Yifan Zhang,Long Lan,Xue Yang,Hongda Sun,Yulin Wang,Di Wang,Jun Song,Jing Zhang,Bo Du*

Main category: cs.CV

TL;DR: GeoEyes是一个针对超高分辨率遥感VQA的MLLM训练框架，通过分阶段训练解决现有缩放工具使用同质化问题，显著提升性能

- Motivation: 现有支持缩放的MLLM在超高分辨率遥感VQA中存在工具使用同质化问题，缩放调用退化为任务无关模式，限制了有效证据获取
- Method: 提出GeoEyes分阶段训练框架：1）冷启动SFT数据集UHR-CoZ，覆盖多样化缩放机制；2）代理强化学习方法AdaZoom-GRPO，明确奖励缩放交互中的证据增益和答案改进
- Result: 模型学会了按需缩放和适当的停止行为，在超高分辨率遥感基准测试中取得显著提升，在XLRS-Bench上达到54.23%准确率
- Conclusion: GeoEyes框架有效解决了MLLM在超高分辨率遥感VQA中的缩放工具使用同质化问题，通过分阶段训练实现了更智能的视觉探索能力


### [105] [HiVid: LLM-Guided Video Saliency For Content-Aware VOD And Live Streaming](https://arxiv.org/abs/2602.14214)
*Jiahui Chen,Bo Peng,Lianchen Jia,Zeyu Zhang,Tianchi Huang,Lifeng Sun*

Main category: cs.CV

TL;DR: HiVid利用LLM作为可扩展的人类代理，为VOD和直播流媒体生成高质量的重要性权重，通过感知、排序和预测模块解决模态限制、评分不一致和低延迟挑战。

- Motivation: 内容感知流媒体需要动态的块级重要性权重来优化主观体验质量，但直接人工标注成本过高，而视觉显著性模型泛化能力差。
- Method: 1. 感知模块：在局部上下文窗口中评估帧，自回归地构建对视频的连贯理解；2. 排序模块：使用LLM引导的归并排序算法进行全局重排序；3. 预测模块：使用多模态时间序列模型预测未来权重，包含内容感知注意力和自适应时域。
- Result: HiVid将VOD权重预测准确率提升11.5%，直播流媒体提升26%，真实用户研究表明流媒体QoE相关性提升14.7%。
- Conclusion: HiVid是首个利用LLM作为可扩展人类代理生成高质量流媒体权重的框架，有效解决了内容感知流媒体的关键挑战。


### [106] [Freq-DP Net: A Dual-Branch Network for Fence Removal using Dual-Pixel and Fourier Priors](https://arxiv.org/abs/2602.14226)
*Kunal Swami,Sudha Velusamy,Chandra Sekhar Seelamantula*

Main category: cs.CV

TL;DR: 提出首个利用双像素传感器的单图像栅栏去除框架，结合几何先验和结构先验，显著超越现有方法

- Motivation: 单图像栅栏遮挡会降低视觉质量并限制下游计算机视觉应用，现有方法要么在静态场景中失败，要么需要多帧运动线索
- Method: 提出Freq-DP Net双分支网络，融合两种互补先验：基于显式代价体积的散焦视差几何先验，和基于快速傅里叶卷积的栅栏全局模式结构先验，通过注意力机制智能融合
- Result: 构建并发布了包含不同栅栏类型的多样化基准测试，实验表明该方法显著优于强大的通用基线，为基于双像素传感器的单图像栅栏去除建立了新的最先进水平
- Conclusion: 首次利用双像素传感器解决栅栏去除问题，通过融合几何和结构先验实现了高精度栅栏分割，为单图像栅栏去除提供了有效解决方案


### [107] [Learning Significant Persistent Homology Features for 3D Shape Understanding](https://arxiv.org/abs/2602.14228)
*Prachi Kudeshia,Jiju Poovvancheri*

Main category: cs.CV

TL;DR: 该论文提出了拓扑增强的3D点云数据集（ModelNet40和ShapeNet的拓扑版本），并开发了TopoGAT方法来自动选择重要的拓扑特征，提升了点云分类和分割性能。

- Motivation: 现有3D形状数据集主要关注几何信息而忽略拓扑结构，这限制了拓扑感知深度学习架构的发展。需要建立统一的几何-拓扑学习基准，并解决传统手工统计方法选择拓扑特征的局限性。
- Method: 1) 创建拓扑增强数据集：为ModelNet40和ShapeNet中的点云添加持久同调特征；2) 提出TopoGAT方法：基于深度学习自动选择重要的持久点（拓扑特征），避免手工统计标准；3) 将选择的拓扑特征集成到标准点云分类和分割流程中。
- Result: 1) 建立了首个拓扑增强的3D点云基准数据集；2) TopoGAT在稳定性和判别能力上优于传统统计方法；3) 集成拓扑特征后，点云分类准确率和分割指标均有提升；4) 实现了持久同调与深度学习工作流的有效结合。
- Conclusion: 拓扑增强数据集和可学习的特征选择方法为3D点云分析提供了统一的几何-拓扑学习框架，促进了拓扑感知深度学习架构的发展，使持久同调能更有效地集成到实际深度学习工作流中。


### [108] [Dual-Signal Adaptive KV-Cache Optimization for Long-Form Video Understanding in Vision-Language Models](https://arxiv.org/abs/2602.14236)
*Vishnu Sai,Dheeraj Sai,Srinath B,Girish Varma,Priyesh Shukla*

Main category: cs.CV

TL;DR: Sali-Cache：一种基于先验优化的双信号自适应缓存框架，通过光学流分析和显著性检测来管理长视频处理的KV缓存，在保持100%准确率的同时实现2.20倍内存压缩。

- Motivation: 视觉语言模型在处理长视频时面临KV缓存随序列长度线性增长的内存瓶颈问题，现有解决方案采用反应式淘汰策略，在计算完整注意力矩阵后才丢弃token，造成大量计算浪费。
- Method: 提出Sali-Cache先验优化框架，通过双信号自适应缓存实现主动内存管理：1）基于光学流分析的时间滤波器检测帧间冗余；2）基于显著性检测的空间滤波器识别视觉显著区域，在进入计算昂贵的注意力操作前智能管理内存分配。
- Result: 在LLaVA 1.6架构上的实验表明，该方法实现了2.20倍的有效内存使用压缩比，同时在BLEU、ROUGE-L和Exact Match指标上保持100%准确率。在相同内存预算下，Sali-Cache能够保持上下文丰富的特征而不降低模型性能。
- Conclusion: Sali-Cache通过先验内存管理有效解决了长视频处理的内存瓶颈，使视觉语言模型能够在消费级硬件上高效处理长视频内容，同时保持模型性能。


### [109] [AbracADDbra: Touch-Guided Object Addition by Decoupling Placement and Editing Subtasks](https://arxiv.org/abs/2602.14237)
*Kunal Swami,Raghu Chittersu,Yuvraj Rathore,Rajeev Irny,Shashavali Doodekula,Alok Shukla*

Main category: cs.CV

TL;DR: AbracADDbra：基于触摸先验的交互式图像编辑框架，通过直观触摸指令实现物体添加，无需繁琐的掩码输入

- Motivation: 解决传统基于文本提示的物体添加方法存在的模糊性，以及基于掩码输入方法的繁琐性问题，提升图像编辑的易用性和精确性
- Method: 采用解耦架构：1）视觉语言Transformer用于触摸引导的物体定位；2）扩散模型联合生成物体和实例掩码，实现高质量融合。同时贡献了Touch2Add基准数据集
- Result: 定位模型显著优于随机放置和通用VLM基线，能够生成高保真度编辑效果。分析显示初始定位准确性与最终编辑质量强相关，验证了解耦方法的有效性
- Conclusion: 该工作为更易用、高效的创意工具铺平了道路，通过直观的触摸交互提升了图像编辑的可用性和精确性


### [110] [Moving Beyond Sparse Grounding with Complete Screen Parsing Supervision](https://arxiv.org/abs/2602.14276)
*A. Said Gurbuz,Sunghwan Hong,Ahmed Nassar,Marc Pollefeys,Peter Staar*

Main category: cs.CV

TL;DR: ScreenParse：大规模屏幕解析数据集与ScreenVLM模型，用于密集标注UI元素，提升计算机使用代理的屏幕理解能力

- Motivation: 现有屏幕标注数据集监督稀疏，仅标注任务相关元素子集，限制了覆盖范围和泛化能力；同时实际部署需要低延迟的本地使用效率
- Method: 提出ScreenParse数据集（77.1万网页截图，2100万元素），通过Webshot自动化流水线生成；训练ScreenVLM模型（3.16亿参数），使用ScreenTag标记表示和结构感知损失函数
- Result: ScreenVLM在密集解析任务上大幅超越大型基础VLM（PageIoU 0.592 vs 0.294），在公开基准测试中表现优异；在ScreenParse上微调基础VLM能持续提升其接地性能
- Conclusion: 密集屏幕监督为UI理解提供了可迁移的结构先验知识，ScreenParse数据集和ScreenVLM模型能有效提升计算机使用代理的屏幕感知能力


### [111] [Differential pose optimization in descriptor space -- Combining Geometric and Photometric Methods for Motion Estimation](https://arxiv.org/abs/2602.14297)
*Andreas L. Teigen,Annette Stahl,Rudolf Mester*

Main category: cs.CV

TL;DR: 论文提出了一种结合光度误差和重投影误差优点的第三种相对位姿优化方法，使用密集几何特征描述子替代光度误差，但实验表明该方法在性能上并未超越基于重投影误差的方法。

- Motivation: 计算机视觉中两帧相对位姿优化问题通常使用光度误差或重投影误差，两者各有优劣（精度、鲁棒性、闭环可能性）。作者希望结合两种范式的优势，提出统一的优化方法。
- Method: 使用密集采样的几何特征描述子，将光度误差替换为描述子残差。这样既能利用微分光度方法的亚像素精度，又能利用几何特征描述子的表达能力。
- Result: 实验表明，虽然提出的方法是一种有趣的方法并能实现精确跟踪，但最终在性能上并未超越基于重投影误差的位姿优化策略，尽管利用了更多信息。
- Conclusion: 分析发现描述子相似性度量变化过于缓慢，不一定严格对应关键点定位精度，这可能是该方法未能超越传统方法的原因。需要进一步研究描述子相似性与几何精度之间的对应关系。


### [112] [A Generative AI Approach for Reducing Skin Tone Bias in Skin Cancer Classification](https://arxiv.org/abs/2602.14356)
*Areez Muhammed Shabu,Mohammad Samar Ansari,Asra Aslam*

Main category: cs.CV

TL;DR: 使用Stable Diffusion和LoRA生成深色皮肤合成图像，通过数据增强改善皮肤癌检测的公平性和准确性

- Motivation: 当前AI皮肤癌诊断工具主要基于浅色皮肤图像训练（ISIC数据集中浅色皮肤占70%以上，深色皮肤不足8%），导致对深色皮肤人群的诊断准确性和公平性降低，需要解决医疗影像中的肤色不平衡问题
- Method: 提出生成式数据增强流程：使用LoRA微调预训练的Stable Diffusion模型，在ISIC数据集的深色皮肤子集上训练，生成基于病变类型和肤色的合成皮肤镜图像
- Result: 在病变分割任务中，使用增强数据集训练的模型在IoU、Dice系数和边界准确性方面均有提升；在二元分类任务中，EfficientNet-B0模型达到92.14%的准确率
- Conclusion: 生成式AI的合成数据增强能显著减少传统皮肤科诊断中的偏见，提高公平性，为未来研究方向开辟了新的挑战


### [113] [Image-based Joint-level Detection for Inflammation in Rheumatoid Arthritis from Small and Imbalanced Data](https://arxiv.org/abs/2602.14365)
*Shun Kato,Yasushi Kondo,Shuntaro Saito,Yoshimitsu Aoki,Mariko Isogawa*

Main category: cs.CV

TL;DR: 该论文提出了一种基于RGB手部图像的类风湿关节炎炎症检测框架，通过自监督预训练和类别不平衡处理，在F1分数和Gmean指标上相比基线模型分别提升了0.2和0.25个点。

- Motivation: 类风湿关节炎（RA）是一种自身免疫性疾病，早期诊断和密切随访对管理至关重要。患者往往需要很长时间才能获得专科治疗，因此需要开发能够通过家庭拍摄的RGB图像轻松检测关节炎症的系统。然而，现有工作尚未明确解决RGB图像中RA炎症检测面临的样本稀缺、数据不平衡等挑战。
- Method: 构建专门的RA炎症检测数据集，提出一个包含全局局部编码器的炎症检测框架。该方法结合了在大规模健康手部图像上的自监督预训练和针对类别不平衡的训练策略，从RGB手部图像中检测RA相关的关节炎症。
- Result: 实验表明，与基线模型相比，所提出的方法在F1分数上提高了0.2个点，在Gmean指标上提高了0.25个点，有效改善了RA炎症的检测性能。
- Conclusion: 该研究通过定量分析证明了视觉检测炎症的难度，并提出了一种有效的RA炎症检测框架，为解决医疗图像分析中的样本稀缺和数据不平衡问题提供了可行方案，有助于实现基于RGB图像的早期RA诊断和监测。


### [114] [Event-based Visual Deformation Measurement](https://arxiv.org/abs/2602.14376)
*Yuliang Wu,Wei Zhai,Yuxin Cui,Tiesong Zhao,Yang Cao,Zheng-Jun Zha*

Main category: cs.CV

TL;DR: 提出事件-帧融合框架，利用事件提供密集时间运动线索，结合帧提供空间精确估计，实现高效视觉变形测量

- Motivation: 传统基于图像的方法依赖帧间微小运动来约束对应搜索空间，这限制了其在高度动态场景中的应用，或需要高速相机带来巨大的存储和计算开销
- Method: 1) 事件-帧融合框架：利用事件提供时间密集运动线索，帧提供空间密集精确估计；2) 仿射不变单纯形(AIS)框架：将变形场划分为线性化子区域，使用低参数表示；3) 邻域贪婪优化策略：让收敛良好的子区域指导收敛较差的邻居，抑制长期密集跟踪中的局部误差累积
- Result: 在包含120多个序列的基准数据集上，方法在生存率上优于最先进基线1.6%，同时仅使用高速视频方法18.9%的数据存储和处理资源
- Conclusion: 提出的AIS框架通过事件-帧融合和邻域贪婪优化，在保持高精度的同时显著降低了计算和存储需求，为视觉变形测量提供了高效解决方案


### [115] [Adapting VACE for Real-Time Autoregressive Video Diffusion](https://arxiv.org/abs/2602.14381)
*Ryan Fosdick*

Main category: cs.CV

TL;DR: 将VACE视频生成框架适配为实时自回归版本，通过将参考帧移至并行条件通路，保持固定块大小和KV缓存，实现无需额外训练的重用预训练权重

- Motivation: 原始VACE支持统一视频控制（参考引导、结构条件、修复、时间扩展），但依赖全序列双向注意力，不兼容需要固定块大小和因果注意力的流式管道
- Method: 关键修改：将参考帧从扩散潜在空间移至并行条件通路，保持固定块大小和KV缓存，重用现有预训练VACE权重无需额外训练
- Result: 在13亿和140亿参数规模上，VACE为结构控制和修复增加20-30%延迟开销，VRAM成本可忽略；但参考到视频的保真度因因果注意力限制而严重下降
- Conclusion: 成功将VACE适配为实时自回归视频生成，实现了流式兼容但牺牲了参考引导质量，提供了开源实现


### [116] [Multi-Turn Adaptive Prompting Attack on Large Vision-Language Models](https://arxiv.org/abs/2602.14399)
*In Chong Choi,Jiacheng Zhang,Feng Liu,Yiliao Song*

Main category: cs.CV

TL;DR: MAPA是一种针对大型视觉语言模型的多轮自适应提示攻击方法，通过交替文本-视觉攻击动作和跨轮迭代优化，显著提高了对安全对齐LVLMs的攻击成功率。

- Motivation: 现有针对纯文本LLMs的多轮越狱攻击在扩展到视觉语言模型时效果不佳，因为过于恶意的视觉输入容易触发安全防御机制，导致模型响应更加保守。
- Method: 提出MAPA方法：1) 在每一轮中交替使用文本和视觉攻击动作以获取最恶意的响应；2) 跨轮通过迭代来回优化调整攻击轨迹，逐步放大响应的恶意程度。
- Result: MAPA在多个最新基准测试中显著优于现有方法，对LLaVA-V1.6-Mistral-7B、Qwen2.5-VL-7B-Instruct、Llama-3.2-Vision-11B-Instruct和GPT-4o-mini的攻击成功率提高了11-35%。
- Conclusion: MAPA通过两层级设计有效解决了视觉语言模型的安全防御挑战，为评估和改进LVLMs的安全性提供了重要方法。


### [117] [pFedNavi: Structure-Aware Personalized Federated Vision-Language Navigation for Embodied AI](https://arxiv.org/abs/2602.14401)
*Qingqian Yang,Hao Wang,Sai Qian Zhang,Jian Li,Yang Hua,Miao Pan,Tao Song,Zhengwei Qi,Haibing Guan*

Main category: cs.CV

TL;DR: pFedNavi：一种面向视觉语言导航的个性化联邦学习框架，通过自适应识别客户端特定层和细粒度参数融合，解决跨客户端异构性问题，显著提升导航性能。

- Motivation: 视觉语言导航需要大量室内环境轨迹指令数据，存在隐私问题。联邦学习虽然能保护隐私，但传统联邦学习在VLN的极端跨客户端异构性（环境和指令风格）下表现不佳，单一全局模型不适用。
- Method: 提出pFedNavi框架：1）通过层间混合系数自适应识别客户端特定层；2）对选定组件（如编码器-解码器投影层和环境敏感解码器层）进行细粒度参数融合，平衡全局知识共享与本地专业化。
- Result: 在R2R和RxR两个标准VLN基准测试中，使用ResNet和CLIP视觉表示，pFedNavi在所有指标上均优于基于FedAvg的VLN基线：导航成功率提升高达7.5%，轨迹保真度提升高达7.8%，在非独立同分布条件下收敛速度加快1.38倍。
- Conclusion: pFedNavi有效解决了VLN中的跨客户端异构性问题，通过个性化联邦学习框架显著提升了导航性能，同时保护了数据隐私，为隐私敏感的视觉语言导航任务提供了实用解决方案。


### [118] [Feature Recalibration Based Olfactory-Visual Multimodal Model for Fine-Grained Rice Deterioration Detection](https://arxiv.org/abs/2602.14408)
*Rongqiang Zhao,Hengrui Hu,Yijing Wang,Mingchun Sun,Jie Liu*

Main category: cs.CV

TL;DR: 提出基于特征重校准的嗅觉-视觉多模态模型，用于细粒度大米变质检测，通过重构标注多模态嵌入特征数据集和注意力网络增强对细微变质特征的敏感性，达到99.89%的分类准确率。

- Motivation: 现有大米变质检测的多模态方法在表示和提取细粒度异常特征方面能力有限，且依赖昂贵设备（如高光谱相机、质谱仪），增加了检测成本和数据获取时间。
- Method: 提出细粒度变质嵌入构造器（FDEC）重构标注多模态嵌入特征数据集，增强样本表示；提出细粒度变质重校准注意力网络（FDRA-Net）强调信号变化并增加对大米表面细粒度变质的敏感性。
- Result: 实验显示该方法达到99.89%的分类准确率，相比现有方法提高了检测精度并简化了流程，现场检测也显示出准确性和操作简便性的优势。
- Conclusion: 该方法能有效解决大米变质检测中的细粒度特征提取问题，降低检测成本，并可扩展到农业和食品工业中的其他农产品检测。


### [119] [Learning Proposes, Geometry Disposes: A Modular Framework for Efficient Spatial Reasoning](https://arxiv.org/abs/2602.14409)
*Haichao Zhu,Zhaorui Yang,Qian Zhang*

Main category: cs.CV

TL;DR: 论文提出一个端到端模块化框架，将学习组件作为几何假设生成器，几何算法作为决策器，在RGB-D相机位姿估计任务中验证了这种设计的有效性。

- Motivation: 研究学习组件在空间感知系统中应该直接替代几何估计还是作为中间模块，探索如何有效结合学习方法和几何算法。
- Method: 使用VGGT作为学习模型生成相机位姿和深度假设，然后用经典的点到平面RGB-D ICP作为几何后端进行决策，在TUM RGB-D基准上进行评估。
- Result: 发现：1）仅学习位姿提议不可靠；2）学习提议的几何若与相机内参不对齐会降低性能；3）当学习提议的深度经过几何对齐并由几何后端处理时，在中等挑战的刚性场景中表现提升。
- Conclusion: 几何不仅是细化组件，更是验证和吸收学习几何观测的关键仲裁者，模块化、几何感知的系统设计对鲁棒空间感知至关重要。


### [120] [Understanding Sensor Vulnerabilities in Industrial XR Tracking](https://arxiv.org/abs/2602.14413)
*Sourya Saha,Md. Nurul Absur*

Main category: cs.CV

TL;DR: XR系统中VIO在传感器退化条件下的实证研究：视觉退化导致厘米级误差，惯性退化可导致数百至数千米轨迹偏差，需重视惯性可靠性

- Motivation: 工业XR系统依赖VIO进行姿态跟踪，但实际环境常偏离理想传感条件。现有VIO评估多关注正常传感器行为，对持续传感器退化在操作条件下的影响理解不足
- Method: 通过系统性的故障注入和定量评估，研究VIO在退化传感条件下的行为，考察影响视觉和惯性模态的各种故障在不同操作状态下的表现
- Result: 发现故障影响存在明显不对称性：影响视觉传感的退化通常导致厘米级的有界姿态误差，而影响惯性传感的退化可导致显著更大的轨迹偏差，某些情况下可达数百至数千米
- Conclusion: 这些观察结果促使在XR系统的评估和设计中更加重视惯性可靠性，特别是在现实工业环境中


### [121] [Hierarchical Vision-Language Interaction for Facial Action Unit Detection](https://arxiv.org/abs/2602.14425)
*Yong Li,Yi Ren,Yizhe Zhang,Wenhua Zhang,Tianyi Zhang,Muyun Jiang,Guo-Sen Xie,Cuntai Guan*

Main category: cs.CV

TL;DR: 提出HiVA方法，利用文本AU描述作为语义先验指导AU检测，通过层次化视觉-语言交互增强AU表示学习

- Motivation: AU检测面临标注数据有限的问题，需要学习具有判别性和泛化性的AU表示。文本AU描述可作为语义先验来增强AU检测
- Method: HiVA方法：1) 使用大语言模型生成多样化的AU描述；2) AU感知动态图模块学习AU特定视觉表示；3) 层次化跨模态注意力架构，包括细粒度AU特定交互的DDCA和建模全局AU依赖的CDCA
- Result: 实验显示HiVA持续超越最先进方法，定性分析表明HiVA产生语义有意义的激活模式，学习到鲁棒且可解释的跨模态对应关系
- Conclusion: HiVA通过层次化视觉-语言交互，利用文本AU描述作为语义先验，有效提升了AU检测性能，实现了鲁棒且语义丰富的AU检测能力


### [122] [D-SECURE: Dual-Source Evidence Combination for Unified Reasoning in Misinformation Detection](https://arxiv.org/abs/2602.14441)
*Gagandeep Singh,Samudi Amarasinghe,Priyanka Singh*

Main category: cs.CV

TL;DR: D-SECURE是一个结合内部篡改检测和外部证据推理的多模态虚假信息检测框架，通过整合HAMMER篡改检测器和DEFAME检索管道，解决现有系统单证据源的局限性。

- Motivation: 当前多模态虚假信息将逼真的图像编辑与流畅但误导性文本结合，难以验证。现有系统依赖单一证据源：基于内容的检测器只能识别局部不一致性，无法确定全局事实真相；基于检索的事实核查器处理粗粒度声明，常忽略细微的视觉或文本篡改。这种分离导致失败案例：内部一致的伪造内容绕过篡改检测器，而事实核查器可能验证包含像素级或令牌级损坏的声明。
- Method: 提出D-SECURE框架，整合HAMMER篡改检测器与DEFAME检索管道。DEFAME执行广泛的验证，HAMMER分析残留或不确定案例中可能包含的细粒度编辑。提供统一的、可解释的报告，结合篡改线索和外部证据。
- Result: 在DGM4和ClaimReview样本上的实验展示了两个系统的互补优势，并验证了它们融合的动机。
- Conclusion: 通过结合内部篡改检测和外部证据推理，D-SECURE能够更有效地检测多模态虚假信息，提供更全面的验证能力。


### [123] [Controlling Your Image via Simplified Vector Graphics](https://arxiv.org/abs/2602.14443)
*Lanqing Guo,Xi Liu,Yufei Wang,Zhihao Li,Siyu Huang*

Main category: cs.CV

TL;DR: 提出Vec2Pix框架，通过矢量图形实现分层可控的图像生成，支持元素级编辑如调整形状、颜色、添加/移除对象

- Motivation: 现有图像生成技术视觉质量显著，但缺乏元素级控制能力，无法直观修改形状、颜色或对象。需要一种能够实现分层可控生成的方法
- Method: 1) 将图像高效解析为语义对齐、结构连贯的分层矢量图形表示；2) 设计基于矢量图形引导的图像合成框架，允许用户自由修改元素并转换为逼真输出；3) 结合矢量图形的结构语义特征和噪声预测，实现几何、颜色和对象语义的精确控制
- Result: 在图像编辑、对象级操作和细粒度内容创建等多样化应用中验证了方法的有效性，建立了可控图像生成的新范式
- Conclusion: 通过矢量图形实现分层可控图像生成，为元素级图像控制提供了新解决方案，支持直观的形状、颜色和对象编辑


### [124] [CoCoDiff: Correspondence-Consistent Diffusion Model for Fine-grained Style Transfer](https://arxiv.org/abs/2602.14464)
*Wenbo Nie,Zixiang Li,Renshuai Tao,Bin Wu,Yunchao Wei,Yao Zhao*

Main category: cs.CV

TL;DR: CoCoDiff：无需训练的细粒度语义一致风格迁移框架，利用预训练扩散模型实现像素级语义对齐

- Motivation: 现有风格迁移方法多关注全局层面，忽略了区域级和像素级的语义对应关系，导致语义一致性不足
- Method: 1. 像素级语义对应模块：挖掘扩散模型中间特征构建内容与风格图像的密集对齐映射
2. 循环一致性模块：跨迭代强制执行结构和感知对齐，保持几何和细节
- Result: 无需额外训练或监督，在视觉质量和定量结果上达到SOTA，优于依赖额外训练或标注的方法
- Conclusion: CoCoDiff证明了预训练扩散模型中存在被忽视的对应线索，通过挖掘这些特征可以实现细粒度语义一致的风格迁移


### [125] [TikArt: Aperture-Guided Observation for Fine-Grained Visual Reasoning via Reinforcement Learning](https://arxiv.org/abs/2602.14482)
*Hao Ding,Zhichuan Yang,Weijie Ge,Ziqin Gao,Chaoyi Lu,Lei Zhao*

Main category: cs.CV

TL;DR: TikArt是一个基于多模态大语言模型的细粒度视觉推理框架，通过"思考-孔径-观察"循环，使用缩放和分割两种孔径动作来聚焦图像关键区域，结合强化学习优化推理策略，在多个细粒度视觉任务上取得显著提升。

- Motivation: 现有MLLMs使用单一全局图像编码时，会丢失微小物体、杂乱区域或细微标记等关键证据，无法进行有效的细粒度视觉推理。
- Method: 提出TikArt框架，采用Think-Aperture-Observe循环：语言生成与两种孔径动作交替进行（Zoom提取矩形裁剪，Segment调用SAM2获取掩码裁剪），每次动作后生成显式观察将视觉线索转为语言记忆。基于Qwen3-VL-8B构建，使用AGRPO强化学习算法优化推理策略，采用两阶段课程学习。
- Result: 在V*、HR-Bench-4K/8K、MME-RealWorld-Lite、MMStar、RefCOCO和ReasonSeg等多个细粒度视觉推理基准上，相比骨干模型取得一致性能提升，并生成可解释的孔径轨迹用于高分辨率推理。
- Conclusion: TikArt通过孔径引导的决策过程有效解决了MLLMs中的细粒度视觉推理问题，将局部视觉线索转化为持久语言记忆，结合强化学习优化策略，在多个任务上验证了其有效性。


### [126] [Gaussian Mesh Renderer for Lightweight Differentiable Rendering](https://arxiv.org/abs/2602.14493)
*Xinpeng Liu,Fumio Okura*

Main category: cs.CV

TL;DR: 提出Gaussian Mesh Renderer (GMR)，将3DGS的高效光栅化过程与传统网格表示结合，实现轻量级可微分网格渲染器

- Motivation: 传统三角形网格模型在表面重建中仍很流行，但传统基于网格的可微分渲染器存在优化缓慢或计算量大的问题。3DGS虽然实现了快速渲染和优化，但需要与网格表示更好地结合。
- Method: 提出Gaussian Mesh Renderer (GMR)，利用3DGS的高效光栅化过程，将高斯基元从对应的网格三角形中解析推导出来，保持结构保真度并实现梯度流动。
- Result: 相比传统网格渲染器，该方法实现了更平滑的梯度，特别有助于在有限内存下使用小批量进行更好的优化。
- Conclusion: GMR成功地将高斯和网格表示紧密集成，提供了一种轻量级可微分网格渲染解决方案，代码已在GitHub开源。


### [127] [Uncertainty-Aware Vision-Language Segmentation for Medical Imaging](https://arxiv.org/abs/2602.14498)
*Aryan Das,Tanishq Rachamalla,Koushik Biswas,Swalpa Kumar Roy,Vinay Kumar Verma*

Main category: cs.CV

TL;DR: 提出一种不确定性感知的多模态分割框架，结合医学影像和临床文本，通过模态解码注意力块和谱熵不确定性损失提升分割精度和可靠性。

- Motivation: 在医学诊断中，图像质量不佳时单模态方法可靠性有限，需要结合临床文本等多模态信息，并考虑预测不确定性以提高模型鲁棒性。
- Method: 提出Modality Decoding Attention Block (MoDAB)和轻量级State Space Mixer (SSMix)实现跨模态融合和长程依赖建模；设计Spectral-Entropic Uncertainty (SEU) Loss联合捕捉空间重叠、谱一致性和预测不确定性。
- Result: 在QATA-COVID19、MosMed++、Kvasir-SEG等公开医学数据集上取得优于现有方法的分割性能，同时计算效率显著更高。
- Conclusion: 不确定性建模和结构化模态对齐在视觉-语言医学分割任务中至关重要，提出的框架在复杂临床场景下提高了模型可靠性。


### [128] [Prototype Instance-semantic Disentanglement with Low-rank Regularized Subspace Clustering for WSIs Explainable Recognition](https://arxiv.org/abs/2602.14501)
*Chentao Li,Pan Huang*

Main category: cs.CV

TL;DR: 提出PID-LRSC框架，通过低秩正则化子空间聚类解决病理图像中肿瘤与非肿瘤实例比例失衡问题，通过原型实例语义解耦解决肿瘤与癌前病变相似性问题，提升模型性能和可解释性。

- Motivation: 病理诊断中肿瘤区域是关键，但肿瘤组织与癌前病变高度相似，且全切片图像中非肿瘤实例通常远多于肿瘤实例，导致多实例学习框架中出现实例-语义纠缠问题，降低模型表示能力和可解释性。
- Method: 提出端到端的原型实例语义解耦框架PID-LRSC：1) 使用二次实例子空间学习构建低秩正则化子空间聚类(LRSC)，解决非肿瘤实例比例过高导致的实例纠缠；2) 采用增强对比学习设计原型实例语义解耦(PID)，解决肿瘤与癌前组织相似性导致的语义纠缠。
- Result: 在多中心病理数据集上进行广泛实验，结果表明PID-LRSC优于其他SOTA方法，在决策过程中提供更清晰的实例语义，显著增强辅助诊断结果的可靠性。
- Conclusion: PID-LRSC框架有效解决了病理图像分析中的实例-语义纠缠问题，提升了模型性能和可解释性，为可靠的辅助诊断提供了有效解决方案。


### [129] [MacNet: An End-to-End Manifold-Constrained Adaptive Clustering Network for Interpretable Whole Slide Image Classification](https://arxiv.org/abs/2602.14509)
*Mingrui Ma,Chentao Li,Pan Huang,Jing Qin*

Main category: cs.CV

TL;DR: 提出端到端多示例学习框架，结合Grassmann重嵌入和流形自适应聚类，提升WSI病理图像分级准确性和可解释性

- Motivation: 现有WSI分析方法存在局限性：两阶段框架使用无领域知识的离线特征编码器；注意力MIL方法结果导向但可解释性有限；聚类方法可解释但受高维特征和语义模糊中心点影响
- Method: 端到端MIL框架，集成Grassmann重嵌入和流形自适应聚类，利用流形几何结构增强聚类鲁棒性；设计先验知识引导的代理实例标注和聚合策略，近似补丁标签并聚焦病理相关肿瘤区域
- Result: 在多中心WSI数据集上验证：1) 聚类整合模型在分级准确性和可解释性方面均表现优异；2) 端到端学习能优化特征表示，且计算资源需求可接受
- Conclusion: 提出的端到端框架通过结合几何结构和先验知识，在保持可解释性的同时提升了WSI病理图像分析的性能


### [130] [MedVAR: Towards Scalable and Efficient Medical Image Generation via Next-scale Autoregressive Prediction](https://arxiv.org/abs/2602.14512)
*Zhicheng He,Yunpeng Zhao,Junde Wu,Ziwei Niu,Zijun Li,Lanfen Lin,Yueming Jin*

Main category: cs.CV

TL;DR: MedVAR是首个基于自回归的医学图像生成基础模型，采用多尺度预测范式实现快速可扩展的医学图像合成，在440,000张CT和MRI图像上训练，在保真度、多样性和可扩展性方面达到SOTA性能。

- Motivation: 医学图像生成在数据增强和隐私保护数据共享中至关重要，但现有方法在架构效率、多器官数据和系统评估方面存在不足，需要开发可扩展的生成基础模型。
- Method: 提出MedVAR自回归基础模型，采用多尺度预测范式，从粗到细生成图像，产生结构化多尺度表示。构建包含约440,000张CT和MRI图像的数据集，涵盖六个解剖区域。
- Result: 在保真度、多样性和可扩展性方面的综合实验表明，MedVAR实现了最先进的生成性能，为未来医学生成基础模型提供了有前景的架构方向。
- Conclusion: MedVAR是首个基于自回归的医学图像生成基础模型，通过多尺度预测范式实现了高效可扩展的医学图像合成，在多个评估维度上表现出色，为医学生成AI提供了新的架构方向。


### [131] [Efficient Text-Guided Convolutional Adapter for the Diffusion Model](https://arxiv.org/abs/2602.14514)
*Aryan Das,Koushik Biswas,Swalpa Kumar Roy,Badri Narayana Patro,Vinay Kumar Verma*

Main category: cs.CV

TL;DR: 提出Nexus Adapters，一种文本引导的高效适配器，用于扩散模型的结构保持条件生成，相比现有方法参数更少且性能更好。

- Motivation: 现有结构保持方法存在两个主要问题：1) 效率低下，适配器参数与基础模型相当；2) 适配器不了解输入提示，仅针对结构输入优化。需要更高效且能理解多模态输入的适配器。
- Method: 提出两种高效适配器：Nexus Prime和Nexus Slim。每个Nexus块包含交叉注意力机制，实现丰富的多模态条件控制，使适配器能同时理解输入提示和结构信息。
- Result: Nexus Prime仅需8M额外参数，性能显著优于基线T2I-Adapter；Nexus Slim比T2I-Adapter少18M参数，仍能达到最先进的结果。
- Conclusion: Nexus Adapters通过文本引导和交叉注意力机制，实现了高效的结构保持条件生成，在参数效率和性能方面都优于现有方法。


### [132] [Architectural Insights for Post-Tornado Damage Recognition](https://arxiv.org/abs/2602.14523)
*Robinson Umeike,Thang Dao,Shane Crawford,John van de Lindt,Blythe Johnston,Wanting,Wang,Trung Do,Ajibola Mofikoya,Sarbesh Banjara,Cuong Pham*

Main category: cs.CV

TL;DR: 论文系统评估了79个深度学习模型在龙卷风建筑损坏评估任务上的表现，发现优化器选择比架构选择更重要，SGD优化器和低学习率能显著提升性能，ConvNeXt-Base模型在跨事件评估中表现最佳。

- Motivation: 龙卷风后快速准确的建筑损坏评估对于搜救、资源分配和社区恢复至关重要，但现有自动化方法难以处理龙卷风破坏的视觉复杂性，主要因为标准预训练数据集的领域偏移和真实灾难数据的极端类别不平衡。
- Method: 提出了一个系统实验框架，评估了79个开源深度学习模型（包括CNN和Vision Transformer），在新建的Quad-State Tornado Damage基准数据集上进行了2300多次控制实验，重点研究了架构与优化的交互作用。
- Result: 优化器选择比架构更重要：从Adam切换到SGD使Vision Transformer和Swin Transformer的F1分数提升25-38点；低学习率（1x10^(-4)）使所有架构平均F1提升10.2点；最佳模型ConvNeXt-Base在跨事件测试中达到46.4% Macro F1（比基线提升34.6点）和85.5% Ordinal Top-1准确率。
- Conclusion: 实现操作级性能的关键在于架构与优化的复杂交互，而非单纯架构选择。优化器选择可以比架构选择产生更大影响，这一发现对灾难响应中的深度学习应用具有重要意义。


### [133] [Error Patterns in Historical OCR: A Comparative Analysis of TrOCR and a Vision-Language Model](https://arxiv.org/abs/2602.14524)
*Ari Vesalainen,Eetu Mäkelä,Laura Ruotsalainen,Mikko Tolonen*

Main category: cs.CV

TL;DR: 比较TrOCR和Qwen在18世纪英文文本OCR中的表现，发现虽然Qwen整体准确率更高，但会静默修改历史重要形式，而TrOCR保持拼写保真度更好但错误传播风险更高

- Motivation: 18世纪印刷文本的OCR仍然具有挑战性，虽然基于Transformer的OCR系统和视觉语言模型取得了较高的整体准确率，但字符错误率（CER）和词错误率（WER）等指标对于学术使用的可靠性提供有限洞察
- Method: 使用长度加权准确度指标和假设驱动的错误分析，比较专门的OCR Transformer（TrOCR）和通用视觉语言模型（Qwen）在线级历史英文文本上的表现
- Result: Qwen实现了更低的CER/WER和对退化输入更强的鲁棒性，但表现出选择性语言正则化和拼写规范化，可能静默改变历史重要形式。TrOCR更一致地保持拼写保真度，但更容易出现级联错误传播
- Conclusion: 架构归纳偏差以系统方式塑造OCR错误结构。具有相似整体准确率的模型在错误局部性、可检测性和下游学术风险方面可能存在显著差异，强调在历史数字化工作流程中需要进行架构感知评估


### [134] [Cross-view Domain Generalization via Geometric Consistency for LiDAR Semantic Segmentation](https://arxiv.org/abs/2602.14525)
*Jindong Zhao,Yuan Gao,Yang Xia,Sheng Nie,Jun Yue,Weiwei Sun,Shaobo Xia*

Main category: cs.CV

TL;DR: 提出CVGC框架解决跨视角LiDAR语义分割的域泛化问题，通过几何增强和一致性约束提升模型在不同采集视角下的泛化能力。

- Motivation: 现有LiDAR语义分割域泛化方法假设相似的采集视角（如车载），但在跨视角场景中表现不佳，因为不同视角会导致结构不完整性和点密度不均匀等问题。
- Method: 提出CVGC框架：1) 跨视角几何增强模块，模拟视角变化引起的可见性和采样密度变化；2) 几何一致性模块，强制同一场景不同几何增强点云的语义和占用预测保持一致。
- Result: 在六个公开LiDAR数据集上的实验表明，CVGC在从单一源域泛化到多个具有异构采集视角的目标域时，始终优于现有最先进方法。
- Conclusion: CVGC为跨视角LiDAR语义分割域泛化提供了首个系统评估框架，通过几何一致性约束有效提升了模型在不同采集视角下的泛化性能。


### [135] [MoRL: Reinforced Reasoning for Unified Motion Understanding and Generation](https://arxiv.org/abs/2602.14534)
*Hongpeng Wang,Zeyu Zhang,Wenhao Li,Hao Tang*

Main category: cs.CV

TL;DR: MoRL是一个统一的多模态运动模型，通过监督微调和强化学习训练，结合特定任务奖励设计，提升运动理解和生成的能力，并引入Chain-of-Motion推理方法增强推理能力。

- Motivation: 当前人类运动理解和生成在推理能力和测试时规划方面存在局限，需要更强大的逻辑推理和感知真实性。
- Method: 提出MoRL统一多模态运动模型，采用监督微调和强化学习训练，设计特定任务奖励（语义对齐、推理连贯性、物理合理性、文本-运动一致性），并引入Chain-of-Motion测试时推理方法进行逐步规划和反思。
- Result: 在HumanML3D和KIT-ML数据集上实验表明，MoRL相比最先进基线方法取得显著提升。
- Conclusion: MoRL通过强化学习奖励设计和Chain-of-Motion推理方法，有效提升了人类运动理解和生成的推理能力和感知真实性。


### [136] [OmniVTON++: Training-Free Universal Virtual Try-On with Principal Pose Guidance](https://arxiv.org/abs/2602.14552)
*Zhaotong Yang,Yong Du,Shengfeng He,Yuhui Li,Xinzhe Li,Yangyang Xu,Junyu Dong,Jian Yang*

Main category: cs.CV

TL;DR: OmniVTON++是一个无需训练的通用虚拟试穿框架，通过结构化服装变形、主姿态引导和连续边界缝合技术，在多种场景下实现高质量的服装试穿合成。

- Motivation: 现有虚拟试穿方法通常针对特定数据条件优化，部署时需要重新训练，限制了其作为统一解决方案的泛化能力。需要开发一个无需训练、具有通用性的框架。
- Method: 提出三个核心技术：1) 结构化服装变形实现对应驱动的服装适配；2) 主姿态引导在扩散采样过程中进行逐步结构调控；3) 连续边界缝合进行边界感知的细化，形成一个无需任务特定重新训练的完整流程。
- Result: 在跨数据集和跨服装类型的评估中达到最先进性能，可靠地在多种场景和扩散骨干网络中运行。除了单服装单人物外，还支持多服装、多人物和动漫角色虚拟试穿。
- Conclusion: OmniVTON++是一个无需训练的通用虚拟试穿框架，通过协调三个核心技术解决了服装对齐、人体结构一致性和边界连续性的挑战，显著扩展了虚拟试穿的应用范围。


### [137] [DriveFine: Refining-Augmented Masked Diffusion VLA for Precise and Robust Driving](https://arxiv.org/abs/2602.14577)
*Chenxu Dang,Sining Ang,Yongkang Li,Haochen Tian,Jie Wang,Guang Li,Hangjun Ye,Jie Ma,Long Chen,Yan Wang*

Main category: cs.CV

TL;DR: DriveFine提出了一种用于自动驾驶的掩码扩散VLA模型，结合了灵活解码与自校正能力，通过block-MoE架构和混合强化学习策略，在多个基准测试中表现出色。

- Motivation: 当前自动驾驶的VLA模型存在两大主流范式：扩散式规划器存在模态对齐困难、训练效率低、泛化有限的问题；基于token的规划器则受累积因果错误和不可逆解码的困扰。这两种范式具有互补的优缺点，需要一种结合两者优势的新方法。
- Method: 提出DriveFine模型，采用掩码扩散VLA架构。核心创新包括：1) block-MoE设计，在生成专家之上无缝注入细化专家，通过推理时的显式专家选择和训练时的梯度阻断实现完全解耦；2) 混合强化学习策略，鼓励细化专家的有效探索同时保持训练稳定性。
- Result: 在NAVSIM v1、v2和Navhard基准测试上的广泛实验表明，DriveFine表现出强大的效能和鲁棒性。block-MoE设计保留了预训练权重的基础能力和通用模式，展现了灵活性和可扩展性。
- Conclusion: DriveFine成功结合了扩散式规划和token式规划的优势，通过创新的block-MoE架构和混合强化学习策略，解决了现有方法的局限性，为自动驾驶VLA模型提供了更有效的解决方案。


### [138] [YOLO26: A Comprehensive Architecture Overview and Key Improvements](https://arxiv.org/abs/2602.14582)
*Priyanto Hidayatullah,Refdinal Tubagus*

Main category: cs.CV

TL;DR: YOLO26是YOLO系列最新版本，通过消除DFL、实现端到端NMS-Free推理、引入ProgLoss+STAL标签分配、使用MuSGD优化器等改进，在CPU模式下推理速度提升43%，旨在实现边缘设备的实时性能。

- Motivation: YOLO作为计算机视觉领域的领先模型已有十年历史，但现有技术文档通常只提供表面信息。本研究旨在深入探索YOLO26的架构细节，特别是其源代码中未充分提取的真实运行机制，为研究人员和开发者提供精确的架构理解。
- Method: 通过严格的架构调查，主要利用GitHub仓库中的源代码和官方文档进行分析。研究提取了YOLO26的CNN架构图，这是首次展示YOLO26基于CNN的核心架构。
- Result: 成功呈现了YOLO26的架构图，揭示了其消除DFL、端到端NMS-Free推理、ProgLoss+STAL标签分配、MuSGD优化器等关键改进。这些改进使YOLO26在CPU模式下推理速度提升43%，并在实例分割、姿态估计、定向边界框解码等多个计算机视觉任务上有所改进。
- Conclusion: 本研究首次详细展示了YOLO26的CNN架构，为希望改进YOLO模型的研究人员和开发者提供了精确的架构理解，有助于YOLO保持其在计算机视觉深度学习领域的领先地位。


### [139] [VariViT: A Vision Transformer for Variable Image Sizes](https://arxiv.org/abs/2602.14615)
*Aswathi Varma,Suprosanna Shit,Chinmay Prabhakar,Daniel Scholz,Hongwei Bran Li,Bjoern Menze,Daniel Rueckert,Benedikt Wiestler*

Main category: cs.CV

TL;DR: VariViT：一种改进的Vision Transformer，能够处理可变尺寸的医学图像，同时保持一致的patch大小，通过新的位置嵌入调整方案和批处理策略，在脑肿瘤分类任务中表现优异。

- Motivation: 传统ViT需要固定尺寸的图像patch，这在医学影像中存在问题：不规则形状的肿瘤结构需要可变尺寸的裁剪，固定尺寸裁剪会导致前景背景比例变化大，而重新调整图像尺寸会损失信息并引入伪影。需要一种能够处理可变图像尺寸的ViT架构。
- Method: 提出VariViT模型，采用新颖的位置嵌入调整方案来处理可变数量的patch，同时保持一致的patch大小。还实现了新的批处理策略来降低计算复杂度，加速训练和推理。
- Result: 在两个3D脑MRI数据集上的评估显示，VariViT在胶质瘤基因型预测和脑肿瘤分类任务中超越了传统ViT和ResNet，分别达到75.5%和76.3%的F1分数。提出的批处理策略相比传统架构减少了高达30%的计算时间。
- Conclusion: VariViT在图像表示学习中表现出高效性，特别适用于医学影像中需要处理可变尺寸图像的任务，能够学习更具区分性的特征，同时提高计算效率。


### [140] [VIGIL: Tackling Hallucination Detection in Image Recontextualization](https://arxiv.org/abs/2602.14633)
*Joanna Wojciechowicz,Maria Łubniewska,Jakub Antczak,Justyna Baczyńska,Wojciech Gromski,Wojciech Kozłowski,Maciej Zięba*

Main category: cs.CV

TL;DR: VIGIL是首个针对多模态图像重语境化任务中幻觉问题的细粒度分类基准数据集和框架，将幻觉分解为五类，并提出多阶段检测流程。

- Motivation: 现有研究通常将幻觉视为统一问题，缺乏对多模态图像重语境化任务中幻觉的细粒度分类和分解评估，存在显著的研究空白。
- Method: 提出多阶段检测流程，通过一系列专门步骤处理重语境化图像，针对对象级保真度、背景一致性和遗漏检测，利用开源模型协调集成。
- Result: 通过广泛的实验评估证明了方法的有效性，能够深入理解模型失败的原因并提供解释，填补了该领域缺乏此类分类和分解方法的空白。
- Conclusion: VIGIL框架提供了对多模态图像重语境化任务中幻觉的细粒度分类和检测，为透明性和进一步探索提供了基准数据集和代码，已开源发布。


### [141] [SketchingReality: From Freehand Scene Sketches To Photorealistic Images](https://arxiv.org/abs/2602.14648)
*Ahmed Bourouis,Mikhail Bessmeltsev,Yulia Gryaditskaya*

Main category: cs.CV

TL;DR: 提出一种基于调制的方法，从自由手绘草图生成图像，优先考虑草图的语义解释而非严格遵循边缘位置，无需像素对齐的真实图像进行训练。

- Motivation: 生成式AI快速发展，但现有方法主要关注边缘图（常被误称为"草图"），而真正处理自由手绘草图（具有固有抽象和变形）的算法仍待探索。目标是平衡照片真实感和草图遵循度，主要障碍是缺乏像素对齐的真实图像。
- Method: 提出基于调制的方法，优先考虑草图的语义解释而非严格遵循边缘位置；引入新颖的损失函数，无需像素对齐的真实图像即可在自由手绘草图上训练。
- Result: 方法在自由手绘草图输入的语义对齐、生成图像的逼真度和整体质量方面均优于现有方法。
- Conclusion: 成功开发了一种能够有效处理自由手绘草图的图像生成方法，通过语义优先的调制策略解决了缺乏像素对齐真实图像的问题，在真实感和草图遵循度之间取得了良好平衡。


### [142] [Advances in Global Solvers for 3D Vision](https://arxiv.org/abs/2602.14662)
*Zhenjun Zhao,Heng Yang,Bangyan Liao,Yingping Zeng,Shaocheng Yan,Yingdong Gu,Peidong Liu,Yi Zhou,Haoang Li,Javier Civera*

Main category: cs.CV

TL;DR: 这篇论文是第一篇关于3D视觉中全局求解器的系统性综述，提出了基于分支定界、凸松弛和渐进非凸性三大范式的分类体系，分析了在10个核心视觉任务中的最优性-鲁棒性-可扩展性权衡，并指出了未来研究方向。

- Motivation: 传统3D视觉中的非凸几何优化问题通常使用局部或启发式方法解决，缺乏理论保证。全局求解器提供了可证明的解决方案，但该领域缺乏系统性综述和统一框架，阻碍了算法发展和实际应用。
- Method: 提出了一个综合分类体系，涵盖三大核心范式：分支定界（BnB）、凸松弛（CR）和渐进非凸性（GNC）。分析了每种范式的理论基础、算法设计和实际增强技术，并考察了它们在10个核心视觉任务中的应用。
- Result: 揭示了全局求解器在最优性、鲁棒性和可扩展性之间的权衡关系，为不同应用场景下的求解器选择提供了指导。建立了统一的视角和路线图，促进可证明、可信赖的感知系统发展。
- Conclusion: 全局求解器是3D视觉中解决非凸几何优化问题的强大范式。未来需要关注算法可扩展性与理论保证的平衡、数据驱动先验与可证明优化的结合、标准化基准的建立，以及安全关键部署的社会影响。


### [143] [MeFEm: Medical Face Embedding model](https://arxiv.org/abs/2602.14672)
*Yury Borets,Stepan Botman*

Main category: cs.CV

TL;DR: MeFEm是基于改进JEPA架构的视觉模型，用于面部图像的生物特征和医学分析，在核心人体测量任务上优于现有基线，并在BMI估计上表现出色。

- Motivation: 现有面部图像分析模型存在数据需求大、领域偏差等问题，需要开发更高效、准确的模型用于生物特征和医学分析。
- Method: 基于改进的联合嵌入预测架构(JEPA)，采用轴向条纹掩码策略聚焦语义相关区域，使用循环损失加权方案，以及CLS令牌的概率重分配以提升线性探测质量。
- Result: 在核心人体测量任务上优于FaRL和Franca等强基线，尽管使用数据量显著更少；在BMI估计上在新整合的闭源数据集上表现出有前景的结果，该数据集解决了现有数据的领域偏差问题。
- Conclusion: MeFEm为面部图像生物特征和医学分析提供了强大的基线模型，模型权重已公开，可用于该领域未来研究。


### [144] [Universal Image Immunization against Diffusion-based Image Editing via Semantic Injection](https://arxiv.org/abs/2602.14679)
*Chanhui Lee,Seunghyun Shin,Donggyu Choi,Hae-gon Jeon,Jeany Son*

Main category: cs.CV

TL;DR: 首个通用图像免疫框架，通过单一对抗扰动保护图像免受扩散模型恶意编辑，无需逐图优化，在数据缺失环境下仍有效

- Motivation: 扩散模型虽带来强大图像编辑能力，但也引发深度伪造和版权侵权等伦理法律风险。现有图像免疫方法需逐图优化对抗扰动，缺乏可扩展性和实用性
- Method: 提出首个通用图像免疫框架，生成单一广泛适用的对抗扰动。受目标攻击中通用对抗扰动技术启发，该方法将语义目标嵌入待保护图像，同时抑制原始内容，误导模型在编辑时的注意力
- Result: 在通用对抗扰动设置下显著优于多个基线方法；在有限扰动预算下与图像特定方法性能相当；在不同扩散模型间展现出强大的黑盒可迁移性
- Conclusion: 该方法为扩散模型驱动的恶意编辑提供了首个通用防御方案，无需训练数据或领域知识，具有实际应用价值


### [145] [It's a Matter of Time: Three Lessons on Long-Term Motion for Perception](https://arxiv.org/abs/2602.14705)
*Willem Davison,Xinyue Hao,Laura Sevilla-Lara*

Main category: cs.CV

TL;DR: 长期运动信息在感知任务中比图像信息更有效，具有更好的泛化能力和计算效率

- Motivation: 探索时间维度在感知中的作用，理解长期运动信息能提供什么世界知识，以及它在视觉学习中的特性
- Method: 利用点轨迹估计技术学习时间表征，并在多种感知任务上进行实验验证
- Result: 1) 长期运动表征能理解动作、物体、材料和空间信息，甚至优于图像；2) 在低数据量和零样本任务中泛化能力远超图像表征；3) 运动信息维度低，在计算效率和准确性之间提供更好权衡
- Conclusion: 长期运动信息是强大的感知工具，未来模型设计应充分利用其优势


### [146] [Depth Completion as Parameter-Efficient Test-Time Adaptation](https://arxiv.org/abs/2602.14751)
*Bingxin Ke,Qunjie Zhou,Jiahui Huang,Xuanchi Ren,Tianchang Shen,Konrad Schindler,Laura Leal-Taixé,Shengyu Huang*

Main category: cs.CV

TL;DR: CAPA：基于参数高效微调（如LoRA/VPT）的测试时优化框架，冻结3D基础模型主干，仅更新少量参数，利用推理时的稀疏几何线索进行适配，实现深度补全任务。

- Motivation: 现有方法通常为辅助输入训练任务特定编码器，容易过拟合且泛化能力差。需要一种能够有效利用预训练3D基础模型几何先验，同时适应具体场景稀疏观测的方法。
- Method: 冻结基础模型主干，仅通过参数高效微调（如LoRA或VPT）更新少量参数。利用推理时稀疏观测的梯度指导优化。对于视频，引入序列级参数共享，联合适配所有帧以利用时序相关性。
- Result: 在室内外数据集上，针对多种条件模式均达到最先进性能。能够有效校正失真和错位结构，提高鲁棒性和多帧一致性。
- Conclusion: CAPA提供了一种模型无关、参数高效的测试时优化框架，能够有效将基础模型的几何先验与场景特定测量相结合，在深度补全任务中表现优异。


### [147] [SAILS: Segment Anything with Incrementally Learned Semantics for Task-Invariant and Training-Free Continual Learning](https://arxiv.org/abs/2602.14767)
*Shishir Muralidhara,Didier Stricker,René Schuster*

Main category: cs.CV

TL;DR: SAILS是一个无需训练的类增量语义分割框架，利用基础模型将任务分解为零样本区域提取和语义关联，完全避免了遗忘问题。

- Motivation: 持续学习面临重复训练、高计算成本和遗忘问题，限制了其在现实世界的应用。现有方法需要迭代模型更新，消耗大量计算资源并加剧遗忘。
- Method: SAILS采用免训练框架，利用Segment Anything Model进行零样本区域提取，然后在固定特征空间通过原型进行语义关联。引入选择性类内聚类，为每个类生成多个原型以更好地建模类内变化。
- Result: SAILS在标准CISS数据集上通常超越现有的基于训练的方法，特别是在长且具有挑战性的任务序列中。完全消除遗忘，保持一致的性能，并展现出正向后向迁移（新类引入能提升旧类性能）。
- Conclusion: SAILS通过免训练方法解决了持续学习的关键挑战，为类增量语义分割提供了高效且无遗忘的解决方案，在现实世界应用中具有重要潜力。


### [148] [GOT-JEPA: Generic Object Tracking with Model Adaptation and Occlusion Handling using Joint-Embedding Predictive Architecture](https://arxiv.org/abs/2602.14771)
*Shih-Fang Chen,Jun-Cheng Chen,I-Hong Jhuo,Yen-Yu Lin*

Main category: cs.CV

TL;DR: GOT-JEPA是一个基于模型预测预训练的通用目标跟踪框架，通过教师-学生架构学习在遮挡和干扰下生成可靠的跟踪模型，结合OccuSolver增强遮挡感知能力，显著提升了跟踪器的泛化性和鲁棒性。

- Motivation: 现有通用目标跟踪器通常针对训练目标进行优化，限制了在未见场景中的鲁棒性和泛化能力，且遮挡推理较为粗糙，缺乏对遮挡模式的详细建模。需要解决泛化性和遮挡感知方面的局限性。
- Method: 提出GOT-JEPA框架，将JEPA从预测图像特征扩展到预测跟踪模型。采用教师-学生架构：教师预测器从干净当前帧生成伪跟踪模型，学生预测器从被破坏的当前帧学习预测相同的伪跟踪模型。进一步提出OccuSolver，采用点中心点跟踪器进行目标感知的可见性估计和详细遮挡模式捕捉，基于跟踪器迭代生成的目标先验逐步细化可见性状态。
- Result: 在七个基准测试上的广泛评估表明，该方法有效增强了跟踪器的泛化性和鲁棒性，提升了在动态环境中的跟踪性能。
- Conclusion: GOT-JEPA通过模型预测预训练框架和OccuSolver的遮挡感知增强，成功解决了通用目标跟踪中的泛化性和遮挡处理问题，为动态环境中的鲁棒跟踪提供了有效解决方案。


### [149] [VIPA: Visual Informative Part Attention for Referring Image Segmentation](https://arxiv.org/abs/2602.14788)
*Yubin Cho,Hyunwoo Yu,Kyeongbo Kong,Kyomin Sohn,Bongjoon Hyun,Suk-Ju Kang*

Main category: cs.CV

TL;DR: 提出VIPA框架，通过视觉表达增强RIS中的跨模态对齐，利用视觉信息部分注意力机制提升细粒度分割性能

- Motivation: 现有RIS方法虽然将视觉信息融入语言标记，但未能有效利用视觉上下文进行细粒度分割。需要更有效地利用视觉上下文来提升分割精度。
- Method: 提出视觉信息部分注意力(VIPA)框架，利用视觉表达提供结构和语义视觉目标信息。设计视觉表达生成器(VEG)模块，通过局部-全局语言上下文线索检索信息性视觉标记，并细化这些标记以减少噪声和共享视觉属性。
- Result: VIPA在四个公共RIS基准测试中超越了现有最先进方法，实验和视觉分析证明了方法的有效性。
- Conclusion: VIPA框架通过视觉表达有效利用视觉上下文，减少跨模态投影的方差，增强语义一致性，使网络注意力能够稳健地对齐细粒度感兴趣区域。


### [150] [Debiasing Central Fixation Confounds Reveals a Peripheral "Sweet Spot" for Human-like Scanpaths in Hard-Attention Vision](https://arxiv.org/abs/2602.14834)
*Pengcheng Pan,Yonekura Shogo,Yasuo Kuniyosh*

Main category: cs.CV

TL;DR: 论文指出视觉识别中眼动扫描路径评估存在中心偏差问题，提出GCS指标来去偏，发现中等视野大小能产生既去偏又类似人类眼动的扫描路径

- Motivation: 现有扫描路径评估指标在物体中心数据集上受中心偏差强烈影响，导致难以区分真正的行为对齐与简单的中心趋势，需要更可靠的评估方法
- Method: 使用Gaze-CIFAR-10数据集，分析硬注意分类器在不同视野大小下的表现，提出GCS（凝视一致性分数）作为去偏复合指标，结合运动相似性评估
- Result: 发现仅中等视野大小能产生既高于去偏中心基线又具有类似人类运动统计的扫描路径，揭示了"捷径机制"（视野过大时）和外围甜点现象
- Conclusion: 需要去偏的扫描路径评估指标来更好地区分行为对齐与中心偏差，中等视野大小能平衡中央采样与外围上下文，对主动感知评估和凝视基准设计有重要启示


### [151] [Integrating Affordances and Attention models for Short-Term Object Interaction Anticipation](https://arxiv.org/abs/2602.14837)
*Lorenzo Mur Labadia,Ruben Martinez-Cantin,Jose J. Guerrero,Giovanni M. Farinella,Antonino Furnari*

Main category: cs.CV

TL;DR: 提出STAformer和STAformer++架构，通过环境可供性和交互热点建模提升短期对象交互预测性能

- Motivation: 短期对象交互预测对可穿戴助手和人机交互至关重要，需要提升现有预测性能
- Method: 1) 提出STAformer和STAformer++架构，集成帧引导时序池化、双图像-视频注意力和多尺度特征融合；2) 引入环境可供性模型作为交互记忆；3) 基于手部和对象轨迹预测交互热点
- Result: 在Ego4D上提升23个百分点，在EPIC-Kitchens STA标签上提升31个百分点
- Conclusion: 通过注意力架构和基于人类行为的可供性建模显著提升短期对象交互预测性能，已开源代码和数据集


### [152] [Multi-dimensional Persistent Sheaf Laplacians for Image Analysis](https://arxiv.org/abs/2602.14846)
*Xiang Xiang Wang,Guo-Wei Wei*

Main category: cs.CV

TL;DR: 提出基于单纯复形的多维持久层拉普拉斯框架用于图像分析，通过利用多个降维维度的互补优势，避免传统降维方法对维度选择的敏感性。

- Motivation: 传统降维方法（如PCA）对降维维度的选择非常敏感，单一维度选择或跨维度平均都存在问题，需要一种能利用多个降维维度互补优势的方法。
- Method: 将图像样本视为单纯复形，在每个维度上使用持久层拉普拉斯提取多尺度局部拓扑谱表示，然后跨尺度和维度聚合谱的统计摘要，形成多尺度多维图像表示。
- Result: 在COIL20和ETH80数据集上的实验表明，该方法在广泛的降维维度范围内表现更稳定，在中等维度区域相比基于PCA的基线方法有持续改进。
- Conclusion: 提出的MPSL框架通过利用多个降维维度的互补信息，提供了一种对维度选择不敏感且性能更稳定的图像分析方法。


### [153] [CT-Bench: A Benchmark for Multimodal Lesion Understanding in Computed Tomography](https://arxiv.org/abs/2602.14879)
*Qingqing Zhu,Qiao Jin,Tejas S. Mathai,Yin Fang,Zhizheng Wang,Yifan Yang,Maame Sarfo-Gyamfi,Benjamin Hou,Ran Gu,Praveen T. S. Balamuralikrishna,Kenneth C. Wang,Ronald M. Summers,Zhiyong Lu*

Main category: cs.CV

TL;DR: CT-Bench是一个首创的CT影像基准数据集，包含20,335个病灶的标注信息和2,850个视觉问答对，用于评估多模态模型在病灶分析任务上的性能。

- Motivation: 当前AI在CT影像病灶分割和报告生成方面的进展受到公开CT数据集稀缺的限制，特别是缺乏病灶级别的标注数据，这阻碍了相关研究的发展。
- Method: 构建了CT-Bench数据集，包含两个部分：1) 病灶图像和元数据集（20,335个病灶，包含边界框、描述和大小信息）；2) 多任务视觉问答基准（2,850个QA对，涵盖病灶定位、描述、大小估计和属性分类）。
- Result: 评估了多种最先进的多模态模型（包括视觉语言模型和医学CLIP变体），发现微调模型在病灶图像和元数据集上能显著提升性能，证明了CT-Bench的临床价值。
- Conclusion: CT-Bench作为一个全面的病灶分析基准数据集，能够有效评估多模态模型在CT影像分析中的性能，并为临床AI应用提供有价值的资源。


### [154] [Wrivinder: Towards Spatial Intelligence for Geo-locating Ground Images onto Satellite Imagery](https://arxiv.org/abs/2602.14929)
*Chandrakanth Gudavalli,Tajuddin Manhar Mohammed,Abhay Yadav,Ananth Vishnu Bhaskar,Hardik Prajapati,Cheng Peng,Rama Chellappa,Shivkumar Chandrasekaran,B. S. Manjunath*

Main category: cs.CV

TL;DR: Wrivinder是一个零样本几何驱动框架，通过聚合多张地面照片重建3D场景并与卫星图像对齐，实现亚30米精度的地理定位，同时发布了MC-Sat数据集用于评估。

- Motivation: 地面图像与地理注册卫星地图的对齐对于地图绘制、导航和态势感知至关重要，但在大视角差异或GPS不可靠时仍然具有挑战性。现有任务缺乏合适的基准数据集。
- Method: 结合SfM重建、3D高斯泼溅、语义基础和单目深度度量线索，生成稳定的天顶视图渲染，可直接与卫星上下文匹配进行度量精确的相机地理定位。
- Result: 在零样本实验中，Wrivinder在密集和大面积场景中实现了亚30米的地理定位精度，展示了基于几何聚合的鲁棒地面到卫星定位的潜力。
- Conclusion: Wrivinder和MC-Sat为无配对监督的几何中心跨视图对齐研究提供了首个全面基准和测试平台，突出了几何聚合在鲁棒地面到卫星定位中的前景。


### [155] [AnchorWeave: World-Consistent Video Generation with Retrieved Local Spatial Memories](https://arxiv.org/abs/2602.14941)
*Zun Wang,Han Lin,Jaehong Yoon,Jaemin Cho,Yue Zhang,Mohit Bansal*

Main category: cs.CV

TL;DR: AnchorWeave：通过多局部几何记忆和编织控制器解决长视频生成中的空间一致性挑战，避免全局3D重建的错位问题

- Motivation: 现有基于记忆的视频生成方法通过从重建的全局3D场景渲染锚点视频来生成，但多视角重建不可避免地引入跨视角错位，导致几何噪声污染条件信号并降低生成质量
- Method: 用多个干净的局部几何记忆替代单个错位的全局记忆，通过覆盖驱动的局部记忆检索与目标轨迹对齐，并在生成过程中通过多锚点编织控制器整合选定的局部记忆
- Result: 广泛实验表明AnchorWeave显著改善了长期场景一致性，同时保持了强大的视觉质量，消融和分析研究进一步验证了局部几何条件、多锚点控制和覆盖驱动检索的有效性
- Conclusion: AnchorWeave通过局部几何记忆和编织控制解决了长视频生成中的空间一致性挑战，为相机可控视频生成提供了更可靠的解决方案


### [156] [PAct: Part-Decomposed Single-View Articulated Object Generation](https://arxiv.org/abs/2602.14965)
*Qingming Liu,Xinyue Yao,Shuyuan Zhang,Yueci Deng,Guiliang Liu,Zhen Liu,Kui Jia*

Main category: cs.CV

TL;DR: 提出一个基于部件的生成框架，能够从单张图像快速生成具有部件分解和运动学结构的3D可动物体，避免了传统优化方法的时间消耗和检索方法的结构不匹配问题。

- Motivation: 当前可动物体生成存在两大问题：优化方法耗时过长（数分钟到数小时），而推理方法依赖模板检索，无法匹配输入观测的具体结构和外观。需要一种既能保持输入一致性，又能快速生成高质量可动资产的方法。
- Method: 采用部件中心的生成框架，将物体建模为一组可动部件，每个部件用带有部件身份和运动线索的潜在令牌编码。在单张图像条件下，模型生成保持实例级对应关系的3D可动资产，同时确保有效的部件结构和运动。
- Result: 在常见可动类别（如抽屉、门）上实验显示，相比基于优化和检索的方法，该方法在输入一致性、部件准确性和运动合理性方面都有提升，同时大幅减少推理时间。
- Conclusion: 提出的部件中心生成框架能够快速生成高质量的可动3D资产，支持可控的组装和运动，适用于具身交互应用，避免了传统方法的耗时优化和结构不匹配问题。


### [157] [ThermEval: A Structured Benchmark for Evaluation of Vision-Language Models on Thermal Imagery](https://arxiv.org/abs/2602.14989)
*Ayush Shrivastava,Kirtan Gangani,Laksh Jain,Mayank Goel,Nipun Batra*

Main category: cs.CV

TL;DR: ThermEval-B是一个包含约55,000个热成像视觉问答对的基准测试，用于评估热成像视觉语言理解能力，发现现有VLM在温度推理、色彩映射变换等方面表现不佳。

- Motivation: 当前视觉语言模型在RGB图像上表现良好，但无法泛化到热成像图像。热成像在夜间监控、搜救、自动驾驶和医疗筛查等可见光失效的场景中至关重要，需要专门的评估基准。
- Method: 构建ThermEval-B基准测试，整合公共数据集和新收集的ThermEval-D数据集（首个提供密集逐像素温度图和语义身体部位标注的数据集）。评估了25个开源和闭源VLM。
- Result: 现有模型在温度基础推理方面持续失败，在色彩映射变换下性能下降，倾向于依赖语言先验或固定响应，即使通过提示或监督微调也只有边际改进。
- Conclusion: 热成像理解需要超越RGB中心假设的专门评估，ThermEval作为基准测试将推动热成像视觉语言建模的进展。


### [158] [Image Generation with a Sphere Encoder](https://arxiv.org/abs/2602.15030)
*Kaiyu Yue,Menglin Jia,Ji Hou,Tom Goldstein*

Main category: cs.CV

TL;DR: Sphere Encoder：一种高效的单步前向生成框架，通过将图像映射到球形潜在空间，仅需少于5步即可生成与多步扩散模型竞争质量的图像。

- Motivation: 当前扩散模型需要多步推理，计算成本高。本文旨在开发一种更高效的生成框架，能够在单次前向传递中生成高质量图像，显著降低推理成本。
- Method: 学习一个编码器将自然图像均匀映射到球形潜在空间，解码器将随机潜在向量映射回图像空间。仅使用图像重建损失训练，通过解码球面上的随机点生成图像。支持条件生成，多次循环编码器/解码器可进一步提升质量。
- Result: 在多个数据集上，Sphere Encoder的性能与最先进的扩散模型相当，但推理成本仅为后者的一小部分（少于5步）。
- Conclusion: Sphere Encoder提供了一种高效的单步生成框架，在保持图像质量的同时大幅降低推理成本，为生成模型的实际应用提供了有前景的替代方案。


### [159] [EditCtrl: Disentangled Local and Global Control for Real-Time Generative Video Editing](https://arxiv.org/abs/2602.15031)
*Yehonathan Litman,Shikun Liu,Dario Seyb,Nicholas Milef,Yang Zhou,Carl Marshall,Shubham Tulsiani,Caleb Leak*

Main category: cs.CV

TL;DR: EditCtrl：一种高效的视频修复控制框架，通过局部视频上下文模块和轻量级全局上下文嵌入器，将计算成本与编辑大小成正比，比现有方法效率高10倍且质量更优。

- Motivation: 现有基于预训练视频基础模型的高保真生成视频编辑方法存在计算效率低下的问题，即使对于稀疏、局部化的编辑，也需要处理完整的视频上下文，导致不必要的计算开销。
- Method: 提出EditCtrl框架，包含两个核心组件：1) 仅对掩码标记操作的局部视频上下文模块，计算成本与编辑大小成正比；2) 轻量级时序全局上下文嵌入器，以最小开销确保视频范围内的上下文一致性。
- Result: EditCtrl比最先进的生成编辑方法计算效率高10倍，甚至比采用全注意力机制的方法在编辑质量上有所提升。该框架还支持多区域文本提示编辑和自回归内容传播等新功能。
- Conclusion: EditCtrl通过将计算资源集中在需要编辑的区域，实现了高效且高质量的视频修复，为视频编辑开辟了新的可能性，包括多区域编辑和内容传播等应用。
## q-bio.GN

### [160] [CellMaster: Collaborative Cell Type Annotation in Single-Cell Analysis](https://arxiv.org/abs/2602.13346)
*Zhen Wang,Yiming Gao,Jieyuan Liu,Enze Ma,Jefferson Chen,Mark Antkowiak,Mengzhou Hu,JungHo Kong,Dexter Pratt,Zhiting Hu,Wei Wang,Trey Ideker,Eric P. Xing*

Main category: q-bio.GN

TL;DR: CellMaster是一个基于LLM的AI代理，用于零样本细胞类型注释，无需预训练或固定标记数据库，在9个数据集上比现有方法准确率提高7.1%

- Motivation: 单细胞RNA测序虽然能揭示复杂组织中的稀有谱系和瞬时状态，但细胞类型注释仍存在瓶颈，因为标记物具有组织和状态依赖性，且新状态缺乏参考
- Method: 开发CellMaster AI代理，模仿专家实践，利用LLM编码知识（如GPT-4o）进行实时注释并提供可解释的理由，无需预训练或固定标记数据库
- Result: 在8个组织的9个数据集上，CellMaster自动模式比最佳基线（包括CellTypist和scTab）准确率提高7.1%；人机协同模式下优势增至18.6%，在亚型群体上提升22.1%，在稀有和新细胞状态上表现尤其突出
- Conclusion: CellMaster通过LLM驱动的零样本注释方法，显著提高了细胞类型注释的准确性和可解释性，特别是在处理稀有和新细胞状态时表现优异
## cs.AI

### [161] [Lang2Act: Fine-Grained Visual Reasoning through Self-Emergent Linguistic Toolchains](https://arxiv.org/abs/2602.13235)
*Yuqi Xiong,Chunyi Peng,Zhipeng Xu,Zhenghao Liu,Zulong Chen,Yukun Yan,Shuo Wang,Yu Gu,Ge Yu*

Main category: cs.AI

TL;DR: Lang2Act提出了一种通过自涌现语言工具链实现细粒度视觉感知和推理的方法，替代了传统VRAG框架依赖固定外部工具的局限，通过两阶段强化学习训练显著提升了视觉语言模型的感知能力。

- Motivation: 现有视觉检索增强生成框架通常依赖预定义的外部工具，将视觉感知与后续推理过程分离，这种解耦设计可能导致视觉信息的不必要损失，特别是在进行裁剪等图像操作时。
- Method: 提出Lang2Act方法，通过自涌现语言工具链实现细粒度视觉感知和推理。设计了两阶段强化学习训练框架：第一阶段优化视觉语言模型自我探索高质量动作以构建可重用的语言工具箱；第二阶段进一步优化模型有效利用这些语言工具进行下游推理。
- Result: 实验结果表明Lang2Act能显著增强视觉语言模型的视觉感知能力，性能提升超过4%。所有代码和数据已开源。
- Conclusion: Lang2Act通过自涌现语言工具链和两阶段强化学习训练，有效解决了传统VRAG框架的局限性，实现了更细粒度的视觉感知和推理能力提升。


### [162] [DECKBench: Benchmarking Multi-Agent Frameworks for Academic Slide Generation and Editing](https://arxiv.org/abs/2602.13318)
*Daesik Jang,Morgan Lindsay Heisler,Linzi Xing,Yifei Li,Edward Wang,Ying Xiong,Yong Zhang,Zhenan Fan*

Main category: cs.AI

TL;DR: DECKBench是一个用于评估多智能体幻灯片生成与编辑的基准框架，包含数据集和评估协议，旨在解决现有评估方法在内容选择、组织、布局和多轮指令跟随方面的不足。

- Motivation: 现有基准和评估协议无法充分衡量学术幻灯片自动生成和迭代编辑中的关键挑战，包括忠实的内容选择、连贯的幻灯片组织、布局感知的渲染和鲁棒的多轮指令跟随。
- Method: 构建DECKBench基准框架，包含基于论文-幻灯片对的数据集和模拟编辑指令；设计系统评估协议评估幻灯片级和演示文稿级的保真度、连贯性、布局质量和多轮指令跟随；实现模块化多智能体基线系统，将任务分解为论文解析与摘要、幻灯片规划、HTML创建和迭代编辑。
- Result: 实验结果表明，提出的基准能够突出系统优势、暴露失败模式，并为改进多智能体幻灯片生成和编辑系统提供可操作的见解。
- Conclusion: 这项工作为学术演示文稿生成和编辑的可重复和可比较评估建立了标准化基础，代码和数据已公开。


### [163] [Building Autonomous GUI Navigation via Agentic-Q Estimation and Step-Wise Policy Optimization](https://arxiv.org/abs/2602.13653)
*Yibo Wang,Guangda Huzhang,Yuwei Hu,Yu Xia,Shiyin Lu,Qing-Guo Chen,Zhao Xu,Weihua Luo,Kaifu Zhang,Lijun Zhang*

Main category: cs.AI

TL;DR: 提出基于MLLM的GUI智能体框架，包含agentic-Q估计和逐步策略优化，降低数据收集成本并实现稳定优化，在GUI导航和定位任务上表现优异。

- Motivation: 现实应用中GUI智能体面临非平稳环境，导致数据整理和策略优化的计算成本高昂，需要更高效的框架来解决这些问题。
- Method: 提出两阶段框架：1) agentic-Q估计，优化Q模型评估动作对任务完成的贡献值；2) 逐步策略优化，从状态-动作轨迹采样，通过强化学习优化策略。所有轨迹由策略自身产生，降低数据收集成本，策略更新与环境解耦确保稳定优化。
- Result: 该框架赋予Ovis2.5-9B强大的GUI交互能力，在GUI导航和定位基准测试中表现卓越，甚至超越更大规模的竞争对手。
- Conclusion: 提出的MLLM中心框架有效解决了GUI智能体在非平稳环境中的计算成本问题，通过agentic-Q估计和逐步策略优化实现了高效稳定的策略学习，展示了在GUI交互任务上的优越性能。


### [164] [VSAL: A Vision Solver with Adaptive Layouts for Graph Property Detection](https://arxiv.org/abs/2602.13880)
*Jiahao Xie,Guangmo Tong*

Main category: cs.AI

TL;DR: 提出VSAL视觉框架，通过自适应布局生成器动态生成信息丰富的图可视化，提升图属性检测性能

- Motivation: 现有基于视觉的图属性检测方法依赖固定的视觉图布局，限制了管道的表达能力，需要更灵活的自适应布局方法
- Method: VSAL框架包含自适应布局生成器，能够针对单个图实例动态生成信息丰富的可视化，从而提高图属性检测效果
- Result: 在哈密顿环、平面性、无爪性和树检测等多个任务上，VSAL优于最先进的基于视觉的方法
- Conclusion: 自适应布局生成器能够显著提升基于视觉的图属性检测性能，VSAL框架为图分析提供了更有效的视觉解决方案


### [165] [Frontier AI Risk Management Framework in Practice: A Risk Analysis Technical Report v1.5](https://arxiv.org/abs/2602.14457)
*Dongrui Liu,Yi Yu,Jie Zhang,Guanxu Chen,Qihao Lin,Hanxi Zhu,Lige Huang,Yijin Zhou,Peng Wang,Shuai Shao,Boxuan Zhang,Zicheng Liu,Jingwei Sun,Yu Li,Yuejin Xie,Jiaxuan Guo,Jia Xu,Chaochao Lu,Bowen Zhou,Xia Hu,Jing Shao*

Main category: cs.AI

TL;DR: 该论文提出了前沿AI风险管理框架，评估了大型语言模型和智能体AI在五个关键维度（网络攻击、说服操纵、战略欺骗、失控AI研发、自我复制）的风险，并提出了缓解策略。

- Motivation: 随着AI模型能力快速演进和智能体AI的普及，需要全面评估前沿AI带来的前所未有的风险，特别是LLM通用能力的快速发展和智能体AI的扩散带来的新型威胁。
- Method: 采用更新的风险评估方法，针对五个关键维度设计更复杂的场景：网络攻击的复杂场景、LLM对LLM说服的新模型评估、战略欺骗的新实验、关注智能体"错误进化"的失控研发、资源受限的自我复制场景，并在Moltbook上监控OpenClaw的安全性能。
- Result: 对前沿AI风险进行了细粒度评估，识别了五个维度的具体威胁，提出并验证了一系列稳健的缓解策略，为前沿AI的安全部署提供了初步的技术和可操作路径。
- Conclusion: 该工作反映了当前对AI前沿风险的理解，强调了需要集体行动来缓解这些挑战，为安全部署前沿AI提供了风险管理框架和缓解策略。
## cs.CY

### [166] [CrisiSense-RAG: Crisis Sensing Multimodal Retrieval-Augmented Generation for Rapid Disaster Impact Assessment](https://arxiv.org/abs/2602.13239)
*Yiming Xiao,Kai Yin,Ali Mostafavi*

Main category: cs.CY

TL;DR: CrisiSense-RAG是一个多模态检索增强生成框架，用于灾害影响评估，通过异步融合逻辑处理时间错位的实时社会报告和高分辨率卫星图像，无需灾害特定微调。

- Motivation: 现有自动化方法难以处理灾害评估中的时间异步问题：实时人类报告捕捉灾害峰值条件，而高分辨率卫星图像通常在峰值后获取，反映的是洪水消退而非最大范围。简单融合这些错位数据流可能导致对峰值洪水的危险低估。
- Method: 提出CrisiSense-RAG框架，将影响评估重新定义为异构数据源的证据合成。采用混合密集-稀疏检索处理文本源，CLIP-based检索处理航空图像。采用分割管道架构和异步融合逻辑，优先处理实时社会证据以确定峰值洪水范围，同时将图像视为结构损坏的持久证据。
- Result: 在飓风哈维的207个ZIP码查询评估中，零样本设置下洪水范围MAE为10.94%至28.40%，损坏严重程度MAE为16.47%至21.65%。提示级对齐对定量有效性至关重要，度量基础化将损坏估计提高了最多4.75个百分点。
- Conclusion: 该方法展示了在真实世界数据约束下实现快速韧性智能的实用且可部署方法，通过证据合成而非简单融合来处理时间异步问题，显著提高了灾害影响评估的准确性。
## cs.OH

### [167] [Bidirectional Temporal Dynamics Modeling for EEG-based Driving Fatigue Recognition](https://arxiv.org/abs/2602.14071)
*YipTin Po,Jianming Wang,Yutao Miao,Jiayan Zhang,Yunxu Zhao,Xiaomin Ouyang,Zhihong Li,Nevin L. Zhang*

Main category: cs.OH

TL;DR: DeltaGateNet：一种用于EEG驾驶疲劳识别的新框架，通过双向时间动态建模解决EEG非平稳性和不对称神经动态问题，在多个数据集上优于现有方法。

- Motivation: 驾驶疲劳是交通事故的主要原因，EEG虽然能直接测量神经活动，但基于EEG的疲劳识别受到强非平稳性和不对称神经动态的阻碍，需要新的方法来应对这些挑战。
- Method: 提出DeltaGateNet框架，包含双向Delta模块（将一阶时间差异分解为正负分量以建模不对称神经激活/抑制模式）和门控时间卷积模块（使用深度时间卷积和残差学习捕获每个EEG通道的长期时间依赖）。
- Result: 在SEED-VIG数据集上，DeltaGateNet获得81.89%的受试者内准确率和55.55%的受试者间准确率；在SADT数据集上，平衡版本达到96.81%/83.21%，非平衡版本达到96.84%/84.49%的准确率，均优于现有方法。
- Conclusion: 显式建模双向时间动态能够在不同受试者和类别分布条件下产生鲁棒且可泛化的性能，为EEG驾驶疲劳识别提供了有效解决方案。
## cs.IR

### [168] [Pailitao-VL: Unified Embedding and Reranker for Real-Time Multi-Modal Industrial Search](https://arxiv.org/abs/2602.13704)
*Lei Chen,Chen Ju,Xu Chen,Zhicheng Wang,Yuheng Jiao,Hongfeng Zhan,Zhaoyang Li,Shihao Xu,Zhixiang Zhao,Tong Jia,Jinsong Lan,Xiaoyong Zhu,Bo Zheng*

Main category: cs.IR

TL;DR: Pailitao-VL是一个用于工业搜索的多模态检索系统，通过两种范式转变解决了现有方法的三个关键挑战：从对比学习转向绝对ID识别任务，以及从点式评估转向列表式比较校准策略，实现了高精度实时检索。

- Motivation: 解决当前最先进解决方案中的三个关键挑战：检索粒度不足、对环境噪声的脆弱性、以及效率与性能之间的巨大差距，为大规模生产环境部署先进的MLLM检索架构提供稳健可扩展的路径。
- Method: 1. 嵌入范式转变：从传统对比学习转向绝对ID识别任务，通过将实例锚定到由数十亿语义原型定义的全局一致潜在空间；2. 生成式重排序器转变：从孤立点式评估转向比较校准列表式策略，结合基于分块的比较推理和校准的绝对相关性评分。
- Result: 在阿里巴巴电商平台的离线基准测试和在线A/B测试中，Pailitao-VL实现了最先进的性能，并带来了显著的商业影响，证明了其在要求高的大规模生产环境中的有效性。
- Conclusion: 这项工作展示了在要求高的大规模生产环境中部署先进的MLLM检索架构的稳健且可扩展的路径，通过两种根本性的范式转变解决了现有方法的局限性，实现了高精度实时工业搜索。
## cs.LG

### [169] [Revisiting the Platonic Representation Hypothesis: An Aristotelian View](https://arxiv.org/abs/2602.14486)
*Fabian Gröger,Shuo Wen,Maria Brbić*

Main category: cs.LG

TL;DR: 该论文提出一个基于排列的零校准框架来修正表示相似性度量中的网络规模偏差，发现全局谱度量的收敛现象在校准后消失，而局部邻域相似性保留显著一致性，从而提出亚里士多德表示假说。

- Motivation: 现有表示相似性度量存在网络规模偏差（增加深度或宽度会系统性夸大相似性得分），这影响了柏拉图表示假说的验证。需要开发校准方法来获得统计保证的相似性度量。
- Method: 提出基于排列的零校准框架，将任何表示相似性度量转换为具有统计保证的校准分数。使用该框架重新评估柏拉图表示假说，分析全局谱度量和局部邻域相似性。
- Result: 校准后，全局谱度量显示的收敛现象基本消失，而局部邻域相似性（非局部距离）在不同模态间保持显著一致性。这表明网络表示收敛于共享的局部邻域关系。
- Conclusion: 提出亚里士多德表示假说：神经网络表示正在收敛到共享的局部邻域关系，而非全局统计模型。校准框架为表示相似性分析提供了统计可靠的工具。


### [170] [Exposing Diversity Bias in Deep Generative Models: Statistical Origins and Correction of Diversity Error](https://arxiv.org/abs/2602.14682)
*Farzan Farnia,Mohammad Jalali,Azim Ospanov*

Main category: cs.LG

TL;DR: 研究发现现代生成模型存在系统性多样性低估偏差，测试数据多样性显著高于生成样本，并提出基于熵的多样性评分和正则化策略来缓解此问题。

- Motivation: 虽然深度生成模型在生成高质量样本方面取得了巨大成功，但一个尚未系统研究的重要问题是：训练好的生成模型是否能忠实捕捉底层数据分布的多样性。本文旨在通过直接比较生成样本与测试样本的多样性来回答这个问题。
- Method: 使用最近提出的无参考熵基多样性评分Vendi和RKE，在多个基准数据集上比较最先进模型生成的样本与从目标数据分布中抽取的测试样本的多样性。分析熵基多样性评分的有限样本行为，并讨论基于Vendi和RKE的多样性感知正则化和引导策略。
- Result: 测试数据在所有基准数据集上始终获得比生成样本显著更高的Vendi和RKE多样性分数，表明现代生成模型存在系统性向下多样性偏差。分析显示熵基多样性评分的期望值随样本量增加而增加，这意味着从有限训练集估计的多样性可能固有地低估真实分布的多样性。
- Conclusion: 优化生成器以最小化与经验数据分布的散度会导致多样性损失。基于Vendi和RKE的多样性感知正则化和引导策略是缓解这种偏差的有原则方向，实证证据表明这些策略有潜力改善结果。


### [171] [Universal Algorithm-Implicit Learning](https://arxiv.org/abs/2602.14761)
*Stefano Woerner,Seong Joon Oh,Christian F. Baumgartner*

Main category: cs.LG

TL;DR: 提出TAIL：基于Transformer的算法隐式元学习器，通过随机投影、随机注入标签嵌入和内联查询处理实现跨模态、跨领域、跨标签空间的通用元学习。

- Motivation: 当前元学习方法局限于狭窄的任务分布和固定的特征/标签空间，且术语使用不一致缺乏精确定义，限制了实际应用和可比性。
- Method: 提出理论框架定义实用普遍性，区分算法显式和算法隐式学习；在此基础上开发TAIL，采用随机投影进行跨模态特征编码、随机注入标签嵌入支持更大标签空间、高效内联查询处理。
- Result: TAIL在标准少样本基准上达到SOTA，能泛化到未见领域和模态（如仅用图像训练却能处理文本分类），处理训练时20倍多的类别数，计算效率比先前Transformer方法高数个数量级。
- Conclusion: 建立了元学习的理论框架和精确术语，提出的TAIL实现了实用普遍性，在跨模态、跨领域、跨标签空间任务上表现出色，为通用元学习提供了新方向。


### [172] [Web-Scale Multimodal Summarization using CLIP-Based Semantic Alignment](https://arxiv.org/abs/2602.14889)
*Mounvik K,N Harshit*

Main category: cs.LG

TL;DR: 提出Web-Scale Multimodal Summarization框架，通过检索网络文本和图像数据生成摘要，使用微调CLIP模型评估图像与主题语义对齐，支持可配置参数和结构化输出下载。

- Motivation: 开发一个轻量级框架，能够从网络资源中检索文本和图像数据，生成多模态摘要，解决传统摘要方法缺乏视觉信息整合的问题。
- Method: 给定用户主题后，系统并行执行网络、新闻和图像搜索。使用微调CLIP模型对检索到的图像进行排名，评估其与主题和文本的语义对齐。可选BLIP字幕生成支持纯图像摘要。框架支持可调节获取限制、语义过滤、摘要样式和结构化输出下载。
- Result: 在500个图像-字幕对和20:1对比负样本的评估中，获得ROC-AUC为0.9270，F1分数为0.6504，准确率为96.99%，显示出强大的多模态对齐能力。
- Conclusion: 该工作提供了一个可配置、可部署的网络规模摘要工具，将语言、检索和视觉模型集成到用户可扩展的管道中，通过Gradio API提供可控参数和预设配置。


### [173] [Picking the Right Specialist: Attentive Neural Process-based Selection of Task-Specialized Models as Tools for Agentic Healthcare Systems](https://arxiv.org/abs/2602.14901)
*Pramit Saha,Joshua Strong,Mohammad Alsharid,Divyanshu Mishra,J. Alison Noble*

Main category: cs.LG

TL;DR: ToolSelect：一种自适应学习模型选择的方法，通过最小化任务条件选择损失的代理损失，在异构专家模型池中为医疗查询选择最佳专家模型。

- Motivation: 在医疗代理系统中，单一"最佳"模型很少存在，不同专家模型在不同数据样本上表现优异。因此，需要可靠地从异构工具候选池中选择合适的专家模型来处理特定查询。
- Method: 提出ToolSelect方法，基于注意力神经过程的选择器，以查询和每个模型的行为摘要为条件，在专家模型中进行选择。通过最小化任务条件选择损失的代理损失来学习模型选择。
- Result: 构建了首个代理胸部X光环境ToolSelectBench，包含1448个查询和55个任务专业化模型。ToolSelect在四个不同任务族中一致优于10个最先进方法。
- Conclusion: ToolSelect为医疗代理系统中的模型选择问题提供了有效解决方案，能够自适应地从异构专家模型池中选择最佳模型，显著提升任务性能。
## cs.CL

### [174] [RMPL: Relation-aware Multi-task Progressive Learning with Stage-wise Training for Multimedia Event Extraction](https://arxiv.org/abs/2602.13748)
*Yongkang Jin,Jianwen Luo,Jingjing Wang,Jianmin Yao,Yu Hong*

Main category: cs.CL

TL;DR: RMPL：一种关系感知的多任务渐进学习框架，用于低资源条件下的多媒体事件抽取，通过整合单模态事件抽取和多媒体关系抽取的异质监督，在多模态设置下提升事件语义的跨模态对齐和论元定位。

- Motivation: 多媒体事件抽取（MEE）需要跨文本和图像模态对事件语义进行对齐，但现有方法面临两个主要问题：1）缺乏标注训练数据（M2E2基准仅提供评估标注），使得监督训练不可行；2）现有方法主要依赖跨模态对齐或VLM的推理时提示，没有显式学习结构化事件表示，在多模态设置中产生较弱的论元定位。
- Method: 提出RMPL（关系感知多任务渐进学习框架），包含异质监督整合和分阶段训练：1）首先使用统一模式训练模型，学习跨模态共享的事件中心表示；2）然后使用混合文本和视觉数据对事件提及识别和论元角色抽取进行微调。框架整合了单模态事件抽取和多媒体关系抽取的监督信号。
- Result: 在M2E2基准测试中，使用多个视觉语言模型（VLMs）进行实验，在不同模态设置下均显示出一致的性能提升。
- Conclusion: RMPL通过整合异质监督和渐进学习策略，有效解决了低资源条件下多媒体事件抽取的挑战，显式学习了结构化事件表示，在多模态设置中实现了更好的事件语义跨模态对齐和论元定位。


### [175] [Index Light, Reason Deep: Deferred Visual Ingestion for Visual-Dense Document Question Answering](https://arxiv.org/abs/2602.14162)
*Tao Xu*

Main category: cs.CL

TL;DR: 提出延迟视觉摄取（DVI）框架，采用需求侧摄取策略，只在索引阶段提取轻量级元数据，将视觉理解推迟到用户提问时，显著降低VLM成本并提高可靠性。

- Motivation: 现有多模态文档问答方法采用供给侧摄取策略，在索引阶段对所有页面运行视觉语言模型生成描述，这种方法成本高（如113页工程图纸需约80,000 VLM token）、端到端不可靠（VLM输出可能因检索基础设施格式不匹配而无法正确检索），且一旦失败无法恢复。
- Method: 提出延迟视觉摄取（DVI）框架，核心原则是"索引用于定位而非理解"：索引阶段仅执行轻量级元数据提取，通过结构化元数据索引和BM25全文搜索实现页面定位，然后将原始图像与具体问题一起发送给VLM进行针对性分析。
- Result: 在两个真实工业工程图纸（113页+7页）上的实验表明，DVI在零摄取VLM成本下达到可比整体准确率（46.7% vs. 48.9%），在视觉必要查询上的有效率达到50%（vs. 预摄取0%），页面定位准确率100%（搜索空间压缩98%）。
- Conclusion: DVI将"问答准确率"问题转化为"页面定位"问题，支持交互式细化和渐进缓存，一旦找到正确图纸页面，获取答案就变成了交互轮次的问题，显著提高了多模态文档问答的效率和可靠性。
## cs.RO

### [176] [FlowHOI: Flow-based Semantics-Grounded Generation of Hand-Object Interactions for Dexterous Robot Manipulation](https://arxiv.org/abs/2602.13444)
*Huajian Zeng,Lingyun Chen,Jiaqi Yang,Yuantai Zhang,Fan Shi,Peidong Liu,Xingxing Zuo*

Main category: cs.RO

TL;DR: FlowHOI是一个两阶段流匹配框架，用于生成语义基础、时序连贯的手-物交互序列，包括手部姿态、物体姿态和接触状态，基于第一人称观察、语言指令和3D高斯场景重建。

- Motivation: 现有的视觉-语言-动作模型虽然能生成合理的末端执行器运动，但在长时程、接触丰富的任务中经常失败，因为底层的手-物交互结构没有被显式表示。需要一个与具体机器人无关的交互表示来捕捉这种结构，使操作行为更容易验证和跨机器人迁移。
- Method: 提出两阶段流匹配框架：1) 将几何中心的抓取与语义中心的操控解耦；2) 使用紧凑的3D场景token和运动-文本对齐损失来语义地基础生成的交互；3) 引入重建流程从大规模第一人称视频中恢复对齐的手-物轨迹和网格，为鲁棒生成提供HOI先验。
- Result: 在GRAB和HOT3D基准测试中，FlowHOI实现了最高的动作识别准确率和比最强扩散基线高1.7倍的物理模拟成功率，同时推理速度提升40倍。在四个灵巧操作任务上展示了真实机器人执行，验证了生成的HOI表示可以重定向到真实机器人执行流程。
- Conclusion: FlowHOI通过显式表示手-物交互结构，生成了语义基础、时序连贯的交互序列，显著提升了长时程、接触丰富任务的性能，并展示了向真实机器人迁移的可行性。


### [177] [Symmetry-Aware Fusion of Vision and Tactile Sensing via Bilateral Force Priors for Robotic Manipulation](https://arxiv.org/abs/2602.13689)
*Wonju Lee,Matteo Grimaldi,Tao Yu*

Main category: cs.RO

TL;DR: 提出Cross-Modal Transformer融合视觉与触觉信号，通过物理正则化实现96.59%插入成功率，接近特权传感器配置

- Motivation: 机器人插入任务需要精确的接触交互，仅靠视觉无法解决。现有研究显示简单的视觉-触觉融合往往无法带来稳定改进，需要更有效的多模态融合方法
- Method: 提出Cross-Modal Transformer (CMT)，通过结构化自注意力和交叉注意力融合手腕摄像头观测与触觉信号。引入物理正则化鼓励双边力平衡，反映人类运动控制原理
- Result: 在TacSL基准测试中，CMT加对称正则化达到96.59%插入成功率，超越简单融合和门控融合基线，接近特权"手腕+接触力"配置的96.09%
- Conclusion: 触觉感知对精确对齐不可或缺；基于原则的多模态融合结合物理正则化能释放视觉与触觉的互补优势，在现实传感条件下接近特权性能


### [178] [High-fidelity 3D reconstruction for planetary exploration](https://arxiv.org/abs/2602.13909)
*Alfonso Martínez-Petersen,Levin Gerdes,David Rodríguez-Martínez,C. J. Pérez-del-Pulgar*

Main category: cs.RO

TL;DR: 提出一个结合辐射场方法（NeRF和高斯泼溅）的自动化环境重建流程，用于行星机器人任务，能够从有限的视觉输入生成密集、逼真且度量一致的3D表示。

- Motivation: 行星探索需要自主机器人系统在缺乏全球定位和实时通信的情况下感知和重建环境。传统SfM和SLAM方法在几何一致性方面表现良好，但在捕捉辐射细节和处理低纹理、非结构化地形方面存在困难，而这类地形在行星环境中很常见。
- Method: 整合辐射场方法（NeRF和高斯泼溅）到统一自动化重建流程中，结合Nerfstudio和COLMAP框架，采用ROS2兼容的工作流程，能够直接处理来自rosbag记录的原始漫游车数据。
- Result: 开发了一个能够从最小视觉输入生成密集、逼真且度量一致的3D表示的流程，支持在行星类似条件下自主系统的改进感知和规划。
- Conclusion: 该流程为基于辐射场的映射研究奠定了基础，弥合了行星探索中几何表示和神经表示之间的差距，支持未来自主行星探索系统的发展。


### [179] [ProAct: A Dual-System Framework for Proactive Embodied Social Agents](https://arxiv.org/abs/2602.14048)
*Zeyi Zhang,Zixi Kang,Ruijie Zhao,Yusen Feng,Biao Jiang,Libin Liu*

Main category: cs.RO

TL;DR: ProAct：一个双系统框架，通过解耦低延迟的行为系统（处理流式多模态交互）和较慢的认知系统（进行长期社交推理），实现具身社交代理的主动行为，解决了实时交互中的时间尺度冲突。

- Motivation: 现有具身社交代理大多为反应式系统，只能在短时间窗口内响应当前感官输入，缺乏主动社交行为所需的长期上下文积累和意图推理能力，这与实时交互的严格延迟要求相冲突。
- Method: 提出ProAct双系统框架：1）低延迟的行为系统处理流式多模态交互；2）较慢的认知系统进行长期社交推理并生成高级主动意图。引入基于ControlNet的流式流匹配模型，支持异步意图注入，实现反应式和主动式手势在单一运动流中的无缝转换。
- Result: 在物理人形机器人上部署ProAct，评估运动质量和交互效果。真实世界交互用户研究表明，参与者和观察者一致认为ProAct在主动性、社交存在感和整体参与度方面优于反应式变体。
- Conclusion: 双系统主动控制框架能有效解决具身社交交互中的时间尺度冲突，实现更自然、主动的社交行为，提升交互体验的感知质量。


### [180] [SemanticFeels: Semantic Labeling during In-Hand Manipulation](https://arxiv.org/abs/2602.14099)
*Anas Al Shikh Khalil,Haozhi Qi,Roberto Calandra*

Main category: cs.RO

TL;DR: SemanticFeels扩展了NeuralFeels框架，将语义标注与神经隐式形状表示相结合，通过视觉和触觉实现物体形状和材料属性的感知，特别关注材料分类任务。

- Motivation: 随着机器人越来越多地融入日常任务，在手中操作时感知物体形状和属性的能力对于自适应和智能行为变得至关重要。
- Method: 使用高分辨率Digit触觉读数，通过微调的EfficientNet-B0卷积神经网络处理生成局部材料预测，然后嵌入到增强的符号距离场网络中，联合预测几何形状和连续材料区域。
- Result: 系统在单材料和多种材料物体上都实现了预测材料与实际材料的高度对应，在多材料物体上的多次操作试验中平均匹配准确率达到79.87%。
- Conclusion: SemanticFeels成功地将语义标注与神经隐式表示相结合，为机器人提供了更全面的物体感知能力，特别是在材料分类方面表现出色。


### [181] [Learning Part-Aware Dense 3D Feature Field for Generalizable Articulated Object Manipulation](https://arxiv.org/abs/2602.14193)
*Yue Chen,Muqing Jiang,Kaifeng Zheng,Jiaqi Liang,Chenrui Tie,Haoran Lu,Ruihai Wu,Hao Dong*

Main category: cs.RO

TL;DR: PA3FF是一种具有部件感知能力的密集3D特征场，通过对比学习从大规模标注数据中学习，用于提升关节物体操作的泛化能力和样本效率。

- Motivation: 关节物体操作在机器人任务中至关重要，但跨不同物体的泛化能力仍然是一个主要挑战。现有方法多基于2D特征，在提升到3D空间时面临运行时间长、多视角不一致、空间分辨率低等挑战。
- Method: 提出Part-Aware 3D Feature Field (PA3FF)，通过对比学习从大规模标注数据集的3D部件提议中训练，以点云为输入前向预测连续3D特征场。基于此特征，开发了Part-Aware Diffusion Policy (PADP)模仿学习框架。
- Result: PA3FF在模拟和真实世界任务中一致优于CLIP、DINOv2、Grounded-SAM等2D和3D表示方法。除了模仿学习，PA3FF还能支持对应关系学习和分割等下游任务。
- Conclusion: PA3FF是一种通用的机器人操作基础表示，通过部件感知的3D特征场有效解决了关节物体操作的泛化挑战，为多样化的下游应用提供了多功能基础。


### [182] [Neurosim: A Fast Simulator for Neuromorphic Robot Perception](https://arxiv.org/abs/2602.15018)
*Richeek Das,Pratik Chaudhari*

Main category: cs.RO

TL;DR: Neurosim是一个高性能实时传感器模拟库，支持动态视觉传感器、RGB相机、深度传感器和惯性传感器，同时能模拟多旋翼飞行器的敏捷动力学。配合Cortex通信库，可实现高达2700 FPS的模拟速度，便于机器学习与机器人工作流的集成。

- Motivation: 为神经形态感知与控制算法提供高效的训练和测试平台，解决真实传感器数据采集成本高、时间同步困难的问题，同时支持多模态数据的自监督学习。
- Method: 开发Neurosim传感器模拟库，支持多种传感器类型和无人机动力学模拟；结合Cortex通信库（基于ZeroMQ），提供Python和C++的高吞吐量、低延迟消息传递，支持NumPy数组和PyTorch张量。
- Result: 在桌面GPU上实现高达~2700 FPS的模拟帧率，成功集成到机器学习与机器人工作流中，支持神经形态算法的训练（如自监督学习）和实时闭环测试。
- Conclusion: Neurosim和Cortex为神经形态感知与控制算法提供了高效、可扩展的模拟和通信框架，显著降低了算法开发与测试的复杂度，推动了相关领域的研究进展。
## eess.IV

### [183] [Deep Learning CNN for Pneumonia Detection: Advancing Digital Health in Society 5.0](https://arxiv.org/abs/2602.13270)
*Hadi Almohab*

Main category: eess.IV

TL;DR: 基于深度学习的卷积神经网络（CNN）用于从胸部X光图像中自动检测肺炎，准确率达91.67%，ROC-AUC为0.96，PR-AUC为0.95，显示出作为快速、一致、可靠的诊断辅助工具的潜力。

- Motivation: 肺炎是全球严重的健康问题，尤其在诊断工具和医疗资源有限的地区导致高发病率和死亡率。需要开发自动化的诊断工具来改善医疗服务。
- Method: 开发基于深度学习的卷积神经网络（CNN），使用标记数据集进行训练，采用归一化、数据增强和图像质量增强等预处理技术来提高模型的鲁棒性和泛化能力。
- Result: 优化后的模型在测试中达到91.67%的准确率，ROC-AUC为0.96，PR-AUC为0.95，在区分肺炎和正常图像方面表现出色。
- Conclusion: 该CNN模型作为快速、一致、可靠的诊断辅助工具具有显著潜力，通过整合人工智能支持社会5.0，改善医疗服务和公共福祉。


### [184] [Learning to Select Like Humans: Explainable Active Learning for Medical Imaging](https://arxiv.org/abs/2602.13308)
*Ifrat Ikhtear Uddin,Longwei Wang,Xiao Qin,Yang Zhou,KC Santosh*

Main category: eess.IV

TL;DR: 提出一种基于可解释性引导的主动学习框架，通过结合分类不确定性和注意力对齐度双重标准，选择既具信息量又关注临床相关特征的样本进行标注，显著提升医学图像分析的数据效率。

- Motivation: 医学图像分析需要大量标注数据，但专家标注成本高、耗时长。传统主动学习方法仅依赖预测不确定性，忽略了模型是否学习临床有意义的特征，这对临床部署至关重要。
- Method: 提出可解释性引导的主动学习框架，采用双重标准选择策略：1) 分类不确定性识别信息量样本；2) 注意力错位度（Grad-CAM注意力图与放射科医生标注ROI的Dice相似度）识别模型关注错误特征的样本。通过测量注意力图与专家标注的对齐程度，智能选择能同时提升预测性能和空间可解释性的样本。
- Result: 在三个专家标注的医学影像数据集（BraTS、VinDr-CXR、SIIM-COVID-19）上评估，仅使用570个策略选择的样本，该方法在所有数据集上均优于随机采样：BraTS准确率77.22%，VinDr-CXR 52.37%，SIIM-COVID 52.66%。Grad-CAM可视化证实模型关注诊断相关区域。
- Conclusion: 将解释引导纳入样本选择过程，不仅能提高数据效率，还能保持临床可解释性。该方法在医学图像分析中实现了预测性能和模型可解释性的双重提升，为临床部署提供了更可靠的解决方案。


### [185] [FUTON: Fourier Tensor Network for Implicit Neural Representations](https://arxiv.org/abs/2602.13414)
*Pooya Ashtari,Pourya Behmandpoor,Nikos Deligiannis,Aleksandra Pizurica*

Main category: eess.IV

TL;DR: FUTON是一种基于傅里叶张量网络的隐式神经表示方法，通过低秩张量分解参数化傅里叶系数，在图像和体积表示任务中优于现有MLP方法，训练速度快2-5倍。

- Motivation: 现有基于MLP的隐式神经表示存在收敛慢、对噪声过拟合、外推能力差等问题，需要一种结合互补归纳偏置的新方法。
- Method: 将信号建模为广义傅里叶级数，系数通过低秩张量分解参数化，使用正交可分离基函数，结合傅里叶基的平滑性/周期性偏置和低秩参数化的低维谱结构偏置。
- Result: 在图像和体积表示任务中持续优于最先进的MLP-based INRs，训练速度快2-5倍；在图像去噪和超分辨率等逆问题上泛化更好、收敛更快。
- Conclusion: FUTON通过结合傅里叶基和低秩张量分解的互补归纳偏置，提供了一种高效、泛化能力强的隐式神经表示方法，具有理论保证和线性复杂度推理算法。


### [186] [Frequency-Enhanced Hilbert Scanning Mamba for Short-Term Arctic Sea Ice Concentration Prediction](https://arxiv.org/abs/2602.13522)
*Feng Gao,Zheng Gong,Wenli Liu,Yanhai Gan,Zhuoran Zheng,Junyu Dong,Qian Du*

Main category: eess.IV

TL;DR: 本文提出FH-Mamba框架，通过3D Hilbert扫描和频率增强机制改进北极海冰浓度预测，解决了传统Mamba模型在时间相关性和边界细节上的不足。

- Motivation: 传统Mamba模型在北极海冰浓度预测中面临时间相关性建模不足和边界细节捕捉困难的问题，需要改进以提升预测精度。
- Method: 提出FH-Mamba框架：1) 3D Hilbert扫描机制，沿保持局部性的路径遍历时空网格；2) 小波变换增强高频细节；3) 混合洗牌注意力模块自适应聚合序列和频率特征。
- Result: 在OSI-450a1和AMSR2数据集上的实验表明，FH-Mamba相比现有最佳基线方法取得了更优的预测性能，证实了Hilbert扫描和频率感知注意力在提升时间一致性和边缘重建方面的有效性。
- Conclusion: FH-Mamba框架通过创新的3D Hilbert扫描和频率增强机制，显著提升了北极海冰浓度短期预测的准确性和细节保留能力，为相关领域提供了有效的解决方案。


### [187] [Learnable Multi-level Discrete Wavelet Transforms for 3D Gaussian Splatting Frequency Modulation](https://arxiv.org/abs/2602.14199)
*Hung Nguyen,An Le,Truong Nguyen*

Main category: eess.IV

TL;DR: 本文提出了一种基于多级离散小波变换的频率调制框架，用于减少3D高斯泼溅中的高斯基元数量，同时保持渲染质量。

- Motivation: 3D高斯泼溅在训练过程中高斯基元数量会大幅增长，导致内存和存储成本增加。现有的AutoOpti3DGS方法使用可学习的单级离散小波变换进行频率调制，但调制深度有限，且联合优化会引入梯度竞争，导致过度的高斯致密化。
- Method: 提出多级离散小波变换频率调制框架，通过递归分解低频子带构建更深的课程学习机制，在早期训练中提供逐渐粗糙的监督。此外，使用单个缩放参数而非完整的2抽头高通滤波器进行调制。
- Result: 在标准基准测试中，该方法进一步减少了高斯基元数量，同时保持了具有竞争力的渲染质量。
- Conclusion: 多级DWT频率调制框架能有效控制3D高斯泼溅中的高斯增长，减少内存和存储成本，同时保持渲染性能。
