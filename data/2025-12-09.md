[[toc]]

## cs.CV

### [1] [Video Models Start to Solve Chess, Maze, Sudoku, Mental Rotation, and Raven' Matrices](https://arxiv.org/abs/2512.05969)
*Hokin Deng*

Main category: cs.CV

TL;DR: 视频生成模型已具备推理能力，在多种推理任务上达到60%成功率，并建立了可扩展的评估框架

- Motivation: 探索视频生成模型是否具备推理能力，建立系统化的评估范式来量化这种能力
- Method: 采用"任务对"设计建立实验范式，构建支持39个模型的代码框架VMEvalKit，实现自动化评估并与人工判断相关
- Result: Sora-2等领先模型在象棋、迷宫、数独、心理旋转、瑞文矩阵等推理任务上达到60%成功率，自动化评估与人工判断高度相关
- Conclusion: 视频生成模型已具备推理能力，建立的评估范式具有高度可扩展性，为通过强化学习提升视频模型推理能力提供了机会


### [2] [Adaptive Dataset Quantization: A New Direction for Dataset Pruning](https://arxiv.org/abs/2512.05987)
*Chenyue Yu,Jianyu Yu*

Main category: cs.CV

TL;DR: 提出一种新颖的数据集量化方法，通过减少样本内冗余来压缩大规模数据集，在保持模型训练性能的同时显著降低存储和通信成本。

- Motivation: 针对资源受限的边缘设备中大规模数据集的存储和通信成本挑战，传统的数据集剪枝和蒸馏方法主要关注样本间冗余，但忽略了样本内的冗余内容。
- Method: 首先应用线性对称量化获得每个样本的初始量化范围和尺度，然后引入自适应量化分配算法，为具有不同精度要求的样本分配不同的量化比率，同时保持恒定的总压缩比。
- Result: 在CIFAR-10、CIFAR-100和ImageNet-1K上的实验表明，该方法在保持模型训练性能的同时实现了显著的数据集压缩，在相同压缩比下优于传统量化和数据集剪枝基线。
- Conclusion: 该方法首次使用有限比特表示数据集以减少存储，引入具有自适应比率分配的数据集级量化算法，为资源受限环境中的大规模数据集管理提供了有效解决方案。


### [3] [VG3T: Visual Geometry Grounded Gaussian Transformer](https://arxiv.org/abs/2512.05988)
*Junho Kim,Seongwon Lee*

Main category: cs.CV

TL;DR: VG3T：一种新颖的多视角前馈网络，通过3D高斯表示预测3D语义占据，解决了多视角融合中的碎片化问题，在nuScenes基准上实现了性能提升和效率优化。

- Motivation: 现有方法在多视角融合方面存在困难，导致3D表示碎片化和性能不佳。需要一种能够统一表示几何和语义的多视角处理方法。
- Method: VG3T采用多视角前馈网络，直接预测一组具有语义属性的3D高斯表示。引入网格采样和位置细化两个关键组件，解决像素对齐高斯初始化中的距离相关密度偏差问题。
- Result: 在nuScenes基准测试中，VG3T相比之前的最优方法实现了1.7%的mIoU提升，同时使用的高斯基元数量减少了46%，显示出优越的效率和性能。
- Conclusion: VG3T通过统一的多视角高斯表示方法，有效解决了3D场景重建中的碎片化问题，为几何和语义的联合表示提供了新范式，在性能和效率方面均有显著提升。


### [4] [EmoDiffTalk:Emotion-aware Diffusion for Editable 3D Gaussian Talking Head](https://arxiv.org/abs/2512.05991)
*Chang Liu,Tianjiao Jing,Chengcheng Ma,Xuanqi Zhou,Zhengxuan Lian,Qin Jin,Hongliang Yuan,Shi-Sheng Huang*

Main category: cs.CV

TL;DR: EmoDiffTalk：首个支持连续多模态情感编辑的3D高斯泼溅说话头生成框架，通过情感感知高斯扩散和文本到动作单元控制器实现精细情感表达

- Motivation: 当前基于3D高斯泼溅的真实感3D说话头在情感表达操控方面存在不足，特别是缺乏细粒度和扩展性的多模态情感编辑能力
- Method: 提出情感感知高斯扩散方法，包括动作单元提示的高斯扩散过程用于细粒度面部动画，以及精确的文本到动作单元情感控制器，支持文本输入的情感编辑
- Result: 在EmoTalk3D和RenderMe-360数据集上实验表明，EmoDiffTalk在情感细腻度、唇形同步保真度和可控性方面优于先前工作
- Conclusion: EmoDiffTalk建立了高质量、扩散驱动、多模态可编辑3D说话头合成的原则性途径，是首批支持连续多模态情感编辑的3D高斯泼溅说话头生成框架


### [5] [Domain-Specific Foundation Model Improves AI-Based Analysis of Neuropathology](https://arxiv.org/abs/2512.05993)
*Ruchika Verma,Shrishtee Kandoi,Robina Afzal,Shengjia Chen,Jannes Jegminat,Michael W. Karlovich,Melissa Umphlett,Timothy E. Richardson,Kevin Clare,Quazi Hossain,Jorge Samanamud,Phyllis L. Faust,Elan D. Louis,Ann C. McKee,Thor D. Stein,Jonathan D. Cherry,Jesse Mez,Anya C. McGoldrick,Dalilah D. Quintana Mora,Melissa J. Nirenberg,Ruth H. Walker,Yolfrankcis Mendez,Susan Morgello,Dennis W. Dickson,Melissa E. Murray,Carlos Cordon-Cardo,Nadejda M. Tsankova,Jamie M. Walker,Diana K. Dangoor,Stephanie McQuillan,Emma L. Thorn,Claudia De Sanctis,Shuying Li,Thomas J. Fuchs,Kurt Farrell,John F. Crary,Gabriele Campanella*

Main category: cs.CV

TL;DR: NeuroFM是专门针对脑组织病理图像训练的领域专用基础模型，相比通用病理基础模型在神经病理学任务上表现更优。

- Motivation: 现有病理基础模型主要基于外科病理数据训练，这些数据富含非神经组织，过度代表肿瘤、炎症、代谢等非神经系统疾病。神经病理学具有独特的细胞类型、细胞结构和疾病特征，这种领域不匹配限制了通用模型捕捉神经退行性疾病关键形态特征的能力。
- Method: 开发了NeuroFM，这是一个专门在涵盖多种神经退行性病变的脑组织全切片图像上训练的基础模型。
- Result: NeuroFM在多个神经病理学特定下游任务上表现优于通用模型，包括混合性痴呆疾病分类、海马区域分割、神经退行性共济失调识别（涵盖小脑性特发性震颤和脊髓小脑性共济失调亚型）。
- Conclusion: 领域专用基础模型能更好地捕捉神经病理学特定特征，为脑疾病诊断和研究提供更准确可靠的AI分析，为数字病理学专业领域的模型开发树立了先例。


### [6] [FishDetector-R1: Unified MLLM-Based Framework with Reinforcement Fine-Tuning for Weakly Supervised Fish Detection, Segmentation, and Counting](https://arxiv.org/abs/2512.05996)
*Yi Liu,Jingyu Song,Vedanth Kallakuri,Katherine A. Skinner*

Main category: cs.CV

TL;DR: FishDetector-R1是一个基于多模态大语言模型的弱监督框架，用于水下鱼类检测、分割和计数，在DeepFish数据集上显著提升了性能指标。

- Motivation: 水下鱼类图像分析对生态监测至关重要，但由于视觉质量退化和标注成本高昂，这一问题仍然具有挑战性。需要开发能够在弱监督下准确进行鱼类检测、分割和计数的解决方案。
- Method: 提出了一个统一的MLLM（多模态大语言模型）框架，包含两个关键组件：1）新颖的"检测到计数"提示，强制空间一致的检测和计数；2）基于可验证奖励的强化学习（RLVR），利用稀疏点标签的互补可扩展范式。
- Result: 在DeepFish数据集上，相比基线方法，AP提高了20%，mIoU提高了10%，MAE降低了30%，GAME降低了35%。消融研究验证了奖励设计的有效性，且改进在其他水下数据集上泛化良好，显示出强大的跨域鲁棒性。
- Conclusion: FishDetector-R1通过弱监督提供了一个可靠且可扩展的解决方案，能够实现准确的海洋视觉理解。该框架在性能指标上取得显著提升，并展现出良好的泛化能力。


### [7] [PrunedCaps: A Case For Primary Capsules Discrimination](https://arxiv.org/abs/2512.06003)
*Ramin Sharifi,Pouya Shiri,Amirali Baniasadi*

Main category: cs.CV

TL;DR: 胶囊网络通过剪枝95%的主要胶囊，实现9.9倍加速和95.36%浮点运算减少，且不损失精度

- Motivation: 胶囊网络相比CNN具有更好的仿射变换鲁棒性和重叠图像检测能力，但主要胶囊数量多导致训练测试慢、资源消耗大，需要提高效率
- Method: 对胶囊网络中的主要胶囊进行剪枝，在MNIST、Fashion-MNIST、CIFAR-10和SVHN数据集上验证效果
- Result: 剪枝95%的主要胶囊后，性能提升9.9倍，动态路由阶段浮点运算减少95.36%，且不损失精度；不同数据集对剪枝的响应程度不同
- Conclusion: 胶囊网络的主要胶囊可以大幅剪枝而不影响精度，显著提升计算效率，为资源受限环境下的应用提供了可行性


### [8] [Simple Agents Outperform Experts in Biomedical Imaging Workflow Optimization](https://arxiv.org/abs/2512.06006)
*Xuefei,Wang,Kai A. Horstmann,Ethan Lin,Jonathan Chen,Alexander R. Farhang,Sophia Stiles,Atharva Sehgal,Jonathan Light,David Van Valen,Yisong Yue,Jennifer J. Sun*

Main category: cs.CV

TL;DR: AI代理能自动优化科学计算机视觉代码，超越人类专家方案，为实际部署提供可行路径

- Motivation: 将生产级计算机视觉工具适配到特定科学数据集存在"最后一公里"瓶颈：微调需要大量标注数据（科学家通常缺乏），而手动代码适配需要科学家数周到数月的努力
- Method: 引入系统化的代理代码优化评估框架，研究三个生产级生物医学成像流程，比较不同代理架构的性能
- Result: 简单的代理框架能持续生成优于人类专家解决方案的适配代码；常见复杂代理架构并非普遍有益，为代理设计提供实用路线图
- Conclusion: AI代理能有效自动化科学代码适配，框架已开源，代理生成函数已部署到生产流程中，展示了实际应用潜力


### [9] [Fast and Flexible Robustness Certificates for Semantic Segmentation](https://arxiv.org/abs/2512.06010)
*Thomas Massena,Corentin Friedrich,Franck Mamalet,Mathieu Serrurier*

Main category: cs.CV

TL;DR: 提出一种基于Lipschitz约束的可认证鲁棒语义分割网络，实现实时兼容的认证，比随机平滑方法快600倍。

- Motivation: 深度神经网络对微小扰动敏感，现有鲁棒性研究主要集中在分类任务，语义分割的高效认证方法较少，需要开发实时兼容的认证方案。
- Method: 引入具有内置Lipschitz约束的新型可认证鲁棒语义分割网络，提出通用化语义分割鲁棒性认证框架，利用Lipschitz网络实现灵活高效计算。
- Result: 在Cityscapes等挑战性数据集上实现竞争性像素精度，认证推理速度比随机平滑方法快600倍，首次实现实时兼容的可认证鲁棒语义分割。
- Conclusion: 该方法为语义分割任务提供了高效、灵活的可认证鲁棒性解决方案，能够计算ℓ₂攻击下的最坏情况性能，并通过对抗攻击验证了证书的紧致性。


### [10] [High-Throughput Unsupervised Profiling of the Morphology of 316L Powder Particles for Use in Additive Manufacturing](https://arxiv.org/abs/2512.06012)
*Emmanuel Akeweje,Conall Kirk,Chi-Wai Chan,Denis Dowling,Mimi Zhang*

Main category: cs.CV

TL;DR: 提出基于机器学习的自动粉末形态分析框架，通过高分辨率成像和聚类方法大规模分析金属粉末形态，为SLM增材制造提供实时原料监控

- Motivation: 传统粉末表征方法效率低且定性，无法捕捉工业规模批次的异质性，而SLM零件质量严重依赖于原料粉末形态
- Method: 开发自动化机器学习框架，结合高通量成像、形状提取和聚类分析；评估三种聚类流程：自编码器流程、形状描述符流程和功能数据流程
- Result: 在约126,000个粉末图像数据集上，傅里叶描述符+k-means流程表现最佳，具有最低的Davies-Bouldin指数和最高的Calinski-Harabasz分数，同时在标准工作站上保持亚毫秒级处理速度
- Conclusion: 该无监督学习框架实现了粉末形态的快速自动评估，支持跟踪重复使用周期中的形状演变，为SLM工作流程中的实时原料监控提供了路径


### [11] [VAT: Vision Action Transformer by Unlocking Full Representation of ViT](https://arxiv.org/abs/2512.06013)
*Wenhao Li,Chengwei Ma,Weixin Mao*

Main category: cs.CV

TL;DR: VAT（Vision Action Transformer）是一种新型架构，通过利用ViT的完整特征层次结构，实现感知与动作生成的深度渐进融合，在机器人模仿学习中达到最先进性能。

- Motivation: 当前机器人学习中，Vision Transformers（ViTs）是视觉感知的标准方法，但大多数方法只使用最后一层的特征，丢弃了有价值的信息。作者认为这提供了不充分的表示，需要利用ViT的完整特征层次结构。
- Method: 提出Vision Action Transformer（VAT），从ViT扩展而来，解锁ViT的完整特征层次结构。VAT处理专门的动作令牌，在所有Transformer层中与视觉特征交互，实现感知与动作生成的深度渐进融合。
- Result: 在模拟操作任务套件中，VAT在四个LIBERO基准测试上实现了98.15%的平均成功率，超越了OpenVLA-OFT等先前方法，建立了新的最先进水平。
- Conclusion: VAT不仅为模仿学习提供了一个强大的模型，还证明了利用视觉模型的完整"表示轨迹"对于推进机器人策略至关重要。这项工作强调了充分利用ViT特征层次的重要性。


### [12] [Benchmarking CXR Foundation Models With Publicly Available MIMIC-CXR and NIH-CXR14 Datasets](https://arxiv.org/abs/2512.06014)
*Jiho Shin,Dominic Marshall,Matthieu Komorowski*

Main category: cs.CV

TL;DR: 该研究对两个大规模胸部X光嵌入模型（CXR-Foundation和MedImageInsight）在公开数据集上进行了基准测试，发现MedImageInsight性能略优，而CXR-Foundation具有更好的跨数据集稳定性。

- Motivation: 尽管基础模型在医学图像表示学习方面表现出色，但它们在跨数据集上的比较行为尚未得到充分探索。本研究旨在对两个大型胸部X光嵌入模型进行标准化基准测试，以了解它们的相对性能。
- Method: 使用统一的预处理流程和固定的下游分类器，在MIMIC-CR和NIH ChestX-ray14数据集上评估两个模型。直接从预训练编码器提取嵌入，使用LightGBM分类器训练多个疾病标签，报告平均AUROC和F1分数及95%置信区间。
- Result: MedImageInsight在大多数任务中性能略高，而CXR-Foundation表现出更强的跨数据集稳定性。MedImageInsight嵌入的无监督聚类显示出与定量结果一致的疾病特异性结构。
- Conclusion: 研究强调了医学基础模型标准化评估的必要性，并为未来多模态和临床整合研究建立了可复现的基线。两个模型各有优势，选择取决于具体应用需求。


### [13] [PrefGen: Multimodal Preference Learning for Preference-Conditioned Image Generation](https://arxiv.org/abs/2512.06020)
*Wenyi Mo,Tianyu Zhang,Yalong Bai,Ligong Han,Ying Ba,Dimitris N. Metaxas*

Main category: cs.CV

TL;DR: 提出基于多模态大语言模型的个性化图像生成框架，通过偏好导向的视觉问答任务提取用户表征，并注入扩散模型实现个性化生成

- Motivation: 现有方法难以捕捉用户细微偏好，缺乏有效编码个性化视觉信号的机制，需要更精准的用户偏好建模方法
- Method: 1) 训练MLLM进行偏好导向的视觉问答以提取细粒度语义线索；2) 引入用户间区分和用户内区分两个互补的探测任务来分离偏好相关特征；3) 设计基于最大均值差异的对齐损失来弥合模态差距；4) 将生成的嵌入用于条件化扩散生成器
- Result: 在图像质量和偏好对齐方面显著优于现有基线方法，验证了表征提取和对齐策略的有效性
- Conclusion: 提出的多模态框架通过有效的用户表征提取和对齐机制，成功实现了既能忠实于文本提示又能符合用户偏好的个性化图像生成


### [14] [Neural reconstruction of 3D ocean wave hydrodynamics from camera sensing](https://arxiv.org/abs/2512.06024)
*Jiabin Liu,Zihao Zhou,Jialei Yan,Anxin Guo,Alvise Benetazzo,Hui Li*

Main category: cs.CV

TL;DR: 提出一种基于注意力增强金字塔架构的波浪自由表面视觉重建神经网络，用于从立体视觉数据中高效重建三维波浪表面和速度场，在真实海况下实现毫米级精度和快速计算。

- Motivation: 解决长期海洋波浪观测任务中密集视觉重建计算成本高的问题，以及持续视觉遮挡带来的挑战，实现对波浪自由表面和速度场的精确三维重建。
- Method: 设计注意力增强的金字塔架构神经网络，适应波浪运动的多尺度和时间连续特性；利用物理约束从演化的自由表面边界进行时间分辨的三维速度场重建；基于立体视觉数据集。
- Result: 在真实海况下实现中央区域毫米级波浪高程预测，主频误差低于0.01 Hz，精确估计高频谱幂律，高保真三维非线性速度场重建，仅需1.35秒即可重建200万个点。
- Conclusion: 该模型优于传统视觉重建方法，在遮挡条件下保持强泛化能力，得益于其全局多尺度注意力和学习到的波浪传播动力学编码，为海洋物理研究提供有效工具。


### [15] [The SAM2-to-SAM3 Gap in the Segment Anything Model Family: Why Prompt-Based Expertise Fails in Concept-Driven Image Segmentation](https://arxiv.org/abs/2512.06032)
*Ranjan Sapkota,Konstantinos I. Roumeliotis,Manoj Karkee*

Main category: cs.CV

TL;DR: SAM2与SAM3之间存在根本性断裂：SAM2是基于空间提示的几何分割，而SAM3是统一的多模态概念驱动架构，具备开放词汇推理和语义理解能力。

- Motivation: 研究SAM2和SAM3之间的根本性差异，解释为什么SAM2的提示分割专业知识无法迁移到SAM3的多模态概念驱动范式，阐明两者在核心设计理念上的本质区别。
- Method: 通过五个核心组件进行对比分析：1) 概念断裂：提示分割vs概念分割；2) 架构差异：纯视觉-时间设计vs多模态融合；3) 数据集差异：视频掩码vs多模态概念标注；4) 训练差异：优化知识不适用；5) 评估差异：几何指标vs语义开放词汇评估。
- Result: 分析表明SAM3是一个全新的分割基础模型类别，标志着从几何分割向概念驱动分割时代的转变，两者在架构、训练、评估等方面存在根本性不连续性。
- Conclusion: SAM3代表了分割基础模型的新范式，开启了概念驱动分割的新时代，为未来研究方向提供了框架。


### [16] [Representation Learning for Point Cloud Understanding](https://arxiv.org/abs/2512.06058)
*Siming Yan*

Main category: cs.CV

TL;DR: 该论文提出了一种通过整合预训练的2D模型来增强3D点云理解的方法，涵盖监督学习、自监督学习和2D到3D迁移学习三个方向，显著提升了3D表示学习效果。

- Motivation: 随着3D数据获取技术的快速发展，3D数据在计算机视觉、机器人等领域应用日益广泛。将3D数据与2D图像结合可以为机器提供更全面的环境理解，但如何有效利用2D知识来增强3D理解而不只是简单转换2D数据是一个关键挑战。
- Method: 论文提出了三个主要方法：1）监督表示学习用于点云基元分割；2）自监督学习方法；3）从2D到3D的迁移学习。核心方法是整合预训练的2D模型来支持3D网络训练，而不是简单地将2D数据转换为3D。
- Result: 通过大量实验验证了所提方法的有效性，表明整合2D知识可以显著提升3D理解能力，推动了点云表示学习的发展。
- Conclusion: 该研究展示了通过有效整合2D知识来增强3D点云理解的可行性，为3D表示学习提供了新的方向，在自动驾驶、机器人、遥感和医疗等领域具有重要应用潜力。


### [17] [EgoEdit: Dataset, Real-Time Streaming Model, and Benchmark for Egocentric Video Editing](https://arxiv.org/abs/2512.06065)
*Runjia Li,Moayed Haji-Ali,Ashkan Mirzaei,Chaoyang Wang,Arpit Sahni,Ivan Skorokhodov,Aliaksandr Siarohin,Tomas Jakab,Junlin Han,Sergey Tulyakov,Philip Torr,Willi Menapace*

Main category: cs.CV

TL;DR: 提出EgoEdit生态系统，包括专门为第一人称视频编辑设计的数据集EgoEditData、支持实时流式推理的编辑器EgoEdit，以及评估套件EgoEditBench，解决第一人称视频编辑中的独特挑战。

- Motivation: 现有AI视频编辑器主要针对第三人称视频，而第一人称视频存在快速自我运动和频繁手物交互等独特挑战，造成显著的领域差距。此外，现有离线编辑流程延迟高，限制了实时交互。
- Method: 构建EgoEditData数据集（专门为第一人称编辑场景设计，包含丰富的手物交互并明确保留手部）；开发EgoEdit编辑器（支持指令跟随和单GPU实时流式推理）；创建EgoEditBench评估套件（针对指令忠实度、手部和交互保留、自我运动下的时间稳定性）。
- Result: EgoEdit在时间稳定性、指令忠实度和交互延迟方面表现优异。在第一人称编辑基准上取得明显优势（现有方法在此表现不佳），同时在通用编辑任务上保持与最强基线相当的性能。
- Conclusion: 提出了完整的EgoEdit生态系统，专门解决第一人称视频编辑的独特挑战，实现了实时交互式编辑。EgoEditData和EgoEditBench将公开供研究社区使用。


### [18] [Shoot-Bounce-3D: Single-Shot Occlusion-Aware 3D from Lidar by Decomposing Two-Bounce Light](https://arxiv.org/abs/2512.06080)
*Tzofi Klinghoffer,Siddharth Somasundaram,Xiaoyu Xiang,Yuchen Fan,Christian Richardt,Akshat Dave,Ramesh Raskar,Rakesh Ranjan*

Main category: cs.CV

TL;DR: 利用单光子激光雷达的多重反射光信息，通过数据驱动方法解决多路复用照明下的3D场景重建问题，特别针对遮挡区域和镜面材料

- Motivation: 单视角3D场景重建在存在遮挡区域和镜面材料（如镜子）时具有挑战性。传统单光子激光雷达方法仅适用于逐点扫描场景，而实际应用中需要同时照明多个场景点，这增加了光传输的复杂性
- Method: 提出数据驱动方法反演单光子激光雷达中的光传输：1）创建首个大规模室内场景激光雷达瞬态数据集（约10万个）；2）学习复杂光传输先验；3）将测量的双重反射光分解为每个激光点的贡献
- Result: 通过实验证明，分解后的光可用于从单次测量中推断具有遮挡和镜子的场景的3D几何结构。代码和数据集已开源
- Conclusion: 该方法能够利用单光子激光雷达的多重反射光信息，解决多路复用照明下的复杂光传输问题，实现遮挡场景和镜面材料的3D重建


### [19] [BeLLA: End-to-End Birds Eye View Large Language Assistant for Autonomous Driving](https://arxiv.org/abs/2512.06096)
*Karthik Mohan,Sonam Singh,Amit Arvind Kale*

Main category: cs.CV

TL;DR: BeLLA是一个端到端架构，将统一的360°BEV表示与大型语言模型连接，用于自动驾驶问答任务，在需要空间推理的问题上显著优于现有方法。

- Motivation: 现有视觉语言模型在自动驾驶研究中存在局限性：单视角编码器无法利用多摄像头系统的空间结构，而聚合多视角特征缺乏统一的空间表示，难以进行自我中心方向、物体关系和上下文推理。
- Method: 提出BeLLA端到端架构，将统一的360°鸟瞰图(BEV)表示与大型语言模型连接，用于自动驾驶场景的问答任务。
- Result: 在NuScenes-QA和DriveLM基准测试中，BeLLA在需要空间推理的问题上（如相对物体定位和行为理解）显著优于现有方法，某些任务获得+9.3%的绝对提升，在其他类别中也表现有竞争力。
- Conclusion: BeLLA通过结合统一的BEV表示和语言模型，有效解决了自动驾驶中空间推理的挑战，能够处理多样化的问答任务，特别是在空间推理方面表现出色。


### [20] [SpectraIrisPAD: Leveraging Vision Foundation Models for Spectrally Conditioned Multispectral Iris Presentation Attack Detection](https://arxiv.org/abs/2512.06103)
*Raghavendra Ramachandra,Sushma Venkatesh*

Main category: cs.CV

TL;DR: 提出SpectraIrisPAD框架，利用多光谱成像和DINOv2 ViT进行虹膜呈现攻击检测，并构建了包含18,848张图像的新数据集MSIrPAD

- Motivation: 虹膜识别虽然准确，但在实际应用中容易受到呈现攻击的威胁。传统虹膜系统主要在近红外波段工作，而多光谱成像能提供互补的反射信息，增强呈现攻击检测方法的泛化能力。
- Method: 提出SpectraIrisPAD框架，使用DINOv2 Vision Transformer作为骨干网络，配备可学习的光谱位置编码、令牌融合和对比学习，提取区分性的波段特定特征来区分真实样本和欺骗攻击。
- Result: 构建了包含18,848张虹膜图像的新数据集MSIrPAD，涵盖8种不同的呈现攻击类别。在未见攻击评估协议下，SpectraIrisPAD在所有性能指标上均优于多个最先进的基线方法。
- Conclusion: SpectraIrisPAD框架在检测多种呈现攻击方面表现出卓越的鲁棒性和泛化能力，证明了多光谱成像和深度学习结合在虹膜呈现攻击检测中的有效性。


### [21] [Explainable Melanoma Diagnosis with Contrastive Learning and LLM-based Report Generation](https://arxiv.org/abs/2512.06105)
*Junwen Zheng,Xinran Xu,Li Rong Wang,Chang Cai,Lucinda Siyun Tan,Dingyuan Wang,Hong Liang Tey,Xiuyi Fan*

Main category: cs.CV

TL;DR: 提出CEFM框架，通过对比学习将临床ABC诊断标准映射到视觉特征空间，生成结构化文本解释，提升黑色素瘤分类的可解释性和临床信任度。

- Motivation: 深度学习在黑色素瘤分类中已达到专家水平，但模型不透明和缺乏可解释性阻碍了临床应用，医生难以信任黑盒模型的决策过程。
- Method: 提出跨模态可解释框架CEFM，使用对比学习作为核心机制，通过双投影头将临床ABC诊断标准映射到Vision Transformer嵌入空间，将对齐的表征通过自然语言生成转换为结构化文本解释。
- Result: 在公开数据集上达到92.79%准确率和0.961的AUC，在多个可解释性指标上有显著提升，学习到的嵌入空间排列与医生应用ABC规则的方式一致。
- Conclusion: CEFM框架成功地将高性能分类与临床信任连接起来，通过将临床语义与视觉特征对齐并生成可理解的解释，为黑色素瘤诊断提供了既准确又可解释的解决方案。


### [22] [Tracking-Guided 4D Generation: Foundation-Tracker Motion Priors for 3D Model Animation](https://arxiv.org/abs/2512.06158)
*Su Sun,Cheng Zhao,Himangi Mittal,Gaurav Mittal,Rohith Kukkala,Yingjie Victor Chen,Mei Chen*

Main category: cs.CV

TL;DR: Track4DGen：两阶段框架，通过注入跟踪器运动先验到扩散特征中，从稀疏输入生成动态4D对象，提升时间一致性和视图连贯性

- Motivation: 从稀疏输入生成动态4D对象面临挑战：需要同时保持外观和运动在视图和时间上的一致性，同时抑制伪影和时间漂移。现有方法仅依赖像素或潜在空间的视频扩散损失监督，缺乏明确的时间感知特征级跟踪指导
- Method: Track4DGen采用两阶段框架：第一阶段在多视图视频扩散模型中注入跟踪器导出的运动先验，强制密集特征级点对应关系；第二阶段使用混合运动编码重建4D高斯泼溅，结合扩散特征（携带跟踪先验）和Hex-plane特征，并用4D球谐函数增强动态建模
- Result: Track4DGen在多视图视频生成和4D生成基准测试中超越基线方法，产生时间稳定、可文本编辑的4D资产。同时创建了Sketchfab28高质量数据集用于对象中心4D生成基准测试
- Conclusion: 通过将跟踪器运动先验显式注入扩散特征表示，Track4DGen有效解决了动态4D对象生成中的时间一致性和视图连贯性问题，为4D内容生成提供了新方法


### [23] [Automated Annotation of Shearographic Measurements Enabling Weakly Supervised Defect Detection](https://arxiv.org/abs/2512.06171)
*Jessica Plassmann,Nicolas Schuler,Michael Schuth,Georg von Freymann*

Main category: cs.CV

TL;DR: 提出基于深度学习的自动化工作流，从剪切散斑测量中生成缺陷标注，减少人工标注需求，支持可扩展的数据集创建

- Motivation: 剪切散斑技术用于检测安全关键部件的亚表面缺陷，但工业应用受限于缺乏高质量标注数据集，因为人工标注劳动密集、主观性强且难以标准化
- Method: 引入自动化工作流，使用深度学习从剪切散斑测量中生成缺陷标注，产生高分辨率分割和边界框标签
- Result: 与专家标注数据对比评估显示，该方法具有足够准确性，能够支持弱监督训练，减少人工工作量
- Conclusion: 该自动化工作流能够支持可扩展的数据集创建，为稳健的缺陷检测提供解决方案


### [24] [Physics-Grounded Shadow Generation from Monocular 3D Geometry Priors and Approximate Light Direction](https://arxiv.org/abs/2512.06174)
*Shilin Hu,Jingyi Xu,Akshat Dave,Dimitris Samaras,Hieu Le*

Main category: cs.CV

TL;DR: 提出将显式物理建模（几何与光照）嵌入深度学习阴影生成的新框架，通过3D几何和主导光方向预测物理阴影位置形状，再用扩散模型精细化，在复杂场景中优于现有方法。

- Motivation: 当前基于深度学习的阴影生成方法很少利用阴影形成的显式物理建模（遮挡物几何和场景光照），而物理建模能提供更准确的阴影位置和形状信息。
- Method: 1) 从单目RGB图像获取密集点云形式的近似3D几何并预测主导光方向；2) 基于阴影形成物理原理恢复阴影位置和形状；3) 将此物理估计集成到扩散框架中，精细化阴影外观同时保持几何和光照一致性。
- Result: 在DESOBAV2数据集上训练，模型生成的阴影既视觉逼真又物理一致，在复杂几何或模糊光照场景中表现优于现有方法。
- Conclusion: 将显式物理建模嵌入深度学习阴影生成框架能产生更逼真、物理一致的阴影，特别是在复杂场景中，证明了物理原理与深度学习结合的有效性。


### [25] [Physics-Grounded Attached Shadow Detection Using Approximate 3D Geometry and Light Direction](https://arxiv.org/abs/2512.06179)
*Shilin Hu,Jingyi Xu,Sagnik Das,Dimitris Samaras,Hieu Le*

Main category: cs.CV

TL;DR: 提出首个联合检测投射阴影和附着阴影的框架，通过光照与几何推理形成闭环优化，并创建了首个包含两种阴影标注的数据集。

- Motivation: 现有阴影检测方法主要针对投射阴影，缺乏专门检测附着阴影的数据集和模型，而附着阴影对理解物体三维结构至关重要。
- Method: 构建包含阴影检测模块和光照估计模块的系统，通过检测阴影推断光照方向，结合表面法线生成几何一致的部分遮挡图，反馈优化阴影预测，形成闭环推理过程。
- Result: 实验表明该迭代几何-光照推理方法显著提升附着阴影检测性能（BER降低至少33%），同时保持对完整阴影和投射阴影的良好检测效果。
- Conclusion: 通过联合推理阴影、光照和几何关系，首次实现了对附着阴影的有效检测，为三维场景理解提供了新工具。


### [26] [SPOOF: Simple Pixel Operations for Out-of-Distribution Fooling](https://arxiv.org/abs/2512.06185)
*Ankit Gupta,Christoph Adami,Emily Dolson*

Main category: cs.CV

TL;DR: 现代深度神经网络（包括卷积和Transformer架构）仍然容易受到高置信度欺骗图像攻击，Transformer模型尤其脆弱。作者提出SPOOF攻击方法，能以更少查询生成高置信度欺骗图像，且现有防御措施效果有限。

- Motivation: 尽管深度神经网络在图像识别任务中表现出色，但它们仍然对与自然图像毫无相似之处的输入表现出过度自信。作者旨在重新验证Nguyen等人（2015）提出的"欺骗图像"问题在现代架构中的持续性，并开发更高效的攻击方法。
- Method: 重新实现了基于CPPN和直接编码的进化欺骗攻击，并提出了SPOOF方法——一种简约、一致且更高效的黑盒攻击方法，能够以最少的像素修改生成高置信度欺骗图像。
- Result: 实验证实高置信度欺骗现象在现代网络中仍然存在，Transformer架构的ViT-B/16最为脆弱，需要比卷积模型更少的查询就能实现近乎确定的错误分类。SPOOF方法能以极低计算成本生成欺骗图像，且即使使用欺骗图像作为额外类别进行重新训练，也只能提供部分抵抗力。
- Conclusion: 现代深度分类器存在持续的脆弱性，即使采用欺骗图像作为额外类别进行重新训练的防御措施，SPOOF攻击仍然能够以稍高的查询预算持续欺骗模型，表明深度神经网络的鲁棒性问题仍未得到根本解决。


### [27] [Multi-Modal Zero-Shot Prediction of Color Trajectories in Food Drying](https://arxiv.org/abs/2512.06190)
*Shichen Li,Ahmadreza Eslaminia,Chenhui Shao*

Main category: cs.CV

TL;DR: 提出了一种新颖的多模态颜色轨迹预测方法，通过整合高维时间颜色信息和干燥工艺参数，实现准确且数据高效的颜色轨迹预测。

- Motivation: 现有研究主要依赖低维颜色特征，无法充分捕捉食品样品复杂的动态颜色轨迹，且现有建模方法缺乏对未见工艺条件的泛化能力。
- Method: 开发了多模态颜色轨迹预测方法，将高维时间颜色信息与干燥工艺参数相结合，实现准确且数据高效的颜色轨迹预测。
- Result: 在未见干燥条件下，模型对饼干干燥的RMSE为2.12，苹果干燥为1.29，相比基线模型误差降低了90%以上。
- Conclusion: 该方法在准确性、鲁棒性和广泛适用性方面表现出色，为食品干燥过程中的颜色质量监控提供了有效解决方案。


### [28] [The MICCAI Federated Tumor Segmentation (FeTS) Challenge 2024: Efficient and Robust Aggregation Methods for Federated Learning](https://arxiv.org/abs/2512.06206)
*Akis Linardos,Sarthak Pati,Ujjwal Baid,Brandon Edwards,Patrick Foley,Kevin Ta,Verena Chung,Micah Sheller,Muhammad Irfan Khan,Mojtaba Jafaritadi,Elina Kontio,Suleiman Khan,Leon Mächler,Ivan Ezhov,Suprosanna Shit,Johannes C. Paetzold,Gustav Grimberg,Manuel A. Nickel,David Naccache,Vasilis Siomos,Jonathan Passerat-Palmbach,Giacomo Tarroni,Daewoon Kim,Leonard L. Klausmann,Prashant Shah,Bjoern Menze,Dimitrios Makris,Spyridon Bakas*

Main category: cs.CV

TL;DR: MICCAI FeTS 2024挑战赛专注于联邦学习在胶质瘤亚区分割中的应用，评估了新的权重聚合方法以提升鲁棒性和效率。PID控制器方法获得最佳排名，在分割性能和通信效率方面均表现优异。

- Motivation: 推动联邦学习在医学影像中的应用，特别是针对多中心胶质瘤MRI数据的分割任务。旨在评估新的权重聚合方法，提高联邦学习的鲁棒性和通信效率，解决实际部署中的挑战。
- Method: 采用标准化联邦学习设置，使用来自BraTS基准的1,251个训练病例、219个验证病例和570个隐藏测试病例的多机构数据集。评估了六支参赛团队提出的权重聚合方法，使用累积评分系统综合考虑分割性能（DSC和HD95）和通信效率（收敛分数）。
- Result: 基于PID控制器的方法获得最高排名，在增强肿瘤、肿瘤核心和全肿瘤分割上的平均DSC分别为0.733、0.761和0.751，HD95分别为33.922mm、33.623mm和32.309mm，同时具有最高的通信效率（收敛分数0.764）。该方法超越了之前挑战赛的最佳方法。
- Conclusion: PID控制器是稳定和优化联邦学习中权重聚合的有效机制，显著推进了医学影像联邦学习的发展。挑战赛代码已开源，促进了该领域的进一步研究。


### [29] [Revisiting SVD and Wavelet Difference Reduction for Lossy Image Compression: A Reproducibility Study](https://arxiv.org/abs/2512.06221)
*Alena Makarova*

Main category: cs.CV

TL;DR: 对结合SVD和WDR的图像压缩方法的可重复性研究：原论文声称优于JPEG2000和WDR，但复现结果显示在PSNR上并未超越，仅在SSIM上部分改进。

- Motivation: 验证原论文声称的SVD+WDR图像压缩技术优于JPEG2000和WDR的结论是否可重复，并识别原方法描述中的模糊之处对可重复性的影响。
- Method: 重新实现原论文方法，填补缺失的实现细节，复现原始实验，并在新图像上进行额外测试，使用PSNR和SSIM作为评估指标。
- Result: 与原论文结论相反：SVD+WDR在PSNR上通常未超越JPEG2000或WDR，仅在SSIM上相对于JPEG2000有部分改进。研究揭示了原方法描述中的模糊点（如量化和阈值初始化）对性能评估的显著影响。
- Conclusion: 原论文的SVD+WDR压缩方法并未如声称那样优于现有技术，研究强调了方法描述清晰度对可重复性的重要性，模糊的实现细节可能导致性能评估偏差。


### [30] [GPU-GLMB: Assessing the Scalability of GPU-Accelerated Multi-Hypothesis Tracking](https://arxiv.org/abs/2512.06230)
*Pranav Balakrishnan,Sidisha Barik,Sean M. O'Rourke,Benjamin M. Marlin*

Main category: cs.CV

TL;DR: 提出一种支持多检测的GLMB滤波器变体，通过打破检测间依赖关系实现更好的并行可扩展性，可在GPU上高效部署。

- Motivation: 传统的标记随机有限集方法（如GLMB滤波器）在多目标跟踪中具有理论优势，但在标准测量模型下维护多个假设的计算成本极高，即使采用假设剪枝近似也很昂贵。当在分布式机器学习虚拟传感器网络中部署跟踪时，需要支持每个对象从同一传感器产生多个检测的能力。
- Method: 研究GLMB滤波器的一种变体，允许同一传感器对每个对象产生多个检测。这种设计打破了标准GLMB滤波器更新中的检测间依赖关系，从而显著提高了并行可扩展性，使得能够在GPU硬件上高效部署。
- Result: 提出的GLMB跟踪器变体通过打破检测间依赖关系，实现了显著改进的并行可扩展性。初步分析了GPU加速实现的运行时间可扩展性，重点关注对象数量和保留假设最大数量对运行时间的影响。
- Conclusion: 通过允许每个对象产生多个检测的GLMB滤波器变体，成功解决了传统方法计算成本高的问题，实现了更好的并行化和GPU加速能力，为在分布式机器学习虚拟传感器网络中部署多目标跟踪提供了高效解决方案。


### [31] [Opinion: Learning Intuitive Physics May Require More than Visual Data](https://arxiv.org/abs/2512.06232)
*Ellen Su,Solim Legris,Todd M. Gureckis,Mengye Ren*

Main category: cs.CV

TL;DR: 在SAYCam发育现实数据集上预训练的V-JEPA模型，在IntPhys2直觉物理基准上未取得显著性能提升，表明仅靠发育现实数据不足以让当前架构学习直觉物理表征。

- Motivation: 人类通过基于直觉物理理解的丰富内部模型来导航世界，而当前最先进的深度学习模型尽管在大量互联网视频数据上训练，在直觉物理基准上仍达不到人类水平。本研究探讨数据分布（而非数据量）是否是学习这些物理原理的关键。
- Method: 使用SAYCam（一个部分捕捉三个儿童日常视觉体验的发育现实、自我中心视频数据集）预训练视频联合嵌入预测架构（V-JEPA）模型。该数据集仅占SOTA模型训练数据量的0.01%。
- Result: 在SAYCam数据集上训练并未导致IntPhys2基准测试的显著性能提升。结果表明，仅使用发育现实数据集训练不足以让当前架构学习支持直觉物理的表征。
- Conclusion: 仅改变视觉数据量和分布可能不足以构建具有人工直觉物理的系统。需要更深入理解人类如何从有限数据中学习物理原理，并可能需要对架构或训练目标进行根本性改变。


### [32] [NexusFlow: Unifying Disparate Tasks under Partial Supervision via Invertible Flow Networks](https://arxiv.org/abs/2512.06251)
*Fangzhou Lin,Yuping Wang,Yuliang Guo,Zixun Huang,Xinyu Huang,Haichong Zhang,Kazunori Yamada,Zhengzhong Tu,Liu Ren,Ziming Zhang*

Main category: cs.CV

TL;DR: NexusFlow是一个轻量级即插即用框架，用于处理异构任务的半监督多任务学习，通过可逆耦合层对齐任务特征分布，在自动驾驶和室内场景任务上均取得SOTA性能。

- Motivation: 现有半监督多任务学习方法主要针对同构密集预测任务，而现实场景中任务结构往往多样且标注不完整，需要处理异构任务的知识迁移问题。
- Method: 引入代理网络和可逆耦合层，将不同任务的特征分布对齐到共享规范空间，保持信息完整性，避免表示坍缩，支持异构任务间的知识迁移。
- Result: 在nuScenes自动驾驶数据集上取得SOTA性能，在NYUv2室内场景数据集上所有任务均获得一致性能提升，验证了框架的广泛适用性。
- Conclusion: NexusFlow是一个有效的轻量级框架，能够处理异构任务的半监督多任务学习，在结构差异大的任务间实现有效知识迁移，具有广泛适用性。


### [33] [Language-driven Fine-grained Retrieval](https://arxiv.org/abs/2512.06255)
*Shijie Wang,Xin Yu,Yadan Luo,Zijian Wang,Pengfei Zhang,Zi Huang*

Main category: cs.CV

TL;DR: LaFG是一个语言驱动的细粒度图像检索框架，使用大语言模型和视觉语言模型将类别名称转换为属性级监督，以解决传统方法在未见类别上泛化能力不足的问题。

- Motivation: 现有细粒度图像检索方法使用基于类别名称的稀疏one-hot标签作为监督，虽然对已见类别有效，但忽略了类别名称中丰富的语义信息，导致跨类别细节可比性建模不足，限制了模型对未见类别的泛化能力。
- Method: 1. 使用LLM将类别名称转换为详细的属性导向描述；2. 利用冻结的VLM将这些描述投影到视觉对齐空间，聚类形成数据集范围的属性词汇表；3. 通过全局提示模板选择类别相关属性，聚合成类别特定的语言原型；4. 用这些原型监督检索模型。
- Result: 该方法通过将类别名称转换为属性级监督，能够更好地建模跨类别细节的可比性，从而提高细粒度图像检索在未见类别上的泛化性能。
- Conclusion: LaFG框架通过语言驱动的属性级监督，解决了传统细粒度图像检索方法语义信息不足的问题，显著提升了模型对未见类别的泛化能力。


### [34] [Knowing the Answer Isn't Enough: Fixing Reasoning Path Failures in LVLMs](https://arxiv.org/abs/2512.06258)
*Chaoyang Wang,Yangfan He,Yiyang Zhou,Yixuan Wang,Jiaqi Liu,Peng Xia,Zhengzhong Tu,Mohit Bansal,Huaxiu Yao*

Main category: cs.CV

TL;DR: LVLMs存在路径选择偏差问题：即使知道正确答案，也常通过错误推理路径得出。论文提出PSO两阶段后训练框架，通过路径选择优化提升推理性能和稳定性。

- Motivation: 揭示大型视觉语言模型（LVLMs）的一个关键但未被充分探索的缺陷：即使模型知道正确答案，也经常通过错误的推理路径得出。核心问题不是知识缺乏，而是在广阔的推理搜索空间中的路径选择偏差。模型虽然能采样正确的解决方案轨迹，但不成比例地偏向不稳定或逻辑不一致的路径，导致结果不稳定和不可靠。
- Method: 提出PSO（路径选择优化）两阶段后训练框架：第一阶段使用带有模板和答案奖励的组相对策略优化（GRPO）来培养结构化、逐步推理；第二阶段进行在线偏好优化，模型从GRPO生成的数据中采样推理路径，自我评估，并对齐到优选轨迹。错误或次优路径同时存储在负向回放记忆（NRM）中作为硬负样本，定期回顾以防止模型重复先前错误并促进持续推理改进。
- Result: 大量实验表明，PSO有效修剪无效推理路径，显著提升推理准确性（平均提升7.4%），并产生更稳定和一致的思维链。
- Conclusion: PSO框架成功解决了LVLMs中的路径选择偏差问题，通过优化推理路径选择，不仅提高了推理准确性，还增强了模型的稳定性和一致性，为改进大型视觉语言模型的推理能力提供了有效方法。


### [35] [TriaGS: Differentiable Triangulation-Guided Geometric Consistency for 3D Gaussian Splatting](https://arxiv.org/abs/2512.06269)
*Quan Tran,Tuan Dang*

Main category: cs.CV

TL;DR: 提出一种通过多视图三角测量约束来增强3D高斯重建几何一致性的方法，解决浮点伪影和结构问题，在DTU数据集上达到0.50mm的Chamfer距离

- Motivation: 当前3D高斯重建仅依赖光度损失，导致重建不一致、产生"浮点"伪影和非结构化几何，难以提取高质量表面
- Method: 通过约束多视图三角测量强制全局几何一致性，利用多个估计视图达成物理世界3D表示共识，通过自监督方式惩罚渲染3D点与鲁棒共识点的偏差
- Result: 在多个数据集上取得SOTA结果，DTU数据集上平均Chamfer距离达到0.50mm，优于同类显式方法
- Conclusion: 提出的几何一致性约束方法显著改善了3D高斯重建质量，解决了浮点伪影问题，代码将开源以确保可复现性


### [36] [FacePhys: State of the Heart Learning](https://arxiv.org/abs/2512.06275)
*Kegang Wang,Jiankai Tang,Yuntao Wang,Xin Liu,Yuxuan Fan,Jiatong Ji,Yuanchun Shi,Daniel McDuff*

Main category: cs.CV

TL;DR: 提出FacePhys算法，基于时空状态空间对偶性，解决rPPG技术中模型可扩展性、跨数据集泛化和实时操作的三难问题，实现高效内存使用和实时心率监测。

- Motivation: 基于摄像头的生命体征测量技术（特别是远程光电容积描记术rPPG）为舒适、普适的健康监测提供了机会，但实际部署面临计算资源限制和压缩传输导致信号质量下降的挑战。
- Method: 提出FacePhys算法，基于时空状态空间对偶性，利用可转移的心脏状态捕捉视频帧间的细微周期性变化，同时保持最小计算开销，支持长视频序列训练和低延迟推理。
- Result: FacePhys实现了新的最先进性能，误差减少49%，实时推理内存占用仅3.6MB，每帧延迟9.46ms，比现有方法提升83%到99%。
- Conclusion: FacePhys解决了rPPG技术的三难问题，实现了可靠的实际部署实时性能，为前端设备上的高效健康监测提供了可行方案。


### [37] [RefBench-PRO: Perceptual and Reasoning Oriented Benchmark for Referring Expression Comprehension](https://arxiv.org/abs/2512.06276)
*Tianyi Gao,Hao Li,Han Fang,Xin Wei,Xiaodong Dong,Hongbo Sun,Ye Yuan,Zhongjiang He,Jinglin Xu,Jingmin Xin,Hao Sun*

Main category: cs.CV

TL;DR: RefBench-PRO是一个新的指称表达式理解基准，将任务分解为感知和推理两个维度共6个子任务，并提出Ref-R1强化学习方案提升定位精度。

- Motivation: 现有REC基准主要评估感知能力，缺乏可解释的评分机制，无法揭示多模态大语言模型在不同认知能力上的基础能力。
- Method: 1) 提出RefBench-PRO基准，将指称表达式分解为感知和推理两个维度，细分为属性、位置、交互、常识、关系和拒绝6个渐进挑战性任务；2) 开发全自动数据生成流水线；3) 提出Ref-R1强化学习方案，采用基于动态IoU的GRPO提升复杂推理条件下的定位精度。
- Result: RefBench-PRO能够对MLLM在指称表达式理解上进行可解释评估，在感知和推理方面都提出了更大挑战，为REC建立了更强的基线。
- Conclusion: 该工作通过细粒度基准和强化学习方案，为多模态大语言模型的指称表达式理解提供了更全面、可解释的评估框架。


### [38] [Unleashing the Intrinsic Visual Representation Capability of Multimodal Large Language Models](https://arxiv.org/abs/2512.06281)
*Hengzhuang Li,Xinsong Zhang,Qiming Peng,Bin Luo,Han Hu,Dengyang Jiang,Han-Jia Ye,Teng Zhang,Hai Jin*

Main category: cs.CV

TL;DR: 提出LaVer框架，通过潜在空间掩码图像建模解决MLLMs中的模态不平衡问题，增强视觉表示学习

- Motivation: 多模态大语言模型存在模态不平衡问题，深层网络中对视觉信息利用不足，导致视觉性能下降或产生幻觉，这源于训练中主要依赖文本预测而缺乏直接视觉监督信号
- Method: 提出潜在视觉重建（LaVer）训练框架，在LLM的联合潜在语义空间中通过掩码图像建模，让MLLMs学习更具区分性的视觉表示
- Result: 实验证明该方法在各种基准测试中表现优越，特别是在需要密集视觉能力的场景中，模型显示出增强的视觉注意力分配和视觉信息利用
- Conclusion: LaVer框架通过提供直接视觉激活信号，有效解决了MLLMs的模态不平衡问题，提升了视觉表示质量和模型性能


### [39] [A Sleep Monitoring System Based on Audio, Video and Depth Information](https://arxiv.org/abs/2512.06282)
*Lyn Chao-ling Chen,Kuan-Wen Chen,Yi-Ping Hung*

Main category: cs.CV

TL;DR: 开发基于事件方法的非侵入式睡眠监测系统，通过红外深度传感器、RGB摄像头和四麦克风阵列检测运动、开关灯和噪音三类睡眠干扰事件

- Motivation: 需要定量评估睡眠干扰，开发非侵入式家庭睡眠监测系统，避免传统方法对睡眠的干扰
- Method: 使用红外深度传感器、RGB摄像头和四麦克风阵列设备，在低光照环境下监测。建立深度信号背景模型检测运动幅度，建立彩色图像背景模型检测光照变化，采用事件检测算法从三类传感器数据中识别事件
- Result: 系统在睡眠条件下测试，实验结果验证了系统的可靠性
- Conclusion: 提出的基于事件方法的非侵入式睡眠监测系统能够有效检测和分类睡眠干扰事件，为定量评估睡眠质量提供了可行方案


### [40] [StrokeNet: Unveiling How to Learn Fine-Grained Interactions in Online Handwritten Stroke Classification](https://arxiv.org/abs/2512.06290)
*Yiheng Huang,Shuang She,Zewei Wei,Jianmin Lin,Ming Yang,Wenyin Liu*

Main category: cs.CV

TL;DR: StrokeNet：一种新颖的笔画分类网络，通过参考点表示和空间查询机制解决笔画间语义关系建模的挑战，在多个手写数据集上达到SOTA性能。

- Motivation: 笔画分类面临书写风格变化、内容模糊和动态书写位置的挑战。核心问题在于建模笔画间的语义关系，现有深度学习方法难以捕捉这种细粒度的局部化交互关系。
- Method: 提出StrokeNet网络架构：1）将笔画编码为参考点对表示（点+特征向量）；2）动态选择参考点并排序，使用Inline Sequence Attention模块构建上下文特征；3）设计Cross-Ellipse Query机制聚类参考点并提取多尺度空间特征；4）联合优化框架同时预测笔画类别和相邻笔画语义转换。
- Result: 在多个公开在线手写数据集上达到最先进性能。在CASIA-onDo数据集上，准确率从93.81%提升到95.54%，证明了方法的有效性和鲁棒性。
- Conclusion: StrokeNet通过参考点表示和空间查询机制有效解决了笔画分类中的语义关系建模问题，为细粒度笔画交互建模提供了新思路，在多个数据集上验证了其优越性能。


### [41] [Exploiting Spatiotemporal Properties for Efficient Event-Driven Human Pose Estimation](https://arxiv.org/abs/2512.06306)
*Haoxian Zhou,Chuanzhi Xu,Langyi Chen,Haodong Chen,Yuk Ying Chung,Qiang Qu,Xaoming Chen,Weidong Cai*

Main category: cs.CV

TL;DR: 提出基于点云框架的事件流人体姿态估计方法，通过事件时间切片卷积和事件切片序列模块利用事件流时空特性，在DHP19数据集上提升性能

- Motivation: 现有方法将事件流转换为密集事件帧会增加计算量并牺牲事件信号的高时间分辨率，需要充分利用事件流的时空特性来提升人体姿态估计性能
- Method: 基于点云框架，设计事件时间切片卷积模块捕获事件切片间的短期依赖，结合事件切片序列模块进行结构化时间建模，并在点云表示中应用边缘增强来改善稀疏事件条件下的空间边缘信息
- Result: 在DHP19数据集上的实验表明，该方法在PointNet、DGCNN和Point Transformer三个代表性点云骨干网络上均能持续提升性能
- Conclusion: 提出的点云框架方法有效利用了事件流的时空特性，避免了传统密集帧转换的计算开销，在人体姿态估计任务中取得了更好的性能


### [42] [ReCAD: Reinforcement Learning Enhanced Parametric CAD Model Generation with Vision-Language Models](https://arxiv.org/abs/2512.06328)
*Jiahao Li,Yusheng Luo,Yunzhong Lou,Xiangdong Zhou*

Main category: cs.CV

TL;DR: ReCAD是一个强化学习框架，通过引导预训练大模型生成精确的参数化CAD模型，在文本到CAD和图像到CAD任务中实现最先进性能。

- Motivation: 现有方法通常依赖监督微调注入知识，支持编辑性有限，且未能充分利用预训练大模型的强大生成先验。需要一种能利用大模型内在生成能力、支持复杂CAD操作且保持几何精度的方法。
- Method: 1) 微调视觉语言模型使其具备基本CAD生成能力，将CAD脚本重写为参数化代码用于生成监督文本描述；2) 提出新颖的强化学习策略，以参数化代码为指导增强模型在复杂问题上的推理；3) 采用分层基元学习过程，在统一奖励函数下逐步教授结构化组合技能。
- Result: 在文本到CAD和图像到CAD任务中均达到最先进水平，显著提升几何精度。在图像到CAD任务中，将平均Chamfer距离从73.47降至29.61（分布内）和从272.06降至80.23（分布外），大幅超越现有基线。
- Conclusion: ReCAD框架成功利用预训练大模型的生成能力，通过强化学习引导生成精确参数化CAD模型，支持复杂操作如模式复制和镜像，在几何精度和语义保真度方面均表现出色。


### [43] [S2WMamba: A Spectral-Spatial Wavelet Mamba for Pansharpening](https://arxiv.org/abs/2512.06330)
*Haoyu Zhang,Junhan Luo,Yugang Cao,Siran Peng,Jie Huang,Liangjian-Deng*

Main category: cs.CV

TL;DR: S2WMamba：通过2D/1D小波变换显式解耦频域信息，结合Mamba跨模态交互的轻量级全色锐化方法

- Motivation: 传统全色锐化方法在处理PAN和MS图像时，空间细节与光谱保真度容易相互纠缠，导致性能受限。需要一种能显式解耦频域信息并进行有效跨模态交互的方法。
- Method: 1) 对PAN图像应用2D Haar DWT定位空间边缘和纹理；2) 对MS图像应用通道级1D Haar DWT分离低频/高频分量；3) 设计光谱分支（注入空间细节）和空间分支（利用光谱信息）；4) 使用基于Mamba的跨调制模块建模长程依赖；5) 多尺度动态门自适应融合分支输出。
- Result: 在WV3、GF2和QB数据集上，S2WMamba匹配或超越了FusionMamba、CANNet、U2Net、ARConv等基线方法，PSNR最高提升0.23 dB，在WV3全分辨率上达到HQNR 0.956。
- Conclusion: 通过显式频域解耦和轻量级跨模态交互，S2WMamba有效解决了全色锐化中空间细节与光谱保真度的纠缠问题，在多个数据集上取得了优异性能。


### [44] [CryoHype: Reconstructing a thousand cryo-EM structures with transformer-based hypernetworks](https://arxiv.org/abs/2512.06332)
*Jeffrey Gu,Minkyu Jeon,Ambri Ma,Serena Yeung-Levy,Ellen D. Zhong*

Main category: cs.CV

TL;DR: CryoHype：基于Transformer的超网络，用于从混合的冷冻电镜图像中重建多种分子结构

- Motivation: 冷冻电镜通常用于单一分子物种的3D结构解析，但现有方法主要关注单个或少数结构的构象异质性，无法有效处理由多种不同分子物种混合产生的组成异质性。需要开发能够同时重建多种不同分子结构的方法。
- Method: 提出CryoHype，一种基于Transformer的超网络，动态调整隐式神经表示的权重。该方法能够从混合的冷冻电镜图像中重建多种不同的分子结构，特别适用于解决组成异质性问题。
- Result: 在包含100个结构的挑战性基准数据集上取得了最先进的结果。进一步证明CryoHype能够扩展到从无标签的冷冻电镜图像中重建1000个不同的结构（在固定姿态设置下）。
- Conclusion: CryoHype为冷冻电镜的高通量结构解析提供了新方法，能够有效处理多种分子物种混合的组成异质性，展示了在复杂生物分子混合物中大规模结构重建的潜力。


### [45] [Beyond Hallucinations: A Multimodal-Guided Task-Aware Generative Image Compression for Ultra-Low Bitrate](https://arxiv.org/abs/2512.06344)
*Kaile Wang,Lijun He,Haisheng Fu,Haixia Bi,Fan Li*

Main category: cs.CV

TL;DR: 提出MTGC框架，通过多模态引导解决超低码率下生成式图像压缩的语义偏差问题，提升语义一致性、感知质量和像素级保真度

- Motivation: 生成式图像压缩在超低码率（bpp < 0.05）下常因生成幻觉导致语义偏差，限制了其在6G语义通信场景中的可靠部署
- Method: 提出MTGC框架：1）集成三种引导模态：文本描述（全局语义）、高压缩图像（低层视觉信息）、语义伪词（细粒度任务相关语义）；2）设计任务感知语义压缩模块（TASCM）生成SPWs；3）设计多模态引导扩散解码器（MGDD）采用双路径协同引导机制，结合交叉注意力和ControlNet残差注入
- Result: MTGC在超低码率下显著提升语义一致性（如DISTS在DIV2K数据集上降低10.59%），同时在感知质量和像素级保真度方面也取得显著提升
- Conclusion: MTGC框架通过多模态引导有效解决了超低码率生成式图像压缩的语义偏差问题，为6G语义通信提供了可靠的解决方案


### [46] [CLUENet: Cluster Attention Makes Neural Networks Have Eyes](https://arxiv.org/abs/2512.06345)
*Xiangshuai Song,Jun-Jie Huang,Tianrui Liu,Ke Liang,Chang Tang*

Main category: cs.CV

TL;DR: CLUENet是一个基于聚类的透明深度架构，通过全局软聚合硬分配、温度缩放余弦注意力、门控残差连接、硬共享特征调度和改进的聚类池化策略，在视觉语义理解任务中实现了准确性、效率和透明度的平衡。

- Motivation: 卷积和注意力模型在视觉任务中虽然成功，但其固定的感受野和复杂架构限制了建模不规则空间模式的能力，且缺乏可解释性，难以满足需要高模型透明度的任务需求。聚类范式虽然提供可解释性和灵活的语义建模，但存在准确性有限、效率低和训练中梯度消失等问题。
- Method: 提出CLUENet（CLUster attEntion Network），包含三个关键创新：1）全局软聚合硬分配，采用温度缩放余弦注意力和门控残差连接增强局部建模；2）块间硬共享特征调度；3）改进的聚类池化策略。
- Result: 在CIFAR-100和Mini-ImageNet上的实验表明，CLUENet超越了现有聚类方法和主流视觉模型，在分类性能和视觉可解释性方面都有显著提升。
- Conclusion: CLUENet为视觉语义理解提供了一个在准确性、效率和透明度之间取得良好平衡的透明深度架构，解决了现有聚类方法的局限性。


### [47] [TreeQ: Pushing the Quantization Boundary of Diffusion Transformer via Tree-Structured Mixed-Precision Search](https://arxiv.org/abs/2512.06353)
*Kaicheng Yang,Kaisen Yang,Baiting Wu,Xun Zhang,Qianrui Yang,Haotong Qin,He Zhang,Yulun Zhang*

Main category: cs.CV

TL;DR: TreeQ：首个针对扩散变换器（DiT）的统一量化框架，通过树结构搜索、环境噪声引导和通用Monarch分支，在4位量化下实现接近无损的性能。

- Motivation: DiT在图像生成中表现出色但计算和内存需求高，混合精度量化在U-Net上成功但DiT量化研究不足，需要专门解决DiT量化挑战的框架。
- Method: 提出TreeQ三组件：1）树结构搜索（TSS）利用DiT线性特性O(n)遍历解空间；2）环境噪声引导（ENG）统一PTQ和QAT优化目标；3）通用Monarch分支（GMB）防止超低位量化信息丢失。
- Result: 在DiT-XL/2上W3A3和W4A4 PTQ/PEFT设置下达到SOTA性能，首次实现DiT模型接近无损的4位PTQ性能。
- Conclusion: TreeQ是首个专门针对DiT的统一量化框架，有效解决了DiT量化的关键挑战，为DiT的实际部署提供了高效解决方案。


### [48] [Rectifying Latent Space for Generative Single-Image Reflection Removal](https://arxiv.org/abs/2512.06358)
*Mingjia Li,Jin Hu,Hainuo Wang,Qiming Hu,Jiarui Wang,Xiaojie Guo*

Main category: cs.CV

TL;DR: 提出一种基于潜在扩散模型的单图像反射去除方法，通过反射等变VAE、可学习任务特定文本嵌入和深度引导早期分支采样策略，显著提升反射去除性能

- Motivation: 单图像反射去除是一个高度不适定问题，现有方法难以推理被破坏区域的组成，导致在真实场景中的恢复和泛化能力不足。潜在空间缺乏解释复合图像作为其组成层线性叠加的内在结构
- Method: 1) 反射等变VAE：将潜在空间与反射形成的线性物理对齐；2) 可学习任务特定文本嵌入：绕过模糊语言提供精确指导；3) 深度引导早期分支采样策略：利用生成随机性获得有希望的结果
- Result: 在多个基准测试中达到新的SOTA性能，并且在具有挑战性的真实世界案例中表现出良好的泛化能力
- Conclusion: 通过重新构建编辑目的的潜在扩散模型，有效感知和处理高度模糊的分层图像输入，产生高质量输出，解决了反射去除中的关键挑战


### [49] [Spoofing-aware Prompt Learning for Unified Physical-Digital Facial Attack Detection](https://arxiv.org/abs/2512.06363)
*Jiabao Guo,Yadian Wang,Hui Ma,Yuhao Fu,Ju Jia,Hui Liu,Shengeng Tang,Lechao Cheng,Yunfeng Diao,Ajian Liu*

Main category: cs.CV

TL;DR: 提出SPL-UAD框架，通过解耦物理攻击和数字攻击的优化分支，实现统一的物理-数字攻击检测，解决现有方法中优化方向冲突的问题。

- Motivation: 现实世界的人脸识别系统同时面临物理呈现攻击和数字伪造攻击的威胁。现有方法主要使用CLIP加正则化约束来提升模型在两种任务上的泛化能力，但这些方法在相同类别提示空间下存在物理和数字攻击检测优化方向冲突的问题。
- Method: 提出SPL-UAD框架：1) 构建可学习的并行提示分支，通过自适应欺骗上下文提示生成增强，实现对每种攻击类型的独立优化控制；2) 设计线索感知增强，利用双提示机制在数据上生成具有挑战性的样本挖掘任务，提升模型对未见攻击类型的鲁棒性。
- Result: 在大型UniAttackDataPlus数据集上的大量实验表明，该方法在统一攻击检测任务中取得了显著的性能提升。
- Conclusion: SPL-UAD框架通过解耦物理和数字攻击的优化分支，有效解决了现有方法中的优化冲突问题，实现了更全面的生物特征数据保护。


### [50] [Human3R: Incorporating Human Priors for Better 3D Dynamic Reconstruction from Monocular Videos](https://arxiv.org/abs/2512.06368)
*Weitao Xiong,Zhiyuan Yuan,Jiahao Lu,Chengfeng Zhao,Peng Li,Yuan Liu*

Main category: cs.CV

TL;DR: 提出Human3R方法，结合SMPL人体模型和单目深度估计的混合几何先验，解决动态人体场景重建中的几何不一致和分辨率退化问题

- Motivation: 现有方法缺乏3D人体结构理解，导致几何不一致的结果（肢体比例扭曲、人-物融合不自然），且内存限制的下采样导致人体边界漂移向背景几何
- Method: 提出Human3R方法，采用分层处理流程：先处理全分辨率图像获取整体场景几何，再通过策略性裁剪和交叉注意力融合增强人体特定细节；通过特征融合模块集成SMPL先验
- Result: 在TUM Dynamics和GTA-IM数据集上的实验表明，在动态人体重建方面具有优越性能
- Conclusion: 通过结合混合几何先验（SMPL人体模型+单目深度估计），Human3R能够保持表面一致性的同时捕捉人体区域的细粒度几何细节，实现几何上合理的重建


### [51] [VG-Refiner: Towards Tool-Refined Referring Grounded Reasoning via Agentic Reinforcement Learning](https://arxiv.org/abs/2512.06373)
*Yuji Wang,Wenlong Liu,Jingxuan Niu,Haoji Zhang,Yansong Tang*

Main category: cs.CV

TL;DR: VG-Refiner：首个工具精炼的指代接地推理框架，通过两阶段思考-再思考机制和精炼奖励，有效处理不可靠工具输出，提升指代和接地任务的准确性。

- Motivation: 现有工具集成视觉推理（TiVR）范式主要关注通过强化学习集成各种视觉工具，但忽略了设计有效的响应机制来处理不可靠或错误的工具输出。这在指代和接地任务中尤为突出，不准确的检测工具预测常常误导TiVR模型产生幻觉推理。
- Method: 提出VG-Refiner框架，引入两阶段思考-再思考机制，使模型能够明确分析和响应工具反馈；设计精炼奖励，鼓励对不良工具结果进行有效修正；提出两个新指标并建立公平评估协议；使用少量任务特定数据增强精炼能力。
- Result: VG-Refiner在指代和推理接地基准测试中实现了准确性和修正能力的显著提升，同时保持了预训练模型的通用能力。
- Conclusion: VG-Refiner是首个专注于工具精炼的指代接地推理框架，通过系统化的精炼机制有效解决了现有TiVR模型在处理不可靠工具输出时的局限性，为视觉推理领域提供了新的解决方案。


### [52] [Are AI-Generated Driving Videos Ready for Autonomous Driving? A Diagnostic Evaluation Framework](https://arxiv.org/abs/2512.06376)
*Xinhao Xiang,Abhijeet Rastogi,Jiawei Zhang*

Main category: cs.CV

TL;DR: 论文研究了AI生成的驾驶视频(AIGV)能否可靠支持自动驾驶模型训练与评估，提出了诊断框架、失败模式分类、基准数据集ADGV-Bench和评估器ADGVE，发现原始AIGV会降低感知性能，但经过ADGVE筛选后能成为真实数据的有效补充。

- Motivation: 文本到视频模型能生成高分辨率驾驶场景，AIGV为自动驾驶提供了低成本、可扩展的数据替代方案。但关键问题是：这类视频能否可靠支持自动驾驶模型的训练和评估？需要系统研究AIGV在自动驾驶应用中的可行性和风险。
- Method: 1) 提出AIGV常见失败模式分类法，包括视觉伪影、物理上不可能的运动和交通语义违规；2) 构建ADGV-Bench基准数据集，包含人工质量标注和多个感知任务的密集标签；3) 提出ADGVE评估器，结合静态语义、时序线索、车道遵守信号和视觉语言模型引导的推理，为每个视频片段生成单一质量评分。
- Result: 实验表明：盲目添加原始AIGV会降低目标检测、跟踪和实例分割等感知任务的性能；但使用ADGVE筛选AIGV后，不仅能改善通用视频质量评估指标，还能提升下游自动驾驶模型性能，使AIGV成为真实世界数据的有益补充。
- Conclusion: 研究揭示了AIGV在自动驾驶应用中的风险和潜力，提供了安全利用大规模视频生成的实际工具。AIGV经过适当筛选后可以成为真实驾驶数据的有效补充，为未来自动驾驶流水线提供了实用的质量评估框架。


### [53] [VAD-Net: Multidimensional Facial Expression Recognition in Intelligent Education System](https://arxiv.org/abs/2512.06377)
*Yi Huo,Yun Ge*

Main category: cs.CV

TL;DR: 该研究为FER2013数据集添加了VAD（效价-唤醒-支配）三维情感标注，并提出了基于正交卷积的VAD预测网络，提高了情感识别的准确性和表达力。

- Motivation: 当前FER数据集主要使用离散情感类别标注（如高兴、愤怒等），表达力有限。未来情感计算需要更全面精确的VAD多维参数，但现有数据集（如AffectNet）缺少支配维度标注。
- Method: 1. 为FER2013数据集添加VAD三维标注，特别是首次标注了支配维度；2. 提出基于正交卷积的网络架构，通过强制卷积核正交化提取更多样化的特征，提高VAD预测能力。
- Result: 1. 实验表明支配维度可以测量，但相比效价和唤醒维度更难获取（无论是人工标注还是网络预测）；2. 正交卷积的消融实验验证了其能获得更好的VAD预测效果。
- Conclusion: 该研究提供了首个包含VAD三维标注的FER数据集基准，并提出了基于正交卷积的VAD预测网络。新建的数据集和代码已公开，可作为VAD多维情感测量的基准。


### [54] [OCFER-Net: Recognizing Facial Expression in Online Learning System](https://arxiv.org/abs/2512.06379)
*Yi Huo,Lei Zhang*

Main category: cs.CV

TL;DR: 提出OCFER-Net，通过正交性正则化提升卷积核多样性，在FER-2013数据集上优于基线1.087%

- Motivation: 在线学习中情感交互很重要，面部表情识别(FER)可帮助教师了解学生情绪状态。现有FER方法很少利用卷积矩阵的正交性，而正交性可以提取更多样化和表达力强的特征。
- Method: 提出OCFER-Net，通过正则化强制卷积核的正交性，从而提取更多样化和表达力强的特征。
- Result: 在挑战性数据集FER-2013上进行实验，结果显示OCFER-Net优于基线方法1.087%
- Conclusion: 正交性正则化能有效提升卷积核的多样性，从而提高面部表情识别的性能，代码已开源。


### [55] [Perceptual Region-Driven Infrared-Visible Co-Fusion for Extreme Scene Enhancement](https://arxiv.org/abs/2512.06400)
*Jing Tao,Yonghong Zong,Banglei Guana,Pengju Sun,Taihang Lei,Yang Shanga,Qifeng Yu*

Main category: cs.CV

TL;DR: 提出基于区域感知的红外-可见光融合框架，通过多曝光多模态成像解决极端环境下几何保真度与热辐射信息融合的挑战

- Motivation: 在极端条件下，现有方法难以在保持可见光图像几何精度的同时有效融合热辐射信息，影响测量准确性
- Method: 使用空间变化曝光相机，结合区域感知特征融合、自适应融合与对比度增强，以及基于区域显著性图的结构相似性补偿机制
- Result: 在合成和真实数据上的实验表明，该方法在图像清晰度和性能指标上优于现有方法
- Conclusion: 提出的区域感知融合框架能有效解决极端环境下红外-可见光谱融合的几何保真问题，并适用于单曝光场景


### [56] [Rethinking Training Dynamics in Scale-wise Autoregressive Generation](https://arxiv.org/abs/2512.06421)
*Gengze Zhou,Chongjian Ge,Hao Tan,Feng Liu,Yicong Hong*

Main category: cs.CV

TL;DR: 提出Self-Autoregressive Refinement (SAR)方法，通过Stagger-Scale Rollout和Contrastive Student-Forcing Loss解决自回归模型中尺度预测的暴露偏差问题，显著提升生成质量。

- Motivation: 自回归生成模型在媒体合成中表现出强大能力，但尺度预测模型存在暴露偏差问题，这主要源于训练-测试不匹配和尺度学习难度不平衡两个原因，限制了生成质量。
- Method: 提出SAR方法，包含两个核心组件：1) Stagger-Scale Rollout (SSR)机制，通过轻量级自回归展开让模型接触自己的中间预测，对齐训练-测试模式；2) Contrastive Student-Forcing Loss (CSFL)，为自生成上下文提供充分监督，确保训练稳定。
- Result: 实验表明，SAR能持续提升预训练AR模型的生成质量，计算开销极小。在ImageNet 256数据集上，FlexVAR-d16模型应用SAR后10个epoch内FID降低5.2%（32xA100 GPU上5小时）。
- Conclusion: SAR作为一种高效、可扩展且有效的后训练方法，有望成为视觉自回归生成的可靠解决方案。


### [57] [A Perception CNN for Facial Expression Recognition](https://arxiv.org/abs/2512.06422)
*Chunwei Tian,Jingyuan Xie,Lingjun Li,Wangmeng Zuo,Yanning Zhang,David Zhang*

Main category: cs.CV

TL;DR: 提出感知CNN（PCNN）用于面部表情识别，通过并行网络学习局部面部特征，结合多域交互机制和两阶段损失函数，在多个数据集上取得优异性能。

- Motivation: 传统CNN在面部表情识别中可能忽略面部区域分割的影响，无法有效捕捉面部细微变化，需要更精细的局部特征学习方法。
- Method: 1. 使用五个并行网络分别学习眼睛、脸颊和嘴巴等局部面部特征；2. 采用多域交互机制融合局部器官特征和全局面部结构特征；3. 设计两阶段损失函数约束感知信息准确性和重建图像质量。
- Result: PCNN在多个实验室和真实世界面部表情识别基准数据集（CK+、JAFFE、FER2013、FERPlus、RAF-DB以及遮挡和姿态变化数据集）上取得了优异结果。
- Conclusion: PCNN通过并行学习局部面部特征、多域特征融合和两阶段损失优化，有效提升了面部表情识别的性能，特别是在捕捉面部细微变化方面表现突出。


### [58] [DragMesh: Interactive 3D Generation Made Easy](https://arxiv.org/abs/2512.06424)
*Tianshan Zhang,Zeyu Zhang,Hao Tang*

Main category: cs.CV

TL;DR: DragMesh：实时交互式3D关节运动生成框架，通过解耦的关节推理与运动生成实现物理一致且实时的物体操控

- Motivation: 现有方法在关节运动生成上存在两难：要么物理一致但速度慢，要么生成速度快但违反基本运动学约束。需要一种既能保持物理一致性又能实时交互的解决方案。
- Method: 提出解耦的运动学推理与运动生成框架：1) 通过KPP-Net解耦语义意图推理（关节类型）和几何回归（轴和原点）；2) 开发基于对偶四元数的DQ-VAE，接收关节先验和用户拖拽输入，通过非自回归Transformer解码器生成完整运动轨迹；3) 使用FiLM条件注入确保运动学约束，配合数值稳定的叉积损失保证轴对齐。
- Result: 实现了实时性能，能够在未见物体上生成合理的关节运动而无需重新训练，为生成式3D智能提供了实用方案。
- Conclusion: DragMesh通过解耦设计和创新的对偶四元数表示，在保持物理一致性的同时实现了实时交互式3D关节运动生成，推动了生成式3D智能的发展。


### [59] [When Gender is Hard to See: Multi-Attribute Support for Long-Range Recognition](https://arxiv.org/abs/2512.06426)
*Nzakiese Mbongo,Kailash A. Hambarde,Hugo Proença*

Main category: cs.CV

TL;DR: 提出双路径Transformer框架，结合CLIP的视觉和文本编码能力，用于远距离性别识别，在U-DetAGReID数据集上超越现有方法。

- Motivation: 远距离图像中的性别识别面临空间分辨率低、视角多变、面部特征缺失等挑战，需要更鲁棒的解决方案。
- Method: 双路径Transformer框架：1) 视觉路径通过选择性微调CLIP图像编码器上层；2) 属性路径通过软生物特征提示（发型、服装等）在CLIP文本-图像空间中推理性别。加入空间通道注意力模块增强判别定位能力。
- Result: 在构建的U-DetAGReID数据集上，该方法在宏观F1、准确率、AUC等多个指标上超越最先进的人体属性和重识别基线，对距离、角度、高度变化具有鲁棒性。
- Conclusion: 语言引导的双路径学习为无约束远距离场景下的负责任性别识别提供了可扩展的基础框架。


### [60] [Automated Deep Learning Estimation of Anthropometric Measurements for Preparticipation Cardiovascular Screening](https://arxiv.org/abs/2512.06434)
*Lucas R. Mareque,Ricardo L. Armentano,Leandro J. Cymberknop*

Main category: cs.CV

TL;DR: 提出基于深度学习的全自动方法，从2D合成人体图像中估计五项关键人体测量指标，用于运动员心血管风险评估，所有模型达到亚厘米级精度。

- Motivation: 运动员心血管检查（PPCE）旨在预防心源性猝死，传统手动测量方法劳动密集、依赖操作者且难以规模化，需要自动化解决方案。
- Method: 使用从3D人体网格生成的100,000张合成图像数据集，训练并评估VGG19、ResNet50和DenseNet121模型，通过全连接层进行回归分析，预测五项关键人体测量指标。
- Result: 所有模型均达到亚厘米级精度，ResNet50表现最佳，在所有测量指标上的平均MAE为0.668厘米，证明深度学习能够提供规模化的人体测量数据。
- Conclusion: 深度学习方法能够准确、规模化地提供人体测量数据，可作为运动员筛查协议的实际工具，未来将在真实世界图像上进行验证以扩展应用范围。


### [61] [AGORA: Adversarial Generation Of Real-time Animatable 3D Gaussian Head Avatars](https://arxiv.org/abs/2512.06438)
*Ramazan Fazylov,Sergey Zagoruyko,Aleksandr Parkin,Stamatis Lefkimmiatis,Ivan Laptev*

Main category: cs.CV

TL;DR: AGORA：首个基于3D高斯泼溅的实时可动画化3D人体化身生成框架，通过FLAME条件变形分支实现身份保持的精细表情控制，支持CPU推理

- Motivation: 现有方法存在局限性：基于NeRF的方法渲染慢且动态不一致，而3DGS方法通常仅限于静态头部生成，缺乏动态控制。需要一种既能生成高质量3D人体化身又能实现实时动画控制的方法
- Method: 1. 将3D高斯泼溅（3DGS）与生成对抗网络结合；2. 引入轻量级FLAME条件变形分支，预测每个高斯的残差；3. 采用双判别器训练方案，利用参数化网格的合成渲染来增强表情保真度
- Result: 1. 在单GPU上渲染速度达250+ FPS；2. 仅CPU推理时约9 FPS；3. 在表情准确性上超越最先进的NeRF方法；4. 实现身份保持的精细表情控制
- Conclusion: AGORA代表了向实用高性能数字人迈出的重要一步，首次展示了实用的仅CPU可动画化3DGS化身合成，在视觉真实性和精确可控性方面均表现出色


### [62] [Towards Stable Cross-Domain Depression Recognition under Missing Modalities](https://arxiv.org/abs/2512.06447)
*Jiuyi Chen,Mingkui Tan,Haifeng Lu,Qiuna Xu,Zhihua Wang,Runhao Zeng,Xiping Hu*

Main category: cs.CV

TL;DR: 提出SCD-MLLM框架，基于多模态大语言模型实现稳定的跨领域抑郁症识别，支持异构数据输入并保持模态缺失时的稳定性。

- Motivation: 抑郁症筛查具有公共卫生紧迫性，现有音频视频检测方法缺乏统一框架，对模态缺失情况不稳定，难以适应真实世界数据。
- Method: 提出SCD-MLLM框架，包含：1) 多源数据输入适配器(MDIA)，使用掩码机制和任务提示将异构输入转为统一token序列；2) 模态感知自适应融合模块(MAFM)，通过共享投影机制自适应融合音视频特征。
- Result: 在五个公开数据集(CMDC、AVEC2014、DAIC-WOZ、DVlog、EATD)上，无论是完整模态还是部分模态设置，SCD-MLLM均优于SOTA模型和主流商业LLM，展现优越的跨领域泛化能力和模态缺失稳定性。
- Conclusion: SCD-MLLM为抑郁症识别提供了统一、稳定、可泛化的多模态框架，能有效处理真实世界中的异构数据和模态缺失问题，具有实际应用价值。


### [63] [Sanvaad: A Multimodal Accessibility Framework for ISL Recognition and Voice-Based Interaction](https://arxiv.org/abs/2512.06485)
*Kush Revankar,Shreyas Deshpande,Araham Sayeed,Ansh Tandale,Sarika Bobde*

Main category: cs.CV

TL;DR: Sanvaad是一个轻量级多模态无障碍框架，支持聋人、视障用户与听力正常人群之间的实时双向通信，结合了手语识别、语音转手语、语音识别和文本转语音等功能。

- Motivation: 当前聋人、视障用户与听力正常人群之间的通信工具通常只支持单向交互，存在沟通障碍。需要一种能够支持双向实时通信的无障碍解决方案。
- Method: 1. 针对聋人用户：使用MediaPipe地标点构建印度手语识别模块，利用其高效低计算负载特性；语音转手语组件将检测到的语音映射到预定义短语并生成相应GIF或字母可视化
2. 针对视障用户：提供无屏幕语音界面，集成多语言语音识别、文本摘要和文本转语音生成
3. 整体框架：基于Streamlit构建界面，支持桌面和移动环境，结合轻量级计算机视觉和语音处理工具
- Result: 开发了Sanvaad框架，能够在边缘设备上流畅运行，无需专用硬件，提供实用的双向通信解决方案。
- Conclusion: Sanvaad通过结合轻量级计算机视觉和语音处理工具，为包容性通信提供了实用且可访问的途径，解决了聋人和视障用户与听力正常人群之间的双向沟通障碍。


### [64] [Method of UAV Inspection of Photovoltaic Modules Using Thermal and RGB Data Fusion](https://arxiv.org/abs/2512.06504)
*Andrii Lysyi,Anatoliy Sachenko,Pavlo Radiuk,Mykola Lysyi,Oleksandr Melnychenko,Diana Zahorodnia*

Main category: cs.CV

TL;DR: 提出一个智能光伏检测框架，通过多模态融合和自适应重采集解决传统方法的热成像偏差、数据冗余和高带宽问题，在公开基准上取得12-15%的性能提升。

- Motivation: 传统光伏检测方法存在热成像调色板偏差、数据冗余和通信带宽要求高等关键缺陷，需要开发自动化、智能化的监测系统来提升光伏电站的安全性和运营效率。
- Method: 采用协同架构：1）学习调色板不变的热成像嵌入表示；2）通过门控机制融合对比度归一化的RGB流；3）使用罗德里格斯更新的自适应重采集控制器确认模糊异常；4）基于DBSCAN和半正矢距离的地理空间去重模块。
- Result: 在PVF-10公开基准上达到0.903的mAP@0.5，比单模态基线提升12-15%；现场验证召回率达96%；去重减少15-20%的重复误报；相关性遥测减少60-70%的空中数据传输。
- Conclusion: 建立了一个主动式光伏检测新范式，系统已具备实际应用准备度，能显著提升检测精度、减少误报并大幅降低通信带宽需求。


### [65] [ShadowWolf -- Automatic Labelling, Evaluation and Model Training Optimised for Camera Trap Wildlife Images](https://arxiv.org/abs/2512.06521)
*Jens Dede,Anna Förster*

Main category: cs.CV

TL;DR: ShadowWolf是一个统一的AI框架，通过动态模型重训练来适应环境变化，减少标注工作量，提高野生动物监测的准确性和效率。

- Motivation: 随着人口增长和栖息地扩张，人类与野生动物的互动增加，从轻微干扰到物种灭绝等严重后果。传统AI训练面临景观、天气、光照和距离等多变环境因素的挑战，需要更鲁棒和自适应的解决方案。
- Method: 提出名为ShadowWolf的统一框架，整合并优化AI模型训练和评估阶段。支持动态模型重训练以适应环境条件和应用需求的变化，减少标注工作量，实现现场模型自适应。
- Result: 该框架提高了野生动物监测系统的准确性和效率，支持更有效和可扩展的保护工作。
- Conclusion: ShadowWolf通过自适应和统一的AI训练方法，解决了野生动物监测中的环境变化挑战，为保护工作提供了更有效的技术支持。


### [66] [On The Role of K-Space Acquisition in MRI Reconstruction Domain-Generalization](https://arxiv.org/abs/2512.06530)
*Mohammed Wattad,Tamir Shor,Alex Bronstein*

Main category: cs.CV

TL;DR: 该论文研究了学习型k空间采集模式在加速MRI中的跨领域泛化能力，提出了一种通过引入采集不确定性来增强领域鲁棒性的新方法。

- Motivation: 现有研究大多关注针对单一数据集或模态优化的采集模式，缺乏对其跨成像领域可迁移性的考虑。需要探索学习型k空间采样在领域转移下的表现，以提升MRI重建的泛化能力。
- Method: 提出了一种增强领域鲁棒性的新方法：在训练过程中引入采集不确定性，通过随机扰动k空间轨迹来模拟不同扫描仪和成像条件的变异性。
- Result: 系统评估表明，使用学习型采样模式训练的模型在跨领域设置下表现出更好的泛化性能。提出的不确定性方法进一步提升了领域鲁棒性。
- Conclusion: k空间轨迹设计不仅应被视为加速机制，更应作为改善MRI重建领域泛化能力的重要自由度。学习型采样模式具有超越训练领域的泛化潜力。


### [67] [Novel Deep Learning Architectures for Classification and Segmentation of Brain Tumors from MRI Images](https://arxiv.org/abs/2512.06531)
*Sayan Das,Arghadip Biswas*

Main category: cs.CV

TL;DR: 本文提出两种深度学习架构：SAETCN用于脑肿瘤分类（准确率99.38%），SAS-Net用于脑肿瘤分割（像素准确率99.23%），解决传统手动检测耗时且现有模型泛化性差的问题。

- Motivation: 脑肿瘤对人类生命构成重大威胁，早期准确检测对诊断治疗至关重要。传统放射科医生手动检测MRI图像耗时且困难，尤其近年来儿童和青少年脑肿瘤发病率上升导致数据量大增。现有CAD系统模型泛化性不足，在验证数据上表现不佳。
- Method: 提出两种新型深度学习架构：1) SAETCN（自注意力增强肿瘤分类网络）用于脑肿瘤分类，处理胶质瘤、脑膜瘤、垂体瘤和非肿瘤四类图像；2) SAS-Net（自注意力分割网络）用于脑肿瘤精确分割。两种架构都利用了自注意力机制。
- Result: SAETCN在验证数据集上达到99.38%的分类准确率，成为少数能够准确检测脑肿瘤的新型深度学习架构之一。SAS-Net实现99.23%的整体像素准确率，在脑肿瘤分割任务上表现优异。
- Conclusion: 提出的两种自注意力深度学习架构在脑肿瘤分类和分割任务上都取得了优异性能，为解决传统手动检测耗时和现有模型泛化性差的问题提供了有效方案，有助于实现早期自动检测脑肿瘤的CAD系统。


### [68] [Bridging spatial awareness and global context in medical image segmentation](https://arxiv.org/abs/2512.06560)
*Dalia Alzu'bi,A. Ben Hamza*

Main category: cs.CV

TL;DR: U-CycleMLP：一种新型U形编码器-解码器网络，用于医学图像分割，通过位置注意力权重激励块、密集空洞块和通道CycleMLP块来平衡分割精度与计算效率。

- Motivation: 现有医学图像分割模型难以有效捕捉局部和全局上下文信息，导致边界像素丢失和分割错误，需要在保持轻量级架构的同时提升分割性能。
- Method: 提出U-CycleMLP网络：编码器使用位置注意力权重激励块、密集空洞块和下采样操作学习多尺度上下文特征；解码器通过上采样、密集空洞块和特征融合机制重建高分辨率分割掩码；在跳跃连接中加入通道CycleMLP块以增强特征整合，同时保持线性计算复杂度。
- Result: 在三个基准数据集上的实验表明，U-CycleMLP相比最先进方法具有竞争力，在所有数据集上获得更好的分割精度，能捕捉细粒度解剖结构，并在不同医学成像模态中表现出鲁棒性。
- Conclusion: U-CycleMLP通过创新的架构设计有效解决了医学图像分割中局部与全局上下文信息捕获的挑战，在保持轻量级的同时实现了优异的分割性能，消融研究进一步验证了核心组件的重要性。


### [69] [SUGAR: A Sweeter Spot for Generative Unlearning of Many Identities](https://arxiv.org/abs/2512.06562)
*Dung Thuy Nguyen,Quang Nguyen,Preston K. Robinette,Eli Jiang,Taylor T. Johnson,Kevin Leach*

Main category: cs.CV

TL;DR: SUGAR是一个用于3D感知生成模型的框架，能够在不重新训练整个模型的情况下，同时或顺序地移除多个身份，同时保持模型质量和多样性。

- Motivation: 随着3D感知生成模型在合成人类身份图像方面取得进展，引发了关于用户同意和从模型输出空间中移除特定个体的迫切问题。
- Method: SUGAR为每个身份学习个性化的替代潜在表示，将重建结果转向视觉上连贯的替代方案，而不是将不需要的身份投射到不现实的输出或依赖静态模板面部。还引入了持续效用保持目标，防止随着更多身份被遗忘而导致的性能退化。
- Result: SUGAR在移除多达200个身份方面实现了最先进的性能，与现有基线相比，保留效用提高了700%。
- Conclusion: SUGAR提供了一个可扩展的生成遗忘框架，能够有效移除多个身份，同时保持模型质量，解决了3D感知生成模型中的用户同意问题。


### [70] [GNC-Pose: Geometry-Aware GNC-PnP for Accurate 6D Pose Estimation](https://arxiv.org/abs/2512.06565)
*Xiujin Liu*

Main category: cs.CV

TL;DR: GNC-Pose：一种完全无需学习的单目6D物体姿态估计方法，通过渲染初始化、几何感知对应点加权和鲁棒的GNC优化，在纹理物体上实现竞争性精度。

- Motivation: 现有方法通常依赖学习特征或类别先验，GNC-Pose旨在提供一种无需学习、无需训练数据、无需类别先验的鲁棒6D姿态估计解决方案。
- Method: 1) 通过特征匹配和渲染对齐获取粗略2D-3D对应点；2) 基于GNC原则引入几何感知的聚类加权机制，根据3D结构一致性分配点置信度；3) 使用LM细化进一步提高精度。
- Result: 在YCB数据集上测试，尽管无需学习特征、训练数据或类别先验，GNC-Pose仍能达到与学习方法和非学习方法相当的竞争性精度。
- Conclusion: GNC-Pose为无学习6D姿态估计提供了一个简单、鲁棒且实用的解决方案，在严重离群点污染下仍能稳定优化。


### [71] [MedGRPO: Multi-Task Reinforcement Learning for Heterogeneous Medical Video Understanding](https://arxiv.org/abs/2512.06581)
*Yuhao Su,Anwesa Choudhuri,Zhongpai Gao,Benjamin Planche,Van Nguyen Nguyen,Meng Zheng,Yuhan Shen,Arun Innanje,Terrence Chen,Ehsan Elhamifar,Ziyan Wu*

Main category: cs.CV

TL;DR: 提出MedVidBench大规模医疗视频理解基准和MedGRPO强化学习框架，解决医疗视频理解中空间精度、时序推理和临床语义的挑战

- Motivation: 现有大型视觉语言模型在医疗视频理解方面表现不佳，需要解决空间精度、时序推理和临床语义等关键问题
- Method: 1) 构建MedVidBench基准：531,850个视频-指令对，涵盖8个医疗来源，采用专家引导提示和双模型验证的质量保证流程；2) 提出MedGRPO框架：跨数据集奖励归一化和医疗LLM评判器，解决多数据集训练中的奖励不平衡问题
- Result: 在MedVidBench上监督微调的Qwen2.5-VL-7B大幅超越GPT-4.1和Gemini-2.5-Flash；MedGRPO框架进一步提升了SFT基线在定位和字幕任务上的表现
- Conclusion: 建立了医疗视觉语言模型的基础基准和稳健训练方法，为医疗领域的视觉语言模型发展奠定了基础


### [72] [From Remote Sensing to Multiple Time Horizons Forecasts: Transformers Model for CyanoHAB Intensity in Lake Champlain](https://arxiv.org/abs/2512.06598)
*Muhammad Adil,Patrick J. Clemins,Andrew W. Schroth,Panagiotis D. Oikonomou,Donna M. Rizzo,Peter D. F. Isles,Xiaohan Zhang,Kareem I. Hannoun,Scott Turnbull,Noah B. Beckage,Asim Zia,Safwan Wshah*

Main category: cs.CV

TL;DR: 提出结合Transformer和BiLSTM的遥感预测框架，利用卫星数据预测蓝藻水华强度，可提前14天预警，在数据稀疏情况下仍保持良好性能。

- Motivation: 蓝藻有害藻华对水生生态系统和公共健康构成严重威胁，尚普兰湖等水域因营养富集和气候变化而频繁发生。遥感技术为解决现场观测稀疏问题提供了可扩展的监测方案。
- Method: 开发基于Transformer和BiLSTM的纯遥感预测框架，使用蓝藻指数和温度卫星数据。针对数据稀疏问题（蓝藻指数缺失30%，温度数据缺失90%），采用两阶段预处理：像素级前向填充和加权时间插补，然后平滑处理。通过等频分箱和温度统计提取特征。
- Result: 模型在多个预测时间窗口表现优异：1天、2天、3天预测的F1分数分别为89.5%、86.4%、85.5%；14天预测的F1分数为78.9%，AUC为82.6%。
- Conclusion: 该模型能够从稀疏卫星数据中捕捉复杂的时空动态，为蓝藻水华管理提供可靠的早期预警，证明了遥感数据在预测蓝藻水华强度方面的有效性。


### [73] [Learning Relative Gene Expression Trends from Pathology Images in Spatial Transcriptomics](https://arxiv.org/abs/2512.06612)
*Kazuya Nishimura,Haruka Hirose,Ryoma Bise,Kaito Shiku,Yasuhiro Kojima*

Main category: cs.CV

TL;DR: 提出STRank损失函数，通过预测基因的相对表达模式而非绝对表达值，来应对RNA测序中的随机噪声和批次效应问题。

- Motivation: 从病理图像估计基因表达可以降低RNA测序成本，但由于测序技术复杂性和细胞内在变异性，观测到的基因表达包含随机噪声和批次效应，准确估计绝对表达值面临重大挑战。
- Method: 提出学习相对表达模式而非绝对水平的新目标，假设基因的相对表达水平在不同独立实验中呈现一致模式。基于此假设，提出名为STRank的新型损失函数，对噪声和批次效应具有鲁棒性。
- Result: 在合成数据集和真实数据集上的实验证明了所提方法的有效性。
- Conclusion: 通过关注相对表达模式而非绝对表达值，STRank方法能够更好地处理基因表达估计中的噪声和批次效应问题，为病理图像到基因表达的映射提供了更稳健的解决方案。


### [74] [Hierarchical Deep Learning for Diatom Image Classification: A Multi-Level Taxonomic Approach](https://arxiv.org/abs/2512.06613)
*Yueying Ke*

Main category: cs.CV

TL;DR: 提出分层卷积网络用于硅藻分类，通过嵌入分类学层次结构提高准确性和错误定位能力

- Motivation: 传统硅藻分类依赖专家，现有深度学习方法多为扁平分类，无法利用分类学层次结构信息
- Method: 使用具有五个级联头的分层卷积网络，联合预测纲、目、科、属、种，通过二进制掩码限制有效后代预测
- Result: 分层模型在物种级准确率与基线相当(69.4%)，但在上层分类级别表现更好，错误分类时92.5%能在属级正确预测
- Conclusion: 分层架构通过自上而下的约束和自下而上的梯度传播，提高了分类的鲁棒性、可解释性和生物学一致性


### [75] [Masked Autoencoder Pretraining on Strong-Lensing Images for Joint Dark-Matter Model Classification and Super-Resolution](https://arxiv.org/abs/2512.06642)
*Achmad Ardani Prasha,Clavino Ourizqi Rachmadi,Muhamad Fauzan Ibnu Syahlan,Naufal Rahfi Anugerah,Nanda Garin Raditya,Putri Amelia,Sabrina Laila Mutiara,Hilman Syachr Ramadhan*

Main category: cs.CV

TL;DR: MAE预训练策略应用于强引力透镜图像，通过掩码自编码器学习可泛化表示，用于暗物质模型分类和超分辨率重建任务，在90%掩码率下取得优于从头训练的性能。

- Motivation: 强引力透镜分析可以揭示暗物质子结构的影响，但处理噪声大、分辨率低的图像具有挑战性。需要开发能够从模拟数据中学习通用表示的方法，以支持多种下游任务。
- Method: 使用掩码自编码器(MAE)在DeepLense ML4SCI基准的模拟强透镜图像上进行预训练，学习通用表示。然后针对两个下游任务分别微调编码器：(1)暗物质模型分类(冷暗物质、轴子状或无子结构)；(2)超分辨率重建(16x16到64x64)。研究了不同掩码率对性能的影响。
- Result: 在90%掩码率下，分类器达到宏AUC 0.968和准确率88.65%，优于从头训练的基线(AUC 0.957，准确率82.46%)。超分辨率任务中，MAE预训练模型重建图像的PSNR约33 dB，SSIM 0.961，略优于从头训练。研究发现掩码率存在权衡：更高的掩码率改善分类但轻微降低重建保真度。
- Conclusion: MAE预训练在物理丰富的模拟数据上提供了灵活、可重用的编码器，适用于多种强透镜分析任务，展示了自监督学习在天体物理数据分析中的潜力。


### [76] [TextMamba: Scene Text Detector with Mamba](https://arxiv.org/abs/2512.06657)
*Qiyan Zhao,Yue Yan,Da-Han Wang*

Main category: cs.CV

TL;DR: 提出基于Mamba的场景文本检测器，通过选择机制与注意力层结合增强长序列特征提取能力，在多个基准测试中取得SOTA性能。

- Motivation: Transformer方法在场景文本检测中虽然解决了CNN的全局特征提取限制，但存在跨域限制和固有缺陷：在建模长距离依赖时会遗忘重要信息或关注无关表示。最近提出的状态空间模型Mamba通过线性复杂度选择机制展现了更好的长距离依赖建模能力。
- Method: 1. 提出基于Mamba的场景文本检测器，将选择机制与注意力层集成；2. 采用Top_k算法显式选择关键信息，减少Mamba建模中的无关信息干扰；3. 设计双尺度前馈网络和嵌入金字塔增强模块，促进高维隐藏状态交互和多尺度特征融合。
- Result: 在多个基准测试中取得SOTA或竞争性性能：CTW1500上F-measure为89.7%，TotalText上为89.2%，ICDAR19ArT上为78.5%。
- Conclusion: 提出的基于Mamba的场景文本检测器通过集成选择机制与注意力层，有效增强了编码器从长序列中提取相关信息的能力，在多个基准测试中表现出优越性能。


### [77] [Personalized Image Descriptions from Attention Sequences](https://arxiv.org/abs/2512.06662)
*Ruoyu Xue,Hieu Le,Jingyi Xu,Sounak Mondal,Abe Leite,Gregory Zelinsky,Minh Hoai,Dimitris Samaras*

Main category: cs.CV

TL;DR: DEPER模型通过结合个性化观看行为和语言风格来生成更符合人类习惯的图像描述，相比仅关注语言风格的方法平均提升24%

- Motivation: 现有个性化图像描述模型只关注语言风格，忽略了个人观看模式（注意力分布）的差异。人们观看同一图像时关注不同区域、对象和细节的顺序不同，导致描述存在显著差异。
- Method: 提出DEPER模型，学习同时捕捉语言风格和观看行为的主题嵌入，通过辅助注意力预测任务指导学习。使用轻量级适配器将这些嵌入与冻结的视觉语言模型对齐，实现少样本个性化而无需重新训练。
- Result: 在四个数据集（涵盖不同观看任务和简短/详细描述）上，DEPER相比现有方法平均提升24%，证明建模个性化注意力能产生更符合人类习惯和更高质量的描述。
- Conclusion: 理解人们如何观看有助于预测他们会说什么；建模人类感知的多样性可以提高多模态系统的性能和人类对齐度。


### [78] [CoT4Det: A Chain-of-Thought Framework for Perception-Oriented Vision-Language Tasks](https://arxiv.org/abs/2512.06663)
*Yu Qi,Yumeng Zhang,Chenting Gong,Xiao Tan,Weiming Zhang,Wei Zhang,Jingdong Wang*

Main category: cs.CV

TL;DR: CoT4Det将感知任务重构为分类、计数和定位三个步骤，显著提升大视觉语言模型在目标检测等感知任务上的性能，在COCO上mAP从19%提升到33%。

- Motivation: 大视觉语言模型在通用视觉问答任务上表现优异，但在感知任务（如目标检测、语义分割）上性能远低于专用专家模型，特别是在密集场景和小物体检测方面存在明显不足。
- Method: 提出Chain-of-Thought for Detection (CoT4Det)方法，将感知任务重构为三个可解释步骤：分类（识别物体类别）、计数（统计物体数量）、定位（确定物体位置），这些步骤更符合大视觉语言模型的推理能力。
- Result: 在Qwen2.5-VL-7B-Instruct模型上，CoT4Det将COCO2017 val的mAP从19.0%提升到33.0%；在RefCOCO系列上超越基线2%，在Flickr30k entities上提升19%，同时不损害通用视觉语言能力。
- Conclusion: 通过将感知任务分解为更符合大视觉语言模型推理模式的步骤，CoT4Det能够显著提升模型在感知任务上的性能，同时保持其通用视觉语言能力，为改进大视觉语言模型的感知能力提供了有效方法。


### [79] [1 + 1 > 2: Detector-Empowered Video Large Language Model for Spatio-Temporal Grounding and Reasoning](https://arxiv.org/abs/2512.06673)
*Shida Gao,Feng Xue,Xiangfeng Wang,Anlong Ming,Teng Long,Yihua Shao,Haozhe Wang,Zhaowen Lin,Wei Wang,Nicu Sebe*

Main category: cs.CV

TL;DR: DEViL提出了一种结合视频大语言模型和开放词汇检测器的架构，通过引用语义令牌实现端到端学习，解决时空定位中自回归空间解码导致的误差累积问题。

- Motivation: 当前MLLMs将边界框作为文本令牌进行自回归生成，导致输出序列过长，空间误差随时间累积，定位结果在视频中逐渐漂移。需要解决时空定位中的误差传播问题。
- Method: 1. 提出DEViL架构，将视频LLM与开放词汇检测器(OVD)耦合；2. 引入引用语义令牌(RST)，将用户查询蒸馏为丰富的语义表示，既作为控制信号又替代OVD的文本嵌入；3. 提出管状挖掘时间正则化(TTReg)，驱动OVD生成时间一致的目标对象查询。
- Result: 实验表明DEViL在各种细粒度视频理解任务上表现优异，特别是在STVG和GroundedVQA任务上。代码将在GitHub上发布。
- Conclusion: DEViL通过结合视频LLM和检测器，解决了时空定位中的误差累积问题，实现了更好的时空一致性和定位精度，为视频理解任务提供了有效解决方案。


### [80] [RunawayEvil: Jailbreaking the Image-to-Video Generative Models](https://arxiv.org/abs/2512.06674)
*Songping Wang,Rufan Qian,Yueming Lyu,Qinglong Liu,Linzhuang Zou,Jie Qin,Songhua Liu,Caifeng Shan*

Main category: cs.CV

TL;DR: RunawayEvil：首个针对图像到视频生成模型的多模态越狱攻击框架，采用"策略-战术-行动"范式，具备动态进化能力，在商业I2V模型上实现了最先进的攻击成功率。

- Motivation: 图像到视频生成系统虽然提供了强大的创意控制能力，但其安全性特别是对越狱攻击的脆弱性尚未得到充分研究。当前缺乏针对这类多模态系统的安全漏洞分析工具。
- Method: 基于"策略-战术-行动"范式构建：1) 策略感知命令单元：通过强化学习策略定制和LLM策略探索实现自我进化；2) 多模态战术规划单元：基于选定策略生成协调的文本越狱指令和图像篡改指南；3) 战术行动单元：执行并评估多模态协调攻击。整个架构具备自我进化能力。
- Result: 在Open-Sora 2.0和CogVideoX等商业I2V模型上实现了最先进的攻击成功率，在COCO2017数据集上比现有方法提升了58.5%到79%。
- Conclusion: 该工作为I2V模型的漏洞分析提供了关键工具，为构建更鲁棒的视频生成系统奠定了基础，揭示了多模态生成系统安全性的重要性。


### [81] [EMGauss: Continuous Slice-to-3D Reconstruction via Dynamic Gaussian Modeling in Volume Electron Microscopy](https://arxiv.org/abs/2512.06684)
*Yumeng He,Zanwei Zhou,Yekun Zheng,Chen Liang,Yunbo Wang,Xiaokang Yang*

Main category: cs.CV

TL;DR: EMGauss：基于高斯溅射的3D重建框架，将切片到3D重建重新定义为3D动态场景渲染问题，解决各向异性结构重建难题

- Motivation: 体积电子显微镜（vEM）存在采集权衡，导致各向异性体积和有限的轴向分辨率。现有深度学习方法基于各向同性假设，在处理形态各向异性结构时失效
- Method: 将切片到3D重建重新定义为基于高斯溅射的3D动态场景渲染问题，将轴向切片进展建模为2D高斯点云的时间演化。引入教师-学生引导机制，在数据稀疏区域使用高置信度预测作为伪监督信号
- Result: 相比基于扩散和GAN的重建方法，EMGauss显著提高了插值质量，支持连续切片合成，无需大规模预训练，并在各向异性结构上表现优异
- Conclusion: EMGauss为vEM提供了一种绕过各向同性假设限制的通用3D重建框架，并可能扩展到其他成像领域的切片到3D重建任务


### [82] [Lightweight Wasserstein Audio-Visual Model for Unified Speech Enhancement and Separation](https://arxiv.org/abs/2512.06689)
*Jisoo Park,Seonghak Lee,Guisik Kim,Taewoo Kim,Junseok Kwon*

Main category: cs.CV

TL;DR: UniVoiceLite：轻量级无监督视听框架，统一语音增强和语音分离任务

- Motivation: 现实音频通常同时包含背景噪声和重叠说话人，传统方法将语音增强和语音分离视为独立任务，需要统一解决方案。现有方法多为多阶段架构、参数复杂且依赖监督训练，限制了可扩展性和泛化能力。
- Method: 提出UniVoiceLite框架，利用唇部运动和面部身份线索指导语音提取，采用Wasserstein距离正则化稳定潜在空间，无需配对噪声-干净数据，实现无监督学习。
- Result: 实验结果表明，UniVoiceLite在噪声和多说话人场景下均表现优异，实现了效率与鲁棒泛化能力的结合。
- Conclusion: UniVoiceLite成功将语音增强和语音分离统一到单一轻量级模型中，通过无监督视听方法解决了传统方法的局限性，代码已开源。


### [83] [The Role of Entropy in Visual Grounding: Analysis and Optimization](https://arxiv.org/abs/2512.06726)
*Shuo Li,Jiajun Sun,Zhihao Zhang,Xiaoran Fan,Senjie Jin,Hui Li,Yuming Yang,Junjie Ye,Lixing Shen,Tao Ji,Tao Gui,Qi Zhang,Xuanjing Huang*

Main category: cs.CV

TL;DR: 本文提出ECVGPO算法，通过熵控制技术改进多模态大语言模型在视觉定位任务中的强化学习微调，平衡探索与利用的权衡，在多个基准测试中取得广泛改进。

- Motivation: 尽管强化学习微调多模态大语言模型取得了显著进展，但熵控制在感知导向任务（如视觉定位）中的作用和特性尚未充分探索。现有研究主要关注推理任务，而视觉定位任务中的熵控制策略仍不明确。
- Method: 首先分析视觉定位任务中熵的作用和特性，并与推理任务进行对比。基于这些发现，提出ECVGPO（熵控制视觉定位策略优化）算法，这是一个可解释的算法，专门设计用于有效的熵调节，通过熵控制更好地平衡探索与利用的权衡。
- Result: 实验表明，ECVGPO在多个基准测试和不同模型上都取得了广泛的改进，验证了熵控制在视觉定位任务中的有效性。
- Conclusion: ECVGPO算法通过有效的熵控制机制，成功解决了视觉定位任务中探索与利用的平衡问题，为多模态大语言模型在感知导向任务中的强化学习微调提供了新的解决方案。


### [84] [Graph Convolutional Long Short-Term Memory Attention Network for Post-Stroke Compensatory Movement Detection Based on Skeleton Data](https://arxiv.org/abs/2512.06736)
*Jiaxing Fan,Jiaojiao Liu,Wenkong Wang,Yang Zhang,Xin Ma,Jichen Zhang*

Main category: cs.CV

TL;DR: 提出基于骨架数据的GCN-LSTM-ATT网络用于中风后补偿性运动检测，准确率达0.8580，优于传统机器学习方法。

- Motivation: 中风患者普遍存在上肢运动功能障碍，康复训练中常出现补偿性运动，这对患者长期恢复不利，因此检测补偿性运动具有重要意义。
- Method: 使用Kinect深度相机采集16名中风患者执行特定康复动作的骨架数据，构建GCN-LSTM-ATT模型（图卷积长短期记忆注意力网络），并与SVM、KNN、RF等传统机器学习算法对比。
- Result: GCN-LSTM-ATT模型的检测准确率达到0.8580，显著高于传统机器学习算法。消融实验表明模型的各个组件对性能提升均有显著贡献。
- Conclusion: 该研究为中风后补偿性运动检测提供了更精确有效的工具，有望促进中风患者康复训练策略的优化。


### [85] [FedSCAl: Leveraging Server and Client Alignment for Unsupervised Federated Source-Free Domain Adaptation](https://arxiv.org/abs/2512.06738)
*M Yashwanth,Sampath Koti,Arunabh Singh,Shyam Marjit,Anirban Chakraborty*

Main category: cs.CV

TL;DR: FedSCAl是一个联邦学习框架，通过服务器-客户端对齐机制解决联邦源自由域自适应问题，在存在显著客户端间域差异的情况下提高伪标签准确性。

- Motivation: 联邦源自由域自适应（FFreeDA）问题中，客户端持有未标记数据且存在显著的客户端间域差异，同时限制只能使用预训练的服务器模型而无法访问源数据集。现有的源自由域自适应方法在联邦学习中面临客户端漂移问题，导致伪标签不可靠。
- Method: 提出FedSCAl框架，采用服务器-客户端对齐（SCAl）机制，通过对齐客户端和服务器模型的预测来正则化客户端更新。该机制帮助缓解客户端漂移，提高伪标签准确性。
- Result: 在基准视觉数据集上的广泛实验表明，FedSCAl在FFreeDA设置下的分类任务中持续优于最先进的联邦学习方法。
- Conclusion: FedSCAl通过服务器-客户端对齐机制有效解决了联邦源自由域自适应中的客户端漂移问题，提高了伪标签准确性，在存在显著域差异的情况下表现出优越性能。


### [86] [Task-Model Alignment: A Simple Path to Generalizable AI-Generated Image Detection](https://arxiv.org/abs/2512.06746)
*Ruoxin Chen,Jiahui Gao,Kaiqing Lin,Keyue Zhang,Yandan Zhao,Isabel Guan,Taiping Yao,Shouhong Ding*

Main category: cs.CV

TL;DR: 论文提出任务-模型对齐原则，通过将AIGI检测分解为语义一致性检查和像素伪影检测两个互补任务，设计双分支检测器AlignGemini，显著提升检测性能。

- Motivation: 现有视觉语言模型(VLMs)用于AI生成图像检测时存在严重幻觉问题，需要大量资源微调但效果仍不理想。研究发现VLMs与像素伪影检测任务存在错配，而传统像素伪影检测器又缺乏语义理解能力。
- Method: 提出任务-模型对齐原则，将AIGI检测形式化为两个互补任务：语义一致性检查和像素伪影检测。实例化为双分支检测器AlignGemini：一个分支使用纯语义监督微调VLM，另一个分支使用纯像素伪影监督训练像素伪影专家。在两个简化数据集上分别施加正交监督。
- Result: 在五个野外基准测试中，AlignGemini实现了平均准确率+9.5%的提升，证明了任务-模型对齐原则在可泛化AIGI检测中的有效性。
- Conclusion: 任务-模型对齐是提升AIGI检测泛化能力的有效路径，通过将检测任务分解为互补的子任务并匹配相应优势模型，可以克服单一模型的局限性。


### [87] [UARE: A Unified Vision-Language Model for Image Quality Assessment, Restoration, and Enhancement](https://arxiv.org/abs/2512.06750)
*Weiqi Li,Xuanyu Zhang,Bin Chen,Jingfen Xie,Yan Wang,Kexin Zhang,Junlin Li,Li Zhang,Jian Zhang,Shijie Zhao*

Main category: cs.CV

TL;DR: UARE是首个统一图像质量评估、修复和增强的视觉语言模型，通过两阶段训练框架将质量评估信号与修复目标对齐，实现多任务协同训练。

- Motivation: 虽然图像质量评估(IQA)和图像修复在概念上紧密相关，但现有工作大多将它们孤立处理。统一多模态理解-生成模型的进展表明更强的理解能力可以提升生成性能，这促使研究如何将IQA与修复统一，让IQA指导修复过程。
- Method: 基于预训练的统一理解和生成模型，提出两阶段训练框架：1) 渐进式从单一类型失真扩展到高阶混合退化，使模型能处理多种退化；2) 使用交错文本-图像数据进行统一微调，将IQA信号与修复目标对齐，实现多任务协同训练。
- Result: 在IQA、修复和增强任务上的广泛实验证明了UARE的有效性，模型能够利用IQA提升修复和增强性能。
- Conclusion: UARE是首个统一图像质量评估、修复和增强的视觉语言模型，通过将IQA与修复任务统一并让IQA指导修复过程，实现了性能提升，为低层视觉任务提供了新的统一框架。


### [88] [VisChainBench: A Benchmark for Multi-Turn, Multi-Image Visual Reasoning Beyond Language Priors](https://arxiv.org/abs/2512.06759)
*Wenbo Lyu,Yingjun Du,Jinglin Zhao,Xianton Zhen,Ling Shao*

Main category: cs.CV

TL;DR: VisChainBench是一个大规模基准测试，用于评估大型视觉语言模型在多图像、多轮场景中进行多步视觉推理的能力，包含1,457个任务和20,000多张图像，覆盖日常场景和工程故障排除等领域。

- Motivation: 现有基准测试主要关注静态或水平比较（如发现视觉差异或评估适当性），且过度依赖语言线索，忽视了渐进式、上下文相关的推理以及视觉到视觉推理的挑战。多图像、多轮场景的理解能力是大型视觉语言模型的关键但尚未充分探索的能力。
- Method: 使用多智能体生成流水线构建VisChainBench基准测试，确保高视觉多样性和受控的语言偏差。基准包含1,457个任务，涵盖20,000多张图像，分布在三个不同领域（日常场景、工程故障排除等），结构设计模拟真实世界的决策过程。
- Result: 创建了VisChainBench基准测试，包含1,457个任务和20,000多张图像，涵盖三个不同领域。基准测试数据、代码和构建方法已通过Hugging Face平台公开可用。
- Conclusion: VisChainBench填补了现有基准测试的空白，能够严格评估大型视觉语言模型在最小语言指导下进行多步视觉推理的能力，为模型在真实世界多图像、多轮场景中的表现提供了评估标准。


### [89] [JOCA: Task-Driven Joint Optimisation of Camera Hardware and Adaptive Camera Control Algorithms](https://arxiv.org/abs/2512.06763)
*Chengyang Yan,Mitch Bryson,Donald G. Dansereau*

Main category: cs.CV

TL;DR: 提出联合优化相机硬件和自适应控制算法的方法，通过混合梯度优化框架提升下游视觉任务性能

- Motivation: 现有相机系统设计主要优化固定制造参数，而许多参数（如曝光设置）需要在运行时自适应控制。当前方法大多分别优化静态和动态参数，缺乏统一的联合优化框架。
- Method: 提出统一优化框架，结合梯度优化和无导数方法，支持连续和离散参数、不可微图像形成过程以及基于神经网络的自适应控制算法。针对运动模糊等不可微效应，提出DF-Grad混合优化策略，使用无导数优化器信号训练自适应控制网络。
- Result: 实验表明，该方法在低光照和快速运动等挑战性条件下优于分别优化静态和动态参数的基线方法，显著提升感知性能。
- Conclusion: 联合优化硬件参数和自适应控制算法能有效提升感知性能，为任务驱动的相机系统设计提供了统一方法。


### [90] [Stitch and Tell: A Structured Multimodal Data Augmentation Method for Spatial Understanding](https://arxiv.org/abs/2512.06769)
*Hang Yin,Xiaomin He,PeiWen Yuan,Yiwei Li,Jiayi Shi,Wenxiao Fan,Shaoxiong Feng,Kan Li*

Main category: cs.CV

TL;DR: 提出Stitch and Tell方法，通过拼接图像和生成空间感知的文本对，无需标注即可提升视觉语言模型的空间理解能力，减少空间幻觉

- Motivation: 现有视觉语言模型存在空间幻觉问题，即对图像中物体相对位置的描述错误。作者认为这主要源于图像和文本之间的不对称性，需要增强模型的空间理解能力
- Method: 提出Stitch and Tell方法：1）沿空间轴拼接图像创建缝合图像；2）基于缝合图像的布局生成空间感知的标题或问答对；3）无需昂贵的高级模型或人工参与，是即插即用的无标注方法
- Result: 在LLaVA-v1.5-7B、LLaVA-Qwen2-1.5B和HALVA-7B三种架构上评估，SiTe显著提升空间理解任务：MME_Position (+5.50%)和Spatial-MM (+4.19%)，同时保持或提升通用视觉语言基准性能：COCO-QA (+1.02%)和MMBench (+4.76%)
- Conclusion: 将空间感知结构显式注入训练数据是缓解空间幻觉、提升空间理解能力的有效方法，同时能保持通用视觉语言能力。该方法简单、无标注、即插即用


### [91] [RDSplat: Robust Watermarking Against Diffusion Editing for 3D Gaussian Splatting](https://arxiv.org/abs/2512.06774)
*Longjie Zhao,Ziming Hong,Zhenyang Ren,Runnan Chen,Mingming Gong,Tongliang Liu*

Main category: cs.CV

TL;DR: RDSplat是一种针对3D高斯泼溅(3DGS)的鲁棒数字水印方法，专门设计来抵御基于扩散的编辑攻击，通过将水印嵌入到低频高斯组件中并结合对抗训练来增强鲁棒性。

- Motivation: 3D高斯泼溅技术已广泛应用于数字资产创建，但现有的3DGS水印方法对基于扩散的编辑攻击非常脆弱，这种编辑可以轻易擦除嵌入的版权信息。因此迫切需要开发能够抵御扩散编辑的鲁棒水印技术。
- Method: RDSplat采用多域框架，在3DGS空间中操作，通过(i)主动针对低频高斯组件嵌入水印，使用协调协方差正则化和2D滤波；(ii)利用基于扩散编辑的低通滤波特性，使用高斯模糊作为训练代理，进行对抗微调以增强水印鲁棒性。
- Result: 在三个基准数据集上的综合定量和定性评估表明，RDSplat在基于扩散的编辑下保持了卓越的鲁棒性，同时保持了水印的不可见性，实现了最先进的性能。
- Conclusion: RDSplat为3D高斯泼溅提供了一种鲁棒的水印范式，能够有效抵御基于扩散的编辑攻击，解决了现有方法的关键脆弱性问题，为数字资产的版权保护提供了可靠解决方案。


### [92] [Physics Informed Human Posture Estimation Based on 3D Landmarks from Monocular RGB-Videos](https://arxiv.org/abs/2512.06783)
*Tobias Leuthold,Michele Xiloyannis,Yves Zimmermann*

Main category: cs.CV

TL;DR: 提出一种实时后处理算法，融合BlazePose的3D和2D估计，通过加权优化结合解剖约束和生物力学模型，显著提升姿态估计精度

- Motivation: 当前物理训练自动教练应用依赖单目视频的姿态估计，但现有方法如BlazePose缺乏解剖约束，有改进空间。需要更准确、鲁棒且符合解剖学的姿态估计来支持物理治疗、医疗保健和运动教练应用。
- Method: 提出实时后处理算法：1) 使用加权优化融合BlazePose的3D和2D估计；2) 通过惩罚偏离预期骨长度和生物力学模型来加入解剖约束；3) 使用自适应测量信任的卡尔曼滤波器精炼个体解剖的骨长度估计
- Result: 在Physio2.2M数据集上评估：3D MPJPE降低10.2%，身体段间角度误差减少16.6%。方法在消费级笔记本和移动设备上运行高效，仅在后端使用匿名数据。
- Conclusion: 该方法提供了一种鲁棒、解剖一致且计算高效的视频到3D姿态估计方案，适用于自动物理治疗、医疗保健和运动教练应用，显著提升了姿态估计的准确性和解剖合理性。


### [93] [Generalized Geometry Encoding Volume for Real-time Stereo Matching](https://arxiv.org/abs/2512.06793)
*Jiaxin Liu,Gangwei Xu,Xianqi Wang,Chengliang Zhang,Xin Yang*

Main category: cs.CV

TL;DR: GGEV：一种实时立体匹配网络，通过深度感知特征和动态成本聚合实现强泛化能力，在零样本泛化中超越现有实时方法

- Motivation: 现有实时立体匹配方法主要关注域内性能而忽视泛化能力，而具有泛化能力的立体基础模型又存在推理延迟大的问题，需要解决实时性与泛化能力之间的权衡
- Method: 提出广义几何编码体积（GGEV）：1）提取编码领域不变结构先验的深度感知特征作为成本聚合指导；2）引入深度感知动态成本聚合（DDCA）模块，自适应地将这些先验融入每个视差假设，增强未见场景中的脆弱匹配关系
- Result: 在KITTI 2012、KITTI 2015和ETH3D基准测试中达到最先进性能，在零样本泛化能力上超越所有现有实时方法
- Conclusion: GGEV成功解决了实时立体匹配中泛化能力与速度的权衡问题，通过轻量级互补模块构建了具有强泛化能力的几何编码体积


### [94] [VDOT: Efficient Unified Video Creation via Optimal Transport Distillation](https://arxiv.org/abs/2512.06802)
*Yutong Wang,Haiyu Zhang,Tianfan Xue,Yu Qiao,Yaohui Wang,Chang Xu,Xinyuan Chen*

Main category: cs.CV

TL;DR: VDOT是一种高效统一的视频生成模型，采用分布匹配蒸馏和最优传输技术，在4步生成中达到或超过100步基线模型的性能

- Motivation: 现有视频生成模型要么只能处理少数特定条件，要么因推理复杂导致生成时间过长，难以在实际应用中部署。需要开发既高效又能处理多种条件的统一视频生成模型。
- Method: 采用分布匹配蒸馏范式，使用最优传输技术优化真实与生成分数分布之间的差异，避免KL散度蒸馏中的零强制或梯度崩溃问题。同时集成判别器感知真实视频数据，并开发自动化视频标注过滤管道支持多任务训练。
- Result: 实验表明，4步生成的VDOT模型在性能上达到或超过需要100步去噪的基线模型，显著提升了生成效率和质量。
- Conclusion: VDOT通过最优传输增强的分布匹配蒸馏，实现了高效稳定的视频生成，解决了现有模型在效率和通用性方面的限制，为实际应用提供了可行方案。


### [95] [MMDuet2: Enhancing Proactive Interaction of Video MLLMs with Multi-Turn Reinforcement Learning](https://arxiv.org/abs/2512.06810)
*Yueqian Wang,Songxiang Liu,Disong Wang,Nuo Xu,Guanglu Wan,Huishuai Zhang,Dongyan Zhao*

Main category: cs.CV

TL;DR: 提出MMDuet2模型，通过多轮强化学习训练实现视频流中的主动交互，模型能自主决定何时回应或保持沉默，无需精确回复时间标注。

- Motivation: 现有视频多模态大语言模型多为回合制交互，无法在视频播放过程中主动决定何时回应。为实现实时应用，需要模型能够主动判断何时响应。
- Method: 提出文本到文本的主动交互方法，基于对话历史和当前视频帧视觉上下文，模型自主决定回应或沉默。采用多轮强化学习训练方法，无需精确回复时间标注，鼓励及时准确回应。
- Result: 在52k视频数据集上通过SFT和RL训练MMDuet2模型，在ProactiveVideoQA基准测试中优于现有主动视频MLLM基线，在响应时机和质量上达到最先进性能。
- Conclusion: MMDuet2通过多轮RL训练实现了有效的主动视频交互，解决了传统方法需要手动调阈值和精确时间标注的问题，为实时视频应用提供了新方案。


### [96] [RMAdapter: Reconstruction-based Multi-Modal Adapter for Vision-Language Models](https://arxiv.org/abs/2512.06811)
*Xiang Lin,Weixin Li,Shu Guo,Lihong Wang,Di Huang*

Main category: cs.CV

TL;DR: RMAdapter：一种双分支重建式多模态适配器，通过适配分支注入任务特定知识，重建分支保留通用知识，在少样本场景下平衡任务适应与泛化能力。

- Motivation: 预训练视觉语言模型（如CLIP）在少样本微调时面临任务特定适应与泛化能力的平衡挑战。现有研究主要关注提示调优方法，而适配器方法探索不足且性能存在差距。
- Method: 提出重建式多模态适配器（RMAdapter），采用双分支架构：1）适配分支通过参数高效微调注入任务特定知识；2）重建分支通过将潜在空间特征重建回原始特征空间来保留通用知识。通过局部重建损失计算、共享投影模块和一致性约束实现轻量化设计。
- Result: 在三个代表性任务上全面评估：新类别泛化、新目标数据集泛化和领域泛化。在不依赖数据增强或重复提示设计的情况下，RMAdapter在所有评估指标上持续优于最先进方法。
- Conclusion: RMAdapter通过双分支架构有效平衡了通用知识与任务特定知识，在少样本多模态迁移学习中实现了更好的性能，为适配器方法提供了新的设计思路。


### [97] [MeshSplatting: Differentiable Rendering with Opaque Meshes](https://arxiv.org/abs/2512.06818)
*Jan Held,Sanghyun Son,Renaud Vandeghen,Daniel Rebain,Matheus Gadelha,Yi Zhou,Anthony Cioppa,Ming C. Lin,Marc Van Droogenbroeck,Andrea Tagliasacchi*

Main category: cs.CV

TL;DR: MeshSplatting是一种基于网格的重建方法，通过可微分渲染联合优化几何和外观，将神经渲染与交互式3D图形连接起来，实现实时场景交互。

- Motivation: 现有的基于基元（如3D高斯泼溅）的方法虽然实现了实时渲染，但其基于点的表示与AR/VR和游戏引擎中基于网格的流程不兼容，需要一种能创建平滑、高质量网格的方法来连接神经渲染和交互式3D图形。
- Method: 通过受限Delaunay三角剖分强制连接性，并优化表面一致性，使用可微分渲染联合优化几何和外观，创建端到端平滑的网格表示。
- Result: 在Mip-NeRF360数据集上，PSNR比当前最先进的MiLo方法提高了+0.69 dB，训练速度快2倍，内存使用减少2倍，能够高效地在实时3D引擎中渲染。
- Conclusion: MeshSplatting成功创建了视觉质量高、端到端平滑的网格，填补了神经渲染与交互式3D图形之间的鸿沟，为实时场景交互提供了无缝解决方案。


### [98] [SparseCoop: Cooperative Perception with Kinematic-Grounded Queries](https://arxiv.org/abs/2512.06838)
*Jiahao Wang,Zhongwei Jiang,Wenchao Sun,Jiaru Zhong,Haibao Yu,Yuner Zhang,Chenyang Lu,Chuang Zhang,Lei He,Shaobing Xu,Jianqiang Wang*

Main category: cs.CV

TL;DR: SparseCoop是一个完全稀疏的协同感知框架，用于3D检测和跟踪，摒弃了中间BEV表示，通过实例查询、粗到精聚合和协同实例去噪任务实现高效协同感知。

- Motivation: 当前协同感知方法存在通信成本高、灵活性差、对齐不精确等问题。基于密集BEV特征的方法通信成本呈二次方增长，且缺乏跨异步或不同视角的精确对齐灵活性。而稀疏查询方法则存在几何表示不足、融合策略次优和训练不稳定等问题。
- Method: 提出完全稀疏的SparseCoop框架，包含三个创新：1) 基于运动学的实例查询，使用包含3D几何和速度的显式状态向量进行精确时空对齐；2) 粗到精聚合模块实现鲁棒融合；3) 协同实例去噪任务加速和稳定训练。
- Result: 在V2X-Seq和Griffin数据集上达到最先进性能，具有卓越的计算效率、低传输成本和强大的通信延迟鲁棒性。
- Conclusion: SparseCoop通过完全稀疏的协同感知框架，有效解决了现有方法的通信成本、对齐精度和训练稳定性问题，为自动驾驶协同感知提供了高效可靠的解决方案。


### [99] [CADE: Continual Weakly-supervised Video Anomaly Detection with Ensembles](https://arxiv.org/abs/2512.06840)
*Satoshi Hashimoto,Tatsuya Konishi,Tomoya Kaichi,Kazunori Matsumoto,Mori Kurokawa*

Main category: cs.CV

TL;DR: CADE是首个将持续学习与弱监督视频异常检测结合的方法，通过双生成器和多判别器集成解决领域偏移和遗忘问题。

- Motivation: 现有弱监督视频异常检测方法主要处理静态数据集，忽略了数据领域可能变化的问题。当领域发生偏移时，仅用新数据训练会导致对先前数据的性能下降（遗忘）。需要从持续学习的角度来解决这一问题。
- Method: 提出CADE方法：1）使用双生成器（DG）解决WVAD中的数据不平衡和标签不确定性；2）提出集成多判别器（MD）来捕捉因遗忘而错过的过去场景中的异常，使用多个模型来缓解"不完整性"问题。
- Result: 在常见的多场景VAD数据集（如ShanghaiTech和Charlotte Anomaly数据集）上，CADE显著优于现有的VAD方法。
- Conclusion: CADE是首个结合持续学习和弱监督视频异常检测的方法，有效解决了领域偏移和遗忘问题，在多场景异常检测中表现出色。


### [100] [Pseudo Anomalies Are All You Need: Diffusion-Based Generation for Weakly-Supervised Video Anomaly Detection](https://arxiv.org/abs/2512.06845)
*Satoshi Hashimoto,Hitoshi Nishimura,Yanan Wang,Mori Kurokawa*

Main category: cs.CV

TL;DR: PA-VAD：一种无需真实异常视频的生成驱动视频异常检测方法，通过合成伪异常视频进行训练，在标准弱监督设置下达到SOTA性能

- Motivation: 实际部署视频异常检测面临真实异常视频稀缺且收集成本高的问题，需要一种无需真实异常视频的实用解决方案
- Method: 1) 使用CLIP选择类别相关初始图像，通过视觉语言模型优化文本提示，调用视频扩散模型合成伪异常视频；2) 训练时采用域对齐正则化模块，结合域对齐和内存使用感知更新，缓解合成异常的过度时空幅度问题
- Result: 在ShanghaiTech达到98.2%，UCF-Crime达到82.5%，超越最强的真实异常方法（ShanghaiTech +0.6%）和UVAD SOTA方法（UCF-Crime +1.9%）
- Conclusion: 无需收集真实异常即可实现高精度异常检测，为可扩展部署提供了实用路径


### [101] [Hide-and-Seek Attribution: Weakly Supervised Segmentation of Vertebral Metastases in CT](https://arxiv.org/abs/2512.06849)
*Matan Atad,Alexander W. Marka,Lisa Steinhelfer,Anna Curto-Vilalta,Yannik Leonhardt,Sarah C. Foreman,Anna-Sophia Walburga Dietrich,Robert Graf,Alexandra S. Gersing,Bjoern Menze,Daniel Rueckert,Jan S. Kirschke,Hendrik Möller*

Main category: cs.CV

TL;DR: 提出一种弱监督方法，仅使用椎体级别的健康/恶性标签（无需病灶掩码），通过扩散自编码器生成健康编辑图像，结合像素差异图和Hide-and-Seek Attribution机制，实现椎体转移瘤的准确分割。

- Motivation: CT中椎体转移瘤的准确分割在临床上很重要，但难以规模化，因为体素级标注稀缺，且溶骨性和成骨性病变常与良性退行性改变相似。
- Method: 结合扩散自编码器生成椎体的健康编辑图像，通过像素差异图提出候选病灶区域，引入Hide-and-Seek Attribution机制：逐个揭示候选区域同时隐藏其他区域，将编辑图像投影回数据流形，通过潜在空间分类器量化每个组件的独立恶性贡献，高分区域形成最终分割。
- Result: 在保留的放射科医生标注上，尽管没有掩码监督，仍取得了优异的成骨性/溶骨性性能（F1: 0.91/0.85; Dice: 0.87/0.78），超过基线方法（F1: 0.79/0.67; Dice: 0.74/0.55）。
- Conclusion: 椎体级别标签可以转化为可靠的病灶掩码，表明生成编辑与选择性遮挡相结合支持CT中准确的弱监督分割。


### [102] [Omni-Referring Image Segmentation](https://arxiv.org/abs/2512.06862)
*Qiancheng Zheng,Yunhang Shen,Gen Luo,Baiyang Song,Xing Sun,Xiaoshuai Sun,Yiyi Zhou,Rongrong Ji*

Main category: cs.CV

TL;DR: 提出Omni-Referring Image Segmentation (OmniRIS)任务，支持文本指令和带掩码/框/涂鸦的参考图像作为全模态提示，实现高度泛化的图像分割。

- Motivation: 现有单模态条件分割任务（如RIS和视觉RIS）无法充分利用文本和视觉模态的各自优势：文本擅长细粒度属性指代，视觉擅长罕见对象定位。需要一种能同时处理多种模态输入和分割设置的任务。
- Method: 1) 提出OmniRIS任务框架，支持文本指令和带掩码/框/涂鸦的参考图像作为全模态提示；2) 构建大型数据集OmniRef（30,956张图像，186,939个全模态提示）；3) 提出OmniSegNet基线模型，解决全模态提示编码等关键挑战。
- Result: 实验验证了OmniSegNet能够有效遵循全模态指令，并展示了OmniRIS在高度泛化图像分割方面的优越性。数据集和评估系统为后续研究提供了基础。
- Conclusion: OmniRIS通过融合文本和视觉模态的优势，支持多种输入格式和分割设置，实现了更通用、更实用的图像分割任务，为高度泛化的视觉理解开辟了新方向。


### [103] [Boosting Unsupervised Video Instance Segmentation with Automatic Quality-Guided Self-Training](https://arxiv.org/abs/2512.06864)
*Kaixuan Lu,Mehmet Onurcan Kaya,Dim P. Papadopoulos*

Main category: cs.CV

TL;DR: AutoQ-VIS提出了一种无监督视频实例分割框架，通过质量引导的自训练方法，在无需人工标注的情况下实现了SOTA性能。

- Motivation: 视频实例分割需要像素级掩码和时间一致性标注，标注成本高昂。现有无监督方法依赖合成数据，但存在合成到真实域的差距问题。
- Method: 建立伪标签生成和自动质量评估的闭环系统，通过质量引导的自训练方法，逐步从合成视频适应到真实视频。
- Result: 在YouTubeVIS-2019验证集上达到52.6 AP50，比之前的SOTA方法VideoCutLER提升4.4%，且无需任何人工标注。
- Conclusion: 质量感知的自训练方法在无监督视频实例分割中具有可行性，能够有效弥合合成到真实域的差距。


### [104] [Spatial Retrieval Augmented Autonomous Driving](https://arxiv.org/abs/2512.06865)
*Xiaosong Jia,Chenhe Zhang,Yule Jiang,Songbur Wong,Zhiyuan Zhang,Chen Chen,Shaofeng Zhang,Xuanhe Zhou,Xue Yang,Junchi Yan,Yu-Gang Jiang*

Main category: cs.CV

TL;DR: 提出空间检索范式，通过引入离线检索的地理图像作为额外输入，增强自动驾驶系统的感知能力，特别是在视野受限、遮挡或极端条件下的表现。

- Motivation: 现有自动驾驶系统依赖车载传感器进行环境感知，但受限于实时感知范围，在视野受限、遮挡或黑暗、雨天等极端条件下容易失效。人类驾驶员能够在能见度差时回忆道路结构，因此希望赋予模型这种"回忆"能力。
- Method: 提出空间检索范式，从离线缓存（如Google Maps或存储的自动驾驶数据集）中检索地理图像作为额外输入。扩展nuScenes数据集，通过Google Maps API检索地理图像并与自车轨迹对齐。在五个核心自动驾驶任务上建立基线。
- Result: 扩展的模态能够提升某些任务的性能。将开源数据集整理代码、数据和基准，供进一步研究这种新的自动驾驶范式。
- Conclusion: 空间检索范式为自动驾驶系统提供了"回忆"能力，通过引入离线地理图像作为额外输入，能够增强系统在视野受限、遮挡或极端条件下的感知性能，是一种即插即用的扩展方案。


### [105] [Less Is More, but Where? Dynamic Token Compression via LLM-Guided Keyframe Prior](https://arxiv.org/abs/2512.06866)
*Yulin Li,Haokun Gui,Ziyang Fan,Junjie Wang,Bin Kang,Bin Chen,Zhuotao Tian*

Main category: cs.CV

TL;DR: DyToK提出了一种无需训练的token压缩方法，利用VLLM自身的注意力机制动态调整每帧token保留比例，提升长视频处理效率

- Motivation: 现有视频大语言模型在处理长视频时面临二次计算复杂度增长的问题，传统关键帧采样方法存在额外计算开销且二进制帧选择范式不够优化
- Method: DyToK通过分析发现VLLM注意力层自然编码了查询条件的关键帧先验，利用这一特性动态调整每帧token保留比例，优先保留语义丰富的帧并抑制冗余
- Result: 实验表明DyToK在效率-准确性权衡方面达到最先进水平，与现有压缩方法兼容，在LLaVA-OneVision和Qwen2.5-VL等模型上实现4.3倍推理加速且保持准确性
- Conclusion: DyToK提供了一种无需训练的即插即用token压缩范式，有效解决了VLLM处理长视频时的计算效率瓶颈问题


### [106] [Towards Robust Pseudo-Label Learning in Semantic Segmentation: An Encoding Perspective](https://arxiv.org/abs/2512.06870)
*Wangkai Li,Rui Sun,Zhaoyang Li,Tianzhu Zhang*

Main category: cs.CV

TL;DR: ECOCSeg提出了一种基于纠错输出码的语义分割方法，通过细粒度编码和位级标签去噪机制，提升伪标签学习的稳定性和泛化能力，在UDA和SSL任务上取得显著改进。

- Motivation: 伪标签学习在语义分割中广泛应用，特别是在标签稀缺的场景如无监督域适应和半监督学习。然而，这种范式会产生错误的伪标签，并且由于使用one-hot编码，这些错误在训练过程中会被进一步放大。
- Method: 提出ECOCSeg方法：1）引入基于ECOC的分类器，将类别分解为属性并处理部分不准确的比特位，提高伪标签学习的稳定性和泛化能力；2）开发位级标签去噪机制，生成更高质量的伪标签，为未标记图像提供充分且鲁棒的监督。
- Result: ECOCSeg可以轻松集成到现有方法中，在多个UDA和SSL基准测试中，跨不同分割架构都表现出显著的性能提升。
- Conclusion: ECOCSeg通过纠错输出码为分割模型提供了新的视角，有效解决了伪标签学习中的错误传播问题，提高了模型的鲁棒性和性能。


### [107] [SceneMixer: Exploring Convolutional Mixing Networks for Remote Sensing Scene Classification](https://arxiv.org/abs/2512.06877)
*Mohammed Q. Alkhatib,Ali Jamali,Swalpa Kumar Roy*

Main category: cs.CV

TL;DR: 提出基于卷积混合器范式的轻量级遥感场景分类模型，通过多尺度深度卷积和逐点操作交替提取局部与上下文信息，在保持低参数量和计算量的同时实现良好性能平衡。

- Motivation: 遥感场景分类对地球观测至关重要，但现有CNN和ViT模型在空间分辨率、视角、方向和背景条件变化下泛化能力有限，需要更高效且鲁棒的解决方案。
- Method: 采用卷积混合器架构，交替使用多尺度深度卷积进行空间混合和逐点操作进行通道混合，高效提取局部和上下文信息，保持低参数量和计算复杂度。
- Result: 在AID数据集上达到74.7%总体准确率、74.57%平均准确率和73.79 Kappa值；在EuroSAT数据集上达到93.90%总体准确率、93.93%平均准确率和93.22 Kappa值，在准确性和效率间取得良好平衡。
- Conclusion: 提出的轻量级卷积混合器模型在遥感场景分类任务中相比广泛使用的CNN和transformer模型，提供了更好的准确性与效率平衡，代码将公开可用。


### [108] [Hierarchical Image-Guided 3D Point Cloud Segmentation in Industrial Scenes via Multi-View Bayesian Fusion](https://arxiv.org/abs/2512.06882)
*Yu Zhu,Naoya Chiba,Koichi Hashimoto*

Main category: cs.CV

TL;DR: 提出分层图像引导的3D分割框架，通过从实例级到部件级的渐进细化，解决工业场景中遮挡和尺度差异问题。

- Motivation: 工业环境中密集布局和多尺度物体导致可靠3D分割困难：严重遮挡削弱几何边界，大尺度差异使端到端模型难以同时捕捉粗粒度和细粒度细节。现有方法要么需要昂贵标注，要么存在跨视图语义不一致问题。
- Method: 分层图像引导框架：1) 实例分割：渲染俯视图，用YOLO-World提示SAM生成掩码，反向投影到3D点云；2) 部件级分割：对每个实例渲染多视图图像，在每个视图应用相同2D分割和反向投影，通过贝叶斯更新融合确保跨视图语义一致性。
- Result: 在真实工厂数据上实验表明，方法能有效处理遮挡和结构复杂性，获得一致高的每类mIoU分数。在公开数据集上的额外评估证实了框架的泛化能力，突出了其鲁棒性、标注效率和适应多样化3D环境的能力。
- Conclusion: 提出的分层图像引导3D分割框架通过渐进细化和跨视图一致性融合，有效解决了工业场景中的遮挡和尺度差异问题，实现了高效、鲁棒且可泛化的3D分割。


### [109] [JoPano: Unified Panorama Generation via Joint Modeling](https://arxiv.org/abs/2512.06885)
*Wancheng Feng,Chen An,Zhenliang He,Meina Kan,Shiguang Shan,Lukun Wang*

Main category: cs.CV

TL;DR: JoPano提出了一种基于DiT的统一全景图生成方法，通过联合面适配器和条件切换机制，在单个模型中同时处理文本到全景图和视图到全景图两种任务，显著提升了生成质量和效率。

- Motivation: 现有全景图生成方法面临两个主要挑战：基于U-Net的架构限制了生成全景图的视觉质量；文本到全景图和视图到全景图两个核心任务通常被独立处理，导致建模冗余和效率低下。
- Method: 1. 提出基于DiT的联合面全景图生成方法，统一两个核心任务；2. 设计联合面适配器，利用全景图的立方体贴图表示，使预训练DiT能够联合建模和生成全景图的不同视图；3. 应用泊松融合减少立方体面边界处的接缝不一致；4. 引入接缝-SSIM和接缝-Sobel指标定量评估接缝一致性；5. 提出条件切换机制，在单个模型中统一文本到全景图和视图到全景图任务。
- Result: JoPano在文本到全景图和视图到全景图生成任务中都能生成高质量全景图，在FID、CLIP-FID、IS和CLIP-Score指标上达到最先进性能。
- Conclusion: JoPano通过统一架构和创新的适配器设计，有效解决了现有全景图生成方法的质量和效率问题，为全景图生成领域提供了更强大的解决方案。


### [110] [Balanced Learning for Domain Adaptive Semantic Segmentation](https://arxiv.org/abs/2512.06886)
*Wangkai Li,Rui Sun,Bohao Liao,Zhaoyang Li,Tianzhu Zhang*

Main category: cs.CV

TL;DR: BLDA提出了一种平衡学习域适应方法，通过分析预测logits分布识别过预测和欠预测类别，使用共享锚分布对齐logits分布，并在自训练中引入logits校正项来缓解类别不平衡问题。

- Motivation: 在语义分割的无监督域适应中，自训练方法由于类别不平衡和域间数据/标签空间分布偏移，难以平衡学习各个类别。现有方法需要先验知识来应对分布偏移，缺乏直接评估和缓解类别偏差的有效手段。
- Method: 1) 通过分析预测logits分布识别过预测和欠预测类别；2) 使用共享锚分布对logits分布进行后处理对齐；3) 在线估计logits分布并在损失函数中引入logits校正项；4) 利用累积密度作为域共享结构知识连接源域和目标域。
- Result: 在两个标准UDA语义分割基准测试上的广泛实验表明，BLDA在集成到多种现有方法时能持续提升性能，特别是对欠预测类别的改进效果显著。
- Conclusion: BLDA提供了一种无需先验分布偏移知识就能直接评估和缓解类别偏差的有效方法，通过平衡学习机制改善了语义分割域适应中的类别不平衡问题，为自训练方法提供了新的改进方向。


### [111] [Overcoming Small Data Limitations in Video-Based Infant Respiration Estimation](https://arxiv.org/abs/2512.06888)
*Liyang Song,Hardik Bishnoi,Sai Kumar Reddy Manne,Sarah Ostadabbas,Briana J. Taylor,Michael Wan*

Main category: cs.CV

TL;DR: 开发首个可复现的婴儿呼吸监测系统，包括400个视频的数据集和基于计算机视觉的呼吸估计算法

- Motivation: 婴儿呼吸监测对早期发现呼吸异常至关重要，但现有技术主要针对成人，缺乏婴儿专用的视频数据集和可复现算法
- Method: 创建AIR-400数据集（400个带标注的婴儿呼吸视频），开发基于婴儿特定感兴趣区域检测和时空神经处理的算法，结合光流输入增强
- Result: 建立了首个可复现的婴儿呼吸估计基准，提供了公开可用的数据集、代码库和训练模型
- Conclusion: 填补了婴儿非接触式呼吸监测的技术空白，为早期检测呼吸异常和预防SIDS等疾病提供了重要工具


### [112] [Scaling Zero-Shot Reference-to-Video Generation](https://arxiv.org/abs/2512.06905)
*Zijian Zhou,Shikun Liu,Haozhe Liu,Haonan Qiu,Zhaochong An,Weiming Ren,Zhiheng Liu,Xiaoke Huang,Kam Woh Ng,Tian Xie,Xiao Han,Yuren Cong,Hang Li,Chuyan Zhu,Aditya Patel,Tao Xiang,Sen He*

Main category: cs.CV

TL;DR: Saber是一个无需R2V训练数据的零样本参考图像到视频生成框架，通过掩码训练和注意力机制设计实现身份一致性和参考感知，在OpenS2V-Eval基准上超越需要R2V数据的方法

- Motivation: 当前参考图像到视频生成方法依赖昂贵的图像-视频-文本三元组数据，这种数据构建成本高且难以扩展，限制了方法的可扩展性
- Method: 提出Saber框架：1) 仅使用视频-文本对训练，无需R2V数据；2) 采用掩码训练策略和注意力模型设计学习身份一致和参考感知表示；3) 集成掩码增强技术减少复制粘贴伪影
- Result: 在OpenS2V-Eval基准上性能优于需要R2V数据的方法，展示了出色的泛化能力，能处理不同数量的参考图像
- Conclusion: Saber通过零样本方法解决了R2V数据稀缺问题，实现了可扩展的参考图像到视频生成，为相关领域提供了新的解决方案


### [113] [NeuroABench: A Multimodal Evaluation Benchmark for Neurosurgical Anatomy Identification](https://arxiv.org/abs/2512.06921)
*Ziyang Song,Zelin Zang,Xiaofan Ye,Boqiang Xu,Long Bai,Jinlin Wu,Hongliang Ren,Hongbin Liu,Jiebo Luo,Zhen Lei*

Main category: cs.CV

TL;DR: 论文提出了首个针对神经外科解剖学理解的多模态基准测试NeuroABench，评估了10多个先进MLLMs在神经外科视频解剖结构识别任务上的表现，发现现有模型性能显著落后于人类水平。

- Motivation: 现有MLLMs在手术视频理解方面主要关注手术流程和工作流，而忽视了临床实践中至关重要的解剖学理解。外科医生在解读、回顾和学习手术视频时高度依赖精确的解剖学知识，但缺乏专门评估解剖学理解能力的多模态基准。
- Method: 开发了NeuroABench基准，包含9小时标注的神经外科视频，涵盖89个不同手术，使用新颖的多模态标注流程和多重审核循环。评估68个临床解剖结构的识别能力，并比较了10多个先进MLLMs与4名神经外科实习生的表现。
- Result: 最佳MLLM在解剖识别任务中仅达到40.87%准确率，而神经外科实习生最佳成绩为56%，最低28%，平均46.5%。最佳MLLM性能仅与最低分实习生相当，显著落后于人类平均水平。
- Conclusion: MLLMs在解剖学理解方面已取得进展，但与人类水平仍有显著差距。NeuroABench为评估和改进手术视频理解中的解剖学认知能力提供了标准化框架，有助于推动手术教育和辅助系统的发展。


### [114] [Can We Go Beyond Visual Features? Neural Tissue Relation Modeling for Relational Graph Analysis in Non-Melanoma Skin Histology](https://arxiv.org/abs/2512.06949)
*Shravan Venkatraman,Muthu Subash Kavitha,Joe Dhanith P R,V Manikandarajan,Jia Wu*

Main category: cs.CV

TL;DR: NTRM提出了一种结合CNN和图神经网络的组织关系建模分割框架，通过建模组织间的空间和功能关系，在皮肤癌组织病理图像分割中显著提升了性能。

- Motivation: 当前基于CNN的组织病理图像分割方法主要关注视觉纹理特征，将不同组织视为独立区域，缺乏对组织间空间关系和生物学背景的建模，特别是在组织重叠或形态相似的区域表现不佳。
- Method: NTRM框架在CNN基础上引入组织级图神经网络：1）在预测区域上构建图结构；2）通过消息传递传播上下文信息；3）通过空间投影细化分割结果，显式编码组织间依赖关系。
- Result: 在Histopathology Non-Melanoma Skin Cancer Segmentation Dataset基准测试中，NTRM显著优于现有方法，Dice相似系数比最佳对比方法高出4.9%到31.25%。
- Conclusion: 关系建模为组织病理图像分割提供了更上下文感知和可解释的解决方案，相比仅依赖局部感受野的传统架构，能更好地理解组织级结构关系。


### [115] [Selective Masking based Self-Supervised Learning for Image Semantic Segmentation](https://arxiv.org/abs/2512.06981)
*Yuemin Wang,Ian Stavness*

Main category: cs.CV

TL;DR: 提出一种新颖的自监督学习方法，通过选择性掩码图像重建作为预训练任务来改进语义分割性能。

- Motivation: 传统随机掩码方法在掩码图像建模预训练中效率不高，需要更智能的掩码策略来提升下游分割任务的性能，特别是在资源受限的场景下。
- Method: 提出选择性掩码方法，通过迭代步骤选择重建损失最高的图像块进行掩码，利用已训练模型的知识来指导掩码过程，而不是随机掩码。
- Result: 在两个通用数据集（Pascal VOC和Cityscapes）和两个杂草分割数据集上，选择性掩码方法比传统随机掩码方法和监督ImageNet预训练在下游分割准确率上分别提升2.9%和2.5%，且显著改善了最低性能类别的准确率。
- Conclusion: 选择性掩码图像重建方法为端到端语义分割工作流程提供了有效实用的解决方案，特别适用于需要有限模型容量以满足推理速度和计算资源要求的场景。


### [116] [Power of Boundary and Reflection: Semantic Transparent Object Segmentation using Pyramid Vision Transformer with Transparent Cues](https://arxiv.org/abs/2512.07034)
*Tuan-Anh Vu,Hai Nguyen-Truong,Ziqiang Zheng,Binh-Son Hua,Qing Guo,Ivor Tsang,Sai-Kit Yeung*

Main category: cs.CV

TL;DR: TransCues：一种用于透明物体分割的Transformer架构，通过边界特征增强和反射特征增强模块，在多个基准数据集上显著超越现有方法

- Motivation: 玻璃等透明物体由于透明性和反射特性，现有分割方法难以将其与不透明材料区分。人类感知依赖边界和反射物体特征来识别玻璃物体，但现有文献未能充分捕捉这两种特性。
- Method: 提出TransCues框架，采用金字塔形Transformer编码器-解码器架构，包含边界特征增强模块和反射特征增强模块，以相互促进的方式整合这两种视觉线索。
- Result: 在多个基准数据集上大幅超越现有最佳方法：Trans10K-v2 (+4.2% mIoU)、MSD (+5.6% mIoU)、RGBD-Mirror (+10.1% mIoU)、TROSD (+13.1% mIoU)、Stanford2D3D (+8.3% mIoU)
- Conclusion: 通过同时利用边界和反射特征，TransCues能有效处理透明物体分割问题，在多种数据集上表现出色，验证了两种视觉线索协同作用的有效性。


### [117] [Evaluating and Preserving High-level Fidelity in Super-Resolution](https://arxiv.org/abs/2512.07037)
*Josep M. Rocafort,Shaolin Su,Javier Vazquez-Corral,Alexandra Gomez-Villa*

Main category: cs.CV

TL;DR: 该论文提出了评估超分辨率模型高级语义保真度的重要性，构建了首个带保真度标注的数据集，分析了现有质量指标与保真度的相关性，并展示了通过保真度反馈微调模型可同时提升语义保真度和感知质量。

- Motivation: 当前超分辨率模型虽然能生成视觉质量高的图像，但有时会产生幻觉改变图像内容，这种高级语义变化容易被人类识别但现有低层图像质量指标无法很好衡量。需要建立高级保真度评估标准来揭示生成式超分辨率模型的可靠性。
- Method: 1) 构建首个带保真度标注的超分辨率模型输出数据集；2) 评估SOTA超分辨率模型在保持高级保真度方面的表现；3) 分析现有图像质量指标与保真度测量的相关性；4) 展示基础模型能更好地处理此高级任务；5) 基于保真度反馈微调超分辨率模型。
- Result: 建立了首个超分辨率保真度标注数据集，发现现有质量指标与高级保真度相关性不足，基础模型在此任务上表现更好，通过保真度反馈微调可同时提升语义保真度和感知质量。
- Conclusion: 高级保真度评估是衡量超分辨率模型可靠性的重要补充标准，对模型评估和优化都有潜在价值。提出的保真度标准、数据集和方法为超分辨率研究提供了新的评估维度。


### [118] [DAUNet: A Lightweight UNet Variant with Deformable Convolutions and Parameter-Free Attention for Medical Image Segmentation](https://arxiv.org/abs/2512.07051)
*Adnan Munir,Shujaat Khan*

Main category: cs.CV

TL;DR: DAUNet是一个轻量级UNet变体，集成了可变形卷积V2和无参数注意力SimAM，在保持模型复杂度不变的情况下提升医学图像分割性能。

- Motivation: 医学图像分割在自动化诊断和治疗规划中至关重要。现有方法在处理几何变化和上下文感知特征融合方面存在不足，同时需要保持模型轻量以适应实时和资源受限的临床环境。
- Method: 提出DAUNet，在瓶颈层使用动态可变形卷积处理几何变化，在解码器和跳跃连接路径中使用SimAM注意力模块进行显著性感知细化，实现空间适应性和上下文感知特征融合。
- Result: 在两个挑战性数据集（FH-PS-AoP超声和FUMPE CT）上，DAUNet在Dice分数、HD95和ASD指标上优于最先进模型，同时保持优越的参数效率。消融研究验证了可变形卷积和SimAM注意力的各自贡献。
- Conclusion: DAUNet对缺失上下文和低对比度区域具有鲁棒性，适合部署在实时和资源受限的临床环境中，为医学图像分割提供了高效解决方案。


### [119] [RAVE: Rate-Adaptive Visual Encoding for 3D Gaussian Splatting](https://arxiv.org/abs/2512.07052)
*Hoang-Nhat Tran,Francesco Di Sario,Gabriele Spadaro,Giuseppe Valenzise,Enzo Tartaglione*

Main category: cs.CV

TL;DR: 提出一种灵活的3D高斯泼溅压缩方案，支持在预设范围内任意速率的插值，无需重新训练即可适应不同带宽和设备限制。

- Motivation: 3D高斯泼溅（3DGS）虽然能实现实时逼真渲染，但存在内存需求大、训练成本高的问题。现有压缩方法只能在固定速率下工作，无法适应变化的带宽和设备约束。
- Method: 提出一种灵活的3DGS压缩方案，支持在预设边界之间任意速率的插值。该方法计算轻量，无需为不同速率重新训练，能在广泛的操作点上保持渲染质量。
- Result: 实验证明该方法实现了高效、高质量的压缩，同时提供动态速率控制，适合沉浸式应用的实际部署。
- Conclusion: 该方法解决了3DGS压缩的灵活性限制问题，为沉浸式应用提供了实用的动态速率控制解决方案，代码将在接受后开源。


### [120] [$\mathrm{D}^{\mathrm{3}}$-Predictor: Noise-Free Deterministic Diffusion for Dense Prediction](https://arxiv.org/abs/2512.07062)
*Changliang Xia,Chengyou Jia,Minnan Luo,Zhuohang Dang,Xin Shen,Bowen Ping*

Main category: cs.CV

TL;DR: D³-Predictor：一种无噪声的确定性扩散模型框架，通过消除扩散采样中的随机噪声，将预训练扩散模型重构为时间步相关的视觉专家集合，用于密集预测任务。

- Motivation: 现有基于扩散模型的密集预测方法存在核心限制：扩散采样中的随机噪声与需要确定性图像到几何映射的密集预测任务本质不匹配。这种随机噪声会破坏细粒度空间线索，使模型偏向时间步特定的噪声目标，从而破坏有意义的几何结构映射。
- Method: 提出D³-Predictor，通过重构预训练扩散模型消除随机性噪声，将其视为时间步相关的视觉专家集合，自监督地聚合这些异质先验为单一、干净、完整的几何先验。同时利用任务特定监督无缝适应密集预测任务。
- Result: 在各种密集预测任务上的广泛实验表明，D³-Predictor在多种场景下达到竞争性或最先进的性能。同时，所需训练数据不到先前方法的一半，并能以单步推理高效执行。
- Conclusion: D³-Predictor通过消除扩散模型中的随机噪声，成功构建了适用于密集预测任务的确定性框架，在性能、数据效率和推理速度方面均有显著优势。


### [121] [Persistent Homology-Guided Frequency Filtering for Image Compression](https://arxiv.org/abs/2512.07065)
*Anil Chintapalli,Peter Tenholder,Henry Chen,Arjun Rao*

Main category: cs.CV

TL;DR: 使用离散傅里叶变换结合持续同调分析，从噪声图像中提取特定频率对应的拓扑特征，实现压缩并提升二分类任务性能

- Motivation: 噪声图像数据集中的特征提取面临模型可靠性挑战，需要能够区分有意义数据并保持压缩效果的鲁棒方法
- Method: 结合离散傅里叶变换和持续同调分析，提取与图像拓扑特征对应的特定频率，通过持续同调引导的频率过滤实现图像压缩和重构
- Result: 实验结果显示压缩效果与JPEG相当（使用六种不同指标评估），在增强卷积神经网络时，相比传统方法能提升二分类任务性能
- Conclusion: 持续同调引导的频率过滤方法能有效增强噪声条件下图像压缩的可靠性，为特征提取和压缩提供了新思路


### [122] [Context-measure: Contextualizing Metric for Camouflage](https://arxiv.org/abs/2512.07076)
*Chen-Yang Wang,Gepeng Ji,Song Shao,Ming-Ming Cheng,Deng-Ping Fan*

Main category: cs.CV

TL;DR: 提出Context-measure，一种基于概率像素感知相关框架的上下文化评估范式，用于评估伪装物体分割，比现有上下文无关指标更可靠。

- Motivation: 伪装主要依赖于上下文，但当前伪装场景的评估指标忽视了这一关键因素。现有指标是为评估一般或显著物体设计的，假设空间上下文不相关，这不符合伪装场景的特性。
- Method: 提出Context-measure，基于概率像素感知相关框架，通过纳入空间依赖性和像素级伪装量化，使评估更符合人类感知。
- Result: 在三个具有挑战性的伪装物体分割数据集上进行广泛实验，结果显示Context-measure比现有上下文无关指标提供更可靠的评估。
- Conclusion: Context-measure可以为涉及伪装模式的各种计算机视觉应用（如农业、工业和医疗场景）提供基础评估基准。


### [123] [DFIR-DETR: Frequency Domain Enhancement and Dynamic Feature Aggregation for Cross-Scene Small Object Detection](https://arxiv.org/abs/2512.07078)
*Bo Gao,Jingcheng Tong,Xingsheng Chen,Han Yu,Zichen Li*

Main category: cs.CV

TL;DR: DFIR-DETR：结合动态特征聚合与频域处理的小目标检测方法，在无人机遥感图像和工业缺陷检测中实现SOTA性能

- Motivation: 解决小目标检测中的三大挑战：特征随下采样严重退化、空间卷积无法有效捕获长距离依赖、标准上采样方法导致特征图不必要膨胀。特别是在无人机遥感和工业缺陷检测中，特征稀疏、背景杂乱、尺度变化大。
- Method: 提出DFIR-DETR架构，包含三个核心模块：1) DCFA模块使用动态K稀疏注意力降低复杂度，结合空间门控线性单元增强非线性建模；2) DFPN模块采用幅度归一化上采样防止特征膨胀，使用双路径洗牌卷积保留多尺度空间细节；3) FIRC3模块在频域操作，实现全局感受野且保持高效。
- Result: 在NEU-DET和VisDrone数据集上分别达到92.9%和51.6%的mAP50，均为当前最优。模型轻量，仅11.7M参数和41.2 GFLOPs，在资源受限环境下表现优异。
- Conclusion: DFIR-DETR通过动态特征聚合和频域处理的结合，有效解决了小目标检测的关键问题，在两个不同领域都展现了强大的泛化能力和实际应用价值，特别适合资源受限的跨场景小目标检测任务。


### [124] [COREA: Coarse-to-Fine 3D Representation Alignment Between Relightable 3D Gaussians and SDF via Bidirectional 3D-to-3D Supervision](https://arxiv.org/abs/2512.07107)
*Jaeyoon Lee,Hojoon Jung,Sungtae Hwang,Jihyong Oh,Jongwon Choi*

Main category: cs.CV

TL;DR: COREA是首个联合学习可重光照3D高斯和SDF的统一框架，通过3D到3D对齐策略实现精确几何重建和忠实重光照。

- Motivation: 现有3DGS方法从2D渲染学习几何，导致表面粗糙和BRDF-光照分解不可靠，需要直接在3D空间中学习几何信号。
- Method: 提出粗到细的双向3D到3D对齐策略：深度提供粗对齐，深度梯度和法线细化精细结构；引入密度控制机制稳定高斯增长。
- Result: 在标准基准测试中，COREA在新视角合成、网格重建和PBR方面均取得优越性能，实现几何保真与内存效率的平衡。
- Conclusion: COREA通过统一框架实现了精确几何重建和忠实重光照，解决了现有3DGS方法的几何粗糙和BRDF分解不稳定问题。


### [125] [MSN: Multi-directional Similarity Network for Hand-crafted and Deep-synthesized Copy-Move Forgery Detection](https://arxiv.org/abs/2512.07110)
*Liangwei Jiang,Jinluo Xie,Yecheng Huang,Hua Zhang,Hongyu Yang,Di Huang*

Main category: cs.CV

TL;DR: 提出MSN双流网络用于复制-移动图像伪造检测，通过多方向CNN和2D相似度矩阵解码器解决现有方法的表示和定位问题，并在多个基准上取得SOTA结果。

- Motivation: 复制-移动图像伪造检测面临复杂变换和精细操作的挑战，现有深度检测模型在表示能力和定位精度方面存在局限，需要更有效的检测方法。
- Method: 提出多方向相似度网络(MSN)，包含：1）多方向CNN网络进行分层编码，通过尺度旋转增强提高特征相似度度量；2）2D相似度矩阵解码器，充分利用图像空间信息进行精确定位。
- Result: 在CASIA CMFD、CoMoFoD和新提出的深度合成伪造数据库上进行了广泛实验，报告了最先进的结果，证明了方法的有效性。
- Conclusion: MSN网络通过改进表示和定位能力，在复制-移动伪造检测中表现出色，同时提出的新数据库为检测深度合成伪造提供了新基准。


### [126] [Training-free Clothing Region of Interest Self-correction for Virtual Try-On](https://arxiv.org/abs/2512.07126)
*Shengjie Lu,Zhibin Wan,Jiejie Liu,Quan Zhang,Mingjie Sun*

Main category: cs.CV

TL;DR: 提出CSC-VTON方法，通过能量函数约束注意力图，提升虚拟试衣中服装细节的保持能力，并设计新评估指标VTID

- Motivation: 现有虚拟试衣方法在生成服装与目标服装的图案、纹理和边界方面存在差异，且现有评估指标只关注图像真实感而忽视与目标元素的对齐
- Method: 使用能量函数约束生成过程中的注意力图，使注意力更集中于服装感兴趣区域，从而保持目标服装细节；同时提出新的评估指标VTID
- Result: 在VITON-HD和DressCode数据集上，LPIPS、FID、KID和VTID指标分别提升1.4%、2.3%、12.3%和5.8%；在下游CC-Reid任务中，LTCC、PRCC、VC-Clothes数据集的Rank-1指标分别提升2.5%、1.1%和1.6%
- Conclusion: 提出的CSC-VTON方法通过注意力约束机制有效提升虚拟试衣的服装细节保持能力，新评估指标VTID能更全面评估生成质量，在下游任务中也表现出良好性能


### [127] [MulCLIP: A Multi-level Alignment Framework for Enhancing Fine-grained Long-context CLIP](https://arxiv.org/abs/2512.07128)
*Chau Truong,Hieu Ta Quang,Dung D. Le*

Main category: cs.CV

TL;DR: MulCLIP提出了一种端到端的多层次对齐框架，通过全局对比对齐、token重建对齐和子标题聚合补丁对齐，有效解决了CLIP模型在处理长文本描述时的局限性，在保持部署效率的同时提升了细粒度理解能力。

- Motivation: 现有视觉语言模型（如CLIP）在短文本上表现良好，但在处理长文本描述时效果不佳。虽然已有方法利用区域建议信息来映射视觉区域和长文本句子，但这些方法部署成本高。需要一种既能处理长文本结构，又能保持部署效率的解决方案。
- Method: MulCLIP采用多层次对齐框架：1）全局对比对齐：保持图像与摘要及长标题的全局对比对齐，扩展位置嵌入以支持更长文本序列；2）token重建对齐：通过局部校准特征进行token重建，增强单词和图像补丁之间的语义连接；3）子标题聚合补丁对齐：自动提取和聚合每个子标题的上下文丰富补丁。
- Result: 在多个基准测试中，MulCLIP方法持续提升了下游任务性能。消融研究证实其多尺度对齐是关键因素，相比基于区域建议的方法，MulCLIP在细粒度能力上表现更好，特别适合多样化的实际应用场景。
- Conclusion: MulCLIP通过创新的多层次对齐框架，有效解决了CLIP模型在处理长文本描述时的局限性，在保持部署效率的同时显著提升了细粒度视觉语言理解能力，为实际应用提供了更实用的解决方案。


### [128] [TrajMoE: Scene-Adaptive Trajectory Planning with Mixture of Experts and Reinforcement Learning](https://arxiv.org/abs/2512.07135)
*Zebin Xing,Pengxuan Yang,Linbo Wang,Yichen Zhang,Yiming Hu,Yupeng Zheng,Junli Wang,Yinfeng Gao,Guang Li,Kun Ma,Long Chen,Zhongpu Xia,Qichao Zhang,Hangjun Ye,Dongbin Zhao*

Main category: cs.CV

TL;DR: 该论文提出了一种改进的自动驾驶规划方法，通过混合专家模型为不同场景提供合适的轨迹先验，并使用强化学习优化轨迹评分机制，在navsim ICCV基准测试中获得第三名。

- Motivation: 当前端到端自动驾驶系统虽然能通过神经网络将传感器输入映射到轨迹空间，但现有方法存在两个关键问题：1) 不同驾驶场景需要不同的轨迹先验，但现有方法往往忽略这一点；2) 轨迹评估机制缺乏策略驱动的优化，受限于单阶段监督训练的局限性。
- Method: 针对问题1，采用混合专家模型为不同场景提供定制的轨迹先验；针对问题2，使用强化学习对轨迹评分机制进行微调；同时集成不同感知骨干网络以增强感知特征。
- Result: 集成模型在navsim ICCV基准测试中获得51.08分，排名第三。
- Conclusion: 通过场景自适应的轨迹先验和强化学习优化的评分机制，能够显著提升自动驾驶规划性能，该方法在基准测试中取得了优异表现。


### [129] [A Large-Scale Multimodal Dataset and Benchmarks for Human Activity Scene Understanding and Reasoning](https://arxiv.org/abs/2512.07136)
*Siyang Jiang,Mu Yuan,Xiang Ji,Bufang Yang,Zeyu Liu,Lilin Xu,Yang Li,Yuting He,Liran Dong,Wenrui Lu,Zhenyu Yan,Xiaofan Jiang,Wei Gao,Hongkai Chen,Guoliang Xing*

Main category: cs.CV

TL;DR: CUHK-X是一个大规模多模态数据集，用于人类动作识别(HAR)、理解(HAU)和推理(HARn)，包含58,445个样本、40个动作，支持RGB、深度、IMU和毫米波等多种传感器数据。

- Motivation: 现有数据集主要提供粗糙的数据标签标注，缺乏对细粒度动作动态的描述，无法满足HAU和HARn任务的需求。同时，大多数大型视觉语言模型难以处理非RGB模态数据，因为缺乏大规模的数据-描述对资源。
- Method: 提出基于提示的场景创建方法，利用LLM生成逻辑连贯的活动序列，然后进行人工验证，确保描述的逻辑和时空一致性。数据集包含两种真值对：数据标签（离散类别）和数据描述（文本描述）。
- Result: 实验结果显示平均准确率：HAR为76.52%，HAU为40.76%，HARn为70.25%。数据集包含58,445个样本，覆盖30名参与者在两个室内环境中执行的40个动作。
- Conclusion: CUHK-X旨在为社区提供数据密集型学习方法，支持鲁棒的多模态人类活动分析，填补了现有数据集在细粒度动作理解和推理方面的空白。


### [130] [Think-Reflect-Revise: A Policy-Guided Reflective Framework for Safety Alignment in Large Vision Language Models](https://arxiv.org/abs/2512.07141)
*Fenghua Weng,Chaochao Lu,Xia Hu,Wenqi Shao,Wenjie Wang*

Main category: cs.CV

TL;DR: 提出Think-Reflect-Revise (TRR)三阶段训练框架，通过策略引导的自我反思增强大型视觉语言模型的安全对齐，显著提升安全性能

- Motivation: 现有单次推理范式容易受到上下文或视觉越狱攻击，因为单次推理可能忽略自身输出中的显式有害内容。关键洞察是利用反思机制，通过第一轮推理中揭示的恶意内容实现真正的自我修正
- Method: 1) 构建包含5000个示例的Reflective Safety Reasoning (ReSafe)数据集，遵循think-reflect-revise流程；2) 使用ReSafe数据集微调目标模型以初始化反思行为；3) 通过强化学习强化策略引导的反思
- Result: TRR显著提升LVLMs在安全感知基准和越狱攻击评估中的安全性能，将Qwen2.5-VL-7B的整体安全响应率从42.8%提升至87.7%，同时在MMMU和MMStar等通用基准上保持稳定性能
- Conclusion: 提出的TRR框架通过策略引导的自我反思有效增强LVLMs的安全对齐，解决了单次推理范式的安全漏洞，实现了真正的自我修正能力


### [131] [CHIMERA: Adaptive Cache Injection and Semantic Anchor Prompting for Zero-shot Image Morphing with Morphing-oriented Metrics](https://arxiv.org/abs/2512.07155)
*Dahyeon Kye,Jeahun Sung,MinKyu Jeon,Jihyong Oh*

Main category: cs.CV

TL;DR: CHIMERA：基于扩散模型的零样本图像变形框架，通过自适应缓存注入和语义锚点提示实现平滑、语义一致的图像变形

- Motivation: 现有扩散模型在图像变形任务中存在过渡突兀或过饱和的问题，缺乏自适应结构和语义对齐，难以实现平滑自然的图像变形
- Method: 1. 将变形定义为缓存反转引导的去噪过程；2. 自适应缓存注入（ACI）：在DDIM反转时缓存输入图像的特征，在去噪时自适应重新注入；3. 语义锚点提示（SAP）：使用视觉语言模型生成共享锚点提示作为语义桥梁；4. 提出全局-局部一致性评分（GLCS）作为变形专用评估指标
- Result: 实验和用户研究表明，CHIMERA相比现有方法实现了更平滑、语义更一致的变形效果，在图像变形任务中达到了新的state-of-the-art水平
- Conclusion: CHIMERA通过创新的缓存注入和语义锚点机制，解决了扩散模型在图像变形中的对齐问题，为高质量图像变形提供了有效的零样本解决方案


### [132] [MuSASplat: Efficient Sparse-View 3D Gaussian Splats via Lightweight Multi-Scale Adaptation](https://arxiv.org/abs/2512.07165)
*Muyu Xu,Fangneng Zhan,Xiaoqin Zhang,Ling Shao,Shijian Lu*

Main category: cs.CV

TL;DR: MuSASplat：一种轻量级多尺度适配器框架，用于稀疏视图3D高斯溅射，大幅减少训练参数和GPU成本，同时保持高质量的新视图合成。

- Motivation: 现有基于预训练3D先验的位姿无关前馈方法虽然效果不错，但需要完全微调大型ViT骨干网络，导致GPU成本过高。需要一种既能保持渲染质量又能显著降低计算负担的方法。
- Method: 提出MuSASplat框架：1）轻量级多尺度适配器，仅微调ViT架构的一小部分参数；2）特征融合聚合器，有效整合多视图特征，替代传统内存库，降低内存和计算复杂度。
- Result: 在多个数据集上的实验表明，MuSASplat在保持最先进渲染质量的同时，显著减少了参数数量和训练资源需求。
- Conclusion: MuSASplat通过轻量级适配器和高效特征融合，实现了稀疏视图3D高斯溅射的高效训练，在渲染质量和计算效率之间取得了良好平衡。


### [133] [When Privacy Meets Recovery: The Overlooked Half of Surrogate-Driven Privacy Preservation for MLLM Editing](https://arxiv.org/abs/2512.07166)
*Siyuan Xu,Yibing Liu,Peilin Chen,Yung-Hui Li,Shiqi Wang,Sam Kwong*

Main category: cs.CV

TL;DR: 该论文提出了一种恢复MLLM中隐私保护数据的方法，通过构建SPPE数据集和条件生成框架，在保护隐私的同时保持MLLM编辑质量。

- Motivation: 现有MLLM隐私保护方法虽然能有效隐藏隐私信息，但缺乏对隐私真实性和恢复质量的评估。本文旨在解决如何在多样化MLLM场景中恢复代理驱动的保护数据这一关键挑战。
- Method: 1) 构建SPPE数据集，包含多种隐私类别和用户指令，提供保护代理及其MLLM编辑版本；2) 将隐私恢复建模为基于互补多模态信号的引导生成任务；3) 提出统一方法，可靠重建隐私内容同时保持MLLM编辑保真度。
- Result: 在SPPE和InstructPix2Pix数据集上的实验表明，该方法能很好地泛化到不同视觉内容和编辑任务，在隐私保护和MLLM可用性之间实现了良好平衡。
- Conclusion: 该工作填补了MLLM隐私恢复评估的研究空白，提出的方法能有效恢复隐私内容同时保持MLLM编辑质量，为隐私保护和可用性平衡提供了解决方案。


### [134] [Towards Unified Semantic and Controllable Image Fusion: A Diffusion Transformer Approach](https://arxiv.org/abs/2512.07170)
*Jiayang Li,Chengjie Jiang,Junjun Jiang,Pengwei Liang,Jiayi Ma,Liqiang Nie*

Main category: cs.CV

TL;DR: DiTFuse：基于扩散Transformer的指令驱动图像融合框架，通过自然语言指令实现端到端、语义感知的多模态图像融合，统一多种融合任务并支持用户交互控制。

- Motivation: 现有图像融合方法在鲁棒性、适应性和可控性方面存在局限：1）多数网络针对特定任务设计，缺乏灵活性；2）难以融入用户意图，特别是在低光退化、色偏、曝光不平衡等复杂场景；3）缺乏真实融合图像作为ground truth，且数据集规模小，难以训练同时理解高层语义和细粒度多模态对齐的端到端模型。
- Method: 提出DiTFuse框架：1）基于扩散Transformer架构，在共享潜在空间中联合编码两幅图像和自然语言指令；2）采用多退化掩码图像建模训练策略，联合学习跨模态对齐、模态不变恢复和任务感知特征选择；3）构建多粒度指令数据集，赋予模型交互融合能力；4）统一红外-可见光、多焦点、多曝光融合以及文本控制精炼和下游任务。
- Result: 在IVIF、MFF、MEF等公共基准测试中表现出优越的定量和定性性能，纹理更清晰，语义保留更好。模型支持多级用户控制和零样本泛化到其他多图像融合场景，包括指令条件分割。
- Conclusion: DiTFuse通过指令驱动的扩散Transformer框架，克服了现有融合方法的局限性，实现了端到端、语义感知的图像融合，提供了灵活的用户控制和广泛的泛化能力，为多模态图像融合提供了统一解决方案。


### [135] [TIDE: Two-Stage Inverse Degradation Estimation with Guided Prior Disentanglement for Underwater Image Restoration](https://arxiv.org/abs/2512.07171)
*Shravan Venkatraman,Rakesh Raj Madavan,Pavan Kumar S,Muthu Subash Kavitha*

Main category: cs.CV

TL;DR: TIDE是一个两阶段水下图像恢复框架，通过分解退化因素并设计专门恢复专家来处理空间变化的复杂水下退化问题。

- Motivation: 水下图像恢复对海洋应用至关重要，但现有方法通常采用统一的恢复策略，难以处理空间变化且同时发生的多种退化问题。
- Method: TIDE采用两阶段逆退化估计框架：1) 将水下退化分解为颜色失真、雾霾、细节损失和噪声四个关键因素，设计专门恢复专家；2) 生成专门恢复假设并自适应融合，然后通过渐进细化阶段校正残留伪影。
- Result: 在标准基准和挑战性浑浊水条件下，TIDE在参考性保真度指标上具有竞争力，在非参考感知质量指标上优于最先进方法，在颜色校正和对比度增强方面有显著改进。
- Conclusion: TIDE通过明确建模退化特征和专门先验分解，有效解决了水下图像恢复中空间变化的多重退化问题，为复杂水下环境提供了强大的恢复解决方案。


### [136] [START: Spatial and Textual Learning for Chart Understanding](https://arxiv.org/abs/2512.07186)
*Zhuoming Liu,Xiaofeng Gao,Feiyang Niu,Qiaozi Gao,Liu Liu,Robinson Piramuthu*

Main category: cs.CV

TL;DR: START提出了一种结合空间和文本学习的图表理解方法，通过图表元素定位和图表到代码生成来增强多模态大语言模型对图表视觉布局和数据细节的理解能力。

- Motivation: 图表理解对于多模态大语言模型在现实场景（如科学论文和技术报告分析）中的部署至关重要。与自然图像不同，图表结合了结构化视觉布局（空间属性）和底层数据表示（文本属性），理解这两者对于精确、细粒度的图表推理至关重要。
- Method: 提出START方法，包含两个关键组件：1）图表元素定位，2）图表到代码生成。创建START-Dataset，使用新颖的数据生成流程：先用MLLM将真实图表图像转换为可执行图表代码，恢复底层数据表示同时保持真实图表视觉分布；然后用LLM演化代码以确定捕获图表视觉结构的元素位置。还提出了Chart Spatial understanding Benchmark（CS-Bench）来评估模型对图表空间结构的理解能力。
- Result: START在不同模型规模和基准测试上都比基础模型有持续提升，并且明显超越了先前的最先进方法。
- Conclusion: 通过结合空间和文本学习，START能够增强多模态大语言模型对图表视觉布局和数据细节的理解能力，在图表理解任务上取得了显著改进。


### [137] [Integrating Multi-scale and Multi-filtration Topological Features for Medical Image Classification](https://arxiv.org/abs/2512.07190)
*Pengfei Gu,Huimin Li,Haoteng Tang,Dongkuan,Xu,Erik Enriquez,DongChul Kim,Bin Fu,Danny Z. Chen*

Main category: cs.CV

TL;DR: 提出了一种新的拓扑引导医学图像分类框架，通过多尺度、多过滤的持续同调特征增强视觉分类骨干网络，显著提升对复杂解剖结构的识别能力。

- Motivation: 现有深度神经网络在医学图像分类中要么过度关注像素强度特征而忽视基本解剖结构（如拓扑不变量编码的结构），要么只能通过单参数持续性捕获简单的拓扑特征。需要更全面的拓扑视角来识别从全局解剖到局部细微异常的结构。
- Method: 1) 计算多分辨率/尺度的立方持续图；2) 开发"葡萄园"算法将多个持续图整合为单一稳定图，捕获从全局到局部的多粒度特征；3) 设计基于交叉注意力的神经网络直接处理整合后的持续图；4) 将拓扑嵌入与CNN或Transformer的特征图融合，形成端到端架构。
- Result: 在三个公共数据集上的评估显示，该方法相对于强基线和最先进方法取得了一致且显著的改进，证明了综合拓扑视角对鲁棒且可解释的医学图像分类的价值。
- Conclusion: 通过整合多尺度和多过滤拓扑特征到端到端架构中，该方法增强了模型识别复杂解剖结构的能力，为医学图像分类提供了更全面、鲁棒且可解释的解决方案。


### [138] [RefLSM: Linearized Structural-Prior Reflectance Model for Medical Image Segmentation and Bias-Field Correction](https://arxiv.org/abs/2512.07191)
*Wenqi Zhao,Jiacheng Sang,Fenghua Cheng,Yonglu Shu,Dong Li,Xiaofeng Yang*

Main category: cs.CV

TL;DR: 提出RefLSM模型，将Retinex反射率分解融入水平集分割，通过反射率分割解决医学图像不均匀光照问题，引入线性结构先验和松弛二元水平集提升精度和鲁棒性。

- Motivation: 医学图像分割面临强度不均匀、噪声、边界模糊和结构不规则等挑战。传统水平集方法依赖近似偏置场估计，在严重非均匀成像条件下表现不佳。
- Method: 提出RefLSM模型：1) 将观察图像分解为反射率和偏置场分量，直接分割光照不变的反射率；2) 引入线性结构先验，引导平滑反射率梯度；3) 嵌入松弛二元水平集，通过凸松弛和符号投影实现稳定演化；4) 采用ADMM优化方案。
- Result: 在多个医学影像数据集上的实验表明，RefLSM相比最先进的水平集方法，在分割精度、鲁棒性和计算效率方面均表现更优。
- Conclusion: RefLSM通过反射率分解有效解决了医学图像分割中的光照不均匀问题，结合结构先验和松弛水平集设计，实现了更精确、鲁棒且高效的分割性能。


### [139] [HVQ-CGIC: Enabling Hyperprior Entropy Modeling for VQ-Based Controllable Generative Image Compression](https://arxiv.org/abs/2512.07192)
*Niu Yi,Xu Tianyi,Ma Mingming,Wang Xinkun*

Main category: cs.CV

TL;DR: 提出HVQ-CGIC框架，通过引入VQ超先验实现可控的生成式图像压缩，显著提升率失真性能

- Motivation: 现有基于向量量化(VQ)的生成式图像压缩方法通常使用静态全局概率分布估计VQ索引的熵，无法适应图像特定内容，导致比特率潜力未充分利用且难以实现灵活的码率控制
- Method: 提出基于VQ超先验的可控生成式图像压缩框架(HVQ-CGIC)，严格推导了为VQ索引熵模型引入超先验的数学基础，通过新颖的损失设计首次在基于VQ的生成式压缩中引入率失真平衡与控制，配合轻量级超先验估计网络
- Result: 在Kodak数据集上，达到与Control-GIC、CDC和HiFiC相同的LPIPS指标时，平均节省61.3%的比特数，相比当前最先进的生成式压缩方法在率失真性能上具有显著优势
- Conclusion: HVQ-CGIC有潜力成为基于VQGAN的图像压缩的基础组件，类似于超先验框架在神经图像压缩中的核心作用


### [140] [SUCCESS-GS: Survey of Compactness and Compression for Efficient Static and Dynamic Gaussian Splatting](https://arxiv.org/abs/2512.07197)
*Seokhyun Youn,Soohyun Lee,Geonho Kim,Weeyoung Kwon,Sung-Ho Bae,Jihyong Oh*

Main category: cs.CV

TL;DR: 该论文是关于高效3D/4D高斯泼溅技术的首次统一综述，系统分类现有方法为参数压缩和结构压缩两大方向，旨在解决3DGS内存和计算需求过大的问题。

- Motivation: 3D高斯泼溅(3DGS)虽然能实现实时高保真3D重建和新视角合成，但存储和渲染数百万高斯需要大量内存和计算资源，特别是在4D动态场景中问题更加严重。因此需要高效压缩技术来减少冗余同时保持重建质量。
- Method: 对高效3D和4D高斯泼溅技术进行首次统一综述，将现有方法系统分类为两大方向：1) 参数压缩：直接减少高斯参数数量；2) 结构压缩：重新组织高斯表示结构。同时涵盖广泛使用的数据集、评估指标和代表性基准比较。
- Result: 提供了高效高斯泼溅技术的系统分类框架，总结了各方法的核心思想和方法趋势，建立了统一的评估体系，为静态和动态3D场景表示的可扩展、紧凑、实时高斯泼溅技术发展奠定了基础。
- Conclusion: 该综述为高效3D/4D高斯泼溅技术提供了首个统一框架，系统分类了现有方法，讨论了当前局限性，并指出了未来研究方向，推动了可扩展、紧凑、实时的高斯泼溅技术在静态和动态3D场景表示中的应用。


### [141] [Generating Storytelling Images with Rich Chains-of-Reasoning](https://arxiv.org/abs/2512.07198)
*Xiujie Song,Qi Jia,Shota Watanabe,Xiaoyi Pang,Ruijie Chen,Mengyue Wu,Kenny Q. Zhu*

Main category: cs.CV

TL;DR: 本文提出Storytelling Image Generation任务，通过两阶段管道StorytellingPainter结合LLMs的推理能力和T2I模型的视觉合成能力，生成具有丰富语义连接的叙事图像，并开发了专门的评估框架。

- Motivation: 叙事图像通过丰富的视觉线索传达逻辑连接的故事，在插图创作、认知筛查等领域有广泛应用，但由于其复杂的语义特性，这类图像难以创建且相对稀缺。因此需要探索如何利用生成式AI模型来创建这类图像。
- Method: 提出两阶段管道StorytellingPainter：1）利用大型语言模型（LLMs）进行创造性推理生成故事；2）使用文本到图像（T2I）模型进行视觉合成。同时开发了包含语义复杂性评估器、KNN多样性评估器和故事-图像对齐评估器的评估框架。针对开源与专有LLMs的性能差距，进一步探索定制训练策略，开发了轻量级有效的Mini-Storytellers模型。
- Result: 实验结果表明该方法的可行性和有效性。提出的StorytellingPainter管道能够生成具有丰富语义连接的叙事图像，评估框架能够全面评估生成图像的质量，而Mini-Storytellers模型在缩小开源与专有LLMs性能差距方面表现良好。
- Conclusion: 本文成功定义了Storytelling Image Generation任务，提出了有效的生成管道和评估框架，为解决叙事图像稀缺问题提供了可行的AI解决方案，并为未来相关研究奠定了基础。


### [142] [Understanding Diffusion Models via Code Execution](https://arxiv.org/abs/2512.07201)
*Cheng Yu*

Main category: cs.CV

TL;DR: 一篇约300行代码的简洁实现，从代码执行角度解释扩散模型，连接理论公式与开源实践

- Motivation: 扩散模型理论复杂，论文中的数学公式与实际开源实现之间存在鸿沟，现有教程主要关注公式推导，对代码如何运行指导有限
- Method: 提供一个约300行的最小化实现，包含前向扩散、反向采样、噪声预测网络和训练循环等核心组件，去除不必要的工程细节
- Result: 创建了一个简洁的代码实现，帮助研究者从实现角度理解扩散模型的实际工作原理，以及代码与理论之间的对应关系
- Conclusion: 该技术报告为研究者提供了清晰、以实现为先的理解方式，展示了扩散模型在实践中如何工作，以及代码与理论如何对应


### [143] [MMRPT: MultiModal Reinforcement Pre-Training via Masked Vision-Dependent Reasoning](https://arxiv.org/abs/2512.07203)
*Xuhui Zheng,Kang An,Ziliang Wang,Yuhang Wang,Faqiang Qian,Yichao Wu*

Main category: cs.CV

TL;DR: MMRPT：首个将强化学习直接融入大规模视觉语言模型预训练的框架，通过掩码多模态数据增强视觉推理能力，而非模仿文本描述。

- Motivation: 当前多模态预训练受限于图像-文本对的描述性偏差，模型倾向于依赖表面语言线索而非真正的视觉理解。需要一种能强化视觉推理的预训练方法。
- Method: 提出掩码多模态强化预训练框架：1）通过视觉token注意力估计句子级视觉依赖性，掩码高度依赖视觉的文本片段；2）模型在语义-视觉奖励引导下通过视觉推理重建这些片段；3）首次将强化学习直接融入大规模视觉语言模型预训练。
- Result: 在多样化基准测试中实现一致的零样本性能提升，监督微调下显著提高鲁棒性，证明强化驱动的掩码推理为多模态模型提供了更可靠、可泛化的预训练目标。
- Conclusion: 强化学习驱动的掩码推理能够有效增强多模态模型的视觉基础能力，提供比传统描述模仿更可靠、可泛化的预训练范式。


### [144] [AutoLugano: A Deep Learning Framework for Fully Automated Lymphoma Segmentation and Lugano Staging on FDG-PET/CT](https://arxiv.org/abs/2512.07206)
*Boyang Pan,Zeyu Zhang,Hongyu Meng,Bin Cui,Yingying Zhang,Wenli Hou,Junhao Li,Langdi Zhong,Xiaoxiao Chen,Xiaoyu Xu,Changjin Zuo,Chao Cheng,Nan-Jie Gong*

Main category: cs.CV

TL;DR: AutoLugano是一个全自动深度学习系统，能够从FDG-PET/CT扫描中实现淋巴瘤的端到端分类，包括病灶分割、解剖定位和Lugano分期，在外部验证中达到88.31%的总体准确率。

- Motivation: 开发一个全自动系统，将基线FDG-PET/CT扫描直接转化为完整的Lugano分期，以辅助淋巴瘤的初始分期、治疗分层和临床决策支持。
- Method: 系统包含三个顺序模块：1）基于3D nnU-Net的解剖感知病灶分割；2）利用TotalSegmentator工具包将分割病灶映射到21个预定义淋巴结区域的解剖定位；3）将受累区域空间分布转化为Lugano分期和治疗分组的自动分期模块。
- Result: 在外部验证集上，区域受累检测的总体准确率为88.31%，敏感性74.47%，特异性94.21%，F1分数80.80%。在治疗分层（局限期vs进展期）任务中，准确率达到85.07%，特异性90.48%，敏感性82.61%。
- Conclusion: AutoLugano是首个将单次基线FDG-PET/CT扫描转化为完整Lugano分期的全自动端到端系统，展示了在辅助初始分期、治疗分层和临床决策方面的强大潜力。


### [145] [Object Pose Distribution Estimation for Determining Revolution and Reflection Uncertainty in Point Clouds](https://arxiv.org/abs/2512.07211)
*Frederik Hagelskjær,Dimitrios Arapis,Steffen Madsen,Thorbjørn Mosekjær Iversen*

Main category: cs.CV

TL;DR: 提出首个仅使用3D无色数据的深度学习物体位姿不确定性估计方法，解决工业场景中颜色信息缺失的问题

- Motivation: 传统单一位姿估计无法捕捉视觉模糊性带来的不确定性，而现有位姿分布方法过度依赖颜色信息，在工业场景中颜色信息往往不可用
- Method: 基于神经网络的方法，仅使用3D无色数据估计物体位姿不确定性，是首个不依赖RGB输入的深度学习位姿分布估计方法
- Result: 在真实世界拣选场景中验证了方法有效性，适用于具有不同几何模糊性的物体，当前实现专注于反射和旋转对称性
- Conclusion: 该方法为工业场景提供了可靠的位姿不确定性估计框架，可扩展到完整的SE(3)位姿分布估计，源代码已公开


### [146] [VFM-VLM: Vision Foundation Model and Vision Language Model based Visual Comparison for 3D Pose Estimation](https://arxiv.org/abs/2512.07215)
*Md Selim Sarowar,Sungho Kim*

Main category: cs.CV

TL;DR: 比较CLIP和DINOv2在3D手物抓取姿态估计中的表现：CLIP在语义理解上更优，DINOv2在几何特征上更强，两者互补。

- Motivation: 视觉基础模型(VFMs)和视觉语言模型(VLMs)为计算机视觉提供了丰富的语义和几何表示，但它们在3D姿态估计任务中的表现差异尚未得到系统比较，特别是在手物抓取场景中。
- Method: 对基于CLIP和DINOv2的方法进行全面的视觉比较，评估它们在6D物体姿态估计任务上的表现，分析各自的优势和互补性。
- Result: CLIP在语义一致性方面表现更好，而DINOv2在密集几何特征方面更优，两者在3D姿态估计中展现出互补优势。
- Conclusion: 为机器人操作和抓取应用选择合适的视觉模型提供了指导：需要语义理解时选择CLIP，需要几何精度时选择DINOv2，两者结合可能获得最佳效果。


### [147] [Towards Robust Protective Perturbation against DeepFake Face Swapping](https://arxiv.org/abs/2512.07228)
*Hengyang Yao,Lin Li,Ke Sun,Jianing Qiu,Huiping Chen*

Main category: cs.CV

TL;DR: 提出EOLT框架，通过强化学习学习变换分布，自动优先关键变换并生成实例特定的扰动，显著提升DeepFake人脸交换防御的鲁棒性。

- Motivation: 当前DeepFake人脸交换防御方法通过在图像中嵌入不可见扰动，但这些扰动在面对压缩、调整大小等基本变换时容易被破坏。研究发现防御鲁棒性对训练变换选择高度敏感，传统的均匀采样变换期望方法存在根本性缺陷。
- Method: 提出EOLT（Expectation Over Learned distribution of Transformation）框架，将变换分布作为可学习组件而非固定设计选择。使用策略网络通过强化学习自动优先关键变换，自适应生成实例特定的扰动，显式建模防御瓶颈同时保持广泛的迁移性。
- Result: 实验表明该方法相比现有最先进方法有显著改进：平均鲁棒性提高26%，在具有挑战性的变换类别上增益高达30%。
- Conclusion: EOLT框架通过将变换分布作为可学习组件，能够更有效地防御DeepFake人脸交换攻击，显著提升防御鲁棒性，为对抗性防御提供了新的方向。


### [148] [ReLKD: Inter-Class Relation Learning with Knowledge Distillation for Generalized Category Discovery](https://arxiv.org/abs/2512.07229)
*Fang Zhou,Zhiqiang Chen,Martin Pavlovski,Yizhong Zhang*

Main category: cs.CV

TL;DR: ReLKD是一个端到端的广义类别发现框架，通过利用隐式类别间关系来增强新类别的分类，特别在标注数据有限时表现优异。

- Motivation: 广义类别发现(GCD)面临在只有已知类别标签的情况下对包含已知和新类别的未标注数据进行分类的挑战。先前研究通常独立处理每个类别，忽略了固有的类别间关系，而直接获取这些关系在现实场景中具有显著挑战。
- Method: ReLKD包含三个关键模块：目标粒度模块用于学习判别性表示，粗粒度模块用于捕捉层次化的类别关系，以及蒸馏模块用于将知识从粗粒度模块转移到目标粒度模块以优化表示学习。
- Result: 在四个数据集上的广泛实验证明了ReLKD的有效性，特别是在标注数据有限的场景下表现优异。
- Conclusion: ReLKD通过有效利用隐式类别间关系并将其知识转移到目标粒度表示学习中，显著提升了广义类别发现的性能，特别是在标注数据有限的情况下。


### [149] [STRinGS: Selective Text Refinement in Gaussian Splatting](https://arxiv.org/abs/2512.07230)
*Abhinav Raundhal,Gaurav Behera,P J Narayanan,Ravi Kiran Sarvadevabhatla,Makarand Tapaswi*

Main category: cs.CV

TL;DR: STRinGS是一个针对3D高斯泼溅（3DGS）的文本感知选择性细化框架，通过分别处理文本和非文本区域来提升文本重建质量，在7K次迭代中比3DGS提升63.6%的文本可读性。

- Motivation: 现实场景中的文本（如标志、标签、说明）包含重要上下文信息，但现有3D表示方法（如3DGS）难以保留细粒度文本细节，文本重建的小错误会导致显著的语义损失。
- Method: 提出STRinGS框架，将文本和非文本区域分开处理：先细化文本区域，然后与非文本区域合并进行全场景优化。还引入了STRinGS-360数据集，包含多样化的文本场景。
- Result: STRinGS能在具有挑战性的配置下产生清晰可读的文本，使用OCR字符错误率（CER）评估，在7K次迭代中比3DGS相对提升63.6%的文本可读性。
- Conclusion: STRinGS方法和数据集共同推动了文本丰富环境中3D场景理解的边界，为更鲁棒的文本感知重建方法铺平了道路。


### [150] [Dropout Prompt Learning: Towards Robust and Adaptive Vision-Language Models](https://arxiv.org/abs/2512.07234)
*Biao Chen,Lin Zuo,Mengmeng Jing,Kunbin He,Yuchen Wang*

Main category: cs.CV

TL;DR: 提出Dropout Prompt Learning方法，通过考虑模态内上下文和模态间对齐的token重要性评估，对视觉语言模型的文本和视觉分支token应用自适应dropout，并结合残差熵正则化来提升模型在低样本学习、长尾分类和分布外泛化等挑战性场景下的鲁棒性。

- Motivation: Dropout作为一种广泛使用的正则化技术，通过随机丢弃神经元来提高模型的泛化能力。本文旨在将dropout思想应用于视觉语言模型，提升其在挑战性场景下的鲁棒性。
- Method: 提出Dropout Prompt Learning方法：1）对文本和视觉分支的token应用dropout，考虑模态内上下文和模态间对齐来评估token重要性，为每个token分配灵活的dropout概率；2）提出残差熵正则化，在保持语义对齐以进行通用知识迁移的同时，鼓励dropout引入的多样化表示。
- Result: 在15个基准测试上验证了方法的有效性，特别是在低样本学习、长尾分类和分布外泛化等挑战性场景中表现优异。在base-to-novel泛化任务上，性能超过正则化方法KgCoOp 5.10%和PromptSRC 2.13%。
- Conclusion: Dropout Prompt Learning通过自适应token dropout和残差熵正则化，有效提升了视觉语言模型在各种挑战性场景下的鲁棒性和泛化能力，在多个基准测试上取得了显著性能提升。


### [151] [Unified Camera Positional Encoding for Controlled Video Generation](https://arxiv.org/abs/2512.07237)
*Cheng Zhang,Boying Li,Meng Wei,Yan-Pei Cao,Camilo Cruz Gambardella,Dinh Phung,Jianfei Cai*

Main category: cs.CV

TL;DR: UCPE提出统一相机位置编码，通过相对光线编码和绝对方向编码实现精确相机控制，在视频生成中达到SOTA效果

- Motivation: 现有相机编码方法通常基于简化的针孔假设，限制了在真实世界相机多样化内参和镜头畸变情况下的泛化能力。需要一种几何一致的表示方法来统一完整的相机信息。
- Method: 提出UCPE（统一相机位置编码），包含相对光线编码（统一6-DoF位姿、内参和镜头畸变）和绝对方向编码（控制初始相机方向）。通过轻量级空间注意力适配器集成到预训练的视频扩散Transformer中，仅增加不到1%的可训练参数。
- Result: 在相机可控文本到视频生成任务中达到最先进的相机控制能力和视觉保真度。构建了包含广泛相机运动和镜头类型的大型视频数据集用于系统训练和评估。
- Conclusion: UCPE验证了作为Transformer通用相机表示的有效性，在相机可控视频生成中表现出色，并有望在未来多视图、视频和3D任务中作为通用相机表示。


### [152] [Squeezed-Eff-Net: Edge-Computed Boost of Tomography Based Brain Tumor Classification leveraging Hybrid Neural Network Architecture](https://arxiv.org/abs/2512.07241)
*Md. Srabon Chowdhury,Syeda Fahmida Tanzim,Sheekar Banerjee,Ishtiak Al Mamoon,AKM Muzahidul Islam*

Main category: cs.CV

TL;DR: 提出基于SqueezeNet v1和EfficientNet-B0的混合深度学习模型，结合手工放射组学特征，用于脑肿瘤MRI分类，达到98.93%准确率。

- Motivation: 脑肿瘤诊断需要及时准确，但MRI肿瘤勾画过程困难、耗时且易受观察者间差异影响。现有方法需要在计算效率和诊断准确性之间取得平衡。
- Method: 结合轻量级SqueezeNet v1和高性能EfficientNet-B0的混合深度学习模型，增强手工放射组学特征（HOG、LBP、Gabor滤波、小波变换）。使用Nickparvar脑肿瘤MRI数据集（7,023张T1加权轴向MRI切片），分为胶质瘤、脑膜瘤、垂体瘤和无肿瘤四类。
- Result: 模型测试准确率达98.93%，使用测试时间增强后达99.08%。模型参数少于210万，计算量小于1.2 GFLOPs，在计算效率和诊断准确性之间取得良好平衡。
- Conclusion: 提出的混合网络在脑肿瘤MRI自动分类中达到接近临床可靠性的水平，具有在临床决策支持系统中应用的潜力。


### [153] [Zero-Shot Textual Explanations via Translating Decision-Critical Features](https://arxiv.org/abs/2512.07245)
*Toshinori Yamauchi,Hiroshi Kera,Kazuhiko Kawamoto*

Main category: cs.CV

TL;DR: TEXTER通过隔离决策关键特征来生成更忠实、可解释的图像分类器文本解释，优于现有零样本方法

- Motivation: 现有零样本解释方法通常将全局图像特征与语言对齐，只能描述可见内容而非驱动预测的关键因素。需要一种能反映分类器特定推理过程的解释方法。
- Method: TEXTER首先识别对预测有贡献的神经元，强调这些神经元编码的决策关键特征，然后将这些强调的特征映射到CLIP特征空间以检索反映模型推理的文本解释。稀疏自编码器进一步提高Transformer架构的可解释性。
- Result: 大量实验表明，TEXTER生成的解释比现有方法更忠实、更可解释。
- Conclusion: 通过隔离决策关键特征再进行对齐，TEXTER能够生成更准确地反映图像分类器推理过程的文本解释，提高了透明度和可解释性。


### [154] [AdLift: Lifting Adversarial Perturbations to Safeguard 3D Gaussian Splatting Assets Against Instruction-Driven Editing](https://arxiv.org/abs/2512.07247)
*Ziming Hong,Tianyu Huang,Runnan Chen,Shanshan Ye,Mingming Gong,Bo Han,Tongliang Liu*

Main category: cs.CV

TL;DR: AdLift：首个针对3D高斯溅射（3DGS）的编辑保护方法，通过将严格有界的2D对抗扰动提升到3D高斯表示中，防止任意视角和维度的指令驱动编辑。

- Motivation: 扩散模型驱动的3DGS编辑技术虽然促进了3D内容创作，但也使3D资产面临未经授权编辑和恶意篡改的风险。现有针对2D图像的对抗扰动保护方法难以直接应用于3DGS，面临视角泛化保护以及保护能力与不可见性平衡两大挑战。
- Method: 提出AdLift方法：1）通过提升严格有界的2D对抗扰动到3D高斯表示的保护机制；2）使用定制的Lifted PGD进行渐进优化，在训练视角间交替进行梯度截断和图像到高斯拟合操作，确保对抗扰动的有效性和不可见性。
- Result: 实验结果表明，AdLift能有效保护3DGS资产免受最先进的指令驱动2D图像和3DGS编辑方法的攻击，在不同视角下提供一致的基于对抗扰动的保护性能，并能泛化到新视角。
- Conclusion: AdLift是首个针对3DGS的编辑保护框架，成功解决了视角泛化保护和不可见性平衡的挑战，为3DGS资产提供了有效的安全保障。


### [155] [See More, Change Less: Anatomy-Aware Diffusion for Contrast Enhancement](https://arxiv.org/abs/2512.07251)
*Junqi Liu,Zejun Wu,Pedro R. A. S. Bassi,Xinze Zhou,Wenxuan Li,Ibrahim E. Hamamci,Sezgin Er,Tianyu Lin,Yi Luo,Szymon Płotka,Bjoern Menze,Daguang Xu,Kai Ding,Kang Wang,Yang Yang,Yucheng Tang,Alan L. Yuille,Zongwei Zhou*

Main category: cs.CV

TL;DR: SMILE是一个解剖感知的扩散模型，用于医学图像增强，它能理解器官形状和对比度动态，只增强临床相关区域而不改变其他区域。

- Motivation: 当前医学图像增强模型存在过度编辑问题，会扭曲器官、产生假阳性、遗漏小肿瘤，因为它们不理解解剖结构和对比度动态。
- Method: 提出SMILE模型，包含三个关键创新：1) 结构感知监督，遵循真实器官边界和对比度模式；2) 无需配准的学习，直接处理未对齐的多期相CT扫描；3) 统一推理，在所有对比度期相提供快速一致的增强。
- Result: 在六个外部数据集上，SMILE在图像质量方面优于现有方法（SSIM提高14.2%，PSNR提高20.6%，FID改善50%），并能生成解剖准确且具有诊断意义的图像。还能提高非对比CT的癌症检测率，F1分数提升达10%。
- Conclusion: SMILE通过解剖感知的扩散模型解决了医学图像增强中的过度编辑问题，在保持解剖准确性的同时提供临床有用的增强效果。


### [156] [DGGAN: Degradation Guided Generative Adversarial Network for Real-time Endoscopic Video Enhancement](https://arxiv.org/abs/2512.07253)
*Handing Xu,Zhenguo Nie,Tairan Peng,Huimin Pan,Xin-Jun Liu*

Main category: cs.CV

TL;DR: 提出一种基于退化感知的实时内窥镜视频增强框架，通过跨帧传播退化表示实现高质量实时增强

- Motivation: 内窥镜手术依赖术中视频，但视频常因光照不均、组织散射、遮挡和运动模糊而质量下降，现有深度学习方法计算量过大难以实时应用
- Method: 使用对比学习提取退化表示，引入融合机制用退化表示调制图像特征指导单帧增强模型，通过退化与恢复图像间的循环一致性约束训练
- Result: 在性能与效率平衡方面优于多种最先进方法，验证了退化感知建模对实时内窥镜视频增强的有效性
- Conclusion: 隐式学习和传播退化表示为临床应用提供了实用途径


### [157] [A graph generation pipeline for critical infrastructures based on heuristics, images and depth data](https://arxiv.org/abs/2512.07269)
*Mike Diessner,Yannick Tarant*

Main category: cs.CV

TL;DR: 提出基於攝影測量的圖生成流程，使用立體相機的RGB影像和深度數據，通過深度學習進行物體檢測和實例分割，結合啟發式規則推斷關係，為關鍵基礎設施創建虛擬表示。

- Motivation: 傳統使用雷射掃描器獲取3D點雲的方法成本高昂且需要專業知識，需要一種更經濟高效的替代方案來創建關鍵基礎設施的虛擬表示。
- Method: 基於攝影測量的圖生成流程，使用立體相機獲取RGB影像和深度數據，通過深度學習進行物體檢測和實例分割，結合用戶定義的啟發式或規則來推斷物體間的關係。
- Result: 在兩個水力系統上的實驗結果顯示，該策略能夠生成接近真實情況的圖，同時方法的靈活性允許針對特定應用進行定制，透明度使其適合用於關鍵基礎設施的高風險決策。
- Conclusion: 提出的基於攝影測量的圖生成流程提供了一種比傳統雷射掃描更經濟高效的替代方案，能夠為關鍵基礎設施創建準確的虛擬表示，具有靈活性和透明度優勢。


### [158] [RVLF: A Reinforcing Vision-Language Framework for Gloss-Free Sign Language Translation](https://arxiv.org/abs/2512.07273)
*Zhi Rao,Yucheng Zhou,Benjia Zhou,Yiqing Huang,Sergio Escalera,Jun Wan*

Main category: cs.CV

TL;DR: 提出RVLF框架解决无注释手语翻译的两个关键问题：通过融合骨骼运动与视觉特征改进手语表示，使用GRPO强化学习优化翻译质量

- Motivation: 无注释手语翻译面临两个主要挑战：1) 现有手语表示方法无法捕捉细微视觉线索；2) 基于LLM的方法存在句子级语义对齐问题，限制了翻译质量
- Method: 提出三阶段强化视觉-语言框架RVLF：1) 构建专门的手语大视觉语言模型，融合骨骼运动线索与DINOv2提取的视觉特征；2) 通过指令微调获得SLT-SFT基线模型；3) 使用GRPO强化学习策略，结合BLEU和ROUGE奖励函数优化模型
- Result: 在CSL-Daily、PHOENIX-2014T、How2Sign和OpenASL数据集上，BLEU-4分数分别提升+5.1、+1.11、+1.4和+1.61，无需外部大规模手语数据集预训练
- Conclusion: RVLF框架有效解决了无注释手语翻译的表示和对齐问题，首次将GRPO应用于手语翻译，显著提升了翻译质量和语义一致性


### [159] [Effective Attention-Guided Multi-Scale Medical Network for Skin Lesion Segmentation](https://arxiv.org/abs/2512.07275)
*Siyu Wang,Hua Wang,Huiyu Li,Fan Zhang*

Main category: cs.CV

TL;DR: 提出一种基于多尺度残差结构的编码器-解码器网络，通过MRCF模块、CMAM模块和EAB桥接机制，显著提升皮肤病变分割的准确性和鲁棒性。

- Motivation: 现有深度学习方法难以有效处理皮肤病变的不规则形状和低对比度问题，传统U-Net的跳跃连接存在信息损失，需要更有效的特征提取和融合机制。
- Method: 1) 基于多尺度残差结构的编码器-解码器网络；2) 多分辨率多通道融合(MRCF)模块捕获跨尺度特征；3) 交叉混合注意力模块(CMAM)重新定义注意力范围并动态计算权重；4) 外部注意力桥(EAB)补偿上采样过程中的信息损失。
- Result: 在多个皮肤病变分割数据集上的实验表明，该模型显著优于现有的transformer和卷积神经网络模型，展现出卓越的分割准确性和鲁棒性。
- Conclusion: 提出的创新网络架构通过多尺度特征提取、跨尺度融合、动态注意力机制和有效的信息补偿，成功解决了皮肤病变分割中的形状不规则和对比度低等挑战，为医疗诊断提供了更精确的工具。


### [160] [Geo3DVQA: Evaluating Vision-Language Models for 3D Geospatial Reasoning from Aerial Imagery](https://arxiv.org/abs/2512.07276)
*Mai Tsujimoto,Junjue Wang,Weihao Xuan,Naoto Yokoya*

Main category: cs.CV

TL;DR: Geo3DVQA是一个用于评估视觉语言模型在仅使用RGB遥感图像进行三维地理空间推理能力的基准测试，包含11万个问题-答案对，涵盖16个任务类别和三个复杂度级别。

- Motivation: 当前三维地理空间分析方法依赖昂贵的专业传感器（如LiDAR和多光谱），限制了全球可访问性。现有方法难以整合多个三维线索、处理多样化查询并提供可解释的推理。
- Method: 创建Geo3DVQA基准测试，包含110k个精心策划的问题-答案对，涵盖16个任务类别和三个复杂度级别：单特征推理、多特征推理和应用级空间分析。使用RGB遥感图像评估视觉语言模型的高度感知三维地理空间推理能力。
- Result: 评估10个最先进的视觉语言模型显示RGB到三维推理的困难性：GPT-4o准确率28.6%，Gemini-2.5-Flash准确率33.0%。领域特定的Qwen2.5-VL-7B微调达到49.6%准确率（提升24.8个百分点）。
- Conclusion: Geo3DVQA揭示了当前视觉语言模型的局限性以及领域适应的有效性，为可扩展、可访问和全面的三维地理空间分析引入了新的挑战前沿。


### [161] [Towards Accurate UAV Image Perception: Guiding Vision-Language Models with Stronger Task Prompts](https://arxiv.org/abs/2512.07302)
*Mingning Guo,Mengwei Wu,Shaoxian Li,Haifeng Li,Chao Tao*

Main category: cs.CV

TL;DR: AerialVP是一个用于无人机图像感知的任务提示增强代理框架，通过主动提取多维辅助信息来增强任务提示，解决了传统VLM方法在复杂无人机图像中的局限性。

- Motivation: 现有基于VLM的图像感知方法在处理无人机图像时面临目标混淆、尺度变化和复杂背景等挑战，因为VLM对图像内容的理解依赖于视觉和文本标记的语义对齐。当任务提示简单而图像内容复杂时，难以实现有效对齐，限制了模型关注任务相关信息的能力。
- Method: 提出AerialVP框架，通过三个阶段增强任务提示：(1)分析任务提示以确定任务类型和增强需求，(2)从工具库中选择适当工具，(3)基于分析和选定工具生成增强的任务提示。同时构建AerialSense基准，包含无人机视觉推理、视觉问答和视觉定位任务。
- Result: 实验结果表明，AerialVP显著增强了任务提示的指导能力，在开源和专有VLM中都带来了稳定且显著的性能提升。
- Conclusion: AerialVP通过主动提取无人机图像的多维辅助信息来增强任务提示，有效克服了传统VLM方法在复杂无人机图像感知中的局限性，为无人机图像理解提供了新的解决方案。


### [162] [Reevaluating Automated Wildlife Species Detection: A Reproducibility Study on a Custom Image Dataset](https://arxiv.org/abs/2512.07305)
*Tobias Abraham Haider*

Main category: cs.CV

TL;DR: 重新评估预训练CNN模型在野生动物物种识别中的表现，使用不同数据集复现实验，获得62%准确率，确认预训练模型可作为实用基线但需要物种特定适应

- Motivation: 评估Carl等人研究的可重复性和泛化性，他们使用预训练的Google Inception-ResNet-v2模型进行欧洲野生哺乳动物物种自动检测。本研究旨在验证该方法的稳健性
- Method: 从零开始重新实现实验，使用公开可用资源和不同数据集（900张图像，90个物种），进行最小预处理，评估分类准确率和宏F1分数
- Result: 总体分类准确率为62%，与原始研究的71%相近；宏F1分数为0.28，显示各类别性能差异显著；确认预训练CNN在物种识别中的实用性但泛化能力有限
- Conclusion: 预训练卷积神经网络可为野生动物物种识别提供实用基线，但需要物种特定适应或迁移学习才能获得一致的高质量预测结果


### [163] [ContextAnyone: Context-Aware Diffusion for Character-Consistent Text-to-Video Generation](https://arxiv.org/abs/2512.07328)
*Ziyang Mai,Yu-Wing Tai*

Main category: cs.CV

TL;DR: ContextAnyone是一个上下文感知的扩散框架，通过单张参考图像实现角色一致性的文本到视频生成，解决了现有方法在保持发型、服装、体型等上下文特征方面的不足。

- Motivation: 现有的文本到视频生成方法在角色个性化方面主要关注面部身份，但忽略了发型、服装、体型等更广泛的上下文线索，这些对于视觉连贯性至关重要。现有方法难以保持跨场景的角色一致性。
- Method: 提出了ContextAnyone框架，基于DiT扩散模型，包含：1) Emphasize-Attention模块，选择性增强参考感知特征并防止身份漂移；2) 双引导损失结合扩散和参考重建目标；3) Gap-RoPE位置嵌入分离参考和视频token以稳定时序建模。
- Result: 实验表明ContextAnyone在身份一致性和视觉质量方面优于现有的参考到视频方法，能够生成跨不同动作和场景的连贯且保持上下文的角色视频。
- Conclusion: ContextAnyone通过上下文感知的扩散框架有效解决了角色一致性视频生成的挑战，在保持广泛上下文特征的同时实现了高质量的视频生成。


### [164] [The Inductive Bottleneck: Data-Driven Emergence of Representational Sparsity in Vision Transformers](https://arxiv.org/abs/2512.07331)
*Kanishk Awadhiya*

Main category: cs.CV

TL;DR: ViTs自发展现U形熵分布，研究发现这种"归纳瓶颈"是数据驱动的适应性机制，而非架构缺陷，其深度与任务语义抽象需求相关。

- Motivation: 尽管ViTs理论上能在所有层保持高维表示，但实际观察到U形熵分布（中间层信息压缩）。研究旨在探究这种"归纳瓶颈"是架构固有缺陷还是数据驱动的适应性机制。
- Method: 通过分析DINO训练的ViTs在不同数据集（UC Merced、Tiny ImageNet、CIFAR-100）上的层间有效编码维度（EED），研究瓶颈深度与语义抽象需求的关系。
- Result: 纹理丰富的数据集在整个网络中保持高秩表示，而面向对象的数据集驱动网络在中间层抑制高频信息，有效"学习"瓶颈以隔离语义特征。
- Conclusion: ViTs的归纳瓶颈是数据依赖的适应性机制，其深度与任务所需的语义抽象程度相关，表明网络能够根据数据特性调整表示策略。


### [165] [Generalized Referring Expression Segmentation on Aerial Photos](https://arxiv.org/abs/2512.07338)
*Luís Marnoto,Alexandre Bernardino,Bruno Martins*

Main category: cs.CV

TL;DR: Aerial-D：一个用于航空影像的大规模指代表达分割数据集，包含37,288张图像和152万条指代表达，涵盖259,709个标注目标，通过自动流水线构建，支持现代和历史航空影像的统一实例和语义分割。

- Motivation: 航空影像（无人机照片、历史航拍档案、高分辨率卫星图像等）在指代表达分割任务中面临独特挑战：空间分辨率差异大、色彩使用不一致、目标可能只有几个像素、场景物体密度高且有部分遮挡。现有数据集难以满足这些需求。
- Method: 1. 构建Aerial-D数据集：37,288张图像，1,522,523条指代表达，259,709个标注目标，涵盖21个类别；2. 采用全自动流水线：结合基于规则的表达生成和LLM增强程序，丰富语言多样性和视觉细节关注；3. 使用过滤器模拟历史成像条件；4. 采用RSRefSeg架构，在Aerial-D和先前航空数据集上联合训练。
- Result: 联合训练在当代基准测试中取得竞争性性能，同时在单色、棕褐色和颗粒状退化的历史航空摄影条件下保持强准确性。数据集、训练模型和完整软件流水线已公开。
- Conclusion: Aerial-D数据集填补了航空影像指代表达分割的空白，通过自动流水线构建的大规模数据集支持现代和历史影像的统一分割，为计算机视觉与自然语言理解的结合在航空领域提供了重要资源。


### [166] [Debiasing Diffusion Priors via 3D Attention for Consistent Gaussian Splatting](https://arxiv.org/abs/2512.07345)
*Shilong Jin,Haoran Duan,Litao Hua,Wentao Huang,Yuan Zhou*

Main category: cs.CV

TL;DR: TD-Attn是一个解决T2I扩散模型中先验视角偏差问题的框架，通过3D感知注意力引导和分层注意力调制来提升3D任务的多视角一致性。

- Motivation: 从文本到图像扩散模型蒸馏的3D任务（如生成或编辑）无需大量3D训练数据，但T2I模型存在先验视角偏差问题，导致物体不同视角间外观冲突。这种偏差使主题词在交叉注意力计算中优先激活先验视角特征，而忽略目标视角条件。
- Method: 提出TD-Attn框架，包含两个关键组件：1) 3D感知注意力引导模块(3D-AAG)：构建视角一致的3D注意力高斯分布，强制注意力聚焦区域的空间一致性；2) 分层注意力调制模块(HAM)：使用语义引导树指导语义响应分析器定位和调制对视角条件高度敏感的CA层，增强的CA图进一步支持构建更一致的3D注意力高斯。
- Result: 大量实验证实TD-Attn有潜力作为通用插件，显著提升3D任务中的多视角一致性。
- Conclusion: TD-Attn通过数学分析揭示了T2I模型中先验视角偏差的根本原因，并提出了一种有效的解决方案，能够作为通用插件增强3D任务的多视角一致性，同时支持可控和精确的3D编辑。


### [167] [MICo-150K: A Comprehensive Dataset Advancing Multi-Image Composition](https://arxiv.org/abs/2512.07348)
*Xinyu Wei,Kangrui Cen,Hongyang Wei,Zhen Guo,Bairui Li,Zeqing Wang,Jinrui Zhang,Lei Zhang*

Main category: cs.CV

TL;DR: 该论文提出了MICo-150K数据集、MICo-Bench基准和Qwen-MICo基线模型，用于解决多图像合成任务中的数据缺乏和评估困难问题。

- Motivation: 多图像合成任务缺乏高质量训练数据和系统评估基准，限制了该领域的发展。
- Method: 1) 将MICo分类为7个代表性任务；2) 构建MICo-150K数据集（包含合成图像和De&Re子集）；3) 创建MICo-Bench评估基准；4) 提出Weighted-Ref-VIEScore评估指标；5) 基于Qwen-Image-Edit微调得到Qwen-MICo基线模型。
- Result: MICo-150K有效提升了模型的MICo能力，Qwen-MICo在3图像合成任务上达到Qwen-Image-2509水平，且支持任意多图像输入。
- Conclusion: 该研究为多图像合成领域提供了全面的数据集、评估基准和基线模型，推动了该领域的发展。


### [168] [DeepAgent: A Dual Stream Multi Agent Fusion for Robust Multimodal Deepfake Detection](https://arxiv.org/abs/2512.07351)
*Sayeem Been Zaman,Wasimul Karim,Arefin Ittesafun Abian,Reem E. Mohamed,Md Rafiqul Islam,Asif Karim,Sami Azam*

Main category: cs.CV

TL;DR: DeepAgent：基于多智能体协作的深度伪造检测框架，通过视觉和音频模态的互补分析提升检测准确性和鲁棒性。

- Motivation: 当前深度伪造检测方法大多将音频和视觉信息集成在单一模型中，容易受到模态不匹配、噪声和篡改的影响。需要一种更鲁棒的框架来同时利用两种模态的优势。
- Method: 提出DeepAgent多智能体协作框架：Agent-1使用AlexNet-based CNN检测视觉篡改痕迹；Agent-2结合声学特征、Whisper音频转录和EasyOCR帧读取来检测音视频不一致性；通过随机森林元分类器融合两个智能体的决策。
- Result: 在Celeb-DF和FakeAVCeleb数据集上，Agent-1达到94.35%准确率；在FakeAVCeleb上，Agent-2和元分类器分别达到93.69%和81.56%；跨数据集验证中，在DeepFakeTIMIT上元分类器达到97.49%准确率。
- Conclusion: 基于层次融合的多智能体方法能够减轻单模态的弱点，增强鲁棒性，有效应对不同类型的深度伪造篡改。


### [169] [Structure-Aware Feature Rectification with Region Adjacency Graphs for Training-Free Open-Vocabulary Semantic Segmentation](https://arxiv.org/abs/2512.07360)
*Qiming Huang,Hao Ai,Jianbo Jiao*

Main category: cs.CV

TL;DR: 提出一种结构感知的特征校正方法，通过构建区域邻接图来捕捉局部结构关系，从而优化CLIP特征，改善开放词汇语义分割中的噪声和不一致问题。

- Motivation: CLIP模型在图像-文本对预训练中侧重于全局语义对齐，导致在细粒度视觉区域与文本关联时性能不佳，产生噪声和不一致的预测。这源于对比训练范式带来的分散偏差，仅使用CLIP特征难以缓解。
- Method: 提出结构感知特征校正方法：1）基于低级特征（颜色、纹理）构建区域邻接图（RAG）来捕捉局部结构关系；2）利用该图来细化CLIP特征，增强局部判别能力；3）将实例特定先验直接融入图像特征校正。
- Result: 实验表明该方法能有效抑制分割噪声，提高区域级一致性，在多个开放词汇分割基准测试中取得强劲性能。
- Conclusion: 通过结合低级结构信息来校正CLIP特征，可以显著改善开放词汇语义分割的局部区域关联问题，为基于视觉语言模型的分割任务提供了一种有效的特征优化方案。


### [170] [Enhancing Small Object Detection with YOLO: A Novel Framework for Improved Accuracy and Efficiency](https://arxiv.org/abs/2512.07379)
*Mahila Moghadami,Mohammad Ali Keyvanrad,Melika Sabaghian*

Main category: cs.CV

TL;DR: 本文提出了一种改进的SW-YOLO方法，用于大尺度航拍图像中的小目标检测，通过优化滑动窗口裁剪策略和网络架构改进，在VisDrone2019数据集上取得了显著精度提升。

- Motivation: 随着航拍图像在关键工业和实际应用中的重要性日益增长，需要开发鲁棒的小目标检测框架。现有方法通常采用图像裁剪和网络架构修改，但仍有改进空间。
- Method: 基于SW-YOLO方法，优化滑动窗口的裁剪尺寸和重叠策略，并在网络架构中引入改进：在颈部加入高级特征提取模块增强特征图，在骨干网络集成CBAM注意力机制以保留空间和通道信息，设计新的检测头提升小目标检测精度。
- Result: 在VisDrone2019数据集上，将mAP .5:.5精度从YOLOv5L的35.5提升至61.2，显著优于SAHI和CZDet（58.36）等现有方法。
- Conclusion: 通过优化裁剪策略和网络架构改进，提出的方法在大尺度航拍图像小目标检测任务中取得了显著性能提升，验证了所提改进的有效性。


### [171] [Tessellation GS: Neural Mesh Gaussians for Robust Monocular Reconstruction of Dynamic Objects](https://arxiv.org/abs/2512.07381)
*Shuohan Tao,Boyao Zhou,Hanzhang Tu,Yuwang Wang,Yebin Liu*

Main category: cs.CV

TL;DR: 提出Tessellation GS方法，通过将2D高斯约束在网格面上，结合自适应面细分策略和重建基础模型先验，实现单摄像头动态场景重建，显著提升稀疏视角下的泛化能力。

- Motivation: 传统3D高斯泼溅在视角外推时因各向异性导致过拟合和泛化能力差，尤其在稀疏视角和动态场景重建中表现不佳。需要一种能处理动态场景且仅需单摄像头输入的方法。
- Method: 提出Tessellation GS：1) 将2D高斯约束在网格面上，通过层次化神经特征推断属性；2) 采用自适应面细分策略，由细节感知损失函数驱动；3) 利用重建基础模型先验初始化高斯变形，支持单静态摄像头重建。
- Result: 在表观和网格重建任务上超越先前SOTA方法，LPIPS降低29.1%，Chamfer距离减少49.2%，能处理传统优化方法难以实现的单静态摄像头动态物体重建。
- Conclusion: Tessellation GS通过结构化约束和自适应细分策略，有效解决了3D高斯泼溅在动态场景重建中的泛化问题，为单摄像头动态场景重建提供了高效解决方案。


### [172] [LogicCBMs: Logic-Enhanced Concept-Based Learning](https://arxiv.org/abs/2512.07383)
*Deepika SN Vemuri,Gautham Bellamkonda,Aditya Pola,Vineeth N Balasubramanian*

Main category: cs.CV

TL;DR: LogicCBM：通过可微分逻辑运算增强概念瓶颈模型，超越线性组合，提升表达能力、准确性和可解释性

- Motivation: 传统概念瓶颈模型（CBMs）通过线性组合语义概念进行预测，但线性组合表达能力有限，无法捕捉概念间的复杂关系
- Method: 提出LogicCBM，在CBM基础上引入可微分逻辑模块，使用逻辑运算符（如AND、OR、NOT）连接学习到的概念，保持端到端可学习性
- Result: 在知名基准测试和合成数据集上的实验表明，LogicCBM具有更好的准确性、有效的干预能力和高度可解释性
- Conclusion: 通过命题逻辑增强概念学习模型，能够超越简单的加权概念组合，利用各种逻辑运算进行最终预测，同时捕捉概念间关系并提高模型表达能力


### [173] [How Far are Modern Trackers from UAV-Anti-UAV? A Million-Scale Benchmark and New Baseline](https://arxiv.org/abs/2512.07385)
*Chunhui Zhang,Li Liu,Zhipeng Zhang,Yong Wang,Hao Wen,Xi Zhou,Shiming Ge,Yanfeng Wang*

Main category: cs.CV

TL;DR: 提出新的无人机反无人机多模态视觉跟踪任务UAV-Anti-UAV，构建百万级数据集，并提出基于Mamba的MambaSTS基线方法

- Motivation: 当前反无人机研究主要关注固定地面摄像头捕获的RGB、红外或RGB-IR视频，缺乏从移动无人机平台跟踪目标无人机的研究，存在研究空白
- Method: 提出MambaSTS方法，使用Mamba和Transformer分别学习全局语义和空间特征，利用状态空间模型的长序列建模能力，通过时间令牌传播机制建立视频级长期上下文
- Result: 构建了包含1,810个视频的百万级数据集，每个视频都有人工标注的边界框、语言提示和15个跟踪属性；实验验证了方法的有效性，并对50种现代深度跟踪算法进行了评估
- Conclusion: UAV-Anti-UAV任务比现有反无人机任务更具挑战性，当前算法仍有很大改进空间；提出的数据集和方法为该领域研究提供了基础


### [174] [GlimmerNet: A Lightweight Grouped Dilated Depthwise Convolutions for UAV-Based Emergency Monitoring](https://arxiv.org/abs/2512.07391)
*Đorđe Nedeljković*

Main category: cs.CV

TL;DR: GlimmerNet：一种超轻量级卷积网络，通过分组扩张深度卷积和聚合器模块，在不增加参数成本的情况下实现多尺度特征提取，在无人机紧急监测任务上达到新的精度-效率平衡前沿。

- Motivation: 虽然视觉Transformer通过自注意力机制增强了全局上下文理解，但通常带来显著的计算开销。本研究旨在保留强大全局感知能力的同时，避免依赖计算昂贵的组件，为资源受限的无人机平台提供实时紧急监测解决方案。
- Method: 提出GlimmerNet网络，基于"将感受野多样性与特征重组分离"的原则。核心包括：1）分组扩张深度卷积块（GDBlocks），将通道分组并分配不同扩张率，实现无额外参数成本的多尺度特征提取；2）聚合器模块，使用分组逐点卷积高效重组跨组表示，显著降低参数开销。
- Result: 仅用31K参数，比最新基线减少29% FLOPs，在无人机聚焦的AIDERv2数据集上达到0.966的加权F1分数，创下新的最先进性能，为实时紧急监测建立了新的精度-效率平衡前沿。
- Conclusion: GlimmerNet证明了在不依赖计算昂贵组件的情况下保留强大全局感知能力的可行性，为资源受限的无人机平台提供了高效的实时紧急监测解决方案，在精度和效率之间达到了新的平衡点。


### [175] [Reconstructing Objects along Hand Interaction Timelines in Egocentric Video](https://arxiv.org/abs/2512.07394)
*Zhifan Zhu,Siddhant Bansal,Shashank Tripathi,Dima Damen*

Main category: cs.CV

TL;DR: 提出ROHIT任务，通过手交互时间线(HIT)建模物体姿态约束，利用约束优化传播(COP)框架提升物体重建质量，在无3D真值情况下评估重建效果。

- Motivation: 现有方法在视频中重建手持物体时面临挑战，特别是在手与物体交互的动态过程中。需要一种能够建模手交互过程中物体姿态变化的方法，以提升重建质量。
- Method: 定义手交互时间线(HIT)，将物体状态分为：静态、接触、稳定抓握、释放、再静态。提出约束优化传播(COP)框架，沿HIT传播物体姿态约束，利用稳定抓握阶段的恒定接触特性进行优化。
- Result: 在两个第一人称数据集上评估：HOT3D（1.2K稳定抓握片段）和EPIC-Kitchens（2.4K片段，390个物体实例）。COP将稳定抓握重建提升6.2-11.3%，HIT重建提升达24.5%。
- Conclusion: ROHIT任务和COP框架能够有效建模手交互过程中的物体姿态变化，在无3D真值情况下通过2D投影误差评估，显著提升物体重建质量，为日常交互场景的物体重建提供新方法。


### [176] [InterAgent: Physics-based Multi-agent Command Execution via Diffusion on Interaction Graphs](https://arxiv.org/abs/2512.07410)
*Bin Li,Ruichi Zhang,Han Liang,Jingyan Zhang,Juze Zhang,Xin Chen,Lan Xu,Jingyi Yu,Jingya Wang*

Main category: cs.CV

TL;DR: InterAgent：首个端到端的文本驱动物理多智能体人形控制框架，通过自回归扩散变换器和交互图外感受表示实现多智能体协调

- Motivation: 现有方法主要局限于单智能体场景，忽略了多智能体交互中必要的物理合理相互作用，需要开发能够模拟人类社交行为复杂协调的多智能体控制框架
- Method: 1. 提出自回归扩散变换器，配备多流块，解耦本体感受、外感受和动作以减少跨模态干扰；2. 引入交互图外感受表示，显式捕捉细粒度关节间空间依赖；3. 设计稀疏边基注意力机制，动态修剪冗余连接并强调关键智能体间空间关系
- Result: 在广泛实验中，InterAgent始终优于多个强基线，达到最先进性能，能够仅从文本提示生成连贯、物理合理且语义忠实的多智能体行为
- Conclusion: InterAgent是首个端到端的文本驱动物理多智能体人形控制框架，通过创新的架构设计实现了多智能体协调，为未来研究提供了重要基础


### [177] [Data-driven Exploration of Mobility Interaction Patterns](https://arxiv.org/abs/2512.07415)
*Gabriele Galatolo,Mirco Nanni*

Main category: cs.CV

TL;DR: 提出基于数据挖掘的方法，从实际数据中发现个体间的移动交互模式，而非依赖预设行为模型

- Motivation: 现有的人类动态建模方法通常基于预设的行为模型，无法充分捕捉个体间的相互影响，这在人群模拟和应急管理等应用中至关重要
- Method: 采用数据挖掘视角，直接从数据中搜索可能反映个体间相互作用的移动事件，并在此基础上寻找复杂、持久的事件模式和随时间演化的配置
- Result: 在两个真实案例研究（汽车和行人）上实例化该方法，进行了全面的实验评估，包括性能、参数敏感性和样本结果解释
- Conclusion: 通过研究这些模式可以获得关于个体间移动交互机制的新见解，有助于改进现有的模拟模型


### [178] [When normalization hallucinates: unseen risks in AI-powered whole slide image processing](https://arxiv.org/abs/2512.07426)
*Karel Moens,Matthew B. Blaschko,Tinne Tuytelaars,Bart Diricx,Jonas De Vylder,Mustafa Yousif*

Main category: cs.CV

TL;DR: WSI归一化方法存在幻觉风险，传统评估方法难以检测，作者提出新指标评估真实临床数据上的幻觉问题

- Motivation: 当前基于深度学习的WSI归一化方法倾向于输出平均化结果，可能掩盖诊断特征，更重要的是会产生视觉难以检测的幻觉内容，对下游分析构成严重威胁，而现有评估方法往往忽视这一问题
- Method: 提出一种新颖的图像比较度量方法，专门用于自动检测归一化输出中的幻觉内容，并使用该度量系统评估在真实临床数据上重新训练的几个知名归一化方法
- Result: 在真实临床数据上重新训练的模型显示出令人担忧的幻觉频率，传统指标未能捕捉到显著的差异和失败，揭示了现有归一化方法在临床部署中的严重问题
- Conclusion: 幻觉风险真实存在且被低估，需要开发更鲁棒、可解释的归一化技术，并在临床部署中建立更严格的验证协议


### [179] [Unified Video Editing with Temporal Reasoner](https://arxiv.org/abs/2512.07469)
*Xiangpeng Yang,Ji Xie,Yiyuan Yang,Yan Huang,Min Xu,Qiang Wu*

Main category: cs.CV

TL;DR: VideoCoF提出了一种链式帧推理方法，通过预测编辑区域潜在表示作为中间推理步骤，实现无需掩码的精确视频编辑，仅需5万视频对训练即可达到SOTA性能。

- Motivation: 现有视频编辑方法存在关键权衡：专家模型依赖任务特定的掩码先验，难以统一；而统一的时序上下文学习模型虽无需掩码，但缺乏显式空间线索，导致指令到区域映射不精确和定位能力弱。
- Method: 提出VideoCoF（链式帧方法），受思维链推理启发，强制视频扩散模型遵循"观察、推理、编辑"流程：先预测推理标记（编辑区域潜在表示），再生成目标视频标记。引入RoPE对齐策略，利用推理标记确保运动对齐并支持超出训练时长的长度外推。
- Result: 仅需5万视频对的最小数据成本，在VideoCoF-Bench上达到最先进性能，验证了方法的效率和有效性。
- Conclusion: VideoCoF通过显式推理步骤解决了视频编辑中精度与通用性的冲突，无需用户提供掩码即可实现精确的指令到区域对齐和细粒度视频编辑，同时支持运动对齐和长度外推。


### [180] [Single-step Diffusion-based Video Coding with Semantic-Temporal Guidance](https://arxiv.org/abs/2512.07480)
*Naifu Xue,Zhaoyang Jia,Jiahao Li,Bin Li,Zihan Zheng,Yuan Zhang,Yan Lu*

Main category: cs.CV

TL;DR: S2VC是一种基于单步扩散的视频编码器，通过条件编码框架和高效单步扩散生成器，在低码率下实现高质量重建，同时显著降低采样复杂度。

- Motivation: 传统和神经视频编码器在码率-失真性能上表现优异，但在低码率下提升感知质量仍具挑战。现有方法要么受限于生成能力产生伪影，要么依赖预训练扩散模型但采样复杂度高。
- Method: 提出S2VC：1) 结合条件编码框架与高效单步扩散生成器；2) 引入上下文语义指导，从缓冲特征中提取帧自适应语义，替代文本描述；3) 在扩散U-Net中加入时间一致性指导，确保帧间时序连贯性。
- Result: S2VC实现了最先进的感知质量，相比先前感知方法平均节省52.73%的码率，证明了单步扩散在高效高质量视频压缩中的潜力。
- Conclusion: 单步扩散模型能够有效平衡视频压缩中的感知质量与计算效率，为低码率高质量视频编码提供了有前景的解决方案。


### [181] [Towards Robust DeepFake Detection under Unstable Face Sequences: Adaptive Sparse Graph Embedding with Order-Free Representation and Explicit Laplacian Spectral Prior](https://arxiv.org/abs/2512.07498)
*Chih-Chung Hsu,Shao-Ning Chen,Chia-Ming Lee,Yi-Fang Wang,Yi-Shiuan Chou*

Main category: cs.CV

TL;DR: 提出LR-GCN方法，通过构建无序时间图嵌入和拉普拉斯谱先验，在噪声或无序人脸序列中鲁棒检测DeepFake，仅需干净数据训练

- Motivation: 现有DeepFake检测器假设人脸序列时序一致且干净，但实际场景中压缩伪影、遮挡和对抗攻击会破坏人脸检测，导致无效或误检人脸，需要鲁棒检测方法
- Method: 提出拉普拉斯正则化图卷积网络(LR-GCN)：1)构建无序时间图嵌入(OF-TGE)，基于语义相似性将CNN特征组织成自适应稀疏图；2)双重稀疏机制抑制无效人脸影响；3)引入图拉普拉斯谱先验作为高通算子，突出伪造伪影，再通过低通GCN聚合，实现任务驱动的谱带通机制
- Result: 在FF++、Celeb-DFv2和DFDC数据集上达到SOTA性能，在严重全局和局部干扰（包括缺失人脸、遮挡和对抗性扰动）下显著提升鲁棒性
- Conclusion: LR-GCN方法能够从噪声或无序人脸序列中鲁棒检测DeepFake，仅需干净数据训练，通过图结构和谱域处理有效应对实际场景中的各种干扰


### [182] [MultiMotion: Multi Subject Video Motion Transfer via Video Diffusion Transformer](https://arxiv.org/abs/2512.07500)
*Penghui Liu,Jiangshan Wang,Yutong Shen,Shanhui Mo,Chenyang Qi,Yue Ma*

Main category: cs.CV

TL;DR: MultiMotion：基于DiT的多物体视频运动迁移框架，通过Mask-aware Attention Motion Flow实现多物体运动解耦与控制，使用RectPC高效采样器，并构建首个多物体运动迁移基准数据集

- Motivation: 现有Diffusion Transformer（DiT）架构在多物体视频运动迁移中存在运动纠缠和缺乏物体级控制的问题，难以实现精确的多物体独立运动控制
- Method: 提出Mask-aware Attention Motion Flow（AMF），利用SAM2掩码在DiT流程中显式解耦和控制多个物体的运动特征；引入RectPC高阶预测器-校正器求解器用于高效采样；构建首个DiT基多物体运动迁移基准数据集
- Result: MultiMotion实现了精确、语义对齐且时序一致的多物体运动迁移，保持了DiT的高质量和可扩展性，在构建的基准数据集上表现优异
- Conclusion: MultiMotion是首个统一的多物体视频运动迁移框架，通过AMF和RectPC解决了DiT中的运动纠缠问题，为多物体运动控制提供了有效解决方案


### [183] [SJD++: Improved Speculative Jacobi Decoding for Training-free Acceleration of Discrete Auto-regressive Text-to-Image Generation](https://arxiv.org/abs/2512.07503)
*Yao Teng,Zhihuan Jiang,Han Shi,Xian Liu,Xuefei Ning,Guohao Dai,Yu Wang,Zhenguo Li,Xihui Liu*

Main category: cs.CV

TL;DR: SJD++是一种无需训练的概率并行解码算法，通过多令牌预测和草稿验证机制，将自回归文本到图像生成的推理速度提升2-3倍

- Motivation: 大型自回归模型能生成高质量高分辨率图像，但推理速度慢，因为需要数百到数千次顺序前向传递进行下一个令牌预测
- Method: 提出Speculative Jacobi Decoding++ (SJD++)，结合Jacobi解码的迭代多令牌预测机制和推测采样的概率草稿验证机制，并在验证后重用高置信度草稿令牌
- Result: 在多个代表性自回归文本到图像生成模型上，SJD++实现了2-3倍的推理延迟减少和2-7倍的步骤压缩，同时保持视觉质量无显著下降
- Conclusion: SJD++是一种有效的训练免费加速方法，显著提升自回归图像生成效率，为实际应用提供可行解决方案


### [184] [ControlVP: Interactive Geometric Refinement of AI-Generated Images with Consistent Vanishing Points](https://arxiv.org/abs/2512.07504)
*Ryota Okumura,Kaede Shiohara,Toshihiko Yamasaki*

Main category: cs.CV

TL;DR: ControlVP：用户引导的框架，用于纠正生成图像中的消失点不一致问题，提升几何一致性

- Motivation: 当前文本到图像模型（如Stable Diffusion）虽然视觉质量优秀，但经常出现几何不一致问题，特别是消失点不一致，导致场景结构不真实，尤其在建筑场景中影响空间真实感
- Method: 扩展预训练扩散模型，结合建筑轮廓的结构引导，引入几何约束明确鼓励图像边缘与透视线索对齐
- Result: 方法增强了全局几何一致性，同时保持了与基线相当的视觉保真度，特别适用于需要准确空间结构的应用（如图像到3D重建）
- Conclusion: ControlVP有效解决了生成图像中的消失点不一致问题，提升了结构真实感，为需要精确几何结构的应用提供了有价值的工具


### [185] [MeshRipple: Structured Autoregressive Generation of Artist-Meshes](https://arxiv.org/abs/2512.07514)
*Junkai Lin,Hang Long,Huipeng Guo,Jielei Zhang,JiaYi Yang,Tianle Guo,Yang Yang,Jianwen Li,Wenxiao Zhang,Matthias Nießner,Wei Yang*

Main category: cs.CV

TL;DR: MeshRipple：一种新的自回归网格生成方法，通过前沿感知的BFS标记化和扩展预测策略解决传统滑动窗口方法破坏长程几何依赖的问题，生成具有高表面保真度和拓扑完整性的网格。

- Motivation: 传统自回归网格生成器将面序列化并使用滑动窗口推理来应对内存限制，但这种不匹配破坏了长程几何依赖关系，导致产生孔洞和碎片化组件。需要解决这一关键限制。
- Method: MeshRipple采用三种关键创新：1)前沿感知的BFS标记化，将生成顺序与表面拓扑对齐；2)扩展预测策略，保持连贯、连接的表面增长；3)稀疏注意力全局内存，提供有效无界的感受野来解决长程拓扑依赖。
- Result: MeshRipple能够生成具有高表面保真度和拓扑完整性的网格，在性能上超越了近期强大的基线方法。
- Conclusion: MeshRipple通过集成设计解决了自回归网格生成中的长程依赖问题，实现了连贯、完整的表面生成，为3D资产表示提供了改进的解决方案。


### [186] [From Orbit to Ground: Generative City Photogrammetry from Extreme Off-Nadir Satellite Images](https://arxiv.org/abs/2512.07527)
*Fei Yu,Yu Liu,Luyang Tang,Mingchao Sun,Zengye Ge,Rui Bu,Yuchao Jin,Haisen Zhao,He Sun,Yangyan Li,Mu Xu,Wenzheng Chen,Baoquan Chen*

Main category: cs.CV

TL;DR: 提出一种从稀疏卫星图像进行城市尺度3D重建的方法，通过2.5D高度图建模城市几何和生成式纹理恢复网络增强外观，实现从卫星视角到地面视角的极端视点外推。

- Motivation: 从卫星图像进行城市尺度3D重建面临极端视点外推的挑战，需要从稀疏的轨道图像合成地面视角，现有方法如NeRF和3DGS在处理严重透视缩短和纹理缺陷的卫星图像时会失败。
- Method: 1. 使用2.5D高度图建模城市几何，实现为Z单调有符号距离场(SDF)，匹配自上而下的城市建筑布局；2. 通过可微分渲染技术从卫星图像绘制网格外观；3. 训练生成式纹理恢复网络增强外观，从退化输入中恢复高频纹理细节。
- Result: 在4km²真实世界区域仅使用少量卫星图像成功重建，在合成逼真地面视图方面达到最先进性能，生成视觉吸引人且可用于下游任务的高保真资产。
- Conclusion: 提出的方法通过针对城市结构和卫星输入的设计选择，解决了从卫星图像进行城市尺度3D重建的极端视点外推问题，为城市规划、仿真等下游任务提供了可扩展且鲁棒的解决方案。


### [187] [Toward More Reliable Artificial Intelligence: Reducing Hallucinations in Vision-Language Models](https://arxiv.org/abs/2512.07564)
*Kassoum Sanogo,Renzo Ardiccioni*

Main category: cs.CV

TL;DR: 提出无需训练的自校正框架，通过不确定性引导的视觉重注意机制减少视觉语言模型的幻觉，在POPE和MMHAL BENCH基准上显著降低幻觉率

- Motivation: 视觉语言模型经常生成看似合理但错误的幻觉内容，需要一种无需额外训练的方法来纠正这些错误
- Method: 基于不确定性量化的自校正框架：结合多维不确定性评估（词元熵、注意力分散度、语义一致性、声明置信度），通过注意力引导裁剪未充分探索的图像区域进行迭代精炼
- Result: 在Qwen2.5-VL-7B模型上，幻觉率降低9.8个百分点，对抗性分割上的物体存在准确率提升4.7个百分点
- Conclusion: 不确定性引导的视觉重注意机制能有效减少幻觉，为可信赖的多模态系统提供无需训练的自校正方案


### [188] [Dual-Stream Cross-Modal Representation Learning via Residual Semantic Decorrelation](https://arxiv.org/abs/2512.07568)
*Xuecheng Li,Weikuan Jia,Alisher Kurbonaliev,Qurbonaliev Alisher,Khudzhamkulov Rustam,Ismoilov Shuhratjon,Eshmatov Javhariddin,Yuanjie Zheng*

Main category: cs.CV

TL;DR: 提出DSRSD-Net框架，通过残差分解和语义解相关约束，解耦模态特定和模态共享信息，解决多模态学习中的模态主导、冗余耦合和虚假相关等问题。

- Motivation: 多模态表示常存在模态主导、冗余信息耦合和虚假跨模态相关性等问题，导致泛化能力差和可解释性有限。强模态会掩盖弱但语义重要的信号，而简单的融合策略会无控制地纠缠模态共享和模态特定因素，难以理解哪个模态真正驱动预测，也无法在模态噪声或缺失时保持鲁棒性。
- Method: 提出双流残差语义解相关网络(DSRSD-Net)：1) 双流表示学习模块，通过残差投影分离模态内(私有)和模态间(共享)潜在因子；2) 残差语义对齐头，使用对比和回归式目标将不同模态的共享因子映射到共同空间；3) 解相关和正交性损失，正则化共享空间的协方差结构，同时强制共享流和私有流之间的正交性，抑制跨模态冗余并防止特征崩溃。
- Result: 在两个大规模教育基准测试上的实验结果表明，DSRSD-Net在下一步预测和最终结果预测方面，始终优于强单模态、早期融合、晚期融合和协同注意力基线。
- Conclusion: DSRSD-Net通过解耦模态特定和模态共享信息，有效解决了多模态学习中的关键挑战，提高了预测性能和可解释性，同时在模态噪声或缺失时保持鲁棒性。


### [189] [All You Need Are Random Visual Tokens? Demystifying Token Pruning in VLLMs](https://arxiv.org/abs/2512.07580)
*Yahong Wang,Juncheng Wu,Zhangkai Ni,Longzhen Yang,Yihang Liu,Chengmei Yang,Ying Wen,Xianfeng Tang,Hui Liu,Yuyin Zhou,Lianghua He*

Main category: cs.CV

TL;DR: 本文发现视觉大语言模型深层存在"信息消失"现象，提出基于信息度量的随机剪枝方法，在保持性能的同时显著提升推理效率。

- Motivation: 现有视觉大语言模型依赖大量视觉token导致计算成本高，而现有训练无关的剪枝方法在深层表现不佳，甚至不如随机剪枝。作者发现这是由于视觉token信息随网络深度增加而逐渐消失导致的。
- Method: 提出通过移除token时模型输出概率变化来量化token信息含量的方法，发现"信息地平线"现象，并基于此提出在深层使用随机剪枝的策略，同时将随机剪枝与现有方法结合。
- Result: 使用DivPrune结合随机剪枝达到最佳效果，在剪除50%视觉token的情况下仍能保持Qwen-2.5-VL-7B模型96.9%的性能，显著提升推理效率。
- Conclusion: 视觉token信息随网络深度逐渐消失，形成"信息地平线"，基于此发现采用随机剪枝策略能有效平衡性能与效率，为VLLM加速提供了新思路。


### [190] [LongCat-Image Technical Report](https://arxiv.org/abs/2512.07584)
*Meituan LongCat Team,Hanghang Ma,Haoxian Tan,Jiale Huang,Junqiang Wu,Jun-Yan He,Lishuai Gao,Songlin Xiao,Xiaoming Wei,Xiaoqi Ma,Xunliang Cai,Yayong Guan,Jie Hu*

Main category: cs.CV

TL;DR: LongCat-Image是一个开源的英中双语图像生成基础模型，在文本渲染、真实感、部署效率和开发者可访问性方面表现优异，采用紧凑的6B参数设计，并建立了完整的开源生态系统。

- Motivation: 解决当前主流模型在多语言文本渲染、真实感、部署效率和开发者可访问性方面的核心挑战，特别是中文文本渲染的行业标准问题。
- Method: 通过预训练、中期训练和SFT阶段的数据精心策划策略，结合RL阶段的奖励模型协调使用，采用紧凑的6B参数扩散模型架构，显著小于常见的20B+ MoE架构。
- Result: 在文本渲染能力和真实感方面达到新的SOTA水平，特别是在中文字符渲染上设定了新的行业标准，支持复杂和罕见字符；在图像编辑方面也达到SOTA结果，具有优异的编辑一致性；部署效率高，VRAM使用少，推理速度快。
- Conclusion: LongCat-Image通过其卓越性能、高效设计和完整的开源生态系统，为开发者和研究人员提供了强大的支持，将推动视觉内容创作的前沿发展。


### [191] [Robust Variational Model Based Tailored UNet: Leveraging Edge Detector and Mean Curvature for Improved Image Segmentation](https://arxiv.org/abs/2512.07590)
*Kaili Qi,Zhongyi Huang,Wenli Yang*

Main category: cs.CV

TL;DR: 提出VM_TUNet的鲁棒版本，结合变分方法和深度学习，通过物理先验、边缘检测器和平均曲率项改进图像分割，在噪声图像和模糊边界场景中取得平衡性能

- Motivation: 针对噪声图像分割中边界模糊或断裂的挑战，需要结合变分PDE的边界平滑优势和深度神经网络的强大表示能力
- Method: 提出鲁棒VM_TUNet框架，将物理先验、边缘检测器和平均曲率项整合到改进的Cahn-Hilliard方程中，包含F模块（频域预处理）和T模块（精确局部计算）两个协作模块
- Result: 在三个基准数据集上实验表明，该方法在性能和计算效率之间取得平衡，相比纯CNN模型获得竞争性定量结果和改善的视觉质量，性能接近基于Transformer的方法但计算成本合理
- Conclusion: 提出的鲁棒VM_TUNet框架成功结合了变分PDE的边界平滑优势和深度学习的表示能力，为噪声图像分割提供了一种有效且计算高效的解决方案


### [192] [More than Segmentation: Benchmarking SAM 3 for Segmentation, 3D Perception, and Reconstruction in Robotic Surgery](https://arxiv.org/abs/2512.07596)
*Wenzhen Dong,Jieming Yu,Yiming Huang,Hongqiu Wang,Lei Zhu,Albert C. S. Chung,Hongliang Ren,Long Bai*

Main category: cs.CV

TL;DR: SAM 3在机器人辅助手术中的实证评估显示，相比SAM和SAM 2，在图像和视频分割方面有显著改进，支持点、边界框和语言提示的零样本分割，并具备3D重建能力，但语言提示在手术领域表现欠佳，复杂动态场景仍存在局限。

- Motivation: 评估SAM 3在机器人辅助手术中的性能，特别是其零样本分割能力（包括新引入的语言提示）和3D感知能力，以了解其在手术领域的实际应用潜力。
- Method: 在MICCAI EndoVis 2017和2018基准上进行综合测试，评估SAM 3的点、边界框和语言提示的零样本分割性能；在动态视频跟踪中测试其能力；使用SCARED、StereoMIS和EndoNeRF数据集评估其单目深度估计和3D器械重建能力。
- Result: SAM 3在空间提示下的图像和视频分割方面明显优于SAM和SAM 2；在单目深度估计和3D器械重建方面表现良好；但语言提示在手术领域表现不佳，复杂动态手术场景仍存在局限性。
- Conclusion: SAM 3在机器人辅助手术中展现出显著进步，特别是在空间提示分割和3D重建方面，但需要领域特定训练来改进语言提示性能，且复杂动态场景的处理能力仍需提升。


### [193] [Online Segment Any 3D Thing as Instance Tracking](https://arxiv.org/abs/2512.07599)
*Hanshi Wang,Zijian Cai,Jin Gao,Yiwei Zhang,Weiming Hu,Ke Wang,Zhipeng Zhang*

Main category: cs.CV

TL;DR: AutoSeg3D将在线3D分割重构为实例跟踪问题，通过对象查询实现时间信息传播，结合长短时关联提升感知一致性，在多个数据集上达到SOTA性能。

- Motivation: 当前基于查询的3D分割方法主要关注空间信息传播，但忽视了感知的动态性和时间维度理解。在具身智能体场景中，视角变化导致物体部分可见，需要时间信息来构建完整物体理解。
- Method: 1) 将在线3D分割重构为实例跟踪问题；2) 使用对象查询进行时间信息传播：长时实例关联保持特征和身份一致性，短时实例更新丰富即时观测；3) 引入空间一致性学习缓解VFMs的碎片化问题；4) 稀疏对象查询实现时间信息交换，避免密集点云交互的计算负担。
- Result: 在ScanNet200上超越ESAM 2.8 AP，在ScanNet、SceneNN和3RScan数据集上均取得一致性能提升，建立了新的SOTA。
- Conclusion: 通过时间信息传播和一致性学习，AutoSeg3D显著提升了具身智能体的环境感知能力，证明了时间维度理解对于在线3D分割的重要性，同时保持了计算效率。


### [194] [Decomposition Sampling for Efficient Region Annotations in Active Learning](https://arxiv.org/abs/2512.07606)
*Jingna Qiu,Frauke Wilm,Mathias Öttl,Jonas Utz,Maja Schlereth,Moritz Schillinger,Marc Aubreville,Katharina Breininger*

Main category: cs.CV

TL;DR: DECOMP是一种新的主动学习采样策略，专门针对密集预测任务，通过分解图像为类别特定组件并采样各类别区域，提高标注多样性和少数类性能。

- Motivation: 密集预测任务（如医学图像分割）的标注成本高、时间密集。现有区域级标注方法存在计算内存成本高、区域选择不相关、过度依赖不确定性采样等问题，需要更高效的主动学习策略。
- Method: DECOMP通过伪标签将图像分解为类别特定组件，从每个类别中采样区域。结合类别预测置信度指导采样过程，确保困难类别获得更多标注，提高标注多样性。
- Result: 在ROI分类、2D分割和3D分割任务中，DECOMP始终超越基线方法，能更好地采样少数类区域并提升这些困难类别的性能。
- Conclusion: DECOMP通过分解采样策略有效解决了密集预测主动学习中的关键问题，提高了标注效率和模型性能，特别是在处理少数类别方面表现优异。


### [195] [MoCA: Mixture-of-Components Attention for Scalable Compositional 3D Generation](https://arxiv.org/abs/2512.07628)
*Zhiqi Li,Wenhuan Li,Tengfei Wang,Zhenwei Wang,Junta Wu,Haoyuan Wang,Yunhan Yang,Zehuan Huang,Yang Li,Peidong Liu,Chunchao Guo*

Main category: cs.CV

TL;DR: MoCA提出了一种可扩展的组合式3D生成模型，通过重要性组件路由和未选组件压缩来降低计算复杂度，实现高效细粒度的3D资产创建。

- Motivation: 现有的部分感知3D生成方法在增加组件数量时，由于二次全局注意力成本导致可扩展性差，需要解决组合式3D生成的计算效率问题。
- Method: MoCA采用两种关键设计：1) 基于重要性的组件路由，选择top-k相关组件进行稀疏全局注意力；2) 不重要组件压缩，在降低计算复杂度的同时保留未选组件的上下文先验。
- Result: 大量实验表明，MoCA在组合式物体和场景生成任务上均优于基线方法，实现了可扩展组件数量的高效3D生成。
- Conclusion: MoCA通过创新的注意力机制设计，解决了组合式3D生成的可扩展性问题，为高效、细粒度的3D资产创建提供了有效解决方案。


### [196] [Liver Fibrosis Quantification and Analysis: The LiQA Dataset and Baseline Method](https://arxiv.org/abs/2512.07651)
*Yuanye Liu,Hanxiao Zhang,Nannan Shi,Yuxin Shi,Arif Mahmood,Murtaza Taj,Xiahai Zhuang*

Main category: cs.CV

TL;DR: LiQA数据集包含440例多期相、多中心MRI扫描，用于肝脏分割和纤维化分期算法评估，挑战赛最佳方法采用半监督学习和多视图共识策略提升临床鲁棒性。

- Motivation: 肝纤维化是全球重大健康负担，需要准确分期以进行有效临床管理。现有算法在真实临床环境中面临域偏移、模态缺失和空间错位等复杂挑战，需要建立标准化基准数据集来评估算法性能。
- Method: 建立LiQA数据集包含440例患者的多期相、多中心MRI扫描。挑战赛最佳方法采用：1）半监督学习框架结合外部数据进行鲁棒分割；2）多视图共识方法结合类激活图（CAM）正则化进行分期。
- Result: 评估表明，利用多源数据和解剖约束能显著增强模型在临床环境中的鲁棒性。该方法在CARE 2024挑战赛中表现最佳，为肝纤维化分期提供了有效的解决方案。
- Conclusion: LiQA数据集为肝脏分割和纤维化分期算法提供了标准化基准。半监督学习与多视图共识方法相结合，能够有效应对临床环境中的复杂挑战，为肝纤维化的准确分期提供了有前景的技术路径。


### [197] [An AI-Powered Autonomous Underwater System for Sea Exploration and Scientific Research](https://arxiv.org/abs/2512.07652)
*Hamad Almazrouei,Mariam Al Nasseri,Maha Alzaabi*

Main category: cs.CV

TL;DR: 提出AI驱动的自主水下航行器系统，整合YOLOv12 Nano实时检测、ResNet50特征提取、PCA降维、K-Means++聚类和GPT-4o Mini生成报告，用于自动化水下物体检测与分析。

- Motivation: 传统海洋探索面临极端条件、能见度低、成本高等挑战，导致大量海域未勘探。需要自动化系统来减少人类潜水风险，提高任务效率和数据分析深度。
- Method: 集成YOLOv12 Nano进行实时物体检测，ResNet50进行特征提取，PCA降维保留98%方差，K-Means++聚类基于视觉特征分组，GPT-4o Mini生成结构化报告。在DeepFish和OzFish数据集（超55,000张图像）上训练评估。
- Result: 系统检测海洋物体mAP@0.5为0.512，精度0.535，召回率0.438。PCA有效降维同时保留98%方差，K-Means成功按视觉相似性聚类。LLM能生成包含位置数据的检测和聚类洞察总结。
- Conclusion: 该集成方法显著降低人类潜水风险，提高任务效率，增强水下数据分析速度和深度，为挑战性海洋环境中的科学研究开辟新途径。


### [198] [Optimization-Guided Diffusion for Interactive Scene Generation](https://arxiv.org/abs/2512.07661)
*Shiaho Li,Naisheng Ye,Tianyu Li,Kashyap Chitta,Tuo An,Peng Su,Boyang Wang,Haiou Liu,Chen Lv,Hongyang Li*

Main category: cs.CV

TL;DR: OMEGA是一个优化引导的无训练框架，通过扩散采样中的约束优化生成物理合理且行为一致的交通场景，特别针对安全关键事件生成。

- Motivation: 自动驾驶评估需要真实多样的多智能体驾驶场景，但现有数据集缺乏安全关键事件。现有生成模型缺乏可控性或产生违反物理/社会约束的样本。
- Method: OMEGA在扩散模型的反向扩散步骤中引入约束优化，确保结构一致性和交互感知。将自车-攻击者交互建模为分布空间的博弈论优化，近似纳什均衡生成对抗场景。
- Result: 在nuPlan和Waymo数据集上，OMEGA将物理和行为有效场景比例从32.35%提升到72.27%（自由探索），从11%提升到80%（可控生成）。能生成5倍多的近碰撞帧（TTC<3秒）同时保持场景真实性。
- Conclusion: OMEGA通过优化引导的扩散采样显著提升了驾驶场景生成的真实性、一致性和可控性，特别适用于生成安全关键的对抗场景用于自动驾驶评估。


### [199] [EgoCampus: Egocentric Pedestrian Eye Gaze Model and Dataset](https://arxiv.org/abs/2512.07668)
*Ronan John,Aditya Kesari,Vincenzo DiMatteo,Kristin Dana*

Main category: cs.CV

TL;DR: 提出了EgoCampus数据集和EgoCampusNet方法，用于预测行人在户外校园导航时的视觉注意力

- Motivation: 现有大多数第一人称数据集专注于室内任务或缺少眼动追踪信息，需要研究户外导航场景中的人类视觉注意力预测
- Method: 使用Meta的Project Aria眼镜收集数据，包含眼动追踪、RGB相机、惯性传感器和GPS，开发了EgoCampusNet方法来预测行人导航时的眼动注视点
- Result: 创建了EgoCampus数据集，包含25条独特户外路径、超过6公里、80多名行人的眼动标注视频，为研究真实世界注意力提供了新资源
- Conclusion: 该工作为研究真实世界视觉注意力和未来导航眼动预测模型提供了新的数据集和方法资源


### [200] [DIST-CLIP: Arbitrary Metadata and Image Guided MRI Harmonization via Disentangled Anatomy-Contrast Representations](https://arxiv.org/abs/2512.07674)
*Mehmet Yigit Avci,Pedro Borges,Virginia Fernandez,Paul Wright,Mehmet Yigitsoy,Sebastien Ourselin,Jorge Cardoso*

Main category: cs.CV

TL;DR: DIST-CLIP是一个用于MRI图像标准化的统一框架，通过解耦解剖内容和图像对比度，使用CLIP编码器提取对比度表示，并利用自适应风格转移模块进行整合，支持目标图像或DICOM元数据作为指导。

- Motivation: 深度学习在医学图像分析中具有巨大潜力，但临床泛化受到数据异质性的严重限制。在MRI中，扫描仪硬件差异、采集协议多样性和序列参数变化导致显著的域偏移，掩盖了潜在的生物信号。现有图像标准化方法要么需要目标图像，要么依赖过于简化的标签，无法捕捉真实临床环境中的复杂性。
- Method: 提出DIST-CLIP框架，明确解耦解剖内容和图像对比度。使用预训练的CLIP编码器提取对比度表示，通过新颖的自适应风格转移模块将这些对比度嵌入整合到解剖内容中。框架灵活支持使用目标图像或DICOM元数据进行指导。
- Result: 在多样化的真实世界临床数据集上训练和评估DIST-CLIP，与最先进方法相比，在风格转换保真度和解剖结构保留方面显示出显著改进。
- Conclusion: DIST-CLIP为MRI数据标准化提供了一个灵活的解决方案，能够有效处理真实临床环境中的异质性，代码和权重将在发表后公开。


### [201] [sim2art: Accurate Articulated Object Modeling from a Single Video using Synthetic Training Data Only](https://arxiv.org/abs/2512.07698)
*Arslan Artykov,Corentin Sautier,Vincent Lepetit*

Main category: cs.CV

TL;DR: 首个从单目视频中联合预测部件分割和关节参数的数据驱动方法，仅使用合成数据训练，在真实物体上表现良好

- Motivation: 理解铰接物体对机器人和数字孪生至关重要，但先前工作主要依赖多视角系统、物体扫描或静态相机，缺乏从自由移动相机单目视频中恢复部件分割和关节参数的解决方案
- Method: 提出首个数据驱动方法，从自由移动相机拍摄的单目视频中联合预测部件分割和关节参数，仅使用合成数据训练，能够处理随意录制的视频
- Result: 方法在合成数据上训练，但在真实世界物体上表现出强大的泛化能力，为铰接物体理解提供了可扩展且实用的解决方案
- Conclusion: 该方法适用于动态环境中的实时应用，为铰接物体理解提供了从单目视频中恢复部件分割和关节参数的有效方案


### [202] [Guiding What Not to Generate: Automated Negative Prompting for Text-Image Alignment](https://arxiv.org/abs/2512.07702)
*Sangha Park,Eunji Kim,Yeongtak Oh,Jooyoung Choi,Sungroh Yoon*

Main category: cs.CV

TL;DR: NPC提出了一种自动化负提示生成方法，通过识别并应用抑制不相关内容的负提示来提升文本到图像生成的精确对齐。

- Motivation: 尽管文本到图像生成取得了显著进展，但对于具有丰富组合结构或想象元素的提示，实现精确的文本-图像对齐仍然具有挑战性。现有方法在处理复杂提示时容易出现对齐错误。
- Method: NPC采用自动化管道，通过分析交叉注意力模式来解释目标负提示（直接与对齐错误相关）和非目标负提示（与提示无关但出现在生成图像中的标记）如何增强对齐。使用验证器-描述器-提议器框架生成候选负提示，并通过显著文本空间评分进行排序，无需额外图像合成。
- Result: 在GenEval++和Imagine-Bench基准测试中，NPC显著优于强基线方法，在GenEval++上达到0.571 vs 0.371，在Imagine-Bench上获得最佳整体性能。
- Conclusion: 通过指导模型不生成什么内容，NPC为扩散模型提供了原则性、完全自动化的路径，以实现更强的文本-图像对齐。该方法通过负提示机制有效提升了生成质量。


### [203] [PVeRA: Probabilistic Vector-Based Random Matrix Adaptation](https://arxiv.org/abs/2512.07703)
*Leo Fillioux,Enzo Ferrante,Paul-Henry Cournède,Maria Vakalopoulou,Stergios Christodoulidis*

Main category: cs.CV

TL;DR: PVeRA是一种概率版本的VeRA适配器，通过概率化修改低秩矩阵来处理输入中的固有模糊性，并在训练和测试时支持不同采样配置，在VTAB-1k基准测试中优于VeRA和其他适配器。

- Motivation: 大型基础模型需要大量数据和计算资源进行训练或微调，成本高昂。适配器方法通过向冻结的主干网络添加少量可训练模块，提供计算高效的解决方案。VeRA适配器使用共享的冻结随机低秩矩阵在参数高效适应方面表现优异，但需要进一步改进。
- Method: 提出PVeRA（概率VeRA适配器），对VeRA的低秩矩阵进行概率化修改。这种方法自然地处理输入中的固有模糊性，并允许在训练和测试时使用不同的采样配置。
- Result: 在VTAB-1k基准测试中对七种适配器进行了全面评估，PVeRA在性能上超越了VeRA和其他适配器。
- Conclusion: PVeRA通过概率化修改VeRA的低秩矩阵，有效处理输入模糊性并支持灵活的采样配置，在参数高效适应任务中表现出优越性能，为大型基础模型的轻量级适应提供了有效解决方案。


### [204] [UnCageNet: Tracking and Pose Estimation of Caged Animal](https://arxiv.org/abs/2512.07712)
*Sayak Dutta,Harish Katti,Shashikant Verma,Shanmuganathan Raman*

Main category: cs.CV

TL;DR: 提出三阶段预处理流水线，通过笼子分割、修复和评估，解决动物追踪与姿态估计在笼状遮挡下的性能下降问题

- Motivation: 现有动物追踪与姿态估计系统（如STEP、ViTPose）在处理带有笼状结构和系统性遮挡的图像视频时性能大幅下降，需要解决这一限制
- Method: 三阶段预处理流水线：1) 使用Gabor增强的ResNet-UNet架构进行笼子分割，2) 使用CRFill进行内容感知的笼子修复，3) 在修复后的帧上评估姿态估计与追踪
- Result: 实验验证表明，通过该流水线去除笼子遮挡后，姿态估计与追踪性能可达到与无遮挡环境相当的水平，关键点检测精度和轨迹一致性显著提升
- Conclusion: 提出的三阶段预处理流水线能有效解决笼状遮挡对动物追踪与姿态估计系统的影响，使系统在遮挡环境下仍能保持良好性能


### [205] [ViSA: 3D-Aware Video Shading for Real-Time Upper-Body Avatar Creation](https://arxiv.org/abs/2512.07720)
*Fan Yang,Heyuan Li,Peihao Li,Weihao Yuan,Lingteng Qiu,Chaoyue Song,Cheng Chen,Yisheng He,Shifeng Zhang,Xiaoguang Han,Steven Hoi,Guosheng Lin*

Main category: cs.CV

TL;DR: 提出结合3D重建模型和视频生成模型优势的新方法，用于从单张输入图像生成高质量上身3D虚拟形象，解决现有方法在纹理模糊、运动僵硬和结构不稳定等问题。

- Motivation: 现有3D虚拟形象生成方法存在矛盾：基于重建的方法能产生稳定结构但纹理模糊、运动僵硬；基于视频生成的方法能合成逼真动态效果但结构不稳定、身份漂移。需要结合两者优势。
- Method: 提出混合框架：使用3D重建模型提供结构和外观先验，指导实时自回归视频扩散模型进行渲染。结合几何稳定性和生成能力，实现高频细节和流畅动态。
- Result: 实验表明该方法显著减少伪影，在视觉质量上大幅超越现有领先方法，能生成具有逼真外观和动态连贯运动的高保真数字虚拟形象。
- Conclusion: 通过结合3D重建的几何稳定性和视频模型的生成能力，实现了高质量、实时可用的上身3D虚拟形象生成，为游戏和虚拟现实等应用提供了稳健高效解决方案。


### [206] [Improving action classification with brain-inspired deep networks](https://arxiv.org/abs/2512.07729)
*Aidas Aglinskas,Stefano Anzellotti*

Main category: cs.CV

TL;DR: 该研究比较了深度神经网络与人类在动作识别中对身体和背景信息的利用差异，并提出了受大脑领域特异性启发的双流架构来提升性能。

- Motivation: 研究动机是探索深度神经网络在动作识别中如何利用身体和背景信息，以及人类是否更有效地同时利用这两种信息。由于训练数据中身体和背景信息可能存在相关性，DNN可能主要依赖其中一种信息而未能充分利用另一种。
- Method: 方法包括：1) 在HAA500数据集上训练DNN，测试其在三种刺激版本（完整、仅背景、仅身体）上的性能；2) 28名人类参与者进行相同的动作识别任务；3) 设计受大脑领域特异性启发的双流架构，分别处理身体和背景信息。
- Result: 结果显示：1) DNN在完整刺激和仅背景刺激上表现相似，但在仅身体刺激上接近随机水平；2) 人类在所有三种刺激版本上都能准确识别动作，且在仅身体刺激上表现优于仅背景刺激；3) 双流架构不仅提高了动作识别性能，其在不同刺激版本上的准确率模式也更接近人类表现。
- Conclusion: 结论表明人类比DNN更有效地利用身体和背景信息进行动作识别，而受大脑领域特异性启发的双流架构能够提升DNN性能并使其表现更接近人类，这为开发更类人的计算机视觉系统提供了新思路。


### [207] [SAVE: Sparse Autoencoder-Driven Visual Information Enhancement for Mitigating Object Hallucination](https://arxiv.org/abs/2512.07730)
*Sangha Park,Seungryong Yoo,Jisoo Mok,Sungroh Yoon*

Main category: cs.CV

TL;DR: SAVE框架通过稀疏自编码器特征引导缓解MLLM的对象幻觉问题，在CHAIR_S上提升10%p，无需训练

- Motivation: 多模态大语言模型存在对象幻觉问题，主要由语言先验和视觉信息丢失引起，需要有效缓解方法
- Method: 提出SAVE框架：1) 使用二值对象存在问答探针识别稀疏自编码器的视觉理解特征；2) 沿这些特征引导模型增强视觉理解
- Result: 在CHAIR_S上提升10%p，在POPE和MMHal-Bench上持续改进，多模型多层的广泛评估证实鲁棒性和泛化性
- Conclusion: SAVE通过稀疏自编码器特征引导有效缓解对象幻觉，抑制不确定对象token生成，增加对图像token的关注


### [208] [SpatialDreamer: Incentivizing Spatial Reasoning via Active Mental Imagery](https://arxiv.org/abs/2512.07733)
*Meng Cao,Xingyu Li,Xue Liu,Ian Reid,Xiaodan Liang*

Main category: cs.CV

TL;DR: SpatialDreamer是一个强化学习框架，通过主动探索、视觉想象和基于证据的推理来解决MLLMs在复杂空间推理任务上的局限性，使用GeoPO方法解决长序列推理的奖励监督问题。

- Motivation: 尽管多模态大语言模型在场景理解方面有进展，但在需要心理模拟的复杂空间推理任务上表现仍然有限。现有方法主要依赖被动观察空间数据，缺乏主动的心理意象过程。
- Method: 提出了SpatialDreamer强化学习框架，通过主动探索、世界模型的视觉想象和基于证据的推理形成闭环过程。为了解决长序列推理任务中细粒度奖励监督的缺乏，提出了几何策略优化（GeoPO），引入树结构采样和具有几何一致性约束的步骤级奖励估计。
- Result: 在多个具有挑战性的基准测试中，SpatialDreamer取得了极具竞争力的结果，标志着MLLMs在类人主动空间心理模拟方面的关键进展。
- Conclusion: SpatialDreamer通过强化学习和主动心理模拟框架，显著提升了MLLMs在复杂空间推理任务上的能力，为类人空间认知提供了新的研究方向。


### [209] [HLTCOE Evaluation Team at TREC 2025: VQA Track](https://arxiv.org/abs/2512.07738)
*Dengjia Zhang,Charles Weng,Katherine Guerrerio,Yi Lu,Kenton Murray,Alexander Martin,Reno Kriz,Benjamin Van Durme*

Main category: cs.CV

TL;DR: HLTCOE团队为TREC VQA的答案生成任务开发了列表式学习框架，通过重排序候选答案提升语义精度和排序一致性

- Motivation: 改进视频问答中的答案生成质量，特别是提升语义精度和排序一致性，解决时序推理和语义消歧问题
- Method: 使用基础多模态模型生成多个候选答案，然后通过基于Masked Pointer Cross-Entropy Loss with Rank Weights训练的模型进行重排序，该损失函数整合了指针选择、排序依赖权重和受限词汇的掩码交叉熵
- Result: 实验显示在准确性和排序稳定性方面取得一致提升，特别是在需要时序推理和语义消歧的问题上效果显著
- Conclusion: 通过将生成式建模与判别式排序相结合，该方法能够产生连贯、细粒度的答案列表，实现了稳定且可解释的列表式优化


### [210] [DiffusionDriveV2: Reinforcement Learning-Constrained Truncated Diffusion Modeling in End-to-End Autonomous Driving](https://arxiv.org/abs/2512.07745)
*Jialv Zou,Shaoyu Chen,Bencheng Liao,Zhiyu Zheng,Yuehao Song,Lefei Zhang,Qian Zhang,Wenyu Liu,Xinggang Wang*

Main category: cs.CV

TL;DR: DiffusionDriveV2使用强化学习解决端到端自动驾驶中扩散模型的模式崩溃问题，通过尺度自适应噪声和分层GRPO策略，在保持多样性的同时提升轨迹质量，在NAVSIM数据集上创下新记录。

- Motivation: 现有基于扩散模型的端到端自动驾驶方法存在模式崩溃问题，倾向于生成保守和同质化的行为。虽然DiffusionDrive使用预定义锚点来划分动作空间并生成多样化轨迹，但其基于模仿学习的方法缺乏足够约束，导致多样性与高质量之间的两难困境。
- Method: 提出DiffusionDriveV2，利用强化学习约束低质量模式并探索更优轨迹。1) 使用适合轨迹规划的尺度自适应乘性噪声促进广泛探索；2) 采用锚点内GRPO管理同一锚点样本的优势估计，以及锚点间截断GRPO引入全局视角，防止不同意图间不恰当的优势比较导致进一步模式崩溃。
- Result: 在NAVSIM v1数据集上达到91.2 PDMS，在NAVSIM v2数据集上达到85.5 EPDMS（使用对齐的ResNet-34骨干网络），创下新记录。实验验证了该方法解决了截断扩散模型中多样性与一致高质量之间的两难困境，实现了最佳权衡。
- Conclusion: DiffusionDriveV2通过强化学习显著提升了端到端自动驾驶扩散模型的整体输出质量，同时保持了其核心高斯混合模型固有的多模态特性，解决了模式崩溃问题，在多样性和高质量之间取得了良好平衡。


### [211] [Unison: A Fully Automatic, Task-Universal, and Low-Cost Framework for Unified Understanding and Generation](https://arxiv.org/abs/2512.07747)
*Shihao Zhao,Yitong Chen,Zeyinzi Jiang,Bojia Zi,Shaozhe Hao,Yu Liu,Chaojie Mao,Kwan-Yee K. Wong*

Main category: cs.CV

TL;DR: Unison是一个低训练成本的多模态统一理解与生成模型，通过两阶段方案自动解析用户意图和任务参数，覆盖多种视觉语言任务。

- Motivation: 现有多模态统一方法存在两个问题：自回归方法需要大量计算资源，两阶段方法任务覆盖有限且生成质量差。两者都缺乏自动解析输入元信息的能力，需要手动参数配置。
- Method: 采用两阶段方案，在保持预训练模型能力的同时，通过极低训练成本（50万样本，50 GPU小时）覆盖多种理解与生成任务。模型能自动解析用户意图、确定任务类型、提取所需元信息。
- Result: 实验表明，在低成本设置下，模型能准确自动识别任务和提取参数，在多种理解和生成任务上取得优异性能。
- Conclusion: Unison实现了多模态任务的完全自动化，无需人工干预，为普通研究者提供了可行的统一理解与生成解决方案。


### [212] [UltrasODM: A Dual Stream Optical Flow Mamba Network for 3D Freehand Ultrasound Reconstruction](https://arxiv.org/abs/2512.07756)
*Mayank Anand,Ujair Alam,Surya Prakash,Priya Shukla,Gora Chand Nandi,Domenec Puig*

Main category: cs.CV

TL;DR: UltrasODM是一个双流框架，通过校准的逐帧不确定性、显著性诊断和可操作提示来辅助超声操作者，减少重建误差并提高临床可靠性。

- Motivation: 临床超声采集高度依赖操作者，快速的探头运动和亮度波动常导致重建误差，降低信任度和临床效用。需要一种能够提供实时反馈和不确定性评估的系统来辅助操作者。
- Method: 提出UltrasODM双流框架：1) 基于运动相似性的对比排序模块对帧进行分组；2) 融合双Mamba时序模块的光流流进行鲁棒的6自由度位姿估计；3) 人机交互层结合贝叶斯不确定性、临床校准阈值和显著性图来突出低置信度区域，当不确定性超过阈值时发出提示。
- Result: 在临床自由手超声数据集上评估，相比UltrasOM，漂移减少15.2%，距离误差减少12.1%，Hausdorff距离减少10.1%，同时生成逐帧不确定性和显著性输出。
- Conclusion: UltrasODM通过强调透明度和临床医生反馈，提高了重建可靠性，支持更安全、更可信的临床工作流程。代码已公开。


### [213] [Modality-Aware Bias Mitigation and Invariance Learning for Unsupervised Visible-Infrared Person Re-Identification](https://arxiv.org/abs/2512.07760)
*Menglin Wang,Xiaojin Gong,Jiachen Li,Genlin Ji*

Main category: cs.CV

TL;DR: 提出一种无监督可见光-红外行人重识别方法，通过模态感知Jaccard距离缓解模态差异，结合分割对比策略学习模态不变特征，在基准数据集上取得SOTA性能。

- Motivation: 无监督可见光-红外行人重识别面临模态差异大的挑战，现有方法通常使用最优传输关联模态内聚类，容易传播局部聚类错误且忽视全局实例级关系。需要解决跨模态学习的两个关键问题：偏差缓解的全局关联和模态不变表示学习。
- Method: 1. 提出模态感知Jaccard距离来缓解模态差异引起的距离偏差，通过全局聚类估计更可靠的跨模态关联；2. 设计"分割-对比"策略获取模态特定的全局原型，在全局关联指导下显式对齐这些原型，实现模态不变且ID可区分的表示学习。
- Result: 在基准VI-ReID数据集上取得了最先进的性能，显著优于现有方法，验证了方法的有效性。
- Conclusion: 通过关注可见光-红外模态偏差，从偏差缓解的全局关联和模态不变表示学习两方面解决跨模态学习问题，提出的方法虽然概念简单但效果显著，为无监督跨模态行人重识别提供了有效解决方案。


### [214] [GorillaWatch: An Automated System for In-the-Wild Gorilla Re-Identification and Population Monitoring](https://arxiv.org/abs/2512.07776)
*Maximilian Schall,Felix Leonard Knöfel,Noah Elias König,Jan Jonas Kubeler,Maximilian von Klinski,Joan Wilhelm Linnemann,Xiaoshi Liu,Iven Jelle Schlegelmilch,Ole Woyciniuk,Alexandra Schild,Dante Wasmuht,Magdalena Bermejo Espinet,German Illera Basas,Gerard de Melo*

Main category: cs.CV

TL;DR: 提出GorillaWatch端到端管道，包含三个新数据集，通过多帧自监督预训练和注意力解释技术，实现濒危大猩猩的自动重识别与追踪，优于专用视频架构。

- Motivation: 目前监测濒危西部低地大猩猩面临巨大挑战，需要从大量相机陷阱视频中手动重新识别个体，自动化过程缺乏大规模野外视频数据集进行深度学习模型训练。
- Method: 1) 引入三个新数据集：Gorilla-SPAC-Wild（最大野外灵长类重识别数据集）、Gorilla-Berlin-Zoo（跨域重识别评估）、Gorilla-SPAC-MoT（多目标追踪评估）；2) 提出GorillaWatch端到端管道，集成检测、追踪和重识别；3) 采用多帧自监督预训练策略，利用轨迹一致性学习领域特征；4) 使用AttnLRP可微分适应验证模型依赖生物特征而非背景相关性；5) 集成时空约束到标准聚类进行无监督种群计数。
- Result: 大规模图像骨干网络特征聚合优于专用视频架构；多帧自监督预训练有效学习领域特征；注意力解释验证模型关注判别性生物特征；无监督种群计数通过时空约束减轻过分割问题。
- Conclusion: GorillaWatch为濒危物种监测提供了可扩展、非侵入性的解决方案，公开代码和数据集将促进野生动物保护技术的发展。


### [215] [Distribution Matching Variational AutoEncoder](https://arxiv.org/abs/2512.07778)
*Sen Ye,Jianning Pei,Mengde Xu,Shuyang Gu,Chunyu Wang,Liwei Wang,Han Hu*

Main category: cs.CV

TL;DR: DMVAE通过显式匹配任意参考分布来优化VAE的潜在空间，发现自监督学习特征分布能平衡重建保真度和建模效率，在ImageNet上仅用64个训练周期达到gFID=3.2。

- Motivation: 现有视觉生成模型（如VAE和基础模型对齐编码器）隐式约束潜在空间而不显式塑造其分布，导致不清楚哪种分布最适合建模。需要系统研究哪种潜在分布更有利于建模。
- Method: 提出Distribution-Matching VAE (DMVAE)，通过分布匹配约束显式对齐编码器的潜在分布与任意参考分布，超越传统VAE的高斯先验，可对齐自监督特征、扩散噪声或其他先验分布。
- Result: 发现自监督学习（SSL）衍生的分布提供了重建保真度和建模效率之间的良好平衡，在ImageNet上仅用64个训练周期达到gFID=3.2。
- Conclusion: 选择合适的潜在分布结构（通过分布级对齐实现），而不是依赖固定先验，是弥合易于建模的潜在空间和高保真图像合成之间差距的关键。


### [216] [OneStory: Coherent Multi-Shot Video Generation with Adaptive Memory](https://arxiv.org/abs/2512.07802)
*Zhaochong An,Menglin Jia,Haonan Qiu,Zijian Zhou,Xiaoke Huang,Zhiheng Liu,Weiming Ren,Kumara Kahatapitiya,Ding Liu,Sen He,Chenyang Zhang,Tao Xiang,Fanny Yang,Serge Belongie,Tian Xie*

Main category: cs.CV

TL;DR: OneStory：通过全局跨镜头上下文建模实现一致且可扩展的多镜头视频叙事生成，将多镜头视频生成重构为下一个镜头生成任务，利用预训练图像到视频模型，并引入帧选择和自适应条件模块。

- Motivation: 现有多镜头视频生成方法难以有效建模长距离跨镜头上下文，因为它们依赖有限的时间窗口或单关键帧条件，导致在复杂叙事下性能下降。需要一种能够全局建模跨镜头上下文的方法来实现一致且可扩展的叙事生成。
- Method: 1. 将多镜头视频生成重构为下一个镜头生成任务，实现自回归镜头合成；2. 引入帧选择模块，基于先前镜头的信息帧构建语义相关的全局记忆；3. 设计自适应条件模块，执行重要性引导的块化处理以生成紧凑上下文；4. 策划高质量多镜头数据集并设计有效的训练策略。
- Result: 在策划的60K数据集上微调预训练I2V模型后，OneStory在文本和图像条件设置下，在多样复杂场景中实现了最先进的叙事连贯性，支持可控且沉浸式的长视频叙事。
- Conclusion: OneStory通过全局跨镜头上下文建模解决了多镜头视频生成的挑战，实现了更一致、可扩展的叙事生成，为长视频叙事提供了有效的解决方案。


### [217] [Multi-view Pyramid Transformer: Look Coarser to See Broader](https://arxiv.org/abs/2512.07806)
*Gyeongjin Kang,Seungkwon Yang,Seungtae Nam,Younggeun Lee,Jungwoo Kim,Eunbyung Park*

Main category: cs.CV

TL;DR: MVP是一个可扩展的多视角Transformer架构，能够从数十到数百张图像中单次前向传播重建大型3D场景，结合局部到全局的视角层次和精细到粗糙的空间层次，实现高效高质量重建。

- Motivation: 现有方法在处理大规模多视角图像（数十到数百张）重建大型复杂3D场景时面临计算效率和可扩展性挑战，需要一种能够同时处理大量输入视图并保持高质量重建的方法。
- Method: 提出Multi-view Pyramid Transformer (MVP)，基于两个核心设计原则：1) 局部到全局的视角间层次结构，从局部视图逐步扩展到组视图再到完整场景；2) 精细到粗糙的视角内层次结构，从详细空间表示逐步聚合为紧凑的信息密集token。结合3D高斯泼溅作为底层3D表示。
- Result: 在多样化数据集上验证，当与3D高斯泼溅结合时，MVP实现了最先进的泛化重建质量，同时保持高效率和可扩展性，能够适应广泛的视角配置。
- Conclusion: MVP通过双层次结构设计成功解决了大规模多视角3D场景重建的效率和可扩展性问题，为大型复杂场景的快速高质量重建提供了有效解决方案。


### [218] [Lang3D-XL: Language Embedded 3D Gaussians for Large-scale Scenes](https://arxiv.org/abs/2512.07807)
*Shai Krakovsky,Gal Fiebelman,Sagie Benaim,Hadar Averbuch-Elor*

Main category: cs.CV

TL;DR: 提出一种在3D高斯表示中嵌入语言场的新方法，通过极低维语义瓶颈特征和多分辨率哈希编码器提高效率，并引入衰减下采样器和正则化解决语义对齐问题。

- Motivation: 在3D表示中嵌入语言场可以实现更丰富的空间环境语义理解，连接几何与描述性意义，支持自然语言查询和编辑场景，改进场景检索、导航和多模态推理等任务。然而，现有特征蒸馏方法在处理大规模互联网数据时面临语义特征错位和内存/运行时效率低下的挑战。
- Method: 1) 在底层3D高斯表示中引入极低维语义瓶颈特征，通过渲染和多分辨率特征哈希编码器处理，显著提高GPU内存和运行时效率；2) 引入衰减下采样器模块，并提出多种正则化方法解决2D地面真值特征的语义错位问题。
- Result: 在野外HolyScenes数据集上评估，该方法在性能和效率方面均超越了现有方法。
- Conclusion: 提出的方法有效解决了大规模场景中语义特征蒸馏的效率和语义对齐问题，为3D场景的语义理解和自然语言交互提供了更高效的解决方案。


### [219] [WorldReel: 4D Video Generation with Consistent Geometry and Motion Modeling](https://arxiv.org/abs/2512.07821)
*Shaoheng Fang,Hanwen Jiang,Yunpeng Bai,Niloy J. Mitra,Qixing Huang*

Main category: cs.CV

TL;DR: WorldReel是一个原生时空一致的4D视频生成器，联合生成RGB帧和4D场景表示（点云、相机轨迹、密集光流），在动态场景和移动相机下实现几何一致性。

- Motivation: 现有视频生成器虽然实现了逼真的视觉效果，但在3D一致性方面存在根本缺陷。需要一种能够保持时空一致性的视频生成方法，为世界建模提供稳定的4D表示。
- Method: 提出WorldReel框架，联合生成RGB帧和4D场景表示（点云、相机轨迹、密集光流）。通过合成数据提供精确的4D监督（几何、运动、相机），结合真实视频提供视觉多样性和真实感。
- Result: WorldReel在动态场景和移动相机下的视频生成中达到新的SOTA，显著提升了几何一致性、运动连贯性指标，减少了视角-时间伪影。
- Conclusion: WorldReel将视频生成推向4D一致的世界建模，使智能体能够通过单一稳定的时空表示进行渲染、交互和场景推理。


### [220] [OpenVE-3M: A Large-Scale High-Quality Dataset for Instruction-Guided Video Editing](https://arxiv.org/abs/2512.07826)
*Haoyang He,Jie Wang,Jiangning Zhang,Zhucun Xue,Xingyuan Bu,Qiangpeng Yang,Shilei Wen,Lei Xie*

Main category: cs.CV

TL;DR: 提出了OpenVE-3M数据集和OpenVE-Bench基准，用于指令式视频编辑，包含空间对齐和非空间对齐编辑类型，并训练了OpenVE-Edit模型在基准上达到SOTA。

- Motivation: 指令式图像编辑数据集质量和多样性不断提升，但大规模高质量的指令式视频编辑数据集仍然稀缺，且缺乏统一的评估基准。
- Method: 1) 构建OpenVE-3M数据集：包含空间对齐编辑（全局风格、背景变化、局部变化/移除/添加、字幕编辑）和非空间对齐编辑（摄像机多镜头编辑、创意编辑），通过精心设计的数据流水线和严格质量过滤生成；2) 构建OpenVE-Bench基准：包含431个视频编辑对，涵盖多样化编辑任务，采用三个与人类判断高度一致的关键指标；3) 训练OpenVE-Edit模型：基于数据集训练5B参数模型。
- Result: OpenVE-3M在规模、编辑类型多样性、指令长度和整体质量上超越现有开源数据集；OpenVE-Edit模型在OpenVE-Bench上达到新的SOTA，超越了包括14B基线在内的所有先前开源模型。
- Conclusion: 提出的OpenVE-3M数据集和OpenVE-Bench基准填补了指令式视频编辑领域的空白，OpenVE-Edit模型展示了高效性和有效性，为视频编辑研究提供了重要资源。


### [221] [One Layer Is Enough: Adapting Pretrained Visual Encoders for Image Generation](https://arxiv.org/abs/2512.07829)
*Yuan Gao,Chen Chen,Tianrong Chen,Jiatao Gu*

Main category: cs.CV

TL;DR: FAE提出了一种简单有效的框架，通过两个分离的深度解码器将预训练视觉表示适配为适合生成的低维潜在空间，仅需单个注意力层即可实现高质量图像生成。

- Motivation: 现有方法难以将理解导向的预训练视觉表示适配到生成友好的潜在空间中，因为表示编码器需要高维潜在空间来捕捉多样化假设，而生成模型需要低维潜在空间来保持注入噪声的保真度。
- Method: FAE框架使用两个分离的深度解码器：一个训练用于重建原始特征空间，另一个将重建特征作为输入进行图像生成。该方法仅需单个注意力层，可适配多种自监督编码器（如DINO、SigLIP）并集成到扩散模型和标准化流等生成模型中。
- Result: 在ImageNet 256x256上，使用CFG的扩散模型达到接近SOTA的FID 1.29（800轮）和1.70（80轮）；不使用CFG时达到SOTA的FID 1.48（800轮）和2.08（80轮），展示了高质量和快速学习能力。
- Conclusion: FAE提供了一种通用且高效的解决方案，能够将预训练视觉表示适配到生成友好的低维潜在空间中，在保持重建和理解能力的同时实现高质量的图像生成。


### [222] [UnityVideo: Unified Multi-Modal Multi-Task Learning for Enhancing World-Aware Video Generation](https://arxiv.org/abs/2512.07831)
*Jiehui Huang,Yuechen Zhang,Xu He,Yuan Gao,Zhi Cen,Bin Xia,Yan Zhou,Xin Tao,Pengfei Wan,Jiaya Jia*

Main category: cs.CV

TL;DR: UnityVideo是一个统一的多模态视频生成框架，通过联合学习分割掩码、人体骨架、DensePose、光流和深度图等多种模态，实现世界感知的视频生成。

- Motivation: 当前视频生成模型受限于单模态条件约束，缺乏跨模态交互和模态多样性，限制了其对世界的全面理解能力。
- Method: 提出两个核心组件：1）动态噪声统一异构训练范式；2）模态切换器与上下文学习器，通过模块化参数和上下文学习实现统一处理。构建了包含130万样本的大规模统一数据集。
- Result: UnityVideo加速了收敛过程，显著增强了零样本泛化能力，在视频质量、一致性和物理世界约束对齐方面表现出色。
- Conclusion: UnityVideo通过多模态联合学习框架，实现了世界感知的视频生成，在质量和泛化能力上超越了现有方法。


### [223] [Relational Visual Similarity](https://arxiv.org/abs/2512.07833)
*Thao Nguyen,Sicheng Mo,Krishna Kumar Singh,Yilin Wang,Jing Shi,Nicholas Kolkin,Eli Shechtman,Yong Jae Lee,Yuheng Li*

Main category: cs.CV

TL;DR: 该论文提出了关系相似性概念，开发了首个能测量图像间关系相似性的视觉语言模型，揭示了现有图像相似性模型在捕捉人类关系感知能力方面的不足。

- Motivation: 人类不仅能感知属性相似性，还能感知关系相似性（如地球与桃子的结构对应关系），但现有视觉相似性度量方法（如LPIPS、CLIP、DINO）仅关注感知属性相似性，无法捕捉人类感知的丰富关系相似性。
- Method: 首先将关系图像相似性形式化为可测量问题，然后构建了包含11.4万张图像-匿名化描述的数据集（描述关注场景的关系逻辑而非表面内容），最后基于该数据集微调视觉语言模型来测量图像间的关系相似性。
- Result: 开发了首个能测量图像间关系相似性的视觉语言模型，该模型基于图像的底层关系结构而非可见外观来连接图像，实验表明现有图像相似性模型无法有效捕捉关系相似性。
- Conclusion: 关系相似性具有重要的现实应用价值，但现有图像相似性模型无法捕捉这一维度，揭示了视觉计算领域的关键空白，提出的模型为基于关系结构而非外观连接图像迈出了第一步。


### [224] [Voxify3D: Pixel Art Meets Volumetric Rendering](https://arxiv.org/abs/2512.07834)
*Yi-Chuan Huang,Jiewen Chan,Hao-Jen Chien,Yu-Lun Liu*

Main category: cs.CV

TL;DR: Voxify3D是一个两阶段可微分框架，通过正交像素艺术监督、基于补丁的CLIP对齐和调色板约束的Gumbel-Softmax量化，实现从3D网格到体素艺术的自动化生成。

- Motivation: 体素艺术在游戏和数字媒体中广泛应用，但从3D网格自动生成面临几何抽象、语义保持和离散颜色一致性之间的冲突挑战。现有方法要么过度简化几何，要么无法实现像素级精确、调色板约束的体素艺术美学。
- Method: 提出Voxify3D框架，包含三个核心组件：1) 正交像素艺术监督消除透视畸变，实现体素-像素精确对齐；2) 基于补丁的CLIP对齐在不同离散化级别保持语义；3) 调色板约束的Gumbel-Softmax量化，在离散颜色空间上实现可微分优化，支持可控调色板策略。
- Result: 实验显示优越性能（37.12 CLIP-IQA，77.90%用户偏好），在多样化角色和可控抽象（2-8种颜色，20x-50x分辨率）上表现优异。
- Conclusion: Voxify3D通过协同整合三个组件，解决了极端离散化下的语义保持、通过体素渲染实现像素艺术美学，以及端到端离散优化等基本挑战，实现了高质量的体素艺术生成。
## cs.LG

### [225] [Vector Quantization using Gaussian Variational Autoencoder](https://arxiv.org/abs/2512.06609)
*Tongda Xu,Wendi Zheng,Jiajun He,Jose Miguel Hernandez-Lobato,Yan Wang,Ya-Qin Zhang,Jie Tang*

Main category: cs.LG

TL;DR: 提出Gaussian Quant技术，将高斯VAE转换为VQ-VAE而无需额外训练，通过目标散度约束提升性能，在图像压缩任务上超越现有VQ-VAE方法。

- Motivation: VQ-VAE由于离散化过程难以训练，需要一种更简单有效的离散化方法。作者希望利用高斯VAE的特性来构建VQ-VAE，避免直接训练离散模型的困难。
- Method: 提出Gaussian Quant技术：1) 生成随机高斯噪声作为码本；2) 找到与后验均值最接近的噪声向量；3) 提出目标散度约束(TDC)来训练高斯VAE以优化GQ效果。
- Result: 理论证明：当码本大小的对数超过高斯VAE的bits-back编码率时，可保证小的量化误差。实验表明：GQ在UNet和ViT架构上优于VQGAN、FSQ、LFQ、BSQ等现有VQ-VAE方法，TDC也优于TokenBridge等高斯VAE离散化方法。
- Conclusion: Gaussian Quant提供了一种简单有效的方法将高斯VAE转换为高性能的VQ-VAE，无需额外训练，为离散表示学习提供了新思路。


### [226] [Financial Fraud Identification and Interpretability Study for Listed Companies Based on Convolutional Neural Network](https://arxiv.org/abs/2512.06648)
*Xiao Li*

Main category: cs.LG

TL;DR: 本文提出基于卷积神经网络的A股上市公司财务舞弊检测框架，通过特征工程将面板数据转换为类图像表示，实现提前预测，并在准确性、鲁棒性和预警性能上优于传统方法。

- Motivation: 上市公司财务舞弊难以检测，传统统计模型难以处理非线性特征交互，机器学习模型缺乏可解释性，且现有方法大多只能基于当年数据判断当年舞弊，时效性有限。
- Method: 设计特征工程方案将公司年度面板数据转换为类图像表示，使用卷积神经网络捕捉横截面和时间模式，实现提前预测；采用局部解释技术从实体、特征和时间三个维度分析模型可解释性。
- Result: CNN在准确性、鲁棒性和预警性能上优于逻辑回归和LightGBM；偿债能力、比率结构、治理结构和内部控制是舞弊的通用预测因子；舞弊公司表现出异质性模式且集中在短期时间窗口。
- Conclusion: 基于CNN的财务舞弊检测框架能有效提前预测舞弊，通过阈值调整适应高风险场景，局部解释技术揭示了舞弊的驱动因素和模式特征，为监管提供实用工具。


### [227] [Estimating Black Carbon Concentration from Urban Traffic Using Vision-Based Machine Learning](https://arxiv.org/abs/2512.06649)
*Camellia Zakaria,Aryan Sadeghi,Weaam Jaafar,Junshi Xu,Alex Mariakakis,Marianne Hatzopoulou*

Main category: cs.LG

TL;DR: 利用交通监控视频和天气数据，通过机器学习模型估计街道级黑碳浓度，填补交通与环境影响数据缺口

- Motivation: 城市黑碳排放主要来自交通，但监测成本高导致数据缺乏，而交通监控系统广泛部署，存在交通状况与环境影响数据不平衡的问题
- Method: 从交通视频中提取车辆行为和状况的视觉信息，结合天气数据，构建机器学习模型估计街道级黑碳浓度
- Result: 模型达到R平方值0.72，RMSE为129.42 ng/m³，能够有效估计街道级黑碳浓度
- Conclusion: 利用现有城市基础设施和建模技术生成交通排放相关信息，为污染减排、城市规划、公共卫生和环境正义提供可操作见解


### [228] [Rethinking Robustness: A New Approach to Evaluating Feature Attribution Methods](https://arxiv.org/abs/2512.06665)
*Panagiota Kiourti,Anu Singh,Preeti Duraipandian,Weichao Zhou,Wenchao Li*

Main category: cs.LG

TL;DR: 提出新的特征归因方法鲁棒性评估框架，包括相似输入的新定义、新鲁棒性指标和基于GAN的生成方法，挑战现有忽视模型输出差异的评估方式。

- Motivation: 当前特征归因方法的鲁棒性评估大多忽略模型输出的差异，需要更客观的指标来揭示归因方法本身的弱点而非神经网络的弱点。
- Method: 1) 提出相似输入的新定义；2) 设计新的鲁棒性评估指标；3) 开发基于生成对抗网络(GAN)的方法来生成这些相似输入；4) 对现有指标和最先进的归因方法进行全面评估。
- Result: 研究结果表明需要更客观的评估指标，能够准确揭示归因方法本身的弱点，从而更准确地评估归因方法的鲁棒性。
- Conclusion: 挑战了当前归因鲁棒性的概念，提出了新的评估框架，强调需要区分归因方法弱点与神经网络弱点，为更准确评估归因方法鲁棒性提供了新方向。


### [229] [Enhancing Interpretability of AR-SSVEP-Based Motor Intention Recognition via CNN-BiLSTM and SHAP Analysis on EEG Data](https://arxiv.org/abs/2512.06730)
*Lin Yang,Xiang Li,Xin Ma,Xinxin Zhao*

Main category: cs.LG

TL;DR: 提出基于增强现实的SSVEP脑机接口系统，结合改进的CNN-BiLSTM架构和多头注意力机制，用于提高运动功能障碍患者的康复训练参与度和意图识别准确性。

- Motivation: 运动功能障碍患者在康复训练中主观参与度低，传统SSVEP-BCI系统依赖外部视觉刺激设备，在实际应用中受限，且治疗师工作负担重。
- Method: 1. 设计基于HoloLens 2的四种EEG类别，收集7名健康受试者的EEG数据；2. 在传统CNN-BiLSTM架构基础上集成多头注意力机制(MACNN-BiLSTM)；3. 提取10个时频EEG特征，通过CNN学习高级表征，BiLSTM建模序列依赖，多头注意力突出运动意图相关模式；4. 使用SHAP方法可视化EEG特征对神经网络决策的贡献。
- Result: 未在摘要中明确给出具体数值结果，但表明该方法能够增强实时运动意图识别能力，支持运动障碍患者的康复恢复。
- Conclusion: 提出的AR-SSVEP系统结合MACNN-BiLSTM模型和SHAP解释性方法，能够提高患者康复训练的主动性和治疗效率，增强模型的可解释性，支持运动障碍患者的康复。


### [230] [Arc Gradient Descent: A Mathematically Derived Reformulation of Gradient Descent with Phase-Aware, User-Controlled Step Dynamics](https://arxiv.org/abs/2512.06737)
*Nikhil Verma,Joonas Linnosmaa,Espinosa-Leal Leonardo,Napat Vajragupta*

Main category: cs.LG

TL;DR: ArcGD优化器在非凸基准函数和真实ML数据集上表现优异，超越Adam等主流优化器，在CIFAR-10上达到最高准确率50.7%，并显示出抗过拟合特性。

- Motivation: 开发一种新的优化器ArcGD，旨在解决现有优化器（如Adam）在非凸优化问题中的局限性，特别是在高维空间和深度学习任务中，提供更好的收敛性和泛化能力。
- Method: 提出ArcGD优化器，首先在具有挑战性的Rosenbrock函数上进行评估（2D到50,000D），然后在CIFAR-10数据集上测试8种不同的MLP架构（1-5隐藏层），与Adam、AdamW、Lion、SGD等优化器对比。
- Result: 在Rosenbrock函数上，ArcGD在相同学习率设置下始终优于Adam；在CIFAR-10上，ArcGD在20,000次迭代后达到最高平均测试准确率50.7%，在8个架构中6个获胜或打平，且持续改进不出现过拟合。
- Conclusion: ArcGD是一种有效的优化器，在非凸优化和深度学习任务中表现优异，具有抗过拟合特性，且与Lion优化器存在理论联系，值得进一步探索其广泛应用潜力。


### [231] [Transformation of Biological Networks into Images via Semantic Cartography for Visual Interpretation and Scalable Deep Analysis](https://arxiv.org/abs/2512.07040)
*Sakib Mostafa,Lei Xing,Md. Tauhidul Islam*

Main category: cs.LG

TL;DR: Graph2Image将大型生物网络转换为二维图像，使用CNN进行分析，解决了现有方法在可扩展性、长距离依赖和可解释性方面的限制。

- Motivation: 生物网络分析面临可扩展性差、长距离依赖捕捉困难、多模态整合困难、表达能力有限和可解释性差等挑战，需要新的方法来解决这些问题。
- Method: 将大型生物网络转换为二维图像集，通过在2D网格上空间排列代表性网络节点，然后使用具有全局感受野和多尺度金字塔的CNN进行分析。
- Result: 在多个大规模生物网络数据集上，分类准确率比现有方法提高达67.2%，能够分析超过10亿节点的网络，并提供可解释的可视化结果。
- Conclusion: Graph2Image提供了一个可扩展、可解释、支持多模态的生物网络分析方法，为疾病诊断和复杂生物系统研究提供了新机会。


### [232] [Winning the Lottery by Preserving Network Training Dynamics with Concrete Ticket Search](https://arxiv.org/abs/2512.07142)
*Tanay Arora,Christof Teuscher*

Main category: cs.LG

TL;DR: CTS算法通过组合优化和梯度平衡，在初始化阶段高效找到高性能稀疏子网络，性能接近或超过计算昂贵的LTR方法，特别是在高稀疏度下优势明显。

- Motivation: 现有彩票票证发现方法存在计算成本高（如LTR）或精度-稀疏度权衡差（如PaI）的问题。PaI方法依赖一阶显著性指标，忽略了权重间的相互依赖关系，导致性能不佳。
- Method: 提出Concrete Ticket Search (CTS)算法，将子网络发现视为组合优化问题，使用Concrete松弛离散搜索空间，并引入GRADBALANCE梯度平衡方案控制稀疏度。进一步提出基于知识蒸馏的剪枝目标，特别是最小化稀疏与密集网络输出的反向KL散度（CTS-KL）。
- Result: 在图像分类任务中，CTS生成的子网络能通过基本合理性检查，精度接近或超过LTR，但计算成本显著降低。例如在ResNet-20/CIFAR10上，达到99.3%稀疏度时精度74.0%（LTR为68.3%），计算时间仅7.9分钟（LTR需95.2分钟）。
- Conclusion: CTS通过整体组合优化方法有效解决了PaI方法的局限性，在高稀疏度下特别优于LTR，为高效发现彩票票证提供了新途径。


### [233] [FlowLPS: Langevin-Proximal Sampling for Flow-based Inverse Problem Solvers](https://arxiv.org/abs/2512.07150)
*Jonghyun Park,Jong Chul Ye*

Main category: cs.LG

TL;DR: FlowLPS：基于预训练流模型解决逆问题的新框架，通过Langevin近端采样策略，在FFHQ和DIV2K数据集上超越现有方法

- Motivation: 现有训练自由方法在应用于流模型时存在两个问题：1）难以收敛到后验模式；2）在潜在空间中产生流形偏差。需要一种能同时保证重建保真度和感知质量的方法。
- Method: FlowLPS框架结合Langevin动力学进行流形一致探索和近端优化进行精确模式搜索，通过Langevin Proximal Sampling策略解决逆问题。
- Result: 在FFHQ和DIV2K数据集上的多个逆任务中，FlowLPS在重建保真度和感知质量之间取得了优越平衡，超越了现有最先进的逆问题求解器。
- Conclusion: FlowLPS为基于预训练流模型的逆问题求解提供了一种有效的训练自由框架，成功解决了现有方法在收敛性和流形一致性方面的局限性。


### [234] [Towards Reliable Test-Time Adaptation: Style Invariance as a Correctness Likelihood](https://arxiv.org/abs/2512.07390)
*Gilhyun Nam,Taewon Kim,Joonhyun Jeong,Eunho Yang*

Main category: cs.LG

TL;DR: SICL是一个无需反向传播的即插即用校准框架，通过风格不变性来估计实例级正确性概率，在测试时适应场景中显著降低校准误差。

- Motivation: 测试时适应（TTA）方法在实际部署中经常导致预测不确定性校准不佳，这在自动驾驶、金融和医疗等高风险领域是严重问题。现有校准方法通常假设固定模型或静态分布，在动态测试条件下性能下降。
- Method: SICL框架利用风格不变性进行鲁棒的不确定性估计，通过测量预测在不同风格变换版本中的一致性来估计实例级正确性概率，仅需模型前向传播，无需反向传播。
- Result: 在四个基线、五种TTA方法和两种现实场景（三种模型架构）的综合评估中，SICL相比传统校准方法平均降低校准误差13个百分点。
- Conclusion: SICL是一个有效的即插即用校准模块，能够显著改善TTA方法中的不确定性校准问题，适用于高风险领域的实际应用。


### [235] [Revolutionizing Mixed Precision Quantization: Towards Training-free Automatic Proxy Discovery via Large Language Models](https://arxiv.org/abs/2512.07419)
*Haidong Kang,Jun Du,Lihong Lin*

Main category: cs.LG

TL;DR: 提出TAP框架，利用大语言模型自动发现混合精度量化的训练免费代理，无需人工专家参与或训练过程

- Motivation: 现有混合精度量化方法要么依赖昂贵的可微分优化（效率低且不灵活），要么需要人工专家设计代理（劳动密集且需要专业知识）。能否设计一个无需人工专家参与和训练的代理？
- Method: 提出LLM驱动的训练免费自动代理发现框架TAP，利用大语言模型为MPQ定制代理。采用基于直接策略优化的强化学习来优化提示，构建LLM与MPQ任务之间的正反馈循环。
- Result: 在主流基准测试中，TAP实现了最先进的性能表现。
- Conclusion: TAP为MPQ社区提供了LLM驱动设计算法的新视角，将显著推动该领域发展。


### [236] [KAN-Dreamer: Benchmarking Kolmogorov-Arnold Networks as Function Approximators in World Models](https://arxiv.org/abs/2512.07437)
*Chenwei Shi,Xueyu Luan*

Main category: cs.LG

TL;DR: KAN-Dreamer将KAN和FastKAN架构集成到DreamerV3中，替换部分MLP和卷积组件，在DeepMind Control Suite上实现与原MLP架构相当的性能表现。

- Motivation: 探索将参数效率高、可解释性强的KAN网络集成到DreamerV3框架中，以结合模型基强化学习的样本效率和KAN的架构优势。
- Method: 提出KAN-Dreamer，用KAN和FastKAN层替换DreamerV3中的特定MLP和卷积组件，在JAX世界模型中实现完全向量化版本，并简化网格管理。研究分为视觉感知、潜在预测和行为学习三个子系统。
- Result: 在DeepMind Control Suite的walker_walk任务上，使用适配的FastKAN作为奖励和继续预测器的替代方案，在样本效率、训练时间和渐近性能方面与原MLP架构表现相当。
- Conclusion: KAN架构可以作为DreamerV3中MLP组件的有效替代，保持性能的同时提供更好的参数效率和可解释性，为基于KAN的世界模型未来发展提供了初步研究基础。


### [237] [Exploring possible vector systems for faster training of neural networks with preconfigured latent spaces](https://arxiv.org/abs/2512.07509)
*Nikita Gabdullin*

Main category: cs.LG

TL;DR: 本文提出使用预定义向量系统（如An根系统）作为潜在空间配置目标，无需分类层即可训练分类器神经网络，特别适用于大规模类别数据集，并能显著加速训练收敛。

- Motivation: 神经网络性能与潜在空间嵌入分布特性密切相关。传统分类器需要分类层，当类别数量极大时训练困难。预定义向量系统可以确保潜在空间具有理想结构，从而简化训练过程。
- Method: 使用预定义向量系统（包括An根系统）作为潜在空间配置目标，训练编码器和视觉变换器时直接优化嵌入向量与目标向量系统的对齐，无需传统分类层。同时探索最小化潜在空间维度的方法。
- Result: 在ImageNet-1K和50k-600k类别数据集上显著加速了训练收敛。使用最小潜在空间维度能获得更快的收敛速度，同时减少存储神经网络嵌入的向量数据库大小。
- Conclusion: 预定义向量系统为大规模类别分类问题提供了有效的训练框架，通过优化潜在空间结构而非传统分类层，实现了训练加速和存储效率提升，具有实际应用价值。


### [238] [ReLaX: Reasoning with Latent Exploration for Large Reasoning Models](https://arxiv.org/abs/2512.07558)
*Shimin Zhang,Xianwei Chen,Yufan Shen,Ziyuan Ye,Jibin Wu*

Main category: cs.LG

TL;DR: 本文提出ReLaX方法，通过分析大语言模型的潜在动态来调控探索-利用平衡，解决RLVR中的熵崩溃问题，在多种推理基准上取得SOTA性能。

- Motivation: RLVR虽然能增强大推理模型的推理能力，但常导致熵崩溃，造成策略过早收敛和性能饱和。现有方法主要操纵token级熵来促进探索，但作者认为token生成背后的潜在动态包含更丰富的计算结构，能更好地指导探索-利用平衡。
- Method: 利用Koopman算子理论获得隐藏状态动态的线性化表示，引入动态谱分散度(DSD)来量化模型潜在动态的异质性，作为策略探索的直接指标。基于此提出ReLaX范式，在策略优化中显式地结合潜在动态来调控探索和利用。
- Result: 在广泛的多模态和纯文本推理基准测试中，ReLaX显著缓解了过早收敛问题，并持续实现了最先进的性能。
- Conclusion: 通过分析大语言模型的潜在动态来调控探索-利用平衡是有效的，ReLaX方法为解决RLVR中的熵崩溃问题提供了新思路，在多个推理任务上表现出色。
## cs.GR

### [239] [Human Geometry Distribution for 3D Animation Generation](https://arxiv.org/abs/2512.07459)
*Xiangjun Tang,Biao Zhang,Peter Wonka*

Main category: cs.GR

TL;DR: 提出两阶段框架：第一阶段学习紧凑的分布式潜在表示，改进SMPL与虚拟形象几何的映射；第二阶段利用有限运动数据多样性生成动画，通过身份条件设计保持长期一致性。

- Motivation: 生成逼真的人体几何动画面临挑战，需要在有限数据下建模具有精细几何细节的自然服装动态。
- Method: 两阶段框架：1) 学习紧凑的分布式潜在表示，建立更均匀的SMPL与虚拟形象几何映射；2) 生成式动画模型，利用有限运动数据多样性，通过身份条件设计保持长期一致性。
- Result: 潜在空间产生高保真人体几何（Chamfer距离降低90%）；动画模型合成多样化动画，具有详细自然的动态（用户研究评分提高2.2倍），在所有评估指标上取得最佳结果。
- Conclusion: 提出的两阶段框架成功解决了在有限数据下生成逼真人体几何动画的挑战，通过改进的潜在表示和生成式动画模型实现了高质量的几何生成和自然动态合成。
## cs.RO

### [240] [GuideNav: User-Informed Development of a Vision-Only Robotic Navigation Assistant For Blind Travelers](https://arxiv.org/abs/2512.06147)
*Hochul Hwang,Soowan Yang,Jahir Sadik Monon,Nicholas A Giudice,Sunghoon Ivan Lee,Joydeep Biswas,Donghyun Kim*

Main category: cs.RO

TL;DR: GuideNav：基于视觉的教-重复导航系统，模仿导盲犬工作方式，无需昂贵传感器即可实现公里级路径跟随

- Motivation: 目前针对盲人和低视力人群的移动辅助系统研究缺乏直接指导机器人导航设计的参考，需要填补这一空白
- Method: 1）对26名导盲犬使用者、4名白手杖使用者、9名导盲犬训练师等进行访谈和15+小时观察；2）开发GuideNav系统：基于视觉的拓扑路径表示、视觉地点识别与时间滤波、相对姿态估计，无需LiDAR等昂贵传感器
- Result: 1）开源了去标识化数据集；2）GuideNav在五个室外环境中实现了公里级路径可靠跟随，能应对教学与重复运行间的场景变化；3）用户研究证实了系统可行性，首次展示了四足移动系统以类似导盲犬的方式检索路径
- Conclusion: GuideNav成功展示了基于视觉的教-重复导航系统在辅助盲人和低视力人群方面的潜力，为人类中心设计的辅助系统提供了新方向


### [241] [MIND-V: Hierarchical Video Generation for Long-Horizon Robotic Manipulation with RL-based Physical Alignment](https://arxiv.org/abs/2512.06628)
*Ruicheng Zhang,Mingyang Zhang,Jun Zhou,Zhangrui Guo,Xiaofan Liu,Zunnan Xu,Zhizhou Zhong,Puxin Yan,Haocheng Luo,Xiu Li*

Main category: cs.RO

TL;DR: MIND-V是一个用于长时程机器人操作视频生成的分层框架，通过语义推理、行为语义桥和运动视频生成器合成物理合理且逻辑连贯的视频，并采用强化学习后训练确保物理一致性。

- Motivation: 现有机器人模仿学习面临长时程、多样化操作数据稀缺的问题，现有视频生成模型只能合成简单动作的短视频，且依赖手动定义轨迹，无法满足复杂机器人操作任务的需求。
- Method: 提出分层框架MIND-V：1) 语义推理中心(SRH)利用预训练视觉语言模型进行任务规划；2) 行为语义桥(BSB)将抽象指令转换为领域不变表示；3) 运动视频生成器(MVG)进行条件视频渲染。采用分阶段视觉未来展开策略增强长时程鲁棒性，并通过GRPO强化学习后训练配合物理预见一致性(PFC)奖励确保物理合理性。
- Result: MIND-V在长时程机器人操作视频生成任务上取得了最先进的性能，建立了可扩展且可控的具身数据合成范式。
- Conclusion: MIND-V通过分层架构和物理一致性约束，成功解决了长时程机器人操作视频生成的挑战，为具身智能的数据合成提供了有效的解决方案。


### [242] [Dynamic Visual SLAM using a General 3D Prior](https://arxiv.org/abs/2512.06868)
*Xingguang Zhong,Liren Jin,Marija Popović,Jens Behley,Cyrill Stachniss*

Main category: cs.RO

TL;DR: 提出一种新颖的单目视觉SLAM系统，能够在动态场景中鲁棒地估计相机位姿，通过结合几何补丁束调整和前馈重建模型的互补优势。

- Motivation: 动态自然环境中的相机位姿估计和3D重建具有挑战性，因为场景动态会严重影响相机位姿估计的准确性。需要开发能够在动态场景中鲁棒工作的SLAM系统。
- Method: 提出一种新颖的单目视觉SLAM系统，结合几何补丁在线束调整和前馈重建模型的互补优势。使用前馈重建模型精确过滤动态区域，并利用其深度预测增强补丁视觉SLAM的鲁棒性。通过将深度预测与束调整估计的补丁对齐，鲁棒处理前馈重建模型批量应用固有的尺度模糊性。
- Result: 系统能够在动态场景中鲁棒地估计相机位姿，通过深度预测与补丁对齐有效处理尺度模糊问题，提高动态环境下的SLAM性能。
- Conclusion: 提出的单目视觉SLAM系统通过结合几何束调整和前馈重建模型，成功解决了动态场景中的相机位姿估计挑战，为机器人、交互可视化和增强现实等应用提供了可靠解决方案。


### [243] [Task adaptation of Vision-Language-Action model: 1st Place Solution for the 2025 BEHAVIOR Challenge](https://arxiv.org/abs/2512.06951)
*Ilia Larchenko,Gleb Zarin,Akash Karnatak*

Main category: cs.RO

TL;DR: 该论文提出了一种视觉-动作策略，在2025 BEHAVIOR挑战赛中获得第一名，该策略基于Pi0.5架构，引入了相关噪声流匹配、可学习混合层注意力等创新，在50个多样化家庭任务中实现了26%的q-score。

- Motivation: BEHAVIOR挑战赛是一个大规模基准测试，包含50个多样化的长视野家庭任务，需要双手操作、导航和上下文感知决策。现有的方法在处理这些复杂任务时面临效率和平滑性挑战。
- Method: 基于Pi0.5架构，引入相关噪声流匹配以提高训练效率并实现相关感知修复；应用可学习混合层注意力和System 2阶段跟踪来解决歧义；训练使用多样本流匹配减少方差，推理时使用动作压缩和挑战特定校正规则。
- Result: 在BEHAVIOR挑战赛中获得第一名，在公开和私有排行榜上的50个任务中均实现了26%的q-score。
- Conclusion: 提出的相关噪声流匹配等创新方法有效提升了视觉-动作策略在复杂家庭任务中的性能，证明了该方法在大规模长视野任务中的有效性。


### [244] [VideoVLA: Video Generators Can Be Generalizable Robot Manipulators](https://arxiv.org/abs/2512.06963)
*Yichao Shen,Fangyun Wei,Zhiying Du,Yaobo Liang,Yan Lu,Jiaolong Yang,Nanning Zheng,Baining Guo*

Main category: cs.RO

TL;DR: VideoVLA将大型视频生成模型转化为机器人操作器，通过联合建模视频、语言和动作模态，同时预测动作序列和未来视觉结果，实现机器人操作的泛化能力。

- Motivation: 当前视觉-语言-动作模型在泛化到新任务、新物体和新环境方面能力有限，需要探索新的范式来提升机器人操作系统的泛化能力。
- Method: 基于多模态扩散变换器，利用预训练的视频生成模型进行联合视觉和动作预测，给定语言指令和图像，同时预测动作序列和未来视觉结果。
- Result: 高质量的未来视觉想象与可靠的动作预测和任务成功相关，VideoVLA展示了强大的泛化能力，包括模仿其他具身的技能和处理新物体。
- Conclusion: 这种同时预测动作及其视觉后果的双重预测策略代表了机器人学习范式的转变，解锁了操作系统中的泛化能力。


### [245] [Mimir: Hierarchical Goal-Driven Diffusion with Uncertainty Propagation for End-to-End Autonomous Driving](https://arxiv.org/abs/2512.07130)
*Zebin Xing,Yupeng Zheng,Qichao Zhang,Zhixing Ding,Pengxuan Yang,Songen Gu,Zhongpu Xia,Dongbin Zhao*

Main category: cs.RO

TL;DR: Mimir是一个新颖的分层双系统框架，通过估计目标点不确定性（拉普拉斯分布）和多速率引导机制，在自动驾驶中生成鲁棒轨迹，显著提升驾驶评分和推理速度。

- Motivation: 当前端到端自动驾驶方法受限于不准确的高层引导信号和复杂引导模块的计算开销，需要更鲁棒、高效的解决方案。
- Method: 提出Mimir框架：1) 使用拉普拉斯分布估计目标点不确定性增强鲁棒性；2) 引入多速率引导机制提前预测扩展目标点以加速推理。
- Result: 在Navhard和Navtest基准测试中，驾驶评分EPDMS提升20%，高层模块推理速度提升1.6倍且不损失准确性。
- Conclusion: Mimir通过不确定性估计和多速率引导机制，有效解决了现有方法的局限性，在自动驾驶轨迹生成方面实现了性能与效率的显著提升。
## cs.SD

### [246] [XM-ALIGN: Unified Cross-Modal Embedding Alignment for Face-Voice Association](https://arxiv.org/abs/2512.06757)
*Zhihua Fang,Shumei Tao,Junxu Wang,Liang He*

Main category: cs.SD

TL;DR: XM-ALIGN是一个统一的跨模态嵌入对齐框架，通过结合显式和隐式对齐机制，显著提升了人脸和语音跨模态验证性能，特别是在"听过"和"未听过"语言上表现优异。

- Motivation: 解决跨模态验证任务中的人脸-语音匹配问题，特别是在处理不同语言（包括未训练过的语言）时提升性能，为ICASSP 2026的FAME挑战赛提供解决方案。
- Method: 从人脸和语音编码器提取特征嵌入，通过共享分类器联合优化，使用均方误差作为嵌入对齐损失确保模态间紧密对齐，并应用数据增强策略提升泛化能力。
- Result: 在MAV-Celeb数据集上展示了优越性能，特别是在"听过"和"未听过"语言上都取得了显著改进。
- Conclusion: XM-ALIGN框架通过统一的跨模态嵌入对齐方法，有效提升了人脸-语音验证性能，为跨模态识别任务提供了有效的解决方案。
## cs.AI

### [247] [Utilizing Multi-Agent Reinforcement Learning with Encoder-Decoder Architecture Agents to Identify Optimal Resection Location in Glioblastoma Multiforme Patients](https://arxiv.org/abs/2512.06990)
*Krishna Arun,Moinak Bhattachrya,Paras Goel*

Main category: cs.AI

TL;DR: 开发用于胶质母细胞瘤诊断和治疗规划的端到端AI系统，包含诊断阶段的序列决策框架和治疗阶段的强化学习生成模型，可降低计算成本、减少推理时间并提高生存率。

- Motivation: 目前医疗领域缺乏支持医生治疗异质性脑肿瘤（如胶质母细胞瘤）的AI系统。胶质母细胞瘤是致死率最高的癌症，五年生存率仅5.1%，急需AI辅助诊断和治疗规划。
- Method: 1. 诊断阶段：采用序列决策框架，包含4个分类模型（卷积神经网络和支持向量机），逐步将患者大脑分类到更具体的类别，最终得出诊断结果。
2. 治疗规划阶段：使用强化学习系统，包含3个生成模型：切除模型（扩散模型）预测可能的切除结果；放疗模型（时空视觉Transformer）生成指定周数后的脑部MRI；化疗模型（扩散模型）生成治疗后MRI。
3. 生存率计算器（卷积神经网络）检查生成的治疗后MRI生存率是否在用户设定目标的15%范围内，否则通过近端策略优化的反馈循环迭代优化切除位置。
- Result: 1. 使用4个小诊断模型的序列决策框架将计算成本降低22.28倍
2. Transformer的回归能力将肿瘤进展推理时间减少113小时
3. 模拟真实情况的增强技术将整体DICE分数提高2.9%
4. 预计可将生存率提高0.9%，可能挽救约2,250人的生命
- Conclusion: 该研究开发了一个端到端的AI系统，能够有效辅助胶质母细胞瘤的诊断和治疗规划，通过创新的序列决策框架和强化学习生成模型，显著降低了计算成本、提高了效率，并有望提高患者生存率。


### [248] [A Geometric Unification of Concept Learning with Concept Cones](https://arxiv.org/abs/2512.07355)
*Alexandre Rocchi--Henry,Thomas Fel,Gianni Franchi*

Main category: cs.AI

TL;DR: 本文通过几何框架统一了概念瓶颈模型（CBM）和稀疏自编码器（SAE），提出两者都学习激活空间中的线性方向形成概念锥，区别仅在于锥的选择方式不同。

- Motivation: 两种可解释性传统（CBM和SAE）各自发展但缺乏交流，需要建立统一框架来连接监督和非监督概念发现方法。
- Method: 提出几何框架：CBM和SAE都学习激活空间中的线性方向形成概念锥。建立包含性评估框架，用CBM提供参考几何，评估SAE学习的概念锥如何近似或包含CBM概念锥。
- Result: 发现了稀疏度和扩展因子的"最佳点"，能最大化与CBM概念的几何和语义对齐。提出了量化指标连接归纳偏置与合理概念的出现。
- Conclusion: 通过共享几何框架统一了监督和非监督概念发现，提供了原则性指标来衡量SAE进展并评估发现概念与人类合理概念的对齐程度。
## cs.CL

### [249] [AquaFusionNet: Lightweight VisionSensor Fusion Framework for Real-Time Pathogen Detection and Water Quality Anomaly Prediction on Edge Devices](https://arxiv.org/abs/2512.06848)
*Sepyan Purnama Kristanto,Lutfi Hakim,Hermansyah*

Main category: cs.CL

TL;DR: AquaFusionNet：轻量级跨模态框架，融合显微成像与水质传感器数据，实现边缘部署的饮用水微生物污染实时监测

- Motivation: 低收入和中等收入地区的小规模饮用水系统中微生物污染波动迅速，现有监测工具只能捕捉片段信息。显微成像提供微生物级可见性，物理化学传感器揭示短期水质变化，但操作员需要分别解读这些数据流，导致实时决策不可靠。
- Method: 提出AquaFusionNet框架，通过门控交叉注意力机制学习微生物外观与传感器动态之间的统计依赖关系，专门为低功耗硬件设计。使用AquaMicro12K数据集（12,846张饮用水环境标注显微图像）进行训练。
- Result: 在印度尼西亚东爪哇7个设施部署6个月，处理184万帧图像，污染事件检测mAP@0.5达94.8%，异常预测准确率96.3%，在Jetson Nano上功耗仅4.8W。相比代表性轻量级检测器，在相同或更低功耗下提供更高准确性。
- Conclusion: 跨模态耦合减少了单模态检测器的常见故障模式（特别是在污垢、浊度峰值和不一致照明条件下）。所有模型、数据和硬件设计均已开源，促进分散式水安全基础设施的复制和适应。


### [250] [DART: Leveraging Multi-Agent Disagreement for Tool Recruitment in Multimodal Reasoning](https://arxiv.org/abs/2512.07132)
*Nithin Sivakumaran,Justin Chih-Yao Chen,David Wan,Yue Zhang,Jaehong Yoon,Elias Stengel-Eskin,Mohit Bansal*

Main category: cs.CL

TL;DR: DART是一个多智能体框架，通过视觉智能体之间的辩论分歧来识别有用的视觉工具，利用工具信息解决分歧并提升视觉问答性能。

- Motivation: 专业视觉工具可以为大语言模型或视觉语言模型提供专家知识，但如何选择合适的工具以及何时调用这些工具是一个挑战。现有的多智能体辩论方法缺乏有效利用视觉工具的能力。
- Method: DART采用多智能体辩论框架，通过智能体之间的分歧来识别有用的视觉工具（如目标检测、OCR、空间推理等）。这些工具引入新信息并提供工具对齐的同意分数，突出与专家工具一致的智能体。最后使用聚合智能体基于智能体输出和工具信息选择最佳答案。
- Result: 在四个多样化基准测试中，DART优于多智能体辩论和单智能体工具调用框架，在A-OKVQA和MMMU上分别比次强基线（带法官模型的多智能体辩论）高出3.4%和2.4%。在M3D医学数据集上比其他基线提高1.3%。文本重叠度分析显示DART比现有方法有更丰富的讨论，工具调用分布分析表明多样化的工具被可靠地用于解决分歧。
- Conclusion: DART通过利用多智能体辩论中的分歧来指导视觉工具的选择，有效提升了视觉问答任务的性能，并能很好地适应新工具和应用领域，为视觉推理提供了更丰富的讨论和更可靠的决策机制。


### [251] [HalluShift++: Bridging Language and Vision through Internal Representation Shifts for Hierarchical Hallucinations in MLLMs](https://arxiv.org/abs/2512.07687)
*Sujoy Nath,Arkaprabha Basu,Sharanya Dasgupta,Swagatam Das*

Main category: cs.CL

TL;DR: 该论文提出HalluShift++方法，通过分析MLLM内部层动态的异常来检测多模态大语言模型中的幻觉问题，相比依赖外部LLM评估器的方法更可靠。

- Motivation: 多模态大语言模型在视觉语言理解任务中表现出色，但经常产生与视觉内容事实不一致的幻觉描述，可能导致严重后果。现有方法主要依赖外部LLM评估器，但这些评估器本身也存在幻觉问题且存在领域适应挑战。
- Method: 提出HalluShift++方法，基于假设：幻觉表现为MLLM内部层动态的可测量异常，而不仅仅是分布偏移。该方法通过层间分析特定假设，将基于文本的LLM幻觉检测扩展到多模态场景。
- Result: HalluShift++能够有效检测多模态大语言模型中的幻觉，代码已开源在GitHub上。
- Conclusion: 通过分析MLLM内部层动态异常来检测幻觉是可行且有效的方法，相比依赖外部评估器的方法更具优势，为MLLM开发过程中的幻觉评估提供了新思路。
## cs.CR

### [252] [OmniSafeBench-MM: A Unified Benchmark and Toolbox for Multimodal Jailbreak Attack-Defense Evaluation](https://arxiv.org/abs/2512.06589)
*Xiaojun Jia,Jie Liao,Qi Guo,Teng Ma,Simeng Qin,Ranjie Duan,Tianlin Li,Yihao Huang,Zhitao Zeng,Dongxian Wu,Yiming Li,Wenqi Ren,Xiaochun Cao,Yang Liu*

Main category: cs.CR

TL;DR: OmniSafeBench-MM是一个全面的多模态越狱攻击防御评估工具箱，集成了13种攻击方法、15种防御策略和多样化数据集，提供三维评估协议来衡量多模态大语言模型的安全性。

- Motivation: 现有多模态越狱攻击基准存在局限性：攻击场景有限、缺乏标准化防御评估、没有统一可复现的工具箱。需要更全面的评估框架来系统评估多模态大语言模型的安全漏洞。
- Method: 开发了OmniSafeBench-MM工具箱，包含13种代表性攻击方法、15种防御策略，数据集涵盖9个主要风险领域和50个细粒度类别，采用咨询式、命令式和陈述式三种查询类型。建立了三维评估协议：危害性（多级尺度）、意图对齐度和响应详细程度。
- Result: 对10个开源和8个闭源多模态大语言模型进行了广泛实验，揭示了它们对多模态越狱攻击的脆弱性。工具箱提供了标准化、可复现的平台，支持未来研究。
- Conclusion: OmniSafeBench-MM通过统一数据、方法和评估，为多模态越狱攻击防御研究提供了标准化基础，有助于更全面地理解和提升多模态大语言模型的安全性。
## eess.IV

### [253] [Proof of Concept for Mammography Classification with Enhanced Compactness and Separability Modules](https://arxiv.org/abs/2512.06575)
*Fariza Dahes*

Main category: eess.IV

TL;DR: 验证并扩展了医学图像分类框架，将改进的ConvNeXt Tiny架构应用于乳腺X光分类，测试了GAGM、SEVector和FSL模块的有效性。

- Motivation: 验证先前在阿尔茨海默症MRI分类中表现良好的改进ConvNeXt Tiny架构（包含GAGM、SEVector和FSL模块）在乳腺X光分类任务中的可迁移性。
- Method: 使用Kaggle整合的INbreast、MIAS和DDSM乳腺X光数据集，比较基线CNN、ConvNeXt Tiny和InceptionV3骨干网络，并加入GAGM和SEVector模块。进行多指标评估（宏F1、每类召回方差、ROC/AUC）、特征可解释性分析（Grad CAM）和开发交互式临床探索仪表板。
- Result: GAGM和SEVector模块能有效增强特征区分能力并减少假阴性（特别是恶性病例），但特征平滑损失（FSL）在乳腺X光分类条件下未显示可测量的改进效果。
- Conclusion: 验证了GAGM和SEVector模块在乳腺X光分类中的有效性，但FSL的效果可能依赖于特定架构和计算假设。研究扩展了原始框架，并指出需要探索替代方法来提高类内紧凑性和类间分离性，以增强恶性与良性病例的区分。


### [254] [Stronger is not better: Better Augmentations in Contrastive Learning for Medical Image Segmentation](https://arxiv.org/abs/2512.05992)
*Azeez Idris,Abdurahman Ali Mohammed,Samuel Fanijo*

Main category: eess.IV

TL;DR: 本文评估了自监督对比学习中强数据增强对医学图像语义分割的影响，发现现有增强方法并不总能提升性能，并探索了更有效的增强策略。

- Motivation: 自监督对比学习在多个下游任务中表现出色，但其中的关键组件——强数据增强（即多种增强技术的组合应用）在医学图像语义分割任务中的效果尚未得到充分验证。
- Method: 对现有数据增强方法在医学图像语义分割任务上进行实验评估，并探索其他可能提升性能的增强技术。
- Result: 令人惊讶地发现，现有的数据增强方法并不总能提升医学图像语义分割的性能，但通过实验找到了能够提供改进性能的其他增强方法。
- Conclusion: 强数据增强在医学图像语义分割任务中需要谨慎选择和设计，并非所有增强技术都能带来性能提升，需要针对特定领域进行优化。


### [255] [Semantic Temporal Single-photon LiDAR](https://arxiv.org/abs/2512.06008)
*Fang Li,Tonglin Mu,Shuling Li,Junran Guo,Keyuan Li,Jianing Li,Ziyang Luo,Xiaodong Fan,Ye Chen,Yunfeng Liu,Hong Cai,Lip Ket Chin,Jinbei Zhang,Shihai Sun*

Main category: eess.IV

TL;DR: 提出基于语义知识库的自更新语义TSP-LiDAR，解决开放集场景下未知目标识别问题，在低信噪比和短采集时间条件下表现优异。

- Motivation: 现有TSP-LiDAR方法无法有效处理开放集场景中的未知目标，且在低信噪比和短采集时间条件下性能显著下降。需要一种能够适应动态环境、无需大量重新训练的方法。
- Method: 将TSP-LiDAR目标识别过程建模为语义通信，引入基于自更新语义知识库（SKB）的语义TSP-LiDAR框架。SKB能够动态更新新遇到目标的语义特征，实现持续适应。
- Result: 仿真和实验结果表明，该方法在低信噪比和有限采集时间条件下优于传统方法。自更新SKB机制在真实实验中，对九种未知目标的识别准确率达到89%（无更新机制为66%）。
- Conclusion: 提出的语义TSP-LiDAR框架在复杂动态环境中具有自适应和鲁棒的目标识别潜力，通过自更新SKB机制实现了对未知目标的持续适应，无需神经网络大量重新训练。


### [256] [Clinical Interpretability of Deep Learning Segmentation Through Shapley-Derived Agreement and Uncertainty Metrics](https://arxiv.org/abs/2512.07224)
*Tianyi Ren,Daniel Low,Pittra Jaengprajak,Juampablo Heras Rivera,Jacob Ruzevick,Mehmet Kurt*

Main category: eess.IV

TL;DR: 该研究探索使用对比度级Shapley值来解释医学图像分割模型，通过分析不同MRI对比度对模型性能的贡献，提出了与临床排名一致性和Shapley排名方差两个指标来评估模型可靠性。

- Motivation: 尽管深度学习在医学图像分割中表现出色，但模型的可解释性对于临床实践中的接受和整合至关重要。现有研究主要关注梯度基技术识别影响区域，而本研究旨在提供更广泛、与临床对齐的方法来解释模型性能如何公平地归因于不同的成像对比度。
- Method: 使用对比度级Shapley值系统性地扰动模型输入以评估特征重要性。基于BraTS 2024数据集，为四种MRI对比度在四种模型架构上生成Shapley值排名。提出了两个指标：模型与"临床医生"成像排名的一致性，以及通过交叉验证折叠间Shapley排名方差量化的不确定性。
- Result: 高性能案例（Dice >0.6）显示出与临床排名显著更高的一致性。Shapley排名方差的增加与性能下降相关（U-Net: r=-0.581）。这些指标为模型可靠性提供了临床可解释的代理。
- Conclusion: 对比度级Shapley值提供了一种临床可解释的方法来评估医学图像分割模型的可靠性，帮助临床医生更好地理解最先进的分割模型，并促进其在临床实践中的接受和整合。


### [257] [Affine Subspace Models and Clustering for Patch-Based Image Denoising](https://arxiv.org/abs/2512.07259)
*Tharindu Wickremasinghe,Marco F. Duarte*

Main category: eess.IV

TL;DR: 该论文研究使用仿射子空间模型进行图像块聚类，以更好地匹配图像块在向量空间中的几何结构，并提出基于该模型的简单去噪算法。

- Motivation: 传统基于线性子空间的图像块聚类方法存在局限性，因为图像块是非负的，在向量空间中并不围绕原点分布，线性子空间模型不能很好地匹配图像块的几何结构。
- Method: 提出使用仿射子空间模型替代线性子空间进行图像块聚类，并设计基于最小二乘投影的简单去噪算法。论文回顾了多种解决仿射子空间聚类问题的算法方法。
- Result: 实验结果表明，仿射子空间聚类在聚类和去噪性能上都有显著提升，相比线性子空间模型能更好地处理图像块的非负特性。
- Conclusion: 仿射子空间模型更适合图像块聚类任务，能更准确地描述图像块在向量空间中的几何分布，从而在聚类和去噪应用中取得更好的性能。


### [258] [Precise Liver Tumor Segmentation in CT Using a Hybrid Deep Learning-Radiomics Framework](https://arxiv.org/abs/2512.07574)
*Xuecheng Li,Weikuan Jia,Komildzhon Sharipov,Alimov Ruslan,Lutfuloev Mazbutdzhon,Ismoilov Shuhratjon,Yuanjie Zheng*

Main category: eess.IV

TL;DR: 提出混合框架结合注意力增强级联U-Net、手工放射组学和3D CNN细化，用于肝脏和肝肿瘤的联合分割

- Motivation: 肝脏肿瘤在增强CT上的三维精确勾画对治疗规划、导航和疗效评估至关重要，但手动勾画耗时、观察者依赖性强且难以跨中心标准化。自动分割面临病灶-实质对比度低、边界模糊或不完整、增强模式异质性以及血管和邻近器官等混淆结构的挑战
- Method: 1) 2.5D两阶段网络：使用密集连接编码器、亚像素卷积解码器和多尺度注意力门，从轴向切片短堆栈生成初始肝脏和肿瘤概率图；2) 三切片细化规则：沿头尾方向强制执行切片间时间一致性，恢复薄小病灶并抑制孤立噪声；3) 放射组学特征选择：从候选病灶提取728个放射组学描述符，通过多策略特征选择减少到20个稳定高信息特征，使用随机森林分类器剔除假阳性区域；4) 3D补丁CNN：基于AlexNet的紧凑3D补丁CNN在肿瘤边界周围窄带进行体素级重标记和轮廓平滑
- Result: 论文未在摘要中提供具体实验结果，但方法设计旨在解决肝脏肿瘤分割的关键挑战，包括低对比度、边界模糊、异质性增强模式和混淆结构等问题
- Conclusion: 提出的混合框架结合了深度学习、放射组学和3D CNN细化，为肝脏和肝肿瘤的精确自动分割提供了综合解决方案，有望提高分割准确性、标准化跨中心结果并减少手动勾画的工作负担


### [259] [R2MF-Net: A Recurrent Residual Multi-Path Fusion Network for Robust Multi-directional Spine X-ray Segmentation](https://arxiv.org/abs/2512.07576)
*Xuecheng Li,Weikuan Jia,Komildzhon Sharipov,Sharipov Hotam Beknazarovich,Farzona S. Ataeva,Qurbonaliev Alisher,Yuanjie Zheng*

Main category: eess.IV

TL;DR: R2MF-Net：用于多方向脊柱X光图像自动分割的循环残差多路径编码器-解码器网络，通过级联粗-细分割、多分支特征提取和跨阶段跳跃连接提高分割精度和稳定性。

- Motivation: 脊柱X光图像分割是脊柱侧弯定量评估（如Cobb角测量、椎体平移估计和曲率分类）的前提。目前临床实践中，医生需要获取冠状位、左屈和右屈X光片来联合评估畸形严重程度和脊柱灵活性。然而，分割步骤仍然高度依赖人工，耗时且不可重复，特别是在低对比度图像、存在肋骨阴影或组织重叠的情况下。
- Method: 提出R2MF-Net，一种循环残差多路径编码器-解码器网络，专门用于多方向脊柱X光图像的自动分割。整体设计包括级联连接的粗分割网络和细分割网络。两个阶段都采用改进的Inception风格多分支特征提取器，同时在跳跃路径中插入循环残差跳跃连接（R2-Jump）模块，逐步对齐编码器和解码器的语义。多尺度跨阶段跳跃（MC-Skip）机制允许细网络重用粗网络多个解码器层次的分层表示，从而增强跨成像方向和对比度条件的分割稳定性。此外，在瓶颈处采用轻量级空间通道挤压激励块（SCSE-Lite）来强调脊柱相关激活并抑制无关结构和背景噪声。
- Result: 在包含228组冠状位、左屈和右屈脊柱X光图像（带有专家标注）的临床多视图X光数据集上评估了R2MF-Net。
- Conclusion: R2MF-Net通过创新的网络架构设计，解决了脊柱X光图像分割中的人工依赖、耗时和不可重复性问题，特别是在低对比度和复杂解剖结构干扰的情况下，为脊柱侧弯的自动化定量评估提供了有效的解决方案。
