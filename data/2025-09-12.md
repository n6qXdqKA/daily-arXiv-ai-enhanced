[[toc]]

## cs.CV

### [1] [Recurrence Meets Transformers for Universal Multimodal Retrieval](https://arxiv.org/abs/2509.08897)
*Davide Caffagni,Sara Sarto,Marcella Cornia,Lorenzo Baraldi,Rita Cucchiara*

Main category: cs.CV

TL;DR: ReT-2是一个统一的多模态检索模型，支持图像和文本组成的多模态查询，并在多模态文档集合中进行检索，通过循环Transformer架构实现跨层和跨模态的动态信息整合。

- Motivation: 随着多模态检索在LLMs和多模态LLMs中的快速发展，出现了越来越复杂的检索任务。现有方法主要依赖于任务特定的视觉-语言模型微调，且仅限于单模态查询或文档。
- Method: ReT-2利用多层表示和循环Transformer架构，采用LSTM启发的门控机制，动态整合跨层和跨模态的信息，捕捉细粒度的视觉和文本细节。
- Result: 在M2KR和M-BEIR基准测试中，ReT-2在不同检索配置下始终达到最先进的性能，同时相比先前方法提供更快的推理速度和更低的内存使用。在检索增强生成管道中集成时，还能提升Encyclopedic-VQA和InfoSeek数据集的性能。
- Conclusion: ReT-2是一个高效统一的多模态检索模型，在多个基准测试中表现出色，具有实际应用价值，源代码和训练模型已公开。


### [2] [Diffusion-Based Action Recognition Generalizes to Untrained Domains](https://arxiv.org/abs/2509.08908)
*Rogerio Guimaraes,Frank Xiao,Pietro Perona,Markus Marks*

Main category: cs.CV

TL;DR: 提出使用视觉扩散模型特征和transformer聚合的方法，在跨物种、跨视角、跨上下文等挑战性条件下实现人类级别的动作识别泛化能力

- Motivation: 人类能够识别相同动作尽管存在巨大的上下文和视角变化（如不同物种、视角、环境），而当前深度学习模型在此类泛化方面存在困难
- Method: 使用视觉扩散模型生成特征，通过transformer进行聚合，特别采用在扩散过程早期时间步条件化的模型来强调语义信息而非像素级细节
- Result: 在跨物种、跨视角、跨上下文三个泛化基准测试中都达到了新的最先进水平
- Conclusion: 该方法使机器动作识别更接近人类级别的鲁棒性，为跨域动作识别提供了有效解决方案


### [3] [PromptGuard: An Orchestrated Prompting Framework for Principled Synthetic Text Generation for Vulnerable Populations using LLMs with Enhanced Safety, Fairness, and Controllability](https://arxiv.org/abs/2509.08910)
*Tung Vu,Lam Nguyen,Quynh Dao*

Main category: cs.CV

TL;DR: PromptGuard是一个模块化提示框架，通过VulnGuard Prompt技术使用对比学习防止LLM生成有害信息，特别保护弱势群体，理论证明可减少25-30%的危害。

- Motivation: 现有安全方法依赖事后过滤或通用对齐技术，无法从生成源头主动防止LLM对弱势群体产生有害、偏见或误导性信息。
- Method: 提出PromptGuard框架，包含VulnGuard Prompt混合技术：整合GitHub精选数据、伦理思维链推理和自适应角色提示，采用多目标优化理论，包含六个核心模块的系统架构。
- Result: 通过熵界和帕累托最优性证明可减少25-30%的分析性危害，建立了使用GitHub数据集的理论验证框架和数学基础。
- Conclusion: PromptGuard为系统性实证研究建立了数学基础，提供了一个智能专家系统用于实时危害预防，特别针对弱势群体的保护。


### [4] [Similarity-based Outlier Detection for Noisy Object Re-Identification Using Beta Mixtures](https://arxiv.org/abs/2509.08926)
*Waqar Ahmad,Evan Murphy,Vladimir A. Krylov*

Main category: cs.CV

TL;DR: 提出Beta-SOD方法，通过Beta混合分布建模相似度分布来检测标签噪声，提升噪声环境下Re-ID性能

- Motivation: Re-ID方法对标签噪声高度敏感，传统方法在噪声环境下性能显著下降，需要鲁棒的噪声处理方案
- Method: 采用孪生网络架构，结合Beta混合相似度异常检测(Beta-SOD)框架，使用二元交叉熵、对比和余弦嵌入损失联合优化
- Result: 在CUHK03、Market-1501和VeRi-776数据集上，在10-30%噪声水平下均优于现有最优方法
- Conclusion: Beta-SOD提供了有效的噪声检测和Re-ID解决方案，具有鲁棒性和广泛适用性


### [5] [SFD-Mamba2Net: Strcture-Guided Frequency-Enhanced Dual-Stream Mamba2 Network for Coronary Artery Segmentation](https://arxiv.org/abs/2509.08934)
*Nan Mu,Ruiqi Song,Zhihui Xu,Jingfeng Jiang,Chen Zhao*

Main category: cs.CV

TL;DR: SFD-Mamba2Net是一个端到端的框架，通过整合多尺度结构先验、状态空间长程依赖建模和频域细节增强策略，显著提升了ICA图像中冠状动脉分割和狭窄检测的准确性。

- Motivation: 冠状动脉疾病是全球主要死因之一，ICA作为诊断金标准需要精确的血管分割和狭窄检测。但ICA图像具有低对比度、高噪声和复杂细粒度血管结构的特点，现有方法难以满足临床需求。
- Method: 提出SFD-Mamba2Net框架：编码器嵌入曲率感知结构增强模块(CASE)来突出细长管状血管结构；解码器引入渐进高频感知模块(PHFP)，通过多级小波分解逐步细化高频细节并整合低频全局结构。
- Result: SFD-Mamba2Net在八个分割指标上均优于最先进方法，在狭窄检测中实现了最高的真阳性率和阳性预测值。
- Conclusion: 该框架通过结构增强和频域细节优化的结合，有效解决了ICA图像分析中的关键挑战，为临床CAD诊断提供了更准确可靠的解决方案。


### [6] [Live(r) Die: Predicting Survival in Colorectal Liver Metastasis](https://arxiv.org/abs/2509.08935)
*Muhammad Alberb,Helen Cheung,Anne Martel*

Main category: cs.CV

TL;DR: 一个全自动化桌面MRI预测桌肠癌肝转移所病人所术后生存的框架，包含分割流水线和影像组学流水线，通过SAMONAI算法和SurvAMINN模型实现了超过10%的预测性能提升。

- Motivation: 桌肠癌肝转移病人所术后生存率差异较大，现有的预后模型基于有限的临床或分子特征，在多发性肝转移框架中预测能力不足。
- Method: 开发了包含分割流水线和影像组学流水线的全自动框架。分割流水线利用提示基础模型处理部分注释数据，并提出SAMONAI算法通过单点提示完成3D分割。影像组学流水线使用SurvAMINN模型，这是一种基于自动编码器的多实例神经网络，从右封侵生存数据中聚焦最具攻击性的肿瘤进行生存分析。
- Result: 在227名患者的机构数据集上进行了广泛评估，证明该框架超越了现有的临床和基因组标记物，C-index提升超10%。
- Conclusion: 研究结果证明了集成自动分割算法和影像组学生存分析在桌肠癌肝转移预测中的潜力，能够提供准确、注释效率高且可解释性强的结果预测。


### [7] [Discovering Divergent Representations between Text-to-Image Models](https://arxiv.org/abs/2509.08940)
*Lisa Dunlap,Joseph E. Gonzalez,Trevor Darrell,Fabian Caba Heilbron,Josef Sivic,Bryan Russell*

Main category: cs.CV

TL;DR: CompCon算法通过进化搜索发现不同文本到图像模型之间的视觉表示差异，识别特定提示触发的一个模型有而另一个模型没有的视觉属性

- Motivation: 研究不同生成模型学习到的视觉表示何时以及如何出现分歧，发现模型输出中的视觉属性差异及其触发提示
- Method: 提出CompCon进化搜索算法，自动发现一个模型输出中更普遍的视觉属性，并找出与这些视觉差异相关的提示概念
- Result: 创建了ID2数据集包含60个输入依赖的差异，CompCon在比较流行文本到图像模型时发现多个分歧表示，如PixArt对孤独提示的湿街道描绘和SD3.5对非裔美国人在媒体职业中的描绘
- Conclusion: CompCon能够有效发现不同文本到图像模型之间的视觉表示差异，为理解模型偏差和表示学习提供了新工具


### [8] [An U-Net-Based Deep Neural Network for Cloud Shadow and Sun-Glint Correction of Unmanned Aerial System (UAS) Imagery](https://arxiv.org/abs/2509.08949)
*Yibin Wang,Wondimagegn Beshah,Padmanava Dash,Haifeng Wang*

Main category: cs.CV

TL;DR: 这篇论文提出了一种基于U-Net深度学习的机器学习方法，用于识别和恢复无人机系统图像中的云影和阳光烈纹影响区域，以提高水质参数估计的准确性。

- Motivation: 无人机系统在云层下拍摄能获得高分辨率图像，但图像往往受到云影和阳光烈纹的影响，这两者严重影响了从无人机图像估计水质参数的准确性。
- Method: 研究提出了一种新的机器学习方法，首先识别和提取云影和阳光烈纹区域，并将其与清晰区域分离。在像素级别提取数据训练U-Net深度学习模型，通过多种评估指标确定最佳模型训练设置。
- Result: 得到了一个高质量的图像纠正模型，能够有效恢复图像中的云影和阳光烈纹区域。
- Conclusion: 该研究提供的深度学习方法能够有效处理无人机图像中的云影和阳光烈纹问题，为水质监测等远程感知应用提供了可靠的图像处理技术。


### [9] [CoSwin: Convolution Enhanced Hierarchical Shifted Window Attention For Small-Scale Vision](https://arxiv.org/abs/2509.08959)
*Puskal Khadka,Rodrigue Rizk,Longwei Wang,KC Santosh*

Main category: cs.CV

TL;DR: CoSwin是一种新颖的特征融合架构，通过将局部卷积特征学习与分层移位窗口注意力相结合，解决了ViT在小数据集上局部特征提取不足的问题。

- Motivation: Vision Transformers在计算机视觉中表现出色，但过分关注全局上下文导致在小数据集上局部特征提取不足，缺乏局部性和平移等变性的归纳偏置。
- Method: 提出CoSwin架构，在每个注意力块中集成可学习的局部特征增强模块，同时捕获细粒度空间细节和全局语义结构。
- Result: 在多个图像分类基准测试中表现优异，相比Swin Transformer基线模型，在CIFAR-10提升2.17%，CIFAR-100提升4.92%，MNIST提升0.10%，SVHN提升0.26%，Tiny ImageNet提升4.47%。
- Conclusion: 局部-全局特征融合有效提升了Transformer在小规模视觉任务中的泛化能力和鲁棒性。


### [10] [iMatcher: Improve matching in point cloud registration via local-to-global geometric consistency learning](https://arxiv.org/abs/2509.08982)
*Karim Slimani,Catherine Achard,Brahim Tamadazte*

Main category: cs.CV

TL;DR: iMatcher是一个完全可微的点云配准特征匹配框架，通过局部图嵌入和全局几何一致性学习，在多个数据集上实现了最先进的配准性能。

- Motivation: 为了解决点云配准中特征匹配的几何一致性问题，需要开发一个能够同时考虑局部和全局一致性的可微匹配框架。
- Method: 使用局部图嵌入模块初始化得分矩阵，通过双向最近邻搜索进行重定位，然后堆叠配对点特征并通过全局几何一致性学习来预测点对匹配概率。
- Result: 在KITTI、KITTI-360和3DMatch等数据集上实现了95%-97%、94%-97%和81.1%的内点率，显著提升了刚性配准性能。
- Conclusion: iMatcher通过可微的局部和全局一致性学习，在室内外不同场景下都表现出优异的鲁棒性和配准精度，达到了state-of-the-art水平。


### [11] [UltrON: Ultrasound Occupancy Networks](https://arxiv.org/abs/2509.08991)
*Magdalena Wysocki,Felix Duelmer,Ananya Bal,Nassir Navab,Mohammad Farid Azampour*

Main category: cs.CV

TL;DR: 提出UltrON方法，利用超声B模式图像的声学特征进行弱监督优化，改进3D形状重建，解决遮挡和视图依赖性问题

- Motivation: 传统基于SDF的隐式表示方法依赖精确标注，忽略了B模式图像中的丰富声学信息，且难以处理超声的视图依赖性和声影伪影问题
- Method: 采用基于占据率的表示方法，提出UltrON框架，利用B模式图像的声学特征进行弱监督优化，并设计新的损失函数补偿视图依赖性
- Result: UltrON能够缓解遮挡和稀疏标注的限制，提高几何一致性，并可泛化到相同解剖结构的不同形状
- Conclusion: 该方法为更准确的3D重建开辟了新途径，代码和数据集将开源


### [12] [Implicit Neural Representations of Intramyocardial Motion and Strain](https://arxiv.org/abs/2509.09004)
*Andrew Bell,Yan Kit Choi,Steffen Peterson,Andrew King,Muhummad Sohaib Nazir,Alistair Young*

Main category: cs.CV

TL;DR: 提出了一种基于隐式神经表示(INR)的方法，无需推理时优化即可预测连续左心室位移，在UK Biobank数据集上实现了最佳跟踪精度和应变测量精度，速度比最准确基线快380倍

- Motivation: 自动量化心脏标记MRI中的心肌运动和应变是一个重要但具有挑战性的任务，需要开发准确且可扩展的分析方法
- Method: 使用基于学习潜在码的条件隐式神经表示(INRs)来预测连续左心室位移，无需推理时优化
- Result: 在452个UK Biobank测试案例中，实现了最佳跟踪精度(2.14 mm RMSE)和最低的全局周向应变(2.86%)与径向应变(6.42%)组合误差，比最准确基线快380倍
- Conclusion: 基于INR的模型非常适合在大规模CMR数据集中进行准确且可扩展的心肌应变分析


### [13] [E-MLNet: Enhanced Mutual Learning for Universal Domain Adaptation with Sample-Specific Weighting](https://arxiv.org/abs/2509.09006)
*Samuel Felipe dos Santos,Tiago Agostinho de Almeida,Jurandy Almeida*

Main category: cs.CV

TL;DR: 提出了增强型互学习网络（E-MLNet），通过动态权重策略改进开放集熵最小化，在通用域自适应任务中显著提升性能

- Motivation: 现有的互学习网络（MLNet）对所有分类器一视同仁，导致学习信号被稀释，需要更精细的边界区分策略
- Method: E-MLNet集成动态权重策略到开放集熵最小化（OEM）中，利用闭集分类器的预测结果，针对每个目标样本聚焦于最相关的类别边界
- Result: 在四个基准测试（Office-31、Office-Home、VisDA-2017、ImageCLEF）上取得最佳平均H分数，在31个任务中22个开放部分DA设置和19个开放集DA设置中超越MLNet基线
- Conclusion: 动态权重策略有效提升了已知和未知类别的区分能力，证明了聚焦自适应策略的优越性


### [14] [COCO-Urdu: A Large-Scale Urdu Image-Caption Dataset with Multimodal Quality Estimation](https://arxiv.org/abs/2509.09014)
*Umair Hassan*

Main category: cs.CV

TL;DR: 提出了COCO-Urdu数据集，这是最大的公开乌尔都语图像字幕数据集，包含59,000张图片和319,000个高质量乌尔都语字幕，旨在解决乌尔都语在多模态研究中的资源匮乏问题。

- Motivation: 乌尔都语作为拥有2.5亿使用者的语言，在多模态和视觉语言研究中严重缺乏资源，现有模型主要基于高资源语言训练，存在语言偏见。缺乏大规模高质量数据集限制了乌尔都语系统的发展。
- Method: 从MS COCO数据集通过分层采样构建，使用SeamlessM4T v2进行翻译，并采用混合多模态质量评估框架（包括COMET-Kiwi翻译质量评估、CLIP视觉相似度、BERTScore语义一致性）进行验证，低质量字幕通过开源大语言模型迭代优化。
- Result: 构建了包含59,000张图片和319,000个乌尔都语字幕的大规模数据集，在BLEU、SacreBLEU和chrF基准测试中表现优异，是目前最大的公开乌尔都语字幕数据集。
- Conclusion: COCO-Urdu数据集和其质量评估管道的发布将减少多模态研究中的语言偏见，为包容性视觉语言系统奠定基础，促进乌尔都语在多模态领域的发展。


### [15] [VoxelFormer: Parameter-Efficient Multi-Subject Visual Decoding from fMRI](https://arxiv.org/abs/2509.09015)
*Chenqian Le,Yilin Zhao,Nikasadat Emami,Kushagra Yadav,Xujin "Chris" Liu,Xupeng Chen,Yao Wang*

Main category: cs.CV

TL;DR: VoxelFormer是一个轻量级transformer架构，通过多主体训练实现fMRI视觉解码，使用Token Merging Transformer进行高效体素压缩和Q-Former生成与CLIP图像嵌入对齐的神经表示。

- Motivation: 现有fMRI视觉解码方法大多依赖特定主体训练，限制了可扩展性和实际部署，需要开发支持多主体训练的高效方法。
- Method: 采用Token Merging Transformer (ToMer)进行体素压缩，结合查询驱动的Q-Former生成固定大小的神经表示，并与CLIP图像嵌入空间对齐。
- Result: 在7T自然场景数据集上，VoxelFormer在训练包含的主体上实现了有竞争力的检索性能，且参数量显著少于现有方法。
- Conclusion: token合并和基于查询的transformer是参数高效神经解码的有前景策略。


### [16] [Integrating Anatomical Priors into a Causal Diffusion Model](https://arxiv.org/abs/2509.09054)
*Binxu Li,Wei Peng,Mingjie Li,Ehsan Adeli,Kilian M. Pohl*

Main category: cs.CV

TL;DR: PCGM是一种新的3D脑MRI反事实生成方法，通过概率图模型整合解剖约束，使用ControlNet编码空间掩码来指导扩散模型，生成高质量且解剖合理的脑部MRI图像，能够复现疾病对皮层区域的细微影响。

- Motivation: 现有反事实生成模型缺乏明确的解剖学归纳偏置，难以保持医学相关的细微局部变异，导致生成的脑部MRI图像解剖学合理性不足。
- Method: 提出概率因果图模型(PCGM)，通过概率图模块捕获解剖约束并转换为空间二值掩码，使用3D ControlNet编码掩码来约束新的反事实去噪UNet，最终通过3D扩散解码器生成高质量脑MRI。
- Result: 在多个数据集上的实验表明，PCGM生成的脑部MRI质量优于多个基线方法，且首次证明从反事实图像提取的脑部测量能够复现神经科学文献中报道的疾病对皮层区域的细微影响。
- Conclusion: PCGM在合成MRI用于研究细微形态差异方面取得了重要里程碑，为脑MRI研究提供了高质量的图像合成工具。


### [17] [Enhancing 3D Medical Image Understanding with Pretraining Aided by 2D Multimodal Large Language Models](https://arxiv.org/abs/2509.09064)
*Qiuhui Chen,Xuancheng Yao,Huping Ye,Yi Hong*

Main category: cs.CV

TL;DR: Med3DInsight是一个创新的3D医学图像预训练框架，通过整合3D图像编码器和2D多模态大语言模型，无需人工标注即可实现深度语义理解，在分割和分类任务上达到最先进性能。

- Motivation: 现有3D医学图像的自监督学习方法缺乏深度语义理解能力，而多模态大语言模型通过文本描述增强图像理解的能力为改进3D医学图像理解提供了新思路。
- Method: 提出Med3DInsight框架，集成3D图像编码器和2D MLLMs，采用平面切片感知transformer模块和基于部分最优传输的对齐方法，对LLM生成内容中的噪声具有更强容忍度。
- Result: 在CT和MRI等多种公共数据集的分割和分类任务上表现出最先进的性能，超越了当前的自监督学习方法。
- Conclusion: Med3DInsight为无需人工标注的可扩展多模态3D医学表示学习提供了新范式，可无缝集成到现有3D医学图像理解网络中提升性能。


### [18] [Improvement of Human-Object Interaction Action Recognition Using Scene Information and Multi-Task Learning Approach](https://arxiv.org/abs/2509.09067)
*Hesham M. Shehata,Mohammad Abdolrahmani*

Main category: cs.CV

TL;DR: 通过多任务学习方法结合环境中固定物体信息，提高了人体动作识别的性能，特别是在人物交互检测方面

- Motivation: 现有图卷积神经网络(GCNs)在人体动作识别中表现优异，但在人物交互检测方面效果不佳，缺乏有效的场景信息表征和适当的学习架构
- Method: 采用多任务学习方法，考虑环境中固定物体信息，并使用交互区域信息，通过收集公共环境的实际数据构建数据集
- Result: 在人体与固定物体交互和非交互动作识别中达到了99.25%的准确率，超过仅使用人体骨架姿势的基准模型的性能2.75%
- Conclusion: 多任务学习结合交互区域信息能够有效提升人体动作识别的性能，特别是在处理人物交互场景时显示出显著优势


### [19] [IRDFusion: Iterative Relation-Map Difference guided Feature Fusion for Multispectral Object Detection](https://arxiv.org/abs/2509.09085)
*Jifeng Shen,Haibo Zhan,Xin Zuo,Heng Fan,Xiaohui Yuan,Jun Li,Wankou Yang*

Main category: cs.CV

TL;DR: 提出IRDFusion框架，通过迭代关系映射差分导向的特征融合机制，实现了超过现有方法的多谱对象检测性能

- Motivation: 解决当前多谱对象检测方法在特征融合过程中存在多余背景和噪声的问题，这限制了感知性能
- Method: 设计了互相特征精炼模块(MFRM)和差分特征反馈模块(DFFM)，构建IRDFusion框架。MFRM通过建模内模和模态间关系来提升特征表征，DFFM动态计算模态间差分特征作为导向信号并反馈给MFRM
- Result: 在FLIR、LLVIP和M^3FD数据集上达到了最先进的性能，在多种具有挑战性的场景中都一致超过现有方法
- Conclusion: IRDFusion通过迭代反馈渐进地放大显著关系信号同时压制特征噪声，实现了高质量的跨模态融合，显示了其稳健性和有效性


### [20] [SQAP-VLA: A Synergistic Quantization-Aware Pruning Framework for High-Performance Vision-Language-Action Models](https://arxiv.org/abs/2509.09090)
*Hengyu Fang,Yijiang Liu,Yuan Du,Li Du,Huanrui Yang*

Main category: cs.CV

TL;DR: SQAP-VLA是一个无需训练的结构化VLA推理加速框架，首次同时实现最先进的量化和token剪枝，解决了两者不兼容的问题，获得1.93倍加速和4.5%性能提升

- Motivation: 现有的VLA模型计算和内存成本过高，阻碍实际部署。现有的压缩方法要么只做量化要么只做token剪枝，但两者存在不兼容问题，无法同时实现整体效率提升
- Method: 提出量化感知的token剪枝标准，在激进量化模型上工作，同时改进量化器设计以增强剪枝效果。通过协同设计量化和token剪枝流程来克服不兼容性
- Result: 在标准VLA模型上实现显著计算效率提升和推理加速，同时保持核心模型性能，获得1.93倍加速和最高4.5%的平均成功率提升
- Conclusion: SQAP-VLA框架成功解决了VLA模型中量化和token剪枝的不兼容问题，为VLA模型的实用部署提供了有效的加速解决方案


### [21] [S-BEVLoc: BEV-based Self-supervised Framework for Large-scale LiDAR Global Localization](https://arxiv.org/abs/2509.09110)
*Chenghao Zhang,Lun Luo,Si-Yuan Cao,Xiaokai Bai,Yuncheng Jin,Zhu Yu,Beinan Yu,Yisen Wang,Hui-Liang Shen*

Main category: cs.CV

TL;DR: S-BEVLoc是一种基于鸟瞰图的自监督LiDAR全局定位框架，无需地面真实位姿，通过地理距离构建训练三元组，在KITTI和NCLT数据集上达到最先进性能。

- Motivation: 当前LiDAR全局定位方法依赖GPS或SLAM里程计获取的地面真实位姿进行监督训练，但高精度位姿获取成本高昂且费时。需要开发无需地面真实位姿的自监督方法。
- Method: 提出S-BEVLoc自监督框架：1）利用已知地理距离构建BEV图像三元组；2）使用CNN提取局部特征；3）采用NetVLAD聚合全局描述符；4）引入SoftCos损失函数增强三元组学习。
- Result: 在KITTI和NCLT大规模数据集上，S-BEVLoc在位置识别、闭环检测和全局定位任务中均达到最先进性能，同时具有比监督方法更好的可扩展性。
- Conclusion: S-BEVLoc成功证明了自监督方法在LiDAR全局定位中的有效性，无需地面真实位姿监督，为大规模应用提供了更经济高效的解决方案。


### [22] [FPI-Det: a face--phone Interaction Dataset for phone-use detection and understanding](https://arxiv.org/abs/2509.09111)
*Jianqin Gao,Tianqi Wang,Yu Zhang,Yishu Zhang,Chenyuan Wang,Allan Dong,Zihao Wang*

Main category: cs.CV

TL;DR: 提出了FPI-Det数据集，包含22,879张图像，用于检测人脸和手机之间的交互关系，填补了现有基准测试在细粒度人机交互检测方面的空白。

- Motivation: 移动设备的广泛使用给安全监控、工作效率评估和注意力管理带来了新挑战，需要系统不仅能识别物体，还要理解行为上下文，推理人脸、手和设备之间的关系。现有通用基准无法充分捕捉这种细粒度的人机交互。
- Method: 构建包含22,879张图像的数据集，涵盖工作场所、教育、交通和公共场景，具有极端尺度变化、频繁遮挡和多样化拍摄条件。评估了代表性的YOLO和DETR检测器。
- Result: 提供了基线结果，并分析了在不同物体大小、遮挡级别和环境下的性能表现。
- Conclusion: FPI-Det数据集为解决细粒度人机交互检测问题提供了重要资源，源代码和数据集已公开可用。


### [23] [Zero-shot Hierarchical Plant Segmentation via Foundation Segmentation Models and Text-to-image Attention](https://arxiv.org/abs/2509.09116)
*Junhao Xing,Ryohei Miyakawa,Yang Yang,Xinpeng Liu,Risa Shinoda,Hiroaki Santo,Yosuke Toda,Fumio Okura*

Main category: cs.CV

TL;DR: ZeroPlantSeg是一个零样本分割方法，用于从顶视图图像中分割莲座状植物个体，无需训练即可实现多物种、多生长阶段的植物个体分割。

- Motivation: 基础分割模型能够零样本提取叶片实例，但分割包含多个重叠叶片的完整植物个体仍然具有挑战性，通常需要物种特定的标注数据集和大量人工劳动。
- Method: 结合基础分割模型提取叶片实例和视觉语言模型推理植物结构，无需额外训练即可提取植物个体。
- Result: 在多个植物物种、生长阶段和拍摄环境的数据集上评估表明，该方法超越了现有零样本方法，并比监督方法具有更好的跨域性能。
- Conclusion: ZeroPlantSeg提供了一种有效的零样本植物个体分割解决方案，减少了人工标注需求，具有良好的泛化能力。


### [24] [Gradient-Attention Guided Dual-Masking Synergetic Framework for Robust Text-based Person Retrieval](https://arxiv.org/abs/2509.09118)
*Tianlu Zheng,Yifan Zhang,Xiang An,Ziyong Feng,Kaicheng Yang,Qichuan Ding*

Main category: cs.CV

TL;DR: 该论文针对CLIP在人物表征学习中的局限性，提出了数据构建和模型架构的协同改进方案，包括构建WebPerson数据集和GA-DMS框架，在多个基准测试中达到最先进性能。

- Motivation: CLIP在人物表征学习中面临两个关键挑战：缺乏大规模标注的人物中心视觉语言数据，以及全局对比学习难以保持细粒度匹配所需的判别性局部特征且对噪声文本标记敏感。
- Method: 1) 开发基于MLLM上下文学习能力的噪声抵抗数据构建管道，自动过滤和标注网络图像，构建包含500万高质量人物中心图像-文本对的WebPerson数据集；2) 提出GA-DMS框架，通过梯度注意力相似性评分自适应掩码噪声文本标记，并加入掩码标记预测目标以增强细粒度语义表征学习。
- Result: 大量实验表明，GA-DMS在多个基准测试中实现了最先进的性能。
- Conclusion: 通过数据构建和模型架构的协同改进，成功提升了CLIP在人物表征学习中的性能，解决了数据稀缺和细粒度特征保持的问题。


### [25] [ALL-PET: A Low-resource and Low-shot PET Foundation Model in the Projection Domain](https://arxiv.org/abs/2509.09130)
*Bin Huang,Kang Chen,Bingxuan Li,Huafeng Liu,Qiegen Liu*

Main category: cs.CV

TL;DR: ALL-PET是一个低资源、低样本的PET投影域基础模型，通过潜在扩散模型和三项创新技术，仅用500个样本就能实现高质量sinogram生成，并在多种PET任务中表现出色。

- Motivation: 解决PET成像中标记数据有限和计算资源不足的问题，克服数据稀缺和效率限制，构建大规模基础模型。
- Method: 使用潜在扩散模型(LDM)，包含三项关键技术：1) Radon掩码增强策略(RMAS)生成多样化训练样本；2) 正负掩码约束嵌入几何一致性；3) 透明医学注意力(TMA)机制增强病灶相关区域。
- Result: 仅用500个样本就实现了高质量的sinogram生成，性能可与使用更大数据集训练的模型相媲美，内存使用低于24GB，在低剂量重建、衰减校正、延迟帧预测和示踪剂分离等任务中表现良好。
- Conclusion: ALL-PET成功解决了PET成像中的数据稀缺和资源限制问题，提供了一个高效、可解释且任务自适应的基础模型解决方案，具有很好的泛化能力。


### [26] [Noise-Robust Topology Estimation of 2D Image Data via Neural Networks and Persistent Homology](https://arxiv.org/abs/2509.09140)
*Dylan Peek,Matthew P. Skerritt,Stephan Chalup*

Main category: cs.CV

TL;DR: 神经网络在噪声环境下预测Betti数方面优于持久同调方法，能够通过学习训练数据中的上下文和几何先验来提升噪声鲁棒性

- Motivation: 比较持久同调(PH)和人工神经网络(ANN)这两种从数据推断拓扑结构的不同方法在噪声鲁棒性方面的表现
- Method: 使用基于立方复形和带符号欧几里得距离变换(SEDT)的PH流程与监督神经网络进行对比，在一个合成数据集和两个真实数据集上测试预测2D二值图像Betti数的性能
- Result: ANN在噪声条件下能够超越PH方法，表现出更好的性能
- Conclusion: 尽管仍处于发展阶段，但使用ANN进行拓扑估计为在结构噪声条件下提供了一种有吸引力的PH替代方案


### [27] [Objectness Similarity: Capturing Object-Level Fidelity in 3D Scene Evaluation](https://arxiv.org/abs/2509.09143)
*Yuiko Uchida,Ren Togo,Keisuke Maeda,Takahiro Ogawa,Miki Haseyama*

Main category: cs.CV

TL;DR: OSIM是一个新的3D场景评估指标，专注于对象级别的感知评估，比现有指标更符合人类视觉感知。

- Motivation: 现有指标主要评估整体图像质量，与人类感知存在差异。人类对3D场景的识别主要基于对单个对象的注意力。
- Method: 利用物体检测模型及其特征表示来量化场景中每个对象的"对象性"，进行以对象为中心的评估。
- Result: 用户研究表明OSIM比现有指标更符合人类感知，并通过标准化实验重新评估了最新的3D重建和生成模型。
- Conclusion: OSIM提供了一个更符合人类感知的3D场景评估框架，有助于明确该领域的技术进展。


### [28] [Video Understanding by Design: How Datasets Shape Architectures and Insights](https://arxiv.org/abs/2509.09151)
*Lei Wang,Piotr Koniusz,Yongsheng Gao*

Main category: cs.CV

TL;DR: 本调查首次采用数据集驱动视角，分析视频理解架构如何响应数据集的结构性压力（运动复杂度、时间跨度、层次组合和多模态丰富性），为模型设计提供实用指导。

- Motivation: 现有调查主要按任务或模型家族分类，忽视了数据集对架构演化的结构性引导作用。需要从数据集驱动的角度重新解读模型发展历程。
- Method: 采用数据集驱动视角，分析运动复杂度、时间跨度、层次组合和多模态丰富性等数据集特征如何为模型施加归纳偏置，并重新解读从双流网络、3D CNN到序列模型、Transformer和多模态基础模型的发展历程。
- Result: 建立了数据集、归纳偏置和架构的统一框架，将重要里程碑模型重新解释为对数据集驱动压力的具体响应。
- Conclusion: 该调查不仅提供了全面的回顾性分析，还为推进通用视频理解提供了规范性路线图，指导模型设计与数据集不变性的对齐，同时平衡可扩展性和任务需求。


### [29] [OCELOT 2023: Cell Detection from Cell-Tissue Interaction Challenge](https://arxiv.org/abs/2509.09153)
*JaeWoong Shin,Jeongun Ryu,Aaron Valero Puche,Jinhee Lee,Biagio Brattoli,Wonkyung Jung,Soo Ick Cho,Kyunghyun Paeng,Chan-Young Ock,Donggeun Yoo,Zhaoyang Li,Wangkai Li,Huayu Mai,Joshua Millward,Zhen He,Aiden Nibali,Lydia Anette Schoenpflug,Viktor Hendrik Koelzer,Xu Shuoyu,Ji Zheng,Hu Bin,Yu-Wen Lo,Ching-Hui Yang,Sérgio Pereira*

Main category: cs.CV

TL;DR: OCELOT 2023挑战赛通过提供多尺度重叠细胞和组织标注数据集，验证了细胞-组织相互作用理解对病理图像分析的重要性，最佳模型相比仅细胞检测基线F1分数提升7.99。

- Motivation: 解决现有深度学习细胞检测模型无法模拟病理学家在不同放大倍数下观察组织形态和细胞细节的交互行为，缺乏多尺度标注数据集的问题。
- Method: 创建包含6个器官、673对标注的TCGA全切片图像数据集，组织挑战赛让参与者开发能理解细胞-组织关系的模型。
- Result: 参赛模型显著提升了对细胞-组织关系的理解，最佳模型在测试集上相比仅细胞检测基线F1分数提高了7.99。
- Conclusion: 多尺度语义整合对实现人类水平性能至关重要，传统仅细胞检测方法需要改进以纳入细胞-组织相互作用。


### [30] [RT-DETR++ for UAV Object Detection](https://arxiv.org/abs/2509.09157)
*Yuan Shufang*

Main category: cs.CV

TL;DR: RT-DETR++通过改进RT-DETR模型的编码器，引入通道门控注意力上采样/下采样机制和CSP-PAC特征融合技术，在无人机图像小目标检测中实现了优越性能，同时保持实时检测速度。

- Motivation: 无人机图像中的目标检测面临小目标密集、尺度变化大、遮挡严重等挑战，需要改进现有模型来提升检测性能。
- Method: 1. 引入通道门控注意力机制的上采样/下采样(AU/AD)双路径系统，减少特征层传播误差并保留细节；2. 在特征融合中采用CSP-PAC技术，使用并行空洞卷积在同一层处理局部和上下文信息，促进多尺度特征融合。
- Result: 新设计的neck结构在小目标和密集目标检测方面表现出优越性能，模型保持实时检测速度且未增加计算复杂度。
- Conclusion: 本研究为实时检测系统中的特征编码设计提供了有效方法，解决了无人机图像目标检测的关键挑战。


### [31] [A Knowledge Noise Mitigation Framework for Knowledge-based Visual Question Answering](https://arxiv.org/abs/2509.09159)
*Zhiyue Liu,Sihang Liu,Jinyuan Liu,Xinru Zhang*

Main category: cs.CV

TL;DR: 知识基础视觉问答中的知识噢余问题解决方案：通过低噢音查询、大模型知识提取和选择性知识集成策略，提高知识相关性并降低噢余干扰

- Motivation: 现有KB-VQA方法直接使用查询知识导致知识噢余和噢音，影响回答准确性
- Method: 1）从图像-问题中提取关键部分构建低噢音查询 2）使用大模型识别和提取有益回答的知识段落 3）采用选择性知识集成策略，仅在模型信心不足时使用知识
- Result: 实验结果显示该框架在知识基础视觉问答任务上超越了最先进方法
- Conclusion: 该训练免费框架能够有效减少知识噢余干扰，提高知识相关性，获得更准确的回答


### [32] [CWSSNet: Hyperspectral Image Classification Enhanced by Wavelet Domain Convolution](https://arxiv.org/abs/2509.09163)
*Yulin Tong,Fengzong Zhang,Haiqin Cheng*

Main category: cs.CV

TL;DR: 本研究提出CWSSNet分类框架，结合3D光谱空间特征和小波卷积，有效解决高光谱图像特征冗余问题，在江西余干县地物分类中取得优异性能

- Motivation: 高光谱遥感技术虽在林业生态和精准农业等领域有重要应用价值，但其多波段、高维度和光谱混合特性导致特征冗余问题突出，需要更精细的地物分类方法
- Method: 使用ZY1F卫星高光谱图像数据，提出CWSSNet框架，集成3D光谱空间特征和小波卷积，采用多尺度卷积注意力模块融合多模态信息，引入小波域多波段分解和卷积操作
- Result: 在余干县实验中达到mIoU 74.50%、mAcc 82.73%、mF1 84.94%，在水体、植被和裸地分类中获得最高IoU，70%训练集比例下训练时间增加有限且分类效果接近最优
- Conclusion: CWSSNet模型具有良好的鲁棒性，在小样本训练条件下保持可靠性能，突破了传统方法的分类性能瓶颈


### [33] [Bridging the Gap Between Ideal and Real-world Evaluation: Benchmarking AI-Generated Image Detection in Challenging Scenarios](https://arxiv.org/abs/2509.09172)
*Chunxiao Li,Xiaoxiao Wang,Meiling Li,Boming Miao,Peng Sun,Yunjian Zhang,Xiangyang Ji,Yao Zhu*

Main category: cs.CV

TL;DR: RRDataset是一个用于评估AI生成图像检测模型在真实世界复杂条件下的综合数据集，涵盖场景泛化、网络传输鲁棒性和重数字化鲁棒性三个维度，揭示了当前检测方法的局限性。

- Motivation: 随着生成模型的快速发展，高度逼真的图像合成对数字安全和媒体可信度提出了新挑战。现有AI生成图像检测方法在复杂真实世界条件下的性能评估存在研究空白。
- Method: 构建RRDataset数据集，包含7个主要场景的高质量图像，测试图像在网络传输和重数字化处理后的检测性能。对17个检测器和10个视觉语言模型进行基准测试，并进行了192人参与的大规模人类研究。
- Result: 基准测试结果揭示了当前AI检测方法在真实世界条件下的局限性，强调了借鉴人类适应能力开发更鲁棒检测算法的重要性。
- Conclusion: 该研究强调了在真实世界复杂条件下评估AI生成图像检测的重要性，并展示了人类少样本学习能力在检测任务中的优势，为开发更鲁棒的检测算法提供了方向。


### [34] [Dark-ISP: Enhancing RAW Image Processing for Low-Light Object Detection](https://arxiv.org/abs/2509.09183)
*Jiasheng Guo,Xin Gao,Yuxiang Yan,Guanghao Li,Jian Pu*

Main category: cs.CV

TL;DR: 轻量级自适应Dark-ISP插件，直接处理Bayer RAW图像，通过跨模块自成增强机制优化任务驱动的原始图像处理流程，在低光环境物体检测中达到更优性能。

- Motivation: 现有方法在低光物体检测中或使用有信息损失的RAW-RGB图像，或采用复杂框架，需要轻量级且高效的解决方案来直接处理Bayer RAW图像以获得更好的检测性能。
- Method: 将传统ISP流水线解构为线性传感器校准和非线性音调映射子模块，改造为可微分组件通过任务驱动损失优化。每个模块具备内容感知适应性和物理信息先验知识，并设计自成增强机制促进子模块合作。
- Result: 在三个RAW图像数据集上进行广泛实验，方法在具有挑战性的低光环境中超越了现有的RGB和RAW基于检测方法，以最少的参数量实现了更优异的结果。
- Conclusion: Dark-ISP提供了一种轻量级且自适应的方案，能够直接处理Bayer RAW图像并通过任务驱动的优化提高低光环境下的物体检测性能，为实际应用提供了有效解决方案。


### [35] [VQualA 2025 Challenge on Visual Quality Comparison for Large Multimodal Models: Methods and Results](https://arxiv.org/abs/2509.09190)
*Hanwei Zhu,Haoning Wu,Zicheng Zhang,Lingyu Zhu,Yixuan Li,Peilin Chen,Shiqi Wang,Chris Wei Zhou,Linhan Cao,Wei Sun,Xiangyang Zhu,Weixia Zhang,Yucheng Zhu,Jing Liu,Dandan Zhu,Guangtao Zhai,Xiongkuo Min,Zhichao Zhang,Xinyue Li,Shubo Xu,Anh Dao,Yifan Li,Hongyuan Yu,Jiaojiao Yi,Yiding Tian,Yupeng Wu,Feiran Sun,Lijuan Liao,Song Jiang*

Main category: cs.CV

TL;DR: VQualA 2025挑战赛评估大型多模态模型在视觉质量比较任务上的表现，通过新颖的基准测试和全面评估协议推动开放域视觉质量推理研究

- Motivation: 评估和提升最先进的大型多模态模型在跨多张图像进行开放端和详细视觉质量差异推理的能力
- Method: 创建包含数千个从粗粒度到细粒度视觉质量比较任务的新基准，涵盖单图像、图像对和多图像组，采用2AFC二元偏好和多选题等全面评估协议
- Result: 约100名参与者提交作品，5个模型展示了指令调优LMM在质量评估方面的新兴能力
- Conclusion: 该挑战赛标志着向开放域视觉质量推理和比较迈出重要一步，为未来可解释和人类对齐的质量评估系统研究提供了催化剂


### [36] [MGTraj: Multi-Granularity Goal-Guided Human Trajectory Prediction with Recursive Refinement Network](https://arxiv.org/abs/2509.09200)
*Ge Sun,Jun Ma*

Main category: cs.CV

TL;DR: MGTraj是一个多粒度目标引导的人类轨迹预测模型，通过从粗到细的递归编码和Transformer精炼网络，在多个数据集上实现了最先进的性能。

- Motivation: 现有目标引导方法在粗粒度目标预测和细粒度轨迹补全之间存在中间粒度未被充分利用的问题，多粒度建模可以更好地捕捉人类动态和运动模式。
- Method: 提出MGTraj模型，递归地从粗到细粒度编码轨迹提案，使用基于Transformer的递归精炼网络(RRN)捕获特征并预测渐进式精炼，采用权重共享策略整合不同粒度特征，并使用速度预测作为辅助任务。
- Result: 在EHT/UCY和Stanford Drone数据集上的综合实验表明，MGTraj优于基线方法，在目标引导方法中达到了最先进的性能。
- Conclusion: 多粒度建模方法有效提升了人类轨迹预测的准确性，MGTraj模型通过递归精炼和跨粒度特征整合实现了优异的性能表现。


### [37] [Medverse: A Universal Model for Full-Resolution 3D Medical Image Segmentation, Transformation and Enhancement](https://arxiv.org/abs/2509.09232)
*Jiesi Hu,Jianfeng Cao,Yanwu Yang,Chenfei Ye,Yixuan Zhang,Hanyang Peng,Ting Ma*

Main category: cs.CV

TL;DR: Medverse是一个通用的3D医学影像上下文学习模型，通过多尺度自回归框架和块状交叉注意力模块，在22个数据集上训练，实现了跨任务、器官和模态的高保真预测和全局解剖理解。

- Motivation: 当前医学影像的上下文学习模型无法同时实现高保真预测和全局解剖理解，且缺乏跨多样任务和解剖区域的统一模型，限制了上下文学习在医学影像中的潜力。
- Method: 采用多尺度自回归上下文学习框架，从粗到细逐步细化预测，生成全分辨率体积输出；提出块状交叉注意力模块，在保持计算效率的同时促进上下文与目标输入之间的长程交互。
- Result: 在未见过的临床中心、器官、物种和成像模态的测试数据集上，Medverse显著优于现有上下文学习基线方法。
- Conclusion: Medverse为医学影像上下文学习建立了新范式，展示了在多样化医学影像任务中实现高保真预测和全局解剖理解的可行性。


### [38] [CoAtNeXt:An Attention-Enhanced ConvNeXtV2-Transformer Hybrid Model for Gastric Tissue Classification](https://arxiv.org/abs/2509.09242)
*Mustafa Yurdakul,Sakir Tasdemir*

Main category: cs.CV

TL;DR: 基于CoAtNet改进的新型混合模型CoAtNeXt，通过替换MBConv层为ConvNeXtV2块和集成CBAM注意力机制，在胃组织病理图像分类中实现了突出的性能，超越了多个CNN和ViT模型。

- Motivation: 胃疾病的早期诊断至关重要，但传统的病理组织学检查完全依靠手工操作，工作强度大且存在评估差异。缺乏标准化程序导致一致性不高，必须开发自动化、可靠和高效的胃组织分析方法。
- Method: 提出CoAtNeXt混合模型，在CoAtNet基础上用改进的ConvNeXtV2块替换MBConv层，并集成卷积块注意力模块(CBAM)以改善局部特征提取。通过网络结构缩放实现计算效率和分类性能的平衡。在两个公开数据集上评估，与20个CNN和ViT模型进行比较。
- Result: 在HMU-GC-HE-30K八分类数据集上：准确率96.47%、精度96.60%、召回率96.47%、F1分数96.45%、AUC 99.89%。在GasHisSDB二分类数据集上：准确率98.29%、精度98.07%、召回率98.41%、F1分数98.23%、AUC 99.90%。性能超过所有测试的CNN和ViT模型，且超越了文献中的以往研究。
- Conclusion: CoAtNeXt是一种坚固的胃组织病理图像分类架构，在二分类和多分类任务中都表现优异。该模型有潜力协助病理医生提高诊断准确性和减轻工作负荷。


### [39] [Towards Better Dental AI: A Multimodal Benchmark and Instruction Dataset for Panoramic X-ray Analysis](https://arxiv.org/abs/2509.09254)
*Jing Hao,Yuxuan Fan,Yanpeng Sun,Kaixin Guo,Lizhuo Lin,Jinrong Yang,Qi Yong H. Ai,Lun M. Wong,Hao Tang,Kuo Feng Hung*

Main category: cs.CV

TL;DR: 提出了首个针对全景X射线影像的大规模多模态指令数据集MMOral和评估基准MMOral-Bench，并基于此开发了OralGPT模型，在牙科领域取得了显著性能提升

- Motivation: 现有大型视觉语言模型在牙科等专业领域的有效性尚未充分探索，特别是全景X射线影像由于解剖结构密集和病理线索细微，现有医疗基准无法充分评估
- Method: 构建包含20,563张标注图像和130万指令实例的MMOral数据集，涵盖属性提取、报告生成、视觉问答和图像对话等任务类型；基于Qwen2.5-VL-7B进行监督微调开发OralGPT模型
- Result: 评估64个大型视觉语言模型发现最佳模型GPT-4o仅达到41.45%准确率；OralGPT经过单轮微调后性能提升24.73%
- Conclusion: MMOral数据集和OralGPT模型为智能牙科发展提供了重要基础，有望推动牙科领域多模态AI系统的临床应用


### [40] [DATE: Dynamic Absolute Time Enhancement for Long Video Understanding](https://arxiv.org/abs/2509.09263)
*Chao Yuan,Yang Yang,Yehui Yang,Zach Cheng*

Main category: cs.CV

TL;DR: 提出DATE方法，通过时间戳注入和语义引导的时间感知采样策略，增强多模态大语言模型的长视频时间理解能力

- Motivation: 现有方法采用均匀帧采样和隐式位置编码，难以处理长视频中的长距离依赖关系，导致关键信息丢失和时间理解能力下降
- Method: 时间戳注入机制(TIM)将视频帧嵌入与文本时间戳交错构建连续时间参考系统；时间感知相似性采样(TASS)将视频采样重新定义为视觉-语言检索任务，采用两阶段算法确保语义相关性和时间覆盖
- Result: 在小时级长视频基准测试中，7B和72B模型均达到最先进性能，7B模型在某些基准上甚至超越了许多72B模型
- Conclusion: DATE方法通过显式时间建模和语义引导采样，显著提升了多模态大语言模型的长视频时间理解和事件定位能力


### [41] [Unified Start, Personalized End: Progressive Pruning for Efficient 3D Medical Image Segmentation](https://arxiv.org/abs/2509.09267)
*Linhao Li,Yiwen Ye,Ziyang Chen,Yong Xia*

Main category: cs.CV

TL;DR: PSP-Seg是一种渐进式剪枝框架，通过块级剪枝和功能解耦损失实现动态高效的3D医学图像分割，在保持性能的同时大幅降低资源消耗。

- Motivation: 解决3D医学图像分割资源消耗大、现有高效模型静态设计缺乏适应性的问题，需要一种能平衡性能与效率的动态方法。
- Method: 从冗余模型开始，通过块级剪枝和功能解耦损失迭代剪枝冗余模块，实现模型动态优化。
- Result: 轻量版PSP-Seg-S性能与nnU-Net相当，GPU内存减少42-45%，训练时间减少29-48%，参数量减少83-87%。
- Conclusion: PSP-Seg是成本效益高且性能优异的替代方案，具有广泛的临床应用潜力。


### [42] [Visual Programmability: A Guide for Code-as-Thought in Chart Understanding](https://arxiv.org/abs/2509.09286)
*Bohao Tang,Yan Ma,Fei Zhang,Jiadi Su,Ethan Chern,Zhulin Hu,Zhixin Wang,Pengfei Liu,Ya Zhang*

Main category: cs.CV

TL;DR: 通过代码作为思维(CaT)方法，使用可验证的符号格式表示图表信息，并通过学习视觉可编程性来动态选择代码路径或直接视觉推理路径

- Motivation: 解决现有图表理解方法的局限性：外部工具方法弱点多且受限于预定工具集，而专门模型通常采用单一的文本链式思维策略，中间步骤难以验证
- Method: 提出视觉可编程性概念，构建适配框架，让VLM学习在CaT路径和直接视觉推理路径之间选择，使用双重奖励系统训练选择策略
- Result: 在多样化的图表理解测试集上展现出强大且稳健的性能
- Conclusion: VLMs不仅可以被教会如何推理，还可以学习如何推理，动态选择每个任务的最优推理路径


### [43] [Modality-Agnostic Input Channels Enable Segmentation of Brain lesions in Multimodal MRI with Sequences Unavailable During Training](https://arxiv.org/abs/2509.09290)
*Anthony P. Addison,Felix Wagner,Wentian Xu,Natalie Voets,Konstantinos Kamnitsas*

Main category: cs.CV

TL;DR: 通过添加模态无关输入通道和人工MRI模态增强技术，使U-net能够处理训练时未见的多模态脑部MRI数据，同时保持对已见模态的分割性能。

- Motivation: 解决现有多模态脑部MRI分割模型仅能处理固定模态组合，无法有效处理推理时遇到的新模态或异构模态组合的问题。
- Method: 在U-net架构中集成模态无关输入通道和模态特异输入通道，通过人工MRI模态增强技术训练模态无关组件，同时维持实际解剖学整体性。
- Result: 在5种脑部病理类型（脑冲、脑瘤、脱骨骤伤、多发硬化和白质高强度）和8种MRI模态的8个数据库中验证，方法能够有效处理训练时见过的模态，同时通过新模态改善分割效果。
- Conclusion: 简单的架构改进能够使分割模型具备处理异构多模态MRI数据的能力，为临床应用提供了更灵活的工具。


### [44] [Model-Agnostic Open-Set Air-to-Air Visual Object Detection for Reliable UAV Perception](https://arxiv.org/abs/2509.09297)
*Spyridon Loukovitis,Anastasios Arsenos,Vasileios Karampinis,Athanasios Voulodimos*

Main category: cs.CV

TL;DR: 提出了一种针对嵌入式检测器的模型无关开放集检测框架，通过熵建模估计语义不确定性，结合谱归一化和温度缩放来增强开放集判别能力，在无人机空对空目标检测中显著提升性能。

- Motivation: 传统闭集检测器在域偏移和飞行数据损坏情况下性能显著下降，对安全关键应用构成风险，需要开发能够处理未知对象拒绝并保持鲁棒性的开放集检测方法。
- Method: 基于嵌入空间的熵建模来估计语义不确定性，采用谱归一化和温度缩放技术增强开放集判别能力，专门设计用于嵌入式检测器的模型无关框架。
- Result: 在AOT空中基准测试和实际飞行测试中验证，相比标准YOLO检测器获得高达10%的相对AUROC增益，背景拒绝进一步增强了鲁棒性而不影响检测精度。
- Conclusion: 该方法特别适用于动态空对空环境中的可靠无人机感知，为开放集检测提供了有效的解决方案，在真实世界条件下表现出优异的性能。


### [45] [Learning Object-Centric Representations in SAR Images with Multi-Level Feature Fusion](https://arxiv.org/abs/2509.09298)
*Oh-Tae Jang,Min-Gon Cho,Kyung-Tae Kim*

Main category: cs.CV

TL;DR: SlotSAR是一个无需掩码标注的SAR图像目标表征解耦框架，通过融合多级特征和注意力机制，有效分离目标与背景杂波。

- Motivation: SAR图像中的复杂背景杂波（如地形反射和斑点噪声）与目标特征相似，导致模型提取纠缠或虚假特征，影响目标表征的清晰度。
- Method: 提出SlotSAR框架：1）从SARATR-X提取高级语义特征，从小波散射网络提取低级散射特征；2）设计多级slot注意力模块整合多级特征，增强slot表征的区分性。
- Result: 实验结果表明SlotSAR在SAR图像处理中达到最先进性能，相比现有OCL方法能更好地保持结构细节。
- Conclusion: SlotSAR通过多级特征融合和注意力机制，成功实现了SAR图像中目标与背景杂波的有效解耦，无需掩码标注即可获得清晰的目标表征。


### [46] [Can Multimodal LLMs See Materials Clearly? A Multimodal Benchmark on Materials Characterization](https://arxiv.org/abs/2509.09307)
*Zhengzhao Lai,Youbin Zheng,Zhenyang Cai,Haonan Lyu,Jinpu Yang,Hongqing Liang,Yan Hu,Benyou Wang*

Main category: cs.CV

TL;DR: 提出了第一个材料表征图像理解基准MatCha，包含1500个需要专业领域知识的问题，评估发现现有MLLM在真实材料表征场景中表现有限

- Motivation: 多模态大语言模型在材料科学中显示出潜力，但其对真实世界材料表征成像数据的理解能力尚未充分探索，需要建立专业基准来评估
- Method: 构建MatCha基准，涵盖材料研究的四个关键阶段和21个不同任务，包含1500个专家级问题，评估最先进MLLM的性能并与人类专家对比
- Result: 现有MLLM在MatCha上表现显著落后于人类专家，处理需要高级专业知识和复杂视觉感知的问题时性能下降，简单的少样本和思维链提示难以改善
- Conclusion: 现有MLLM对真实材料表征场景的适应性有限，MatCha基准将促进新材料发现和自主科学代理等领域的未来研究


### [47] [You Share Beliefs, I Adapt: Progressive Heterogeneous Collaborative Perception](https://arxiv.org/abs/2509.09310)
*Hao Si,Ehsan Javanmardi,Manabu Tsukada*

Main category: cs.CV

TL;DR: PHCP是一个无需联合训练的异构协作感知框架，通过推理时自训练适配器实现动态特征对齐，在少量无标签数据下达到与全数据集训练SOTA方法相当的性能

- Motivation: 解决现实世界中不同车辆模型异构性带来的协作感知挑战，避免传统方法需要联合训练或预先存储所有可能协作模型的不实用性
- Method: 将问题建模为少样本无监督域适应，在推理时通过自训练适配器动态对齐特征，无需标注数据和联合训练
- Result: 在OPV2V数据集上的广泛实验表明，PHCP在各种异构场景下均取得强劲性能，仅使用少量无标签数据即可达到与全数据集训练SOTA方法相当的表现
- Conclusion: PHCP成功证明了在推理时直接处理异构协作感知问题的可行性，为实际应用提供了更实用的解决方案


### [48] [Image Recognition with Vision and Language Embeddings of VLMs](https://arxiv.org/abs/2509.09311)
*Illia Volkov,Nikita Kisel,Klara Janouskova,Jiri Matas*

Main category: cs.CV

TL;DR: 这篇论文对视觉-语言模型在图像分类中的语言引导和纯视觉推理能力进行了综合评估，并提出了一种基于类别精度的简单融合方法来提升性能。

- Motivation: 虽然视觉-语言模型在零样本分类中表现强劲，但其纯视觉推理能力很少被深入研究，需要全面评估语言和视觉方式的补充性。
- Method: 使用多种双编码器VLMs模型（包括SigLIP 2和 RADIOv2.5），在ImageNet-1k数据集上进行标准化测试，分析提示设计、类别多样性、k-NN近邻数等因素影响，并提出基于类别精度的无学习融合方法。
- Result: 语言和视觉在图像分类中展现补充性强项，不同类别适合不同的推理方式。使用融合方法后分类性能得到显著提升。
- Conclusion: 视觉-语言模型的语言和视觉推理方式具有补充性，通过简单的融合策略可以有效利用这种补充性来提高图像分类的性能。


### [49] [Fine-Grained Customized Fashion Design with Image-into-Prompt benchmark and dataset from LMM](https://arxiv.org/abs/2509.09324)
*Hui Li,Yi You,Qiqi Chen,Bingfeng Zhang,George Q. Huang*

Main category: cs.CV

TL;DR: 提出了BUG工作流，利用大语言模型通过图像转提示技术自动创建和精细定制服装设计，解决了文本不确定性带来的定制困难问题

- Motivation: 当前生成式AI虽然能轻松将脑暴转化为时尚设计，但缺乏专业背景知识的终端用户在细粒度定制时仍受文本不确定性困扰
- Method: 提出Better Understanding Generation (BUG)工作流，结合LMM和image-into-prompt技术，从聊天中自动创建和精细定制服装设计
- Result: 构建了FashionEdit数据集模拟真实服装设计流程，在生成相似性、用户满意度和质量方面进行评估，证明了模型有效性
- Conclusion: 该框架释放了用户超越文字的创意潜力，降低了服装设计/编辑的门槛，无需进一步人工干预


### [50] [Exploring Pre-training Across Domains for Few-Shot Surgical Skill Assessment](https://arxiv.org/abs/2509.09327)
*Dimitrios Anastasiou,Razvan Caramalau,Nazir Sirajudeen,Matthew Boal,Philip Edwards,Justin Collins,John Kelly,Ashwin Sridhar,Maxine Tran,Faiz Mumtaz,Nevil Pavithran,Nader Francis,Danail Stoyanov,Evangelos B. Mazomenos*

Main category: cs.CV

TL;DR: 本文研究自监督预训练策略对手术技能评估(SSA)少样本学习性能的影响，发现领域相关的小数据集优于大规模但领域不匹配的数据集，且加入特定手术程序数据能显著提升性能

- Motivation: 手术技能评估需要专家标注，成本高昂且耗时。少样本学习提供了可扩展的解决方案，但预训练策略在SSA中尚未充分探索
- Method: 将SSA构建为少样本任务，评估不同预训练源在三种少样本设置下的表现。量化领域相似性，分析领域差距和特定手术程序数据对迁移性的影响
- Result: 领域相关的小数据集表现优于大规模不匹配数据集，在1-shot、2-shot和5-shot设置下分别达到60.16%、66.03%和73.65%的准确率。加入特定手术程序数据平均提升1.22%准确率和2.28% F1分数
- Conclusion: 预训练数据与目标任务的领域相关性比数据规模更重要，精心选择的领域相关数据结合特定程序数据能显著提升少样本SSA性能


### [51] [Classification of Driver Behaviour Using External Observation Techniques for Autonomous Vehicles](https://arxiv.org/abs/2509.09349)
*Ian Nell,Shane Gilroy*

Main category: cs.CV

TL;DR: 一种基于计算机视觉的驾驶员行为分类系统，通过实时物体跟踪和车道位置监测来识别分心驾驶和不安全行为

- Motivation: 人为错误是道路交通事故的主要原因，特别是分心驾驶和驾驶能力受限的情况，需要有效的监测方法
- Method: 使用YOLO物体检测模型和自定义车道估计算法，通过实时物体跟踪、横向位移分析和车道位置监测来识别不安全驾驶行为
- Result: 在多样化视频数据集上进行实验评估，证明了该框架在不同路面和环境条件下的可靠性和适应性
- Conclusion: 该视觉基于方法能够分析非连接车辆的行为，为道路安全监测提供了一种有效的解决方案


### [52] [Texture-aware Intrinsic Image Decomposition with Model- and Learning-based Priors](https://arxiv.org/abs/2509.09352)
*Xiaodong Wang,Zijun He,Xin Yuan*

Main category: cs.CV

TL;DR: 提出一种基于纹理引导正则化的单张图像本征图像分解方法，能够有效处理复杂光照和丰富纹理场景，生成高质量的本征反射层和阴影层。

- Motivation: 解决传统学习方法在复杂场景（空间变化光照和丰富纹理）中产生的纹理缺失和过度平滑问题，提升真实世界图像的本征分解质量。
- Method: 设计纹理引导正则化项，将分解问题转化为优化框架，通过推断光照和纹理信息来分离材质纹理和光照效果。
- Result: 结合新颖的纹理感知先验能够产生优于现有方法的结果，能够处理严重光照和丰富纹理情况。
- Conclusion: 纹理引导的正则化方法有效提升了本征图像分解在复杂真实场景中的性能，为高质量本征图像生成提供了新思路。


### [53] [Plug-and-play Diffusion Models for Image Compressive Sensing with Data Consistency Projection](https://arxiv.org/abs/2509.09365)
*Xiaodong Wang,Ping Wang,Zhangyuan Li,Xin Yuan*

Main category: cs.CV

TL;DR: 本文探讨了PnP方法与DDIM在解决不适定逆问题（特别是单像素成像）中的联系，提出了一个统一框架将学习先验与物理前向模型结合，并设计了混合数据一致性模块来提升重建质量。

- Motivation: 研究PnP方法和扩散模型在逆问题求解中的联系与区别，特别是它们在去噪机制和采样过程上的差异，旨在为单像素成像等逆问题提供更好的重建解决方案。
- Method: 将扩散过程解耦为三个可解释阶段：去噪、数据一致性强制和采样；提出混合数据一致性模块，线性组合多个PnP式保真度项，直接应用于去噪估计以改善测量一致性。
- Result: 在单像素成像任务上的实验结果表明，该方法获得了更好的重建质量。
- Conclusion: 通过统一框架整合学习先验和物理模型，结合混合数据一致性校正，可以在不破坏扩散采样轨迹的情况下有效提升逆问题求解的重建性能。


### [54] [A Fully Automatic Framework for Intracranial Pressure Grading: Integrating Keyframe Identification, ONSD Measurement and Clinical Data](https://arxiv.org/abs/2509.09368)
*Pengxu Wen,Tingting Yu,Ziwei Nie,Cheng Jiang,Zhenyu Yin,Mingyang He,Bo Liao,Xiaoping Yang*

Main category: cs.CV

TL;DR: 这篇论文提出了一种全自动的两阶段框架，通过视神经夹直径测量和临床数据融合，实现了无创的内顶压分级预测，显著提升了临床评估的准确性和可靠性。

- Motivation: 内顶压升高对腥功能构成严重威胁，需要及时监测。虽然腰穿是金标准测量方法，但其侵入性和风险驱动了对非侵入性替代方案的需求。视神经夹直径作为有前景的生物标记物，但现有手工测量方法存在不一致性、主观性和变异性问题。
- Method: 设计了一种全自动的两阶段框架：第一阶段进行眼底超声视频处理，包括框级解剖分割、基于规则的关键帧识别和精确的ONSD测量；第二阶段融合ONSD指标和临床特征，进行内顶压分级预测。
- Result: 实验结果显示，该方法在验证集上达到了$0.845 \pm 0.071$的准确率（五折交叉验证），在独立测试集上达到0.786的准确率，显著超过传统的阈值基础方法（验证准确率$0.637 \pm 0.111$，测试准确率0.429）。
- Conclusion: 通过有效减少操作变异性和融合多源信息，该框架为临床ICP评估建立了可靠的非侵入性方法，有望改善急性神经疾病患者的管理水平。


### [55] [Unsupervised Integrated-Circuit Defect Segmentation via Image-Intrinsic Normality](https://arxiv.org/abs/2509.09375)
*Botong Zhao,Qijun Shi,Shujing Lyu,Yue Lu*

Main category: cs.CV

TL;DR: 无监督IC缺陷分割框架，通过从测试图像中提取正常特征并重建正常内容，利用重建殊差进行缺陷分割，免需外部正常数据支持

- Motivation: 现有IC缺陷分割方法需要外部正常数据库进行对比，但IC图像布局差异大且对齐困难，方法脆弱
- Method: 设计可学习正常信息提取器从测试图像获取代表性正常特征，通过一致性损失确保特征与正常区域关联，使用解码器重建正常内容，利用重建殊差进行缺陷分割，使用伪异常增广稳定训练
- Result: 在三个IC制程步骤的数据集上均显示出比现有方法更一致的改进，对产品变化具有强壁静性
- Conclusion: 该无监督框架能够有效分割IC缺陷，免需外部正常数据支持，适用于不同产品和布局变化的场景


### [56] [Decoupling Clinical and Class-Agnostic Features for Reliable Few-Shot Adaptation under Shift](https://arxiv.org/abs/2509.09397)
*Umaima Rahman,Raza Imam,Mohammad Yaqub,Dwarikanath Mahapatra*

Main category: cs.CV

TL;DR: DRiFt是一个医学视觉语言模型框架，通过特征解耦将临床相关信号与任务无关噪声分离，使用LoRA和可学习提示令牌提升模型泛化能力和鲁棒性。

- Motivation: 医学视觉语言模型在分布偏移下的可靠性是临床部署的主要担忧，模型常因成像协议和自由文本报告的变异性学习到任务无关的相关性，限制了泛化能力并增加真实世界失败风险。
- Method: 提出结构化特征解耦框架DRiFt，使用参数高效调优（LoRA）和可学习提示令牌显式分离临床相关信号与任务无关噪声，并通过为多样化医学数据集生成标题来策划高质量、临床基础的图像-文本对以增强跨模态对齐。
- Result: 方法在分布内性能上比先前基于提示的方法提升+11.4% Top-1准确率和+3.3% Macro-F1，同时在未见数据集上保持强鲁棒性。消融研究表明解耦任务相关特征和精心对齐显著增强模型泛化能力并减少域偏移下的不可预测行为。
- Conclusion: 这些见解有助于构建更安全、更可信的临床用视觉语言模型，DRiFt框架为医学VLMs的可靠部署提供了有效解决方案。


### [57] [FS-Diff: Semantic guidance and clarity-aware simultaneous multimodal image fusion and super-resolution](https://arxiv.org/abs/2509.09427)
*Yuchan Jie,Yushen Xu,Xiaosong Li,Fuqiang Zhou,Jianming Lv,Huafeng Li*

Main category: cs.CV

TL;DR: FS-Diff是一种基于扩散模型的联合图像融合和超分辨率方法，通过语义引导和清晰度感知机制，能够从低分辨率多模态图像中恢复丰富的细节和语义信息。

- Motivation: 在军事侦察和远程检测等实际应用中，多模态图像中的目标和背景结构容易损坏，分辨率低且语义信息弱，导致现有融合技术效果不佳。
- Method: 将图像融合和超分辨率统一为条件生成问题，利用清晰度感知机制提供语义引导，采用双向特征Mamba提取全局特征，通过改进的U-Net网络实现随机迭代去噪过程。
- Result: 在六个公共数据集和自建的AVMS基准测试上，FS-Diff在多种放大倍数下均优于现有最先进方法，能够恢复更丰富的细节和语义信息。
- Conclusion: FS-Diff通过扩散模型和语义引导机制，有效解决了低分辨率多模态图像融合问题，为实际应用提供了高质量的融合结果。


### [58] [Semantic Concentration for Self-Supervised Dense Representations Learning](https://arxiv.org/abs/2509.09429)
*Peisong Wen,Qianqian Xu,Siran Dai,Runmin Cong,Qingming Huang*

Main category: cs.CV

TL;DR: 这篇论文提出了一种显式语义聚集方法（CoTAP），用于解决密集自盛学习中的过度分散问题，通过排名损失和对象感知筛波器来提升表征学习效果。

- Motivation: 图像级别自盛学习已取得进展，但密集表征学习仍面临过度分散问题，导致同一实例/类别的补丁散开，影响下游密集任务的性能。需要探索显式语义聚集方法来解决这一挑战。
- Method: 1. 通过莘聚补丁对应关系来突破严格空间对齐限制
2. 提出噪声容忍性排名损失，将平均精度（AP）损失扩展到连续目标
3. 设计对象感知筛波器，通过跨注意力机制将补丁映射到可学习的对象原型空间
- Result: 在多个任务上进行了实验研究，结果齐声支持了该方法的有效性，代码已在GitHub上开源
- Conclusion: 该方法成功地实现了显式语义聚集，有效解决了密集自盛学习中的过度分散问题，为密集表征学习提供了新的解决方案。


### [59] [FlexiD-Fuse: Flexible number of inputs multi-modal medical image fusion based on diffusion model](https://arxiv.org/abs/2509.09456)
*Yushen Xu,Xiaosong Li,Yuchun Wang,Xiaoqi Cheng,Huafeng Li,Haishu Tan*

Main category: cs.CV

TL;DR: FlexiD-Fuse是一个基于扩散模型的医学图像融合网络，能够处理任意数量的输入模态，解决了现有方法只能处理固定数量模态输入的限制。

- Motivation: 现有的医学图像融合方法只能处理固定数量的模态输入（如双模态或三模态），无法直接处理变化的输入数量，这限制了其在临床环境中的应用。
- Method: 将扩散融合问题转化为基于扩散过程和分层贝叶斯建模的最大似然估计问题，通过将期望最大化算法整合到扩散采样迭代过程中，实现任意数量输入图像的高质量融合。
- Result: 在哈佛数据集上的实验表明，该方法在变输入医学图像融合中取得了最佳性能，同时在红外-可见光、多曝光和多焦点图像融合任务中也表现出优越性。
- Conclusion: FlexiD-Fuse方法能够有效处理任意数量的输入模态，在医学图像融合和其他多模态图像融合任务中都表现出卓越的性能和通用性。


### [60] [Resource-Efficient Glioma Segmentation on Sub-Saharan MRI](https://arxiv.org/abs/2509.09469)
*Freedmore Sidume,Oumayma Soula,Joseph Muthui Wacira,YunFei Zhu,Abbas Rabiu Muhammad,Abderrazek Zeraii,Oluwaseun Kalejaye,Hajer Ibrahim,Olfa Gaddour,Brain Halubanza,Dong Zhang,Udunna C Anazodo,Confidence Raymond*

Main category: cs.CV

TL;DR: 针对撒哈拉以南非洲地区MRI数据稀缺问题，开发了基于3D Attention UNet的高效脑胶质瘤分割模型，在有限数据下取得良好性能，模型小巧实用。

- Motivation: 解决撒哈拉以南非洲地区高质量标注MRI数据稀缺的问题，为资源受限环境开发实用的脑胶质瘤分割解决方案。
- Method: 采用3D Attention UNet架构，加入残差块，利用BraTS 2021数据集进行迁移学习预训练，在BraTS-Africa数据集上进行评估。
- Result: 在95例MRI数据上获得Dice分数：增强肿瘤0.76、坏死和非增强肿瘤核心0.80、周围非功能半球0.85，模型大小约90MB，单体积推理时间不到1分钟。
- Conclusion: 该模型在资源受限环境下表现出良好的泛化能力和实用性，有助于缩小全球健康AI公平性差距，为服务不足地区提供高性能医学影像解决方案。


### [61] [OpenFake: An Open Dataset and Platform Toward Large-Scale Deepfake Detection](https://arxiv.org/abs/2509.09495)
*Victor Livernoche,Akshatha Arodi,Andreea Musulan,Zachary Yang,Adam Salvail,Gaétan Marceau Caron,Jean-François Godbout,Reihaneh Rabbany*

Main category: cs.CV

TL;DR: 这篇论文提出了一个政治相关的深度伪造图片检测数据集，包含300万张真实图片和96.3万张高质量合成图片，并创建了群众竞争平台以应对不断发展的生成技术。

- Motivation: 现有深度伪造检测数据集存在限制：使用过时的生成方法、低实际效果、单人脸图像，导致合成图像检测效果不佳。现代专有模型生成的合成图片越来越难以识别，加剧了错误信息的传播。
- Method: 通过分析社交媒体内容确定深度伪造传播模态，进行人类知觉研究，构建包含300万张真实图片和96.3万张高质量合成图片的数据集，并创建群众竞争平台让参与者提交具有挑战性的合成图像。
- Result: 创建了一个全面的政治相关深度伪造检测数据集，包含大量真实和合成图片对，来自专有和开源模型。群众竞争平台确保检测方法能够持续适应新兴生成技术的挑战。
- Conclusion: 该研究为对抗现代高级错误信息传播提供了重要工具，通过持续更新的群众驱动方式，保障公共讨论免受精细化错误信息的威胁。


### [62] [Improving Human Motion Plausibility with Body Momentum](https://arxiv.org/abs/2509.09496)
*Ha Linh Nguyen,Tze Ho Elden Tse,Angela Yao*

Main category: cs.CV

TL;DR: 该论文提出使用全身线性和角动量作为约束来连接局部运动与全局运动，通过动量一致性损失函数改善运动生成质量

- Motivation: 现有方法将人体运动分解为局部关节运动和全局根关节运动并分别处理，但这两部分在物理上相互耦合。传统方法难以精确捕捉这种物理关联，而基于关节扭矩和外部力的计算方法又过于复杂昂贵
- Method: 利用全身线性和角动量作为物理约束，提出新的损失函数来强制生成的运动动量分布与真实数据保持一致。动量反映了关节级动力学对身体空间运动的聚合效应
- Result: 引入动量一致性损失后，减少了脚部滑动和抖动，改善了平衡性，同时保持了运动重建的准确性
- Conclusion: 动量约束提供了一种物理基础的方法来关联局部关节行为与全局位移，有效解决了局部与全局运动耦合的建模问题


### [63] [Region-Wise Correspondence Prediction between Manga Line Art Images](https://arxiv.org/abs/2509.09501)
*Yingxuan Li,Jiafeng Mao,Qianru Qiu,Yusuke Matsui*

Main category: cs.CV

TL;DR: 这篇论文提出了一种新的Transformer基础框架，用于预测沪漫线条图像之间的区域对应关系，无需预先分割或标注，在多个数据集上达到了高准确率。

- Motivation: 理解沪漫线条图像之间的区域对应关系是沪漫处理的基础任务，可支持自动上色、中间帧生成等应用，但该任务在无预先分割的实际场景中仍未得到充分研究。
- Method: 将每张线条图分割成补丁集合，使用Transformer框架学习图像内和图像间的补丁级相似性，然后通过边缘感知聚类和区域匹配算法将补丁级预测转换为一致的区域级对应关系。
- Result: 在多个数据集上达到了高补丁级准确率（6.34%），并生成了一致的区域级对应关系。
- Conclusion: 该方法为无预先分割的沪漫线条图像区域对应提供了有效解决方案，显示了其在实际沪漫应用中的潜力。


### [64] [Generative Diffusion Contrastive Network for Multi-View Clustering](https://arxiv.org/abs/2509.09527)
*Jian Zhu,Xin Zou,Xi Wang,Ning Zhang,Bian Wu,Yao Yang,Ying Zhou,Lingfang Zeng,Chang Tang,Cheng Luo*

Main category: cs.CV

TL;DR: 通过随机生成激散融合方法SGDF和生成激散对比网络GDCN，解决多视图聚类中的低质量数据问题，实现了独特的多视图融合方案。

- Motivation: 多视图聚类中存在低质量数据问题，主要由两个原因导致：某些视图受到噪声数据污染，以及部分视图存在数据缺失。这些问题影响了多视图融合的效果和聚类性能。
- Method: 提出随机生成激散融合（SGDF）方法，利用多重生成机制处理每个样本的多视图特征。基于SGDF，进一步提出生成激散对比网络（GDCN）。
- Result: 大量实验表明GDCN在深度多视图聚类任务中达到了最先进的性能水平。
- Conclusion: SGDF和GDCN方法能够有效处理多视图聚类中的低质量数据问题，提供了一种稳健的多视图融合解决方案。


### [65] [DualTrack: Sensorless 3D Ultrasound needs Local and Global Context](https://arxiv.org/abs/2509.09530)
*Paul F. R. Wilson,Matteo Ronchetti,Rüdiger Göbl,Viktoria Markova,Sebastian Rosenzweig,Raphael Prevost,Parvin Mousavi,Oliver Zettinig*

Main category: cs.CV

TL;DR: DualTrack是一种新颖的双编码器架构，通过解耦的局部和全局编码器分别处理超声图像中的细粒度特征和高级解剖特征，实现了传感器无关的3D超声重建，在大型公共基准测试中达到最先进精度，平均重建误差低于5毫米。

- Motivation: 传统3D超声系统成本高且复杂，限制了其广泛应用。传感器无关的3D超声使用深度学习从2D图像序列估计3D探头轨迹，但现有方法要么忽略全局特征，要么将其与局部特征提取紧密耦合，无法有效建模这两个互补方面。
- Method: 提出DualTrack双编码器架构：局部编码器使用密集时空卷积捕获细粒度特征；全局编码器使用图像主干网络（如2D CNN或基础模型）和时间注意力层嵌入高级解剖特征和长程依赖关系；轻量级融合模块结合这些特征来估计轨迹。
- Result: 在大型公共基准测试中，DualTrack实现了最先进的精度和全局一致的3D重建，优于先前方法，平均重建误差低于5毫米。
- Conclusion: DualTrack通过解耦的局部和全局特征提取，有效解决了传感器无关3D超声重建问题，为低成本、高性能的3D超声成像提供了有前景的解决方案。


### [66] [Improving Video Diffusion Transformer Training by Multi-Feature Fusion and Alignment from Self-Supervised Vision Encoders](https://arxiv.org/abs/2509.09547)
*Dohun Lee,Hyeonho Jeong,Jiwook Kim,Duygu Ceylan,Jong Chul Ye*

Main category: cs.CV

TL;DR: 提出Align4Gen方法，通过将视频生成器的中间特征与预训练视觉编码器的特征表示对齐，提升视频扩散模型的生成质量。

- Motivation: 当前视频扩散模型主要关注架构创新和训练目标改进，而对特征表示能力的提升关注较少。研究表明特征对齐可以改善视频生成效果。
- Method: 提出多特征融合和对齐方法，集成到视频扩散模型训练中。首先分析评估不同视觉编码器的判别性和时序一致性，然后选择适合的特征进行对齐。
- Result: 在无条件和类条件视频生成任务上都取得了改进，通过各种量化指标验证了生成质量的提升。
- Conclusion: 特征对齐是提升视频扩散模型性能的有效方法，Align4Gen方法为视频生成提供了新的优化方向。


### [67] [InterAct: Advancing Large-Scale Versatile 3D Human-Object Interaction Generation](https://arxiv.org/abs/2509.09555)
*Sirui Xu,Dongting Li,Yucheng Zhang,Xiyan Xu,Qi Long,Ziyin Wang,Yunzhi Lu,Shuchang Dong,Hezi Jiang,Akshat Gupta,Yu-Xiong Wang,Liang-Yan Gui*

Main category: cs.CV

TL;DR: InterAct是一个大规模3D人机交互基准数据集，通过整合和优化现有数据，解决了现有数据集在运动质量、标注和接触伪影方面的不足，提供了30.7小时的高质量人机交互数据。

- Motivation: 现有的大规模人体运动捕捉数据集在人机交互建模方面存在局限性，包括数据质量不高、标注不完整以及接触穿透、漂浮、手部运动不正确等伪影问题。
- Method: 1) 整合和标准化21.81小时的HOI数据并添加详细文本标注；2) 提出统一的优化框架，基于接触不变性原理减少伪影并修正手部运动，将数据集扩展到30.70小时；3) 定义六个基准任务并开发统一的HOI生成建模方法。
- Result: 实现了最先进的性能，广泛实验验证了该数据集作为推进3D人机交互生成研究的基础资源的实用性。
- Conclusion: InterAct数据集为3D人机交互生成研究提供了高质量的基础资源，数据集已公开并将持续维护，支持该领域的持续研究发展。


### [68] [Invisible Attributes, Visible Biases: Exploring Demographic Shortcuts in MRI-based Alzheimer's Disease Classification](https://arxiv.org/abs/2509.09558)
*Akshit Achara,Esther Puyol Anton,Alexander Hammers,Andrew P. King*

Main category: cs.CV

TL;DR: 该研究探讨了基于深度学习的阿尔茨海默病MRI诊断中存在的种族和性别捷径学习与偏见问题，通过多数据集和模型验证了分布偏移和性能偏差的存在

- Motivation: 深度学习算法在MRI脑部成像诊断中可能存在捷径学习问题，使用与输出标签无关的虚假特征进行预测，当这些特征与受保护属性相关时，会导致对少数群体的性能偏见
- Method: 首先研究DL算法是否能从3D脑MRI扫描中识别种族或性别以确定分布偏移；然后研究训练集种族或性别不平衡是否导致模型性能下降；最后对受保护属性和AD分类任务进行定量和定性特征归因分析
- Result: 使用多个数据集和DL模型（ResNet和SwinTransformer）证明了基于种族和性别的捷径学习和偏见在DL-based AD分类中的存在
- Conclusion: 这项工作为开发更公平的脑MRI深度学习诊断工具奠定了基础


### [69] [PeftCD: Leveraging Vision Foundation Models with Parameter-Efficient Fine-Tuning for Remote Sensing Change Detection](https://arxiv.org/abs/2509.09572)
*Sijun Dong,Yuxuan Hu,LiBo Wang,Geng Chen,Xiaoliang Meng*

Main category: cs.CV

TL;DR: PeftCD是一个基于视觉基础模型(VFMs)和参数高效微调(PEFT)的变化检测框架，通过LoRA和Adapter模块实现高效任务适应，在多个数据集上达到SOTA性能。

- Motivation: 解决多时相多源遥感图像中伪变化普遍、标注样本稀缺和跨域泛化困难的问题
- Method: 使用权重共享的Siamese编码器，集成LoRA和Adapter模块，采用SAM2和DINOv3作为骨干网络，配合轻量级解码器
- Result: 在SYSU-CD(IoU 73.81%)、WHUCD(92.05%)、MSRSCD(64.07%)、MLCD(76.89%)、CDD(97.01%)、S2Looking(52.25%)和LEVIR-CD(85.62%)等多个数据集上达到最先进性能
- Conclusion: PeftCD在准确性、效率和泛化性之间实现了最佳平衡，为大规模VFMs在遥感变化检测应用中的适配提供了强大且可扩展的范式


### [70] [Visual Grounding from Event Cameras](https://arxiv.org/abs/2509.09584)
*Lingdong Kong,Dongyue Lu,Ao Liang,Rong Li,Yuhao Dong,Tianshuai Hu,Lai Xing Ng,Wei Tsang Ooi,Benoit R. Cottereau*

Main category: cs.CV

TL;DR: Talk2Event是首个基于事件相机数据的大规模语言驱动目标定位基准，包含5,567个真实驾驶场景、13,458个标注目标和30,000+验证过的指代表达式，支持可解释的组合式目标定位。

- Motivation: 事件相机具有微秒级精度和抗运动模糊的优势，但在自然语言理解方面的多模态感知研究较少，需要填补这一空白。
- Method: 构建基于真实驾驶场景的大规模数据集，每个指代表达式包含外观、状态、与观察者关系、与周围物体关系四个结构化属性，显式捕捉时空和关系线索。
- Result: 创建了包含5,567个场景、13,458个标注对象和30,000+验证表达式的基准数据集，支持超越简单目标识别的上下文推理。
- Conclusion: Talk2Event为推进多模态和时间感知感知提供了基础，在机器人、人机交互等领域具有应用前景。


### [71] [Kling-Avatar: Grounding Multimodal Instructions for Cascaded Long-Duration Avatar Animation Synthesis](https://arxiv.org/abs/2509.09595)
*Yikang Ding,Jiwen Liu,Wenyuan Zhang,Zekun Wang,Wentao Hu,Liyuan Cui,Mingming Lao,Yingchao Shao,Hui Liu,Xiaohan Li,Ming Chen,Xiaoqiang Liu,Yu-Shen Liu,Pengfei Wan*

Main category: cs.CV

TL;DR: Kling-Avatar是一个新颖的级联框架，通过多模态指令理解和照片级真实感人像生成，解决了现有音频驱动虚拟人视频生成方法在叙事连贯性和角色表现力方面的局限性。

- Motivation: 现有方法将指令条件仅视为由声学或视觉线索驱动的低级跟踪，而没有建模指令传达的交流目的，这影响了叙事连贯性和角色表现力。
- Method: 采用两阶段流水线：第一阶段使用多模态大语言模型（MLLM）导演生成蓝图视频，控制角色动作和情感等高级语义；第二阶段在蓝图关键帧指导下，使用首尾帧策略并行生成多个子片段。
- Result: 能够生成生动、流畅、长达1080p和48fps的长时视频，在唇形同步准确性、情感和动态表现力、指令可控性、身份保持和跨域泛化方面表现出色。
- Conclusion: Kling-Avatar为基于语义的高保真音频驱动虚拟人合成建立了新的基准，适用于数字人直播和视频博客等实际应用。


### [72] [Mechanistic Learning with Guided Diffusion Models to Predict Spatio-Temporal Brain Tumor Growth](https://arxiv.org/abs/2509.09610)
*Daria Laslo,Efthymios Georgiou,Marius George Linguraru,Andreas Rauschecker,Sabine Muller,Catherine R. Jutzeler,Sarah Bruningk*

Main category: cs.CV

TL;DR: 提出混合机制学习框架，结合数学肿瘤生长模型和引导去噪扩散模型，从先前MRI扫描合成解剖学可行的未来脑肿瘤MRI图像

- Motivation: 预测脑肿瘤的时空进展对于指导神经肿瘤学临床决策至关重要，需要在数据有限的情况下实现生物信息化的图像生成
- Method: 使用常微分方程系统构建机制模型捕捉肿瘤动态和放疗效果，结合梯度引导的DDIM模型进行图像合成，使生成图像与预测生长和患者解剖结构对齐
- Result: 在BraTS成人和儿童胶质瘤数据集上训练，在60个纵向儿科DMG病例上评估，生成真实随访扫描，提供肿瘤生长概率图，显示临床相关生长范围和方向性
- Conclusion: 该方法在数据有限情况下实现生物信息化的图像生成，提供考虑机制先验的生成式时空预测


### [73] [Measuring Epistemic Humility in Multimodal Large Language Models](https://arxiv.org/abs/2509.09658)
*Bingkui Tong,Jiaer Xia,Sifeng Shang,Kaiyang Zhou*

Main category: cs.CV

TL;DR: HumbleBench是一个新的多模态大语言模型幻觉基准测试，专门评估模型拒绝错误答案的能力，包含"以上都不是"选项来测试认知谦逊。

- Motivation: 现有基准测试主要关注识别准确性，但忽略了模型在提供选项都不正确时拒绝回答的关键能力，这对于构建可信AI系统至关重要。
- Method: 基于全景场景图数据集，利用细粒度场景图标注提取真实实体和关系，使用GPT-4-Turbo生成多选题，并经过严格人工筛选，每个问题都包含"以上都不是"选项。
- Result: 评估了多种最先进的多模态大语言模型，包括通用模型和专用推理模型，提供了有价值的发现和见解。
- Conclusion: HumbleBench通过引入显式的错误选项拒绝机制，填补了当前评估套件的重要空白，为安全关键场景中的MLLM可靠性提供了更真实的衡量标准。


### [74] [Can Understanding and Generation Truly Benefit Together -- or Just Coexist?](https://arxiv.org/abs/2509.09666)
*Zhiyuan Yan,Kaiqing Lin,Zongjian Li,Junyan Ye,Hui Han,Zhendong Wang,Hao Liu,Bin Lin,Hao Li,Xue Xu,Xinyan Xiao,Jingdong Wang,Haifeng Wang,Li Yuan*

Main category: cs.CV

TL;DR: 本文提出UAE框架，通过自编码器视角统一多模态学习：编码器(I2T)将图像压缩为文本，解码器(T2I)从文本重建图像，使用重建保真度作为统一训练目标实现双向信息流。

- Motivation: 通过重建保真度作为统一训练目标，强制理解和生成过程之间的连贯双向信息流，带来相互增益，解决多模态学习中理解和生成的统一问题。
- Method: 提出UAE框架：1)使用大规模长上下文图像标题预训练解码器；2)通过强化学习提出Unified-GRPO三阶段训练：冷启动阶段、生成促进理解阶段、理解促进生成阶段。
- Result: 编码器自主产生更具描述性的标题，解码器同时展示出理解复杂描述的能力，实现高保真度重建。提出首个评估UMM统一度的基准Unified-Bench。
- Conclusion: 多模态学习领域出现惊喜发现：随着RL进展，编码器和解码器相互促进，实现了理解和生成的高度统一，为统一多模态模型提供了新范式。


### [75] [Geometric Neural Distance Fields for Learning Human Motion Priors](https://arxiv.org/abs/2509.09667)
*Zhengdi Yu,Simone Foti,Linguang Zhang,Amy Zhao,Cem Keskin,Stefanos Zafeiriou,Tolga Birdal*

Main category: cs.CV

TL;DR: NRMF是一种新颖的3D生成式人体运动先验模型，通过神经距离场在黎曼流形上建模人体运动，实现鲁棒、时序一致且物理合理的3D运动恢复

- Motivation: 现有VAE或扩散模型方法无法充分建模人体运动的几何约束和物理合理性，需要一种能够显式建模运动动力学并在底层关节几何空间保持一致性的方法
- Method: 在关节旋转、角速度和角加速度的乘积空间构建神经距离场，提出自适应步长混合投影算法和几何积分器来生成合理运动轨迹
- Result: 在AMASS数据集上训练后，NRMF在去噪、运动插值和部分2D/3D观测拟合等多种任务上表现出显著且一致的性能提升
- Conclusion: NRMF通过几何感知的运动建模方法，为3D人体运动恢复提供了鲁棒且物理合理的解决方案，具有良好的泛化能力


### [76] [Locality in Image Diffusion Models Emerges from Data Statistics](https://arxiv.org/abs/2509.09672)
*Artem Lukoianov,Chenyang Yuan,Justin Solomon,Vincent Sitzmann*

Main category: cs.CV

TL;DR: 本文研究发现扩散模型中局部性特征源于图像数据集的统计特性，而非卷积神经网络的归纳偏置，并提出了更好的解析去噪器。

- Motivation: 现有研究认为扩散模型性能差距源于卷积网络的平移等变性和局部性归纳偏置，但本文质疑这一假设，试图证明局部性实际上是图像数据集的统计特性。
- Method: 通过分析最优参数线性去噪器的局部性特征，理论推导和实验验证像素相关性如何导致局部性，并基于此构建新的解析去噪器。
- Result: 证明最优参数线性去噪器表现出与深度神经网络去噪器相似的局部性特征，且这种局部性直接源于自然图像数据集中的像素相关性。
- Conclusion: 扩散模型中的局部性主要来自图像数据集的统计特性，而非网络架构的归纳偏置，这一发现有助于构建更准确的解析模型来匹配深度扩散模型的行为。


### [77] [SpatialVID: A Large-Scale Video Dataset with Spatial Annotations](https://arxiv.org/abs/2509.09676)
*Jiahao Wang,Yufeng Yuan,Rujie Zheng,Youtian Lin,Jian Gao,Lin-Zhuo Chen,Yajie Bao,Yi Zhang,Chang Zeng,Yanxi Zhou,Xiaoxiao Long,Hao Zhu,Zhaoxiang Zhang,Xun Cao,Yao Yao*

Main category: cs.CV

TL;DR: 提出了SpatialVID数据集，包含大量真实世界视频，具有丰富的3D标注信息，解决了当前空间智能模型训练数据稀缺的问题。

- Motivation: 当前空间智能模型在可扩展性和真实世界保真度方面受到大规模高质量训练数据稀缺的限制，现有数据集在规模、多样性和标注丰富度方面存在不足。
- Method: 收集超过21,000小时的原始视频，通过分层过滤流程处理成270万个片段，总计7,089小时的动态内容，并通过标注流程添加相机位姿、深度图、动态掩码等详细空间和语义信息。
- Result: 创建了包含丰富多样场景、相机运动和密集3D标注的大规模数据集，数据分析显示其丰富性和多样性能够直接促进模型泛化能力和性能提升。
- Conclusion: SpatialVID数据集为视频和3D视觉研究社区提供了重要资源，解决了训练数据稀缺问题，有助于推动空间智能模型的发展。


### [78] [FLUX-Reason-6M & PRISM-Bench: A Million-Scale Text-to-Image Reasoning Dataset and Comprehensive Benchmark](https://arxiv.org/abs/2509.09680)
*Rongyao Fang,Aldrich Yu,Chengqi Duan,Linjiang Huang,Shuai Bai,Yuxuan Cai,Kun Wang,Si Liu,Xihui Liu,Hongsheng Li*

Main category: cs.CV

TL;DR: FLUX-Reason-6M是一个600万高质量图像和2000万双语描述的大型数据集，PRISM-Bench是包含7个评估赛道的新基准，旨在解决开源文本到图像模型在复杂推理方面的性能差距。

- Motivation: 开源文本到图像模型因缺乏大规模推理数据集和全面评估基准，导致与闭源系统存在性能差距，需要提供工业级资源来推动社区发展。
- Method: 构建FLUX-Reason-6M数据集（6M图像+20M双语描述），按6个关键特征组织，设计显式生成思维链；创建PRISM-Bench评估基准（7个赛道），使用先进视觉语言模型进行细致评估。
- Result: 经过15000 A100 GPU天的数据整理，为社区提供了前所未有的资源；对19个领先模型的评估揭示了关键性能差距和改进需求。
- Conclusion: 发布的数据集、基准和评估代码将催化下一代面向推理的文本到图像生成技术的发展。
## physics.med-ph

### [79] [Explainable AI for Accelerated Microstructure Imaging: A SHAP-Guided Protocol on the Connectome 2.0 scanner](https://arxiv.org/abs/2509.09513)
*Quentin Uhl,Tommaso Pavan,Julianna Gerold,Kwok-Shing Chan,Yohan Jun,Shohei Fujita,Aneri Bhatt,Yixin Ma,Qiaochu Wang,Hong-Hsi Lee,Susie Y. Huang,Berkin Bilgic,Ileana Jelescu*

Main category: physics.med-ph

TL;DR: 通过解释性人工智能优化扩散磁共振弄式协议，在14分钟内完成神经元交换成像，保持参数精度的同时大幅缩短扫描时间

- Motivation: 现有的扩散磁共振神经元交换成像模型需要过长的扫描时间，限制了其在神经科学和临床研究中的应用
- Method: 使用解释性人工智能策略（导向递归特征消除）从15个特征协议中选择最优的8个特征子集，并在生物细胞参数映射中验证性能
- Result: 缩短协议获得了与完整协议相似的参数估计和直观图谱，水交换时间估计偏差减少超过2倍，并保持了良好的重测可靠性
- Conclusion: 该混合优化框架可以在14分钟内实现神经元交换成像，为交换敏感扩散磁共振成像提供了高效的数据采集方案，具有广泛的应用前景
## math.NA

### [80] [DeepTV: A neural network approach for total variation minimization](https://arxiv.org/abs/2409.05569)
*Andreas Langer,Sara Behnamian*

Main category: math.NA

TL;DR: 该论文提出使用神经网络解决无限维全变分最小化问题的方法，发现原始神经网络问题通常无解，因此引入辅助神经网络问题并通过Γ-收敛证明其收敛性，同时提出离散版本并建立与有限差分的联系。

- Motivation: 神经网络方法在求解偏微分方程方面表现良好，如物理信息神经网络和深度Ritz方法。本文旨在探索使用神经网络解决无限维全变分最小化问题，但发现原始问题存在理论缺陷。
- Method: 提出辅助神经网络问题来解决原始问题无解的理论问题，证明其Γ-收敛性；进一步提出离散版本的辅助神经网络问题，并证明其Γ-收敛到原始无限维问题；建立离散神经网络问题与有限差分离散化之间的联系。
- Result: 理论分析表明辅助神经网络问题确实有解且收敛到原始问题；离散版本同样具有Γ-收敛性；数值实验支持理论发现，验证了方法的有效性。
- Conclusion: 通过引入辅助问题和离散化策略，成功解决了使用神经网络求解无限维全变分最小化问题的理论障碍，Γ-收敛分析为特定离散化方案提供了理论依据，数值结果证实了方法的可行性。
## eess.IV

### [81] [Dynamic Structural Recovery Parameters Enhance Prediction of Visual Outcomes After Macular Hole Surgery](https://arxiv.org/abs/2509.09227)
*Yinzheng Zhao,Zhihao Zhao,Rundong Jiang,Louisa Sackewitz,Quanmin Liang,Mathias Maier,Daniel Zapp,Peter Charbel Issa,Mohammad Ali Nasseri*

Main category: eess.IV

TL;DR: 本文提出动态结构参数并将其集成到多模态深度学习框架中，用于预测id性全层黄盒空间病人的本后视力恢复情况，显著提高了预测准确性。

- Motivation: 为了提高对id性全层黄盒空间病人本后视力恢复的预测准确性，需要引入新的动态结构参数并将其集成到多模态深度学习框架中。
- Method: 利用公开纵向OCT数据集，开发阶段特异分割模型和自动化流程提取定量、复合、定性和动态特征。构建二元逻辑回归模型和多模态深度学习模型，评估动态参数的增量预测价值。
- Result: 分割模型准确度高（均值Dice>0.89）。动态恢复率提高了逻辑回归AUC，多模态DL模型表现更优，AUC最高提高0.12，显示原始图像和动态参数的互补价值。
- Conclusion: 集成动态参数的多模态DL模型显著提高了预测准确性，作为一种全自动化过程，是个性化黄盒空手术本后管理的有前景的临床决策支持工具。


### [82] [Virtual staining for 3D X-ray histology of bone implants](https://arxiv.org/abs/2509.09235)
*Sarah C. Irvine,Christian Lucas,Diana Krüger,Bianca Guedert,Julian Moosmann,Berit Zeller-Plumhoff*

Main category: eess.IV

TL;DR: Error

- Motivation: Error
- Method: Error
- Result: Error
- Conclusion: Error


### [83] [In-Loop Filtering Using Learned Look-Up Tables for Video Coding](https://arxiv.org/abs/2509.09494)
*Zhuoyuan Li,Jiacheng Li,Yao Li,Jialin Li,Li Li,Dong Liu,Feng Wu*

Main category: eess.IV

TL;DR: 该论文提出了一种基于查找表(LUT)的实用循环滤波(LUT-ILF++)框架，用于替代计算复杂的深度神经网络滤波方案，在保持编码收益的同时大幅降低计算复杂度和存储成本。

- Motivation: 神经网络基于循环滤波方案虽然能够提升编码效果，但带来了较高的计算复杂度和硬件要求，限制了其广泛应用。需要找到一种既保持编码性能又能降低复杂度的实用方案。
- Method: 训练一个参考范围限制的DNN模型，然后遍历所有可能输入并将输出值缓存到LUT中。在编码过程中，通过查找表和插值来执行滤波，避免重载的DNN推理计算。还包括多种滤波LUT合作、定制索引机制、跨组件索引和LUT压缩技术。
- Result: 在VVC引用软件中实现的实验结果显示，在AI和RA配置下对常见测试序列分别实现了平均0.82%/2.97%/1.63%和0.85%/4.11%/2.06%的码率减少。与DNN基于方案相比，时间复杂度和存储成本大幅降低。
- Conclusion: LUT-ILF++框架提供了一种高效实用的循环滤波解决方案，在保持良好编码性能的同时大幅降低了计算复杂度，为下一代视频编码标准提供了实用的滤波技术选择。
## cs.GR

### [84] [CameraVDP: Perceptual Display Assessment with Uncertainty Estimation via Camera and Visual Difference Prediction](https://arxiv.org/abs/2509.08947)
*Yancheng Cai,Robert Wanat,Rafal Mantiuk*

Main category: cs.GR

TL;DR: 相机基于VDP的显示器评估框架，结合高精度重建流水线和视觉差异预测，能够进行感知性质量测量

- Motivation: 传统显示器测量方法无法捕捉空间变化效应和高频失真，而相机测量又引入光学和光度形变，需要结合人眼视觉模型进行感知评估
- Method: 组合HDR图像堆叠、MTF逆变换、暗角校正、几何反变形、单应变换和颜色校正的重建流水线，结合Visual Difference Predictor(VDP)模型人眼视觉可见性
- Result: 通过敏损像素检测、颜色缘效识别和显示器不均匀性评估三个应用验证框架，不确定性分析能估计理论性能上限和提供信心区间
- Conclusion: CameraVDP框架能够使普通相机作为精确的显示器测量仪器，完整解决了从物理测量到感知评估的问题
## cs.CL

### [85] [Can Vision-Language Models Solve Visual Math Equations?](https://arxiv.org/abs/2509.09013)
*Monjoy Narayan Choudhury,Junling Wang,Yifan Hou,Mrinmaya Sachan*

Main category: cs.CL

TL;DR: 视觉语言模型在视觉方程求解任务中表现不佳，主要瓶颈在于系数计数能力不足，其次是变量识别和多步骤推理的组合误差

- Motivation: 研究视觉语言模型在需要感知与符号计算整合的任务中的局限性，特别是视觉方程求解这种数学推理任务
- Method: 将视觉方程求解任务分解为系数计数和变量识别两个子任务，分析各环节的误差来源和性能瓶颈
- Result: VLMs在文本方程上表现良好，但在视觉方程上失败；计数是主要瓶颈；识别和推理的组合引入额外误差；随着方程复杂度增加，符号推理本身也成为限制因素
- Conclusion: 当前VLMs在视觉数学推理方面存在关键弱点，需要改进计数能力、多步骤推理和符号计算能力
## cs.SD

### [86] [DiFlow-TTS: Discrete Flow Matching with Factorized Speech Tokens for Low-Latency Zero-Shot Text-To-Speech](https://arxiv.org/abs/2509.09631)
*Ngoc-Son Nguyen,Hieu-Nghia Huynh-Nguyen,Thanh V. T. Tran,Truong-Son Hy,Van Nguyen*

Main category: cs.SD

TL;DR: DiFlow-TTS是首个探索纯离散流匹配的语音合成模型，通过显式建模分解的语音属性，在零样本设置下实现高质量语音合成，推理速度比现有基线快25.8倍

- Motivation: 解决零样本文本到语音合成中推理速度慢和重复伪影的问题，充分利用离散表示的优势，避免现有方法将离散标记嵌入连续空间的做法
- Method: 采用纯离散流匹配方法，在紧凑统一架构中显式建模分解的语音属性，利用上下文学习条件化文本内容和参考语音提取的韵律声学属性，使用分解流预测机制分别处理韵律和声学细节
- Result: 在自然度、韵律、说话人风格保持和能量控制等关键指标上表现优异，模型紧凑且实现低延迟推理，生成速度比最新基线快25.8倍
- Conclusion: DiFlow-TTS证明了纯离散流匹配在语音合成中的有效性，为高质量零样本TTS提供了高效解决方案
## cs.RO

### [87] [OmniEVA: Embodied Versatile Planner via Task-Adaptive 3D-Grounded and Embodiment-aware Reasoning](https://arxiv.org/abs/2509.09332)
*Yuecheng Liu,Dafeng Chi,Shiguang Wu,Zhanguang Zhang,Yuzheng Zhuang,Bowen Yang,He Zhu,Lingfeng Zhang,Pengwei Xie,David Gamaliel Arcos Bravo,Yingxue Zhang,Jianye Hao,Xingyue Quan*

Main category: cs.RO

TL;DR: OmniEVA是一个多模态大语言模型驱动的具身智能规划器，通过任务自适应3D接地机制和具身感知推理框架，解决了现有系统的几何适应性差距和具身约束差距问题。

- Motivation: 当前基于MLLM的具身系统存在两个关键局限：几何适应性差距（2D输入或硬编码3D几何注入导致空间信息不足或泛化受限）和具身约束差距（忽略真实机器人的物理约束，导致计划理论上有效但实际不可行）。
- Method: 提出两个关键创新：(1)任务自适应3D接地机制，使用门控路由器根据上下文需求进行选择性3D融合调节；(2)具身感知推理框架，将任务目标和具身约束共同纳入推理循环。
- Result: 实验结果表明OmniEVA不仅实现了最先进的通用具身推理性能，还在广泛的下游场景中展现出强大能力，在包括原始和复合任务的基准测试中证实了其稳健和通用的规划能力。
- Conclusion: OmniEVA通过创新的3D接地和具身约束整合方法，有效解决了现有MLLM具身系统的局限性，为具身智能提供了更加实用和适应性强的规划解决方案。


### [88] [ObjectReact: Learning Object-Relative Control for Visual Navigation](https://arxiv.org/abs/2509.09594)
*Sourav Garg,Dustin Craggs,Vineeth Bhat,Lachlan Mares,Stefan Podgorski,Madhava Krishna,Feras Dayoub,Ian Reid*

Main category: cs.RO

TL;DR: 这篇论文提出了一种基于对象的相对控制方法(Object-relative control)，通过构建相对3D场景图来实现更好的视觉导航性能，充分利用对象表征的体验和路径不变性优势。

- Motivation: 传统的基于图像相对性的导航方法(image-relative approach)存在限制，因为图像与代理体的姿态和体验强相关联。而对象作为地图的属性，提供了一种体验和轨迹不变的世界表征方式。
- Method: 提出了一种顶度形式的"相对"3D场景图表征，用于获取更信息丰富的对象级全局路径规划成本。训练了一个称为"ObjectReact"的本地控制器，直接条件化在高级"WayObject Costmap"表征上，消除了显式RGB输入的需求。
- Result: 在传感器高度变化和多种导航任务中，对象相对控制方法比图像相对方法显示出更好的性能。笔者还证明了仅用模拟器训练的策略能够良好地沿用到真实室内环境。
- Conclusion: 对象相对控制方法为视觉导航提供了一种更优雅的解决方案，具有更高的可沿用性和空间理解能力，能够在不同体验和轨迹情况下保持稳定性能。


### [89] [Dexplore: Scalable Neural Control for Dexterous Manipulation from Reference-Scoped Exploration](https://arxiv.org/abs/2509.09671)
*Sirui Xu,Yu-Wei Chao,Liuyu Bian,Arsalan Mousavian,Yu-Xiong Wang,Liang-Yan Gui,Wei Yang*

Main category: cs.RO

TL;DR: Dexplore是一个统一的单循环优化方法，直接从大规模手-物体运动捕捉数据中学习机器人控制策略，避免了传统三阶段方法的问题，并通过强化学习保持策略在自适应空间范围内完成任务。

- Motivation: 现有的手-物体运动捕捉数据存在不准确性和人-机器人手之间的本体差异，传统三阶段方法（重定向、跟踪、残差校正）会导致演示数据利用不足和误差累积。
- Method: 提出统一的单循环优化方法，将重定向和跟踪联合进行，将演示作为软指导而非绝对真值。从原始轨迹推导自适应空间范围，使用强化学习训练策略在范围内完成任务并最小化控制努力。
- Result: 该方法能保持演示意图，使机器人特定策略自然涌现，提高对噪声的鲁棒性，并能扩展到大规模演示语料库。最终将跟踪策略蒸馏为基于视觉的技能条件生成控制器。
- Conclusion: Dexplore提供了一个原则性的桥梁，将不完美的演示转化为灵巧操作的有效训练信号，支持跨物体泛化和真实世界部署。
## cs.LG

### [90] [Value bounds and Convergence Analysis for Averages of LRP attributions](https://arxiv.org/abs/2509.08963)
*Alexander Binder,Nastaran Takmil-Homayouni,Urun Dogan*

Main category: cs.LG

TL;DR: 本文通过将LRP型归因方法表示为修正梯度矩阵的乘积，建立了与雅可比矩阵乘法的类比，推导了奇异值上界和归因图值的分量级界限，并获得了控制经验均值收敛到期望的乘法常数。

- Motivation: 分析LRP型归因方法的数值特性，特别是研究归因值的分布规律和收敛性质，为多数据增强场景和Smoothgrad型方法提供理论支撑。
- Method: 将LRP归因方法表示为修正梯度矩阵的乘积形式，推导奇异值上界和分量级界限，应用这些界限获得控制经验均值收敛的乘法常数。
- Result: 发现LRP-beta方法的常数与权重范数无关，这与基于梯度的方法和LRP-epsilon形成显著区别，对多数据增强和Smoothgrad型方法有重要影响。
- Conclusion: LRP-beta方法在数值稳定性方面具有独特优势，其收敛常数不依赖于权重范数，这为实际应用中的归因方法选择提供了重要理论依据。


### [91] [Adaptive Pareto-Optimal Token Merging for Edge Transformer Models in Semantic Communication](https://arxiv.org/abs/2509.09168)
*Omar Erak,Omar Alhussein,Hatem Abou-Zeid,Mehdi Bennis*

Main category: cs.LG

TL;DR: 这篇论文提出了一种无需训练的自适应标记合并框架，通过多目标优化和贝叶斯优化来减少视觉Transformer模型的计算开销和传输资源消耗，同时保持语义通信的准确性。

- Motivation: 大规模Transformer模型在语义通信系统中显示出强大能力，但其计算需求过高，在资源受限的6G网络中实际部署遇到困难。
- Method: 采用贝叶斯优化来解决每层合并比例的多目标优化问题，构建希望特前沿来平衡准确性和计算成本，支持根据应用需求和通道条件进行自适应调整。
- Result: 实验结果显示该方法在各种信器比的器情况下都能显著减少浮点运算量，同时保持竞争力的准确性，超过其他基线方法。
- Conclusion: 该研究为未来边缘智能系统中基于Transformer的语义通信部署提供了一种可扩展且高效的方法，能够根据需求灵活在延迟和语义保真度之间进行权衡。


### [92] [Breaking the Statistical Similarity Trap in Extreme Convection Detection](https://arxiv.org/abs/2509.09195)
*Md Tanveer Hossain Munim*

Main category: cs.LG

TL;DR: 深度学习天气模型当前评价指标存在"统计相似性陷阱"，奖励模糊预测而漏掉稀有高影响事件。论文提出DART框架，通过双解码器结构和物理驱动方法，专门优化极端对流检测，显著提升了实际预警能力。

- Motivation: 现有深度学习天气模型的评价指标存在显著缺陷，导致模型过度关注统计相似性而忽视了关键的极端天气事件检测。这称为"统计相似性陷阱"，很多精巧基准模型虽然在相关性指标上表现优异，但在危险对流检测上却完全失效。
- Method: 提出DART（Dual Architecture for Regression Tasks）框架，采用双解码器结构，将背景和极端事件明确分解。包含物理驱动的过采样技术和任务特定损失函数设计。该框架将粗糕大气预报转换为高分辨率卫星亮温场，专门优化于检测低于220K的极端对流现象。
- Result: 四项关键发现：1）实证了统计相似性陷阱在多个基准模型中的存在；2）发现"IVT奇豫"，移除被认为必需的总水气运输量反而提升极端对流检测270%；3）DART实现CSI=0.273（偏差2.52），显著优于基准模型；4）2023年8月吉大钢洪水灾害案例验证了方法的实际效果。
- Conclusion: DART框架系统性解决了天气预报中的混合转换-分割-降维任务挑战，为可信任的极端天气AI预警提供了新途径。该方法训练效玉高（标准硬件上10分钟内），支持调参检验，并能无缝集成到现有气象工作流程中。


### [93] [Graph Alignment via Dual-Pass Spectral Encoding and Latent Space Communication](https://arxiv.org/abs/2509.09597)
*Maysam Behmanesh,Erkan Turan,Maks Ovsjanikov*

Main category: cs.LG

TL;DR: 提出了一种新颖的图对齐框架，通过双通道编码器和几何感知功能映射模块，同时增强节点区分度并确保跨图潜在空间的几何一致性，在无监督图对齐任务中表现优异。

- Motivation: 现有无监督图对齐方法存在两个关键问题：GNN嵌入中的过度平滑导致节点区分度降低，以及结构噪声、特征异质性和训练不稳定性导致的跨图潜在空间错位，最终导致不可靠的节点对应关系。
- Method: 采用双通道编码器结合低通和高通谱滤波器生成既结构感知又高度区分的嵌入；引入几何感知功能映射模块学习图嵌入之间的双射等距变换，确保跨表示的一致几何关系。
- Result: 在图基准测试中 consistently 优于现有无监督对齐基线，对结构不一致性和挑战性对齐场景表现出 superior 鲁棒性；在视觉-语言基准测试中有效泛化，能够无监督对齐视觉和语言表示。
- Conclusion: 该框架成功解决了图对齐中的节点区分度和跨图几何一致性问题，不仅在图领域表现优异，还能有效泛化到跨模态表示对齐任务。
## cs.AI

### [94] [Mind Meets Space: Rethinking Agentic Spatial Intelligence from a Neuroscience-inspired Perspective](https://arxiv.org/abs/2509.09154)
*Bui Duc Manh,Soumyaratna Debnath,Zetong Zhang,Shriram Damodaran,Arvind Kumar,Yueyi Zhang,Lu Mi,Erik Cambria,Lin Wang*

Main category: cs.AI

TL;DR: 这篇论文提出了一种基于神经科学原理的计算框架，用于提升自主智能体系结构的空间推理能力，包含六个核心模块和应用预览。

- Motivation: 当前自主智能系统在空间推理能力上存在显著缺口，主要限于符号和序列处理，而人类空间智能则基于多感知觉整合和认知地图，因此需要缩小这个差距以提升人工智能体系与物理世界的交互能力。
- Method: 研究者首先分析了计算神经科学中的空间神经模型，然后提出了一个基于神经科学原理的计算框架。该框架将生物功能映射到六个核心计算模块：生物启发的多模态感知、多感知整合、自我中心-绝对坐标转换、人工认知地图、空间记忆和空间推理。
- Result: 论文通过框架导向的分析评估了现有方法的相关性，识别了阻碍神经科学基础空间推理模块发展的关键缺口，并探讨了从虚拟到体现系统的应用预览。
- Conclusion: 这份工作为研究社区提供了基于神经科学的视角和结构化路径，希望能够推动空间推理能力在动态或非结构化环境中的普适性发展。
## eess.SP

### [95] [Ultrafast Deep Learning-Based Scatter Estimation in Cone-Beam Computed Tomography](https://arxiv.org/abs/2509.08973)
*Harshit Agrawal,Ari Hietanen,Simo Särkkä*

Main category: eess.SP

TL;DR: 通过下采样和网络参数优化，在保持散射估计精度的同时，实现了FLOPs降低78倍、推理时间缩短16倍、GPU内存需求减少12倍的显著改善

- Motivation: 散射伪影严重影响CBCT图像质量，现有深度学习方法因网络计算量大，在移动CBCT系统或边缘设备上部署受限
- Method: 首先在6种分辨率下比较4种插值方法的重构错误，然后在5种图像分辨率下训练独立网络，评估FLOPs、推理时间和GPU内存需求
- Result: 在MAPE从4.42%降至3.85%、MSE从2.01×10^{-2}降至1.34×10^{-2}的情况下，实现了FLOPs降低78倍、推理时间缩短16倍、GPU内存减少12倍，并在水模和Sedentex CT幻象体上验证了方法的稳健性
- Conclusion: 研究强调了下采样在深度学习散射估计中的重要作用，通过显著降低计算资源需求，为移动CBCT和边缘设备上的散射校正提供了可行性
