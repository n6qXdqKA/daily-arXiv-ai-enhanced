[[toc]]

## cs.CV

### [1] [Do Open-Vocabulary Detectors Transfer to Aerial Imagery? A Comparative Evaluation](https://arxiv.org/abs/2601.22164)
*Christos Tsourveloudis*

Main category: cs.CV

TL;DR: 首次系统评估开放词汇目标检测模型在航空图像上的零样本性能，发现严重领域迁移失败，语义混淆是主要瓶颈。

- Motivation: 开放词汇目标检测在自然图像上表现良好，但在航空图像上的可迁移性尚未探索，需要建立基准评估和了解领域适应性挑战。
- Method: 在LAE-80C航空数据集（3,592张图像，80个类别）上评估5个最先进的OVD模型，采用严格的零样本条件，通过全局、Oracle和单类别推理模式分离语义混淆和视觉定位问题。
- Result: 最佳模型（OWLv2）仅获得27.6%的F1分数和69%的假阳性率；将词汇量从80类减少到3.2类带来15倍性能提升；提示工程策略无效；不同数据集间性能差异巨大（DIOR：0.53 F1，FAIR1M：0.12 F1）。
- Conclusion: 航空图像开放词汇检测面临严重领域迁移挑战，语义混淆是主要瓶颈，需要开发领域自适应方法，研究结果为该领域建立了基准期望。


### [2] [What Lies Beneath: A Call for Distribution-based Visual Question & Answer Datasets](https://arxiv.org/abs/2601.22218)
*Jill P. Naiman,Daniel J. Evans,JooYoung Seo*

Main category: cs.CV

TL;DR: 该论文提出一个针对科学图表的新型VQA基准测试，重点解决图表标记与底层数据之间不存在一一对应关系的推理挑战。

- Motivation: 当前VQA数据集大多关注真实世界图像或简单图表分析，缺乏针对复杂科学图表的评估。现有图表VQA数据集要么不包含底层数据，要么假设图表标记与数据存在一一对应关系，而现实中图表是数据的转换（分析、简化、修改），这种差异引入了当前数据集未能捕捉的推理挑战。
- Method: 首先调研现有VQA数据集并指出当前领域的局限性。然后基于真实数据生成合成直方图，向人类和大型推理模型提问，其中精确答案依赖于对底层数据的访问。最后发布开源数据集，包括图表、底层数据、生成数据使用的分布参数，以及所有图表标记和文本的边界框。
- Result: 创建了一个专门针对科学图表的VQA基准测试数据集，其中图表标记与底层数据之间不存在一一对应关系，填补了现有研究的空白。
- Conclusion: 需要专门的科学图表VQA基准测试来评估模型在图表标记与底层数据不存在一一对应关系情况下的推理能力，发布的开放数据集为未来研究提供了重要资源。


### [3] [Lost in Space? Vision-Language Models Struggle with Relative Camera Pose Estimation](https://arxiv.org/abs/2601.22228)
*Ken Deng,Yifu Qiu,Yoni Kasten,Shay B. Cohen,Yftah Ziser*

Main category: cs.CV

TL;DR: VLMs在3D空间理解和多视角推理方面存在显著不足，特别是在相对相机姿态估计任务中表现远低于几何方法和人类水平。

- Motivation: 虽然视觉语言模型在2D感知和语义推理方面表现出色，但它们在3D空间结构理解方面存在明显局限。本研究通过相对相机姿态估计这一基础视觉任务来探究这一差距。
- Method: 提出了两个基准：VRRPI-Bench（基于未标记的自我中心视频，带有相对相机运动的语言化标注）和VRRPI-Diag（诊断基准，分离各个运动自由度）。评估了VLMs在相对相机姿态估计任务上的表现。
- Result: 大多数VLMs无法超越浅层的2D启发式方法，特别是在深度变化和绕光轴旋转方面表现不佳。即使是GPT-5（0.64）也远低于经典几何基线（0.97）和人类表现（0.92）。在多图像推理方面，VLMs表现不一致（最佳59.7%）。
- Conclusion: 研究揭示了VLMs在3D基础和多视角空间推理方面的局限性，表明当前模型在理解3D空间结构方面仍有很大提升空间。


### [4] [Geometry without Position? When Positional Embeddings Help and Hurt Spatial Reasoning](https://arxiv.org/abs/2601.22231)
*Jian Shi,Michael Birsak,Wenqing Cui,Zhenyu Li,Peter Wonka*

Main category: cs.CV

TL;DR: 本文从几何视角重新审视视觉Transformer中的位置编码，发现位置编码不仅是token索引，更是塑造表示空间结构的几何先验，通过诊断工具揭示了位置编码如何影响多视角几何一致性和空间推理。

- Motivation: 重新审视视觉Transformer中位置编码的作用，从几何角度理解位置编码如何影响模型的空间表示能力，澄清位置编码作为空间结构因果机制的角色。
- Method: 引入token级别的诊断工具，测量ViT表示中多视角几何一致性如何依赖于一致的位置编码，在14个基础ViT模型上进行广泛实验。
- Result: 揭示了位置编码如何影响多视角几何和空间推理，证明了位置编码作为塑造表示空间结构的几何先验的作用，澄清了位置编码作为控制ViT表示中空间结构的因果机制。
- Conclusion: 位置编码在视觉Transformer中不仅是简单的token索引，而是作为几何先验塑造空间表示结构的关键机制，对多视角几何一致性和空间推理有重要影响。


### [5] [Is Hierarchical Quantization Essential for Optimal Reconstruction?](https://arxiv.org/abs/2601.22244)
*Shirin Reyhanian,Laurenz Wiskott*

Main category: cs.CV

TL;DR: 单层VQ-VAE在匹配表征预算和避免码书崩溃的情况下，可以达到与分层VQ-VAE相同的重建保真度，挑战了分层量化对高质量重建具有固有优势的假设。

- Motivation: 重新审视分层VQ-VAE是否在重建精度上真正优于单层模型。由于分层模型中高层信息完全来源于低层，理论上不应包含额外的重建内容，因此研究在匹配表征预算和避免码书崩溃的情况下，单层模型能否达到相同重建质量。
- Method: 比较两层VQ-VAE与容量匹配的单层模型在高分辨率ImageNet图像上的表现。采用轻量级干预措施：从数据初始化、定期重置不活跃码书向量、系统调整码书超参数，以减少码书崩溃。
- Result: 当表征预算匹配且码书崩溃得到缓解时，单层VQ-VAE能够匹配分层变体的重建保真度。不充分的码书利用会限制单层模型性能，过高维度的嵌入会破坏量化稳定性并增加码书崩溃。
- Conclusion: 分层量化对于高质量重建并非固有优势。在匹配表征预算和有效管理码书崩溃的情况下，单层VQ-VAE可以达到与分层模型相同的重建精度，挑战了传统认知。


### [6] [VMonarch: Efficient Video Diffusion Transformers with Structured Attention](https://arxiv.org/abs/2601.22275)
*Cheng Liang,Haoxian Chen,Liang Hou,Qi Fan,Gangshan Wu,Xin Tao,Limin Wang*

Main category: cs.CV

TL;DR: VMonarch：一种基于Monarch矩阵的新型注意力机制，用于视频扩散变换器，通过结构化稀疏实现次二次复杂度，在保持生成质量的同时显著提升计算效率。

- Motivation: 视频扩散变换器（Video DiTs）中注意力机制的二次复杂度严重限制了上下文可扩展性。研究发现视频DiTs中高度稀疏的时空注意力模式可以自然地用Monarch矩阵表示，这是一种具有灵活稀疏性的结构化矩阵，可通过交替最小化算法实现次二次注意力。
- Method: 1) 采用时空Monarch分解显式捕捉视频数据的帧内和帧间相关性；2) 引入重计算策略缓解Monarch矩阵交替最小化过程中的不稳定伪影；3) 提出融合到FlashAttention中的新型在线熵算法，实现长序列的快速Monarch矩阵更新。
- Result: VMonarch在VBench上经过最小调优后达到与全注意力相当或更优的生成质量。克服了Video DiTs中的注意力瓶颈，将注意力FLOPs减少17.5倍，在长视频注意力计算中实现超过5倍的加速，在90%稀疏度下超越最先进的稀疏注意力方法。
- Conclusion: VMonarch通过Monarch矩阵的结构化稀疏表示，有效解决了视频扩散变换器中注意力机制的二次复杂度问题，实现了高效的长视频生成，为视频生成模型的可扩展性提供了新思路。


### [7] [Coarse-to-Real: Generative Rendering for Populated Dynamic Scenes](https://arxiv.org/abs/2601.22301)
*Gonzalo Gomez-Nogales,Yicong Hong,Chongjian Ge,Marc Comino-Trinidad,Dan Casas,Yi Zhou*

Main category: cs.CV

TL;DR: C2R是一个生成式渲染框架，能从粗糙的3D模拟生成逼真的城市人群视频，通过混合CG-真实训练策略实现可控性和真实性。

- Motivation: 传统渲染管线需要复杂资产、精确材质和光照，计算资源消耗大，在动态人群场景的可扩展性和真实感方面存在挑战。
- Method: 使用粗糙3D渲染控制场景布局、相机运动和人物轨迹，通过学习的神经渲染器根据文本提示生成真实外观、光照和细节动态。采用两阶段混合CG-真实训练策略，从大规模真实视频学习生成先验，通过跨域共享隐式时空特征引入可控性。
- Result: 系统支持从粗糙到精细的控制，能泛化到多样化的CG和游戏输入，从最小化的3D输入生成时间一致、可控且逼真的城市场景视频。
- Conclusion: C2R框架通过结合粗糙3D模拟的显式控制和生成式神经渲染，实现了高质量、可控的城市人群视频合成，解决了传统渲染在动态场景中的可扩展性和真实感问题。


### [8] [FlexMap: Generalized HD Map Construction from Flexible Camera Configurations](https://arxiv.org/abs/2601.22376)
*Run Wang,Chaoyi Zhou,Amir Salarpour,Xi Liu,Zhi-Qi Cheng,Feng Luo,Mert D. Pesé,Siyu Huang*

Main category: cs.CV

TL;DR: FlexMap：一种灵活的高清地图构建方法，无需固定相机配置或显式2D到BEV变换，通过几何感知基础模型和跨帧注意力实现自适应多相机配置。

- Motivation: 当前高清地图构建方法需要校准的多相机设置和2D到BEV变换，当传感器故障或相机配置在不同车辆间变化时变得脆弱，限制了实际部署。
- Method: 使用几何感知基础模型通过跨帧注意力隐式编码3D场景理解，包含时空增强模块（分离跨视图空间推理与时间动态）和相机感知解码器（使用潜在相机令牌实现视图自适应注意力）。
- Result: FlexMap在多种配置下优于现有方法，同时保持对缺失视图和传感器变化的鲁棒性，实现了更实用的现实世界部署。
- Conclusion: FlexMap通过消除显式几何投影和固定相机配置要求，为自动驾驶系统提供了更灵活、鲁棒的高清地图构建解决方案，支持实际部署中的传感器变化。


### [9] [Jailbreaks on Vision Language Model via Multimodal Reasoning](https://arxiv.org/abs/2601.22398)
*Aarush Noheria,Yuguang Yao*

Main category: cs.CV

TL;DR: 提出一种结合后训练思维链提示和ReAct驱动自适应噪声的越狱框架，通过双重策略绕过视觉语言模型的安全过滤器

- Motivation: 视觉语言模型对提示变化高度敏感，可能暴露安全对齐的漏洞。现有方法在绕过安全过滤器方面效果有限，需要更隐蔽有效的攻击策略。
- Method: 1) 利用后训练思维链提示构建隐蔽提示；2) 提出ReAct驱动的自适应噪声机制，基于模型反馈迭代扰动输入图像，在可能激活安全防御的区域优化对抗噪声
- Result: 实验结果表明，双重策略显著提高了攻击成功率，同时在文本和视觉领域保持了自然性
- Conclusion: 该框架揭示了视觉语言模型安全对齐的脆弱性，为开发更鲁棒的防御机制提供了重要见解


### [10] [EMBC Special Issue: Calibrated Uncertainty for Trustworthy Clinical Gait Analysis Using Probabilistic Multiview Markerless Motion Capture](https://arxiv.org/abs/2601.22412)
*Seth Donahue,Irina Djuraskovic,Kunal Shah,Fabian Sinz,Ross Chafetz,R. James Cotton*

Main category: cs.CV

TL;DR: 基于变分推理的概率多视角无标记运动捕捉系统能够可靠地量化不确定性，在步态分析中表现出良好的校准性能，无需地面真值即可识别不可靠输出。

- Motivation: 临床实践中需要多视角无标记运动捕捉系统不仅准确，还要能提供可靠的置信区间来指示个体测量的准确性，以建立临床信任。
- Method: 基于变分推理估计关节角度后验分布的概率方法，使用68名参与者的数据，与仪器化步道和标准标记式运动捕捉进行验证，使用期望校准误差评估置信区间校准。
- Result: 模型表现出可靠的校准性能，步长和跨步长的ECE值一般<0.1，中位步长误差~16mm，跨步长误差~12mm，下肢关节运动学误差1.5-3.8度，预测不确定性与观测误差强相关。
- Conclusion: 概率模型能够量化认知不确定性，无需同步地面真值仪器即可识别不可靠输出，为临床实施提供了信任基础。


### [11] [Countering the Over-Reliance Trap: Mitigating Object Hallucination for LVLMs via a Self-Validation Framework](https://arxiv.org/abs/2601.22451)
*Shiyu Liu,Xinyi Wen,Zhibin Lan,Ante Wang,Jinsong Su*

Main category: cs.CV

TL;DR: 论文提出了一种无需训练的自验证框架，通过语言先验无关验证来缓解大型视觉语言模型在图像描述任务中的物体幻觉问题。

- Motivation: 尽管大型视觉语言模型取得进展，但物体幻觉问题仍然严重，模型会描述不存在的物体，影响可靠性。先前工作归因于模型过度依赖语言先验，但缺乏深入分析。研究发现随着生成长度增加，语言先验依赖导致幻觉物体token概率膨胀，加剧幻觉问题。
- Method: 提出语言先验无关验证方法，使模型能忠实验证物体存在的置信度。基于此提出无需训练的自验证框架：首先验证候选描述中物体的存在性，然后通过描述选择或聚合来缓解物体幻觉。
- Result: 实验结果显示，该框架在图像描述任务中显著缓解物体幻觉（例如LLaVA-v1.5-7B在CHAIRI指标上提升65.6%），超越了先前的最先进方法。
- Conclusion: 该研究揭示了通过挖掘大型视觉语言模型自身内在潜力来缓解幻觉问题的新路径，为提升模型可靠性提供了有效方案。


### [12] [ScribbleSense: Generative Scribble-Based Texture Editing with Intent Prediction](https://arxiv.org/abs/2601.22455)
*Yudi Zhang,Yeming Geng,Lei Zhang*

Main category: cs.CV

TL;DR: ScribbleSense：结合多模态大语言模型和图像生成模型，解决涂鸦式3D纹理编辑中的意图模糊和语义定位不清问题，实现更直观的涂鸦交互编辑。

- Motivation: 现有3D模型纹理编辑方法主要支持基于轮廓的草图交互，而粗粒度的涂鸦式交互利用有限。涂鸦指令的抽象性常导致编辑意图模糊和目标语义位置不明确，需要解决这些问题来提升涂鸦交互的实用性。
- Method: 提出ScribbleSense方法：1）利用多模态大语言模型（MLLMs）的视觉能力预测涂鸦背后的编辑意图；2）一旦识别涂鸦的语义意图，使用全局生成的图像提取局部纹理细节，从而锚定局部语义并缓解目标语义位置的模糊性。
- Result: 实验结果表明，该方法有效利用了MLLMs的优势，在基于涂鸦的纹理编辑交互中实现了最先进的编辑性能。
- Conclusion: ScribbleSense成功解决了涂鸦式3D纹理编辑中的意图模糊和语义定位问题，通过结合MLLMs和图像生成模型，显著提升了涂鸦交互的实用性和编辑效果。


### [13] [Training-Free Representation Guidance for Diffusion Models with a Representation Alignment Projector](https://arxiv.org/abs/2601.22468)
*Wenqiang Zu,Shenghao Xie,Bo Lei,Lei Ma*

Main category: cs.CV

TL;DR: 提出一种基于表示对齐投影器的扩散模型引导方法，通过将预测的语义表示注入采样中间步骤，改善早期去噪阶段的语义漂移问题，显著提升图像合成的语义一致性和视觉质量。

- Motivation: 现有扩散模型的推理时引导方法（如无分类器引导和代表性引导）虽然能增强语义对齐，但未能充分利用无监督特征表示。这些视觉表示包含丰富的语义结构，但由于推理时缺乏真实参考图像，其集成受到限制。研究发现扩散变换器在早期去噪阶段存在语义漂移问题，随机性导致即使在相同条件下也会产生不一致的对齐。
- Method: 引入一种基于表示对齐投影器的引导方案，该投影器将预测的表示注入到中间采样步骤中，提供有效的语义锚点，而不需要修改模型架构。该方法在SiTs和REPAs模型上进行实验验证。
- Result: 在ImageNet类条件合成任务中取得了显著改进，FID分数大幅降低：REPA-XL/2从5.9提升到3.3。该方法在SiT模型上也优于代表性引导。与无分类器引导结合时产生互补增益，增强了语义连贯性和视觉保真度。
- Conclusion: 基于表示信息的扩散采样是一种实用的策略，能够加强语义保持和图像一致性，为扩散模型的高质量视觉合成提供了有效的引导方法。


### [14] [Head-Aware Visual Cropping: Enhancing Fine-Grained VQA with Attention-Guided Subimage](https://arxiv.org/abs/2601.22483)
*Junfei Xie,Peng Pan,Xulong Zhang*

Main category: cs.CV

TL;DR: HAVC是一种无需训练的视觉裁剪方法，通过选择性地利用注意力头来提升多模态大语言模型在细粒度视觉问答中的视觉定位能力。

- Motivation: 多模态大语言模型在视觉问答中表现出色，但由于低分辨率输入和噪声注意力聚合，在细粒度推理方面仍有局限。需要一种方法来提升模型的视觉定位精度。
- Method: 提出HAVC方法：1) 通过OCR诊断任务筛选具有真实定位能力的注意力头；2) 在推理时使用空间熵增强空间集中度，使用梯度敏感性评估预测贡献；3) 融合信号生成视觉裁剪指导图，裁剪出任务相关区域子图像；4) 将子图像与原始图像-问题对一起输入MLLM。
- Result: 在多个细粒度VQA基准测试中，HAVC持续优于最先进的裁剪策略，实现了更精确的定位和更强的视觉定位能力。
- Conclusion: HAVC提供了一种简单而有效的策略，通过训练免费的方式增强MLLM的精度，为提升多模态模型的细粒度推理能力提供了新思路。


### [15] [PromptMAD: Cross-Modal Prompting for Multi-Class Visual Anomaly Localization](https://arxiv.org/abs/2601.22492)
*Duncan McCain,Hossein Kashiani,Fatemeh Afghah*

Main category: cs.CV

TL;DR: PromptMAD：基于跨模态提示的无监督视觉异常检测框架，通过视觉-语言对齐整合语义指导，在MVTec-AD数据集上实现SOTA性能

- Motivation: 多类别视觉异常检测面临三大挑战：物体类别多样性、异常样本稀缺性、伪装缺陷存在性。现有方法在语义理解和细微异常检测方面存在不足。
- Method: 1. 跨模态提示框架：利用CLIP编码的文本提示描述正常和异常类别特征，为视觉重建提供语义上下文；2. 引入Focal loss解决像素级类别不平衡问题；3. 监督分割器融合多尺度卷积特征、Transformer空间注意力和扩散迭代细化，生成高分辨率异常图
- Result: 在MVTec-AD数据集上实现最先进的像素级性能：平均AUC达到98.35%，AP达到66.54%，在不同类别上保持高效性
- Conclusion: PromptMAD通过整合语义指导和解决类别不平衡问题，显著提升了多类别视觉异常检测性能，特别是在细微和纹理异常检测方面表现优异


### [16] [MIRRORTALK: Forging Personalized Avatars Via Disentangled Style and Hierarchical Motion Control](https://arxiv.org/abs/2601.22501)
*Renjie Lu,Xulong Zhang,Xiaoyang Qu,Jianzong Wang,Shangfei Wang*

Main category: cs.CV

TL;DR: MirrorTalk是一个基于条件扩散模型的生成框架，通过语义解耦风格编码器从参考视频中提取纯风格表示，并使用层次调制策略实现高精度唇部同步和个性化面部动态合成。

- Motivation: 现有方法在合成个性化说话人脸时，难以将说话者特有的风格与语义内容解耦，导致无法将说话者的独特个性忠实地转移到任意语音上，限制了个性化表达的准确性。
- Method: 提出MirrorTalk框架：1）基于条件扩散模型；2）引入语义解耦风格编码器（SDSE）从简短参考视频中提取纯风格表示；3）在扩散过程中采用层次调制策略，动态平衡音频和风格特征在不同面部区域的贡献。
- Result: 大量实验表明，MirrorTalk在唇部同步准确性和个性化保持方面显著优于现有最先进方法。
- Conclusion: MirrorTalk通过解耦风格与语义内容，结合层次调制策略，成功实现了高精度唇部同步和个性化面部动态合成，为个性化说话人脸生成提供了有效解决方案。


### [17] [DreamVAR: Taming Reinforced Visual Autoregressive Model for High-Fidelity Subject-Driven Image Generation](https://arxiv.org/abs/2601.22507)
*Xin Jiang,Jingwen Chen,Yehao Li,Yingwei Pan,Kezhou Chen,Zechao Li,Ting Yao,Tao Mei*

Main category: cs.CV

TL;DR: DreamVAR是一个基于视觉自回归模型的主题驱动图像生成框架，通过预填充主题特征序列和强化学习优化，在保持主题一致性和语义对齐方面优于现有扩散模型方法。

- Motivation: 尽管视觉自回归模型具有统一架构和高效推理的优势，但在主题驱动图像生成领域的潜力尚未得到充分探索。现有扩散模型虽然能生成高质量图像，但VAR模型在这方面的应用仍有待开发。
- Method: 1. 使用视觉分词器提取参考主题的多尺度特征；2. 在预测目标图像token之前，预填充完整的主题特征序列（而非跨尺度交错）；3. 采用强化学习联合优化语义对齐和主题一致性。
- Result: 大量实验表明，DreamVAR在保持主题外观方面优于领先的基于扩散的方法，实现了更好的主题一致性和语义对齐。
- Conclusion: DreamVAR展示了VAR模型在主题驱动图像生成中的潜力，通过简化自回归依赖关系和缓解训练-测试差异，为这一领域提供了新的有效解决方案。


### [18] [CoVA: Text-Guided Composed Video Retrieval for Audio-Visual Content](https://arxiv.org/abs/2601.22508)
*Gyuwon Han,Young Kyun Jang,Chanho Eom*

Main category: cs.CV

TL;DR: 提出CoVA任务和AV-Comp基准，用于视频检索时同时考虑视觉和音频变化，并开发AVT模型进行多模态特征融合

- Motivation: 现有视频检索基准只考虑视觉变化，忽略了音频差异，需要开发能同时处理视觉和音频变化的检索任务
- Method: 构建AV-Comp基准数据集，包含视频对和描述差异的文本查询；提出AVT Compositional Fusion模型，通过选择性对齐查询到最相关模态来整合视频、音频和文本特征
- Result: AVT模型优于传统单模态融合方法，为CoVA任务提供了强有力的基线
- Conclusion: CoVA任务填补了视频检索中同时考虑视觉和音频变化的空白，AV-Comp基准和AVT模型为这一新任务提供了基础框架


### [19] [DNA: Uncovering Universal Latent Forgery Knowledge](https://arxiv.org/abs/2601.22515)
*Jingtong Dou,Chuancheng Shi,Yemin Wang,Shiming Guo,Anqi Yi,Wenhua Wu,Li Zhang,Fei Shen,Tat-Seng Chua*

Main category: cs.CV

TL;DR: 提出DNA框架，通过挖掘预训练模型中的固有伪造检测能力，无需端到端重训练，在少样本条件下实现优越检测性能

- Motivation: 随着生成式AI达到超逼真水平，表面伪影检测已过时。现有方法依赖资源密集的黑盒骨干网络微调，但作者认为伪造检测能力已编码在预训练模型中，无需端到端重训练
- Method: 提出判别性神经锚点(DNA)框架，采用粗到细的挖掘机制：1)分析特征解耦和注意力分布变化，定位模型从全局语义转向局部异常的关键中间层；2)引入三元融合评分指标配合曲率截断策略，剥离语义冗余，精确分离对伪造痕迹敏感的伪造判别单元(FDUs)；3)构建HIFI-Gen高保真合成基准数据集
- Result: 实验表明，仅依赖这些锚点，DNA在少样本条件下实现优越检测性能，在不同架构和未见生成模型上表现出显著鲁棒性
- Conclusion: 唤醒潜在神经元比大量微调更有效，验证了伪造检测能力已编码在预训练模型中而非需要端到端重训练


### [20] [Can 3D point cloud data improve automated body condition score prediction in dairy cattle?](https://arxiv.org/abs/2601.22522)
*Zhou Tang,Jin Wang,Angelo De Castro,Yuxi Zhang,Victoria Bastos Primo,Ana Beatriz Montevecchio Bernardino,Gota Morota,Xu Wang,Ricardo C Chebel,Haipeng Yu*

Main category: cs.CV

TL;DR: 本研究比较了深度图像和点云数据在奶牛体况评分预测中的表现，发现深度图像在多数情况下优于点云数据，点云对噪声和模型架构更敏感。

- Motivation: 传统的奶牛体况评分主观且劳动密集，计算机视觉方法如深度图像已被应用，但三维点云数据能提供更丰富的几何特征，然而两者直接比较的研究有限。
- Method: 在四种设置下比较俯视深度图像和点云数据：1)未分割原始数据，2)分割全身数据，3)分割后躯数据，4)手工特征数据。使用1020头奶牛数据，采用个体级交叉验证防止数据泄露。
- Result: 深度图像模型在使用未分割原始数据和分割全身数据时准确率更高；使用分割后躯数据时两者性能相当；使用手工特征数据时两者准确率都下降。点云预测对噪声和模型架构更敏感。
- Conclusion: 在评估条件下，三维点云相比深度图像在奶牛体况评分预测中没有提供一致的优势，深度图像仍是更可靠的选择。


### [21] [SHED Light on Segmentation for Dense Prediction](https://arxiv.org/abs/2601.22529)
*Seung Hyun Lee,Sangwoo Mo,Stella X. Yu*

Main category: cs.CV

TL;DR: SHED是一种新的编码器-解码器架构，通过将分割融入密集预测来显式加强几何先验，通过双向分层推理实现层次感知，无需显式分割监督即可提升深度边界清晰度和结构一致性。

- Motivation: 现有密集预测方法将像素视为独立预测，忽略了真实世界场景的强结构特性，导致结构不一致问题。需要一种能显式融入几何先验的方法来改善这一问题。
- Method: 提出SHED编码器-解码器架构，通过双向分层推理将分割标记分层池化（编码器）和反池化（解码器）。模型仅在最终输出端进行监督，使分割层次自然涌现而无需显式分割监督。
- Result: SHED提升了深度边界清晰度和分割一致性，在从合成到真实世界的跨域泛化中表现优异。其层次感知解码器能更好地捕捉全局3D场景布局，改善语义分割性能，同时提升3D重建质量并揭示可解释的部分级结构。
- Conclusion: SHED通过显式融入几何先验和双向分层推理，有效解决了传统像素级方法的结构不一致问题，在密集预测任务中实现了更好的结构一致性和可解释性。


### [22] [Hybrid Cross-Device Localization via Neural Metric Learning and Feature Fusion](https://arxiv.org/abs/2601.22551)
*Meixia Lin,Mingkai Liu,Shuxue Peng,Dikai Fan,Shengyu Gu,Xianliang Huang,Haoyang Ye,Xiao Liu*

Main category: cs.CV

TL;DR: 提出用于CroCoDL 2025挑战赛的混合跨设备定位流水线，结合检索编码器和两个互补定位分支，在HYDRO和SUCCU基准上显著提升召回率和精度

- Motivation: 解决跨设备定位挑战，需要处理不同传感器配置和环境的复杂定位问题，提高在多样化场景中的定位准确性和鲁棒性
- Method: 1. 共享检索编码器提取特征；2. 几何分支（特征融合+PnP）；3. 神经网络前馈分支（MapAnything）；4. 神经引导候选剪枝策略；5. 深度条件定位优化
- Result: 在HYDRO和SUCCU基准上显著提升召回率和精度，挑战赛最终得分92.62（R@0.5m, 5°）
- Conclusion: 混合方法结合几何和神经网络组件，通过互补定位分支和优化策略，在跨设备定位任务中取得了优异性能


### [23] [Leveraging Data to Say No: Memory Augmented Plug-and-Play Selective Prediction](https://arxiv.org/abs/2601.22570)
*Aditya Sarkar,Yi Li,Jiacheng Cheng,Shlok Mishra,Nuno Vasconcelos*

Main category: cs.CV

TL;DR: 该论文提出MA-PaPSP方法，通过记忆增强和检索机制解决视觉语言基础模型在选择性预测中的嵌入不稳定和分数校准问题。

- Motivation: 现有选择性预测方法主要针对闭集任务，而视觉语言基础模型面临从闭集到开集、有限到无限词汇的复杂任务，需要低复杂度、免训练、通用性强的解决方案。
- Method: 提出记忆增强的PaPSP方法：1) 使用检索数据集存储图像-文本对；2) 通过检索最近邻对平均来减少嵌入方差；3) 使用对比归一化改进分数校准。
- Result: 在多个数据集上的实验表明，MA-PaPSP在选择性描述、图像-文本匹配和细粒度分类任务上优于PaPSP和其他选择性预测基线方法。
- Conclusion: MA-PaPSP通过记忆增强有效解决了视觉语言基础模型选择性预测中的嵌入不稳定和校准问题，为开放词汇任务提供了有效的免训练解决方案。


### [24] [DELNet: Continuous All-in-One Weather Removal via Dynamic Expert Library](https://arxiv.org/abs/2601.22573)
*Shihong Liu,Kun Zuo,Hanguang Xiao*

Main category: cs.CV

TL;DR: DELNet是一个用于天气图像修复的持续学习框架，通过判断阀和动态专家库实现无需重新训练现有模型即可处理新任务，显著降低部署成本。

- Motivation: 现有的全合一天气图像修复方法依赖预收集数据，对于未见过的退化类型需要重新训练，导致成本高昂。需要一种能够持续学习新任务而无需重新训练现有模型的方法。
- Method: DELNet包含两个核心组件：1）判断阀，用于测量任务相似度以区分新任务和已知任务；2）动态专家库，存储针对不同退化类型训练的专家模型。对于新任务，选择top-k专家进行知识迁移，同时添加新专家捕捉任务特定特征；对于已知任务，直接重用相应专家。
- Result: 在OTS、Rain100H和Snow100K数据集上的实验表明，DELNet超越了最先进的持续学习方法，分别实现了16%、11%和12%的PSNR增益。这些结果证明了DELNet的有效性、鲁棒性和效率。
- Conclusion: DELNet通过持续学习框架显著降低了天气图像修复的重新训练成本，实现了实际部署的可行性，在真实场景中具有实用价值。


### [25] [Mitigating Hallucinations in Video Large Language Models via Spatiotemporal-Semantic Contrastive Decoding](https://arxiv.org/abs/2601.22574)
*Yuansheng Gao,Jinman Zhao,Tong Zhang,Xingguo Xu,Han Bao,Zonghui Wang,Wenzhi Chen*

Main category: cs.CV

TL;DR: 提出时空语义对比解码策略，通过破坏视频特征的时空一致性和语义关联构建负特征，在推理时与原视频特征对比来抑制视频大语言模型的幻觉问题。

- Motivation: 视频大语言模型虽然在各种任务上表现优异，但仍存在幻觉问题，即生成与视频内容或事实证据不一致的输出。现有的解码方法大多依赖启发式设计，未能精确捕捉幻觉的根本原因及其细粒度时空语义关联，导致在复杂场景中鲁棒性和泛化能力有限。
- Method: 提出时空语义对比解码策略：1）通过故意破坏视频特征的时空一致性和语义关联来构建负特征；2）在推理过程中，通过与原视频特征进行对比解码来抑制幻觉生成。
- Result: 大量实验表明，该方法不仅有效减少了幻觉的发生，而且保持了模型的通用视频理解和推理能力。
- Conclusion: 提出的时空语义对比解码策略能够更有效地缓解视频大语言模型的幻觉问题，相比现有方法具有更好的鲁棒性和泛化能力。


### [26] [PhoStream: Benchmarking Real-World Streaming for Omnimodal Assistants in Mobile Scenarios](https://arxiv.org/abs/2601.22575)
*Xudong Lu,Huankang Guan,Yang Bo,Jinpeng Chen,Xintong Guo,Shuhan Li,Fang Liu,Peiwen Sun,Xueying Li,Wei Zhang,Xue Yang,Rui Liu,Hongsheng Li*

Main category: cs.CV

TL;DR: PhoStream是首个面向移动助手的流式音频-视觉基准测试，包含5,572个开放性问题，评估模型在连续实时流中的视频、音频和时间推理能力，发现当前MLLMs在决定何时响应方面存在严重缺陷。

- Motivation: 当前多模态大语言模型擅长离线音频-视觉理解，但在连续实时流中作为移动助手的能力尚未充分探索。日常手机使用中，助手需要跟踪流式输入并在正确时间响应，而现有基准测试通常局限于选择题或使用较短视频。
- Method: 提出PhoStream基准测试，包含5,572个开放QA对，来自578个视频，涵盖4种场景和10种能力。采用自动化生成流水线构建，并进行严格人工验证。使用现实在线推理流水线评估模型，采用LLM-as-a-Judge方法评估开放响应。
- Result: 实验显示LLM评分存在时间不对称性：模型在即时和向后任务上表现良好（Gemini 3 Pro超过80分），但在向前任务上急剧下降（16.40分），主要因为模型在所需视觉和音频线索出现前就过早响应。
- Conclusion: 当前MLLMs存在根本性局限：不仅难以决定说什么，更难以决定何时说。模型需要在流式环境中学习适当的响应时机判断能力。


### [27] [Cross-Domain Few-Shot Learning for Hyperspectral Image Classification Based on Mixup Foundation Model](https://arxiv.org/abs/2601.22581)
*Naeem Paeedeh,Mahardhika Pratama,Ary Shiddiqi,Zehong Cao,Mukesh Prasad,Wisnu Jatmiko*

Main category: cs.CV

TL;DR: MIFOMO提出了一种基于基础模型的跨域少样本高光谱图像分类方法，通过混合域适应和凝聚投影解决数据稀缺和域差异问题，性能优于现有方法达14%。

- Motivation: 现有跨域少样本高光谱图像分类方法依赖不现实的数据增强（外部噪声）来扩大样本量，参数多易过拟合，且未利用具有强泛化能力的基础模型。
- Method: 基于遥感基础模型构建MIFOMO，引入凝聚投影快速适应下游任务（冻结主干网络），提出混合域适应解决极端域差异问题，并采用标签平滑处理噪声伪标签。
- Result: 实验证明MIFOMO优于现有方法，性能提升最高达14%，代码已开源。
- Conclusion: MIFOMO通过利用基础模型的泛化能力，结合凝聚投影、混合域适应和标签平滑，有效解决了跨域少样本高光谱图像分类中的数据稀缺和域差异问题。


### [28] [FOTBCD: A Large-Scale Building Change Detection Benchmark from French Orthophotos and Topographic Data](https://arxiv.org/abs/2601.22596)
*Abdelrrahman Moubane*

Main category: cs.CV

TL;DR: FOTBCD是一个大规模法国建筑变化检测数据集，覆盖法国28个省份，包含约28,000对前后图像及像素级变化掩码，旨在评估地理域转移下的泛化能力。

- Motivation: 现有建筑变化检测数据集通常局限于单个城市或有限区域，缺乏地理多样性，难以评估模型在地理域转移下的泛化能力。需要大规模、地理分布广泛的数据集来推动该领域发展。
- Method: 基于法国国家地理研究所(IGN)的权威正射影像和地形建筑数据，构建覆盖28个省份的大规模数据集。将25个省份用于训练，3个地理上不相连的省份用于评估。数据集包含FOTBCD-Binary（约28,000对图像及像素级变化掩码）和FOTBCD-Instances（实例级标注子集）。
- Result: 发布了FOTBCD-Binary数据集（公开可用）和FOTBCD-Instances子集。通过固定基线方法，在LEVIR-CD+和WHU-CD上进行了基准测试，证明数据集层面的地理多样性能够显著提升建筑变化检测的跨域泛化能力。
- Conclusion: FOTBCD是一个大规模、地理多样化的建筑变化检测数据集，填补了现有基准的空白。实验表明地理多样性有助于提升模型在地理域转移下的泛化性能，为相关研究提供了重要的基准资源。


### [29] [TTSA3R: Training-Free Temporal-Spatial Adaptive Persistent State for Streaming 3D Reconstruction](https://arxiv.org/abs/2601.22615)
*Zhijie Zheng,Xinhao Xiang,Jiawei Zhang*

Main category: cs.CV

TL;DR: TTSA3R：一种无需训练、利用时空自适应信号进行3D重建的框架，通过分析状态演化和观测质量来缓解长期序列中的灾难性遗忘问题。

- Motivation: 现有的流式循环模型在3D重建中虽然能保持持久状态表示，但在长序列中会遭受灾难性记忆遗忘问题。现有方法仅从注意力角度考虑单维度信号，忽略了时空一致性。
- Method: 提出TTSA3R框架，包含两个模块：1) 时间自适应更新模块，通过分析时间状态演化模式来调节更新幅度；2) 空间上下文更新模块，通过观测-状态对齐和场景动态来定位需要更新的空间区域。最后融合这两个互补信号来确定状态更新策略。
- Result: 在多种3D任务上的实验证明了TTSA3R的有效性。在扩展序列上，该方法仅增加15%的错误率，而基线模型错误率增加超过200%，显著提高了长期重建稳定性。
- Conclusion: TTSA3R通过同时考虑时间状态演化和空间观测质量，实现了更稳定和高效的3D重建，有效缓解了长期序列中的灾难性遗忘问题。


### [30] [UniGeo: A Unified 3D Indoor Object Detection Framework Integrating Geometry-Aware Learning and Dynamic Channel Gating](https://arxiv.org/abs/2601.22616)
*Xing Yi,Jinyang Huang,Feng-Qi Cui,Anyang Tong,Ruimin Wang,Liu Liu,Dan Guo*

Main category: cs.CV

TL;DR: UniGeo：一种统一的3D室内检测框架，通过几何感知学习模块和动态通道门控机制增强稀疏点云场景的几何关系建模和特征表示。

- Motivation: 随着机器人和增强现实应用的普及，基于点云的3D物体检测研究日益重要。现有方法在多数据集统一训练方面存在不足，未能有效建模稀疏点云场景的几何关系，且忽略了重要区域的特征分布，限制了性能提升。
- Method: 提出UniGeo框架：1) 几何感知学习模块，建立从空间关系到特征权重的可学习映射，实现显式几何特征增强；2) 动态通道门控机制，利用可学习的通道级权重自适应优化稀疏3D U-Net网络生成的特征，显著增强关键几何信息。
- Result: 在六个不同的室内场景数据集上进行广泛实验，结果明确验证了该方法具有优越性能。
- Conclusion: UniGeo框架通过几何关系建模和特征优化机制，有效解决了现有方法在稀疏点云场景中的局限性，为3D室内物体检测提供了更优的解决方案。


### [31] [LINA: Linear Autoregressive Image Generative Models with Continuous Tokens](https://arxiv.org/abs/2601.22630)
*Jiahao Wang,Ting Pan,Haoge Deng,Dongchen Han,Taiqiang Wu,Xinlong Wang,Ping Luo*

Main category: cs.CV

TL;DR: LINA是一个基于线性注意力的高效文本到图像生成模型，通过优化归一化方法和引入卷积增强局部建模，在保持性能的同时大幅降低计算成本。

- Motivation: 连续token的自回归模型在视觉生成中很有前景，但计算成本高。研究旨在设计计算高效的线性注意力机制，降低文本到图像合成的计算负担。
- Method: 1. 系统分析不同设计选择下的缩放行为：比较除法归一化与减法归一化；2. 引入深度卷积增强局部建模；3. 将门控机制扩展到双向设置，提出KV门控，通过可学习参数实现灵活的token记忆管理。
- Result: LINA在ImageNet上达到2.18 FID（约14亿参数），在GenEval上达到0.74（约15亿参数）。单个线性注意力模块相比softmax注意力减少约61% FLOPs，能生成1024x1024高保真图像。
- Conclusion: 除法归一化在线性生成变换器中缩放效果更好，卷积对局部建模至关重要。提出的LINA模型证明了线性注意力在保持竞争力的同时能显著降低计算成本，为高效视觉生成提供了新方向。


### [32] [What can Computer Vision learn from Ranganathan?](https://arxiv.org/abs/2601.22634)
*Mayukh Bagchi,Fausto Giunchiglia*

Main category: cs.CV

TL;DR: 该论文提出使用S.R. Ranganathan的分类学原则来解决计算机视觉中的语义鸿沟问题，并开发了vTelos标注方法，实验证明该方法能提升标注质量和视觉识别准确率。

- Motivation: 计算机视觉中存在语义鸿沟问题，即视觉语义与词汇语义之间的不匹配，这导致了有缺陷的CV数据集设计和基准测试。需要寻找一个原则性的方法来设计高质量的CV数据集。
- Method: 采用S.R. Ranganathan的分类学原则，并将其适当调整后应用于计算机视觉领域，开发了vTelos CV标注方法学。
- Result: 论文提供了实验证据，表明vTelos方法能够改善CV标注质量和准确率，从而验证了该方法的有效性。
- Conclusion: Ranganathan的分类学原则为解决计算机视觉中的语义鸿沟问题提供了原则性的起点，vTelos标注方法能够有效提升CV数据集质量和识别性能。


### [33] [Unsupervised Synthetic Image Attribution: Alignment and Disentanglement](https://arxiv.org/abs/2601.22663)
*Zongfang Liu,Guangyi Chen,Boyang Sun,Tongliang Liu,Kun Zhang*

Main category: cs.CV

TL;DR: 提出无监督合成图像溯源方法Alignment and Disentanglement，通过对比自监督学习和信息最大化损失实现概念对齐和表示解耦，在真实基准测试中超越有监督方法。

- Motivation: 随着合成图像质量提高，识别模型生成图像的概念来源对版权保护和模型透明度至关重要。现有方法需要标注的合成图像-训练源配对数据，但获取这种配对监督成本高昂且困难。
- Method: 提出Alignment and Disentanglement方法：1) 使用对比自监督学习进行基础概念对齐；2) 通过Infomax损失促进表示解耦来增强溯源能力。该方法基于MoCo和DINO等对比自监督模型具有跨域对齐能力的观察，从理论角度解释了如何通过分解典型相关分析目标来近似概念匹配过程。
- Result: 在真实世界基准测试AbC上，无监督方法意外地超越了有监督方法。
- Conclusion: 提出的无监督合成图像溯源方法通过概念对齐和表示解耦，在无需成本高昂的配对标注情况下取得了优异性能，为这一挑战性任务提供了新的视角。


### [34] [ExpAlign: Expectation-Guided Vision-Language Alignment for Open-Vocabulary Grounding](https://arxiv.org/abs/2601.22666)
*Junyi Hu,Tian Bai,Fengyi Wu,Wenyan Li,Zhenming Peng,Yi Zhang*

Main category: cs.CV

TL;DR: ExpAlign：基于多实例学习理论框架的开放词汇视觉语言对齐方法，通过期望对齐头和能量多尺度一致性正则化，在弱监督下实现细粒度对齐，提升开放词汇检测和零样本实例分割性能。

- Motivation: 现有开放词汇对齐方法存在两个问题：1）全局句子嵌入缺乏细粒度表达能力；2）基于显式监督或复杂跨注意力设计的token级对齐方法成本高。需要一种在弱监督下实现细粒度对齐的轻量高效方法。
- Method: 1）基于多实例学习理论框架，提出期望对齐头，通过注意力软MIL池化在token-region相似度上进行隐式token和实例选择；2）能量多尺度一致性正则化方案，包括Top-K多正例对比目标和基于拉格朗日约束自由能最小化的几何感知一致性目标。
- Result: 在开放词汇检测和零样本实例分割任务上表现优异，特别是在长尾类别上。在LVIS minival split上达到36.2 AP_r，优于同规模的其他SOTA方法，同时保持轻量和推理高效。
- Conclusion: ExpAlign通过理论驱动的多实例学习框架和一致性正则化，在弱监督下实现了细粒度的视觉语言对齐，为开放词汇任务提供了轻量高效的解决方案，在长尾类别上表现尤为突出。


### [35] [VisionTrim: Unified Vision Token Compression for Training-Free MLLM Acceleration](https://arxiv.org/abs/2601.22674)
*Hanxun Yu,Wentong Li,Xuan Qu,Song Wang,Junbo Chen,Jianke Zhu*

Main category: cs.CV

TL;DR: VisionTrim是一个无需训练的多模态大语言模型加速框架，通过视觉令牌选择和文本引导的令牌合并来减少计算成本

- Motivation: 多模态大语言模型在高分辨率和视频场景中因过多的视觉令牌导致计算成本过高，现有令牌减少方法通常关注孤立的流水线组件且忽视文本对齐，导致性能下降
- Method: 提出VisionTrim统一框架，包含两个即插即用模块：1) 主导视觉令牌选择模块，通过全局-局部视图保留关键视觉令牌；2) 文本引导视觉补充模块，在文本线索指导下进行上下文感知的令牌合并
- Result: 在多样化的图像和视频多模态基准测试中表现出性能优势，推动了多模态大语言模型在实际应用中的部署
- Conclusion: VisionTrim为无需训练的多模态大语言模型加速提供了一个有效的统一框架，通过视觉令牌选择和文本引导的令牌合并解决了计算成本问题


### [36] [Fire on Motion: Optimizing Video Pass-bands for Efficient Spiking Action Recognition](https://arxiv.org/abs/2601.22675)
*Shuhan Ye,Yuanbin Qian,Yi Yu,Chong Wang,Yuqi Xie,Jiazhen Xu,Kun Wang,Xudong Jiang*

Main category: cs.CV

TL;DR: 该论文提出PBO（Pass-Bands Optimizer）模块，通过优化SNN的时域通带，使其专注于运动相关频段，从而显著提升SNN在动态视频任务上的性能。

- Motivation: SNN虽然在静态图像任务上接近ANN，但在动态视频任务上表现不佳。作者诊断出根本原因在于标准脉冲动态行为类似于时域低通滤波器，强调静态内容而衰减运动相关频段，导致SNN无法有效处理动态任务。
- Method: 提出PBO（Pass-Bands Optimizer）模块，这是一个即插即用的优化器，仅引入两个可学习参数和轻量级一致性约束。PBO通过抑制对分类贡献小的静态成分，有效高通滤波数据流，使脉冲活动集中在运动相关内容上。
- Result: 在UCF101数据集上，PBO带来超过10个百分点的性能提升。在更复杂的多模态动作识别和弱监督视频异常检测任务上，PBO也带来一致且显著的性能增益。
- Conclusion: PBO通过优化SNN的时域通带，使其专注于任务相关的运动频段，为基于SNN的视频处理和理解提供了新视角，同时保持了计算效率和架构兼容性。


### [37] [Visual Personalization Turing Test](https://arxiv.org/abs/2601.22680)
*Rameen Abdal,James Burgess,Sergey Tulyakov,Kuan-Chieh Jackson Wang*

Main category: cs.CV

TL;DR: VPTT提出基于感知不可区分性而非身份复制的视觉个性化评估新范式，通过VPTT框架（包含10k人物基准、视觉检索增强生成器和VPTT评分）验证个性化生成AI的感知质量。

- Motivation: 传统视觉个性化评估主要关注身份复制准确性，但忽略了内容是否看起来像特定人物可能创建或分享的真实内容。需要一种基于感知不可区分性的新评估范式来更好地衡量个性化生成质量。
- Method: 提出VPTT框架：1) VPTT-Bench包含10,000个人物基准；2) VPRAG视觉检索增强生成器；3) VPTT评分指标，通过人类和视觉语言模型判断校准，仅使用文本进行评估。
- Result: 人类、VLM和VPTT评分之间显示出高度相关性，验证了VPTT评分作为可靠感知代理的有效性。VPRAG在一致性和原创性之间达到最佳平衡，为个性化生成AI提供了可扩展且隐私安全的基础。
- Conclusion: VPTT为视觉个性化评估提供了新的感知不可区分性范式，VPTT框架能够可靠评估个性化内容质量，VPRAG方法在保持隐私安全的同时实现了高质量个性化生成。


### [38] [OOVDet: Low-Density Prior Learning for Zero-Shot Out-of-Vocabulary Object Detection](https://arxiv.org/abs/2601.22685)
*Binyi Su,Chenghao Huang,Haiyong Chen*

Main category: cs.CV

TL;DR: 提出OOVDet框架，通过合成区域级OOV提示和挖掘伪OOV图像样本来改进零样本OOV检测，防止模型将未定义类别误分类为已知类别。

- Motivation: 现有零样本OOV检测方法容易过拟合已知类别，导致未定义类别被高置信度误分类为已知类别。需要解决模型缺乏OOV数据先验知识的问题。
- Method: 1) 从类别条件高斯分布的低似然区域采样合成区域级OOV提示；2) 提出基于Dirichlet的梯度归因机制挖掘伪OOV图像样本；3) 通过低密度先验约束构建OOV决策边界，使用高斯核密度估计正则化OOV类优化。
- Result: 实验结果表明，该方法在零样本场景下显著提高了OOV检测性能。
- Conclusion: 提出的OOVDet框架通过合成OOV提示和挖掘伪OOV样本，有效解决了零样本OOV检测中的过拟合问题，提高了未定义类别的检测可靠性。


### [39] [PEAR: Pixel-aligned Expressive humAn mesh Recovery](https://arxiv.org/abs/2601.22693)
*Jiahao Wu,Yunfei Liu,Lijian Lin,Ye Zhu,Lei Zhu,Jingyi Li,Yu Li*

Main category: cs.CV

TL;DR: PEAR是一个快速、鲁棒的像素对齐表达性人体网格重建框架，能够实时（100+FPS）从单张图像恢复SMPLX和scaled-FLAME参数，解决了现有方法推理慢、细节不准确的问题。

- Motivation: 现有SMPLX方法存在三大问题：1) 推理速度慢；2) 只能恢复粗略身体姿态；3) 面部和手部等细粒度区域存在错位或不自然伪影。这些问题限制了方法在下游任务中的应用。
- Method: 采用简洁统一的ViT架构恢复粗略3D人体几何，通过像素级监督优化几何细节，并提出模块化数据标注策略增强训练数据鲁棒性。无需预处理即可同时推断SMPLX和scaled-FLAME参数。
- Result: 在多个基准数据集上的实验表明，相比之前的SMPLX方法，PEAR在姿态估计准确性上有显著提升，同时保持超过100 FPS的实时推理速度。
- Conclusion: PEAR是一个快速、鲁棒的预处理免费框架，能够高效准确地从单张图像恢复表达性人体网格，解决了现有方法在推理速度、细节准确性和面部表情捕捉方面的局限性。


### [40] [Bi-MCQ: Reformulating Vision-Language Alignment for Negation Understanding](https://arxiv.org/abs/2601.22696)
*Tae Hun Kim,Hyun Gyu Lee*

Main category: cs.CV

TL;DR: 提出Bi-MCQ框架，通过双向多项选择学习增强医学视觉语言模型对否定陈述的理解能力，显著提升疾病缺失检测性能。

- Motivation: 现有视觉语言模型在理解否定临床陈述方面表现较弱，主要因为对比对齐目标将否定视为次要的语言变化而非意义反转操作。在多标签设置中，基于提示的InfoNCE微调进一步强化了简单正面对齐，限制了疾病缺失的有效学习。
- Method: 将视觉语言对齐重新表述为条件语义比较问题，通过双向多项选择学习框架实现。联合训练图像到文本和文本到图像的多项选择任务，使用肯定、否定和混合提示。引入方向特定的交叉注意力融合模块处理双向推理所需的不对称线索并减少对齐干扰。
- Result: 在ChestXray14、Open-I、CheXpert和PadChest数据集上，Bi-MCQ比最先进的CARZero模型的零样本性能在否定理解方面提升高达0.47 AUC，在正负组合评估上获得高达0.08的绝对增益。相比基于InfoNCE的微调，Bi-MCQ将肯定-否定AUC差距平均减少0.12。
- Conclusion: 目标重新表述可以显著增强医学视觉语言模型中的否定理解能力，Bi-MCQ框架通过条件语义比较而非全局相似性最大化，有效解决了现有方法在否定陈述理解上的局限性。


### [41] [DAVIS: OOD Detection via Dominant Activations and Variance for Increased Separation](https://arxiv.org/abs/2601.22703)
*Abid Hassan,Tuan Ngo,Saad Shafiq,Nenad Medvidovic*

Main category: cs.CV

TL;DR: DAVIS是一种简单的后处理OOD检测方法，通过补充全局平均池化丢弃的通道方差和最大激活统计量，显著提升了OOD检测性能。

- Motivation: 现有OOD检测方法大多基于全局平均池化后的特征表示，但GAP操作会丢失激活图中的重要分布统计信息，特别是通道方差和最大激活值，这些信息对OOD检测具有高度判别性。
- Method: 提出DAVIS方法，在特征向量中补充通道方差和主导（最大）激活统计量，直接解决GAP导致的信息损失问题。这是一种简单且广泛适用的后处理技术。
- Result: 在多种架构（ResNet、DenseNet、EfficientNet）上取得显著改进：CIFAR-10上FPR95降低48.26%，CIFAR-100上降低38.13%，ImageNet-1k上降低26.83%，为OOD检测设立了新基准。
- Conclusion: DAVIS通过利用GAP操作前被忽略的分布统计量，为OOD检测提供了原则性改进基础，表明超越均值统计的重要性，为实际部署提供了更可靠的保障。


### [42] [Gated Relational Alignment via Confidence-based Distillation for Efficient VLMs](https://arxiv.org/abs/2601.22709)
*Yanlong Chen,Amirhossein Habibian,Luca Benini,Yawei Li*

Main category: cs.CV

TL;DR: GRACE框架通过结合知识蒸馏和量化感知训练，在信息瓶颈原则下实现视觉语言模型的高效INT4量化，性能超越FP16基线，同时大幅提升推理速度和减少内存占用。

- Motivation: 视觉语言模型部署成本高，后训练量化通常导致显著精度损失，而量化感知训练在VLMs领域尚未充分探索，需要一种能保持性能的高效量化方法。
- Method: 基于信息瓶颈原则，统一知识蒸馏和量化感知训练：提出置信门控解耦蒸馏过滤不可靠监督，关系中心核对齐转移视觉标记结构，以及通过拉格朗日松弛的自适应控制器平衡保真度和容量约束。
- Result: 在LLaVA和Qwen系列模型上，INT4量化模型一致优于FP16基线（如LLaVA-1.5-7B在SQA上70.1 vs. 66.8），几乎匹配教师模型性能，使用真实INT4内核实现3倍吞吐量和54%内存减少。
- Conclusion: GRACE框架显著优于现有量化方法，为资源受限部署提供了有吸引力的解决方案，通过信息瓶颈原则有效平衡了量化压缩和性能保持。


### [43] [OpenVTON-Bench: A Large-Scale High-Resolution Benchmark for Controllable Virtual Try-On Evaluation](https://arxiv.org/abs/2601.22725)
*Jin Li,Tao Chen,Shuai Jiang,Weijie Wang,Jingwen Luo,Chenhui Wu*

Main category: cs.CV

TL;DR: OpenVTON-Bench：一个包含约10万张高分辨率图像对的大规模虚拟试穿基准数据集，采用多模态评估协议从五个维度评估VTON质量，与人类判断高度一致。

- Motivation: 尽管扩散模型提升了虚拟试穿系统的视觉保真度，但可靠评估仍是瓶颈。传统指标难以量化细粒度纹理细节和语义一致性，现有数据集在规模和多样性上达不到商业标准。
- Method: 构建包含约10万张高分辨率图像对的大规模数据集，使用DINOv3层次聚类进行语义平衡采样和Gemini密集标注。提出多模态评估协议，从五个维度评估质量：背景一致性、身份保真度、纹理保真度、形状合理性和整体真实感。协议整合VLM语义推理和基于SAM3分割与形态学腐蚀的多尺度表示度量。
- Result: 实验结果显示与人类判断高度一致（Kendall's τ为0.833，而SSIM为0.611），为VTON评估建立了稳健的基准。
- Conclusion: OpenVTON-Bench解决了虚拟试穿评估中的关键瓶颈，提供了大规模、多样化的数据集和可靠的多维度评估协议，显著提升了评估的准确性和实用性。


### [44] [GaussianOcc3D: A Gaussian-Based Adaptive Multi-modal 3D Occupancy Prediction](https://arxiv.org/abs/2601.22729)
*A. Enes Doruk,Hasan F. Ates*

Main category: cs.CV

TL;DR: GaussianOcc3D：一种基于3D高斯表示的多模态3D语义占据预测框架，通过LiDAR深度特征聚合、熵基特征平滑、自适应相机-LiDAR融合和Gauss-Mamba头等模块，在多个基准上实现SOTA性能。

- Motivation: 3D语义占据预测对自动驾驶至关重要，但单模态方法在相机语义和LiDAR几何之间存在权衡。现有多模态框架面临模态异质性、空间不对齐和表示危机（体素计算量大，BEV表示有损失）等问题。
- Method: 提出基于内存高效的连续3D高斯表示的多模态框架，包含四个核心模块：1) LiDAR深度特征聚合(LDFA)，使用深度可变形采样将稀疏信号提升到高斯基元；2) 熵基特征平滑(EBFS)减轻域噪声；3) 自适应相机-LiDAR融合(ACLF)通过不确定性感知重加权处理传感器可靠性；4) Gauss-Mamba头利用选择性状态空间模型实现线性复杂度的全局上下文建模。
- Result: 在Occ3D、SurroundOcc和SemanticKITTI基准测试中分别达到49.4%、28.9%和25.2%的mIoU分数，实现最先进性能。在雨天和夜间等挑战性条件下表现出优越的鲁棒性。
- Conclusion: GaussianOcc3D通过创新的3D高斯表示和多模态融合策略，有效解决了现有方法的局限性，在3D语义占据预测任务中取得了显著性能提升，特别是在恶劣天气条件下的鲁棒性表现突出。


### [45] [ImgCoT: Compressing Long Chain of Thought into Compact Visual Tokens for Efficient Reasoning of Large Language Model](https://arxiv.org/abs/2601.22730)
*Xiaoshu Chen,Sihang Zhou,Ke Liang,Taichun Zhou,Xinwang Liu*

Main category: cs.CV

TL;DR: ImgCoT将思维链从文本重建目标改为视觉图像，用空间归纳偏置替代语言偏置，更好地捕捉全局推理结构；松散的ImgCoT结合视觉潜在token和关键文本推理步骤，在减少token的同时保留推理细节。

- Motivation: 现有方法将文本思维链作为重建目标，迫使潜在token保留表层语言特征（如词汇选择和语法），引入了强烈的语言归纳偏置，优先考虑语言形式而非推理结构，限制了逻辑抽象能力。
- Method: 提出ImgCoT，将重建目标从文本思维链改为通过渲染思维链得到的视觉图像，用空间归纳偏置替代语言偏置；进一步提出松散的ImgCoT，这是一种混合推理方法，通过基于低token对数似然选择的关键文本推理步骤来增强视觉潜在token。
- Result: 在多个数据集和大型语言模型上的广泛实验证明了两种版本ImgCoT的有效性，能够更好地捕捉全局推理结构，同时用比完整思维链更少的token保留细粒度推理细节。
- Conclusion: 将思维链压缩从文本重建转向视觉重建，用空间偏置替代语言偏置，能更好地捕捉推理结构；结合视觉潜在token和关键文本步骤的混合方法，能在减少token的同时保持推理细节。


### [46] [Lingua-SafetyBench: A Benchmark for Safety Evaluation of Multilingual Vision-Language Models](https://arxiv.org/abs/2601.22737)
*Enyi Shi,Pengyang Shao,Yanxin Zhang,Chenhang Cui,Jiayi Lyu,Xu Xie,Xiaobo Xia,Fei Shen,Tat-Seng Chua*

Main category: cs.CV

TL;DR: Lingua-SafetyBench是一个包含100,440个有害图像-文本对的多语言多模态安全基准，覆盖10种语言，揭示了VLLMs在不同语言和模态下的安全风险不对称性。

- Motivation: 现有基准要么是多语言但仅文本，要么是多模态但单语言，缺乏对多语言多模态联合输入下VLLMs安全性的全面评估。现有方法依赖排版式视觉内容，缺乏语义基础的图像-文本对，限制了真实跨模态交互的覆盖。
- Method: 构建Lingua-SafetyBench基准，包含100,440个有害图像-文本对，覆盖10种语言，明确划分为图像主导和文本主导子集以分离风险来源。评估11个开源VLLMs，并对Qwen系列进行控制研究。
- Result: 发现一致的不对称性：图像主导风险在高资源语言中攻击成功率更高，而文本主导风险在非高资源语言中更严重。Qwen系列的扩展和版本升级总体上降低了ASR，但不成比例地使高资源语言受益，在文本主导风险下扩大了高低资源语言之间的差距。
- Conclusion: 仅靠模型扩展不足以解决多语言多模态安全问题，需要语言和模态感知的安全对齐方法。强调了超越简单扩展的语言和模态感知安全对齐的必要性。


### [47] [StreamSense: Streaming Social Task Detection with Selective Vision-Language Model Routing](https://arxiv.org/abs/2601.22738)
*Han Wang,Deyi Ji,Lanyun Zhu,Jiebo Luo,Roy Ka-Wei Lee*

Main category: cs.CV

TL;DR: StreamSense：一种流式检测器，通过轻量级流式编码器与选择性路由到VLM专家相结合，实现实时社交信号监测，在保持高准确率的同时降低计算延迟。

- Motivation: 直播平台需要实时监测和响应社交信号，但现有方法要么计算成本高（如全量使用VLM），要么准确率不足。需要一种既能处理大多数简单情况，又能将复杂/模糊情况升级到更强模型的方法。
- Method: 1. 轻量级流式编码器处理大多数时间戳；2. 选择性路由机制将困难/模糊案例升级到VLM专家；3. 上下文不足时延迟决策；4. 编码器训练采用跨模态对比损失和对齐目标段IoU加权损失。
- Result: 在多个社交流式检测任务（情感分类、仇恨内容审核等）上，StreamSense比纯VLM流式方法准确率更高，同时仅偶尔调用VLM，显著降低了平均延迟和计算成本。
- Conclusion: 选择性升级和延迟决策是理解流式社交任务的有效原语，StreamSense在准确率与效率之间取得了良好平衡，为实时社交信号监测提供了实用解决方案。


### [48] [Beauty and the Beast: Imperceptible Perturbations Against Diffusion-Based Face Swapping via Directional Attribute Editing](https://arxiv.org/abs/2601.22744)
*Yilong Huang,Songze Li*

Main category: cs.CV

TL;DR: FaceDefense：针对扩散式换脸攻击的增强型主动防御框架，通过扩散损失和面部属性编辑实现更好的保护效果与视觉不可感知性平衡

- Motivation: 扩散式换脸技术虽然性能优越，但也加剧了恶意换脸侵犯肖像权和个人声誉的风险。现有主动防御方法面临核心权衡：大扰动会扭曲面部结构，小扰动则保护效果不足。
- Method: 提出FaceDefense框架：1）引入新的扩散损失增强对抗样本的防御效果；2）采用定向面部属性编辑修复扰动引起的扭曲，提升视觉不可感知性；3）设计两阶段交替优化策略生成最终扰动人脸图像。
- Result: 大量实验表明，FaceDefense在不可感知性和防御效果方面显著优于现有方法，实现了更优的权衡。
- Conclusion: FaceDefense有效解决了扩散式换脸主动防御中的核心权衡问题，通过创新的损失函数和优化策略，在保护效果和视觉质量之间取得了更好的平衡。


### [49] [Procedural Knowledge Extraction from Industrial Troubleshooting Guides Using Vision Language Models](https://arxiv.org/abs/2601.22754)
*Guillermo Gil de Avalle,Laura Maruster,Christos Emmanouilidis*

Main category: cs.CV

TL;DR: 评估两种视觉语言模型在工业故障排除指南结构化知识提取中的表现，比较标准提示与增强布局模式提示策略

- Motivation: 工业故障排除指南包含流程图式诊断程序，需要将其结构化以便集成到操作员支持系统中。手动提取耗时且易错，需要自动化解决方案。
- Method: 评估两种视觉语言模型，比较两种提示策略：标准指令引导提示 vs 增强的故障排除布局模式提示方法
- Result: 结果显示模型在布局敏感性和语义鲁棒性之间存在特定权衡，为实际部署决策提供参考
- Conclusion: 视觉语言模型在自动化工业故障排除指南知识提取方面具有潜力，但需要根据具体需求在布局敏感性和语义鲁棒性之间做出权衡选择


### [50] [Is Training Necessary for Anomaly Detection?](https://arxiv.org/abs/2601.22763)
*Xingwu Zhang,Guanxuan Li,Paul Henderson,Gerardo Aragon-Camarasa,Zijun Long*

Main category: cs.CV

TL;DR: 本文提出了一种无需训练的检索式异常检测方法RAD，通过多级检索匹配测试图像与存储的正常特征，在多个基准测试中达到SOTA性能。

- Motivation: 当前基于重建的多类无监督异常检测方法存在保真度-稳定性困境，作者希望突破重建范式，探索更有效的异常检测方法。
- Method: 提出RAD方法：1）存储正常特征到内存中；2）通过多级检索匹配测试图像块与内存中的正常特征；3）无需训练，完全基于检索。
- Result: 在四个基准测试（MVTec-AD、VisA、Real-IAD、3D-ADAM）上达到SOTA性能，在MVTec-AD上仅用一张正常图像就达到96.7%像素AUROC，接近全数据性能的98.5%。
- Conclusion: 检索式异常检测方法理论上优于重建残差方法，颠覆了多类无监督异常检测需要任务特定训练的假设，证明基于内存检索的方法可以达到SOTA性能。


### [51] [Color Matters: Demosaicing-Guided Color Correlation Training for Generalizable AI-Generated Image Detection](https://arxiv.org/abs/2601.22778)
*Nan Zhong,Yiran Xu,Mian Zou*

Main category: cs.CV

TL;DR: 提出DCCT框架，通过模拟相机成像管道的颜色相关性来检测AI生成图像，解决了现有生成伪影检测器的泛化失败问题

- Motivation: 现实AI生成图像威胁数字真实性，现有基于生成伪影的检测器存在泛化失败问题，需要利用相机成像管道的固有特性来提高检测能力
- Method: 提出DCCT框架：模拟CFA采样模式，将彩色图像分解为单通道输入和剩余两通道作为目标，训练自监督U-Net建模条件分布，利用颜色相关性差异构建二元分类器
- Result: DCCT在超过20个未见生成器上实现了最先进的泛化能力和鲁棒性，显著优于先前方法
- Conclusion: 通过利用相机成像管道的颜色相关性特征，DCCT框架有效解决了AI生成图像检测的泛化问题，为数字真实性保护提供了可靠解决方案


### [52] [Diachronic Stereo Matching for Multi-Date Satellite Imagery](https://arxiv.org/abs/2601.22808)
*Elías Masquil,Luca Savant Aira,Roger Marí,Thibaud Ehret,Pablo Musé,Gabriele Facciolo*

Main category: cs.CV

TL;DR: 提出首个卫星图像时变立体匹配方法，能够在时间间隔较长的图像对上进行可靠的3D重建，解决了季节、光照变化导致的传统立体匹配失效问题。

- Motivation: 传统立体匹配方法假设图像对在相近时间拍摄，当卫星图像拍摄时间相隔数月时，强烈的季节、光照和阴影变化会违反标准立体假设，导致现有管道失败。需要开发能够处理时间间隔较长图像对的立体匹配方法。
- Method: 1) 微调先进的深度立体网络，利用单目深度先验；2) 在专门策划的包含多样化时变图像对的数据集上进行训练。具体从预训练的MonSter模型开始，在DFC2019遥感挑战赛的立体图像对上进行微调，该数据集包含同步和时变图像对。
- Result: 在多日期WorldView-3图像上的实验表明，该方法在同步和时变设置下均优于传统管道和未经调整的深度立体模型。在冬季-秋季图像对测试中，平均海拔误差从3.99米降低到1.23米。
- Conclusion: 在时间多样化图像上进行微调，结合单目先验，对于实现从先前不兼容的采集日期进行3D重建至关重要。该方法首次实现了卫星图像的时变立体匹配，能够处理时间间隔较长的图像对。


### [53] [FarmMind: Reasoning-Query-Driven Dynamic Segmentation for Farmland Remote Sensing Images](https://arxiv.org/abs/2601.22809)
*Haiyang Wu,Weiliang Mu,Jipeng Zhang,Zhong Dandan,Zhuofei Du,Haifeng Li,Tao Chao*

Main category: cs.CV

TL;DR: 提出FarmMind框架，通过推理-查询机制动态获取辅助图像，突破静态分割范式限制，提升农田遥感图像分割性能

- Motivation: 现有农田遥感图像分割方法采用静态分割范式，仅依赖单个输入图像片段，在处理具有模糊性和视觉不确定性的复杂场景时推理能力有限。人类专家在解释模糊遥感图像时会主动查询辅助图像进行交叉验证，受此启发需要开发动态分割框架
- Method: 提出FarmMind框架，引入推理-查询机制：首先分析分割模糊的根本原因，然后基于分析确定需要查询的辅助图像类型（如更高分辨率、更大尺度或时间相邻数据），动态按需查询外部辅助图像以补偿单张输入图像信息不足
- Result: 大量实验表明，FarmMind相比现有方法实现了更优的分割性能和更强的泛化能力
- Conclusion: FarmMind通过模拟人类专家的思考过程，突破静态分割范式限制，为农田遥感图像分割提供了一种有效的动态分割框架，代码和数据集已开源


### [54] [A Comparative Evaluation of Large Vision-Language Models for 2D Object Detection under SOTIF Conditions](https://arxiv.org/abs/2601.22830)
*Ji Zhou,Yilin Ding,Yongqi Zhao,Jiachen Xu,Arno Eichberger*

Main category: cs.CV

TL;DR: 本文系统评估了10种大型视觉语言模型在SOTIF安全关键2D目标检测中的表现，发现它们在复杂自然场景中比传统YOLO检测器召回率高出25%以上，但在合成扰动场景中几何精度不如传统方法。

- Motivation: 自动驾驶的环境感知可靠性仍是主要挑战，SOTIF关注感知不足带来的安全风险。大型视觉语言模型展现出有前景的语义推理能力，但其在安全关键2D目标检测中的定量效果尚未充分探索。
- Method: 使用专门为长尾交通场景和环境退化设计的PeSOTIF数据集，系统评估了10种代表性大型视觉语言模型，并与基于YOLO的传统感知方法进行定量比较。
- Result: 实验结果显示关键权衡：在复杂自然场景中，表现最佳的大型视觉语言模型（如Gemini 3、Doubao）比YOLO基线召回率高出25%以上，对视觉退化表现出更强的鲁棒性；相反，基线方法在合成扰动场景中保持几何精度优势。
- Conclusion: 这些发现凸显了语义推理与几何回归的互补优势，支持将大型视觉语言模型作为SOTIF导向自动驾驶系统中的高级安全验证器使用。


### [55] [NativeTok: Native Visual Tokenization for Improved Image Generation](https://arxiv.org/abs/2601.22837)
*Bin Wu,Mengqi Huang,Weinan Jia,Zhendong Mao*

Main category: cs.CV

TL;DR: NativeTok提出原生视觉标记化框架，通过在标记化阶段强制因果依赖关系，解决传统VQ图像生成中两阶段不匹配问题，实现更高效的图像重建和更好的生成一致性。

- Motivation: 传统VQ图像生成的两阶段流程存在不匹配问题：第一阶段标记化的改进不一定能提升第二阶段生成质量，因为现有方法无法约束标记间的依赖关系，导致生成模型需要从无序分布中学习，产生偏差和弱一致性。
- Method: 提出原生视觉标记化框架NativeTok，包含：(1) Meta Image Transformer用于潜在图像建模；(2) Mixture of Causal Expert Transformer，其中每个轻量级专家块基于先前标记和潜在特征生成单个标记。还设计了分层原生训练策略，只更新新的专家块以确保训练效率。
- Result: 大量实验证明了NativeTok的有效性，能够在标记化阶段嵌入关系约束，实现高效重建，同时保持训练效率。
- Conclusion: 通过强制因果依赖的原生视觉标记化，NativeTok解决了传统VQ图像生成中的两阶段不匹配问题，实现了更一致和高效的图像生成。


### [56] [Neural Clothing Tryer: Customized Virtual Try-On via Semantic Enhancement and Controlling Diffusion Model](https://arxiv.org/abs/2601.22838)
*Zhijing Yang,Weiwei Zhang,Mingliang Yang,Siyuan Peng,Yukai Shi,Junpeng Tan,Tianshui Chen,Liruo Zhong*

Main category: cs.CV

TL;DR: 提出NCT框架解决定制化虚拟试穿任务，利用扩散模型结合语义增强和控制模块，实现服装语义保持与模特姿态、外观的灵活编辑

- Motivation: 传统虚拟试穿任务限制较多，用户无法定制化数字人偶的外观、姿态等属性。本文提出定制化虚拟试穿任务，让用户能根据个人偏好定制数字人偶，提升虚拟试穿体验的灵活性和参与度
- Method: 提出神经服装试穿者框架，包含语义增强模块和语义控制模块。语义增强模块利用视觉语言编码器学习跨模态对齐特征，作为扩散模型的条件输入；语义控制模块以服装图像、定制姿态图像和语义描述为输入，保持服装细节同时编辑模特姿态、表情等属性
- Result: 在公开基准测试上的大量实验表明，所提出的NCT框架具有优越性能
- Conclusion: NCT框架成功解决了定制化虚拟试穿任务，通过语义增强和控制模块实现了服装语义保持与模特属性的灵活编辑，提升了虚拟试穿体验


### [57] [How Much of a Model Do We Need? Redundancy and Slimmability in Remote Sensing Foundation Models](https://arxiv.org/abs/2601.22841)
*Leonard Hackel,Tom Burgert,Begüm Demir*

Main category: cs.CV

TL;DR: 遥感基础模型在比计算机视觉模型小得多的规模下就进入过参数化状态，增加参数主要产生冗余表示而非新抽象，可通过剪枝保持高性能

- Motivation: 当前遥感领域直接套用计算机视觉的模型缩放假设，但未充分验证这种转移的合理性。作者假设遥感基础模型在比计算机视觉模型小得多的规模下就进入过参数化状态
- Method: 使用后剪枝方法，均匀缩减预训练编码器的宽度，在6个最先进的遥感基础模型和4个下游分类任务上测量表示冗余。还使用可学习剪枝训练、方差解释比和特征相关性分析
- Result: 遥感基础模型在1%计算量下仍能保持71%以上的相对准确率，而ImageNet训练的MAE模型在同样计算量下准确率低于10%，存在7倍差异。可学习剪枝训练能进一步提升MoCo和MAE模型性能
- Conclusion: 遥感基础模型以高冗余度分布任务相关信息，后剪枝既可作为资源受限环境的实用部署策略，也可作为挑战当前遥感缩放范式的诊断工具


### [58] [Inference-Time Dynamic Modality Selection for Incomplete Multimodal Classification](https://arxiv.org/abs/2601.22853)
*Siyi Du,Xinzhe Luo,Declan P. O'Regan,Chen Qin*

Main category: cs.CV

TL;DR: DyMo提出了一种推理时动态模态选择框架，通过最大化任务相关信息来智能选择可靠恢复的模态，解决了不完全多模态学习中的丢弃-补全困境。

- Motivation: 多模态深度学习在实际部署中常面临不完全多模态数据问题。现有方法要么丢弃缺失模态（丢失有价值信息），要么恢复它们（可能引入噪声），形成了丢弃-补全困境。
- Method: 提出DyMo框架：1）基于信息论建立任务相关信息与任务损失的理论联系，设计可计算的奖励函数；2）开发动态模态选择算法，在推理时为每个测试样本自适应选择可靠模态；3）设计兼容任意模态组合的网络架构和鲁棒训练策略。
- Result: 在多种自然和医学图像数据集上的实验表明，DyMo在各种缺失数据场景下显著优于现有不完全/动态多模态学习方法。
- Conclusion: DyMo通过推理时动态模态选择，有效解决了不完全多模态学习中的丢弃-补全困境，超越了传统的丢弃或补全范式，实现了更优的性能。


### [59] [Under-Canopy Terrain Reconstruction in Dense Forests Using RGB Imaging and Neural 3D Reconstruction](https://arxiv.org/abs/2601.22861)
*Refael Sheffer,Chen Pinchover,Haim Zisman,Dror Ozeri,Roee Litman*

Main category: cs.CV

TL;DR: 提出一种仅使用常规RGB图像重建无树冠地面视图的新方法，基于神经辐射场（NeRF），通过特定拍摄策略和低光照损失处理弱光环境，并采用两种互补方法去除遮挡的树冠元素。

- Motivation: 现有解决方案依赖专用传感器：要么是沉重昂贵的机载激光雷达，要么是热合成孔径摄影的机载光学切片（AOS），专门用于人员检测。需要一种成本效益高、仅使用常规RGB图像的替代方案，用于搜索救援、路径测绘、森林清查等应用。
- Method: 基于神经辐射场（NeRF）的3D重建方法，包含特定图像采集策略以确保足够光照穿透树冠，采用低光照损失处理弱光环境，并提出两种互补的每射线积分控制方法来去除遮挡的树冠元素。
- Result: 在搜索救援任务中，该方法实现了与热AOS相当的人员检测效果（仅使用RGB图像）。在森林清查任务如树木计数中也显示出潜力，证明其作为专用传感器的高分辨率、成本效益替代方案的可行性。
- Conclusion: 该方法为搜索救援、路径测绘和森林清查任务提供了一种成本效益高、高分辨率的替代方案，仅使用常规RGB图像即可重建无树冠的逼真地面视图，无需专用传感器。


### [60] [When Anomalies Depend on Context: Learning Conditional Compatibility for Anomaly Detection](https://arxiv.org/abs/2601.22868)
*Shashank Mishra,Didier Stricker,Jason Rambach*

Main category: cs.CV

TL;DR: 该论文提出了一种上下文异常检测方法，通过视觉-语言表示学习主体-上下文兼容性关系，在CAAD-3K、MVTec-AD和VisA数据集上取得SOTA性能。

- Motivation: 传统异常检测假设异常是观测的固有属性，但现实中许多异常取决于上下文因素。例如，在跑道上跑步是正常的，但在高速公路上跑步就是异常的。需要重新审视上下文异常检测问题。
- Method: 提出条件兼容性学习框架，利用视觉-语言表示在有限监督下建模主体-上下文关系。引入CAAD-3K基准数据集，通过控制主体身份同时变化上下文来隔离上下文异常。
- Result: 该方法在CAAD-3K基准上显著优于现有方法，在MVTec-AD和VisA数据集上达到最先进性能，证明建模上下文依赖性能够补充传统结构异常检测。
- Conclusion: 上下文异常检测是视觉领域的重要问题，通过建模主体-上下文兼容性关系可以有效检测上下文依赖的异常，该方法在多个基准上验证了有效性。


### [61] [DINO-SAE: DINO Spherical Autoencoder for High-Fidelity Image Reconstruction and Generation](https://arxiv.org/abs/2601.22904)
*Hun Chang,Byunghee Cha,Jong Chul Ye*

Main category: cs.CV

TL;DR: DINO-SAE：基于DINO的球形自编码器，通过方向语义对齐和幅度灵活性提升重建保真度，结合黎曼流匹配在球形流形上训练DiT，实现SOTA重建质量。

- Motivation: 现有基于预训练视觉基础模型（如DINO）的生成自编码器存在重建保真度有限的问题，主要因为高频细节丢失。对比表示中的语义信息主要编码在特征向量方向上，而强制严格的幅度匹配会阻碍编码器保留细粒度细节。
- Method: 提出DINO球形自编码器（DINO-SAE）：1）分层卷积块嵌入模块增强局部结构和纹理保留；2）余弦相似度对齐目标强制语义一致性同时允许特征幅度灵活性；3）利用SSL基础模型表示内在位于超球面的特性，采用黎曼流匹配直接在球形潜在流形上训练扩散变换器（DiT）。
- Result: 在ImageNet-1K上达到SOTA重建质量：0.37 rFID和26.2 dB PSNR，同时保持与预训练VFM的强语义对齐。黎曼流匹配的DiT收敛高效，80轮达到3.47 gFID。
- Conclusion: DINO-SAE成功桥接语义表示和像素级重建，通过方向语义对齐和幅度灵活性解决了现有方法的高频细节丢失问题，黎曼流匹配在球形流形上的应用进一步提升了生成性能。


### [62] [Multi-Cue Anomaly Detection and Localization under Data Contamination](https://arxiv.org/abs/2601.22913)
*Anindya Sundar Das,Monowar Bhuyan*

Main category: cs.CV

TL;DR: 提出一个鲁棒的视觉异常检测框架，结合有限异常监督和自适应偏差学习，通过复合异常评分实现准确检测和可解释定位

- Motivation: 现有工业视觉异常检测方法存在两大局限：1) 假设训练数据纯净无异常污染（现实中很少成立）；2) 无法利用标记异常样本学习异常特征，导致检测性能下降
- Method: 提出集成有限异常监督的自适应偏差学习框架，包含三个互补的异常评分组件：统计异常偏差评分、基于熵的不确定性评分、基于分割的空间异常评分，并通过自适应实例加权减轻污染样本影响
- Result: 在MVTec和VisA基准测试中超越现有最佳方法，在数据污染情况下仍保持强大的检测和定位性能，并具有良好可解释性
- Conclusion: 该框架通过结合有限异常监督和复合评分机制，有效解决了现实工业场景中数据污染问题，实现了鲁棒、可解释的异常检测和定位


### [63] [Deep in the Jungle: Towards Automating Chimpanzee Population Estimation](https://arxiv.org/abs/2601.22917)
*Tom Raynes,Otto Brookes,Timm Haucke,Lukas Bösch,Anne-Sophie Crunchant,Hjalmar Kühl,Sara Beery,Majid Mirmehdi,Tilo Burghardt*

Main category: cs.CV

TL;DR: 该研究探索将单目深度估计（MDE）集成到相机陷阱工作流中，用于大猩猩种群密度和丰度估计，替代传统人工距离测量方法。

- Motivation: 传统相机陷阱调查中，动物到相机的距离测量依赖人工解释，劳动密集且耗时。需要探索更高效的自动化替代方案来支持大猩猩保护工作。
- Method: 使用220个野生黑猩猩相机陷阱视频数据集，结合两种MDE模型（DPT和Depth Anything）与多种距离采样策略，生成检测距离估计，进而推断种群密度和丰度。
- Result: 校准后的DPT模型在距离估计准确性和下游密度/丰度推断方面优于Depth Anything。两种模型都存在系统性偏差，倾向于高估检测距离，从而低估密度和丰度。总体估计结果与传统方法相差在22%以内。
- Conclusion: MDE驱动的相机陷阱距离采样是传统人工距离估计的可行实用替代方案，尽管存在系统性偏差，但能显著减少人工工作量，为大猩猩保护提供有效工具。


### [64] [Q-Hawkeye: Reliable Visual Policy Optimization for Image Quality Assessment](https://arxiv.org/abs/2601.22920)
*Wulin Xie,Rui Dai,Ruidong Ding,Kaikui Liu,Xiangxiang Chu,Xinwen Hou,Jie Wen*

Main category: cs.CV

TL;DR: Q-Hawkeye提出了一种基于强化学习的可靠视觉策略优化框架，通过不确定性感知动态优化和感知感知优化解决现有IQA方法的可靠性限制问题。

- Motivation: 现有基于RL的IQA方法存在两个关键可靠性限制：1）不同训练样本的预测稳定性差异大，但现有GRPO方法使用统一的优势权重，放大了不稳定样本的噪声信号；2）大多数工作强调基于文本的推理而忽视了模型对图像内容的视觉感知能力。
- Method: 提出Q-Hawkeye框架：1）通过多次rollout预测分数的方差估计预测不确定性，利用不确定性重新加权每个样本的更新强度；2）构建退化图像与其原始图像的配对输入，引入隐式感知损失约束模型基于真实视觉证据进行质量判断。
- Result: 大量实验表明Q-Hawkeye在多个数据集上优于最先进方法，并展现出更好的泛化能力。
- Conclusion: Q-Hawkeye通过不确定性感知动态优化和感知感知优化，有效解决了现有RL-based IQA方法的可靠性限制，提高了图像质量评估的准确性和稳定性。


### [65] [Semantic Leakage from Image Embeddings](https://arxiv.org/abs/2601.22929)
*Yiyi Chen,Qiongkai Xu,Desmond Eliott,Qiongxiu Li,Johannes Bjerva*

Main category: cs.CV

TL;DR: 图像嵌入存在语义泄露风险，即使不重建原图，通过保持局部语义邻域结构也能泄露敏感信息

- Motivation: 挑战图像嵌入隐私风险有限的假设，揭示语义信息可能通过嵌入压缩过程泄露
- Method: 提出SLImE框架：轻量级推理框架，使用本地训练的语义检索器结合现成模型，无需训练任务特定解码器
- Result: 在多种嵌入模型（GEMINI、COHERE、NOMIC、CLIP）上验证，能一致恢复语义信息，包括标签、符号表示和连贯描述
- Conclusion: 图像嵌入存在根本性漏洞，语义邻域结构的保持导致语义泄露，对隐私保护提出挑战


### [66] [Triage: Hierarchical Visual Budgeting for Efficient Video Reasoning in Vision-Language Models](https://arxiv.org/abs/2601.22959)
*Anmin Wang,Nan Zhang,Wei Tao,Xiaoyang Qu,Guokuan Li,Jiguang Wan,Jianzong Wang*

Main category: cs.CV

TL;DR: Triage是一个无需训练、即插即用的视频推理框架，通过分层视觉预算解决VLMs处理视频时的计算冗余问题，提升推理速度并减少内存占用。

- Motivation: 视觉语言模型在处理视频时面临巨大计算挑战，因为视频数据冗余导致token序列过长，计算成本过高。
- Method: 采用分层视觉预算方法：第一阶段帧级预算通过评估视觉动态和相关性识别关键帧；第二阶段token级预算分两步分配token：先保留高相关性核心token，再通过批处理最大边际相关性算法选择多样化的上下文token。
- Result: 实验表明Triage在多个视频推理基准测试中，在保持或超越基线和其他方法性能的同时，显著提高了推理速度并减少了内存占用。
- Conclusion: Triage通过将视频推理重新定义为资源分配问题，有效解决了VLMs处理视频时的计算冗余挑战，为高效视频理解提供了实用解决方案。


### [67] [Improving Supervised Machine Learning Performance in Optical Quality Control via Generative AI for Dataset Expansion](https://arxiv.org/abs/2601.22961)
*Dennis Sprute,Hanna Senke,Holger Flatt*

Main category: cs.CV

TL;DR: 该研究探索使用生成式AI（Stable Diffusion和CycleGAN）解决工业光学质检中数据不平衡问题，通过生成缺陷图像扩增数据集，提升分割模型性能。

- Motivation: 工业光学质检中，缺陷样本稀少导致数据集高度不平衡，传统方法（特殊损失函数、传统数据增强）存在超参数调优困难或只能改变简单图像特征等局限性。
- Method: 研究采用生成式AI方法，具体使用Stable Diffusion和CycleGAN作为图像生成模型，针对联合收割机部件的热成像图像进行数据集扩增，用于后续缺陷检测的分割任务。
- Result: 使用Stable Diffusion进行数据集扩增效果最佳，分割性能提升4.6%，Mean IoU达到84.6%。
- Conclusion: 生成式AI（特别是Stable Diffusion）能有效解决工业质检中的数据不平衡问题，显著提升监督机器学习模型的性能。


### [68] [About an Automating Annotation Method for Robot Markers](https://arxiv.org/abs/2601.22982)
*Wataru Uemura,Takeru Nagashima*

Main category: cs.CV

TL;DR: 提出基于ArUco标记的自动标注方法，用于训练深度学习模型识别标记，无需人工标注，在模糊、失焦等条件下表现优于传统图像处理方法

- Motivation: 工厂自动化中自主移动机器人依赖标记进行定位和识别，传统OpenCV方法在噪声、运动模糊、失焦或光照变化下容易失败，而深度学习需要大量标注数据，人工标注成为瓶颈
- Method: 利用ArUco标记自带识别模块提供的ID和位置信息实现自动标注，使用自动标注的数据集训练YOLO模型，评估在不同条件下的性能
- Result: 实验表明该方法在模糊或失焦图像中识别性能优于传统图像处理技术，自动标注减少了人工工作量并确保标注质量一致性
- Conclusion: 提出的自动标注方法有效解决了深度学习训练中的数据标注瓶颈问题，提高了标记识别的鲁棒性，未来将研究置信度阈值与识别性能的关系


### [69] [Self-Supervised Slice-to-Volume Reconstruction with Gaussian Representations for Fetal MRI](https://arxiv.org/abs/2601.22990)
*Yinsong Wang,Thomas Fletcher,Xinzhe Luo,Aine Travers Dineen,Rhodri Cusack,Chen Qin*

Main category: cs.CV

TL;DR: 提出GaussianSVR，一种基于3D高斯表示的自监督切片到体积重建框架，用于胎儿MR图像重建，无需真实标签数据

- Motivation: 传统切片到体积重建方法耗时且需要多正交堆栈，而基于学习的方法依赖难以获取的真实标签数据，需要开发自监督解决方案
- Method: 使用3D高斯表示目标体积，通过模拟前向切片采集模型实现自监督训练，引入多分辨率训练策略联合优化高斯参数和空间变换
- Result: GaussianSVR在胎儿MR体积重建任务上优于基线方法，实现了高保真重建
- Conclusion: 提出的自监督框架有效解决了胎儿MR重建中的标签依赖问题，3D高斯表示和多分辨率策略提升了重建质量和效率


### [70] [Leveraging Multi-Rater Annotations to Calibrate Object Detectors in Microscopy Imaging](https://arxiv.org/abs/2601.23007)
*Francesco Campi,Lucrezia Tondo,Ekin Karabati,Johannes Betge,Marie Piraud*

Main category: cs.CV

TL;DR: 提出基于多标注者注释的模型校准方法，通过训练独立专家模型并聚合预测来模拟共识，在结直肠类器官数据集上改善了校准性能

- Motivation: 深度学习目标检测器在显微镜成像中表现出色，但其置信度估计通常缺乏校准，限制了在生物医学应用中的可靠性。现有标签采样策略（混合标注训练）不够理想，需要更原则性的方法来捕捉标注者间的变异性
- Method: 提出标注者特定集成策略：为每个专家训练独立的模型，然后聚合这些模型的预测来模拟共识。这种方法比混合标注训练更原则性地捕捉了标注者间的变异性
- Result: 在由两名专家标注的结直肠类器官数据集上的实验表明，该方法显著改善了校准性能，同时保持了可比较的检测准确度
- Conclusion: 明确建模标注者间的分歧可以产生更可信赖的生物医学成像目标检测器，多标注者注释为模型校准提供了有效途径


### [71] [One-shot Optimized Steering Vector for Hallucination Mitigation for VLMs](https://arxiv.org/abs/2601.23041)
*Youxu Shi,Suorong Yang,Dong Liu*

Main category: cs.CV

TL;DR: OSGA提出一种单次优化的输入无关引导框架，通过方差数据选择策略和生成锚正则化，学习单个通用引导向量来改善VLM的幻觉和安全问题。

- Motivation: 尽管视觉语言模型在多模态任务上表现良好，但仍存在幻觉和安全相关的问题。现有的引导方法在效率和效果之间存在权衡，作者观察到当任务具有对齐的语义意图时，引导向量可以在不同输入间泛化。
- Method: OSGA框架：1）通过方差数据选择策略选择信息丰富的样本；2）使用对比目标和生成锚正则化学习单个引导向量；3）在推理时将该向量应用于特定层，无需修改模型参数。
- Result: 在多个基准测试中，单个OSGA优化的引导向量能持续改善幻觉缓解和安全增强，且开销可忽略不计，证明了单次引导作为可靠VLM的实用可扩展解决方案。
- Conclusion: OSGA展示了单次引导作为改善视觉语言模型可靠性的实用且可扩展的方法，通过单个优化实例学习的通用引导向量能有效缓解幻觉和增强安全性。


### [72] [HierLoc: Hyperbolic Entity Embeddings for Hierarchical Visual Geolocation](https://arxiv.org/abs/2601.23064)
*Hari Krishna Gadi,Daniel Matos,Hongyi Luo,Lu Liu,Yongliang Wang,Yanfeng Zhang,Liqiu Meng*

Main category: cs.CV

TL;DR: 提出基于双曲空间的实体层次化地理定位方法，用24万个实体嵌入替代500万图像嵌入，在OSV5M基准上实现SOTA性能

- Motivation: 现有视觉地理定位方法存在三个主要问题：大规模检索需要存储大量图像嵌入、网格分类器忽略地理连续性、生成模型难以处理细节。需要更高效且能捕捉地理层次结构的方法。
- Method: 提出实体中心的地理定位框架，将图像直接与国家、地区、子区域、城市等地理实体对齐。使用双曲空间嵌入地理实体层次结构，并通过Geo-Weighted Hyperbolic对比学习，将haversine距离直接融入对比目标函数。
- Result: 在OSV5M基准上建立新的SOTA：平均测地误差降低19.5%，细粒度子区域准确率提升43%。仅需24万个实体嵌入，而非传统方法的500万图像嵌入，实现高效推理。
- Conclusion: 几何感知的层次化嵌入为全球图像地理定位提供了可扩展且概念新颖的替代方案，能够实现可解释的预测和高效推理。


### [73] [Rethinking Transferable Adversarial Attacks on Point Clouds from a Compact Subspace Perspective](https://arxiv.org/abs/2601.23102)
*Keke Tang,Xianheng Liu,Weilong Peng,Xiaofei Wang,Daizong Liu,Peican Zhu,Can Lu,Zhihong Tian*

Main category: cs.CV

TL;DR: CoSA提出了一种基于紧凑子空间视角的可迁移对抗攻击框架，通过低维语义空间中的原型组合表示点云，在低秩子空间中优化对抗扰动，提高跨模型迁移性。

- Motivation: 现有基于模型特定梯度或启发式方法的点云对抗攻击在跨模型迁移性方面存在局限，难以泛化到未见过的网络架构。
- Method: CoSA从紧凑子空间角度重新思考对抗迁移性，将每个点云表示为类别特定原型的紧凑组合，这些原型捕获共享语义结构，同时在低秩子空间中优化对抗扰动以产生架构无关的相干变化。
- Result: 在多个数据集和网络架构上的实验表明，CoSA一致优于最先进的可迁移攻击方法，同时保持竞争性的不可感知性和在常见防御策略下的鲁棒性。
- Conclusion: 通过将对抗扰动约束在语义有意义的方向上，抑制模型依赖噪声，CoSA框架显著提高了点云对抗攻击的跨模型迁移性，为可迁移对抗攻击提供了新视角。


### [74] [FlowCalib: LiDAR-to-Vehicle Miscalibration Detection using Scene Flows](https://arxiv.org/abs/2601.23107)
*Ilir Tahiraj,Peter Wittal,Markus Lienkamp*

Main category: cs.CV

TL;DR: FlowCalib：首个利用静态物体场景流检测LiDAR与车辆间标定误差的框架，无需额外传感器，通过运动线索识别角度偏差。

- Motivation: 当前方法主要关注传感器间误差校正，但忽略了导致这些误差的根本原因——单个传感器本身的标定误差。LiDAR传感器的角度偏差会在自动驾驶中引发安全问题，因此需要直接检测传感器到车辆的标定误差。
- Method: 利用旋转偏差在连续3D点云生成的流场中引入的系统性偏差，结合神经场景流先验进行流估计，采用双分支检测网络融合学习的全局流特征与手工几何描述符，执行全局二元分类和轴特定二元分类任务。
- Result: 在nuScenes数据集上的实验表明，FlowCalib能够鲁棒地检测标定误差，为传感器到车辆标定误差检测建立了基准。
- Conclusion: FlowCalib是首个利用场景流检测LiDAR-车辆标定误差的框架，通过运动线索有效识别角度偏差，为自动驾驶安全提供了重要保障。


### [75] [Segment Any Events with Language](https://arxiv.org/abs/2601.23159)
*Seungjun Lee,Gim Hee Lee*

Main category: cs.CV

TL;DR: SEAL是首个支持开放词汇事件实例分割（OV-EIS）的语义感知分割框架，能够在多个粒度级别（实例级和部件级）进行事件分割和开放词汇掩码分类。

- Motivation: 虽然自由形式语言场景理解在图像、点云和LiDAR等多种模态中已有广泛研究，但事件传感器相关研究稀缺且主要集中在语义级理解。需要填补开放词汇事件实例分割的研究空白。
- Method: 提出SEAL框架，基于视觉提示实现统一的事件分割和开放词汇掩码分类。在附录中还提出了无需用户提供视觉提示的通用时空OV-EIS变体。
- Result: 构建了四个涵盖从粗到细类别配置和从实例级到部件级语义粒度的基准测试。实验表明SEAL在性能和推理速度上大幅优于基线方法，且架构参数高效。
- Conclusion: SEAL是首个解决开放词汇事件实例分割问题的框架，在多个粒度级别上实现了高性能的事件分割和分类，为事件传感器场景理解提供了新方向。


### [76] [Hi-Light: A Path to high-fidelity, high-resolution video relighting with a Novel Evaluation Paradigm](https://arxiv.org/abs/2601.23167)
*Xiangrui Liu,Haoxiang Li,Yezhou Yang*

Main category: cs.CV

TL;DR: Hi-Light是一个无需训练的视频重光照框架，通过三个技术创新解决视频重光照中的闪烁、细节丢失和缺乏评估指标的问题，并提出了首个量化光照一致性的评估指标。

- Motivation: 视频重光照具有巨大创意潜力和商业价值，但面临三大挑战：缺乏合适的评估指标、严重的光照闪烁问题，以及在编辑过程中细粒度细节的退化。
- Method: 1. 基于亮度先验的锚定引导重光照扩散：稳定中间重光照视频；2. 混合运动自适应光照平滑滤波器：利用光流确保时间稳定性而不引入运动模糊；3. LAB细节融合模块：保留原始视频的高频细节信息。
- Result: Hi-Light在定性和定量比较中显著优于现有最先进方法，能够生成稳定、高细节的重光照视频。提出的光照稳定性分数是首个专门测量光照一致性的量化指标。
- Conclusion: Hi-Light通过创新的训练免费框架成功解决了视频重光照的关键挑战，包括稳定性、细节保留和评估问题，为高质量视频重光照提供了有效解决方案。


### [77] [Med-Scout: Curing MLLMs' Geometric Blindness in Medical Perception via Geometry-Aware RL Post-Training](https://arxiv.org/abs/2601.23220)
*Anglin Liu,Ruichao Chen,Yi Lu,Hongxia Xu,Jintai Chen*

Main category: cs.CV

TL;DR: Med-Scout 框架通过强化学习利用医学图像内在几何逻辑，解决多模态大语言模型在医疗诊断中的几何盲区问题，显著提升几何感知能力。

- Motivation: 当前最先进的多模态大语言模型在医疗诊断中存在几何盲区问题，即无法将输出基于客观几何约束，导致看似合理但事实错误的幻觉。这源于训练范式过于注重语言流畅性而忽视几何保真度。
- Method: 提出Med-Scout框架，通过强化学习利用未标记医学图像中的内在几何逻辑。设计了三个战略代理任务来获取可验证的监督信号：分层尺度定位、拓扑拼图重建和异常一致性检测。同时创建了Med-Scout-Bench基准来量化几何感知缺陷。
- Result: Med-Scout显著缓解了几何盲区问题，在基准测试中优于领先的专有和开源多模态大语言模型超过40%。增强的几何感知能力还能泛化到更广泛的医学理解，在放射学和综合医学视觉问答任务中取得优异结果。
- Conclusion: Med-Scout框架通过利用医学图像内在几何逻辑的强化学习方法，有效解决了多模态大语言模型的几何盲区问题，提升了医疗诊断的几何感知能力和准确性。


### [78] [Region-Normalized DPO for Medical Image Segmentation under Noisy Judges](https://arxiv.org/abs/2601.23222)
*Hamza Kalisch,Constantin Seibold,Jens Kleesiek,Ken Herrmann,Frederic Jonske*

Main category: cs.CV

TL;DR: 提出RN-DPO方法，通过区域归一化改进医学图像分割中的偏好优化，利用噪声质量信号进行无额外标注的模型微调

- Motivation: 医学图像分割需要密集像素标注，成本高且难以扩展。现有系统已能产生自动质量信号（如模型一致性、不确定性、掩码质量分数），但这些信号有噪声和偏差，直接用于偏好优化可能导致有害更新
- Method: 提出Region-Normalized DPO (RN-DPO)，一种分割感知的目标函数，通过归一化掩码间分歧区域的大小来调整偏好更新，减少有害比较的影响并提高优化稳定性。基于小标注集训练的监督基础分割器生成提案
- Result: 在两个医学数据集和多种机制下，RN-DPO提高了持续性能并稳定了基于偏好的微调，优于标准DPO和强基线方法，且无需额外像素标注
- Conclusion: RN-DPO能有效利用噪声质量信号进行医学图像分割模型的偏好优化，通过区域归一化机制减少有害更新，提高优化稳定性，为无额外标注的模型改进提供了可行方案


### [79] [Video-o3: Native Interleaved Clue Seeking for Long Video Multi-Hop Reasoning](https://arxiv.org/abs/2601.23224)
*Xiangyu Zeng,Zhiqiu Zhang,Yuhan Zhu,Xinhao Li,Zikang Wang,Changlian Ma,Qingyu Zhang,Zizheng Huang,Kun Ouyang,Tianxiang Jiang,Ziang Yan,Yi Wang,Hongjie Zhang,Yali Wang,Limin Wang*

Main category: cs.CV

TL;DR: Video-o3是一个用于长视频理解的多模态大语言模型框架，通过迭代发现关键视觉线索、精细检查关键片段和自适应终止来提升稀疏关键证据的识别能力。

- Motivation: 现有长视频理解模型主要依赖均匀采样和单轮推理，难以在大量冗余内容中识别稀疏但关键的证据，需要更智能的迭代探索机制。
- Method: 提出Task-Decoupled Attention Masking解决推理与工具调用异质性导致的注意力分散问题，以及Verifiable Trajectory-Guided Reward平衡探索覆盖与推理效率。构建Seeker-173K数据集用于大规模训练。
- Result: 在MLVU上达到72.1%准确率，在Video-Holmes上达到46.5%准确率，显著优于现有方法，展示了强大的多跳证据搜索和推理能力。
- Conclusion: Video-o3通过原生工具调用机制有效解决了长视频理解中的稀疏关键证据识别问题，验证了迭代探索框架在复杂视频场景中的有效性。


### [80] [ShotFinder: Imagination-Driven Open-Domain Video Shot Retrieval via Web Search](https://arxiv.org/abs/2601.23232)
*Tao Yu,Haopeng Jin,Hao Wang,Shenghua Chai,Yujia Yang,Junhao Gong,Jiaming Guo,Minghui Zhang,Xinlong Chen,Zhenghao Zhang,Yuxuan Zhou,Yanpei Gong,YuanCheng Liu,Yiming Ding,Kangwei Zeng,Pengfei Yang,Zhongtian Luo,Yufei Xiong,Shanbin Zhang,Shaoxiong Cheng,Huang Ruilin,Li Shuo,Yuxi Niu,Xinyuan Zhang,Yueya Xu,Jie Mao,Ruixuan Ji,Yaru Zhao,Mingchen Zhang,Jiabing Yang,Jiaqi Liu,YiFan Zhang,Hongzhu Yi,Xinming Wang,Cheng Zhong,Xiao Ma,Zhang Zhang,Yan Huang,Liang Wang*

Main category: cs.CV

TL;DR: ShotFinder：首个针对开放域视频镜头检索的基准测试，包含5种可控约束类型，揭示了多模态大模型在视频镜头检索上的显著能力差距

- Motivation: 当前大语言模型在信息检索方面进展迅速，但现有研究主要关注文本或静态多模态设置。开放域视频镜头检索涉及更丰富的时间结构和复杂语义，缺乏系统性的基准测试和分析。
- Method: 1) 提出ShotFinder基准，将编辑需求形式化为关键帧导向的镜头描述，引入5种可控单因素约束：时间顺序、颜色、视觉风格、音频、分辨率；2) 从YouTube收集1,210个高质量样本，覆盖20个主题类别，使用大模型生成并人工验证；3) 提出文本驱动的三阶段检索和定位流程：查询扩展、候选视频检索、描述引导的时间定位。
- Result: 实验显示多模态大模型与人类性能存在显著差距，不同约束类型表现不平衡：时间定位相对容易，而颜色和视觉风格仍是主要挑战。
- Conclusion: 开放域视频镜头检索是多模态大模型尚未克服的关键能力，ShotFinder基准为这一领域提供了系统性的评估框架。


### [81] [Structured Over Scale: Learning Spatial Reasoning from Educational Video](https://arxiv.org/abs/2601.23251)
*Bishoy Galoaa,Xiangyu Bai,Sarah Ostadabbas*

Main category: cs.CV

TL;DR: 该论文提出了DoraVQA数据集，通过从《爱探险的朵拉》教育视频中提取问答对来训练视觉语言模型，解决了现有模型在简单推理任务上的不足，实现了从狭窄教育内容到广泛多模态理解的泛化。

- Motivation: 现有视觉语言模型在标准视频理解基准上表现良好，但在学龄前儿童都能解决的简单推理任务（如计数、空间推理、组合理解）上系统性失败。作者认为教育视频的结构化内容可以为提升这些能力提供理想的训练信号。
- Method: 1. 从8季《爱探险的朵拉》中自动提取5,344个问答对，创建DoraVQA数据集，具有精确的时间戳对齐；2. 利用教育内容中固有的清晰正确性信号和结构化推理轨迹，使用Group Relative Policy Optimization (GRPO)对Qwen2和Qwen3进行微调。
- Result: 仅在38小时儿童教育视频上训练，就在DoraVQA上提升8-14分，在CVBench上达到SOTA的86.16%，在Video-MME和NExT-QA上表现出强泛化能力，证明了从狭窄教育内容到广泛多模态理解的有效泛化。
- Conclusion: 视觉语言模型可以通过结构化教育内容学习执行需要稳健推理的任务，表明内容结构的重要性不亚于内容规模。教育视频的结构化教学特性为提升模型推理能力提供了有效途径。


### [82] [Training-Free Test-Time Adaptation with Brownian Distance Covariance in Vision-Language Models](https://arxiv.org/abs/2601.23253)
*Yi Zhang,Chun-Wun Cheng,Angelica I. Aviles-Rivero,Zhihai He,Liang-Jie Zhang*

Main category: cs.CV

TL;DR: TaTa提出了一种无需训练和反向传播的测试时适应方法，利用布朗距离协方差动态适应视觉语言模型到新领域，显著降低计算成本并提升性能。

- Motivation: 视觉语言模型在领域偏移下性能下降，现有测试时适应方法计算密集、依赖反向传播且多为单模态，需要更高效稳定的适应方案。
- Method: 使用布朗距离协方差（捕捉线性和非线性依赖关系）进行动态适应，结合属性增强提示、动态聚类和伪标签细化，无需训练或反向传播。
- Result: 在多个数据集上显著降低计算成本，同时在领域和跨数据集泛化方面达到最先进性能。
- Conclusion: TaTa为视觉语言模型提供了一种高效稳定的测试时适应方法，解决了领域偏移问题，具有实际应用价值。


### [83] [User Prompting Strategies and Prompt Enhancement Methods for Open-Set Object Detection in XR Environments](https://arxiv.org/abs/2601.23281)
*Junfeng Lin,Yanming Xiu,Maria Gorlatova*

Main category: cs.CV

TL;DR: 该研究评估了开放集目标检测模型在XR环境中对用户提示的鲁棒性，发现模型在模糊提示下性能下降，通过提示增强可显著提升性能。

- Motivation: 现有开放集目标检测模型在基准测试中表现良好，但在实际XR交互场景中，用户生成的提示往往存在模糊、欠详细或过度详细等问题，这些模型在真实用户提示下的行为尚未得到充分研究。
- Method: 评估了GroundingDINO和YOLO-E两个OSOD模型在真实XR图像上的表现，使用视觉语言模型模拟四种用户提示行为：标准、欠详细、过度详细和语用模糊提示，并研究了两种增强策略对这些提示的影响。
- Result: 两种模型在欠详细和标准提示下表现稳定，但在模糊提示下性能下降。过度详细提示主要影响GroundingDINO。提示增强显著提高了在模糊提示下的鲁棒性，mIoU提升超过55%，平均置信度提升41%。
- Conclusion: 基于研究结果，提出了针对XR环境中OSOD模型的多种提示策略和提示增强方法，以改善模型在实际交互场景中的表现。


### [84] [VideoGPA: Distilling Geometry Priors for 3D-Consistent Video Generation](https://arxiv.org/abs/2601.23286)
*Hongyang Du,Junjie Ye,Xiaoyan Cong,Runhao Li,Jingcheng Ni,Aman Agarwal,Zeqi Zhou,Zekun Li,Randall Balestriero,Yue Wang*

Main category: cs.CV

TL;DR: VideoGPA：一种自监督框架，通过几何基础模型自动生成密集偏好信号，使用DPO指导视频扩散模型，显著提升3D结构一致性和时间稳定性

- Motivation: 现有视频扩散模型在生成视频时难以保持3D结构一致性，常出现物体变形或空间漂移问题。标准去噪目标缺乏对几何一致性的明确激励
- Method: 提出VideoGPA框架：1）利用几何基础模型自动生成密集偏好信号；2）通过直接偏好优化（DPO）引导视频扩散模型；3）自监督方式无需人工标注
- Result: VideoGPA显著提升了时间稳定性、物理合理性和运动连贯性，在广泛实验中持续优于最先进的基线方法，仅需少量偏好对
- Conclusion: VideoGPA通过几何偏好对齐有效解决了视频扩散模型的3D一致性问题，为视频生成提供了数据高效的自监督解决方案
## cs.LG

### [85] [Attention Isn't All You Need for Emotion Recognition:Domain Features Outperform Transformers on the EAV Dataset](https://arxiv.org/abs/2601.22161)
*Anmol Guragain*

Main category: cs.LG

TL;DR: 复杂注意力机制在小规模多模态情感识别数据集上表现不佳，而简单的领域特定特征改进效果更好

- Motivation: 研究复杂注意力机制是否能在小规模多模态情感识别数据集（EAV）上提升性能
- Method: 实现三类模型：基线Transformer（M1）、新型分解注意力机制（M2）、改进的CNN基线（M3），并进行系统比较
- Result: 复杂注意力机制在小数据集上表现不佳（比基线低5-13个百分点），而简单的领域特定特征改进显著提升性能（音频+3.66pp，EEG+7.62pp，视觉+1.28pp）
- Conclusion: 对于小规模情感识别任务，领域知识和适当实现比架构复杂性更重要


### [86] [SurrogateSHAP: Training-Free Contributor Attribution for Text-to-Image (T2I) Models](https://arxiv.org/abs/2601.22276)
*Mingyu Lu,Soham Gadgil,Chris Lin,Chanwoo Kim,Su-In Lee*

Main category: cs.LG

TL;DR: SurrogateSHAP：一个无需重新训练的Shapley值近似框架，用于评估文本到图像扩散模型中数据贡献者的价值，显著降低计算成本

- Motivation: 随着文本到图像扩散模型在创意工作流程中的广泛应用，需要建立公平的数据贡献者价值评估框架。传统的Shapley值方法面临双重计算瓶颈：模型重新训练的高成本和组合子集数量的指数增长
- Method: 提出SurrogateSHAP框架：1) 通过预训练模型推理近似昂贵的重新训练过程；2) 使用梯度提升树近似效用函数，并从树模型中解析推导Shapley值
- Result: 在三个不同的归因任务中表现优异：CIFAR-20上的DDPM-CFG图像质量评估、后印象派艺术品的Stable Diffusion美学评估、时尚产品数据的FLUX.1产品多样性评估。相比现有方法显著降低计算开销，并能有效识别影响临床图像中虚假相关性的数据源
- Conclusion: SurrogateSHAP为数据贡献者价值评估提供了可扩展的解决方案，能够有效识别关键贡献者，并为审计安全关键生成模型提供了可行路径


### [87] [Weak Diffusion Priors Can Still Achieve Strong Inverse-Problem Performance](https://arxiv.org/abs/2601.22443)
*Jing Jia,Wei Yuan,Sifan Liu,Liyue Shen,Guanyang Wang*

Main category: cs.LG

TL;DR: 扩散模型在逆问题中作为先验时，即使训练数据与目标信号不匹配（弱先验），也能取得与完整强度、领域内基线相当的性能，研究探索了这种现象的条件和原因。

- Motivation: 研究动机是理解为什么在逆问题求解中，使用不匹配或低保真度的扩散模型先验（弱先验）往往能取得与高质量、领域内先验相近的性能，以及这种现象何时会发生。
- Method: 通过大量实验研究弱先验在不同条件下的表现，并基于贝叶斯一致性理论分析，给出高维测量使后验集中于真实信号附近的条件。
- Result: 研究发现弱先验在测量信息丰富时（如观测到大量像素）能够成功，同时识别了其失效的机制。理论分析提供了弱扩散先验可靠使用的原则性依据。
- Conclusion: 扩散模型作为逆问题先验时，即使训练数据与目标信号不匹配，只要测量信息足够丰富，弱先验也能可靠地恢复信号，这为实际应用中扩散先验的使用提供了理论指导。


### [88] [Stabilizing Consistency Training: A Flow Map Analysis and Self-Distillation](https://arxiv.org/abs/2601.22679)
*Youngjoong Kim,Duhoe Kim,Woosung Kim,Jaesik Park*

Main category: cs.LG

TL;DR: 本文从流映射角度理论分析一致性模型，揭示训练不稳定和收敛问题的根源，提出改进的自蒸馏方法稳定优化，并扩展到扩散策略学习

- Motivation: 一致性模型虽然能实现快速生成建模，但存在训练不稳定和可复现性有限的问题。现有解释零散，理论关系不明确，需要系统理论分析来理解这些问题根源
- Method: 从流映射角度对一致性模型进行理论分析，揭示训练稳定性和收敛行为如何导致退化解。基于此重新设计自蒸馏方法，避免梯度范数过大以实现稳定优化
- Result: 提出的方法不仅解决了图像生成中的收敛问题，还能扩展到基于扩散的策略学习，且无需预训练扩散模型初始化，展示了更广泛的适用性
- Conclusion: 通过流映射理论框架系统分析一致性模型，阐明了训练不稳定的机制，提出的改进自蒸馏方法能有效稳定优化，并验证了该方法在生成建模和强化学习中的通用性


### [89] [SQUAD: Scalable Quorum Adaptive Decisions via ensemble of early exit neural networks](https://arxiv.org/abs/2601.22711)
*Matteo Gambella,Fabrizio Pittorino,Giuliano Casale,Manuel Roveri*

Main category: cs.LG

TL;DR: SQUAD：首个将早退机制与分布式集成学习结合的推理方案，通过基于法定人数的停止准则和优化的层次多样性选择，显著提升不确定性估计并减少推理时间。

- Motivation: 传统早退神经网络依赖单一模型的置信度阈值，但由于校准问题经常不可靠，需要更稳健的早退决策机制。
- Method: 提出SQUAD方案，采用基于法定人数的停止准则，按计算复杂度顺序收集中间预测直到达成共识；引入QUEST神经架构搜索方法，选择具有优化层次多样性的早退学习器。
- Result: 相比最先进的动态解决方案，测试准确率提升高达5.95%，计算成本相当；相比静态集成，推理延迟降低高达70.60%，同时保持良好准确率。
- Conclusion: SQUAD通过共识驱动的早退机制，在减少推理时间的同时提供了统计上稳健的早退决策，显著改进了传统早退方法的局限性。


### [90] [Vision-Language Models Unlock Task-Centric Latent Actions](https://arxiv.org/abs/2601.22714)
*Alexander Nikulin,Ilya Zisman,Albina Klepach,Denis Tarasov,Alexander Derevyagin,Andrei Polubarov,Lyubaykin Nikita,Vladislav Kurenkov*

Main category: cs.LG

TL;DR: 利用视觉语言模型（VLMs）的常识推理能力，为潜在动作模型（LAMs）提供可提示的表征，有效分离可控变化与噪声，显著提升在含干扰环境中的性能

- Motivation: 现有潜在动作模型（LAMs）在处理包含动作相关干扰的观测时容易失败，会编码噪声而非有意义的潜在动作。相比之下，人类仅凭简短任务描述就能轻松区分视频中任务相关动作与无关细节。因此需要利用视觉语言模型（VLMs）的常识推理能力来解决这一问题。
- Method: 利用视觉语言模型（VLMs）提供可提示的表征，在无监督方式下有效分离可控变化与噪声。将这些表征作为LAM训练的目标，并对多种流行的VLMs进行基准测试，分析不同提示和超参数下的鲁棒性。发现简单要求VLMs忽略干扰就能显著提升潜在动作质量。
- Result: 研究发现不同VLMs提供的可提示表征质量存在显著差异，且对提示和超参数的鲁棒性不同。有趣的是，较新的VLMs可能比旧版本表现更差。通过要求VLMs忽略干扰，潜在动作质量得到大幅提升，在Distracting MetaWorld上的下游成功率最高可提升六倍。
- Conclusion: 利用视觉语言模型的常识推理能力为潜在动作模型提供可提示表征是有效的，能够显著提升在含干扰环境中的性能。研究揭示了不同VLMs在提供此类表征时的质量差异，并发现简单的提示策略就能带来显著改进。


### [91] [Decomposing and Composing: Towards Efficient Vision-Language Continual Learning via Rank-1 Expert Pool in a Single LoRA](https://arxiv.org/abs/2601.22828)
*Zhan Fa,Yue Duan,Jian Zhang,Lei Qi,Wanqi Yang,Yinghuan Shi*

Main category: cs.LG

TL;DR: 提出一种基于LoRA分解为Rank-1专家池的持续学习框架，通过动态组合稀疏任务特定更新和正交化损失，在减少96.7%参数的同时实现SOTA性能。

- Motivation: 视觉语言模型的持续学习面临任务适应性和灾难性遗忘的挑战。现有方法通常有较重推理负担或依赖外部知识，而直接使用LoRA缓解遗忘问题并不简单。
- Method: 将单个LoRA模块重构为可分解的Rank-1专家池，根据[CLS]令牌语义动态选择专家组成稀疏任务特定更新，并提出激活引导正交损失来正交化关键LoRA权重。
- Result: 在多个设置下实现所有指标的SOTA结果，超越零样本上界，减少96.7%可训练参数，无需外部数据集或任务ID判别器，合并LoRA权重更少且无推理延迟。
- Conclusion: 该方法通过稀疏组合和正交化实现领域感知学习，最小化任务间干扰，保持下游任务性能，为视觉语言模型持续学习提供计算轻量级解决方案。


### [92] [MoVE: Mixture of Value Embeddings -- A New Axis for Scaling Parametric Memory in Autoregressive Models](https://arxiv.org/abs/2601.22887)
*Yangyan Li*

Main category: cs.LG

TL;DR: MoVE（混合值嵌入）通过引入全局可学习值嵌入库，将模型容量与计算成本解耦，允许独立扩展参数记忆而不增加网络深度或宽度，在文本和图像生成任务中实现更好性能。

- Motivation: 自回归序列建模存在根本限制：模型容量与计算成本紧密耦合，扩展参数记忆（事实知识或视觉模式存储库）需要加深或加宽网络，导致计算成本成比例增加。需要打破这种耦合，建立新的容量扩展维度。
- Method: 提出MoVE机制，引入全局共享的可学习值嵌入库，通过可微分软门控机制在每个序列步骤中动态混合从该库检索的概念到标准值投影中。这种架构允许通过简单增加嵌入槽数量来独立于网络深度扩展参数记忆。
- Result: 在文本生成和图像生成两个代表性自回归建模应用中，MoVE相比标准和分层记忆基线都带来一致的性能提升，能够构建"记忆密集"模型，在可比计算预算下实现更低的困惑度和更高的保真度。
- Conclusion: MoVE成功打破了模型容量与计算成本之间的耦合，为自回归建模建立了新的容量扩展维度，为构建更高效的生成AI模型提供了有前景的方向。
## cs.CL

### [93] [PaperBanana: Automating Academic Illustration for AI Scientists](https://arxiv.org/abs/2601.23265)
*Dawei Zhu,Rui Meng,Yale Song,Xiyu Wei,Sujian Li,Tomas Pfister,Jinsung Yoon*

Main category: cs.CL

TL;DR: PaperBanana是一个基于先进视觉语言模型和图像生成模型的智能代理框架，用于自动生成可直接用于发表的学术插图，显著减轻研究流程中的插图制作负担。

- Motivation: 尽管基于语言模型的自主AI科学家发展迅速，但在研究流程中生成可直接用于发表的插图仍然是一个劳动密集型的瓶颈问题，需要大量人工投入。
- Method: PaperBanana采用智能代理框架，协调专门的代理来执行参考文献检索、内容和风格规划、图像渲染，并通过自我批判进行迭代优化。框架基于最先进的视觉语言模型和图像生成模型。
- Result: 通过PaperBananaBench（包含292个从NeurIPS 2025出版物中提取的方法论图测试案例）的综合实验表明，PaperBanana在忠实性、简洁性、可读性和美观性方面持续优于领先的基线方法。该方法还能有效扩展到高质量统计图的生成。
- Conclusion: PaperBanana为自动生成可直接用于发表的学术插图铺平了道路，显著减轻了研究人员的插图制作负担。
## cs.RO

### [94] [High-Definition 5MP Stereo Vision Sensing for Robotics](https://arxiv.org/abs/2601.22445)
*Leaf Jiang,Matthew Holzel,Bernhard Kaplan,Hsiou-Yuan Liu,Sabyasachi Paul,Karen Rankin,Piotr Swierczynski*

Main category: cs.RO

TL;DR: 该研究提出了一种针对5MP+高分辨率立体视觉系统的新型校准和立体匹配方法，旨在实现高精度和快速处理，并展示了高像素相机通过高精度校准才能产生高质量点云。

- Motivation: 高分辨率（5MP+）立体视觉系统对提升机器人能力至关重要，但传统方法无法满足高精度校准和快速处理的需求，这限制了高角分辨率传感器的潜力发挥。
- Method: 采用新型帧间校准和立体匹配方法处理5MP相机图像，并引入通过对比实时视差图与计算密集型算法生成的地面真值视差图来评估实时性能的新方法。
- Result: 研究证明高像素相机只有通过实施高精度校准才能产生高质量点云，同时新方法在保持高精度的同时实现了快速处理。
- Conclusion: 高分辨率立体视觉系统的潜力需要通过高精度校准和高效处理方法来充分实现，本研究提出的方法为此提供了有效解决方案。


### [95] [CARE: Multi-Task Pretraining for Latent Continuous Action Representation in Robot Control](https://arxiv.org/abs/2601.22467)
*Jiaqi Shi,Xulong Zhang,Xiaoyang Qu,Jianzong Wang*

Main category: cs.RO

TL;DR: CARE是一个无需动作标注的视觉-语言-动作模型训练框架，仅使用视频-文本对进行预训练，通过多任务目标学习连续潜在动作表示，在小规模标注数据上微调即可用于机器人控制。

- Motivation: 现有视觉-语言-动作模型依赖动作监督，限制了可扩展性和泛化能力。需要开发无需动作标注的弱监督训练方法。
- Method: CARE框架仅使用视频-文本对进行预训练，设计多任务目标学习连续潜在动作表示，然后在少量标注数据上训练动作头用于控制。
- Result: 在多个仿真任务中，CARE表现出更高的成功率、更好的语义可解释性，并能避免捷径学习。
- Conclusion: CARE证明了在弱监督下进行机器人控制的可扩展性、可解释性和有效性。
## eess.IV

### [96] [Deep Lightweight Unrolled Network for High Dynamic Range Modulo Imaging](https://arxiv.org/abs/2601.12526)
*Brayan Monroy,Jorge Bacca*

Main category: eess.IV

TL;DR: 提出一种基于深度先验和优化展开的HDR重建方法，使用轻量卷积去噪器快速恢复饱和图像，并引入尺度等变性实现自监督微调

- Motivation: 现有的模数成像恢复方法在噪声环境下表现不佳，需要一种能够有效处理噪声并适应不同分布的鲁棒恢复算法
- Method: 将HDR重建建模为包含深度先验的优化问题，展开为优化启发的深度神经网络，使用轻量卷积去噪器，并引入尺度等变性实现自监督微调
- Result: 在广泛评估中，该方法在性能和质量上优于现有最先进的恢复算法，能够有效恢复强度值并抑制噪声
- Conclusion: 提出的优化启发的深度网络结合尺度等变性自监督微调，为模数成像提供了一种高效、鲁棒的HDR重建解决方案


### [97] [SCENE: Semantic-aware Codec Enhancement with Neural Embeddings](https://arxiv.org/abs/2601.22189)
*Han-Yu Lin,Li-Wei Chen,Hung-Shin Lee*

Main category: eess.IV

TL;DR: 提出SCENE框架，一种轻量级、语义感知的预处理方法，通过选择性处理压缩伪影来提升视频感知质量，无需修改现有编码管道。

- Motivation: 标准视频编解码器产生的压缩伪影会降低感知质量，需要一种轻量级方法来增强压缩视频流的感知保真度。
- Method: 将视觉语言模型的语义嵌入集成到高效卷积架构中，使用可微分编解码器代理进行端到端训练，优先保留感知显著的结构。
- Result: 在高分辨率基准测试中，在客观指标（MS-SSIM）和感知指标（VMAF）上均优于基线方法，特别是在显著区域的纹理细节保留方面表现突出。
- Conclusion: 语义引导、编解码器感知的预处理是增强压缩视频流的有效方法，能够实现实时性能且不修改现有视频处理管道。


### [98] [A Survey on Semantic Communication for Vision: Categories, Frameworks, Enabling Techniques, and Applications](https://arxiv.org/abs/2601.22202)
*Runze Cheng,Yao Sun,Ahmad Taha,Xuesong Liu,David Flynn,Muhammad Ali Imran*

Main category: eess.IV

TL;DR: 该论文系统综述了面向视觉数据传输的语义通信（SemCom-Vision），提出了一种基于语义量化方案的新分类视角，将现有方法分为语义保持通信、语义扩展通信和语义细化通信三类，并分析了机器学习赋能的编码器-解码器模型、训练算法及知识利用策略。

- Motivation: 语义通信作为视觉数据传输的变革性范式，能够从传输原始数据转向传输有意义的内容，缓解通信资源压力。然而，实现语义通信面临准确语义量化、多样化任务下的鲁棒语义提取与重建、有效知识利用的收发器协调以及适应不可预测无线环境等挑战。
- Method: 采用跨学科分析方法，整合计算机视觉和通信工程，为机器学习赋能的SemCom-Vision设计提供全面指南。提出基于语义量化方案的新分类视角，将现有方法分为语义保持通信（SPC）、语义扩展通信（SEC）和语义细化通信（SRC）三类。详细阐述了每类方法的机器学习编码器-解码器模型和训练算法，以及知识结构和利用策略。
- Result: 建立了系统性的SemCom-Vision综述框架，提供了基于通信目标的新分类体系，分析了各类方法的机器学习实现方案，并探讨了知识利用策略，为未来语义通信系统设计提供了理论基础和实践指导。
- Conclusion: 该综述为视觉数据传输的语义通信领域提供了全面的分析框架，提出的分类视角有助于理解不同通信目标下的语义量化策略，机器学习方法的系统分析为实际系统设计提供了技术路线，知识利用策略的探讨为未来自适应语义通信系统发展指明了方向。


### [99] [EndoCaver: Handling Fog, Blur and Glare in Endoscopic Images via Joint Deblurring-Segmentation](https://arxiv.org/abs/2601.22537)
*Zhuoyu Wu,Wenhui Ou,Pei-Sze Tan,Jiayan Yang,Wenqi Fang,Zheng Wang,Raphaël C. -W. Phan*

Main category: eess.IV

TL;DR: EndoCaver是一个轻量级transformer架构，通过单向引导的双解码器设计，联合执行图像去模糊和息肉分割任务，在保持高性能的同时大幅减少模型参数，适合临床设备部署。

- Motivation: 内窥镜图像分析对结直肠癌筛查至关重要，但实际应用中常受镜头起雾、运动模糊和镜面高光等图像退化问题影响，严重损害自动化息肉检测性能。
- Method: 提出EndoCaver轻量级transformer，采用单向引导的双解码器架构，整合全局注意力模块(GAM)进行跨尺度聚合、去模糊-分割对齐器(DSA)传递恢复线索，以及基于余弦的调度器(LoCoS)实现稳定多任务优化。
- Result: 在Kvasir-SEG数据集上，EndoCaver在干净数据上达到0.922 Dice分数，在严重图像退化下达到0.889 Dice，超越现有方法同时减少90%模型参数。
- Conclusion: EndoCaver展示了高效性和鲁棒性，特别适合在临床设备上部署，为实际内窥镜图像分析提供了实用解决方案。


### [100] [Bonnet: Ultra-fast whole-body bone segmentation from CT scans](https://arxiv.org/abs/2601.22576)
*Hanjiang Zhu,Pedro Martelleto Rezende,Zhang Yang,Tong Ye,Bruce Z. Gao,Feng Luo,Siyu Huang,Jiancheng Yang*

Main category: eess.IV

TL;DR: Bonnet是一个用于CT扫描全身骨骼分割的超快速稀疏体积处理流程，相比现有3D体素模型（如nnU-Net）将推理时间减少约25倍，同时保持相似精度。

- Motivation: 准确的骨骼分割对于手术规划和解剖分析很重要，但现有的3D体素模型（如nnU-Net和STU-Net）需要大量计算，通常每个扫描需要几分钟，这限制了时间关键型应用。
- Method: Bonnet整合了一系列新颖的框架组件：基于HU值的骨骼阈值化、使用稀疏spconv-based U-Net进行分块推理、多窗口融合形成完整体积预测。
- Result: 在TotalSegmentator上训练，并在RibSeg、CT-Pelvic1K和CT-Spine1K上无需额外调优即可评估，Bonnet在肋骨、骨盆和脊柱上获得高Dice分数，同时在RTX A6000上每个扫描仅需2.69秒。相比强体素基线，达到相似精度但推理时间减少约25倍。
- Conclusion: Bonnet提供了一种高效准确的全身骨骼分割解决方案，显著减少了计算时间，适合时间敏感的应用场景，工具包和预训练模型已开源。


### [101] [Training Beyond Convergence: Grokking nnU-Net for Glioma Segmentation in Sub-Saharan MRI](https://arxiv.org/abs/2601.22637)
*Mohtady Barakat,Omar Salah,Ahmed Yasser,Mostafa Ahmed,Zahirul Arief,Waleed Khan,Dong Zhang,Aondona Iorumbur,Confidence Raymond,Mohannad Barakat,Noha Magdy*

Main category: eess.IV

TL;DR: 在非洲脑胶质瘤MRI分割任务中，通过nnUNet建立基线并探索"grokking"现象，在有限计算资源下获得良好性能，并通过延长训练触发grokking进一步提升分割精度。

- Motivation: 撒哈拉以南非洲地区胶质瘤临床负担日益加重，患者中位生存期不足两年，诊断影像资源极度有限。需要专门针对本地数据训练的自动化工具，而非从高收入国家条件差异巨大的环境中移植。
- Method: 使用BraTS Africa 2025挑战赛数据集，建立nnUNet基线模型。探索两种训练策略：1) 资源受限的快速训练（仅几个epoch）；2) 延长训练以触发"grokking"现象（从记忆到泛化的突然性能跃升）。
- Result: 快速训练下nnUNet获得良好Dice分数：全肿瘤92.3%、肿瘤核心86.6%、增强肿瘤86.3%。通过触发grokking现象，性能进一步提升：全肿瘤92.2%、肿瘤核心90.1%、增强肿瘤90.2%。
- Conclusion: 即使在计算资源受限的非洲机构，nnUNet也能在脑胶质瘤分割任务中取得良好性能。通过延长训练触发grokking现象，可以在不增加标注数据的情况下进一步提升模型性能，为资源受限环境提供有效解决方案。


### [102] [Active Learning-Driven Lightweight YOLOv9: Enhancing Efficiency in Smart Agriculture](https://arxiv.org/abs/2601.22732)
*Hung-Chih Tu,Bo-Syun Chen,Yun-Chien Cheng*

Main category: eess.IV

TL;DR: 提出基于主动学习的轻量级目标检测框架，用于温室环境下番茄和番茄花的实时检测，在边缘设备上实现高效部署

- Motivation: 农业机器人在温室环境中部署边缘设备进行实时检测时面临三大挑战：1) 相机距离变化导致的大尺度变化；2) 植物结构造成的严重遮挡；3) 高度不平衡的类别分布。传统目标检测方法难以同时实现高检测精度和部署效率
- Method: 提出主动学习驱动的轻量级目标检测框架，包含三个关键部分：1) 分析原始农业图像中物体尺寸分布，重新定义操作目标范围以提高学习稳定性；2) 引入高效特征提取模块降低计算成本，并采用轻量级注意力机制增强多尺度和遮挡场景下的特征表示；3) 采用主动学习策略，在有限标注预算下迭代选择高信息量样本进行标注和训练
- Result: 在保持低参数量和适合边缘设备部署的推理成本的同时，有效提升了番茄和番茄花在原始图像中的检测性能。在有限标注条件下，框架实现了67.8% mAP的整体检测精度
- Conclusion: 该方法验证了在智能农业应用中的实用性和可行性，为温室环境下农业机器人的实时目标检测提供了有效的解决方案


### [103] [Development of Domain-Invariant Visual Enhancement and Restoration (DIVER) Approach for Underwater Images](https://arxiv.org/abs/2601.22878)
*Rajini Makam,Sharanya Patil,Dhatri Shankari T M,Suresh Sundaram,Narasimhan Sundararajan*

Main category: eess.IV

TL;DR: DIVER是一个无监督的域不变水下图像增强框架，结合经验校正与物理引导建模，在多种水下环境中实现鲁棒增强，显著优于现有方法。

- Motivation: 水下图像因波长相关衰减、散射和光照不均匀性而严重退化，且退化程度随水类型和深度变化。现有方法在浅水表现尚可，但在深水、不均匀光照或人工照明条件下性能下降。
- Method: DIVER框架整合经验校正与物理引导建模：1) IlluminateNet进行自适应亮度增强或光谱均衡滤波器进行光谱归一化；2) 自适应光学校正模块通过通道自适应滤波优化色调和对比度；3) Hydro-OpticNet使用物理约束学习补偿后向散射和波长相关衰减。通过无监督学习和复合损失函数优化参数。
- Result: 在8个不同数据集（浅水、深水、高浑浊环境、自然低光和人工照明场景）上评估，DIVER在所有数据集上一致达到最佳或接近最佳性能，表现出强大的域不变能力。在UCIQE指标上比SOTA方法至少提升9%，在SeaThru数据集上GPMAE至少降低4.9%。同时改善了机器人感知的ORB关键点重复性和匹配性能。
- Conclusion: DIVER框架通过结合经验校正和物理引导建模，实现了跨不同水下环境的鲁棒图像增强，显著优于现有方法，并验证了其在机器人感知应用中的实用性。


### [104] [Scale Equivariance Regularization and Feature Lifting in High Dynamic Range Modulo Imaging](https://arxiv.org/abs/2601.23037)
*Brayan Monroy,Jorge Bacca*

Main category: eess.IV

TL;DR: 提出基于学习的HDR恢复框架，通过尺度等变正则化和特征提升输入设计，解决模数成像中的包裹伪影问题

- Motivation: 模数成像通过循环包裹饱和强度实现高动态范围采集，但重建困难，因为自然图像边缘和人工包裹不连续性之间存在模糊性
- Method: 1) 尺度等变正则化：在曝光变化下强制一致性；2) 特征提升输入设计：结合原始模数图像、包裹有限差分和闭式初始化
- Result: 在感知和线性HDR质量指标上实现最先进性能，增强网络区分真实结构和包裹伪影的能力
- Conclusion: 提出的学习框架有效解决了模数成像中的HDR恢复挑战，通过正则化和输入设计显著提升了重建质量


### [105] [Vision-Language Controlled Deep Unfolding for Joint Medical Image Restoration and Segmentation](https://arxiv.org/abs/2601.23103)
*Ping Chen,Zicheng Huang,Xiangming Wang,Yungeng Liu,Bingyu Liang,Haijin Zeng,Yongyong Chen*

Main category: eess.IV

TL;DR: VL-DUN是一个用于联合医学图像恢复与分割的统一框架，通过数学耦合的展开机制和频率感知Mamba模块，实现了恢复与分割的相互增强，在多模态基准上取得了SOTA性能。

- Motivation: 传统医学图像处理流程将恢复（低层信号恢复）和分割（高层语义理解）作为独立任务处理，但这两个任务本质上是协同的：恢复提供清晰解剖结构以改进分割，而分割先验可以正则化恢复过程。顺序处理的次优性需要更统一的解决方案。
- Method: 1. 将联合医学图像恢复与分割（AiOMIRS）表述为统一的优化问题，推导出可解释的联合展开机制，使恢复和分割在数学上耦合以实现相互精炼。2. 引入频率感知Mamba机制，以线性复杂度捕获长距离依赖关系进行全局分割，同时保留恢复所需的高频纹理，有效缓解标准架构的频谱偏差。
- Result: 在多模态基准测试中建立了新的最先进水平：PSNR提高了0.92 dB，Dice系数提高了9.76%。结果表明，联合协作学习相比独立任务处理为复杂临床工作流程提供了更优越、更稳健的解决方案。
- Conclusion: VL-DUN通过将恢复和分割任务数学耦合，并利用频率感知Mamba机制有效建模全局上下文，证明了联合协作学习在医学图像处理中的优越性，为临床工作流程提供了更强大的解决方案。


### [106] [Scale-Cascaded Diffusion Models for Super-Resolution in Medical Imaging](https://arxiv.org/abs/2601.23201)
*Darshan Thaker,Mahmoud Mostapha,Radu Miron,Shihan Qiu,Mariappan Nadar*

Main category: eess.IV

TL;DR: 提出基于拉普拉斯金字塔的多尺度扩散先验模型，用于医学图像超分辨率，通过分频带训练扩散先验并逐级细化重建，在提升感知质量的同时减少推理时间。

- Motivation: 现有扩散模型作为生成先验通常只在单一尺度上训练，忽略了图像数据的层次化尺度结构。医学图像超分辨率需要更好地利用多尺度信息来提升重建质量。
- Method: 将图像分解为拉普拉斯金字塔尺度，为每个频带训练独立的扩散先验。开发算法利用这些先验在不同尺度上逐步细化超分辨率重建。
- Result: 在脑部、膝盖和前列腺MRI数据上的评估显示，该方法在感知质量上优于基线方法，同时通过较小的粗尺度网络减少了推理时间。
- Conclusion: 该框架将多尺度重建与扩散先验统一起来，为医学图像超分辨率提供了一种有效方法，既改善了感知质量又提高了计算效率。
## cs.GR

### [107] [HeatMat: Simulation of City Material Impact on Urban Heat Island Effect](https://arxiv.org/abs/2601.22796)
*Marie Reinbigler,Romain Rouffet,Peter Naylor,Mikolaj Czerkawski,Nikolaos Dionelis,Elisabeth Brunet,Catalin Fetita,Rosalie Martin*

Main category: cs.GR

TL;DR: HeatMat：基于开放数据的高分辨率城市热岛效应分析方法，通过街景图像和视觉语言模型估计建筑材料，结合2.5D模拟器快速分析材料对热岛效应的影响

- Motivation: 城市热岛效应研究面临传感器数据时空分辨率不足的挑战，且难以分析建筑材料的具体影响。现有方法难以准确估计城市建筑材料分布，特别是建筑立面材料。
- Method: 1. 使用街景图像和预训练视觉语言模型估计建筑材料，补充OpenStreetMap的2D几何数据；2. 将信息编码为表示城市垂直结构和材料特性的2D地图；3. 开发2.5D模拟器建模耦合热传递，实现多分辨率随机访问表面温度估计
- Result: 方法仅依赖开放数据，实现了城市尺度高分辨率热岛效应分析。2.5D模拟器相比等效3D模拟速度提升20倍，支持多分辨率温度估计
- Conclusion: HeatMat提供了一种基于开放数据的高效方法，能够分析建筑材料对城市热岛效应的个体影响，为城市规划和材料配置测试提供了实用工具


### [108] [EAG-PT: Emission-Aware Gaussians and Path Tracing for Indoor Scene Reconstruction and Editing](https://arxiv.org/abs/2601.23065)
*Xijie Yang,Mulin Yu,Changjian Jiang,Kerui Ren,Tao Lu,Jiangmiao Pang,Dahua Lin,Bo Dai,Linning Xu*

Main category: cs.GR

TL;DR: EAG-PT提出了一种基于2D高斯表示的统一场景表示方法，结合了辐射场的高质量重建和基于物理的光线传输，解决了室内场景编辑中的光照问题。

- Motivation: 现有方法存在两难：基于辐射场的方法（如NeRF、3DGS）能高质量重建室内场景，但编辑时因烘焙光照和缺乏显式光线传输而失效；而基于物理的逆渲染方法依赖网格表示和路径追踪，对几何保真度要求高，在实际室内场景中成为瓶颈。
- Method: 提出EAG-PT方法，核心包括：1）使用2D高斯作为统一场景表示和传输友好的几何代理，避免重建网格；2）在重建过程中显式分离发光和非发光组件以支持场景编辑；3）通过高效单次反弹优化和高质量多次反弹路径追踪，将重建与最终渲染解耦。
- Result: 在合成和真实室内场景上的实验表明，EAG-PT在编辑后能产生比辐射场景重建更自然、物理一致的渲染结果，同时相比基于网格的逆路径追踪方法，能保留更精细的几何细节并避免网格引起的伪影。
- Conclusion: 该方法为室内设计、XR内容创作和具身AI等应用提供了有前景的方向，实现了高质量重建与物理正确光线传输的统一。
## astro-ph.IM

### [109] [Denoising the Deep Sky: Physics-Based CCD Noise Formation for Astronomical Imaging](https://arxiv.org/abs/2601.23276)
*Shuhong Liu,Xining Ge,Ziying Gu,Lin Gu,Ziteng Cui,Xuangeng Chu,Jun Liu,Dong Li,Tatsuya Harada*

Main category: astro-ph.IM

TL;DR: 提出基于物理的CCD噪声合成框架，通过多曝光平均生成高信噪比基图，合成真实噪声配对数据用于监督学习，并发布多波段真实望远镜数据集

- Motivation: 天文成像在实用观测条件下仍受噪声限制，传统校准流程主要去除结构化伪影但保留随机噪声。基于学习的去噪方法面临配对训练数据稀缺、科学工作流需要物理可解释和可复现模型的挑战
- Method: 提出物理噪声合成框架，建模CCD噪声形成过程（光子散粒噪声、光响应非均匀性、暗电流噪声、读出效应、宇宙射线和热像素异常值）。通过平均多个未配准曝光生成高信噪比基图，使用噪声模型合成真实噪声配对数据
- Result: 构建了丰富的配对数据集用于监督学习，并发布了包含双望远镜多波段采集的真实世界数据集，提供配对原始帧、仪器管道校准帧、校准数据和高信噪比堆叠基图
- Conclusion: 该物理噪声合成框架解决了天文去噪中训练数据稀缺问题，为基于学习的去噪方法提供了物理可解释、可复现的解决方案，并通过真实数据集支持实际评估
## cs.IR

### [110] [Compact Hypercube Embeddings for Fast Text-based Wildlife Observation Retrieval](https://arxiv.org/abs/2601.22783)
*Ilyass Moummad,Marius Miron,David Robinson,Kawtar Zaher,Hervé Goëau,Olivier Pietquin,Pierre Bonnet,Emmanuel Chemla,Matthieu Geist,Alexis Joly*

Main category: cs.IR

TL;DR: 提出紧凑超立方体嵌入用于快速文本检索野生动物观测，通过二进制表示实现大规模图像和音频数据库的高效搜索

- Motivation: 大规模生物多样性监测平台依赖多模态野生动物观测，但现有基础模型的高维相似性搜索计算成本高，难以从海量档案中检索相关观测
- Method: 基于跨视图代码对齐哈希框架，将轻量级哈希扩展到多模态设置，在共享汉明空间中对齐自然语言描述与视觉或听觉观测，利用预训练野生动物基础模型并通过参数高效微调适配哈希
- Result: 在iNaturalist2024和iNatSounds2024等大规模基准测试中，离散超立方体嵌入检索性能与连续嵌入相当甚至更优，同时大幅降低内存和搜索成本，哈希目标还提升了底层编码器表示能力
- Conclusion: 二进制语言检索为生物多样性监测系统提供了可扩展且高效的大规模野生动物档案搜索方案
