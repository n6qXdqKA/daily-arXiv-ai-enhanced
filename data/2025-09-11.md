[[toc]]

## cs.CV

### [1] [3D and 4D World Modeling: A Survey](https://arxiv.org/abs/2509.07996)
*Lingdong Kong,Wesley Yang,Jianbiao Mei,Youquan Liu,Ao Liang,Dekai Zhu,Dongyue Lu,Wei Yin,Xiaotao Hu,Mingkai Jia,Junyuan Deng,Kaiwen Zhang,Yang Wu,Tianyi Yan,Shenyuan Gao,Song Wang,Linfeng Li,Liang Pan,Yong Liu,Jianke Zhu,Wei Tsang Ooi,Steven C. H. Hoi,Ziwei Liu*

Main category: cs.CV

TL;DR: 该论文是关于3D和4D世界建模的首个系统性综述，提出了明确的定义和分类体系，填补了现有研究在标准化和系统性方面的空白。

- Motivation: 现有世界建模研究主要关注2D图像和视频生成，忽视了3D/4D表示方法（如RGB-D、占据网格、LiDAR点云）的快速发展，且缺乏标准化的定义和分类体系，导致文献中的研究分散且不一致。
- Method: 建立了精确的定义体系，提出了结构化分类法（VideoGen视频生成、OccGen占据生成、LiDARGen激光雷达生成），系统总结了3D/4D场景下的数据集和评估指标。
- Result: 提供了首个专门针对3D和4D世界建模与生成的全面综述，为领域发展提供了连贯的基础性参考框架。
- Conclusion: 该综述填补了3D/4D世界建模领域的系统性空白，为未来研究提供了标准化框架和发展方向，有助于推动该领域的进一步发展。


### [2] [An Explainable Deep Neural Network with Frequency-Aware Channel and Spatial Refinement for Flood Prediction in Sustainable Cities](https://arxiv.org/abs/2509.08003)
*Shahid Shafi Dar,Bharat Kaurav,Arnav Jain,Chandravardhan Singh Raghaw,Mohammad Zia Ur Rehman,Nagendra Kumar*

Main category: cs.CV

TL;DR: XFloodNet是一个基于深度学习的城市洪水分类框架，通过跨模态注意力机制和多尺度特征提取，在三个基准数据集上取得了最先进的性能表现。

- Motivation: 传统洪水检测方法依赖单模态数据和静态规则系统，无法捕捉洪水事件的动态非线性关系。现有注意力机制和集成学习方法在层次细化、跨模态特征集成以及对噪声环境的适应性方面存在局限。
- Method: 提出XFloodNet框架，包含三个核心组件：1)分层跨模态门控注意力机制；2)异构卷积自适应多尺度注意力模块；3)级联卷积Transformer特征细化技术。
- Result: 在Chennai Floods、Rhine18 Floods和Harz17 Floods三个数据集上分别达到93.33%、82.24%和88.60%的F1分数，显著超越现有方法。
- Conclusion: XFloodNet通过先进的深度学习技术重新定义了城市洪水分类，解决了传统方法的局限性，在多个基准数据集上实现了最先进的性能。


### [3] [Video Parallel Scaling: Aggregating Diverse Frame Subsets for VideoLLMs](https://arxiv.org/abs/2509.08016)
*Hyungjin Chung,Hyelin Nam,Jiyeon Kim,Hyojun Go,Byeongjun Park,Junho Kim,Joonseok Lee,Seongsu Ha,Byung-Hoon Kim*

Main category: cs.CV

TL;DR: Video Parallel Scaling (VPS) 是一种推理时方法，通过并行处理视频帧子集来扩展视频大语言模型的感知带宽，避免长上下文带来的计算成本问题

- Motivation: 视频大语言模型在处理长视频时面临计算成本过高和性能下降的问题，需要一种不增加上下文窗口但能提升时间推理能力的方法
- Method: 运行多个并行推理流，每个流处理视频帧的不同子集，然后聚合这些互补流的输出概率来整合更丰富的视觉信息
- Result: 在多个模型架构和规模（2B-32B）上的实验表明，VPS 在 Video-MME 和 EventHallusion 等基准测试中持续显著提升性能，比其他并行方法扩展性更好
- Conclusion: VPS 提供了一种内存高效且鲁棒的框架，可增强视频大语言模型的时间推理能力，且与其他解码策略互补


### [4] [Two Stage Context Learning with Large Language Models for Multimodal Stance Detection on Climate Change](https://arxiv.org/abs/2509.08024)
*Lata Pangtey,Omkar Kabde,Shahid Shafi Dar,Nagendra Kumar*

Main category: cs.CV

TL;DR: 多模态立场检测框架，通过层次融合文本和视觉信息，在气候变化立场检测任务上超越现有方法

- Motivation: 现有立场检测方法主要仅使用文本数据，而现实社交媒体内容越来越多地结合文本和视觉元素，需要充分利用多模态信息
- Method: 使用大语言模型提取文本摘要，领域知识图片描述生成器解释视觉内容，通过专门的transformer模块关合建模文本和图片之间的交互
- Result: 在MultiClimate数据集上达到准确率76.2%，精度76.3%，召回率76.2%，F1分76.2%，超越了现有最先进方法
- Conclusion: 本文提出的多模态融合框架能够有效利用文本和视觉信息，在立场检测任务上取得了显著的性能提升


### [5] [Two-Stage Swarm Intelligence Ensemble Deep Transfer Learning (SI-EDTL) for Vehicle Detection Using Unmanned Aerial Vehicles](https://arxiv.org/abs/2509.08026)
*Zeinab Ghasemi Darehnaei,Mohammad Shokouhifar,Hossein Yazdanjouei,S. M. J. Rastegar Fatemi*

Main category: cs.CV

TL;DR: SI-EDTL是一个两阶段群体智能集成深度迁移学习模型，用于无人机图像中的多车辆检测，通过集成多个预训练模型和分类器，结合鲸鱼优化算法调优，在AU-AIR数据集上表现优异

- Motivation: 解决无人机图像中多车辆检测的挑战，传统方法在复杂场景下检测精度不足，需要开发更准确高效的检测模型
- Method: 两阶段集成方法：第一阶段使用三个预训练的Faster R-CNN特征提取器（InceptionV3、ResNet50、GoogLeNet）与五个迁移分类器（KNN、SVM、MLP、C4.5、朴素贝叶斯）组合成15个基础学习器；第二阶段通过加权平均集成，使用鲸鱼优化算法优化超参数平衡准确率、精确率和召回率
- Result: 在MATLAB R2020b中实现并行处理，在AU-AIR无人机数据集上超越了现有方法
- Conclusion: SI-EDTL模型通过集成学习和优化算法，显著提升了无人机图像中多车辆检测的性能，为复杂场景下的目标检测提供了有效解决方案


### [6] [MCTED: A Machine-Learning-Ready Dataset for Digital Elevation Model Generation From Mars Imagery](https://arxiv.org/abs/2509.08027)
*Rafał Osadnik,Pablo Gómez,Eleni Bohacek,Rickbir Bahia*

Main category: cs.CV

TL;DR: 这篇论文提供了一个新的火星数字高程模型预测数据集MCTED，包含80,898个样本，并验证了小型U-Net模型在该数据集上的性能超过了现有的深度估计基础模型。

- Motivation: 解决火星数字高程模型中常见的伪式和数据缺失问题，为机器学习应用提供一个高质量、多样化的数据集。
- Method: 使用火星轨道器CTX仪器收集的高分辨率正弄图像和DEM数据，通过综合处理流水线生成数据集，包含光学图像补丁、DEM补丁和两个掩码补丁，并进行训练/验证数据分割。
- Result: 生成了80,898个样本的MCTED数据集，小型U-Net模型在该数据集上的高程预测性能超过了DepthAnythingV2基础模型的零样本性能。
- Conclusion: MCTED数据集为火星高程模型预测提供了高质量的训练数据，小型专门模型可以在该领域超过通用基础模型，数据集已开源发布。


### [7] [APML: Adaptive Probabilistic Matching Loss for Robust 3D Point Cloud Reconstruction](https://arxiv.org/abs/2509.08104)
*Sasan Sharifipour,Constantino Álvarez Casado,Mohammad Sabokrou,Miguel Bordallo López*

Main category: cs.CV

TL;DR: 提出APML损失函数，通过可微分的Sinkhorn迭代实现点云预测任务中的一对一匹配，解决了传统损失函数的多对一对应问题，在保持接近二次时间复杂度的情况下获得更好的空间分布和收敛性能

- Motivation: 传统点云预测损失函数（如CD、HyperCD、InfoCD）存在多对一对应问题，导致密集区域点拥堵和稀疏区域覆盖不足，且包含不可微操作；EMD虽然能实现一对一匹配但计算复杂度高
- Method: 提出自适应概率匹配损失（APML），利用基于温度缩放相似度矩阵的Sinkhorn迭代实现完全可微分的一对一匹配近似，通过分析计算温度参数避免手动调参
- Result: 在ShapeNet基准测试和WiFi CSI到3D人体点云生成任务中，APML损失实现了更快的收敛速度、更好的空间分布（特别是在低密度区域），以及相当或改进的定量性能，无需额外超参数搜索
- Conclusion: APML损失提供了一种计算高效、完全可微分的点云匹配解决方案，在保持接近Chamfer距离计算效率的同时，获得了类似EMD的一对一匹配优势，适用于各种点云预测任务


### [8] [Lightweight Deep Unfolding Networks with Enhanced Robustness for Infrared Small Target Detection](https://arxiv.org/abs/2509.08205)
*Jingjing Liu,Yinchao Han,Xianchao Xiu,Jianhua Zhang,Wanquan Liu*

Main category: cs.CV

TL;DR: 提出L-RPCANet轻量级框架，通过层次瓶颈结构和噪声抑制模块解决红外小目标检测中的参数轻量化和噪声鲁棒性问题

- Motivation: 现有深度展开网络在红外小目标检测中虽然表现良好，但在参数轻量化和噪声鲁棒性方面仍面临重大挑战
- Method: 基于鲁棒主成分分析构建层次瓶颈结构，使用瓶颈层进行特征提取，嵌入噪声抑制模块，并采用SENet作为通道注意力机制
- Result: 在ISTD数据集上的大量实验验证了该方法相比RPCANet、DRPCANet和RPCANet++等最先进方法的优越性
- Conclusion: L-RPCANet在保持轻量化和鲁棒性的同时实现了优异性能，代码将在GitHub上开源


### [9] [Sparse Transformer for Ultra-sparse Sampled Video Compressive Sensing](https://arxiv.org/abs/2509.08228)
*Miao Cao,Siming Zheng,Lishun Wang,Ziyang Chen,David Brady,Xin Yuan*

Main category: cs.CV

TL;DR: 这篇论文提出了超稀疏采样(USS)策略和BSTFormer模型，通过降低数码相机的能耗和提高动态范围，实现了高效的视频压缩成像。

- Motivation: 传统数码相机在高分辨率和高帧率时能耗过高，需要物理层压缩采样来降低能耗。以图像修复(I2P)为灵感，提出更节能的采样策略。
- Method: 提出Ultra-Sparse Sampling(USS)策略，在每个空间位置只设置一个子帧为1，其他为0。并构建BSTFormer模型，结合局部块注意力、全局稀疏注意力和时间注意力来处理USS测量数据。
- Result: 在模拟和实际数据上，该方法显著超越了之前的最先进算法。USS策略还具有比随机采样(RS)更高的动态范围。
- Conclusion: USS策略是实现隧片上视频SCI系统的良好选择，具有固定曝光时间和高动态范围的优势，为高速高分辨率相机提供了可持续的解决方案。


### [10] [GTA-Crime: A Synthetic Dataset and Generation Framework for Fatal Violence Detection with Adversarial Snippet-Level Domain Adaptation](https://arxiv.org/abs/2509.08232)
*Seongho Kim,Sejong Ryu,Hyoukjun You,Je Hyeong Hong*

Main category: cs.CV

TL;DR: 提出了GTA-Crime数据集和生成框架，利用GTA5游戏生成致命暴力视频，并通过域适应策略提升真实世界暴力检测准确率

- Motivation: 现有视频异常检测方法难以检测致命事件（如枪击、刺伤），因为这类事件罕见且存在数据收集的伦理问题
- Method: 使用GTA5游戏创建致命暴力视频数据集，提出片段级域适应策略（Wasserstein对抗训练）来弥合合成数据与真实数据之间的特征差异
- Result: 实验验证了GTA-Crime数据集的有效性，结合域适应策略能够持续提升真实世界致命暴力检测的准确率
- Conclusion: GTA-Crime为致命暴力检测提供了可行的合成数据解决方案，通过域适应技术成功将游戏生成数据应用于真实场景的异常检测


### [11] [RepViT-CXR: A Channel Replication Strategy for Vision Transformers in Chest X-ray Tuberculosis and Pneumonia Classification](https://arxiv.org/abs/2509.08234)
*Faisal Ahmed*

Main category: cs.CV

TL;DR: 提出RepViT-CXR方法，通过通道复制策略将单通道胸部X光图像适配到ViT架构，在TB和肺炎检测任务上达到SOTA性能

- Motivation: 解决ViT架构预训练在自然图像上需要三通道输入，而胸部X光扫描本质上是灰度单通道图像的不匹配问题
- Method: 采用通道复制策略，将单通道CXR图像转换为ViT兼容格式，避免信息损失
- Result: 在三个基准数据集上表现优异：TB-CXR数据集准确率99.9%、AUC 99.9%；儿科肺炎数据集准确率99.0%、AUC 99.0%；深圳TB数据集准确率91.1%、AUC 91.2%，均超越现有最佳方法
- Conclusion: 简单有效的通道复制策略能让ViT在灰度医学影像任务中充分发挥表征能力，具有实际临床筛查系统部署潜力


### [12] [Symmetry Interactive Transformer with CNN Framework for Diagnosis of Alzheimer's Disease Using Structural MRI](https://arxiv.org/abs/2509.08243)
*Zheng Yang,Yanteng Zhang,Xupeng Kou,Yang Liu,Chao Ren*

Main category: cs.CV

TL;DR: 提出了一种结合3D CNN编码器和对称交互Transformer的端到端网络，用于检测阿尔茨海默病引起的脑萎缩不对称性，在ADNI数据集上达到92.5%的诊断准确率。

- Motivation: 现有研究大多基于预训练或忽略脑部疾病引起的不对称特征，需要开发能够更好捕捉AD引起的左右脑萎缩不对称性的方法。
- Method: 使用3D CNN编码器提取特征，通过对称交互Transformer(SIT)处理左右半球对齐特征，重点关注结构变化引起的不对称区域。
- Result: 在ADNI数据集上达到92.5%的诊断准确率，优于多种CNN方法和CNN结合通用Transformer的方法，可视化显示网络更关注脑萎缩区域。
- Conclusion: 该方法能够有效捕捉AD引起的病理不对称特征，具有较好的可解释性和诊断性能，为阿尔茨海默病的早期诊断提供了有效工具。


### [13] [EVDI++: Event-based Video Deblurring and Interpolation via Self-Supervised Learning](https://arxiv.org/abs/2509.08260)
*Chi Zhang,Xiang Zhang,Chenxu Jiang,Gui-Song Xia,Lei Yu*

Main category: cs.CV

TL;DR: EVDI++是一个自监督的事件相机视频去模糊和插值框架，利用事件相机的高时间分辨率来解决传统相机长曝光导致的运动模糊问题，通过可学习双积分网络和自适应融合策略实现高质量视频恢复。

- Motivation: 传统帧式相机在长曝光时会产生明显的视觉模糊和帧间信息丢失，严重影响视频质量。事件相机具有高时间分辨率特性，可以捕捉运动细节，因此被用来解决运动模糊和帧率不足的问题。
- Method: 提出Learnable Double Integral (LDI)网络估计参考帧与清晰潜在图像的映射关系；引入基于学习的除法重建模块优化结果和训练效率；设计无参数自适应融合策略利用LDI输出的置信度；构建自监督学习框架利用模糊帧、潜在图像和事件流之间的相互约束进行训练。
- Result: 在合成和真实数据集上的大量实验表明，该方法在视频去模糊和插值任务中达到了最先进的性能，并在使用DAVIS346c相机构建的真实数据集上展示了良好的泛化能力。
- Conclusion: EVDI++提供了一个统一的自监督框架，成功利用事件相机的高时间分辨率特性有效解决了视频运动模糊和帧间插值问题，在真实场景中表现出优异的性能。


### [14] [Hyperspectral Mamba for Hyperspectral Object Tracking](https://arxiv.org/abs/2509.08265)
*Long Gao,Yunhe Zhang,Yan Jiang,Weiying Xie,Yunsong Li*

Main category: cs.CV

TL;DR: 提出HyMamba网络，通过状态空间模块统一建模光谱、跨深度和时间信息，在7个基准数据集上实现最先进的性能

- Motivation: 现有高光谱跟踪器无法有效捕捉内在光谱信息、时间依赖性和跨深度交互，需要新的方法来充分利用高光谱数据的丰富信息
- Method: 提出HyMamba网络，包含光谱状态集成(SSI)模块和高光谱Mamba(HSM)模块，通过三个方向扫描SSM同步学习空间和光谱信息
- Result: 在HOTC2020数据集上达到73.0%的AUC分数和96.3%的DP@20分数，在7个基准数据集上实现state-of-the-art性能
- Conclusion: HyMamba通过统一建模光谱、跨深度和时间信息，有效提升了高光谱目标跟踪的性能，证明了所提方法的有效性


### [15] [Examining Vision Language Models through Multi-dimensional Experiments with Vision and Text Features](https://arxiv.org/abs/2509.08266)
*Saurav Sengupta,Nazanin Moradinasab,Jiebei Liu,Donald E. Brown*

Main category: cs.CV

TL;DR: 研究发现视觉语言模型在处理需要关注图像特定区域的精确问题时，会依赖训练时的固有偏见而忽略视觉证据，导致性能下降。

- Motivation: 探索视觉语言模型在处理需要关注图像细节的精确问题时，为何会忽视视觉证据而依赖训练偏见，以及输入数据特征如何影响模型性能。
- Method: 建立多维检测框架，系统分析输入数据特征（图像和提示词）对性能的影响，使用开源视觉语言模型研究注意力值随输入参数（图像大小、物体数量、背景颜色、提示词特异性）的变化。
- Result: 即使图像特征和提示词特异性的微小变化也会导致视觉语言模型回答方式和整体性能的巨大变化。
- Conclusion: 视觉语言模型在处理精确视觉问题时存在显著偏见，输入参数的微小变化会显著影响模型行为，需要开发方法来表征这种变化。


### [16] [Generalized Zero-Shot Learning for Point Cloud Segmentation with Evidence-Based Dynamic Calibration](https://arxiv.org/abs/2509.08280)
*Hyeonseok Kim,Byeongkeun Kang,Yeejin Lee*

Main category: cs.CV

TL;DR: E3DPC-GZSL是一种针对3D点云广义零样本语义分割的新方法，通过证据不确定性估计和动态校准机制解决seen类过拟合问题，在ScanNet v2和S3DIS数据集上达到SOTA性能

- Motivation: 解决3D点云零样本分割中模型对seen类的预测偏置问题，特别是在训练数据规模较小的3D应用中，这种偏置问题比图像任务更加严重
- Method: 集成基于证据的不确定性估计器到分类器中，使用动态校准堆叠因子调整预测概率；提出新的训练策略，通过合并可学习参数和文本特征来改进语义空间和不确定性估计
- Result: 在ScanNet v2和S3DIS等广义零样本语义分割数据集上实现了最先进的性能
- Conclusion: E3DPC-GZSL有效解决了3D点云零样本分割中的seen类过拟合问题，通过不确定性估计和语义空间优化显著提升了模型对unseen类的识别能力


### [17] [Dual-Thresholding Heatmaps to Cluster Proposals for Weakly Supervised Object Detection](https://arxiv.org/abs/2509.08289)
*Yuelin Guo,Haoyu He,Zhiyuan Chen,Zitong Huang,Renhao Lu,Lu Shi,Zejun Wang,Weizhe Zhang*

Main category: cs.CV

TL;DR: 本文提出了一种改进的弱监督物体检测方法，通过热力图导向的建议选择算法、基础检测网络和负确定性监督损失，解决了现有方法在假假定位框生成、语义差距咏收效率等方面的问题，在PASCAL VOC数据集上达到了独创性能水平。

- Motivation: 现有的弱监督物体检测方法存在三个主要问题：1）假假定位框要么只覆盖区别性部位覆盖不全，要么无法区分相邻的同类实例；2）WSDDN基础网络缺乏背景类表征并存在语义差距；3）忽略建议在优化中被丢弃，导致效率低下。
- Method: 提出了三项核心技术：1）热力图导向的建议选择算法（HGPS），利用双阈值在热力图上预选建议；2）弱监督基础检测网络（WSBDN），为每个建议增加背景类表征并使用热力图进行预监督；3）负确定性监督损失，对忽略的建议进行负监督以加快效率。
- Result: 在PASCAL VOC 2007和2012数据集上进行了广泛实验，分别达到了58.5%/81.8%（VOC 2007）和55.6%/80.5%（VOC 2012）的mAP/mCorLoc分数，性能在弱监督物体检测方法中处于领先地位。
- Conclusion: 本文提出的方法有效解决了弱监督物体检测中的三大关键问题，通过热力图导向的建议选择、基础检测网络改进和负确定性监督等技术，显著提升了检测性能和效率，为弱监督物体检测领域提供了新的解决方案。


### [18] [An Open Benchmark Dataset for GeoAI Foundation Models for Oil Palm Mapping in Indonesia](https://arxiv.org/abs/2509.08303)
*M. Warizmi Wafiq,Peter Cutter,Ate Poortinga,Daniel Marc G. dela Torre,Karis Tenneson,Vanna Teck,Enikoe Bihari,Chanarun Saisaward,Weraphong Suaruang,Andrea McMahon,Andi Vika Faradiba Muin,Karno B. Batiran,Chairil A,Nurul Qomar,Arya Arismaya Metananda,David Ganz,David Saah*

Main category: cs.CV

TL;DR: 一个开放访问的印尼油椰植株地理空间数据集，通过高分辨率卫星图像专家标注制作，支持可持续性监测和遮蓝气候目标。

- Motivation: 油椰植株是印尼遮蓝的主要原因之一，需要详细可靠的地监映射来支持可持续性展开和监管框架。
- Method: 通过专家标注2020-2024年高分辨率卫星图像，采用多解释员共识和现场验证保证质量，制作了包含油椰植株阶段和相似多年生作物的层次分类系统。
- Result: 产生了一个适合训练卷积神经网络和地理空间基础模型的开放访问数据集，填补了遮感训练数据的关键空白。
- Conclusion: 该数据集通过支持油椰扩张的透明监测，有助于实现全球遮蓝减少目标，并遵循FAIR数据原则。


### [19] [SimCroP: Radiograph Representation Learning with Similarity-driven Cross-granularity Pre-training](https://arxiv.org/abs/2509.08311)
*Rongsheng Wang,Fenghe Tang,Qingsong Yao,Rui Yan,Xu Zhang,Zhen Huang,Haoran Lai,Zhiyang He,Xiaodong Tao,Zihang Jiang,Shaohua Kevin Zhou*

Main category: cs.CV

TL;DR: SimCroP是一个用于胸部CT扫描的相似性驱动跨粒度预训练框架，通过多模态掩码建模、相似性驱动对齐和跨粒度融合，提升稀疏病变区域的识别能力，在多个下游任务中优于现有方法。

- Motivation: CT扫描中病变分布具有空间稀疏性，且放射影像与报告描述之间存在复杂的隐式关系，传统方法难以有效处理这些挑战。
- Method: 采用多模态掩码建模优化编码器理解低层语义，相似性驱动对齐选择和对齐正确图像块与报告句子，跨粒度融合模块整合实例级和词-块级多模态信息。
- Result: 在五个公共数据集上的图像分类和分割任务中，SimCroP超越了最先进的医学自监督学习和医学视觉-语言预训练方法。
- Conclusion: SimCroP框架通过创新的相似性驱动对齐和跨粒度融合机制，有效解决了CT影像中稀疏病变的识别挑战，在医学影像分析任务中表现出优异性能。


### [20] [Boosted Training of Lightweight Early Exits for Optimizing CNN Image Classification Inference](https://arxiv.org/abs/2509.08318)
*Yehudit Aperstein,Alexander Apartsin*

Main category: cs.CV

TL;DR: 提出BTS-EE增强训练方案，通过顺序训练和校准解决早期退出网络中的协方差偏移问题，在CINIC-10数据集上实现计算量减少45%而精度仅下降2%

- Motivation: 资源受限平台上实时图像分类需要平衡精度与延迟功耗，传统早期退出训练存在协方差偏移问题，下游分支训练与推理时处理的数据分布不匹配
- Method: BTS-EE顺序训练方法，逐分支训练和校准；轻量级1D卷积分支架构；Class Precision Margin校准方法实现逐类阈值调优
- Result: 在ResNet18骨干网络上，BTS-EE在64种配置下均优于非增强训练，计算量最多减少45%，精度仅下降2%
- Conclusion: 该方法扩展了CNN在实时图像处理系统中的部署设计空间，为工业检测、嵌入式视觉和无人机监控等应用提供实用效率提升


### [21] [Retrieval-Augmented VLMs for Multimodal Melanoma Diagnosis](https://arxiv.org/abs/2509.08338)
*Jihyun Moon,Charmgil Hong*

Main category: cs.CV

TL;DR: 通过检索增强的视觉-语言模型框架，结合相似病例信息来提高黑色素瘩的诊断准确性

- Motivation: 现有CNN模型忽视临床元数据且需要大量预处理，而通用VLMs在专业医疗领域表现不佳
- Method: 提出检索增强的VLM框架，在诊断提示中融入语义相似的病例信息
- Result: 无需细调即可做出信息化预测，在分类准确性和错误置信方面显著超过传统基线方法
- Conclusion: 检索增强的提示策略为临床决策支持提供了稳健的解决方案


### [22] [InsFusion: Rethink Instance-level LiDAR-Camera Fusion for 3D Object Detection](https://arxiv.org/abs/2509.08374)
*Zhongyu Xia,Hansong Yang,Yongtao Wang*

Main category: cs.CV

TL;DR: InsFusion是一种3D目标检测方法，通过从原始和融合特征中提取提案并查询原始特征来减少多视角相机和LiDAR融合过程中的误差累积

- Motivation: 解决多视角相机和LiDAR融合过程中在特征提取、透视变换和特征融合等环节噪声和误差逐渐累积的问题
- Method: 提出InsFusion方法，从原始和融合特征中提取提案，利用这些提案查询原始特征，并结合注意力机制处理原始特征
- Result: 在nuScenes数据集上的实验表明，InsFusion与多种先进基线方法兼容，并实现了新的最先进的3D目标检测性能
- Conclusion: InsFusion通过有效处理特征融合过程中的误差累积问题，显著提升了多传感器3D目标检测的精度和鲁棒性


### [23] [Bitrate-Controlled Diffusion for Disentangling Motion and Content in Video](https://arxiv.org/abs/2509.08376)
*Xiao Li,Qi Chen,Xiulian Peng,Kai Yu,Xie Chen,Yan Lu*

Main category: cs.CV

TL;DR: 通过变据器架构和低码率向量量化，提出了一种自监督视频表征解耦框架，能够将视频数据分离为动态运动和静态内容组件，并通过去噪扩散模型进行表征学习。

- Motivation: 解决视频数据中运动和内容组件混合的问题，提供一种更少偏见和假设的自监督解耦表征学习方法。
- Method: 使用变据器架构生成帧间运动和剧情内容的隐式特征，通过低码率向量量化作为信息瓶颈促进解耦，并使用去噪扩散模型进行条件表征学习。
- Result: 在说话头部视频的运动转移和自回归运动生成任务上验证了方法的有效性，同时能够泛化到2D卡通角色等其他类型视频数据。
- Conclusion: 该方法为自监督视频解耦表征学习提供了新视角，对视频分析和生成领域做出了贡献。


### [24] [Semantic Causality-Aware Vision-Based 3D Occupancy Prediction](https://arxiv.org/abs/2509.08388)
*Dubing Chen,Huan Zheng,Yucheng Zhou,Xianfei Li,Wenlong Liao,Tao He,Pai Peng,Jianbing Shen*

Main category: cs.CV

TL;DR: 提出了一种新颖的因果损失函数，通过端到端监督实现2D到3D语义占位预测的模块化管道整体优化，解决了现有方法因模块独立优化导致的级联误差问题。

- Motivation: 现有基于视觉的3D语义占位预测方法通常采用模块化管道，这些模块独立优化或使用预配置输入，导致级联误差。需要一种能够实现整体端到端监督的方法。
- Method: 设计了基于2D到3D语义因果关系的因果损失函数，使整个管道可微分。提出了语义因果感知的2D到3D转换，包含三个组件：通道分组提升、可学习相机偏移和归一化卷积。
- Result: 在Occ3D基准测试中达到了最先进的性能，表现出对相机扰动的显著鲁棒性和改进的2D到3D语义一致性。
- Conclusion: 通过因果损失函数实现了模块化2D到3D转换管道的端到端监督，使先前不可训练的组件完全可学习，显著提升了3D语义占位预测的性能和鲁棒性。


### [25] [VRAE: Vertical Residual Autoencoder for License Plate Denoising and Deblurring](https://arxiv.org/abs/2509.08392)
*Cuong Nguyen,Dung T. Tran,Hong Nguyen,Xuan-Vu Phan,Nam-Phong Nguyen*

Main category: cs.CV

TL;DR: 通过竖向殊差自动编码器(VRAE)架构，在参数仅增加1%的情况下，对比传统自动编码器提升PSNR约20%，降低NMSE约50%，改善SSIM约1%

- Motivation: 在逆天气、光照不良或高速运动条件下，车辆图像容易出现严重噪声和模糊，影响号牌识别系统的准确性，特别是当号牌占图像小区域时
- Method: 提出竖向殊差自动编码器(VRAE)架构，通过辅助块注入输入相关特征来指导表征学习，比传统自动编码器更好地保保存一般信息
- Result: 在车辆图像数据集上表现超过AE、GAN和流基方法，在同样深度下提升PSNR约20%，降低NMSE约50%，改善SSIM约1%，参数仅增加约1%
- Conclusion: VRAE架构能够在参数效率极高的情况下显著提升逆天气车辆图像的识别性能，为交通监控系统提供了高效的图像增强方案


### [26] [Sparse BEV Fusion with Self-View Consistency for Multi-View Detection and Tracking](https://arxiv.org/abs/2509.08421)
*Keisuke Toida,Taigo Sakai,Naoki Kato,Kazutoyo Yokota,Takeshi Nakamura,Kazuhiro Hotta*

Main category: cs.CV

TL;DR: SCFusion是一个多视图多目标跟踪框架，通过稀疏变换、密度感知加权和多视图一致性损失来解决BEV投影中的特征失真问题，在WildTrack和MultiviewX数据集上达到最先进性能。

- Motivation: 多视图多目标跟踪中，传统的鸟瞰图投影方法存在特征失真和非均匀密度问题，导致检测和跟踪精度下降，需要更好的特征融合方法。
- Method: 提出SCFusion框架：1）稀疏变换避免投影中的插值失真；2）密度感知加权基于空间置信度和相机距离自适应融合特征；3）多视图一致性损失让每个相机在融合前学习判别性特征。
- Result: 在WildTrack数据集上达到95.9%的IDF1分数，在MultiviewX数据集上达到89.2%的MODP分数，优于基线方法TrackTacular。
- Conclusion: SCFusion有效缓解了传统BEV投影的局限性，为多视图目标检测和跟踪提供了鲁棒且准确的解决方案。


### [27] [LD-ViCE: Latent Diffusion Model for Video Counterfactual Explanations](https://arxiv.org/abs/2509.08422)
*Payal Varshney,Adriano Lucieri,Christoph Balada,Sheraz Ahmed,Andreas Dengel*

Main category: cs.CV

TL;DR: LD-ViCE是一个基于潜在扩散模型的视频反事实解释框架，通过潜在空间操作降低计算成本，生成真实且可解释的反事实解释，在三个视频数据集上表现优异。

- Motivation: 视频AI系统在安全关键领域应用广泛，但现有解释技术存在时间连贯性不足、鲁棒性差、缺乏因果洞察等问题，需要更有效的解释方法。
- Method: 使用最先进的扩散模型在潜在空间操作，通过额外的精炼步骤生成真实且可解释的反事实解释，降低计算成本。
- Result: 在EchoNet-Dynamic、FERV39k和Something-Something V2三个数据集上，LD-ViCE比现有最优方法R2分数提升高达68%，推理时间减少一半。
- Conclusion: LD-ViCE生成了语义有意义且时间连贯的解释，为目标模型行为提供了有价值的洞察，是迈向AI在安全关键领域可信部署的重要一步。


### [28] [Beyond Distribution Shifts: Adaptive Hyperspectral Image Classification at Test Time](https://arxiv.org/abs/2509.08436)
*Xia Yue,Anfeng Liu,Ning Chen,Chenjia Huang,Hui Liu,Zhou Huang,Leyuan Fang*

Main category: cs.CV

TL;DR: 提出HyperTTA框架，通过多退化数据集、光谱空间Transformer分类器和轻量级测试时适应策略，增强高光谱图像分类模型在各种退化条件下的鲁棒性。

- Motivation: 高光谱图像分类模型对噪声、模糊、压缩和大气效应等现实世界退化引起的分布偏移高度敏感，需要提高模型在多样化退化条件下的鲁棒性。
- Method: 1) 构建包含9种代表性退化的多退化高光谱数据集；2) 设计光谱空间Transformer分类器(SSTC)，采用多级感受野机制和标签平滑正则化；3) 提出置信度感知熵最小化LayerNorm适配器(CELA)进行轻量级测试时适应。
- Result: 在两个基准数据集上的广泛实验表明，HyperTTA在各种退化场景下均优于现有基线方法，验证了其分类主干和TTA方案的有效性。
- Conclusion: HyperTTA框架通过系统化的数据集构建、先进的分类器设计和轻量级测试时适应策略，显著提升了高光谱图像分类在退化条件下的鲁棒性能，且无需源数据或目标标注。


### [29] [Spherical Brownian Bridge Diffusion Models for Conditional Cortical Thickness Forecasting](https://arxiv.org/abs/2509.08442)
*Ivan Stoyanov,Fabian Bongratz,Christian Wachinger*

Main category: cs.CV

TL;DR: 基于球面布朗运动模型的直接方法，预测个体化高分辨率直觉层厚度变化轨迹，在ADNI和OASIS数据集上实现了更高准确性和可解释性。

- Motivation: 准确预测个体化高分辨率直觉层厚度轨迹对检测神经退行性疾病和提早干预至关重要，但因直觉的非欧几里得几何特性和多模态数据整合考需面临挑战。
- Method: 提出球面布朗运动模型(SBDM)，采用双向条件布朗运动扩散过程预测直觉表面顶点级CTh轨迹，设计条件球面U-Net(CoS-UNet)结合球面卷积和密集交叉注意力整合直觉表面和表格条件。
- Result: 在ADNI和OASIS纵向数据集上实验显示，SBDM实现了显著减少的预测误差，能够生成个体真实和反事实CTh轨迹。
- Conclusion: SBDM为直觉发育假设场景探索提供了新框架，在直觉层厚度预测上实现了更高准确性和可解释性。


### [30] [First-order State Space Model for Lightweight Image Super-resolution](https://arxiv.org/abs/2509.08458)
*Yujie Zhu,Xinyi Zhang,Yekai Lu,Guang Yang,Faming Fang,Guixu Zhang*

Main category: cs.CV

TL;DR: 提出了FSSM（一阶状态空间模型）来改进Mamba模块，通过引入一阶保持条件和token相关性，在不增加参数量的情况下提升了轻量级超分辨率任务的性能。

- Motivation: 现有的Mamba视觉模型主要关注网络架构和扫描路径，而很少关注SSM模块本身。为了探索状态空间模型的潜力，需要改进SSM计算过程。
- Method: 在SSM中应用一阶保持条件，推导新的离散化形式，并分析累积误差，通过引入token相关性来增强原始Mamba模块。
- Result: 在五个基准数据集上，FSSM在不增加参数量的情况下提升了MambaIR的性能，超越了当前轻量级超分辨率方法，达到了最先进的结果。
- Conclusion: FSSM通过改进SSM模块的计算过程，有效提升了轻量级超分辨率任务的性能，证明了状态空间模型在视觉任务中的潜力。


### [31] [Maximally Useful and Minimally Redundant: The Key to Self Supervised Learning for Imbalanced Data](https://arxiv.org/abs/2509.08469)
*Yash Kumar Sharma,Vineet Nair,Wilson Naik*

Main category: cs.CV

TL;DR: 提出基于互信息的多视图对比自监督学习方法，解决不平衡数据集问题，在多个基准测试中达到新的SOTA准确率

- Motivation: 对比自监督学习在平衡数据集上表现良好，但在不平衡数据集上泛化能力不足。受Yann LeCun关于多视图框架可扩展到超过两个视图的启发，研究如何改进不平衡数据集上的表现
- Method: 基于互信息理论提出多视图目标函数，通过区分类内和类间判别特征来提取尾部类的代表性特征，引入新的损失函数过滤极端特征
- Result: 在多种自监督框架上验证有效，Cifar10-LT提升2%，Cifar100-LT提升5%，Imagenet-LT提升3%，达到新的SOTA准确率
- Conclusion: 多视图目标函数能有效改善不平衡数据集上的自监督学习表现，通过互信息理论和特征过滤机制提升尾部类别的表征学习能力


### [32] [Prompt-Driven Image Analysis with Multimodal Generative AI: Detection, Segmentation, Inpainting, and Interpretation](https://arxiv.org/abs/2509.08489)
*Kaleem Ahmad*

Main category: cs.CV

TL;DR: 基于单个提示的统一图像分析管道，结合开放词汇检测、提示分割、文本条件塞光和视觉语言描述功能

- Motivation: 将多个图像分析步骤（定位、分割、编辑、描述）统一到单个自然语言指令中，提供透明可调试的工作流
- Method: 建立结合开放词汇检测、提示分割、文本条件塞光和视觉语言描述的统一管道，包含交互式UI和脚本化CLI
- Result: 在单词提示段落中，检测和分割在90%情况下生成可用面具，准确率超15%；塞光占总运行时间60-75%
- Conclusion: 提供了一种透明可靠的模式，通过明确的拦栏和运维实践来组装现代视觉多模态模型，提高物体替换、场景增强和删除的可靠性


### [33] [A Structured Review of Underwater Object Detection Challenges and Solutions: From Traditional to Large Vision Language Models](https://arxiv.org/abs/2509.08490)
*Edwine Nabahirwa,Wei Song,Minghua Zhang,Yi Fang,Zhou Ni*

Main category: cs.CV

TL;DR: 水下物体检测面临多重挑战，本文系统分析了五大挑战领域，探讨了从传统方法到大型视觉-语言模型的发展，并通过案例研究展示了合成数据生成和模型微调的潜力。

- Motivation: 水下物体检测在海洋科研、水下机器人和海洋保护中具有重要价值，但现有方法无法充分应对水下环境的复杂性。需要系统分析挑战并探索新方法来提升检测性能。
- Method: 采用系统分类方法，将水下物体检测挑战分为五大类别：图像质量退化、目标相关问题、数据挑战、计算处理约束和检测方法限制。分析了从传统到现代方法的进展，并探索大型视觉-语言模型的应用潜力，包括使用DALL-E 3生成合成数据集和微调Florence-2模型。
- Result: 识别了三个关键发现：(i)现有水下检测方法在应对图像退化和小物体检测方面仍不充分；(ii)LVLMs生成合成数据具有潜力，但需要进一步提高真实性和适用性；(iii)LVLMs在水下检测中有广阔前景，但实时应用研究仍不足。
- Conclusion: 大型视觉-语言模型为水下物体检测带来了新的机遇，特别是在合成数据生成和多模态处理方面。未来需要重点研究模型优化技术以实现实时应用，并提高合成数据的质量和实用性。


### [34] [Chirality in Action: Time-Aware Video Representation Learning by Latent Straightening](https://arxiv.org/abs/2509.08502)
*Piyush Bagad,Andrew Zisserman*

Main category: cs.CV

TL;DR: 这篇论文提出了一种自监督学习方法，通过渗透性直观直线化偏置来改善视频表征的时间敏感性，以识别对称动作对。

- Motivation: 开发对时间变化敏感的紧凑视频表征，解决当前视频嵌入表征在识别对称动作（如打开/关闭门）时表现差的问题。
- Method: 使用基于自动编码器的自监督学习方法，在冻结的图像特征序列上注入时间敏感性，采用受渗透性直观直线化启发的引导偏置。
- Result: 在Something-Something、EPIC-Kitchens和Charade三个数据集上表现优异，超过大规模视频模型，与现有模型结合后能提升标准分类性能。
- Conclusion: 该方法能够生成紧凑但具有良好时间敏感性的视频表征，在对称动作识别任务上表现突出，为视频理解提供了有效的时间敏感表征。


### [35] [HuMo: Human-Centric Video Generation via Collaborative Multi-Modal Conditioning](https://arxiv.org/abs/2509.08519)
*Liyang Chen,Tianxiang Ma,Jiawei Liu,Bingchuan Li,Zhuowei Chen,Lijie Liu,Xu He,Gen Li,Qian He,Zhiyong Wu*

Main category: cs.CV

TL;DR: HuMo是一个统一的人类中心视频生成框架，通过构建高质量多模态数据集和两阶段训练范式，有效解决了多模态输入协调、主体保持和音视频同步的挑战。

- Motivation: 现有方法在处理文本、图像和音频等多模态输入时面临两个主要挑战：配对三元组训练数据稀缺，以及难以协调主体保持和音视频同步两个子任务。
- Method: 1) 构建高质量配对多模态数据集；2) 采用两阶段渐进式训练：第一阶段使用最小侵入式图像注入策略保持主体，第二阶段通过焦点预测策略实现音视频同步；3) 推理时使用时间自适应分类器自由引导策略。
- Result: 实验结果表明HuMo在各项子任务上超越了专门的先进方法，建立了统一的多模态条件人类视频生成框架。
- Conclusion: HuMo成功解决了多模态人类视频生成中的关键挑战，通过创新的数据集构建、训练策略和推理方法，实现了协同多模态控制的有效统一框架。


### [36] [MESH -- Understanding Videos Like Human: Measuring Hallucinations in Large Video Models](https://arxiv.org/abs/2509.08538)
*Garry Yang,Zizhe Chen,Man Hon Wong,Haoyu Lei,Yongqiang Chen,Zhenguo Li,Kaiwen Zhou,James Cheng*

Main category: cs.CV

TL;DR: MESH是一个新的视频幻觉评估基准，采用问答框架和自下而上方法，系统评估大型视频模型的幻觉问题。

- Motivation: 现有视频幻觉基准过度依赖人工分类，忽略了人类自然理解视频的感知过程，需要更系统化的评估方法。
- Method: 使用问答框架（二元和多项选择），包含目标和陷阱实例，采用自下而上方法评估基础对象、粗到细的主体特征以及主体-动作对。
- Result: 大型视频模型在识别基础对象和特征方面表现良好，但在处理细节或对齐多个动作时幻觉显著增加。
- Conclusion: MESH提供了有效且全面的视频幻觉识别方法，能够系统评估LVMs的幻觉问题。


### [37] [ViewSparsifier: Killing Redundancy in Multi-View Plant Phenotyping](https://arxiv.org/abs/2509.08550)
*Robin-Nico Kampa,Fabian Deuser,Konrad Habel,Norbert Oswald*

Main category: cs.CV

TL;DR: 本文提出了ViewSparsifier方法，在植物生长建模挑战赛中通过多视图学习获得了植物年龄预测和叶片计数估计两个任务的最佳成绩

- Motivation: 传统的单视图分类或回归模型无法充分捕捉植物表型性状的所有信息，影响植物健康评估和收获准备度预测的准确性
- Method: 使用多视图数据集，通过随机选择24个视图（选择向量）学习视图不变嵌入，并尝试了从5个高度级别随机选择视图（共120个视图，选择矩阵）的方法
- Result: ViewSparsifier方法在ACM Multimedia 2025的Growth Modelling挑战赛中赢得了植物年龄预测和叶片计数估计两个任务
- Conclusion: 多视图学习方法能有效提升植物表型分析性能，随机视图选择策略是未来研究的有前景方向


### [38] [Vision-Language Semantic Aggregation Leveraging Foundation Model for Generalizable Medical Image Segmentation](https://arxiv.org/abs/2509.08570)
*Wenjun Yu,Yinchen Zhou,Jia-Xuan Jiang,Shubin Zeng,Yuee Li,Zhong Wang*

Main category: cs.CV

TL;DR: 这篇论文提出了一种新的多模态聚合方法，通过EM聚合机制和文本导向像素解码器，有效解决了医学图像分割中的语义空隔和特征分散问题，在多个领域普适性测试中超越了现有最优方法。

- Motivation: 多模态模型在自然图像分割中表现突出，但在医学领域应用中性能不佳。这主要因为抽象文本提示与细粒度医学视觉特征之间存在显著的语义空隔，以及由此导致的特征分散问题。
- Method: 从语义聚合的角度出发，提出了期望最大化(EM)聚合机制和文本导向像素解码器。EM聚合通过动态聚类将特征聚合成紧凑的语义中心，减少特征分散；文本导向解码器利用领域不变的文本知识来指导深度视觉表征。
- Result: 在公开的心脏和眼底数据集上进行了大量实验，结果表明该方法在多个领域普适性测试中一贯地超过了现有的SOTA方法。
- Conclusion: 通过EM聚合机制和文本导向像素解码器的协同作用，有效地缩小了文本提示与医学图像之间的语义空隔，明显提升了模型的普适性能力，为医学图像分割提供了有效的解决方案。


### [39] [Improving Greenland Bed Topography Mapping with Uncertainty-Aware Graph Learning on Sparse Radar Data](https://arxiv.org/abs/2509.08571)
*Bayu Adhi Tama,Homayra Alam,Mostafa Cham,Omar Faruque,Jianwu Wang,Vandana Janeja*

Main category: cs.CV

TL;DR: GraphTopoNet是一个图学习框架，通过融合异构监督和蒙特卡洛dropout建模不确定性，用于生成格陵兰冰床高精度地图，比基线方法减少60%误差

- Motivation: 格陵兰冰床地图对海平面预测至关重要，但雷达观测数据稀疏且不均匀，需要更精确的建模方法
- Method: 构建基于地表观测数据（高程、速度、质量平衡）的空间图，添加梯度特征和多项式趋势，采用混合损失函数结合置信度加权的雷达监督和动态平衡正则化
- Result: 在格陵兰三个子区域应用，性能优于插值、卷积和图基线方法，误差减少高达60%，同时保留冰川细尺度特征
- Conclusion: GraphTopoNet展示了图机器学习如何将稀疏不确定的地球物理观测转化为大陆尺度的可操作知识，提高了操作建模的可靠性


### [40] [Implicit Shape-Prior for Few-Shot Assisted 3D Segmentation](https://arxiv.org/abs/2509.08580)
*Mathilde Monvoisin,Louise Piecuch,Blanche Texier,Cédric Hémon,Anaïs Barateau,Jérémie Huet,Antoine Nordez,Anne-Sophie Boureau,Jean-Claude Nunes,Diana Mateus*

Main category: cs.CV

TL;DR: 提出了一种基于隐式形状先验的医学图像分割方法，通过稀疏切片标注实现多器官3D分割，并自动选择最具信息量的切片来减少人工标注工作量

- Motivation: 减轻医学专业人员在3D分割任务中的手动工作量，特别是在放疗规划和退行性疾病诊断中需要精确器官分割但无法完全自动化的场景
- Method: 引入隐式形状先验，从稀疏切片手动标注中分割体积并推广到多器官情况，同时提供自动选择最具信息量切片的简单框架来指导最小化后续交互
- Result: 实验验证显示该方法在两个医学用例中有效：脑癌患者风险器官的辅助分割，以及为肌少症患者创建新数据库的加速
- Conclusion: 该方法能显著减少医学3D分割中的人工工作量，在放疗规划和疾病诊断中具有实际应用价值


### [41] [EfficientIML: Efficient High-Resolution Image Manipulation Localization](https://arxiv.org/abs/2509.08583)
*Jinhan Li,Haoyang He,Lei Xie,Jiangning Zhang*

Main category: cs.CV

TL;DR: 通过构建高分辨率SIF数据集和轻量级EfficientIML模型，解决了传统检测方法在激流基伪造方式下的计算资源约束问题

- Motivation: 因为影像设备分辨率提升和激流基伪造技术的出现，传统检测方法缺乏对这种新型操纵的暴露，且现有方法面临计算资源约束
- Method: 构建包含1200+激流生成操纵的高分辨率SIF数据集，并提出轻量约EfficientIML模型，采用三阶段EfficientRWKV背锁，结合混合状态空间和注意力网络，以及多尺度监督策略
- Result: 在自建数据集和标准测试集上评估显示，该方法在定位性能、FLOPs和推理速度方面都超过了ViT基础和其他SOTA轻量级基线模型
- Conclusion: 该方法通过新的数据集和轻量约模型结构，有效解决了激流基伪造检测的计算效率问题，适合实时审计应用


### [42] [CLAPS: A CLIP-Unified Auto-Prompt Segmentation for Multi-Modal Retinal Imaging](https://arxiv.org/abs/2509.08618)
*Zhihao Zhao,Yinzheng Zhao,Junjie Yang,Xiangtong Yao,Quanmin Liang,Shahrooz Faghihroohi,Kai Huang,Nassir Navab,M. Ali Nasseri*

Main category: cs.CV

TL;DR: CLAPS是一个用于视网膜影像多模态统一分割的新方法，通过CLIP预训练、自动空间提示生成和文本提示增强，实现完全自动化的精确分割。

- Motivation: 解决当前医学影像分割中的三个关键挑战：文本疾病描述的模态模糊性、SAM工作流对人工提示的依赖、以及缺乏跨模态和任务的统一框架。
- Method: 1) 在多模态视网膜数据集上预训练CLIP图像编码器；2) 使用GroundingDINO自动生成空间边界框提示；3) 为每种成像模态添加独特的"模态签名"来增强文本提示；4) 用自动化提示引导SAM进行精确分割。
- Result: 在12个不同数据集和11个关键分割类别上的实验表明，CLAPS达到与专业专家模型相当的性能，并在大多数指标上超越现有基准，展现出广泛的泛化能力。
- Conclusion: CLAPS提供了一个完全自动化和统一的视网膜影像分割框架，能够有效处理多模态数据，解决了现有方法的局限性，展现出作为基础模型的强大泛化性能。


### [43] [AdsQA: Towards Advertisement Video Understanding](https://arxiv.org/abs/2509.08621)
*Xinwei Long,Kai Tian,Peng Xu,Guoli Jia,Jingxuan Li,Sa Yang,Yihua Shao,Kaiyan Zhang,Che Jiang,Hao Xu,Yang Liu,Jiaheng Ma,Bowen Zhou*

Main category: cs.CV

TL;DR: 这篇论文提出了AdsQA视频QA测试基准，使用广告视频来评估大语言模型的视觉理解能力，并提出ReAd-R模型在该数据集上达到最佳性能。

- Motivation: 利用广告视频中丰富的营销逻辑、说服策略和观众参与等特征，探索LLM在超越普通视觉内容理解方面的能力。
- Method: 构建AdsQA数据集（包含1,544个广告视频、10,962个剪辑），设计5种挑战性任务；提出ReAd-R模型，通过奖励驱动的优化进行反思和答案生成。
- Result: 在14个顶级LLM上测试，ReAd-R模型显著超过具备长链推理能力的强劲竞争对手，达到了state-of-the-art的性能。
- Conclusion: 广告视频是测试LLM视觉理解能力的有效平台，ReAd-R模型通过奖励驱动的反思机制显示了在复杂任务上的优势。


### [44] [UOPSL: Unpaired OCT Predilection Sites Learning for Fundus Image Diagnosis Augmentation](https://arxiv.org/abs/2509.08624)
*Zhihao Zhao,Yinzheng Zhao,Junjie Yang,Xiangtong Yao,Quanmin Liang,Daniel Zapp,Kai Huang,Nassir Navab,M. Ali Nasseri*

Main category: cs.CV

TL;DR: 提出UOPSL框架，利用OCT空间先验知识增强眼底图像疾病识别，解决多模态眼科图像配对数据稀缺问题

- Motivation: 多模态眼科图像诊断中，配对数据获取成本高昂，眼底摄影简单但OCT数据有限，传统方法难以捕捉细粒度空间信息
- Method: 通过对比学习在未配对的OCT和眼底图像上学习病灶偏好位点矩阵，在OCT潜在空间中捕获病灶定位模式，在仅使用眼底图像的分类任务中利用该矩阵辅助学习
- Result: 在9个不同数据集、28个关键类别上的实验表明，该框架优于现有基准方法
- Conclusion: 该研究成功利用OCT空间先验知识提升了基于眼底图像的疾病识别性能，为多模态医学图像分析提供了新思路


### [45] [LADB: Latent Aligned Diffusion Bridges for Semi-Supervised Domain Translation](https://arxiv.org/abs/2509.08628)
*Xuqin Wang,Tao Wu,Yanfeng Zhang,Lu Liu,Dong Wang,Mingwei Sun,Yongliang Wang,Niclas Zeller,Daniel Cremers*

Main category: cs.CV

TL;DR: LADB是一个半监督的样本到样本转换框架，利用部分配对数据在共享潜在空间中对齐源域和目标域分布，无需完全监督即可实现确定性域映射。

- Motivation: 扩散模型在数据稀缺领域面临挑战，需要大量重新训练或昂贵的配对数据。LADB旨在解决这些限制，在部分配对数据的情况下有效弥合域间差距。
- Method: 通过在共享潜在空间中对齐源域和目标域分布，将预训练的源域扩散模型与目标域潜在对齐扩散模型（LADM）集成，利用部分配对的潜在表示进行训练。
- Result: 实验结果显示在部分监督下的深度到图像转换任务中表现优异，并能扩展到多源转换和多目标转换任务，展示了处理多样化用例的灵活性。
- Conclusion: LADB为现实世界域转换提供了一个可扩展且通用的解决方案，特别适用于数据标注成本高或不完整的场景。


### [46] [Skeleton-based sign language recognition using a dual-stream spatio-temporal dynamic graph convolutional network](https://arxiv.org/abs/2509.08661)
*Liangjin Liu,Haoyang Zheng,Pei Zhou*

Main category: cs.CV

TL;DR: DSLNet提出双参考系双流架构，通过手腕中心坐标系进行形状分析，面部中心坐标系进行轨迹建模，解决了孤立手语识别中形态相似但语义不同的手势识别难题

- Motivation: 解决孤立手语识别中由于手势形态相似但语义不同导致的几何模糊问题，现有单参考系方法难以有效处理这种复杂性
- Method: 使用双参考系双流架构：手腕中心坐标系用于视图不变的形状分析，面部中心坐标系用于上下文感知的轨迹建模；采用拓扑感知图卷积处理形状，Finsler几何编码器处理轨迹，通过几何驱动的最优传输融合机制整合
- Result: 在WLASL-100、WLASL-300和LSA64数据集上分别达到93.70%、89.97%和99.79%的准确率，参数量显著少于竞争模型
- Conclusion: DSLNet通过解耦和建模手势形态与轨迹，在多个数据集上实现了最先进的性能，证明了双参考系方法在解决手语识别几何模糊问题上的有效性


### [47] [FractalPINN-Flow: A Fractal-Inspired Network for Unsupervised Optical Flow Estimation with Total Variation Regularization](https://arxiv.org/abs/2509.08670)
*Sara Behnamian,Rasoul Khaksarinezhad,Andreas Langer*

Main category: cs.CV

TL;DR: FractalPINN-Flow是一个无监督深度学习框架，通过分形变形网络直接从连续灰度帧学习光流估计，无需真实标注数据，在合成和基准数据集上表现出色。

- Motivation: 传统光流估计方法需要大量标注数据，而真实标注难以获取。本文旨在开发无需真实标注的无监督方法，利用分形几何和自相似性原理来捕捉精细细节和长距离运动模式。
- Method: 采用分形变形网络(FDN)架构，基于递归编码器-解码器结构，使用跳跃连接捕捉多尺度特征。训练目标基于变分公式，结合L1和L2数据保真度项确保亮度恒定性，以及总变差(TV)正则化项促进空间平滑性和连贯流场。
- Result: 在合成和基准数据集上的实验表明，FractalPINN-Flow能够产生准确、平滑且边缘保持的光流场。特别在高分辨率数据和标注有限场景下表现优异。
- Conclusion: 该无监督框架成功实现了从原始灰度帧直接学习光流估计，分形网络结构和变分正则化的结合有效提升了光流估计的质量和鲁棒性，为缺乏标注数据的实际应用提供了可行解决方案。


### [48] [Multi-Modal Robust Enhancement for Coastal Water Segmentation: A Systematic HSV-Guided Framework](https://arxiv.org/abs/2509.08694)
*Zhen Tian,Christos Anagnostopoulos,Qiyuan Wang,Zhiwei Gao*

Main category: cs.CV

TL;DR: 提出了Robust U-Net框架，通过HSV颜色空间监督和多模态约束改进海岸线水域分割，显著提升训练稳定性和分割质量

- Motivation: 传统RGB方法在复杂海岸线环境中存在训练不稳定和泛化能力差的问题，需要更鲁棒的水域分割方法
- Method: 集成HSV颜色监督、梯度海岸线优化、形态学后处理、海域清理和连通性控制五个协同组件
- Result: HSV监督影响最大(0.85分)，完整框架实现84%方差减少的训练稳定性提升，各项评估指标均有改善
- Conclusion: 该方法在保持计算效率的同时，显著提升了海岸线水域分割的鲁棒性和准确性


### [49] [Computational Imaging for Enhanced Computer Vision](https://arxiv.org/abs/2509.08712)
*Humera Shaikh,Kaur Jashanpreet*

Main category: cs.CV

TL;DR: 本文对计算成像技术及其对计算机视觉应用的变革性影响进行了全面综述，重点分析了各种CI技术如何解决传统成像在挑战性条件下的局限性，并探讨了CI与CV任务之间的协同关系。

- Motivation: 传统成像方法在低光照、运动模糊、高动态范围等挑战性条件下往往无法提供高质量的视觉数据，限制了先进计算机视觉系统的性能。计算成像技术通过增强图像采集和重建过程来解决这些限制。
- Method: 系统性地调研了多种计算成像技术，包括光场成像、高动态范围成像、去模糊、高速成像和眩光抑制等，并分析了这些技术与核心计算机视觉任务（如目标检测、深度估计、光流、人脸识别和关键点检测）之间的协同关系。
- Result: 研究发现计算成像技术能够显著提升计算机视觉系统在真实场景中的鲁棒性、准确性和效率，特别是在自动驾驶、监控、增强现实和机器人等应用领域。
- Conclusion: 计算成像与计算机视觉的深度融合为开发任务特定的自适应成像管道提供了重要机遇，同时也面临着新的挑战和未来研究方向，需要进一步探索两者的协同优化。


### [50] [BcQLM: Efficient Vision-Language Understanding with Distilled Q-Gated Cross-Modal Fusion](https://arxiv.org/abs/2509.08715)
*Sike Xiang,Shuang Chen,Amir Atapour-Abarghouei*

Main category: cs.CV

TL;DR: 轻量化多模态大语言模型BcQLM，仅1.2B参数但性能可比标准模型，适用于资源受限环境的视觉问答任务

- Motivation: 多模态大模型都布置面临资源约束挑战，需要在保持性能的同时提高能效和可持续性
- Method: 提出BreezeCLIP视觉-语言编码器，构建端到端的BcQLM框架，具有模块化和可扩展设计
- Result: 在多个数据集上验证了在减少计算成本的同时保持了与标准大模型相当的性能
- Conclusion: BcQLM为实际硬件约束下的多模态大模型部署提供了可行解决方案


### [51] [CrowdQuery: Density-Guided Query Module for Enhanced 2D and 3D Detection in Crowded Scenes](https://arxiv.org/abs/2509.08738)
*Marius Dähling,Sebastian Krebs,J. Marius Zöllner*

Main category: cs.CV

TL;DR: 提出CrowdQuery(CQ)方法，通过预测和嵌入目标密度图来增强基于transformer的检测器，在拥挤场景中显著提升2D和3D检测性能

- Motivation: 现有密度图定义通常依赖于头部位置或基于目标的空间统计，需要扩展到包含个体边界框维度信息，以改善拥挤场景中的检测效果
- Method: 提出CQ模块预测目标密度图并嵌入密度信息到解码器中，使用密度引导的查询来改进检测。构建CQ2D和CQ3D架构，适用于通用2D和3D transformer检测器
- Result: 在STCrowd数据集上相比基础模型有显著性能提升，优于大多数SOTA方法。在CrowdHuman数据集上集成到SOTA检测器中可进一步提升性能
- Conclusion: CQ是首个有效桥接2D和3D拥挤环境检测的方法，具有通用性和无需额外数据的优势，代码已开源


### [52] [ArgoTweak: Towards Self-Updating HD Maps through Structured Priors](https://arxiv.org/abs/2509.08764)
*Lena Wild,Rafael Valencia,Patric Jensfelt*

Main category: cs.CV

TL;DR: ArgoTweak是首个提供真实地图先验、当前地图和传感器数据三元组的公开数据集，解决了现有方法依赖合成先验导致的sim2real差距问题，通过双射映射框架实现细粒度地图元素级修改，显著提升了高精地图的自验证和自更新能力。

- Motivation: 现有公开数据集缺乏地图先验、当前地图和传感器数据的三元组，导致方法必须依赖合成先验，造成不一致性和显著的sim2real差距，需要真实的地图先验数据来支持可靠的高精地图自验证和自更新。
- Method: 采用双射映射框架，将大规模地图修改分解为地图元素级的细粒度原子变化，确保可解释性，同时保持未变化元素的高保真度。
- Result: 实验表明，在ArgoTweak上训练的模型相比合成先验显著减少了sim2real差距，广泛的消融实验进一步验证了结构化先验和详细变化标注的重要性。
- Conclusion: ArgoTweak通过建立可解释的先验辅助高精地图基准，推动了可扩展的自改进地图解决方案的发展，为可靠的地图先验集成提供了重要资源。


### [53] [Calibrating MLLM-as-a-judge via Multimodal Bayesian Prompt Ensembles](https://arxiv.org/abs/2509.08777)
*Eric Slyman,Mehrab Tanjim,Kushal Kafle,Stefan Lee*

Main category: cs.CV

TL;DR: 这篇论文提出了MMB方法，通过进行多模态提示集成和图像聚类来改善多模态大语言模型在文本到图像生成评估中的偏见和检定问题。

- Motivation: 多模态大语言模型在评估文本到图像生成系统时存在偏见、过于自信和在不同图像领域表现不一致的问题，而标准的提示集成方法在多模态任务中效果不佳。
- Method: 提出多模态混合贝叶斯提示集成（MMB）方法，结合贝叶斯提示集成和图像聚类技术，让评估模型能够根据每个样本的视觉特征动态分配提示权重。
- Result: 在HPSv2和MJBench两个TTI测试集上，MMB方法在成对偏好判断中提高了准确性，大大改善了检定效果，超迈现有基线方法。
- Conclusion: 研究结果高度识别了多模态特定策略对于评估模型检定的重要性，为可靠的大规模TTI评估指明了前进方向。


### [54] [An End-to-End Deep Learning Framework for Arsenicosis Diagnosis Using Mobile-Captured Skin Images](https://arxiv.org/abs/2509.08780)
*Asif Newaz,Asif Ur Rahman Adib,Rajit Sahil,Mashfique Mehzad*

Main category: cs.CV

TL;DR: 使用深度学习模型通过手机拍摄的皮肤图像进行碳中毒的自动化诊断，Swin Transformer模型达到最高准确率，并通过LIME和Grad-CAM提供可解释性

- Motivation: 碳中毒在南亚和东南亚是严重公共健康问题，早期皮肤表现容易误诊，特别是在农村地区缺乏皮肤科医生。需要自动化图像诊断方案支持早期发现和及时干预
- Method: 建立包含20个类别、11000张图像的数据集，比较多种深度学习模型（CNN和Transformer）的性能，集成LIME和Grad-CAM提供模型可解释性，并开发网页版诊断工具
- Result: Transformer模型显著超过CNN，Swin Transformer达到86%准确率。可解释性工具确认模型关注病变区域，提高了临床透明度。外部验证显示模型具有良好的泛化能力
- Conclusion: 该框架证明了深度学习在碳中毒无侵入、易访问和可解释诊断中的潜力。可作为农村和资源有限社区的实用诊断帮助工具，支持早期发现和及时干预


### [55] [Quantifying Accuracy of an Event-Based Star Tracker via Earth's Rotation](https://arxiv.org/abs/2509.08794)
*Dennis Melamed,Connor Hashemi,Scott McCloskey*

Main category: cs.CV

TL;DR: 事件相机在星迹踪定向中的精度验证，利用地球自转作为真实地面对比，达到18.47秒的RMS锐差精度

- Motivation: 解决事件相机在星迹踪定向中缺乏准确真实地面的问题，利用地球规律自转作为高精度对比标准
- Method: 将静止事件相机通过地面望远镜指向夜空，仅使用地球自转作为相机移动来源，处理事件流估算方位并与IERS测量的地球方位进行对比
- Result: 系统达到均方根锐差18.47秒，绝对锐差78.84秒的定向精度，结合事件相机的低计算量、高动态范围、低能耗和快更新率优势
- Conclusion: 事件相机在低成本、低延迟星迹踪定向中具有实用价值，开源了代码和数据以便后续研究


### [56] [Handling Multiple Hypotheses in Coarse-to-Fine Dense Image Matching](https://arxiv.org/abs/2509.08805)
*Matthieu Vilain,Rémi Giraud,Yannick Berthoumieu,Guillaume Bourmaud*

Main category: cs.CV

TL;DR: BEAMER提出了一种新的密集图像匹配方法，通过在每个尺度为每个源位置预测多个对应假设而非单一假设，显著提升了在深度不连续和强缩放情况下的匹配鲁棒性。

- Motivation: 现有密集匹配方法在每个尺度仅产生单一对应假设，在深度不连续或目标图像是源图像强缩放等挑战性场景中容易产生错误匹配。
- Method: 采用波束搜索策略在每个尺度传播多个假设，并将这些多假设集成到交叉注意力层中，构建BEAMER架构来学习和传播多假设。
- Result: BEAMER相比最先进方法显著更鲁棒，特别是在深度不连续和目标图像强缩放场景下表现优异。
- Conclusion: 预测和传播多个对应假设的策略能有效提升密集图像匹配的准确性和鲁棒性，BEAMER架构为此提供了有效实现。


### [57] [GeneVA: A Dataset of Human Annotations for Generative Text to Video Artifacts](https://arxiv.org/abs/2509.08818)
*Jenna Kang,Maria Silva,Patsorn Sangkloy,Kenneth Chen,Niall Williams,Qi Sun*

Main category: cs.CV

TL;DR: GeneVA是一个大规模视频生成伪影数据集，包含丰富的人工标注，专注于自然文本提示生成的视频中的时空伪影问题

- Motivation: 现有的概率生成模型从静态图像合成扩展到文本驱动的视频生成，但其固有的随机性会导致不可预测的伪影（如不可能的物理现象和时间不一致性），而现有数据集主要关注生成图像，缺乏针对视频时空复杂性的系统基准
- Method: 构建GeneVA大规模数据集，包含自然文本提示生成的视频，并配备丰富的人工标注，专门关注时空伪影问题
- Result: 创建了一个专门针对视频生成时空伪影的大规模标注数据集
- Conclusion: GeneVA数据集能够支持和协助关键应用，如基准测试模型性能和改进生成视频质量，填补了视频生成评估领域的空白


### [58] [RewardDance: Reward Scaling in Visual Generation](https://arxiv.org/abs/2509.08826)
*Jie Wu,Yu Gao,Zilyu Ye,Ming Li,Liang Li,Hanzhong Guo,Jie Liu,Zeyue Xue,Xiaoxia Hou,Wei Liu,Yan Zeng,Weilin Huang*

Main category: cs.CV

TL;DR: RewardDance是一个可扩展的视觉生成奖励建模框架，通过生成式奖励范式解决现有方法的局限性，支持模型规模扩展到260亿参数，并有效解决了奖励黑客问题。

- Motivation: 现有奖励模型在视觉生成中存在架构限制和模态约束，Bradley-Terry损失与视觉语言模型的下一个token预测机制不匹配，且RLHF优化过程存在奖励黑客问题，阻碍了有效扩展。
- Method: 提出RewardDance框架，将奖励分数重新定义为模型预测"yes"token的概率，表示生成图像在特定标准下优于参考图像，使奖励目标与VLM架构内在对齐。
- Result: RewardDance在文本到图像、文本到视频和图像到视频生成任务中显著超越最先进方法，大规模奖励模型在RL微调期间保持高奖励方差，证明其抗黑客攻击能力。
- Conclusion: RewardDance通过生成式奖励范式成功解决了奖励模型扩展的挑战，实现了模型规模和上下文规模的扩展，并有效缓解了模式崩溃问题。


### [59] [SAFT: Shape and Appearance of Fabrics from Template via Differentiable Physical Simulations from Monocular Video](https://arxiv.org/abs/2509.08828)
*David Stotko,Reinhard Klein*

Main category: cs.CV

TL;DR: 提出了一种结合3D几何重建和外观估计的新方法，仅使用单目RGB视频就能对织物进行高质量3D动态重建和物理渲染。

- Motivation: 解决单目视频中3D动态场景重建的深度模糊问题，同时实现几何重建和外观估计，以获得逼真的织物变形和渲染效果。
- Method: 采用物理模拟和可微分渲染技术，引入了两个新的正则化项来处理单目视频中的深度模糊问题，提高重建的合理性。
- Result: 与最新方法相比，3D重建误差减少了2.64倍，每个场景平均运行时间为30分钟，能够从单目视频中恢复出清晰的细节。
- Conclusion: 该方法在单目RGB视频的3D织物重建和外观估计方面取得了显著改进，为动态场景重建提供了有效的解决方案。
## cs.GR

### [60] [X-Part: high fidelity and structure coherent shape decomposition](https://arxiv.org/abs/2509.08643)
*Xinhao Yan,Jiachen Xu,Yang Li,Changfeng Ma,Yunhan Yang,Chunshi Wang,Zibo Zhao,Zeqiang Lai,Yunfei Zhao,Zhuo Chen,Chunchao Guo*

Main category: cs.GR

TL;DR: X-Part是一个可控的生成模型，通过边界框提示和语义特征注入实现3D对象的有意义部件分解，达到最先进的部件级形状生成性能。

- Motivation: 现有的基于部件的生成方法缺乏足够的可控性，且语义分解效果不佳，无法满足网格重拓扑、UV映射和3D打印等下游应用需求。
- Method: 利用边界框作为部件生成提示，注入点级语义特征实现有意义分解，并设计了可编辑的交互式部件生成流程。
- Result: 实验结果表明X-Part在部件级形状生成方面达到了最先进的性能，能够生成具有高几何保真度的语义有意义且结构连贯的部件。
- Conclusion: 这项工作为创建生产就绪、可编辑且结构合理的3D资产建立了新范式，代码将公开发布以供研究使用。
## cs.SD

### [61] [PianoVAM: A Multimodal Piano Performance Dataset](https://arxiv.org/abs/2509.08800)
*Yonghyun Kim,Junhyung Park,Joonhyung Bae,Kirak Kim,Taegyun Kwon,Alexander Lerch,Juhan Nam*

Main category: cs.SD

TL;DR: PianoVAM是一个包含视频、音频、MIDI、手部关键点、指法标注和丰富元数据的钢琴演奏数据集，基于Disklavier钢琴采集业余钢琴家的日常练习数据，支持多模态音乐信息检索研究。

- Motivation: 音乐表演的多模态特性促使MIR社区对音频以外数据的需求增加，需要更全面的钢琴演奏数据集来支持多模态研究。
- Method: 使用Disklavier钢琴采集业余钢琴家的日常练习数据，包含同步的音频、MIDI和俯视视角视频；使用预训练手部姿态估计模型提取手部关键点，采用半自动指法标注算法进行指法标注。
- Result: 构建了PianoVAM数据集，包含多模态对齐数据；提出了基于视频手部关键点的指法标注方法；提供了音频和音视频钢琴转录的基准测试结果。
- Conclusion: PianoVAM数据集为多模态音乐信息检索研究提供了宝贵资源，支持钢琴转录等应用，并展示了在多模态数据采集和对齐方面的挑战与解决方案。
## cs.LG

### [62] [Revisiting Deepfake Detection: Chronological Continual Learning and the Limits of Generalization](https://arxiv.org/abs/2509.07993)
*Federico Fontana,Anxhelo Diko,Romeo Lanzino,Marco Raoul Marini,Bachir Kaddar,Gian Luca Foresti,Luigi Cinque*

Main category: cs.LG

TL;DR: 将深度伪造检测重新定义为持续学习问题，提出高效框架来增量适应新兴伪造技术，同时保留历史知识，训练速度比完全重训练快155倍，但对未来生成器的泛化能力接近随机水平。

- Motivation: 深度伪造生成技术快速发展，非持续学习方法需要频繁且昂贵的重训练，现有方法依赖不真实的模拟序列，无法有效应对真实世界的时间演化挑战。
- Method: 提出持续学习框架，模拟7年间深度伪造技术的真实时间演化，基于轻量级视觉骨干网络实现实时检测性能，并引入两个新评估指标C-AUC和FWT-AUC。
- Result: 实现了高效适应（比完全重训练快155倍）和稳健的历史知识保留，但对未来生成器的泛化能力接近随机水平（FWT-AUC≈0.5），提出了非通用深度伪造分布假说。
- Conclusion: 当前方法能够有效适应新兴伪造技术并保留历史知识，但无法很好泛化到未来未见过的生成器，这揭示了深度伪造检测的根本挑战，需要新的研究方向。


### [63] [Adapting Vision-Language Models for Neutrino Event Classification in High-Energy Physics](https://arxiv.org/abs/2509.08461)
*Dikshant Sagar,Kaiwen Yu,Alejandro Yankelevich,Jianming Bian,Pierre Baldi*

Main category: cs.LG

TL;DR: 视觉语言模型在粒子物理实验中识别中微子相互作用的性能优于传统卷积神经网络，同时提供更好的可解释性和多模态推理能力

- Motivation: 探索视觉语言模型在处理高能物理实验中的像素化探测器数据方面的应用潜力，特别是在中微子相互作用识别任务中
- Method: 使用经过微调的LLaMa 3.2视觉语言模型，与NOvA和DUNE实验中使用的先进卷积神经网络架构进行基准测试对比
- Result: 视觉语言模型在分类性能上超越了卷积神经网络，同时提供了更好的可解释性和整合辅助文本或语义信息的灵活性
- Conclusion: 视觉语言模型因其高性能、可解释性和泛化能力，有潜力成为物理事件分类的通用骨干网络，为实验性中微子物理中的多模态推理开辟了新途径
## cs.RO

### [64] [Quadrotor Navigation using Reinforcement Learning with Privileged Information](https://arxiv.org/abs/2509.08177)
*Jonathan Lee,Abhishek Rathod,Kshitij Goel,John Stecklein,Wennie Tabib*

Main category: cs.RO

TL;DR: 基于强化学习的四旋翼小型无人机导航方法，利用可微模拟、新损失函数和特权信息解决大障碍物导航问题，在模拟和实际环境中都取得了超过基线方法的性能。

- Motivation: 现有的学习基于导航方法在窄障碍物场景中表现良好，但当目标位置被大型墙壁或地形阻挡时表现就会受限。需要一种能够有效导航绅过大障碍物的方法。
- Method: 使用可微模拟、新的损失函数和特权信息（时间到达地图），通过航向对准损失来指导机器人绅过大障碍物。
- Result: 在照片实体模拟环境中达到86%的成功率，超过基线方法34%。在室外复杂环境中进行了20次飞行，覆盖589米距离无碰撞，最高速度达4米/秒。
- Conclusion: 该方法能够有效解决四旋翼小型无人机在大障碍物环境中的导航问题，在模拟和实际部署中都表现出良好的性能和稳定性。


### [65] [Foundation Models for Autonomous Driving Perception: A Survey Through Core Capabilities](https://arxiv.org/abs/2509.08302)
*Rajendramayavan Sathyam,Yueqi Li*

Main category: cs.RO

TL;DR: 这篇调查性论文系统论了基础模型如何改革自动驾驶感知领域，通过四大关键能力架构提升模型的通用性、空间理解、多感知稳健性和时间推理能力

- Motivation: 解决传统专门化深度学习模型在自动驾驶感知中的局限性，包括沿射性、扩展性和分布偏移稳健性等挑战
- Method: 提出了一种新的分类法，以四大关键能力为核心：通用知识、空间理解、多感知稳健性和时间推理。超越传统方法本位的调查，重点关注概念设计原则
- Result: 对各个关键能力进行了系统性的评估和综述，为基础模型在自动驾驶感知中的发展提供了能力驱动的指南
- Conclusion: 基础模型将引领自动驾驶感知的革命，但仍面临实时集成、计算需求、模型可靠性等挑战，需要进一步研究确保其安全有效部署


### [66] [Good Deep Features to Track: Self-Supervised Feature Extraction and Tracking in Visual Odometry](https://arxiv.org/abs/2509.08333)
*Sai Puneeth Reddy Gottam,Haoming Zhang,Eivydas Keras*

Main category: cs.RO

TL;DR: 通过自监督学习和任务特定反馈增强深度特征提取与跟踪，提高大规模外部环境下视觉定位的稳定性和通用性

- Motivation: 解决大规模、外部和长期视觉定位中因光照变化、动态场景、低纹理区域导致的特征提取和跟踪性能下降问题，改善学习方法在分布外数据上的通用性
- Method: 采用自监督学习策略，通过任务特定反馈机制增强深度特征提取和跟踪能力
- Result: 提升了特征的稳定性和信息密度，在具有挑战性的环境中改善了方法的通用性和可靠性
- Conclusion: 自监督学习策略能够有效地提升深度特征提取和跟踪的性能，为具有挑战性的大规模外部定位场景提供更稳定和可靠的解决方案


### [67] [TANGO: Traversability-Aware Navigation with Local Metric Control for Topological Goals](https://arxiv.org/abs/2509.08699)
*Stefan Podgorski,Sourav Garg,Mehdi Hosseinzadeh,Lachlan Mares,Feras Dayoub,Ian Reid*

Main category: cs.RO

TL;DR: 一种新的RGB单目标导航管道，通过对象级顶层拓扑策略和局部轨迹控制，实现了无需三维地图或预训练控制器的零样本导航。

- Motivation: 解决传统视觉导航依赖全局一致三维地图或学习控制器的问题，这些方法计算费用高且在多样环境中普遍性差。
- Method: 集成全局拓扑路径规划与局部轨迹控制，使用单目深度和可通行性估计持续预测局部轨迹，并包含自动切换机制在必要时调用基准控制器。
- Result: 在模拟和真实环境中验证了方法的有效性、稳健性和可部署性，性能超过现有最优方法。
- Conclusion: 该方法为开收集环境中的视觉导航提供了更适应性强、效果更好的解决方案，且不需领域特定微调。


### [68] [SocialNav-SUB: Benchmarking VLMs for Scene Understanding in Social Robot Navigation](https://arxiv.org/abs/2509.08757)
*Michael J. Munje,Chen Tang,Shuijing Liu,Zichao Hu,Yifeng Zhu,Jiaxun Cui,Garrett Warnell,Joydeep Biswas,Peter Stone*

Main category: cs.RO

TL;DR: 这篇论文提出了SocialNav-SUB标准化测试框架，用于评估视觉-语言模型在社交机器人导航场景中的理解能力，发现当前最佳模型仍落后于规则基础方法和人类水平。

- Motivation: 社交机器人导航需要复杂场景理解能力，而当前视觉-语言模型的社交场景理解能力缺乏系统性评估。
- Method: 构建SocialNav-SUB数据集和测试框架，通过视觉问答任务评估VLMs在空间、时空和社交推理方面的表现，与人类和规则基准进行对比。
- Result: 当前最佳VLM虽然达到了一定的准确率，但仍落后于简单的规则方法和人类水平，显示出在社交场景理解方面的关键缺口。
- Conclusion: 该标准化测试框架为社交机器人导航基础模型的研究奠定了基础，提供了一个统一的评估框架来探索VLMs如何满足实际社交导航需求。
## eess.IV

### [69] [STROKEVISION-BENCH: A Multimodal Video And 2D Pose Benchmark For Tracking Stroke Recovery](https://arxiv.org/abs/2509.07994)
*David Robinson,Animesh Gupta,Rizwan Quershi,Qiushi Fu,Mubarak Shah*

Main category: eess.IV

TL;DR: StrokeVision-Bench是首个专门针对中风患者执行临床结构化方块转移任务的数据集，包含1000个标注视频，旨在通过计算机视觉实现客观、量化的上肢功能评估。

- Motivation: 当前中风后上肢功能评估主要依赖治疗师主观观察和粗糙评分系统，缺乏敏感性来检测细微运动改善。现有数据集主要关注日常生活活动，缺乏临床结构化评估任务，且混合健康和中风人群，限制了临床实用性。
- Method: 收集1000个标注视频，分为四个临床相关动作类别，每个样本提供原始视频帧和2D骨骼关键点两种模态。对多种先进的视频动作识别和基于骨骼的动作分类方法进行基准测试。
- Result: 建立了该领域的性能基准，为未来自动化中风康复评估研究提供了基础数据集和评估框架。
- Conclusion: StrokeVision-Bench填补了临床结构化评估任务数据集的空白，为开发客观、量化的中风康复评估工具提供了重要资源，有助于推动个性化康复规划的发展。


### [70] [Expert-Guided Explainable Few-Shot Learning for Medical Image Diagnosis](https://arxiv.org/abs/2509.08007)
*Ifrat Ikhtear Uddin,Longwei Wang,KC Santosh*

Main category: eess.IV

TL;DR: 提出专家引导的可解释少样本学习框架，通过整合放射科医生提供的ROI区域和Dice相似度解释损失，在提升分类性能的同时增强模型可解释性，在BraTS和VinDr-CXR数据集上取得显著准确率提升

- Motivation: 解决医学图像分析中专家标注数据有限的问题，同时提升模型泛化能力和临床可信度，弥合性能与可解释性之间的差距
- Method: 结合Grad-CAM空间注意力监督，引入基于Dice相似度的解释损失，与原型网络目标联合优化，使模型关注临床相关区域
- Result: BraTS准确率从77.09%提升至83.61%，VinDr-CXR从54.33%提升至73.29%，Grad-CAM可视化证实注意力与诊断区域对齐
- Conclusion: 专家引导的注意力监督能有效提升少样本医学图像诊断的性能和可解释性，增强临床可信度


### [71] [Validation of a CT-brain analysis tool for measuring global cortical atrophy in older patient cohorts](https://arxiv.org/abs/2509.08012)
*Sukhdeep Bal,Emma Colbourne,Jasmine Gan,Ludovica Griffanti,Taylor Hanayik,Nele Demeyere,Jim Davies,Sarah T Pendlebury,Mark Jenkinson*

Main category: eess.IV

TL;DR: 这是一个基于深度学习的自动化工具，用于测量老年患者脑CT扫描中的全脑肝缩（GCA）评分，验证了其与人工评分的一致性和与年龄、认知功能的关联性。

- Motivation: 目前脑肝缩的量化需要耗时的视觉评分标准，需要自动化的脑图像分析工具来提高效率和标准化。
- Method: 使用深度学习技术开发自动GCA评分工具，在864份CT脑扫描图像上进行训练和测试，与两位经过训练的人工评分员进行比较验证。
- Result: 自动化工具与人工评分员的一致性较高（MAE=3.2，Kappa=0.45），较两位人工评分员之间的一致性更好，并且GCA评分与年龄和认知功能显著相关。
- Conclusion: 该深度学习工具能够准确地自动测量全脑肝缩评分，为大规模健康数据研究提供标准化的定量指标，有望成为未来床边临床应用的原型工具。


### [72] [CardioComposer: Flexible and Compositional Anatomical Structure Generation with Disentangled Geometric Guidance](https://arxiv.org/abs/2509.08015)
*Karim Kadry,Shoaib Goraya,Ajay Manicka,Abdalla Abdelwahed,Farhad Nezami,Elazer Edelman*

Main category: eess.IV

TL;DR: 提出了一种基于可解释椭球体原语的可编程组合框架，用于引导无条件扩散模型生成可控且解剖学真实的人体解剖结构

- Motivation: 当前3D解剖学生成模型在可控性和解剖真实性之间存在权衡，需要一种能够同时保持解剖真实性和提供精确控制的方法来研究结构-功能关系和医疗设备设计
- Method: 使用嵌入3D空间的可解释椭球体原语来引导无条件扩散模型，通过在多组织分割图中选择特定组织并应用几何矩损失来指导反向扩散过程
- Result: 该框架支持在推理过程中独立控制大小、形状、位置以及多组件约束的组合
- Conclusion: 该方法提供了一种可编程和组合式的解剖学生成控制框架，能够在保持解剖真实性的同时实现精确的可控性


### [73] [Enhancing Privacy Preservation and Reducing Analysis Time with Federated Transfer Learning in Digital Twins-based Computed Tomography Scan Analysis](https://arxiv.org/abs/2509.08018)
*Avais Jan,Qasim Zia,Murray Patterson*

Main category: eess.IV

TL;DR: 本文提出了一种基于数字孪生的联邦迁移学习(FTL)框架，用于解决CT扫描分析中的数据隐私、计算资源有限和数据异构性问题，在非IID数据环境下表现优于传统联邦学习和聚类联邦学习方法。

- Motivation: 解决医疗CT扫描分析中的数据隐私保护、计算资源限制和数据异构性挑战，同时实现实时协作和患者身份保护。
- Method: 采用联邦迁移学习(FTL)框架，结合预训练模型和节点间知识迁移，在数字孪生使能的CT扫描仪和云服务器之间进行实时协作。
- Result: FTL方法在收敛时间、模型准确率、精确率、召回率和F1分数等指标上均优于传统FL和CFL方法，特别在非IID数据环境下表现优异。
- Conclusion: FTL技术为数字孪生基础的CT扫描分析提供了可靠、高效且安全的解决方案，有望推动精准医疗和智能医疗系统的发展，同时保护患者隐私。


### [74] [Physics-Guided Rectified Flow for Low-light RAW Image Enhancement](https://arxiv.org/abs/2509.08330)
*Juntai Zeng*

Main category: eess.IV

TL;DR: 本文提出了一种物理导向的正向流框架PGRF，通过组合加性和乘性噪声模型以及像素级噪声模拟，在低光RAW图像增强任务中取得显著改善。

- Motivation: 现有的深度学习方法依赖合成数据集，但传统的噪声模型往往只考虑加性噪声忽略乘性成分，且采用全局校准而忽视像素级制造差异，导致无法准确重现真实传感噪声。
- Method: 从低照明条件下的物理噪声生成机制推导噪声模型，提出新的复合模型组合加性和乘性噪声。采用物理基础的每像素噪声模拟和校准方案，并与正向流生成框架结合构建PGRF框架，利用物理指导导向清洁图像生成。
- Result: 建立了LLID数据集，实验结果表明所提框架在低光RAW图像增强任务中取得显著改善。
- Conclusion: 本文提出的PGRF框架通过组合物理噪声模型和正向流生成技术，有效解决了低光条件下RAW图像增强的挑战，为该领域提供了新的解决方案。


### [75] [CNN-ViT Hybrid for Pneumonia Detection: Theory and Empiric on Limited Data without Pretraining](https://arxiv.org/abs/2509.08586)
*Prashant Singh Basnet,Roshan Chitrakar*

Main category: eess.IV

TL;DR: 混合CNN和ViT模型在小规模数据集下表现优异，在类别不平衡情况下保持稳定性，训练时间与ViT相当

- Motivation: 探索在限制规模训练数据集上混合CNN和ViT模型的结构优势，并考察类别不平衡对模型性能的影响
- Method: 从头开始训练混合CNN-ViT模型，在不同数据比例和平衡/不平衡数据集上进行实验对比
- Result: 混合模型在50%平衡数据上达到最高回入0.9443，F1分数稳定在0.85左右，在不平衡数据集上超过单独CNN和ViT，训练时间与ViT相当
- Conclusion: 混合模型能够结合CNN和ViT的优势，在小规模数据集和类别不平衡情况下保持高性能和稳定性，具有实际应用价值


### [76] [RoentMod: A Synthetic Chest X-Ray Modification Model to Identify and Correct Image Interpretation Model Shortcuts](https://arxiv.org/abs/2509.08640)
*Lauren H. Cooke,Matthias Jung,Jan M. Brendel,Nora M. Kerkovits,Borek Foldyna,Michael T. Lu,Vineet K. Raghu*

Main category: eess.IV

TL;DR: RoentMod是一个反事实图像编辑框架，通过生成具有指定病理特征的逼真胸部X光片，来检测和纠正医学AI中的捷径学习问题，提高模型鲁棒性。

- Motivation: 胸部X光片是医学中最常见的检查之一，深度学习模型在解读方面表现良好但容易受到捷径学习的影响，即模型依赖虚假相关性而非临床相关特征进行决策。
- Method: RoentMod结合开源医学图像生成器(RoentGen)和图像到图像修改模型，无需重新训练即可生成具有用户指定合成病理的解剖学逼真CXRs，同时保留原始扫描的无关系解剖特征。
- Result: 在放射科医生评估中，93%的RoentMod生成图像看起来逼真，89-99%正确整合了指定发现。使用RoentMod训练后，模型在内部验证中AUC提高3-19%，外部测试中5/6病理提高1-11%。
- Conclusion: RoentMod是检测和纠正医学AI中捷径学习的广泛应用工具，通过受控反事实干预增强了CXR解读模型的鲁棒性和可解释性，为医学影像基础模型改进提供了通用策略。
