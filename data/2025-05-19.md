[[toc]]

## cs.CV

### [1] [Robust Emotion Recognition via Bi-Level Self-Supervised Continual Learning](https://arxiv.org/abs/2505.10575)
*Adnan Ahmad,Bahareh Nakisa,Mohammad Naim Rastgoo*

Main category: cs.CV

TL;DR: 论文提出了一种基于动态记忆缓冲区的双层次自监督持续学习框架SSOCL，用于解决生理信号（如EEG）情感识别中的跨主体差异和噪声标签问题。

- Motivation: 生理信号情感识别面临跨主体差异和噪声标签的挑战，现有方法难以处理连续无标记数据流。
- Method: 提出SSOCL框架，通过动态缓冲区迭代优化和伪标签分配，结合快速适应模块和聚类映射模块，处理连续无标记数据流。
- Result: 在两个主流EEG任务上的实验验证表明，SSOCL能适应连续数据流并在跨主体泛化上优于现有方法。
- Conclusion: SSOCL框架有效解决了生理信号情感识别中的实际问题，具有广泛的应用潜力。


### [2] [Bias and Generalizability of Foundation Models across Datasets in Breast Mammography](https://arxiv.org/abs/2505.10579)
*Germani Elodie,Selin Türk Ilayda,Zeineddine Fatima,Mourad Charbel,Albarqouni Shadi*

Main category: cs.CV

TL;DR: 研究探讨了基础模型（FMs）在乳腺X光分类中的公平性和偏见问题，发现数据集聚合和领域适应策略虽能提升性能，但无法完全消除偏见，而公平性技术能更稳定地实现公平性能。

- Motivation: 尽管计算机辅助诊断工具在乳腺癌筛查中有所发展，但其临床采用仍受数据变异性和固有偏见的限制。基础模型（FMs）虽表现出强大的泛化能力，但可能因虚假相关性而性能下降。
- Method: 利用来自不同来源的大规模数据集（包括代表性不足的地区数据和内部数据集），研究FMs的公平性和偏见，并测试了模态特定预训练、数据集聚合、领域适应和公平性技术等方法。
- Result: 模态特定预训练提升性能，但单数据集训练的模型泛化能力差；数据集聚合改善整体性能但未能完全消除偏见；领域适应策略减少偏见但牺牲性能；公平性技术实现更稳定和公平的性能。
- Conclusion: 研究强调在基于FMs的模型中纳入严格的公平性评估和缓解策略的必要性，以促进包容和可泛化的人工智能。


### [3] [Relative Drawing Identification Complexity is Invariant to Modality in Vision-Language Models](https://arxiv.org/abs/2505.10583)
*Diogo Freitas,Brigt Håvardstun,Cèsar Ferri,Darío Garigliotti,Jan Arne Telle,José Hernández-Orallo*

Main category: cs.CV

TL;DR: 论文探讨了多模态大语言模型中视觉与文本模态的潜在空间一致性，通过机器教学理论验证了图像和坐标表示的教学复杂度差异。

- Motivation: 研究多模态模型中视觉与文本模态是否共享潜在空间，验证其一致性假设。
- Method: 使用机器教学理论，对比Quick, Draw!数据集中图像（位图）和坐标（TikZ格式）两种表示的教学复杂度。
- Result: 图像表示通常需要更少教学片段且准确率更高，但两种模态的教学复杂度排序相似，表明概念简洁性可能超越模态。
- Conclusion: 概念的简洁性可能是跨模态的固有属性，支持多模态模型潜在空间的一致性假设。


### [4] [Aquarius: A Family of Industry-Level Video Generation Models for Marketing Scenarios](https://arxiv.org/abs/2505.10584)
*Huafeng Shi,Jianzhong Liang,Rongchang Xie,Xian Wu,Cheng Chen,Chang Liu*

Main category: cs.CV

TL;DR: Aquarius是一套面向营销场景的工业级视频生成模型家族，支持大规模集群和百亿参数模型，通过高效工程架构和算法创新实现高性能视频合成。

- Motivation: 旨在揭秘工业级视频生成系统的设计细节，推动生成视频领域的发展。
- Method: 包括分布式图与视频数据处理管道、不同规模的模型架构、高性能训练基础设施、多xPU并行推理加速以及多种营销场景应用。
- Result: Aquarius在高保真、多比例、长时长视频合成中表现卓越，训练基础设施实现36% MFU，推理速度提升2.35倍。
- Conclusion: Aquarius框架为工业级视频生成提供了高效解决方案，未来将扩展更多下游应用和评估指标。


### [5] [Efficient Malicious UAV Detection Using Autoencoder-TSMamba Integration](https://arxiv.org/abs/2505.10585)
*Azim Akhtarshenas,Ramin Toosi,David López-Pérez,Tohid Alizadeh,Alireza Hosseini*

Main category: cs.CV

TL;DR: 本文提出了一种基于4层TSMamba架构的AE分类器系统，用于检测恶意无人机，显著提高了分类准确率和计算效率。

- Motivation: 恶意无人机对下一代网络构成严重威胁，如未经授权的监视和数据盗窃，因此需要高效检测方法。
- Method: 采用4层TSMamba架构的AE生成残差值，再通过ResNet分类器处理，降低复杂度并提高准确性。
- Result: 实验显示，在二分类和多分类场景中，召回率高达99.8%，优于基准的96.7%，同时降低了计算复杂度。
- Conclusion: 该方法具有鲁棒性和可扩展性，适用于大规模部署，为恶意无人机检测提供了有效解决方案。


### [6] [Super-Resolution Generative Adversarial Networks based Video Enhancement](https://arxiv.org/abs/2505.10589)
*Kağan ÇETİN*

Main category: cs.CV

TL;DR: 该研究通过扩展单图像超分辨率SRGAN结构，提出了一种改进的视频超分辨率方法，引入3D非局部块以捕捉时空关系，并开发了实验训练管道。

- Motivation: SRGAN在单图像增强中表现良好，但未考虑视频处理中的时间连续性，因此需要改进以适应视频数据。
- Method: 提出了一种结合3D非局部块的框架，采用基于补丁的学习和高级数据退化技术，训练模型以捕捉时空关系。
- Result: 实验表明，该方法在时间一致性、纹理清晰度和减少视觉伪影方面优于传统单图像方法。
- Conclusion: 该研究为视频增强任务提供了实用的学习解决方案，适用于流媒体、游戏和数字修复等领域。


### [7] [ARFC-WAHNet: Adaptive Receptive Field Convolution and Wavelet-Attentive Hierarchical Network for Infrared Small Target Detection](https://arxiv.org/abs/2505.10595)
*Xingye Cui,Junhai Luo,Jiakun Deng,Kexuan Li,Xiangyu Qiu,Zhenming Peng*

Main category: cs.CV

TL;DR: 提出了一种名为ARFC-WAHNet的网络，结合自适应感受野卷积和小波注意力层次结构，用于红外小目标检测，显著提升了检测精度和鲁棒性。

- Motivation: 红外图像中目标纹理和结构信息有限，传统卷积核和池化操作导致特征丢失和信息利用不足，限制了检测性能。
- Method: 设计了多感受野特征交互卷积模块（MRFFIConv）、小波频率增强下采样模块（WFED）、高低特征融合模块（HLFF）和全局中值增强注意力模块（GMEA）。
- Result: 在SIRST、NUDT-SIRST和IRSTD-1k数据集上表现优于现有方法，尤其在复杂背景下。
- Conclusion: ARFC-WAHNet通过自适应特征提取和多模块协同，显著提升了红外小目标检测的性能。


### [8] [SRMamba: Mamba for Super-Resolution of LiDAR Point Clouds](https://arxiv.org/abs/2505.10601)
*Chuang Chen,Wenyi Ge*

Main category: cs.CV

TL;DR: SRMamba是一种基于Hough Voting和Hole Compensation的LiDAR点云超分辨率方法，适用于稀疏场景，通过多方向扫描和视觉状态空间模型恢复3D结构。

- Motivation: 解决LiDAR点云稀疏性和不规则结构带来的超分辨率挑战，特别是在新视角下的点云上采样问题。
- Method: 采用Hough Voting和Hole Compensation消除水平线性空洞，结合视觉状态空间模型和多方向扫描机制恢复3D结构，使用非对称U-Net适应不同光束LiDAR。
- Result: 在SemanticKITTI和nuScenes数据集上，SRMamba在定性和定量评估中显著优于其他算法。
- Conclusion: SRMamba有效解决了稀疏LiDAR点云的超分辨率问题，尤其在新视角下表现优异。


### [9] [MIRAGE: A Multi-modal Benchmark for Spatial Perception, Reasoning, and Intelligence](https://arxiv.org/abs/2505.10604)
*Chonghan Liu,Haoran Wang,Felix Henry,Pu Miao,Yajie Zhang,Yu Zhao,Peiran Wu*

Main category: cs.CV

TL;DR: MIRAGE是一个多模态基准测试，用于评估模型在计数、空间关系推理及其组合任务中的能力，揭示了现有模型的局限性。

- Motivation: 现有计算机视觉模型在物体属性识别和空间关系推理方面存在显著不足，影响了动态推理能力。
- Method: 提出MIRAGE基准测试，通过多样复杂场景评估模型的计数、关系推理及其组合能力。
- Result: MIRAGE揭示了当前先进模型在细粒度识别和推理方面的关键局限性。
- Conclusion: MIRAGE为未来时空推理研究提供了改进方向。


### [10] [MMLongBench: Benchmarking Long-Context Vision-Language Models Effectively and Thoroughly](https://arxiv.org/abs/2505.10610)
*Zhaowei Wang,Wenhao Yu,Xiyu Ren,Jipeng Zhang,Yu Zhao,Rohit Saxena,Liang Cheng,Ginny Wong,Simon See,Pasquale Minervini,Yangqiu Song,Mark Steedman*

Main category: cs.CV

TL;DR: MMLongBench是首个针对长上下文视觉语言模型（LCVLMs）的多样化基准测试，涵盖13,331个示例和五类任务，评估模型在不同输入长度下的表现。

- Motivation: 随着长上下文视觉语言模型的发展，缺乏全面评估其能力的基准测试，MMLongBench填补了这一空白。
- Method: MMLongBench包含五类任务和多种图像类型，通过跨模态标记化方案提供标准化输入长度（8K-128K tokens），并评估46个开源和闭源模型。
- Result: 结果显示：单任务表现不能代表整体能力；现有模型在长上下文任务中仍有挑战；推理能力强的模型表现更好。
- Conclusion: MMLongBench为诊断和推进下一代LCVLMs提供了基础。


### [11] [Mitigate Language Priors in Large Vision-Language Models by Cross-Images Contrastive Decoding](https://arxiv.org/abs/2505.10634)
*Jianfei Zhao,Feng Zhang,Xin Sun,Chong Feng*

Main category: cs.CV

TL;DR: 论文提出了一种名为CICD的无训练方法，通过跨图像对比解码来减少大型视觉语言模型中的语言先验，从而缓解幻觉问题。

- Motivation: 大型视觉语言模型中的语言先验是导致幻觉的主要原因之一，这些先验源于预训练语言模型的知识，且独立于视觉输入。
- Method: 提出CICD方法，通过识别关键和有害的先验，并利用对比解码消除有害先验，同时保持文本流畅性和视觉信息。
- Result: 在四个基准测试和六个LVLM上验证了CICD的有效性，尤其在图像描述任务中表现突出。
- Conclusion: CICD是一种简单有效的方法，能够显著减少语言先验，同时保持模型的性能。


### [12] [Advancing Multiple Instance Learning with Continual Learning for Whole Slide Imaging](https://arxiv.org/abs/2505.10649)
*Xianrui Li,Yufei Cui,Jun Li,Antoni B. Chan*

Main category: cs.CV

TL;DR: 论文提出两种方法（AKD和PMP）改进MIL模型的持续学习能力，解决注意力层遗忘问题，提升准确性和内存效率。

- Motivation: 传统MIL模型在持续学习中适应性差，无法有效整合新数据，且注意力层遗忘严重。
- Method: 提出注意力知识蒸馏（AKD）和伪袋记忆池（PMP），分别解决注意力层遗忘和内存占用问题。
- Result: 实验表明，该方法在多样WSI数据集上显著提升准确性和内存效率，优于现有CL方法。
- Conclusion: 为大规模弱标注临床数据集的持续学习奠定基础，推动适应性更强的诊断模型发展。


### [13] [CLIP Embeddings for AI-Generated Image Detection: A Few-Shot Study with Lightweight Classifier](https://arxiv.org/abs/2505.10664)
*Ziyang Ou*

Main category: cs.CV

TL;DR: 研究探讨了CLIP嵌入是否包含AI生成图像的信息，提出了一种轻量级分类方法，在CIFAKE基准上达到95%准确率，但对某些图像类型（如广角照片和油画）分类仍有挑战。

- Motivation: 验证AI生成图像的真实性日益重要，但现有视觉语言模型（如CLIP）在预训练中缺乏相关标签，其分类能力未被充分探索。
- Method: 使用冻结的CLIP模型提取视觉嵌入，通过轻量级网络和微调最终分类器进行分类。
- Result: 在CIFAKE基准上达到95%准确率，少量数据适应后为85%。某些图像类型（如广角照片和油画）分类困难。
- Conclusion: CLIP嵌入可用于AI生成图像分类，但某些类型图像仍具挑战性，需进一步研究。


### [14] [GA3CE: Unconstrained 3D Gaze Estimation with Gaze-Aware 3D Context Encoding](https://arxiv.org/abs/2505.10671)
*Yuki Kawana,Shintaro Shiba,Quan Kong,Norimasa Kobori*

Main category: cs.CV

TL;DR: 提出了一种新的3D视线估计方法GA3CE，通过学习主体与场景中物体的空间关系来估计3D视线方向，适用于无约束场景。

- Motivation: 解决在无约束场景中（如主体距离远或背对摄像头）难以从2D观测估计3D视线方向的问题。
- Method: 使用3D姿态和物体位置表示主体和场景，提出GA3CE方法，结合D$^3$位置编码来学习空间关系。
- Result: 在单帧设置下，相比基线方法，平均角度误差减少了13%-37%。
- Conclusion: GA3CE方法通过3D上下文编码显著提升了3D视线估计的准确性。


### [15] [Are Spatial-Temporal Graph Convolution Networks for Human Action Recognition Over-Parameterized?](https://arxiv.org/abs/2505.10679)
*Jianyang Xie,Yitian Zhao,Yanda Meng,He Zhao,Anh Nguyen,Yalin Zheng*

Main category: cs.CV

TL;DR: 论文提出稀疏ST-GCNs生成器，通过多级稀疏结构提升骨架动作识别性能，实验证明在参数大幅减少的情况下仍能保持或超越密集网络的性能。

- Motivation: 现有ST-GCNs在骨架动作识别中性能相近，可能存在过参数化问题，通过稀疏化探索更高效的模型结构。
- Method: 提出稀疏ST-GCNs生成器，从随机初始化的密集网络中训练稀疏架构，并整合多级稀疏结构。
- Result: 稀疏ST-GCNs在参数减少95%时性能下降<1%，多级稀疏ST-GCNs仅需66%参数且性能提升>1%。
- Conclusion: 稀疏化方法显著提升了ST-GCNs的效率，为骨架动作识别提供了更轻量且高性能的解决方案。


### [16] [GaussianFormer3D: Multi-Modal Gaussian-based Semantic Occupancy Prediction with 3D Deformable Attention](https://arxiv.org/abs/2505.10685)
*Lingjun Zhao,Sizhe Wei,James Hays,Lu Gan*

Main category: cs.CV

TL;DR: 提出了一种基于3D高斯的多模态语义占用预测框架GaussianFormer3D，结合LiDAR和相机数据，通过3D可变形注意力机制提升预测精度和效率。

- Motivation: 3D语义占用预测对自动驾驶至关重要，现有方法多基于密集网格表示，而3D高斯提供了一种更紧凑的连续表示。
- Method: 采用体素到高斯的初始化策略，利用LiDAR数据提供几何先验，设计LiDAR引导的3D可变形注意力机制优化高斯表示。
- Result: 在道路和非道路数据集上实验表明，GaussianFormer3D在保持高精度的同时降低了内存消耗并提升了效率。
- Conclusion: GaussianFormer3D在多模态融合方法中表现出色，为3D语义占用预测提供了高效且准确的解决方案。


### [17] [Automated Detection of Salvin's Albatrosses: Improving Deep Learning Tools for Aerial Wildlife Surveys](https://arxiv.org/abs/2505.10737)
*Mitchell Rogers,Theo Thompson,Isla Duporge,Johannes Fischer,Klemens Pütz,Thomas Mattern,Bing Xue,Mengjie Zhang*

Main category: cs.CV

TL;DR: 研究评估了通用鸟类检测模型BirdDetector在零样本和微调设置下对Salvin信天翁繁殖种群的监测效果，发现微调显著提升检测精度。

- Motivation: 利用无人机和深度学习技术高效监测野生动物种群，尤其是在偏远和挑战性环境中。
- Method: 使用无人机拍摄的高分辨率图像，评估BirdDetector模型的零样本和微调性能，结合增强推理和图像增强技术。
- Result: 零样本设置提供强基线，但微调后检测精度显著提高。
- Conclusion: 预训练深度学习模型在物种特异性监测中具有潜力，尤其是在偏远地区。


### [18] [IMAGE-ALCHEMY: Advancing subject fidelity in personalised text-to-image generation](https://arxiv.org/abs/2505.10743)
*Amritanshu Tiwari,Cherish Puniani,Kaustubh Sharma,Ojasva Nema*

Main category: cs.CV

TL;DR: 提出了一种两阶段方法，通过LoRA微调Stable Diffusion XL的注意力权重，解决个性化文本到图像生成中的遗忘和过拟合问题。

- Motivation: 现有文本到图像扩散模型在个性化生成新主题时存在遗忘、过拟合或计算开销大的问题。
- Method: 采用两阶段流程：1) 使用未修改的SDXL生成通用场景；2) 通过分割驱动的Img2Img流程选择性插入个性化主题。
- Result: 在SDXL上DINO相似度得分为0.789，优于现有方法。
- Conclusion: 该方法在保留SDXL生成能力的同时，实现了高保真度的个性化主题集成。


### [19] [Mapping Semantic Segmentation to Point Clouds Using Structure from Motion for Forest Analysis](https://arxiv.org/abs/2505.10751)
*Francisco Raverta Capua,Pablo De Cristoforis*

Main category: cs.CV

TL;DR: 提出了一种生成森林环境语义分割点云的新方法，填补了公开数据集的空白。

- Motivation: 由于成本高、设备要求严格且耗时，公开的森林点云数据集稀缺，尤其是基于SfM算法的语义分割数据集。
- Method: 使用自定义森林模拟器生成带语义标签的RGB图像，并通过改进的开源SfM软件生成语义分割点云。
- Result: 生成的点云包含几何和语义信息，可用于训练和评估深度学习模型。
- Conclusion: 该方法为森林点云语义分割提供了实用工具和数据集。


### [20] [Benchmarking performance, explainability, and evaluation strategies of vision-language models for surgery: Challenges and opportunities](https://arxiv.org/abs/2505.10764)
*Jiajun Cheng,Xianwu Zhao,Shan Lin*

Main category: cs.CV

TL;DR: 论文探讨了通用视觉语言模型（VLMs）在手术领域的表现，通过多数据集测试揭示了其在手术场景中的局限性。

- Motivation: 微创手术（MIS）存在视觉和技术挑战，现有方法依赖小规模标注数据。通用VLMs的成功引发了对其在手术领域适应性的研究兴趣。
- Method: 通过在多类手术数据集（如腹腔镜和内镜黏膜下剥离术）上测试VLMs，评估其性能和限制。
- Result: 基准测试显示VLMs在手术场景中难以稳定地将语言与正确区域关联。
- Conclusion: 通用VLMs在手术领域表现有限，需进一步改进以适应专业需求。


### [21] [Unifying Segment Anything in Microscopy with Multimodal Large Language Model](https://arxiv.org/abs/2505.10769)
*Manyu Li,Ruian He,Zixian Zhang,Weimin Tan,Bo Yan*

Main category: cs.CV

TL;DR: 该论文提出了一种利用多模态大语言模型（MLLMs）增强Segment Anything Model（SAM）的方法，通过注入视觉语言知识（VLK）提升其在显微图像分割中的跨域泛化能力。

- Motivation: 现有生物医学图像分割模型在未见领域数据上表现不佳，缺乏视觉语言知识是主要原因。MLLMs的多模态理解能力为解决这一问题提供了灵感。
- Method: 提出uLLSAM方法，包括视觉语言语义对齐（VLSA）模块和语义边界正则化（SBR），以注入VLK并优化边界感知。
- Result: 在9个域内显微数据集上，Dice和SA分别提升7.71%和12.10%；在10个域外数据集上，分别提升6.79%和10.08%。
- Conclusion: uLLSAM通过VLK注入和边界优化显著提升了SAM的跨域泛化能力，实现了最先进的性能。


### [22] [Completely Weakly Supervised Class-Incremental Learning for Semantic Segmentation](https://arxiv.org/abs/2505.10781)
*David Minkwan Kim,Soeun Lee,Byeongkeun Kang*

Main category: cs.CV

TL;DR: 本文提出了一种完全弱监督的类增量学习语义分割方法，仅使用图像级标签即可学习基类和新类的分割。通过结合定位器和基础模型的伪标签，并引入样本引导的数据增强方法，实验表明该方法在多个设置中优于部分弱监督方法。

- Motivation: 传统的类增量语义分割（CISS）方法需要昂贵的像素级标注，而部分弱监督方法虽有所改进，但完全弱监督方法尚未被探索。本文旨在填补这一空白。
- Method: 提出了一种基于不确定性的伪标签生成方法，结合定位器和基础模型的输出，并引入样本引导的数据增强以减少灾难性遗忘。
- Result: 在15-5 VOC和10-10 VOC设置中，完全弱监督方法优于部分弱监督方法，在COCO-to-VOC设置中表现也具竞争力。
- Conclusion: 本文首次实现了完全弱监督的CISS方法，并通过实验验证了其有效性。


### [23] [SynRailObs: A Synthetic Dataset for Obstacle Detection in Railway Scenarios](https://arxiv.org/abs/2505.10784)
*Qiushi Guo,Jason Rambach*

Main category: cs.CV

TL;DR: SynRailObs是一个高保真合成数据集，用于铁路环境中障碍物检测，弥补现有公开数据集的不足，支持多种天气和地理条件。

- Motivation: 现有公开数据集无法满足铁路安全研究中障碍物检测的需求，阻碍了研究进展。
- Method: 使用扩散模型生成难以捕捉的障碍物，创建高保真合成数据集SynRailObs，并在真实铁路环境中测试其有效性。
- Result: 实验表明，SynRailObs能显著提升障碍物检测性能，模型在不同距离和环境条件下表现一致，并具备零样本能力。
- Conclusion: SynRailObs为铁路安全应用中的障碍物检测提供了重要支持，具有广泛的应用潜力。


### [24] [EA-3DGS: Efficient and Adaptive 3D Gaussians with Highly Enhanced Quality for outdoor scenes](https://arxiv.org/abs/2505.10787)
*Jianlin Guo,Haihong Xiao,Wenxiong Kang*

Main category: cs.CV

TL;DR: EA-3DGS是一种针对户外场景的高质量实时渲染方法，通过网格结构和高效高斯剪枝策略优化3D高斯泼溅（3DGS）的性能。

- Motivation: 当前基于NeRF的方法在建筑规模场景重建中表现优异，但训练和推理速度慢；3DGS在户外场景中因点表示缺乏调整机制和内存限制而表现不佳。
- Method: 引入网格结构初始化高斯组件，提出高效高斯剪枝策略和结构感知的密集化策略，并使用向量量化减少参数存储需求。
- Result: 在13个场景（包括公开数据集和自采集数据）上验证了方法的优越性。
- Conclusion: EA-3DGS显著提升了户外场景的渲染质量和效率。


### [25] [MoCLIP: Motion-Aware Fine-Tuning and Distillation of CLIP for Human Motion Generation](https://arxiv.org/abs/2505.10810)
*Gabriel Maldonado,Armin Danesh Pazho,Ghazal Alinezhad Noghre,Vinit Katariya,Hamed Tabkhi*

Main category: cs.CV

TL;DR: MoCLIP是一种改进的CLIP模型，通过添加运动编码头和对比学习，提升了文本到运动生成的准确性和保真度。

- Motivation: 现有基于CLIP的文本编码器在理解运动的时间与运动学结构方面存在局限，需要改进以更好地生成运动。
- Method: MoCLIP通过添加运动编码头，使用对比学习和tethering损失在运动序列上微调CLIP模型。
- Result: 实验显示MoCLIP在Top-1、Top-2和Top-3准确率上有所提升，同时保持竞争力的FID分数。
- Conclusion: MoCLIP是一个有效的框架，能显著提升文本到运动生成的质量和兼容性。


### [26] [From Embeddings to Accuracy: Comparing Foundation Models for Radiographic Classification](https://arxiv.org/abs/2505.10823)
*Xue Li,Jameson Merkow,Noel C. F. Codella,Alberto Santamaria-Pang,Naiteek Sangani,Alexander Ersoy,Christopher Burt,John W. Garrett,Richard J. Bruce,Joshua D. Warner,Tyler Bradshaw,Ivan Tarapov,Matthew P. Lungren,Alan B. McMillan*

Main category: cs.CV

TL;DR: 研究评估了通用和医学专用基础模型嵌入在放射学分类中的效用，发现MedImageInsight嵌入结合SVM适配器表现最佳（mAUC 93.8%），且适配器计算高效、公平性良好。

- Motivation: 探索基础模型嵌入在医学影像诊断中的适用性，尤其是轻量级适配器的训练效果。
- Method: 使用六种基础模型提取嵌入，训练适配器进行多类放射学分类，评估性能和计算效率。
- Result: MedImageInsight嵌入表现最佳（mAUC 93.8%），适配器计算高效（训练<1分钟，推理秒级），公平性良好（性别差异<2%，年龄组标准差<3%）。
- Conclusion: 基础模型嵌入（尤其是MedImageInsight）支持高效、准确且公平的放射学分类，适合临床应用。


### [27] [A High-Performance Thermal Infrared Object Detection Framework with Centralized Regulation](https://arxiv.org/abs/2505.10825)
*Jinke Li,Yue Wu,Xiaoyan Yang*

Main category: cs.CV

TL;DR: 提出了一种基于集中特征调节的新型热红外目标检测框架CRT-YOLO，通过EMA模块和CFP网络提升全局信息提取能力，显著优于传统方法。

- Motivation: 传统方法在热红外图像目标检测中难以有效提取和融合局部-全局信息，限制了性能。
- Method: 提出CRT-YOLO框架，结合EMA模块和CFP网络，实现全局范围的热红外信息交互。
- Result: 在两个基准数据集上的实验表明，CRT-YOLO显著优于传统方法。
- Conclusion: CRT-YOLO通过集中特征调节和全局信息提取，推动了热红外目标检测领域的发展。


### [28] [NeuSEditor: From Multi-View Images to Text-Guided Neural Surface Edits](https://arxiv.org/abs/2505.10827)
*Nail Ibrahimli,Julian F. P. Kooij,Liangliang Nan*

Main category: cs.CV

TL;DR: NeuSEditor是一种基于文本引导的神经隐式表面编辑方法，解决了现有方法在编辑过程中难以保持身份和几何一致性的问题。

- Motivation: 隐式表面表示虽然紧凑且连续，但在编辑时难以保持身份和几何一致性，现有方法存在局限性。
- Method: NeuSEditor通过身份保持架构将场景分离为前景和背景，结合几何感知蒸馏损失提升渲染和几何质量。
- Result: NeuSEditor在定量和定性上优于PDS和InstructNeRF2NeRF等现有方法。
- Conclusion: NeuSEditor提供了一种高效、无需持续更新数据集和源提示的编辑方法，显著提升了编辑效果。


### [29] [RefPose: Leveraging Reference Geometric Correspondences for Accurate 6D Pose Estimation of Unseen Objects](https://arxiv.org/abs/2505.10841)
*Jaeguk Kim,Jaewoo Park,Keuntek Lee,Nam Ik Cho*

Main category: cs.CV

TL;DR: RefPose提出了一种基于参考图像和几何对应关系的6D姿态估计方法，通过动态适应新物体形状，在未见物体上表现优异。

- Motivation: 解决单目RGB图像中未见物体6D姿态估计的挑战，尤其是缺乏先验物体知识的问题。
- Method: 利用参考图像和几何对应关系，分初始姿态预测和迭代细化两阶段，引入相关性体积引导的注意力机制。
- Result: 在BOP基准数据集上达到最先进性能，同时保持高效运行时间。
- Conclusion: RefPose通过动态适应和几何对应关系，为未见物体的姿态估计提供了高效且鲁棒的解决方案。


### [30] [A Convolution-Based Gait Asymmetry Metric for Inter-Limb Synergistic Coordination](https://arxiv.org/abs/2505.10869)
*Go Fukino,Kanta Tachibana*

Main category: cs.CV

TL;DR: 本文提出了一种基于LTI系统的步态对称性评估方法，通过建模节段间协调性并使用差异度量来评估对称性。

- Motivation: 传统步态对称性评估依赖EMG信号或加速度差异，本文旨在提供一种更直接的方法。
- Method: 使用LTI系统建模节段间协调性，并提出差异度量来评估对称性。
- Result: 方法在五名对称和非对称步态受试者中进行了测试。
- Conclusion: 该方法为步态对称性评估提供了一种新工具。


### [31] [A Light and Smart Wearable Platform with Multimodal Foundation Model for Enhanced Spatial Reasoning in People with Blindness and Low Vision](https://arxiv.org/abs/2505.10875)
*Alexey Magay,Dhurba Tripathi,Yu Hao,Yi Fang*

Main category: cs.CV

TL;DR: 提出了一种基于空间增强多模态大语言模型的方法，结合硬件设备，帮助视障人士更好地理解和导航环境。

- Motivation: 视障人士在导航和物体定位上面临挑战，现有技术缺乏空间推理能力和轻量化设计。
- Method: 通过微调多模态大语言模型，加入空间推理能力，并结合眼镜附件硬件，提供实时反馈。
- Result: 在VizWiz数据集上验证了方法的高准确性和用户体验提升。
- Conclusion: 该方法填补了先进机器学习模型与实用辅助设备之间的空白，显著提升了视障人士的独立导航能力。


### [32] [PoseBench3D: A Cross-Dataset Analysis Framework for 3D Human Pose Estimation](https://arxiv.org/abs/2505.10888)
*Saad Manzur,Bryan Vela,Brandon Vela,Aditya Agrawal,Lan-Anh Dang-Vu,David Li,Wayne Hayes*

Main category: cs.CV

TL;DR: 提出PoseBench3D框架，用于标准化评估3D人体姿态估计方法在跨数据集上的性能。

- Motivation: 解决现有方法在单一数据集上表现良好但难以适应多样化实际场景的问题。
- Method: 构建统一测试环境，评估18种方法在4个常用数据集上的表现，支持未来数据集扩展。
- Result: 生成100多项跨数据集评估结果，分析预处理技术和数据集参数对性能的影响。
- Conclusion: PoseBench3D为模型泛化能力提供了标准化评估工具，促进未来研究。


### [33] [Patient-Specific Dynamic Digital-Physical Twin for Coronary Intervention Training: An Integrated Mixed Reality Approach](https://arxiv.org/abs/2505.10902)
*Shuo Wang,Tong Ren,Nan Cheng,Rong Wang,Li Zhang*

Main category: cs.CV

TL;DR: 研究开发了一种基于4D-CTA的动态心脏模型框架，结合数字孪生技术，为冠状动脉介入提供精确的个性化工具。

- Motivation: 现有训练系统缺乏对心脏生理动态的准确模拟，需要更精确的术前规划和医生培训工具。
- Method: 利用4D-CTA数据构建动态模型，制造透明血管物理模型，开发心脏输出分析和虚拟血管造影系统。
- Result: 虚拟与真实血管造影形态一致性达80.9%，导丝运动轨迹误差低于1.1毫米，透明模型在CABG训练中表现优异。
- Conclusion: 患者特定的数字-物理孪生方法有效再现冠状动脉解剖结构和动态特性，为教育和临床规划提供动态环境。


### [34] [VISTA: Enhancing Vision-Text Alignment in MLLMs via Cross-Modal Mutual Information Maximization](https://arxiv.org/abs/2505.10917)
*Mingxiao Li,Na Su,Fang Qu,Zhizhou Zhong,Ziyang Chen,Zhaopeng Tu,Xiaolong Li*

Main category: cs.CV

TL;DR: 本文提出VISTA方法，通过信息论分析揭示交叉熵损失的局限性，并设计显式对齐目标以提升多模态大语言模型的视觉对齐能力。

- Motivation: 当前多模态大语言模型（MLLMs）存在模态对齐偏差，偏向文本信息而忽视视觉等其他模态。本文旨在解决这一问题。
- Method: 通过信息论分析交叉熵损失的隐式对齐目标，提出VISTA方法，引入显式对齐目标以最大化跨模态互信息。
- Result: VISTA显著提升了现有MLLMs的视觉理解能力，无需额外模块或数据，并在多个基准数据集上优于基线模型。
- Conclusion: VISTA为MLLMs模态对齐研究提供了新方向，解决了跨模态信息融合的挑战。


### [35] [Towards Cross-modal Retrieval in Chinese Cultural Heritage Documents: Dataset and Solution](https://arxiv.org/abs/2505.10921)
*Junyi Yuan,Jian Zhang,Fangyu Wu,Dongming Lu,Huanda Lu,Qiufeng Wang*

Main category: cs.CV

TL;DR: 论文提出一个名为CulTi的多模态数据集，专注于中国文化遗产，并提出了一种名为LACLIP的无训练局部对齐策略，显著提升了跨模态检索性能。

- Motivation: 中国文化遗产包含丰富的多模态信息，但缺乏专门的数据集和模型来支持跨模态检索研究。
- Method: 构建CulTi数据集（5,726对图像-文本），并提出LACLIP策略，基于微调的中文CLIP实现局部对齐。
- Result: LACLIP在CulTi数据集上显著优于现有模型，尤其在细粒度语义关联方面表现突出。
- Conclusion: CulTi数据集和LACLIP策略填补了中国文化遗产跨模态检索的空白，为相关研究提供了新工具。


### [36] [M4-SAR: A Multi-Resolution, Multi-Polarization, Multi-Scene, Multi-Source Dataset and Benchmark for Optical-SAR Fusion Object Detection](https://arxiv.org/abs/2505.10931)
*Chao Wang,Wei Lu,Xiang Li,Jian Yang,Lei Luo*

Main category: cs.CV

TL;DR: 论文提出首个光学-SAR融合目标检测数据集M4-SAR，并开发了E2E-OSDet框架，显著提升复杂环境下的检测精度。

- Motivation: 光学和SAR图像在复杂环境中各有优劣，但缺乏标准化的大规模数据集阻碍了融合研究的发展。
- Method: 构建M4-SAR数据集，开发统一评测工具包，并提出E2E-OSDet框架以减少跨域差异。
- Result: 融合光学和SAR数据可将mAP提升5.7%，尤其在复杂环境中效果显著。
- Conclusion: M4-SAR数据集和E2E-OSDet框架为未来研究提供了重要基准和工具。


### [37] [Visual Anomaly Detection under Complex View-Illumination Interplay: A Large-Scale Benchmark](https://arxiv.org/abs/2505.10996)
*Yunkang Cao,Yuqi Cheng,Xiaohao Xu,Yiheng Zhang,Yihan Sun,Yuxiang Tan,Yuxin Zhang,Xiaonan Huang,Weiming Shen*

Main category: cs.CV

TL;DR: M2AD是一个新的大规模视觉异常检测（VAD）基准数据集，旨在评估VAD方法在复杂视角和光照条件下的鲁棒性。

- Motivation: 现有VAD系统对真实世界成像变化（尤其是视角和光照的复杂交互）的敏感性限制了其实际应用，而当前基准数据集忽视了这一挑战。
- Method: M2AD包含119,880张高分辨率图像，通过系统捕获10类999个样本的12种视角和10种光照配置（共120种），并设计了两种评估协议：M2AD-Synergy和M2AD-Invariant。
- Result: 实验表明，现有VAD方法在M2AD上表现不佳，凸显了视角和光照交互带来的巨大挑战。
- Conclusion: M2AD为开发和验证能够应对真实世界复杂性的VAD方法提供了重要工具，数据集和测试套件将公开以推动研究。


### [38] [DDAE++: Enhancing Diffusion Models Towards Unified Generative and Discriminative Learning](https://arxiv.org/abs/2505.10999)
*Weilai Xiang,Hongyu Yang,Di Huang,Yunhong Wang*

Main category: cs.CV

TL;DR: 论文提出了一种称为“自条件”的机制，通过利用去噪网络内部的丰富语义来指导其解码层，从而提升扩散模型的生成质量和特征表示能力。

- Motivation: 扩散模型在图像合成中表现出色，但其生成预训练是否能提升模型自身训练效果，以及特征质量是否能超越自监督学习模型，是待解决的关键问题。
- Method: 引入自条件机制，利用去噪网络的语义信息指导解码层，形成更紧密的瓶颈以提升生成质量。
- Result: 实验表明，该方法在生成FID和识别准确率上均有提升，计算开销仅增加1%，且适用于多种扩散架构。
- Conclusion: 自条件机制成功整合了判别性技术（如对比自蒸馏），在不牺牲生成质量的前提下，使扩散模型成为强大的表示学习工具。


### [39] [ForensicHub: A Unified Benchmark & Codebase for All-Domain Fake Image Detection and Localization](https://arxiv.org/abs/2505.11003)
*Bo Du,Xuekang Zhu,Xiaochen Ma,Chenfan Qu,Kaiwen Feng,Zhe Yang,Chi-Man Pun,Jian Liu,Jizhe Zhou*

Main category: cs.CV

TL;DR: ForensicHub是首个用于全领域假图像检测与定位的统一基准和代码库，旨在打破领域孤岛，促进跨领域比较和发展。

- Motivation: FIDL领域高度分散，缺乏统一基准，导致各领域独立发展，无法跨领域比较，阻碍整体发展。
- Method: 提出模块化和配置驱动的架构，分解法证流程为可互换组件；实现10个基线模型、6个主干网络、2个新基准，并通过适配器设计整合现有基准。
- Result: 深入分析提供了8个关键见解，涵盖模型架构、数据集特性和评估标准。
- Conclusion: ForensicHub显著推动了FIDL领域的跨领域整合，为未来突破提供了基础。


### [40] [Towards Robust and Controllable Text-to-Motion via Masked Autoregressive Diffusion](https://arxiv.org/abs/2505.11013)
*Zongye Zhang,Bohan Kong,Qingjie Liu,Yunhong Wang*

Main category: cs.CV

TL;DR: MoMADiff结合掩码建模与扩散过程，通过帧级连续表示生成3D人体运动，支持用户提供关键帧，提升运动质量与指令忠实度。

- Motivation: 现有方法在训练分布内表现良好，但对分布外运动泛化能力不足，且离散标记或连续表示方法各有局限。
- Method: 提出MoMADiff框架，结合掩码建模与扩散过程，使用帧级连续表示生成运动，支持用户关键帧控制。
- Result: 在多个数据集上表现优于现有方法，运动质量、指令忠实度和关键帧遵循性均显著提升。
- Conclusion: MoMADiff通过结合掩码建模与扩散过程，实现了高质量、可控的3D人体运动生成。


### [41] [WildDoc: How Far Are We from Achieving Comprehensive and Robust Document Understanding in the Wild?](https://arxiv.org/abs/2505.11015)
*An-Lan Wang,Jingqun Tang,Liao Lei,Hao Feng,Qi Liu,Xiang Fei,Jinghui Lu,Han Wang,Weiwei Liu,Hao Liu,Yuliang Liu,Xiang Bai,Can Huang*

Main category: cs.CV

TL;DR: WildDoc是一个专为评估自然环境中文档理解能力而设计的基准测试，填补了现有基准（如DocVQA和ChartQA）在真实场景多样性上的不足。

- Motivation: 现有基准主要针对扫描或数字文档，未能反映真实世界中的复杂挑战（如光照变化和物理变形）。WildDoc旨在填补这一空白。
- Method: WildDoc包含多样化的手动拍摄文档图像，每份文档在四种不同条件下拍摄，以评估模型鲁棒性。
- Result: 评估显示，现有MLLMs在WildDoc上性能显著下降，鲁棒性不足。
- Conclusion: WildDoc揭示了真实世界文档理解的独特挑战，为未来研究提供了新方向。


### [42] [Rethinking the Mean Teacher Strategy from the Perspective of Self-paced Learning](https://arxiv.org/abs/2505.11018)
*Pengchen Zhang,Alan J. X. Guo,Sipin Luo,Zhe Han,Lin Guo*

Main category: cs.CV

TL;DR: 论文提出了一种双师生学习框架（DTSL），通过跨架构模型的一致性输出生成伪标签，提升了半监督医学图像分割的性能。

- Motivation: 减少医学图像分割中的人工标注成本，同时提升半监督学习的效果。
- Method: 采用双师生学习框架（DTSL），结合跨架构模型的一致性输出生成伪标签，并通过Jensen-Shannon散度共识标签生成器（CLG）优化学习过程。
- Result: 在多个数据集上表现优于现有方法，消融实验验证了模块的有效性。
- Conclusion: DTSL框架通过跨架构模型的一致性学习，显著提升了半监督医学图像分割的性能。


### [43] [Classifying Shelf Life Quality of Pineapples by Combining Audio and Visual Features](https://arxiv.org/abs/2505.11020)
*Yi-Lu Jiang,Wen-Chang Chang,Ching-Lin Wang,Kung-Liang Hsu,Chih-Yi Chiu*

Main category: cs.CV

TL;DR: 本文提出了一种多模态多视角分类模型，用于基于音频和视觉特征对菠萝进行四种质量等级分类，以减少浪费并提高收入。

- Motivation: 通过非破坏性方法确定菠萝的货架期质量，以减少浪费并增加收入。
- Method: 构建多模态多视角分类模型，利用PQC500数据集（包含500个菠萝的音频和视觉数据），改进对比视听掩码自编码器，并提出高效计算的训练数据采样方法。
- Result: 实验表明，提出的跨模态模型在音频主导采样下达到84%的准确率，分别比单模态音频和视觉模型高6%和18%。
- Conclusion: 跨模态模型在菠萝质量分类中表现优异，具有实际应用潜力。


### [44] [CleanPatrick: A Benchmark for Image Data Cleaning](https://arxiv.org/abs/2505.11034)
*Fabian Gröger,Simone Lionetti,Philippe Gottfrois,Alvaro Gonzalez-Jimenez,Ludovic Amruthalingam,Elisabeth Victoria Goessinger,Hanna Lindemann,Marie Bargiela,Marie Hofbauer,Omar Badri,Philipp Tschandl,Arash Koochek,Matthew Groh,Alexander A. Navarini,Marc Pouly*

Main category: cs.CV

TL;DR: CleanPatrick是首个大规模图像数据清洗基准，基于Fitzpatrick17k皮肤科数据集，通过众包标注和专家审核生成高质量数据，评估多种方法在去重、离题检测和标签错误识别上的表现。

- Motivation: 现有图像数据清洗基准依赖合成噪声或小规模人工研究，缺乏真实性和可比性。CleanPatrick旨在填补这一空白，推动数据为中心的AI发展。
- Method: 收集496,377个众包标注，识别离题样本（4%）、近重复（21%）和标签错误（22%），结合项目反应理论和专家审核生成基准。
- Result: 自监督表示在近重复检测中表现优异，经典方法在有限预算下能有效检测离题样本，标签错误检测仍是医学细粒度分类的挑战。
- Conclusion: CleanPatrick为图像数据清洗提供了系统评估框架，促进数据驱动AI的可靠性。


### [45] [Artifacts of Idiosyncracy in Global Street View Data](https://arxiv.org/abs/2505.11046)
*Tim Alpherts,Sennay Ghebreab,Nanne van Noord*

Main category: cs.CV

TL;DR: 研究发现，即使密集采样，全球28个城市的街景数据仍因城市布局等特性存在偏差，并提出评估方法。阿姆斯特丹案例研究进一步揭示了数据收集过程中的偏差来源。

- Motivation: 街景数据在计算机视觉应用中广泛使用，但现有数据集假设为系统性代表城市，而实际存在覆盖不均的问题。研究旨在揭示城市特性如何导致数据偏差。
- Method: 定量分析全球28个城市街景数据的覆盖分布偏差，并提出评估方法；通过阿姆斯特丹案例研究，结合半结构化访谈，分析收集过程对数据代表性的影响。
- Result: 发现城市布局等特性会导致街景数据偏差，即使密集采样；阿姆斯特丹案例揭示了数据收集过程中的具体偏差来源。
- Conclusion: 城市特性会导致街景数据偏差，需改进数据收集方法以减少偏差，提高数据代表性。


### [46] [CUBIC: Concept Embeddings for Unsupervised Bias Identification using VLMs](https://arxiv.org/abs/2505.11060)
*David Méndez,Gianpaolo Bontempo,Elisa Ficarra,Roberto Confalonieri,Natalia Díaz-Rodríguez*

Main category: cs.CV

TL;DR: CUBIC是一种无需预定义偏见候选或失败样本的新方法，通过图像-文本潜在空间和线性分类器探针自动发现可解释的偏见概念。

- Motivation: 深度视觉模型常依赖数据集中的虚假相关性学习偏见，而现有方法需要大量人工标注。CUBIC旨在无需标注的情况下自动识别这些偏见。
- Method: CUBIC利用图像-文本潜在空间和线性分类器探针，通过分析超类标签潜在表示受概念影响的程度来识别偏见。
- Result: 实验表明，CUBIC能有效发现未知偏见，且无需失败样本或先验知识。
- Conclusion: CUBIC为无监督偏见识别提供了一种高效且无需人工干预的方法。


### [47] [HSRMamba: Efficient Wavelet Stripe State Space Model for Hyperspectral Image Super-Resolution](https://arxiv.org/abs/2505.11062)
*Baisong Li,Xingwang Wang,Haixiao Xu*

Main category: cs.CV

TL;DR: HSRMamba改进Visual Mamba模型，通过条带扫描和小波分解减少伪影和模态冲突，提升超分辨率性能。

- Motivation: 解决Visual Mamba模型因单向扫描导致的图像生成伪影问题。
- Method: 引入条带扫描方案和小波分解，平衡计算效率和特征模态。
- Result: 实验表明HSRMamba在计算负载和性能上均优于现有方法。
- Conclusion: HSRMamba在超分辨率任务中实现了最佳效果。


### [48] [Towards Self-Improvement of Diffusion Models via Group Preference Optimization](https://arxiv.org/abs/2505.11070)
*Renjie Chen,Wenfeng Lin,Yichen Zhang,Jiangchuan Wei,Boyuan Liu,Chao Feng,Jiao Ran,Mingyu Guo*

Main category: cs.CV

TL;DR: 论文提出Group Preference Optimization (GPO)，通过扩展DPO为组偏好优化并引入奖励标准化，解决了T2I扩散模型中DPO对偏好对的敏感性和数据收集问题，显著提升了生成质量。

- Motivation: DPO在T2I扩散模型中表现优异，但对偏好对的敏感性和高质量数据收集的困难限制了其应用。
- Method: 扩展DPO为组偏好优化（GPO），引入奖励标准化进行重加权，无需显式数据选择。
- Result: GPO在多种扩散模型和任务中有效，结合YOLO和OCR等模型，将Stable Diffusion 3.5 Medium的计数和文本渲染能力提升20个百分点。
- Conclusion: GPO是一种即插即用的自改进方法，无需额外推理开销，显著提升了T2I扩散模型的性能。


### [49] [Pseudo-Label Quality Decoupling and Correction for Semi-Supervised Instance Segmentation](https://arxiv.org/abs/2505.11075)
*Jianghang Lin,Yilin Lu,Yunhang Shen,Chaoyang Zhu,Shengchuan Zhang,Liujuan Cao,Rongrong Ji*

Main category: cs.CV

TL;DR: 论文提出PL-DC框架，通过解耦伪标签的类别和掩码质量评估，动态修正类别标签，并引入像素级掩码不确定性机制，显著提升半监督实例分割性能。

- Motivation: 解决半监督实例分割中因伪标签噪声导致的性能不稳定问题，特别是类别和掩码质量评估的单一阈值限制。
- Method: 1. 实例级解耦双阈值过滤机制；2. 类别级动态实例类别修正模块；3. 像素级掩码不确定性感知机制。
- Result: 在COCO和Cityscapes数据集上取得显著性能提升，1% COCO标注数据下mAP提升+11.6，5% Cityscapes标注数据下mAP提升+15.5。
- Conclusion: PL-DC框架有效解决了伪标签噪声问题，显著提升了半监督实例分割的性能，尤其在标注数据稀缺时表现优异。


### [50] [Hybrid-Emba3D: Geometry-Aware and Cross-Path Feature Hybrid Enhanced State Space Model for Point Cloud Classification](https://arxiv.org/abs/2505.11099)
*Bin Liu,Chunyang Wang,Xuelian Liu,Guan Xi,Ge Zhang,Ziteng Yao,Mengxue Dong*

Main category: cs.CV

TL;DR: Hybrid-Emba3D提出了一种双向Mamba模型，通过几何特征耦合和跨路径特征混合，解决了点云分类任务中局部几何特征提取与模型复杂度平衡的问题。

- Motivation: 点云分类任务需要高效提取局部几何特征，同时控制模型复杂度。Mamba架构虽能解决Transformer的计算瓶颈，但其单向依赖性与点云无序性矛盾，限制了局部空间相关性建模。
- Method: 提出Hybrid-Emba3D，结合几何特征耦合机制和双路径特征混合，增强局部特征判别力，并突破传统SSM的长程建模限制。
- Result: 在ModelNet40上达到95.99%的分类准确率，仅增加0.03M参数。
- Conclusion: Hybrid-Emba3D通过几何特征耦合和跨路径混合，显著提升了点云分类性能，同时保持低复杂度。


### [51] [MAVOS-DD: Multilingual Audio-Video Open-Set Deepfake Detection Benchmark](https://arxiv.org/abs/2505.11109)
*Florinel-Alin Croitoru,Vlad Hondru,Marius Popescu,Radu Tudor Ionescu,Fahad Shahbaz Khan,Mubarak Shah*

Main category: cs.CV

TL;DR: 论文提出了首个大规模多语言音频-视频深度伪造检测开放集基准数据集，包含8种语言的250小时真实与伪造视频，60%为生成数据。实验表明现有先进检测器在开放集场景下性能下降。

- Motivation: 当前深度伪造检测缺乏多语言开放集基准，难以评估检测器的泛化能力。
- Method: 构建包含8种语言的250小时数据集，60%为生成数据，采用7种不同生成模型。训练、验证和测试集划分确保开放集评估。
- Result: 现有先进检测器在开放集场景下性能显著下降。
- Conclusion: 多语言开放集检测具有挑战性，需进一步改进检测器泛化能力。


### [52] [Deepfake Forensic Analysis: Source Dataset Attribution and Legal Implications of Synthetic Media Manipulation](https://arxiv.org/abs/2505.11110)
*Massimiliano Cassia,Luca Guarnera,Mirko Casu,Ignazio Zangara,Sebastiano Battiato*

Main category: cs.CV

TL;DR: 本文提出了一种新的法证框架，通过可解释的特征分析识别GAN生成图像的训练数据集（如CelebA或FFHQ），在真实与合成图像的分类及数据集归属上达到98-99%的准确率。

- Motivation: GAN生成的合成媒体在验证真实性和追踪数据集来源方面带来挑战，涉及版权、隐私和法律合规问题。
- Method: 结合频谱变换（傅里叶/DCT）、颜色分布度量和局部特征描述符（SIFT），提取合成图像中的统计特征，并使用监督分类器（随机森林、SVM、XGBoost）进行分类。
- Result: 实验结果显示，频域特征（DCT/FFT）在捕捉数据集特定伪影（如上采样模式和频谱异常）方面表现突出，颜色直方图揭示了GAN训练中的隐式正则化策略。
- Conclusion: 该框架提升了生成模型的问责和治理能力，适用于数字取证、内容审核和知识产权诉讼，并探讨了其在法律和伦理方面的应用。


### [53] [Redundancy-Aware Pretraining of Vision-Language Foundation Models in Remote Sensing](https://arxiv.org/abs/2505.11121)
*Mathis Jürgen Adler,Leonard Hackel,Gencer Sumbul,Begüm Demir*

Main category: cs.CV

TL;DR: 提出了一种加权特征聚合（WFA）策略，用于遥感（RS）中的视觉语言模型（VLM）预训练，以减少冗余信息并提高效率。

- Motivation: 解决遥感领域VLM预训练中多描述冗余导致的效率问题。
- Method: 采用两种技术计算描述的重要性权重：非参数唯一性和基于学习的注意力机制。
- Result: 实验表明WFA策略能高效且有效地预训练VLM，并提供了技术选择指南。
- Conclusion: WFA策略在遥感领域具有实用价值，代码已公开。


### [54] [PhiNet v2: A Mask-Free Brain-Inspired Vision Foundation Model from Video](https://arxiv.org/abs/2505.11129)
*Makoto Yamada,Kian Ming A. Chai,Ayoub Rhim,Satoki Ishikawa,Mohammad Sabokrou,Yao-Hung Hubert Tsai*

Main category: cs.CV

TL;DR: PhiNet v2是一种基于Transformer的架构，处理时序视觉输入，无需强数据增强，性能与最先进视觉模型相当。

- Motivation: 现有自监督学习未充分利用生物视觉处理系统的启发，PhiNet v2旨在更接近人类视觉处理方式。
- Method: 采用Transformer架构和变分推断，从连续图像序列中学习鲁棒视觉表示。
- Result: PhiNet v2在性能上与最先进模型竞争，且无需强数据增强。
- Conclusion: 该研究推动了更接近生物视觉的计算机视觉系统发展。


### [55] [One Image is Worth a Thousand Words: A Usability Preservable Text-Image Collaborative Erasing Framework](https://arxiv.org/abs/2505.11131)
*Feiran Li,Qianqian Xu,Shilong Bao,Zhiyong Yang,Xiaochun Cao,Qingming Huang*

Main category: cs.CV

TL;DR: 提出了一种文本-图像协同概念擦除框架（Co-Erasing），通过视觉监督提升擦除效果，减少对良性概念的干扰。

- Motivation: 现有概念擦除方法依赖文本提示，难以平衡擦除效果和对其他概念的干扰，文本与图像模态间的知识差距是主要原因。
- Method: 结合文本提示和不良图像描述概念，通过负向指导降低目标概念生成概率，并设计文本引导的图像概念细化策略。
- Result: 实验表明，Co-Erasing在擦除效果和可用性之间取得了更好的平衡，显著优于现有方法。
- Conclusion: Co-Erasing通过视觉监督解决了文本-图像模态间的知识差距，提升了概念擦除的效能和实用性。


### [56] [Human-Aligned Bench: Fine-Grained Assessment of Reasoning Ability in MLLMs vs. Humans](https://arxiv.org/abs/2505.11141)
*Yansheng Qiu,Li Xiao,Zhaopan Xu,Pengfei Zhou,Zheng Wang,Kaipeng Zhang*

Main category: cs.CV

TL;DR: 论文提出了一个名为Human-Aligned Bench的基准测试，用于评估多模态推理模型与人类表现的细粒度对齐情况。

- Motivation: 当前的大型语言模型（LLMs）和多模态大语言模型（MLLMs）在推理任务中是否具备与人类相当的能力尚不明确，因此需要一种基准测试来量化这种差距。
- Method: 收集了9,794个多模态问题，涵盖四种问题类型（视觉推理、定义判断、类比推理和逻辑判断），并附有人类成功率和易错选项。
- Result: 实验发现当前MLLMs在多模态推理中的表现与人类存在显著差异。
- Conclusion: 该基准为下一代模型的开发提供了重要见解。


### [57] [Learning Dense Hand Contact Estimation from Imbalanced Data](https://arxiv.org/abs/2505.11152)
*Daniel Sungho Jung,Kyoung Mu Lee*

Main category: cs.CV

TL;DR: 提出了一种解决手部接触估计中类别和空间不平衡问题的框架HACO，通过平衡接触采样和顶点级类别平衡损失（VCB）改进学习效果。

- Motivation: 手部接触对人类交互至关重要，但现有数据集存在类别和空间不平衡问题，影响密集接触估计的学习效果。
- Method: 使用平衡接触采样解决类别不平衡问题，提出VCB损失解决空间不平衡问题。
- Result: 有效预测密集手部接触，避免了类别和空间不平衡问题。
- Conclusion: HACO框架成功解决了手部接触估计中的不平衡问题，代码将公开。


### [58] [CheX-DS: Improving Chest X-ray Image Classification with Ensemble Learning Based on DenseNet and Swin Transformer](https://arxiv.org/abs/2505.11168)
*Xinran Li,Yu Liu,Xiujuan Xu,Xiaowei Zhao*

Main category: cs.CV

TL;DR: 提出了一种结合CNN和Transformer的模型CheX-DS，用于胸部X光片的多标签分类，解决了数据不平衡问题，性能优于现有方法。

- Motivation: 当前方法主要依赖CNN，忽略了全局特征，而自注意力机制在视觉任务中表现优异，因此提出结合两者的模型。
- Method: 基于DenseNet和Swin Transformer，采用集成学习方法结合两者优势，并使用加权二元交叉熵损失和非对称损失解决数据不平衡。
- Result: 在NIH ChestX-ray14数据集上平均AUC达到83.76%，优于之前的研究。
- Conclusion: CheX-DS模型结合了CNN和Transformer的优势，有效解决了数据不平衡问题，性能显著提升。


### [59] [CompAlign: Improving Compositional Text-to-Image Generation with a Complex Benchmark and Fine-Grained Feedback](https://arxiv.org/abs/2505.11178)
*Yixin Wan,Kai-Wei Chang*

Main category: cs.CV

TL;DR: CompAlign是一个评估和改进文本到图像模型在复杂组合场景生成能力的基准，包含900个复杂多主体提示，并提出CompQuest评估框架和模型对齐方法。

- Motivation: 现有T2I模型在生成高分辨率图像时难以准确描绘多对象、属性和空间关系的组合场景。
- Method: 提出CompAlign基准和CompQuest评估框架，后者将复杂提示分解为原子子问题并使用MLLM提供细粒度反馈。
- Result: 评估显示模型在复杂3D空间关系任务上表现较差，开源与闭源模型存在性能差距；对齐后模型在组合准确性上有显著提升。
- Conclusion: CompAlign和CompQuest为组合图像生成提供了有效评估和改进方法，对齐后模型表现优于现有方法。


### [60] [Imputation-free and Alignment-free: Incomplete Multi-view Clustering Driven by Consensus Semantic Learning](https://arxiv.org/abs/2505.11182)
*Yuzhuo Dai,Jiaqi Jin,Zhibin Dong,Siwei Wang,Xinwang Liu,En Zhu,Xihong Yang,Xinbiao Gan,Yu Feng*

Main category: cs.CV

TL;DR: FreeCSL框架通过共识原型学习和启发式图聚类，解决了不完整多视图聚类中的语义不一致问题，无需依赖对齐和插补。

- Motivation: 解决不完整多视图聚类中因数据缺失导致的视图内原型偏移和视图间语义不一致问题。
- Method: 1. 学习共识原型以构建共享语义空间；2. 基于模块化的启发式图聚类增强簇内紧凑性和簇间分离性。
- Result: FreeCSL在不完整多视图聚类任务中表现出更自信和鲁棒的分配效果。
- Conclusion: FreeCSL通过共识语义学习和簇语义增强，有效提升了不完整多视图聚类的性能。


### [61] [FALCON: False-Negative Aware Learning of Contrastive Negatives in Vision-Language Pretraining](https://arxiv.org/abs/2505.11192)
*Myunsoo Kim,Seong-Woong Shim,Byung-Jun Lee*

Main category: cs.CV

TL;DR: FALCON是一种自适应平衡硬负样本和假负样本的学习策略，用于提升视觉-语言预训练（VLP）的效果。

- Motivation: 假负样本在VLP中因多对多对应关系导致冲突监督信号，影响嵌入空间和硬负采样效果。
- Method: FALCON通过动态调度负样本选择，自适应平衡硬负和假负样本，优化跨模态对齐。
- Result: 实验表明FALCON在ALBEF和BLIP-2框架及多种下游任务中显著提升性能。
- Conclusion: FALCON有效缓解假负样本影响，提升VLP的鲁棒性和效果。


### [62] [DiCo: Revitalizing ConvNets for Scalable and Efficient Diffusion Modeling](https://arxiv.org/abs/2505.11196)
*Yuang Ai,Qihang Fan,Xuefeng Hu,Zhenheng Yang,Ran He,Huaibo Huang*

Main category: cs.CV

TL;DR: DiCo（Diffusion ConvNet）是一种基于卷积的高效扩散模型，通过引入紧凑通道注意力机制提升性能，在生成质量和速度上优于DiT。

- Motivation: 研究发现DiT中的全局自注意力冗余，主要捕捉局部模式，因此探索卷积作为更高效的替代方案。
- Method: 提出DiCo，采用标准卷积模块和紧凑通道注意力机制，减少通道冗余并增强特征多样性。
- Result: DiCo在ImageNet基准测试中表现优异，DiCo-XL在256x256和512x分辨率下FID分别为2.05和2.53，速度提升2.7x和3.1x。DiCo-H（1B参数）FID达1.90。
- Conclusion: DiCo证明了卷积在扩散模型中的高效性和表达力，为视觉生成提供了更优方案。


### [63] [GeoMM: On Geodesic Perspective for Multi-modal Learning](https://arxiv.org/abs/2505.11216)
*Shibin Mei,Hang Wang,Bingbing Ni*

Main category: cs.CV

TL;DR: 本文首次将测地距离引入多模态学习，提出一种新距离度量方法，通过图结构和最短路径算法计算测地距离，并结合分层图和动态更新策略优化计算效率。实验验证了其有效性。

- Motivation: 传统距离度量在多模态学习中难以区分语义相似但含义不同的样本，测地距离作为一种非线性空间度量方法，有望解决这一问题。
- Method: 构建图结构表示样本邻接关系，通过最短路径算法计算测地距离；提出分层图和动态更新策略以提高计算效率。
- Result: 实验表明，该方法能有效捕捉样本间复杂关系，提升多模态学习模型性能。
- Conclusion: 测地距离在多模态学习中具有潜力，提出的方法解决了传统距离度量的局限性，并通过优化策略实现了高效计算。


### [64] [AW-GATCN: Adaptive Weighted Graph Attention Convolutional Network for Event Camera Data Joint Denoising and Object Recognition](https://arxiv.org/abs/2505.11232)
*Haiyu Li,Charith Abhayaratne*

Main category: cs.CV

TL;DR: 提出了一种基于自适应图的事件相机噪声数据去除框架，显著提升了事件相机在物体识别中的性能。

- Motivation: 事件相机生成的数据包含大量冗余和噪声，如何在去噪的同时保留关键时空信息是主要挑战。
- Method: 结合自适应事件分割、多因素边权重机制和自适应图去噪策略，有效整合时空信息。
- Result: 在四个数据集上识别准确率分别为83.77%、76.79%、99.30%和96.89%，优于现有方法。
- Conclusion: 该方法在去噪和识别性能上均显著优于传统方法，为事件相机应用提供了有效解决方案。


### [65] [Diffusion-NPO: Negative Preference Optimization for Better Preference Aligned Generation of Diffusion Models](https://arxiv.org/abs/2505.11245)
*Fu-Yun Wang,Yunhao Shui,Jingtan Piao,Keqiang Sun,Hongsheng Li*

Main category: cs.CV

TL;DR: 本文提出了一种针对负偏好的训练方法，以改进扩散模型生成结果与人类偏好的一致性。

- Motivation: 现有偏好对齐方法忽视了无条件/负条件输出的处理，导致生成结果质量受限。
- Method: 训练一个专门针对负偏好的模型，无需新策略或数据集，仅需对现有技术进行微小修改。
- Result: 该方法与多种模型（如SD1.5、SDXL等）兼容，显著提升了生成结果与人类偏好的一致性。
- Conclusion: 通过处理负偏好，该方法有效提升了扩散模型的生成质量和对齐效果。


### [66] [Entropy-Driven Genetic Optimization for Deep-Feature-Guided Low-Light Image Enhancement](https://arxiv.org/abs/2505.11246)
*Nirjhor Datta,Afroza Akther,M. Sohel Rahman*

Main category: cs.CV

TL;DR: 提出了一种基于NSGA-II算法的无监督图像增强框架，优化亮度、对比度和伽马参数，平衡视觉质量与语义保真度。

- Motivation: 现有图像增强方法常忽略语义特征，本文旨在解决这一问题。
- Method: 使用预训练深度神经网络提取特征，结合GPU加速的NSGA-II算法优化多目标（图像熵、感知相似性、亮度），并通过局部搜索微调结果。
- Result: 在无配对数据集上，BRISQUE和NIQE平均得分分别为19.82和3.652，增强图像在阴影区域可见性、对比度平衡和细节保留方面表现优异。
- Conclusion: 该方法为无监督图像增强提供了新方向，尤其适用于语义一致性要求高的场景。


### [67] [DRAGON: A Large-Scale Dataset of Realistic Images Generated by Diffusion Models](https://arxiv.org/abs/2505.11257)
*Giulia Bertazzini,Daniele Baracchi,Dasara Shullani,Isao Echizen,Alessandro Piva*

Main category: cs.CV

TL;DR: 论文介绍了DRAGON数据集，包含25种扩散模型生成的图像，旨在支持合成内容检测技术的发展。

- Motivation: 扩散模型生成的虚假图像被用于传播错误信息和仇恨言论，需要开发有效的检测工具。现有数据集覆盖范围有限且易过时。
- Method: 提出DRAGON数据集，涵盖多种扩散模型，并利用大语言模型扩展输入提示以提升图像多样性和质量。
- Result: 数据集包含多种尺寸，支持不同研究需求，并附带专用测试集作为新方法的基准。
- Conclusion: DRAGON数据集为合成内容检测和溯源技术提供了重要资源，有助于应对虚假图像的挑战。


### [68] [Multi-view dense image matching with similarity learning and geometry priors](https://arxiv.org/abs/2505.11264)
*Mohamed Ali Chebbi,Ewelina Rupnik,Paul Lopes,Marc Pierrot-Deseilligny*

Main category: cs.CV

TL;DR: MV-DeepSimNets是一种用于多视角相似性学习的深度神经网络套件，利用极线几何训练，通过几何先验生成几何感知特征，提升多视角重建效果。

- Motivation: 传统多视角重建方法需要繁琐的数据集创建，且性能有限。MV-DeepSimNets旨在通过几何先验和深度假设投影，提升多视角重建的效率和泛化能力。
- Method: 结合极线几何和单应性矫正生成几何感知特征，通过平面扫描投影到深度假设上，聚合相似性并正则化成本体积。
- Result: 在航空和卫星图像中表现优于现有相似性学习和端到端回归模型，泛化能力强。
- Conclusion: MV-DeepSimNets通过几何先验和高效特征生成，显著提升了多视角重建性能，适用于多种分辨率图像。


### [69] [Equal is Not Always Fair: A New Perspective on Hyperspectral Representation Non-Uniformity](https://arxiv.org/abs/2505.11267)
*Wuzhou Quan,Mingqiang Wei,Jinhui Tang*

Main category: cs.CV

TL;DR: FairHyp是一个公平性导向的框架，通过专门模块解决高光谱图像（HSI）中的非均匀性问题，在分类、去噪、超分辨率和修复等任务中表现优异。

- Motivation: 高光谱图像的非均匀性导致现有模型性能不佳，FairHyp旨在通过模块化设计解决这一问题。
- Method: FairHyp结合Runge-Kutta启发的空间适配器、多感受野卷积模块和光谱上下文状态空间模型，实现维度特异性适应。
- Result: 实验表明FairHyp在多种任务中优于现有方法，验证了其有效性。
- Conclusion: FairHyp重新定义了HSI建模中的公平性，为高维视觉任务提供了新范式。


### [70] [MTevent: A Multi-Task Event Camera Dataset for 6D Pose Estimation and Moving Object Detection](https://arxiv.org/abs/2505.11282)
*Shrutarv Awasthi,Anas Gouda,Sven Franke,Jérôme Rutinowski,Frank Hoffmann,Moritz Roidl*

Main category: cs.CV

TL;DR: MTevent数据集为高速机器人感知提供支持，结合事件相机和RGB相机，解决动态环境中6D姿态估计和移动物体检测的挑战。

- Motivation: 高速移动机器人面临RGB相机在动态环境中的局限性，事件相机因其低延迟和异步特性成为潜在解决方案。
- Method: 使用立体事件相机和RGB相机捕获75个场景，涵盖极端视角、光照变化和遮挡等挑战性条件。
- Result: 在RGB图像上使用FoundationPose进行6D姿态估计，平均召回率仅为0.22，凸显RGB方法的局限性。
- Conclusion: MTevent数据集为事件视觉研究提供新资源，推动高速机器人视觉的发展。


### [71] [Breaking the Batch Barrier (B3) of Contrastive Learning via Smart Batch Mining](https://arxiv.org/abs/2505.11293)
*Raghuveer Thirukovalluru,Rui Meng,Ye Liu,Karthikeyan K,Mingyi Su,Ping Nie,Semih Yavuz,Yingbo Zhou,Wenhu Chen,Bhuwan Dhingra*

Main category: cs.CV

TL;DR: 提出了一种名为B3的新批量构建策略，通过预训练教师模型和社区检测算法优化对比学习中的负样本质量，显著提升了模型性能。

- Motivation: 对比学习的效果受批量大小和质量影响较大，现有方法需要大批量才能取得好效果。B3旨在通过优化批量构建，在小批量下也能实现高性能。
- Method: 使用预训练教师模型对数据集中的样本进行排名，构建稀疏相似图，并通过社区检测算法识别强负样本簇，以此构建高质量的批量。
- Result: 在MMEB多模态嵌入基准测试中，B3方法在7B和2B模型规模上分别比之前最佳方法提升了1.3和2.9分，且仅需64的批量大小。
- Conclusion: B3通过优化批量构建策略，显著提升了对比学习的性能，且在小批量下也能超越现有方法。


### [72] [CROC: Evaluating and Training T2I Metrics with Pseudo- and Human-Labeled Contrastive Robustness Checks](https://arxiv.org/abs/2505.11314)
*Christoph Leiter,Yuki M. Asano,Margret Keuper,Steffen Eger*

Main category: cs.CV

TL;DR: 提出了CROC框架，用于自动化评估文本到图像生成任务的评估指标，通过合成对比测试案例量化指标鲁棒性，并生成数据集CROC$^{syn}$和CROC$^{hum}$。

- Motivation: 现有评估指标在文本到图像生成任务中的适用性需要验证，而人工评估成本高且自动化方法稀缺。
- Method: 提出CROC框架，通过合成对比测试案例生成数据集CROC$^{syn}$，并训练新指标CROCScore。
- Result: CROCScore在开源方法中表现最佳，现有指标在否定提示和身体部位识别等任务中存在鲁棒性问题。
- Conclusion: CROC框架为评估指标提供了自动化解决方案，并揭示了现有指标的不足。


### [73] [Temporally-Grounded Language Generation: A Benchmark for Real-Time Vision-Language Models](https://arxiv.org/abs/2505.11326)
*Keunwoo Peter Yu,Joyce Chai*

Main category: cs.CV

TL;DR: 该论文提出了一种新的基准任务TGLG，用于评估视觉语言模型在实时交互环境中的表现，并提出了VLM-TSI模型，显著优于基线方法。

- Motivation: 研究视觉语言模型在实时交互环境中的表现，解决其生成语义准确且时间精确的语句的需求。
- Method: 提出TGLG基准任务和TRACE评估指标，并开发VLM-TSI模型，通过时间同步交错视觉和语言令牌实现实时语言生成。
- Result: VLM-TSI显著优于基线方法，但整体性能仍有限，表明TGLG任务的挑战性。
- Conclusion: TGLG任务具有挑战性，需要进一步研究实时视觉语言模型。


### [74] [MARRS: Masked Autoregressive Unit-based Reaction Synthesis](https://arxiv.org/abs/2505.11334)
*Y. B. Wang,S Wang,J. N. Zhang,J. F. Wu,Q. D. He,C. C. Fu,C. J. Wang,Y. Liu*

Main category: cs.CV

TL;DR: 该论文提出了一种名为MARRS的新框架，用于生成协调且细粒度的人类反应动作，解决了现有方法在信息损失和代码本利用率低等问题。

- Motivation: 当前的自回归建模方法在动作生成任务中表现优异，但在人类动作-反应合成任务中存在量化信息损失和代码本利用率低等问题，尤其是涉及细粒度手部动作时。
- Method: 提出MARRS框架，包括Unit-distinguished Motion VAE（UD-VAE）独立编码身体和手部单元，Action-Conditioned Fusion（ACF）提取特定信息，以及Adaptive Unit Modulation（AUM）促进单元间交互。
- Result: 定量和定性结果表明，该方法在生成协调且细粒度的反应动作方面表现优异。
- Conclusion: MARRS框架通过独立编码和单元间交互，显著提升了人类动作-反应合成的性能。


### [75] [Dynamic Base model Shift for Delta Compression](https://arxiv.org/abs/2505.11344)
*Chenyu Huang,Peng Ye,Shenghe Zheng,Xiaohui Wang,Lei Bai,Tao Chen,Wanli Ouyang*

Main category: cs.CV

TL;DR: 论文提出动态基础模型转移（DBMS）方法，通过调整基础模型和压缩规模参数，显著提升高压缩率下的性能。

- Motivation: 现有方法以预训练模型为基础压缩增量参数，可能导致性能下降，尤其是在高压缩率下。
- Method: 动态调整基础模型和压缩规模参数，优化增量压缩性能。
- Result: DBMS在高压缩率下仍能保持微调模型性能，显著优于现有方法。
- Conclusion: DBMS是一种通用方法，可与其他技术结合，适用于多种模型类型。


### [76] [Dynam3D: Dynamic Layered 3D Tokens Empower VLM for Vision-and-Language Navigation](https://arxiv.org/abs/2505.11383)
*Zihan Wang,Seungjun Lee,Gim Hee Lee*

Main category: cs.CV

TL;DR: Dynam3D提出了一种动态分层的3D表示模型，用于解决视觉与语言导航（VLN）任务中3D几何与空间语义理解不足、大规模探索能力有限及动态环境适应性差的问题。

- Motivation: 现有视频-语言大模型（Video-VLMs）在VLN任务中表现优异，但在实际3D导航中仍面临3D几何理解不足、大规模探索能力有限和动态环境适应性差等挑战。
- Method: Dynam3D通过将2D CLIP特征投影到3D空间，构建多层次3D表示（patch-instance-zone），并采用动态分层更新策略，实现3D几何与语义理解。
- Result: Dynam3D在多个VLN基准测试（R2R-CE、REVERIE-CE、NavRAG-CE）中取得最优性能，并通过预探索、长期记忆和真实机器人实验验证了其实用性。
- Conclusion: Dynam3D通过动态分层3D表示和大规模3D-语言预训练，显著提升了VLN任务的性能，适用于实际部署。


### [77] [MutualNeRF: Improve the Performance of NeRF under Limited Samples with Mutual Information Theory](https://arxiv.org/abs/2505.11386)
*Zifan Wang,Jingwei Li,Yitang Li,Yunze Liu*

Main category: cs.CV

TL;DR: MutualNeRF利用互信息理论提升NeRF在有限样本下的性能，通过统一度量图像相关性优化稀疏视角采样和少视角合成。

- Motivation: NeRF在3D场景合成中表现优异，但在有限数据下性能受限，现有方法缺乏统一的理论支持。
- Method: 引入互信息作为度量标准，通过贪婪算法优化稀疏视角采样，并通过正则化项最大化少视角合成中的互信息。
- Result: 实验表明，MutualNeRF在有限样本下优于现有基线方法。
- Conclusion: MutualNeRF通过互信息理论有效提升了NeRF在有限数据下的性能。


### [78] [Patho-R1: A Multimodal Reinforcement Learning-Based Pathology Expert Reasoner](https://arxiv.org/abs/2505.11404)
*Wenchuan Zhang,Penghao Zhang,Jingru Guo,Tao Cheng,Jie Chen,Shuwan Zhang,Zhang Zhang,Yuhao Yi,Hong Bu*

Main category: cs.CV

TL;DR: 论文提出Patho-R1，一种基于多模态强化学习的病理学推理模型，通过高质量数据集和三阶段训练提升诊断准确性和推理能力。

- Motivation: 当前病理学视觉语言模型在诊断准确性和推理合理性上存在局限，主要由于数据集缺乏深度和结构化诊断信息。
- Method: 利用病理学教科书和专家构建高质量数据集，采用三阶段训练：知识注入、监督微调推理、强化学习优化。
- Result: Patho-R1和PathoCLIP在多项病理学任务中表现优异，包括零样本分类、跨模态检索和问答。
- Conclusion: Patho-R1通过高质量数据集和多阶段训练显著提升了病理学推理能力，为医学领域提供了新工具。


### [79] [EmotionHallucer: Evaluating Emotion Hallucinations in Multimodal Large Language Models](https://arxiv.org/abs/2505.11405)
*Bohao Xing,Xin Liu,Guoying Zhao,Chengyu Liu,Xiaolan Fu,Heikki Kälviäinen*

Main category: cs.CV

TL;DR: 该论文提出了首个用于检测和分析多模态大语言模型（MLLMs）中情绪幻觉的基准EmotionHallucer，并揭示了当前模型在此问题上的表现。

- Motivation: 情绪理解是重要但具有挑战性的任务，而MLLMs常因幻觉生成无关或无意义内容。目前缺乏对情绪相关幻觉的专门评估。
- Method: 基于情绪心理学知识和真实世界多模态感知，使用对抗性二元问答框架评估38个LLMs和MLLMs。
- Result: 发现多数模型存在情绪幻觉问题，闭源模型表现优于开源模型，且推理能力提供额外优势。
- Conclusion: 论文提出的PEP-MEK框架将情绪幻觉检测平均提升9.90%。


### [80] [Improving Object Detection Performance through YOLOv8: A Comprehensive Training and Evaluation Study](https://arxiv.org/abs/2505.11424)
*Rana Poureskandar,Shiva Razzagzadeh*

Main category: cs.CV

TL;DR: 评估YOLOv8分割模型在面部皱纹检测与分割中的性能。

- Motivation: 研究旨在验证YOLOv8模型在面部皱纹检测与分割任务中的有效性。
- Method: 采用YOLOv8分割模型处理面部图像，检测并分割皱纹。
- Result: 研究展示了模型在皱纹检测与分割任务中的表现。
- Conclusion: YOLOv8模型在面部皱纹检测与分割中具有潜力。


### [81] [Face Consistency Benchmark for GenAI Video](https://arxiv.org/abs/2505.11425)
*Michal Podstawski,Malgorzata Kudelska,Haohong Wang*

Main category: cs.CV

TL;DR: 论文提出了Face Consistency Benchmark (FCB)，用于评估AI生成视频中角色一致性的框架，填补现有解决方案的不足。

- Motivation: 当前AI视频生成技术在角色一致性方面存在挑战，缺乏标准化评估方法。
- Method: 引入FCB框架，提供标准化指标评估角色一致性。
- Result: FCB揭示了现有解决方案的不足，推动更可靠方法的发展。
- Conclusion: 该研究是提升AI视频生成中角色一致性的重要一步。


### [82] [SurgPose: Generalisable Surgical Instrument Pose Estimation using Zero-Shot Learning and Stereo Vision](https://arxiv.org/abs/2505.11439)
*Utsav Rai,Haozheng Xu,Stamatia Giannarou*

Main category: cs.CV

TL;DR: 论文提出了一种基于零样本RGB-D模型的6自由度手术工具姿态估计方法，结合RAFT-Stereo深度估计和改进的SAM-6D，显著提升了在未见手术工具上的姿态估计性能。

- Motivation: 传统标记方法和监督学习方法在手术工具姿态估计中存在局限性，如遮挡、反射和泛化能力不足。零样本方法在RMIS中尚未探索，本文旨在填补这一空白。
- Method: 结合FoundationPose和SAM-6D等零样本RGB-D模型，引入RAFT-Stereo进行深度估计，并改进SAM-6D的分割模块为Mask R-CNN，提升分割精度。
- Result: 改进的SAM-6D在零样本姿态估计中优于FoundationPose，为RMIS中的RGB-D零样本方法设定了新基准。
- Conclusion: 本文提升了零样本姿态估计的泛化能力，并首次将RGB-D零样本方法应用于RMIS。


### [83] [HumaniBench: A Human-Centric Framework for Large Multimodal Models Evaluation](https://arxiv.org/abs/2505.11454)
*Shaina Raza,Aravind Narayanan,Vahid Reza Khazaie,Ashmal Vayani,Mukund S. Chettiar,Amandeep Singh,Mubarak Shah,Deval Pandya*

Main category: cs.CV

TL;DR: HumaniBench是一个包含32K真实世界图像-问题对的基准测试，用于评估大型多模态模型（LMMs）在公平性、伦理、同理心等人类中心AI原则上的表现。

- Motivation: 尽管LMMs在视觉语言任务上表现优异，但在公平性、伦理等人类价值观对齐方面仍有不足，因此需要专门的评估工具。
- Method: 通过GPT4辅助的标注流程构建HumaniBench，涵盖7项人类中心AI原则和7种任务，评估15种LMMs。
- Result: 专有模型表现较好，但稳健性和视觉定位仍是弱点；开源模型在准确性与人类对齐原则的平衡上存在困难。
- Conclusion: HumaniBench是首个围绕人类中心AI原则设计的基准测试，为诊断对齐差距和指导LMMs提供工具。


### [84] [PSDiffusion: Harmonized Multi-Layer Image Generation via Layout and Appearance Alignment](https://arxiv.org/abs/2505.11468)
*Dingbang Huang,Wenbo Li,Yifei Zhao,Xinyu Pan,Yanhong Zeng,Bo Dai*

Main category: cs.CV

TL;DR: PSDiffusion提出了一种统一的扩散框架，用于同时生成多层文本到图像，解决了现有方法在多层交互和全局一致性上的不足。

- Motivation: 现有多层生成方法无法处理层间交互（如全局布局、物理接触和视觉效果），同时保持高质量的透明度。
- Method: PSDiffusion通过全局层交互机制，单次前馈过程生成多层图像（RGB背景和多个RGBA前景）。
- Result: 模型能同时生成高质量且完整的各层图像，并确保层间的空间和视觉交互以实现全局一致性。
- Conclusion: PSDiffusion为多层图像生成提供了一种高效且一致的方法。


### [85] [Unsupervised Detection of Distribution Shift in Inverse Problems using Diffusion Models](https://arxiv.org/abs/2505.11482)
*Shirin Shoushtari,Edward P. Chandler,Yuanhao Wang,M. Salman Asif,Ulugbek S. Kamilov*

Main category: cs.CV

TL;DR: 提出了一种无监督度量方法，利用间接测量和扩散模型的评分函数估计分布偏移，无需干净测试图像。

- Motivation: 解决扩散模型在成像逆问题中因分布偏移导致的性能下降问题，且无需干净测试图像。
- Method: 提出基于评分的无监督度量方法，利用间接测量和不同数据集的扩散模型评分函数估计KL散度。
- Result: 该度量方法仅使用损坏测量即可近似干净图像的KL散度，并通过对齐分布评分提升重建质量。
- Conclusion: 无监督评分度量方法有效估计分布偏移并改善逆问题重建效果。


### [86] [GIE-Bench: Towards Grounded Evaluation for Text-Guided Image Editing](https://arxiv.org/abs/2505.11493)
*Yusu Qian,Jiasen Lu,Tsu-Jui Fu,Xinze Wang,Chen Chen,Yinfei Yang,Wenze Hu,Zhe Gan*

Main category: cs.CV

TL;DR: 该论文提出了一个新的基准GIE-Bench，用于更准确地评估文本引导的图像编辑模型，重点关注功能正确性和图像内容保留。

- Motivation: 现有评估方法（如CLIP）缺乏精确性，需要一种更可靠的评估框架。
- Method: 通过自动生成多选题验证功能正确性，并使用对象感知掩码技术评估内容保留。
- Result: GPT-Image-1在指令遵循准确性上领先，但存在过度修改非目标区域的问题。
- Conclusion: GIE-Bench为文本引导图像编辑提供了可扩展且可复现的评估框架。


### [87] [QVGen: Pushing the Limit of Quantized Video Generative Models](https://arxiv.org/abs/2505.11497)
*Yushi Huang,Ruihao Gong,Jing Liu,Yifu Ding,Chengtao Lv,Haotong Qin,Jun Zhang*

Main category: cs.CV

TL;DR: QVGen是一个针对视频扩散模型（DMs）的量化感知训练框架，能够在极低位（如4位或更低）量化下实现高性能和高效推理。

- Motivation: 视频扩散模型的高计算和内存需求限制了其实际部署，现有量化方法直接应用于视频DMs效果不佳。
- Method: 提出QVGen框架，引入辅助模块（Φ）减少量化误差，并通过秩衰减策略逐步消除Φ以消除推理开销。
- Result: 在4位量化下，QVGen首次实现与全精度模型相当的质量，并在多项指标上显著优于现有方法。
- Conclusion: QVGen为视频DMs的高效量化提供了有效解决方案，显著提升了性能并减少了计算成本。
## cs.LG

### [88] [A probabilistic framework for dynamic quantization](https://arxiv.org/abs/2505.10689)
*Gabriele Santini,Francesco Paissan,Elisabetta Farella*

Main category: cs.LG

TL;DR: 提出一种动态量化神经网络的概率框架，通过轻量级代理模型自适应调整量化参数，实现高效计算且性能损失可忽略。

- Motivation: 解决传统量化方法在动态输入下性能下降的问题，同时减少计算和内存开销。
- Method: 使用概率模型和轻量级代理模型，动态调整每输入样本的量化参数。
- Result: 在计算机视觉任务中验证，性能损失极小，优于标准量化策略。
- Conclusion: 该方法在性能和计算开销之间取得了最佳平衡。


### [89] [Hashing for Structure-based Anomaly Detection](https://arxiv.org/abs/2505.10873)
*Filippo Leveni,Luca Magri,Cesare Alippi,Giacomo Boracchi*

Main category: cs.LG

TL;DR: 提出了一种基于低维流形结构的高效异常检测方法，通过高维嵌入和局部敏感哈希技术降低计算成本。

- Motivation: 解决在低维流形结构中识别异常样本的问题，提高检测效率。
- Method: 利用高维嵌入（Preference Space）和局部敏感哈希技术，避免显式计算高维距离。
- Result: 提出的方法在异常检测中达到最先进性能，且计算成本更低。
- Conclusion: 该方法在高效性和性能上表现优异，代码已开源。


### [90] [MultiLink: Multi-class Structure Recovery via Agglomerative Clustering and Model Selection](https://arxiv.org/abs/2505.10874)
*Luca Magri,Filippo Leveni,Giacomo Boracchi*

Main category: cs.LG

TL;DR: 论文提出了一种名为MultiLink的新算法，用于在噪声和异常值污染的数据集中恢复多种不同类别的结构。该方法通过偏好分析和聚类同时处理多类别模型，具有速度快、对阈值不敏感等优势。

- Motivation: 解决在噪声和异常值污染的数据集中恢复多种不同类别结构的问题，特别是几何结构。
- Method: 提出MultiLink算法，结合动态模型拟合和模型选择，通过新的链接方案决定是否合并两个聚类。
- Result: 实验表明，MultiLink在多类别和单类别问题上优于现有方法，且代码已公开。
- Conclusion: MultiLink是一种高效且鲁棒的方法，适用于多类别结构的恢复问题。


### [91] [Preference Isolation Forest for Structure-based Anomaly Detection](https://arxiv.org/abs/2505.10876)
*Filippo Leveni,Luca Magri,Cesare Alippi,Giacomo Boracchi*

Main category: cs.LG

TL;DR: 论文提出了一种名为偏好隔离森林（PIF）的通用异常检测框架，结合了自适应隔离方法和偏好嵌入的灵活性，通过将数据嵌入高维偏好空间来识别异常点。

- Motivation: 解决检测不符合低维流形结构模式的异常样本的问题。
- Method: 提出PIF框架，包含三种隔离方法：Voronoi-iForest、RuzHash-iForest和Sliding-PIF，分别基于Voronoi图、局部敏感哈希和局部性先验。
- Result: 通过高维偏好空间嵌入和隔离方法有效识别异常点。
- Conclusion: PIF框架在异常检测中表现出高效性和灵活性，适用于多种场景。


### [92] [CTP: A hybrid CNN-Transformer-PINN model for ocean front forecasting](https://arxiv.org/abs/2505.10894)
*Yishuo Wang,Feng Zhou,Muping Zhou,Qicheng Meng,Zhijun Hu,Yi Wang*

Main category: cs.LG

TL;DR: 提出了一种结合CNN、Transformer和PINN的新框架CTP，用于海洋锋面预测，解决了现有方法在空间连续性和物理一致性上的不足。

- Motivation: 海洋锋面在海洋生物地球化学和物理过程中起关键作用，但现有方法如LSTM、ConvLSTM等在多步预测中难以保持空间连续性和物理一致性。
- Method: CTP整合了局部空间编码、长程时间注意力和物理约束，结合CNN、Transformer和PINN。
- Result: 在南海和黑潮区域的实验中，CTP在单步和多步预测中均达到SOTA性能，显著优于基线模型。
- Conclusion: CTP通过结合多种技术，显著提升了海洋锋面预测的准确性和稳定性。


### [93] [Assessing the Performance of Analog Training for Transfer Learning](https://arxiv.org/abs/2505.11067)
*Omobayode Fagbohungbe,Corey Lammie,Malte J. Rasch,Takashi Ando,Tayfun Gokmen,Vijay Narayanan*

Main category: cs.LG

TL;DR: 本文介绍了一种名为c-TTv2的新算法，用于解决模拟内存计算中设备非线性和不对称性带来的训练挑战，并在Swin-ViT模型上评估其性能。

- Motivation: 模拟内存计算具有快速、并行和高效的特点，但现有训练算法无法应对设备的非线性和不对称性，限制了其潜力。
- Method: 提出c-TTv2算法，利用chopped技术解决设备特性问题，并在Swin-ViT模型和CIFAR100数据集上进行评估。
- Result: c-TTv2算法在模拟迁移学习中表现出色，并对设备参数变化（如权重噪声、对称点偏移等）具有鲁棒性。
- Conclusion: c-TTv2算法为模拟内存计算提供了一种有效的训练解决方案，解决了现有算法的局限性。


### [94] [What's Inside Your Diffusion Model? A Score-Based Riemannian Metric to Explore the Data Manifold](https://arxiv.org/abs/2505.11128)
*Simone Azeglio,Arianna Di Bernardo*

Main category: cs.LG

TL;DR: 论文提出了一种基于分数的黎曼度量方法，利用扩散模型中的Stein分数函数刻画数据流形的内在几何特性，无需显式参数化。该方法通过定义环境空间中的度量张量，有效生成沿流形轮廓的自然测地线，并在实验中优于基线方法。

- Motivation: 尽管扩散模型在捕捉复杂图像分布方面表现出色，但其学习的数据流形的几何特性仍未被充分理解。本文旨在填补这一空白。
- Method: 引入基于分数的黎曼度量，利用Stein分数函数定义度量张量，生成沿流形轮廓的测地线，并开发高效算法计算这些测地线。
- Result: 在合成数据、Rotated MNIST和自然图像实验中，该方法在感知指标（LPIPS）和分布级指标（FID、KID）上优于基线，生成更平滑、更真实的图像过渡。
- Conclusion: 该方法揭示了扩散模型学习的隐式几何结构，为通过黎曼几何导航自然图像流形提供了理论基础。


### [95] [Towards Robust Spiking Neural Networks:Mitigating Heterogeneous Training Vulnerability via Dominant Eigencomponent Projection](https://arxiv.org/abs/2505.11134)
*Desong Zhang,Jia Hu,Geyong Min*

Main category: cs.LG

TL;DR: SNNs trained with direct encoding and BPTT are vulnerable to catastrophic collapse from slight data distribution shifts. DEP method mitigates this by reducing Hessian spectral radius.

- Motivation: SNNs' energy efficiency is offset by vulnerability to heterogeneous data, risking deployment reliability.
- Method: Developed Dominant Eigencomponent Projection (DEP) to orthogonally project gradients, reducing Hessian spectral radius.
- Result: DEP enhances SNN robustness against data poisoning and outperforms baselines.
- Conclusion: DEP provides a safer, more reliable method for SNN deployment by addressing inherent vulnerabilities.


### [96] [Maximizing Asynchronicity in Event-based Neural Networks](https://arxiv.org/abs/2505.11165)
*Haiqing Hao,Nikola Zubić,Weihua He,Zhipeng Sui,Davide Scaramuzza,Wenhui Wang*

Main category: cs.LG

TL;DR: EVA是一种新型异步到同步（A2S）框架，通过事件异步表示学习生成高表达性和泛化性的表示，在识别和检测任务中表现优异。

- Motivation: 事件相机的高时间分辨率、低延迟和低冗余特性挑战了传统基于张量的机器学习方法，现有A2S方法在表达性和泛化性上不足。
- Method: EVA借鉴语言建模中的线性注意力和自监督学习技术，构建事件异步表示。
- Result: EVA在DVS128-Gesture和N-Cars识别任务中优于现有A2S方法，并在Gen1检测任务中达到47.7 mAP。
- Conclusion: EVA展示了在实时事件视觉应用中的变革潜力。


### [97] [Visual Planning: Let's Think Only with Images](https://arxiv.org/abs/2505.11409)
*Yi Xu,Chengzu Li,Han Zhou,Xingchen Wan,Caiqi Zhang,Anna Korhonen,Ivan Vulić*

Main category: cs.LG

TL;DR: 论文提出了一种新的视觉规划范式（Visual Planning），通过纯视觉表示进行推理，优于传统的文本推理方法。

- Motivation: 语言可能并非所有任务中最自然或有效的推理模态，尤其是在涉及空间和几何信息的任务中。
- Method: 提出了视觉规划范式，通过图像序列执行推理，并引入VPRL（基于GRPO的强化学习框架）来优化视觉模型。
- Result: 在FrozenLake、Maze和MiniBehavior等视觉导航任务中，视觉规划优于纯文本推理方法。
- Conclusion: 视觉规划是一种可行且有前景的替代语言推理的方法，为图像化推理任务开辟了新途径。
## cs.RO

### [98] [TartanGround: A Large-Scale Dataset for Ground Robot Perception and Navigation](https://arxiv.org/abs/2505.10696)
*Manthan Patel,Fan Yang,Yuheng Qiu,Cesar Cadena,Sebastian Scherer,Marco Hutter,Wenshan Wang*

Main category: cs.RO

TL;DR: TartanGround是一个大规模多模态数据集，旨在提升地面机器人在多样化环境中的感知与自主能力。

- Motivation: 现有数据集在多样化场景中泛化能力不足，TartanGround旨在填补这一空白。
- Method: 通过集成自动管道收集数据，模拟多种地面机器人运动模式，涵盖多种传感器数据。
- Result: 收集了910条轨迹和1.5百万样本，现有方法在多样化场景中泛化能力不足。
- Conclusion: TartanGround可作为训练和评估学习任务的测试平台，推动机器人感知与自主能力的进步。


### [99] [GrowSplat: Constructing Temporal Digital Twins of Plants with Gaussian Splats](https://arxiv.org/abs/2505.10923)
*Simeon Adebola,Shuangyu Xie,Chung Min Kim,Justin Kerr,Bart M. van Marrewijk,Mieke van Vlaardingen,Tim van Daalen,Robert van Loo,Jose Luis Susa Rincon,Eugen Solowjow,Rick van de Zedde,Ken Goldberg*

Main category: cs.RO

TL;DR: 提出了一种结合3D高斯泼溅和样本对齐管道的新框架，用于构建植物的时间数字孪生，解决了植物生长重建中的复杂几何、遮挡和非刚性变形问题。

- Motivation: 植物生长的精确时间重建对表型分析和育种至关重要，但由于复杂的几何形状、遮挡和非刚性变形，这一任务具有挑战性。
- Method: 首先从多视角相机数据重建高斯泼溅，然后采用两阶段配准方法：基于特征的粗对齐和快速全局配准，再通过迭代最近点进行精细对齐。
- Result: 在荷兰植物表型中心的数据上评估了该方法，成功重建了红杉和藜麦物种的详细时间模型。
- Conclusion: 该方法能够生成一致的4D植物发育模型，为植物表型分析提供了有效工具。


### [100] [DexGarmentLab: Dexterous Garment Manipulation Environment with Generalizable Policy](https://arxiv.org/abs/2505.11032)
*Yuran Wang,Ruihai Wu,Yue Chen,Jiarui Wang,Jiaqi Liang,Ziyu Zhu,Haoran Geng,Jitendra Malik,Pieter Abbeel,Hao Dong*

Main category: cs.RO

TL;DR: 论文提出了DexGarmentLab环境，专注于灵巧（尤其是双手）的衣物操作，并提出了HALO算法以提高泛化能力。

- Motivation: 衣物操作的多样性和变形性使其成为挑战，现有研究缺乏真实的灵巧操作模拟。
- Method: 提出DexGarmentLab环境，利用衣物结构对应性自动生成数据集，并设计HALO算法（分层衣物操作策略）以提高泛化能力。
- Result: HALO在实验中表现优于现有方法，能泛化到未见过的衣物形状和变形情况。
- Conclusion: DexGarmentLab和HALO为衣物操作提供了高效解决方案，显著减少了人工干预并提升了泛化性能。


### [101] [Planar Velocity Estimation for Fast-Moving Mobile Robots Using Event-Based Optical Flow](https://arxiv.org/abs/2505.11116)
*Liam Boyle,Jonas Kühne,Nicolas Baumann,Niklas Bastuck,Michele Magno*

Main category: cs.RO

TL;DR: 提出了一种基于事件相机和平面运动学的速度估计方法，解决了传统轮式里程计和IMU融合方法在复杂环境下的局限性。

- Motivation: 移动机器人（如自动驾驶）需要精确的速度估计，但传统方法依赖强假设或复杂模型，难以适应多变环境。
- Method: 结合事件相机的光流和平面运动学，无需依赖轮地接触假设，提高了鲁棒性。
- Result: 实验表明，该方法性能与现有方法相当，横向误差降低38.3%，并在高速场景下验证了有效性。
- Conclusion: 该方法在复杂环境中表现优异，具有实际应用潜力。


### [102] [Open-Source Multi-Viewpoint Surgical Telerobotics](https://arxiv.org/abs/2505.11142)
*Guido Caccianiga,Yarden Sharon,Bernard Javot,Senya Polikovsky,Gökce Ergün,Ivan Capobianco,André L. Mihaljevic,Anton Deguet,Katherine J. Kuchenbecker*

Main category: cs.RO

TL;DR: 论文探讨了通过引入多视角可视化与控制范式提升微创手术机器人系统的协作与感知能力。

- Motivation: 重新思考并扩展手术远程操作的视觉化与控制范式，以提升手术协作与机器感知的鲁棒性。
- Method: 构建同步多视角、多传感器的手术机器人系统，集成高性能视觉组件并升级控制逻辑。
- Result: 系统支持多视角协作、独立调整视图及实时3D感知，为共享自治提供基础。
- Conclusion: 开源系统将促进研究社区的发展，加速前沿研究的临床转化。


### [103] [Exploiting Radiance Fields for Grasp Generation on Novel Synthetic Views](https://arxiv.org/abs/2505.11467)
*Abhishek Kashyap,Henrik Andreasson,Todor Stoyanov*

Main category: cs.RO

TL;DR: 论文探讨了基于视觉的机器人抓取中，利用高斯泼溅技术合成新视角图像以提高抓取精度和覆盖率。

- Motivation: 多视角图像能提高抓取精度，但移动相机耗时且可能受限，因此探索通过合成新视角补充信息。
- Method: 使用高斯泼溅技术合成新视角图像，并在Graspnet-1billion数据集上验证效果。
- Result: 合成视角补充了稀疏真实视角的抓取信息，提高了抓取覆盖率和力闭合抓取数量。
- Conclusion: 未来可扩展至单图像构建辐射场，结合扩散模型或通用辐射场进一步优化抓取提取。
## stat.ML

### [104] [A Fourier Space Perspective on Diffusion Models](https://arxiv.org/abs/2505.11278)
*Fabian Falck,Teodora Pandeva,Kiarash Zahirnia,Rachel Lawrence,Richard Turner,Edward Meeds,Javier Zazo,Sushrut Karmalkar*

Main category: stat.ML

TL;DR: 扩散模型在图像、音频等数据模态中表现出色，但其前向过程在傅里叶空间中存在高频信息快速损坏的问题，导致生成质量下降。通过调整前向过程，使所有频率以相同速率损坏，可显著提升高频主导数据集的性能。

- Motivation: 研究扩散模型前向过程在傅里叶空间中的归纳偏差，揭示高频信息快速损坏对生成质量的影响。
- Method: 理论分析和实验验证DDPM前向过程在傅里叶空间中的问题，并提出一种新的前向过程，使所有频率以相同速率损坏。
- Result: 新方法在高频主导数据集上表现显著提升，在标准图像基准上与DDPM相当。
- Conclusion: 调整前向过程的频率损坏速率可改善扩散模型的生成质量，尤其适用于高频信息重要的场景。
## eess.IV

### [105] [GRNN:Recurrent Neural Network based on Ghost Features for Video Super-Resolution](https://arxiv.org/abs/2505.10577)
*Yutong Guo*

Main category: eess.IV

TL;DR: 论文提出了一种基于“Ghost特征”的方法，以减少视频超分辨率（VSR）模型中的特征冗余，并结合RNN解决梯度消失问题，提升了PSNR和SSIM指标。

- Motivation: 现代基于CNN的VSR系统计算成本高，且存在特征冗余问题，但这一问题在VSR领域很少被讨论。
- Method: 提出使用“Ghost特征”减少冗余，结合RNN解决梯度消失问题，输入包括当前帧、下一帧、前一帧输出和隐藏状态。
- Result: 在多个基准模型和数据集上，PSNR和SSIM有所提升，视频纹理细节保留更好。
- Conclusion: Ghost特征和RNN的结合有效减少了VSR模型的计算成本和特征冗余，同时提升了性能。


### [106] [ExploreGS: a vision-based low overhead framework for 3D scene reconstruction](https://arxiv.org/abs/2505.10578)
*Yunji Feng,Chengpu Yu,Fengrui Ran,Zhi Yang,Yinni Liu*

Main category: eess.IV

TL;DR: ExploreGS是一种基于视觉的低开销3D场景重建框架，用于无人机，通过RGB图像替代传统激光雷达点云采集，实现低成本高质量重建。

- Motivation: 传统激光雷达点云采集成本高，而无人机需要轻量级、低成本的3D重建方案。
- Method: 结合场景探索与模型重建，利用BoW模型实现实时处理，支持机载3D高斯泼溅（3DGS）训练。
- Result: 在仿真和真实环境中验证了框架的高效性和适用性，重建质量与先进方法相当。
- Conclusion: ExploreGS为资源受限设备提供了一种高效、低成本的3D重建解决方案。


### [107] [MOSAIC: A Multi-View 2.5D Organ Slice Selector with Cross-Attentional Reasoning for Anatomically-Aware CT Localization in Medical Organ Segmentation](https://arxiv.org/abs/2505.10672)
*Hania Ghouse,Muzammil Behzad*

Main category: eess.IV

TL;DR: 提出了一种基于视觉语言模型（VLM）的解剖感知切片选择器，用于高效多器官分割，并引入新指标SLC评估定位精度。

- Motivation: 现有3D分割方法计算和内存消耗大，2D方法缺乏上下文感知且存在类别不平衡问题，需改进。
- Method: 使用VLM融合三视图（2.5D）表示，选择性保留结构相关切片，减少输入量。
- Result: 模型在所有器官上显著优于基线，实现了高效且空间一致的器官切片过滤。
- Conclusion: 该方法显著降低下游分割成本，同时保持高解剖保真度。


### [108] [ROIsGAN: A Region Guided Generative Adversarial Framework for Murine Hippocampal Subregion Segmentation](https://arxiv.org/abs/2505.10687)
*Sayed Mehedi Azim,Brian Corbett,Iman Dehzangi*

Main category: eess.IV

TL;DR: 论文提出了一种名为ROIsGAN的新方法，用于自动分割海马体亚区，并提供了四个新的IHC数据集。该方法在性能上优于传统模型。

- Motivation: 海马体亚区的精确分割对理解疾病机制和开发治疗方法至关重要，但目前缺乏针对组织图像的自动化分割方法。
- Method: 提出ROIsGAN，一种基于U-Net的生成对抗网络，结合区域引导判别器损失（Dice和二元交叉熵损失）优化边界和结构细节。
- Result: ROIsGAN在DG、CA1和CA3亚区的分割性能上优于传统模型，Dice得分提升1-10%，IoU提升达11%。
- Conclusion: 该研究为海马体亚区的自动化分割提供了基础数据集和方法，支持神经科学研究的可扩展高精度分析。


### [109] [Predicting Risk of Pulmonary Fibrosis Formation in PASC Patients](https://arxiv.org/abs/2505.10691)
*Wanying Dou,Gorkem Durak,Koushik Biswas,Ziliang Hong,Andrea Mia Bejar,Elif Keles,Kaan Akin,Sukru Mehmet Erturk,Alpay Medetalibeyoglu,Marc Sala,Alexander Misharin,Hatice Savas,Mary Salvatore,Sachin Jambawalikar,Drew Torigian,Jayaram K. Udupa,Ulas Bagci*

Main category: eess.IV

TL;DR: 本文提出了一种结合深度学习和放射组学的多中心胸部CT分析框架，用于预测COVID-19后遗症（PASC）相关的肺纤维化，准确率达82.2%，AUC为85.5%。

- Motivation: PASC（长期COVID）症状多样且持续时间不确定，肺纤维化是重要表现之一，但临床评估和诊断面临挑战。
- Method: 采用卷积神经网络（CNN）和可解释特征提取的深度学习方法，结合放射组学分析胸部CT影像。
- Result: 模型在分类任务中达到82.2%准确率和85.5% AUC，并通过Grad-CAM可视化和特征分析提供临床见解。
- Conclusion: 深度学习驱动的计算方法在PASC相关肺纤维化的早期检测和风险评估中具有潜力。


### [110] [Adaptive Spatial Transcriptomics Interpolation via Cross-modal Cross-slice Modeling](https://arxiv.org/abs/2505.10729)
*NingFeng Que,Xiaofei Wang,Jingjing Chen,Yixuan Jiang,Chao Li*

Main category: eess.IV

TL;DR: C2-STi是一种用于在相邻空间转录组学（ST）切片之间插值缺失切片的新方法，解决了ST分析中因缺失切片和高成本导致的限制。

- Motivation: 空间转录组学（ST）分析需要连续切片以获得3D空间信息，但缺失切片和高成本限制了多切片ST的生成。
- Method: C2-STi设计了三个模块：1）距离感知局部结构调制模块，2）金字塔基因共表达相关模块，3）跨模态对齐模块，以解决ST插值的挑战。
- Result: 在公开数据集上的实验表明，C2-STi在单切片和多切片ST插值上优于现有方法。
- Conclusion: C2-STi为ST插值提供了一种高效且灵活的方法，填补了技术空白。


### [111] [Pretrained hybrid transformer for generalizable cardiac substructures segmentation from contrast and non-contrast CTs in lung and breast cancers](https://arxiv.org/abs/2505.10855)
*Aneesh Rangnekar,Nikhil Mankuzhy,Jonas Willmann,Chloe Choi,Abraham Wu,Maria Thor,Andreas Rimner,Harini Veeraraghavan*

Main category: eess.IV

TL;DR: 论文提出了一种混合变压器卷积网络（HTN），用于在成像对比和患者扫描位置不同的情况下分割心脏亚结构，并在几何和剂量指标上表现出鲁棒性。

- Motivation: AI自动分割在临床应用中可能因训练数据与临床案例特征不同而性能下降，因此需要一种鲁棒的方法来适应不同成像条件和患者位置。
- Method: 通过改进预训练的变压器为混合变压器卷积网络（HTN），并在平衡和不平衡数据集上训练模型，评估其在验证集上的性能。
- Result: 平衡模型在几何和剂量指标上与人工标注相似，且在6/8亚结构中对CT对比度变化鲁棒，在5/8亚结构中对患者扫描位置变化鲁棒。
- Conclusion: HTN在成像和患者特征变化的情况下表现出鲁棒的准确性，且通过平衡数据集训练，可用更少的标注数据实现可靠的分割。


### [112] [Generative Models in Computational Pathology: A Comprehensive Survey on Methods, Applications, and Challenges](https://arxiv.org/abs/2505.10993)
*Yuan Zhang,Xinfeng Zhang,Xiaoming Qi Xinyu Wu,Feng Chen,Guanyu Yang,Huazhu Fu*

Main category: eess.IV

TL;DR: 综述回顾了生成模型在计算病理学中的进展，涵盖图像、文本、多模态生成等方向，分析了150多项研究，并探讨了挑战与未来方向。

- Motivation: 生成模型在计算病理学中展现出潜力，如高效学习、数据增强和多模态表示，但面临高保真生成、临床解释性等挑战。
- Method: 通过分析150多项代表性研究，梳理了从GAN到扩散模型等生成架构的演变，并总结了数据集和评估方法。
- Result: 总结了生成模型在病理学中的应用现状，指出了高保真全切片图像生成、伦理法律问题等局限性。
- Conclusion: 未来需开发统一、多模态且临床可部署的生成系统，为研究者和从业者提供参考。


### [113] [Diffusion Model in Hyperspectral Image Processing and Analysis: A Review](https://arxiv.org/abs/2505.11158)
*Xing Hu,Xiangcheng Liu,Qianqian Duan,Danfeng Hong,Dawei Zhang*

Main category: eess.IV

TL;DR: 扩散模型在高光谱图像处理中展现出独特优势，能有效处理高维数据、去噪及数据增强，显著提升分析精度和效率。

- Motivation: 高光谱图像的高维性、数据冗余和噪声干扰给分析带来挑战，传统模型难以满足需求。
- Method: 通过模拟数据在时间中的扩散过程，扩散模型处理高维数据并生成高质量样本。
- Result: 扩散模型在高维数据处理、去噪、分类和异常检测等任务中表现优异。
- Conclusion: 扩散模型为高光谱图像分析提供了新方向，未来研究潜力巨大。


### [114] [From Fibers to Cells: Fourier-Based Registration Enables Virtual Cresyl Violet Staining From 3D Polarized Light Imaging](https://arxiv.org/abs/2505.11394)
*Alexander Oberstrass,Esteban Vaca,Eric Upschulte,Meiqi Niu,Nicola Palomero-Gallagher,David Graessel,Christian Schiffer,Markus Axer,Katrin Amunts,Timo Dickscheid*

Main category: eess.IV

TL;DR: 该论文提出了一种基于深度学习的虚拟染色方法，用于从3D-PLI图像生成细胞染色图像，解决了传统染色过程中的对齐问题。

- Motivation: 研究动机是通过深度学习技术解决脑组织切片在染色过程中的非线性变形问题，以实现纤维和细胞结构的精确对齐分析。
- Method: 方法包括利用深度学习进行图像到图像的转换，结合傅里叶基的配准技术，处理训练数据的对齐问题。
- Result: 结果表明，该方法能够从3D-PLI图像预测出与真实细胞染色高度匹配的虚拟染色图像。
- Conclusion: 结论是该方法为脑组织微结构的综合分析提供了一种高效且精确的解决方案。
## cs.SD

### [115] [Seeing Sound, Hearing Sight: Uncovering Modality Bias and Conflict of AI models in Sound Localization](https://arxiv.org/abs/2505.11217)
*Yanhao Jia,Ji Xie,S Jivaganesh,Hao Li,Xu Wu,Mengmi Zhang*

Main category: cs.SD

TL;DR: 研究探讨了AI在声音定位中如何处理跨模态冲突，发现人类优先依赖听觉信息，而AI模型则倾向于视觉输入。通过微调模型，性能显著提升，并展现出类似人类的左右定位偏好。

- Motivation: 尽管多模态AI在整合视觉和音频方面取得进展，但其在跨模态冲突中的表现及模态偏好尚不明确。研究旨在系统评估AI的声音定位能力及其与人类表现的差异。
- Method: 通过心理物理学实验评估领先多模态模型，涵盖六种视听条件（一致、冲突、缺失等）。随后使用3D模拟生成的立体音频图像数据集微调模型。
- Result: 人类表现优于AI，尤其在冲突或视觉缺失时依赖听觉信息。AI模型则倾向于视觉输入，性能接近随机水平。微调后的模型性能超越现有基准，并展现出类似人类的左右定位偏好。
- Conclusion: 研究揭示了感官输入质量和系统架构对多模态表示准确性的影响，为改进AI的跨模态冲突处理提供了方向。
## cs.CL

### [116] [Multimodal Event Detection: Current Approaches and Defining the New Playground through LLMs and VLMs](https://arxiv.org/abs/2505.10836)
*Abhishek Dey,Aabha Bothera,Samhita Sarikonda,Rishav Aryan,Sanjay Kumar Podishetty,Akshay Havalgi,Gaurav Singh,Saurabh Srivastava*

Main category: cs.CL

TL;DR: 研究社交媒体事件检测的挑战，比较了单模态、多模态和生成模型的表现，发现多模态方法优于单模态，但生成模型在精度上落后于监督方法。

- Motivation: 传统单模态系统难以应对社交媒体数据的快速和多模态传播特性，因此探索多模态和生成模型的有效性。
- Method: 使用单模态模型（ModernBERT、ConvNeXt-V2）、多模态融合技术和生成模型（GPT-4o、LLaVA），并测试生成模型在单模态输入下的表现。
- Result: 多模态方法显著优于单模态，生成模型因参数多但精度低而落后于监督方法，且难以正确生成事件类别。生成模型能有效处理社交媒体常见问题（如leet speak）。
- Conclusion: 多模态方法在事件检测中表现最佳，生成模型虽能处理特定问题，但在精度和事件分类上仍需改进。


### [117] [A Survey on the Safety and Security Threats of Computer-Using Agents: JARVIS or Ultron?](https://arxiv.org/abs/2505.10924)
*Ada Chen,Yongjiang Wu,Junyuan Zhang,Shu Yang,Jen-tse Huang,Kun Wang,Wenxuan Wang,Shuai Wang*

Main category: cs.CL

TL;DR: 本文系统化研究了计算机使用代理（CUAs）的安全与威胁，提出了分类、防御策略及评估方法，为未来研究和实践提供指导。

- Motivation: 随着AI驱动的CUAs能力增强，其安全风险日益突出，需系统化分析威胁与防御策略。
- Method: 通过文献综述，围绕四个目标展开：定义CUA、分类威胁、提出防御策略、总结评估方法。
- Result: 提出了CUAs的威胁分类、防御策略及评估框架，为研究和实践提供结构化基础。
- Conclusion: 本文为CUAs的安全研究奠定基础，指导未来漏洞探索和安全设计。
## cs.GR

### [118] [Textured mesh Quality Assessment using Geometry and Color Field Similarity](https://arxiv.org/abs/2505.10824)
*Kaifa Yang,Qi Yang,Zhu Li,Yiling Xu*

Main category: cs.GR

TL;DR: 提出了一种基于点的新方法FMQM，用于评估纹理网格质量，通过几何和颜色场提取特征，优于现有方法且计算效率高。

- Motivation: 现有纹理网格质量评估方法准确性不足，受场表示3D几何和颜色信息的启发，提出FMQM。
- Method: FMQM利用有符号距离场和新提出的最近表面点颜色场，提取几何相似性、几何梯度相似性、空间颜色分布相似性和空间颜色梯度相似性四个特征。
- Result: 在三个基准数据集上，FMQM优于现有方法，且计算复杂度低，适合实际应用。
- Conclusion: FMQM是一种高效、准确的纹理网格质量评估方法，适用于3D图形和可视化领域。
