[[toc]]

## cs.CV

### [1] [Scalable spatial point process models for forensic footwear analysis](https://arxiv.org/abs/2602.07006)
*Alokesh Manna,Neil Spencer,Dipak K. Dey*

Main category: cs.CV

TL;DR: 开发了一个分层贝叶斯模型来量化鞋印中"意外特征"的稀有性，通过潜在高斯模型和空间变化系数改进法医鞋印分析。

- Motivation: 在法医调查中，仅匹配鞋子的品牌和型号不足以确定嫌疑人的鞋子，因为同一型号有数千双。需要分析鞋底上的"意外特征"（如划痕、磨损）的稀有性来量化证据强度。
- Method: 开发了分层贝叶斯模型，采用潜在高斯模型框架实现高效推理，通过集成嵌套拉普拉斯近似扩展到大规模标注鞋印数据，并引入空间变化系数来建模鞋底花纹与意外特征位置的关系。
- Result: 在保留数据上表现出优越性能，提高了法医鞋印分析的准确性和可靠性。
- Conclusion: 该方法通过量化意外特征模式的稀有性，显著增强了法医鞋印证据的评估能力，为调查人员提供了更准确可靠的工具。


### [2] [Where Not to Learn: Prior-Aligned Training with Subset-based Attribution Constraints for Reliable Decision-Making](https://arxiv.org/abs/2602.07008)
*Ruoyu Chen,Shangquan Sun,Xiaoqing Guo,Sanyi Zhang,Kangwei Liu,Shiming Liu,Zhangcheng Wang,Qunli Zhang,Hua Zhang,Xiaochun Cao*

Main category: cs.CV

TL;DR: 提出基于归因的人类先验对齐方法，通过惩罚模型对非先验证据的依赖，引导模型决策依据与人类期望的证据区域对齐，提升模型准确性和决策合理性。

- Motivation: 传统监督学习仅提供类别标签，模型可能通过捷径相关性而非预期证据实现高准确率。人类先验可以帮助约束这种行为，但模型学习到的表示常与人类感知存在差异，对齐模型与人类先验仍具挑战性。
- Method: 将人类先验编码为模型应依赖的输入区域（如边界框），利用高保真度的基于子集选择的归因方法在训练中暴露模型决策证据。当归因区域显著偏离先验区域时，惩罚对非先验证据的依赖，通过训练目标施加由人类先验诱导的归因约束。
- Result: 在图像分类和MLLM-based GUI代理模型的点击决策任务中验证方法有效性。在传统分类和自回归生成设置中，人类先验对齐一致提高了任务准确性，同时增强了模型决策的合理性。
- Conclusion: 提出的基于归因的人类先验对齐方法能有效引导模型决策依据与人类期望的证据区域对齐，不仅提升任务准确性，还增强决策合理性，为解决模型依赖捷径相关性而非预期证据的问题提供了有效途径。


### [3] [MAU-GPT: Enhancing Multi-type Industrial Anomaly Understanding via Anomaly-aware and Generalist Experts Adaptation](https://arxiv.org/abs/2602.07011)
*Zhuonan Wang,Zhenxuan Fan,Siwen Tan,Yu Zhong,Yuqian Yuan,Haoyuan Li,Hao Jiang,Wenqiao Zhang,Feifei Shao,Hongwei Wang,Jun Xiao*

Main category: cs.CV

TL;DR: 提出了MAU-Set工业异常理解数据集和MAU-GPT多模态大模型，通过AMoE-LoRA机制统一异常感知和通用专家适应，在工业异常检测任务上超越现有方法。

- Motivation: 工业制造规模化需要自动化细粒度产品图像分析，但现有方法受限于数据集覆盖不足和模型泛化能力差，难以处理多样复杂的异常模式。
- Method: 1) 构建MAU-Set多类型工业异常理解数据集，涵盖多个工业领域和分层任务结构；2) 提出MAU-GPT领域适应多模态大模型，采用AMoE-LoRA机制统一异常感知和通用专家适应；3) 建立严格的评估协议。
- Result: MAU-GPT在所有领域都持续优于现有最先进方法，展示了在可扩展自动化工业检测方面的强大潜力。
- Conclusion: MAU-Set数据集和MAU-GPT模型为解决工业异常理解中的数据集覆盖和模型泛化问题提供了有效方案，推动了自动化工业质量控制的进步。


### [4] [A General Model for Retinal Segmentation and Quantification](https://arxiv.org/abs/2602.07012)
*Zhonghua Wang,Lie Ju,Sijia Li,Wei Feng,Sijin Zhou,Ming Hu,Jianhao Xiong,Xiaoying Tang,Yifan Peng,Mingquan Lin,Yaodong Ding,Yong Zeng,Wenbin Wei,Li Dong,Zongyuan Ge*

Main category: cs.CV

TL;DR: RetSAM是一个通用的视网膜分割和量化框架，通过深度学习在20万张眼底图像上训练，能够分割多种解剖结构和病变，并提取30多种标准化生物标志物，显著提升分割性能并支持大规模眼科研究。

- Motivation: 视网膜成像快速、无创且广泛可用，为眼科和全身健康评估提供可量化的结构和血管信号。然而，由于公共多标签数据集有限且缺乏统一的分割到量化流程，大规模分析仍然困难。
- Method: 提出RetSAM框架，采用多阶段训练策略，结合私有和公共眼底数据，支持三类任务：分割五种解剖结构、四种视网膜表型模式和20多种不同病变类型，并将分割结果转化为30多种标准化生物标志物。
- Result: 在17个公共数据集上实现卓越分割性能，平均DSC比先前最佳方法提高3.9个百分点，在具有挑战性的多任务基准上提升高达15个百分点，在不同人群、成像设备和临床环境中具有良好的泛化能力。
- Conclusion: RetSAM将眼底图像转化为标准化、可解释的定量表型，支持跨主要眼科疾病的系统性相关性分析，包括糖尿病视网膜病变、年龄相关性黄斑变性、青光眼和病理性近视，从而推动大规模眼科研究和转化应用。


### [5] [Steering to Say No: Configurable Refusal via Activation Steering in Vision Language Models](https://arxiv.org/abs/2602.07013)
*Jiaxi Yang,Shicheng Liu,Yuchen Yang,Dongwon Lee*

Main category: cs.CV

TL;DR: CR-VLM是一个基于激活引导的可配置拒绝框架，通过教师强制机制提取可配置拒绝向量、门控机制防止过度拒绝、以及反事实视觉增强模块，实现视觉语言模型中的用户自适应安全对齐。

- Motivation: 现有视觉语言模型的拒绝机制大多是"一刀切"的，无法适应不同用户需求和上下文约束，导致要么拒绝不足要么过度拒绝，需要更灵活可配置的拒绝策略。
- Method: CR-VLM包含三个组件：1）通过教师强制机制提取可配置拒绝向量来增强拒绝信号；2）引入门控机制保护范围内查询的接受性，防止过度拒绝；3）设计反事实视觉增强模块，使视觉表示与拒绝要求对齐。
- Result: 在多个数据集和各种视觉语言模型上的综合实验表明，CR-VLM实现了有效、高效且鲁棒的可配置拒绝，为视觉语言模型中的用户自适应安全对齐提供了可扩展路径。
- Conclusion: CR-VLM通过激活引导的可配置拒绝框架，解决了现有拒绝机制缺乏适应性的问题，为实现用户自适应的视觉语言模型安全对齐提供了有效解决方案。


### [6] [Vectra: A New Metric, Dataset, and Model for Visual Quality Assessment in E-Commerce In-Image Machine Translation](https://arxiv.org/abs/2602.07014)
*Qingyu Wu,Yuxuan Han,Haijun Li,Zhao Xu,Jianshan Zhao,Xu Jin,Longyue Wang,Weihua Luo*

Main category: cs.CV

TL;DR: Vectra是首个基于MLLM的、无需参考图像的电商图文翻译视觉质量评估框架，包含多维评分系统、大规模数据集和4B参数模型，在人类排名相关性上达到SOTA。

- Motivation: 现有电商图文翻译研究中，视觉渲染质量对用户参与度至关重要，但当前基于参考的方法缺乏可解释性，而模型作为评判者的方法缺乏领域细粒度奖励信号。
- Method: 提出Vectra框架：1) Vectra Score将视觉质量分解为14个可解释维度，引入空间感知的缺陷面积比量化；2) Vectra Dataset从110万真实产品图像构建，包含2K基准集、30K推理标注和3.5K专家偏好标注；3) Vectra Model是4B参数的MLLM，能生成量化分数和诊断推理。
- Result: Vectra在人类排名相关性上达到SOTA，其模型在评分性能上超越了GPT-5和Gemini-3等领先MLLM。
- Conclusion: Vectra填补了电商图文翻译视觉质量评估的空白，提供了首个无需参考图像、基于MLLM的评估框架，具有可解释性和细粒度评估能力。


### [7] [Robust and Real-Time Bangladeshi Currency Recognition: A Dual-Stream MobileNet and EfficientNet Approach](https://arxiv.org/abs/2602.07015)
*Subreena,Mohammad Amzad Hossain,Mirza Raquib,Saydul Akbar Murad,Farida Siddiqi Prity,Muhammad Hanif,Nick Rahimi*

Main category: cs.CV

TL;DR: 提出混合CNN架构用于孟加拉国纸币识别，结合MobileNetV3-Large和EfficientNetB0特征提取与MLP分类器，在资源受限设备上实现高精度识别，并引入可解释AI方法增强透明度。

- Motivation: 为视障人士提供准确的纸币识别技术，减少他们对他人依赖带来的欺诈风险。当前识别模型存在局限性，需要更鲁棒且适合资源受限设备的解决方案。
- Method: 1) 构建新的孟加拉国纸币数据集（包含控制环境和真实场景）；2) 整合四个额外数据集增强鲁棒性；3) 提出混合CNN架构（MobileNetV3-Large + EfficientNetB0）进行特征提取；4) 使用多层感知机分类器；5) 采用五折交叉验证和七种评估指标；6) 集成LIME和SHAP等可解释AI方法。
- Result: 模型在控制数据集上达到97.95%准确率，复杂背景上92.84%，所有数据集组合上94.98%。通过五折交叉验证和多种评估指标验证性能，并实现模型可解释性。
- Conclusion: 提出的混合CNN架构在纸币识别任务中表现出色，兼顾高精度和计算效率，适合资源受限设备。数据集构建和可解释AI方法的集成增强了系统的实用性和可信度，为视障人士辅助技术提供了有效解决方案。


### [8] [Gaussian-Constrained LeJEPA Representations for Unsupervised Scene Discovery and Pose Consistency](https://arxiv.org/abs/2602.07016)
*Mohsen Mostafa*

Main category: cs.CV

TL;DR: 该论文研究了使用高斯约束表示（受LeJEPA启发）来解决无监督3D场景重建中的挑战，特别是在多场景、视觉模糊的图像集合中。通过三个逐步改进的流程，验证了高斯约束嵌入能提升场景分离和相机姿态估计的鲁棒性。

- Motivation: 从非结构化图像集合中进行无监督3D场景重建是一个基础性挑战，特别是当图像来自多个不相关场景且包含显著视觉模糊时。IMC2025挑战赛凸显了这些困难，需要在真实世界条件下（包括异常值和混合内容）同时进行场景发现和相机姿态估计。
- Method: 提出了三个逐步改进的流程，最终采用受LeJEPA启发的方案，对学习到的图像嵌入施加各向同性高斯约束。该方法不是引入新的理论保证，而是实证评估这些约束如何影响聚类一致性和姿态估计的鲁棒性。
- Result: 在IMC2025上的实验结果表明，与启发式基线相比，高斯约束嵌入能够改善场景分离和姿态合理性，特别是在视觉模糊的设置中。
- Conclusion: 这些发现表明，理论驱动的表示约束为桥接自监督学习原理和实际运动恢复结构流程提供了一个有前景的方向。


### [9] [XAI-CLIP: ROI-Guided Perturbation Framework for Explainable Medical Image Segmentation in Multimodal Vision-Language Models](https://arxiv.org/abs/2602.07017)
*Thuraya Alzubaidi,Sana Ammar,Maryam Alsharqi,Islem Rekik,Muzammil Behzad*

Main category: cs.CV

TL;DR: 提出XAI-CLIP框架，通过多模态视觉-语言模型定位临床相关解剖区域，指导可解释AI过程，显著提升医学图像分割的解释性和效率。

- Motivation: 尽管基于Transformer的医学图像分割模型性能优越，但其有限的可解释性阻碍了临床信任和部署。现有XAI技术计算成本高、需要多次前向传播，且常产生噪声或解剖学无关的解释。
- Method: 提出XAI-CLIP框架，利用多模态视觉-语言模型嵌入定位临床相关解剖区域，结合语言引导的区域定位与医学图像分割，应用有针对性的区域感知扰动，生成边界清晰的显著性图。
- Result: 在FLARE22和CHAOS数据集上，XAI-CLIP相比传统扰动方法：运行时间减少60%，Dice分数提升44.6%，基于遮挡的解释的IoU提高96.7%。定性结果显示更清晰、解剖学一致的归因图。
- Conclusion: 将多模态视觉-语言表示整合到基于扰动的XAI框架中，显著提升了医学图像分割系统的可解释性和效率，为实现透明且可临床部署的系统提供了途径。


### [10] [Deep Learning Based Multi-Level Classification for Aviation Safety](https://arxiv.org/abs/2602.07019)
*Elaheh Sabziyan Varnousfaderani,Syed A. M. Shihab,Jonathan King*

Main category: cs.CV

TL;DR: 提出基于卷积神经网络的图像鸟类分类框架，用于识别鸟种、群体形态和规模，以改进航空鸟击预防系统

- Motivation: 鸟击对航空安全构成重大威胁，现有鸟击预防系统主要依赖鸟类雷达，但无法识别鸟种，而不同鸟种的飞行行为和高度偏好不同，这对准确预测飞行路径至关重要
- Method: 提出基于卷积神经网络（CNN）的图像鸟类分类框架，与相机系统配合实现自主视觉检测。CNN用于识别鸟种，并为特定物种的预测模型提供关键输入。此外还实现了专门的CNN分类器来估计群体形态类型和群体规模
- Result: 该方法能够识别鸟种、群体形态和规模，这些特征为航空安全提供有价值的补充信息。群体类型和规模有助于理解集体飞行行为和轨迹分散，群体规模直接关系到潜在撞击严重程度
- Conclusion: 通过图像识别技术增强现有鸟击预防系统，提供物种特异性信息，从而提高飞行路径预测的准确性，改善航空安全


### [11] [The Geometry of Representational Failures in Vision Language Models](https://arxiv.org/abs/2602.07025)
*Daniele Savietto,Declan Campbell,André Panisson,Marco Nurisso,Giovanni Petri,Jonathan D. Cohen,Alan Perotti*

Main category: cs.CV

TL;DR: 论文分析了视觉语言模型在多物体视觉任务中的失败机制，提出通过概念向量的几何重叠来解释模型错误模式

- Motivation: 视觉语言模型在多物体视觉任务中表现出令人困惑的失败，如幻觉不存在的元素或无法在干扰物中识别最相似的对象。这些错误反映了类似人类认知约束的"绑定问题"，但人工系统中的内部机制仍不清楚
- Method: 通过分析开放权重视觉语言模型（Qwen、InternVL、Gemma）的表征几何，比较提取"概念向量"的方法，并通过引导干预验证这些向量，在简化和自然视觉任务中可靠地操纵模型行为
- Result: 观察到这些概念向量之间的几何重叠与特定错误模式强相关，为理解内部表征如何塑造模型行为和驱动视觉失败提供了基于量化的框架
- Conclusion: 概念向量的几何分析为理解视觉语言模型在多物体任务中的失败机制提供了机制性见解，建立了内部表征与行为错误之间的定量联系


### [12] [Modality Gap-Driven Subspace Alignment Training Paradigm For Multimodal Large Language Models](https://arxiv.org/abs/2602.07026)
*Xiaomin Yu,Yi Xin,Wenjie Zhang,Chonghan Liu,Hanzhen Zhao,Xiaoxing Hu,Xinlei Yu,Ziyue Qiao,Hao Tang,Xue Yang,Xiaobin Hu,Chengwei Qin,Hui Xiong,Yu Qiao,Shuicheng Yan*

Main category: cs.CV

TL;DR: 提出ReVision框架，通过ReAlign训练免费模态对齐策略，利用未配对数据解决模态间隙问题，为MLLMs提供高效扩展路径

- Motivation: 尽管多模态对比学习在视觉和语言表示对齐方面取得成功，但存在模态间隙问题：表达相同语义的不同模态嵌入占据系统偏移区域。现有方法受限于过度简化的各向同性假设，难以应用于大规模场景。
- Method: 1. 提出固定框架模态间隙理论，将模态间隙分解为稳定偏差和各向异性残差；2. 提出ReAlign训练免费模态对齐策略，通过Anchor、Trace和Centroid Alignment三步对齐文本表示到图像表示分布；3. 基于ReAlign提出ReVision可扩展训练范式，在预训练阶段集成ReAlign，让模型从未配对文本学习视觉表示分布。
- Result: 框架证明统计对齐的未配对数据可以有效替代昂贵的图像-文本对，为MLLMs的高效扩展提供稳健路径。
- Conclusion: 通过精确建模模态间隙几何形状并利用未配对数据，实现了高效的多模态模型扩展，解决了大规模场景下的模态对齐问题。


### [13] [Fair Context Learning for Evidence-Balanced Test-Time Adaptation in Vision-Language Models](https://arxiv.org/abs/2602.07027)
*Sanggeon Yun,Ryozo Masukawa,SungHeon Jeong,Wenjun Huang,Hanning Chen,Mohsen Imani*

Main category: cs.CV

TL;DR: FCL提出了一种基于公平性约束的测试时适应框架，避免使用熵最小化，通过解耦增强探索和公平校准来缓解共享证据偏差问题。

- Motivation: 现有基于提示的测试时适应方法依赖熵最小化，但在类别共享视觉特征时可能放大虚假相关性并导致过度自信的错误。需要一种避免熵最小化的方法来处理分布偏移下的鲁棒性问题。
- Method: FCL采用情节式测试时适应框架，基于加性证据分解假设，将适应过程解耦为：(1)基于增强的探索来识别可能的类别候选；(2)公平驱动的校准，通过调整文本上下文来平等化对常见视觉证据的敏感性。
- Result: FCL在多种领域偏移和细粒度基准测试中实现了与最先进测试时适应方法相竞争的性能，有效缓解了部分特征痴迷问题。
- Conclusion: 通过避免熵最小化并引入公平性约束，FCL能够有效校准文本嵌入，提高视觉语言模型在分布偏移下的鲁棒性，为测试时适应提供了新的理论框架。


### [14] [A Comparative Study of Adversarial Robustness in CNN and CNN-ANFIS Architectures](https://arxiv.org/abs/2602.07028)
*Kaaustaaub Shankar,Bharadwaj Dogga,Kelly Cohen*

Main category: cs.CV

TL;DR: ANFIS增强的CNN在对抗攻击下的鲁棒性表现不一致：ResNet18-ANFIS有所改善，而VGG-ANFIS通常表现更差，表明神经模糊增强并非普遍有益。

- Motivation: 传统CNN缺乏可解释性且易受对抗攻击，神经模糊混合模型（如DCNFIS）用ANFIS替换全连接层以提高可解释性，但其鲁棒性尚未充分研究。
- Method: 比较标准CNN（ConvNet、VGG、ResNet18）与其ANFIS增强版本在MNIST、Fashion-MNIST、CIFAR-10和CIFAR-100数据集上，使用基于梯度的PGD攻击和无梯度的Square攻击进行评估。
- Result: ANFIS集成并未一致提高干净准确率，且对鲁棒性的影响具有架构依赖性：ResNet18-ANFIS表现出改善的对抗鲁棒性，而VGG-ANFIS通常表现不如基线模型。
- Conclusion: 神经模糊增强可以在特定架构中提高鲁棒性，但并非普遍有益；架构选择对ANFIS增强效果至关重要。


### [15] [UNIKIE-BENCH: Benchmarking Large Multimodal Models for Key Information Extraction in Visual Documents](https://arxiv.org/abs/2602.07038)
*Yifan Ji,Zhipeng Xu,Zhenghao Liu,Zulong Chen,Qian Zhang,Zhibo Yang,Junyang Lin,Yu Gu,Ge Yu,Maosong Sun*

Main category: cs.CV

TL;DR: UNIKIE-BENCH是一个用于评估大型多模态模型文档关键信息提取能力的统一基准，包含约束类别和开放类别两个赛道，揭示了现有模型在多样化模式定义、长尾关键字段和复杂布局下的性能挑战。

- Motivation: 现实世界文档的关键信息提取面临布局结构、视觉质量和任务特定需求的巨大差异，而现有大型多模态模型在这方面的能力缺乏全面系统的评估基准。
- Method: 提出UNIKIE-BENCH统一基准，包含两个互补赛道：1) 约束类别KIE赛道，基于场景预定义模式反映实际应用需求；2) 开放类别KIE赛道，提取文档中明确存在的任何关键信息。
- Result: 对15个最先进的大型多模态模型进行实验，发现在多样化模式定义、长尾关键字段和复杂布局下性能显著下降，不同文档类型和场景间存在明显性能差异。
- Conclusion: 研究揭示了基于大型多模态模型的关键信息提取在基础准确性和布局感知推理方面仍面临持续挑战，需要进一步改进。


### [16] [OMNI-Dent: Towards an Accessible and Explainable AI Framework for Automated Dental Diagnosis](https://arxiv.org/abs/2602.07041)
*Leeje Jang,Yao-Yi Chiang,Angela M. Hastings,Patimaporn Pungchanchaikul,Martha B. Lucas,Emily C. Schultz,Jeffrey P. Louie,Mohamed Estai,Wen-Chen Wang,Ryan H. L. Ip,Boyen Huang*

Main category: cs.CV

TL;DR: OMNI-Dent是一个数据高效、可解释的牙科诊断框架，将临床推理原则融入视觉语言模型，利用智能手机多视角照片进行牙齿级评估，无需牙科特定微调。

- Motivation: 当前AI牙科诊断方法主要将诊断视为视觉模式识别任务，未能反映牙科专业人员的结构化临床推理。这些方法需要大量专家标注数据，且难以适应多样化的真实世界成像条件。许多人缺乏及时的专业评估机会。
- Method: OMNI-Dent框架整合了牙科专家的诊断启发式方法，引导通用视觉语言模型（VLM）在智能手机多视角照片上进行牙齿级评估，无需对VLM进行牙科特定微调。利用VLM现有的视觉-语言能力，在缺乏临床影像的情况下支持诊断评估。
- Result: 该框架作为早期辅助工具，帮助用户识别潜在异常并确定何时需要专业评估，为缺乏现场护理机会的个人提供实用选择。
- Conclusion: OMNI-Dent通过将临床推理原则融入VLM管道，提供了一种数据高效、可解释的牙科诊断方法，能够适应多样化的真实世界成像条件，解决传统AI方法在牙科诊断中的局限性。


### [17] [COMBOOD: A Semiparametric Approach for Detecting Out-of-distribution Data for Image Classification](https://arxiv.org/abs/2602.07042)
*Magesh Rajasekaran,Md Saiful Islam Sajol,Frej Berglind,Supratik Mukhopadhyay,Kamalika Das*

Main category: cs.CV

TL;DR: COMBOOD是一个新颖的无监督半参数框架，用于图像识别中的OOD检测，通过结合最近邻和马氏距离两种信号，在近OOD和远OOD场景下都能提供准确的置信度分数。

- Motivation: 在推理时识别OOD数据对许多机器学习应用至关重要，尤其是自动化应用。现有方法在近OOD场景（实际应用中常见）中表现不佳，需要一种能同时处理近OOD和远OOD场景的有效方法。
- Method: COMBOOD框架结合了两种距离度量信号：最近邻（非参数方法）和马氏距离（参数方法）。最近邻方法提供非参数的OOD检测，马氏距离在远OOD场景中特别有效。该框架在半参数设置中融合这两种信号，为OOD检测生成置信度分数。
- Result: COMBOOD在OpenOOD基准数据集（v1和v1.5）以及文档数据集上，在远OOD和近OOD场景下都优于最先进的OOD检测方法。在大多数基准数据集上，COMBOOD带来的准确率提升具有统计显著性。框架的复杂度与嵌入空间大小呈线性关系。
- Conclusion: COMBOOD是一个有效的半参数框架，通过结合最近邻和马氏距离的优势，在近OOD和远OOD场景下都能提供准确的OOD检测，适用于许多实际应用场景。


### [18] [PipeMFL-240K: A Large-scale Dataset and Benchmark for Object Detection in Pipeline Magnetic Flux Leakage Imaging](https://arxiv.org/abs/2602.07044)
*Tianyi Qu,Songxiao Yang,Haolin Wang,Huadong Song,Xiaoting Guo,Wenguang Hu,Guanlin Liu,Honghe Chen,Yafei Ou*

Main category: cs.CV

TL;DR: PipeMFL-240K：首个大规模公开的管道漏磁检测数据集与基准，包含24万张图像和19万标注，解决现有研究缺乏公平比较和可复现评估的问题。

- Motivation: 尽管深度学习在自动化漏磁检测解释方面有前景，但由于缺乏大规模公开数据集和基准，可靠模型的进展受到限制，难以进行公平比较和可复现评估。
- Method: 构建了PipeMFL-240K数据集，包含240,320张图像和191,530个高质量边界框标注，来自11条总长约1,480公里的管道。数据集具有三个独特挑战：12个类别的极端长尾分布、大量微小目标（仅几个像素）、显著的类内变异性。
- Result: 使用最先进的目标检测器进行广泛实验建立基线。结果显示现代检测器在漏磁数据的固有特性上仍然存在困难，表明有相当大的改进空间。
- Conclusion: PipeMFL-240K为管道漏磁检测提供了可靠且具有挑战性的测试平台，将加速算法创新和可复现研究，为高效管道诊断和维护规划奠定关键基础。


### [19] [VLRS-Bench: A Vision-Language Reasoning Benchmark for Remote Sensing](https://arxiv.org/abs/2602.07045)
*Zhiming Luo,Di Wang,Haonan Guo,Jing Zhang,Bo Du*

Main category: cs.CV

TL;DR: VLRS-Bench是首个专门针对遥感复杂推理任务的基准测试，包含2000个问答对，涵盖认知、决策和预测三个维度，旨在推动遥感领域多模态大语言模型的发展。

- Motivation: 现有遥感基准测试主要偏向感知任务（如目标识别和场景分类），这限制了多模态大语言模型在认知要求高的遥感应用中的发展。需要专门的复杂推理基准来推动该领域进步。
- Method: 提出了VLRS-Bench基准测试，包含2000个问答对，平均长度71词，涵盖14个任务和最多8个时间阶段。通过整合遥感先验知识和专家知识的专门流程构建，确保地理空间真实性和推理复杂性。
- Result: 实验结果显示现有最先进的多模态大语言模型在该基准上存在显著瓶颈，为遥感社区推进多模态推理提供了关键见解。
- Conclusion: VLRS-Bench填补了遥感领域复杂推理基准的空白，揭示了当前模型的局限性，为未来遥感多模态大语言模型的发展提供了重要方向。


### [20] [ShapBPT: Image Feature Attributions Using Data-Aware Binary Partition Trees](https://arxiv.org/abs/2602.07047)
*Muhammad Rashid,Elvio G. Amparore,Enrico Ferrari,Damiano Verda*

Main category: cs.CV

TL;DR: 提出ShapBPT方法，将分层Shapley值应用于图像数据的多尺度层次结构，实现更高效、语义更丰富的视觉可解释性。

- Motivation: 现有分层Shapley方法未能利用图像数据的多尺度结构，导致收敛慢且与真实形态特征对齐弱；缺乏针对计算机视觉任务的数据感知层次结构，限制了结构化视觉数据的模型可解释性。
- Method: 提出ShapBPT方法，基于分层Shapley公式，将Shapley系数分配给为图像定制的多尺度层次结构——二叉分割树(BPT)，通过数据感知的层次分割确保特征归因与内在图像形态对齐。
- Result: 实验证明ShapBPT有效性：与图像结构对齐更优、效率高于现有XCV方法；20人用户研究确认人类更偏好ShapBPT的解释。
- Conclusion: ShapBPT将分层Shapley方法与图像数据连接，为视觉可解释性提供了更高效、语义更丰富的方法，填补了结构化视觉数据模型可解释性的空白。


### [21] [Enhancing IMU-Based Online Handwriting Recognition via Contrastive Learning with Zero Inference Overhead](https://arxiv.org/abs/2602.07049)
*Jindong Li,Dario Zanca,Vincent Christlein,Tim Hamann,Jens Barth,Peter Kämpf,Björn Eskofier*

Main category: cs.CV

TL;DR: 提出ECHWR训练框架，通过临时辅助分支和双重对比目标提升IMU手写识别性能，不增加推理成本，在OnHW-Words500数据集上显著降低错误率。

- Motivation: 边缘设备上的在线手写识别面临内存限制，需要在保持推理效率的同时提升识别精度。现有方法在特征表示和识别准确性方面仍有改进空间。
- Method: 提出ECHWR训练框架：1) 使用临时辅助分支在训练阶段对齐传感器信号与文本语义嵌入；2) 采用双重对比目标：批内对比损失用于模态对齐，新颖的错误对比损失区分正确信号与合成硬负样本；3) 训练后丢弃辅助分支，保持原始高效架构。
- Result: 在OnHW-Words500数据集上显著优于现有方法：作者独立分割字符错误率降低7.4%，作者依赖分割降低10.4%。错误对比损失在处理未见书写风格方面表现出有效性。
- Conclusion: ECHWR框架在不增加推理成本的前提下，通过临时辅助分支和双重对比目标有效提升了IMU手写识别性能，特别是错误对比损失对处理新书写风格有重要作用。


### [22] [Interpreting Physics in Video World Models](https://arxiv.org/abs/2602.07050)
*Sonia Joseph,Quentin Garrido,Randall Balestriero,Matthew Kowal,Thomas Fel,Shahab Bakhtiari,Blake Richards,Mike Rabbat*

Main category: cs.CV

TL;DR: 视频编码器内部存在"物理涌现区"，物理变量以分布式而非分解式表征，运动方向通过高维环形几何结构编码。

- Motivation: 探究视频模型是否依赖物理变量的分解式表征，还是通过任务特定的分布式方式隐式表示这些变量，以理解现代视频世界模型的内部工作机制。
- Method: 使用分层探测、子空间几何分析、补丁级解码和定向注意力消融等方法，在基于编码器的视频Transformer中表征物理信息的可访问性和组织方式。
- Result: 发现跨架构的中间深度"物理涌现区"，物理变量在此变得可访问；标量物理量早期即可获得，而运动方向仅在涌现区变得可访问，且通过具有环形几何结构的高维群体编码。
- Conclusion: 现代视频模型不使用经典物理引擎那样的分解式物理变量表征，而是使用分布式表征，这种表征足以进行物理预测。


### [23] [Neural Sentinel: Unified Vision Language Model (VLM) for License Plate Recognition with Human-in-the-Loop Continual Learning](https://arxiv.org/abs/2602.07051)
*Karthik Sivakoti*

Main category: cs.CV

TL;DR: Neural Sentinel：基于视觉语言模型的统一车牌识别系统，单次前向传播完成车牌识别、状态分类和车辆属性提取，准确率92.3%，比传统OCR方法提升显著。

- Motivation: 传统ALPR系统采用多阶段流水线（目标检测+OCR模块），存在误差累积、延迟高、架构复杂的问题。需要更高效、准确且能处理多任务的统一解决方案。
- Method: 使用PaliGemma 3B视觉语言模型，通过LoRA微调，单次前向传播回答多个关于车辆图像的视觉问题。引入人机协同持续学习框架，通过经验回放防止灾难性遗忘。
- Result: 车牌识别准确率92.3%，比EasyOCR提升14.1%，比PaddleOCR提升9.9%。平均推理延迟152ms，校准误差0.048。零样本泛化到车辆颜色检测(89%)、安全带检测(82%)、乘员计数(78%)等任务。
- Conclusion: 统一视觉语言方法代表了ALPR系统的范式转变，提供更优的准确性、降低的架构复杂性以及传统流水线方法无法实现的涌现多任务能力。


### [24] [Toward Accurate and Accessible Markerless Neuronavigation](https://arxiv.org/abs/2602.07052)
*Ziye Xie,Oded Schlesinger,Raj Kundu,Jessica Y. Choi,Pablo Iturralde,Dennis A. Turner,Stefan M. Goetz,Guillermo Sapiro,Angel V. Peterchev,J. Matias Di Martino*

Main category: cs.CV

TL;DR: 提出并评估无标记神经导航方法，使用低成本可见光和红外光相机结合面部几何建模，替代传统基于标记的系统，验证显示精度足够用于经颅磁刺激。

- Motivation: 传统神经导航系统依赖主体安装的标记，需要手动配准，可能在手术过程中移位，并引起不适。这些系统昂贵且复杂，限制了神经导航在临床和研究环境中的普及。
- Method: 引入无标记方法，使用低成本可见光和红外光相机（结合立体视觉和深度感知）结合面部几何的算法建模，替代昂贵的硬件和物理标记。
- Result: 在50名人类受试者上的验证显示，最佳无标记算法相比传统基于标记系统的中位跟踪误差仅为2.32毫米和2.01°，精度足以用于经颅磁刺激，且显著优于先前的无标记结果。
- Conclusion: 提出的无标记神经导航方法可以降低设置成本和复杂性，提高患者舒适度，并扩大神经导航在临床和研究环境中的可及性。不同相机传感器数据的融合可以进一步提高整体精度。


### [25] [RECITYGEN -- Interactive and Generative Participatory Urban Design Tool with Latent Diffusion and Segment Anything](https://arxiv.org/abs/2602.07057)
*Di Mo,Mingyang Sun,Chengxiu Yin,Runjia Tian,Yanhong Wu,Liyan Xu*

Main category: cs.CV

TL;DR: RECITYGEN是一个结合潜在扩散模型和交互式语义分割的工具，允许用户通过文本提示交互式生成城市街景的变体图像，用于参与式城市设计。

- Motivation: 传统自上而下的城市设计方法往往忽视公众意见，导致设计愿景与现实之间存在差距。数字工具的发展为更多利益相关者参与城市设计提供了机会，但需要更易用的工具来降低参与门槛。
- Method: 结合最先进的潜在扩散模型和交互式语义分割技术，开发了RECITYGEN工具，用户可以通过文本提示交互式创建城市环境的变体街景图像。
- Result: 在北京的试点项目中，用户使用RECITYGEN为正在进行的城市更新项目提出改进建议。尽管存在一些限制，但该工具在符合公众偏好方面显示出显著潜力。
- Conclusion: RECITYGEN代表了向更动态和包容的城市规划方法的转变，通过降低设计生成门槛，使公众能够更有效地参与城市设计过程。


### [26] [FADE: Selective Forgetting via Sparse LoRA and Self-Distillation](https://arxiv.org/abs/2602.07058)
*Carolina R. Kelsch,Leonardo S. B. Pereira,Natnael Mola,Luis H. Arribas,Juan C. S. M. Avedillo*

Main category: cs.CV

TL;DR: FADE是一个用于文本到图像扩散模型的轻量级两阶段遗忘方法，通过参数定位和自蒸馏实现高效概念擦除，同时保持模型整体性能。

- Motivation: 随着数据保护法规和负责任AI实践的要求，需要从训练模型中移除特定数据或概念的影响。当前文本到图像扩散模型的遗忘方法面临高计算成本和难以平衡有效遗忘与保留无关概念的挑战。
- Method: FADE采用两阶段方法：1) 使用基于梯度的显著性识别与遗忘集最相关的参数，通过稀疏LoRA适配器进行约束更新；2) 应用自蒸馏目标，用用户定义的替代概念覆盖被遗忘概念，同时保留在保留数据上的行为。
- Result: 在UnlearnCanvas基准测试和多个数据集上的消融研究表明，FADE实现了最先进的遗忘性能，在遗忘-保留权衡方面具有细粒度控制，适配器内存效率高、可逆，可在运行时合并或移除。
- Conclusion: FADE在多个领域实现了强大的概念擦除和高保留性，是扩散基图像生成模型中选择性遗忘的合适解决方案，适配器轻量且部署灵活。


### [27] [From Images to Decisions: Assistive Computer Vision for Non-Metallic Content Estimation in Scrap Metal](https://arxiv.org/abs/2602.07062)
*Daniil Storonkin,Ilia Dziub,Maksim Golyadkin,Ilya Makarov*

Main category: cs.CV

TL;DR: 开发计算机视觉系统，通过多实例学习和多任务学习从图像中自动评估废钢污染程度和分类废钢类型，减少主观判断并提高安全性

- Motivation: 目前废钢质量主要通过人工目视评估非金属夹杂物含量，这种方法主观性强且存在安全隐患（粉尘和移动机械），需要自动化解决方案来减少主观差异并提高安全性
- Method: 将污染评估构建为车厢级别的回归任务，采用多实例学习（MIL）处理序列数据，并结合多任务学习（MTL）同时进行污染评估和废钢分类；系统包括磁铁/车厢检测、版本化推理服务、操作员审查和主动学习循环
- Result: 最佳结果：MIL方法达到MAE 0.27和R² 0.83；MTL设置达到MAE 0.36，废钢分类F1分数0.79；系统实现近实时处理，减少主观差异并提高安全性
- Conclusion: 提出的计算机视觉管道能够有效评估废钢污染程度和分类废钢类型，减少主观变异性，提高人员安全性，并能够集成到验收和熔炼计划工作流程中


### [28] [Exploring Physical Intelligence Emergence via Omni-Modal Architecture and Physical Data Engine](https://arxiv.org/abs/2602.07064)
*Minghao Han,Dingkang Yang,Yue Jiang,Yizhou Liu,Lihua Zhang*

Main category: cs.CV

TL;DR: OmniFysics：一个紧凑的全模态模型，通过物理数据引擎注入显式物理知识，统一理解图像、音频、视频和文本，并集成语音和图像生成。

- Motivation: 现有全模态模型在物理理解方面存在脆弱性，因为关键物理属性在视觉上是模糊的，且在网络规模数据中稀疏表示。需要注入显式物理知识来增强模型的物理理解能力。
- Method: 1. 构建物理数据引擎：FysicsAny通过层次检索将显著对象映射到已验证的物理属性，生成物理基础的指令-图像监督；FysicsOmniCap通过音频-视觉一致性过滤蒸馏网络视频，生成高质量视频-指令对。2. 采用分阶段多模态对齐和指令调优训练OmniFysics模型。3. 使用潜在空间流匹配进行文本到图像生成。4. 使用意图路由器仅在需要时激活生成功能。
- Result: 在标准多模态基准测试中表现有竞争力，在物理导向评估中结果有所改进。
- Conclusion: OmniFysics通过注入显式物理知识，增强了全模态模型的物理理解能力，在保持紧凑模型规模的同时，实现了跨模态的统一理解和生成能力。


### [29] [Contactless estimation of continuum displacement and mechanical compressibility from image series using a deep learning based framework](https://arxiv.org/abs/2602.07065)
*A. N. Maria Antony,T. Richter,E. Gladilin*

Main category: cs.CV

TL;DR: 提出一种基于深度学习的端到端方法，直接从图像序列估计连续位移和材料压缩性，相比传统方法在效率和精度上都有优势。

- Motivation: 传统非接触式材料力学性能评估方法依赖耗时的迭代算法和非刚性图像配准，不适合高通量数据处理，需要更高效的解决方案。
- Method: 采用两个深度神经网络分别进行图像配准和材料压缩性估计，构建端到端框架直接从图像序列预测位移场和材料压缩性。
- Result: 深度学习模型在参考数据集上训练后，即使在图像配准预测的映射与参考位移场存在显著局部偏差时，也能准确确定材料压缩性。
- Conclusion: 深度学习端到端模型的卓越精度源于其评估高阶认知特征（如矢量场的涡度）的能力，而非传统的图像位移局部特征。


### [30] [Bidirectional Reward-Guided Diffusion for Real-World Image Super-Resolution](https://arxiv.org/abs/2602.07069)
*Zihao Fan,Xin Lu,Yidi Liu,Jie Huang,Dong Li,Xueyang Fu,Zheng-Jun Zha*

Main category: cs.CV

TL;DR: Bird-SR：基于双向奖励引导的扩散框架，通过奖励反馈学习将超分辨率建模为轨迹级偏好优化，联合利用合成LR-HR对和真实世界LR图像，在保持结构一致性的同时提升感知质量。

- Motivation: 基于扩散的超分辨率方法能合成丰富细节，但在合成配对数据上训练的模型往往因分布偏移而在真实世界低分辨率图像上失效。需要一种能同时利用合成数据和真实世界图像的方法。
- Method: 提出Bird-SR框架：1）早期扩散步在合成对上直接优化以保证结构保真度；2）后期采样步对合成和真实图像应用质量引导奖励；3）通过相对优势空间和语义对齐约束防止奖励攻击；4）采用动态保真度-感知权重策略平衡结构保持和感知优化。
- Result: 在真实世界超分辨率基准测试中，Bird-SR在感知质量方面持续优于最先进方法，同时保持了结构一致性。
- Conclusion: Bird-SR通过奖励反馈学习和动态平衡策略，有效解决了真实世界超分辨率中结构保真与感知质量的权衡问题，为实际应用提供了有效解决方案。


### [31] [MosaicThinker: On-Device Visual Spatial Reasoning for Embodied AI via Iterative Construction of Space Representation](https://arxiv.org/abs/2602.07082)
*Haoming Wang,Qiyao Xue,Weichen Liu,Wei Gao*

Main category: cs.CV

TL;DR: MosaicThinker：一种用于设备端具身AI的推理时计算技术，通过整合多帧空间信息到统一语义地图来增强小型视觉语言模型的空间推理能力

- Motivation: 现有视觉语言模型在空间推理方面能力较弱，尤其是处理涉及多帧复杂空间关系的任务时，缺乏3D空间信息知识，而设备端具身AI需要这种能力来指导机器人操作和动作规划
- Method: 提出MosaicThinker技术，将多帧碎片化的空间信息整合到统一的全局语义地图表示中，并通过视觉提示引导视觉语言模型在语义地图上进行空间推理
- Result: 实验结果表明，该技术能显著提高资源受限设备上跨帧空间推理的准确性，适用于多种类型和复杂度的推理任务
- Conclusion: MosaicThinker通过整合多帧空间信息到统一语义地图，有效增强了设备端小型视觉语言模型的跨帧空间推理能力，为具身AI应用提供了实用的解决方案


### [32] [WorldEdit: Towards Open-World Image Editing with a Knowledge-Informed Benchmark](https://arxiv.org/abs/2602.07095)
*Wang Lin,Feng Wang,Majun Zhang,Wentao Hu,Tao Jin,Zhou Zhao,Fei Wu,Jingyuan Chen,Alan Yuille,Sucheng Ren*

Main category: cs.CV

TL;DR: WorldEdit是一个专门设计用于世界驱动图像编辑的数据集，通过两阶段训练框架提升模型处理隐式编辑指令的能力，显著缩小了与GPT-4o等先进模型的差距。

- Motivation: 现有图像编辑模型在处理显式指令（如属性操作、风格转换）方面表现出色，但在处理隐式编辑指令（描述视觉变化的原因而非具体结果）时面临挑战。这些模型依赖统一的编辑策略，缺乏处理复杂世界知识和推理的能力。
- Method: 1) 引入WorldEdit数据集，包含高质量编辑样本，指令经过改写以符合现实世界因果逻辑；2) 提供WorldEdit-Test用于评估模型在因果编辑场景的性能；3) 采用两阶段训练框架微调Bagel等模型，并整合因果验证奖励机制。
- Result: 提出的数据集和方法显著缩小了与GPT-4o和Nano-Banana的差距，在指令遵循和知识合理性方面表现出竞争力，而这两个方面通常是开源系统的薄弱环节。
- Conclusion: WorldEdit数据集和两阶段训练框架有效解决了图像编辑模型处理隐式指令的局限性，通过整合世界知识和因果推理能力，提升了模型在复杂编辑任务中的性能。


### [33] [TLC-Plan: A Two-Level Codebook Based Network for End-to-End Vector Floorplan Generation](https://arxiv.org/abs/2602.07100)
*Biao Xiong,Zhen Peng,Ping Wang,Qiegen Liu,Xian Zhong*

Main category: cs.CV

TL;DR: TLC-Plan是一个直接从边界输入生成矢量平面图的层次化生成模型，采用两级VQ-VAE和自回归transformer，在RPLAN数据集上取得SOTA性能（FID=1.84，MSE=2.06）。

- Motivation: 现有方法在栅格空间中操作并依赖后处理矢量化，导致结构不一致并阻碍端到端学习。受组合空间推理启发，需要开发与人类建筑工作流程（基于模块化和可重用模式）对齐的直接矢量平面图生成方法。
- Method: 提出TLC-Plan：1）使用两级VQ-VAE编码全局布局（语义标记的房间边界框）和细化局部几何（多边形级编码）；2）统一为CodeTree表示；3）使用自回归transformer在边界条件下采样编码，生成多样且拓扑有效的设计，无需显式房间拓扑或维度先验。
- Result: 在RPLAN数据集上取得最先进性能（FID=1.84，MSE=2.06），在LIFULL数据集上也取得领先结果。框架推进了约束感知和可扩展的矢量平面图生成，适用于实际建筑应用。
- Conclusion: TLC-Plan通过层次化生成模型直接合成矢量平面图，解决了现有方法的结构不一致问题，实现了与人类建筑工作流程对齐的端到端学习，为实际建筑应用提供了有效的解决方案。


### [34] [Zero-Shot UAV Navigation in Forests via Relightable 3D Gaussian Splatting](https://arxiv.org/abs/2602.07101)
*Zinan Lv,Yeqian Qian,Chen Sang,Hao Liu,Danping Zou,Ming Yang*

Main category: cs.CV

TL;DR: 提出基于可重光照3D高斯泼溅的强化学习框架，实现无人机在非结构化室外环境中的零样本导航，克服光照变化挑战

- Motivation: 无人机在非结构化室外环境中使用单目视觉导航面临仿真与现实之间的视觉域差距问题，现有方法将静态光照与几何耦合，限制了策略在动态真实光照下的泛化能力
- Method: 提出可重光照3D高斯泼溅技术，分解场景组件实现物理基础的光照编辑；在高保真仿真中训练端到端强化学习策略，通过多样化的合成光照条件增强训练，学习光照不变的视觉特征
- Result: 轻量级四旋翼无人机在复杂森林环境中实现高达10米/秒的鲁棒、无碰撞导航，对剧烈光照变化表现出显著韧性，无需微调
- Conclusion: 提出的框架成功解决了仿真到现实的视觉域差距问题，通过可重光照神经表示和光照增强训练，实现了无人机在动态真实光照条件下的零样本导航能力


### [35] [Extended to Reality: Prompt Injection in 3D Environments](https://arxiv.org/abs/2602.07104)
*Zhuoheng Li,Ying Chen*

Main category: cs.CV

TL;DR: PI3D是一种针对3D环境中多模态大语言模型的提示注入攻击，通过放置带有文本的物理物体来覆盖模型的原始任务

- Motivation: 随着MLLMs在3D环境中的应用增加（如机器人、对话代理），攻击者可以通过放置物理物体来操纵模型行为，而现有研究主要关注文本域和2D数字图像攻击，缺乏对3D物理环境攻击的研究
- Method: 提出PI3D攻击方法，通过优化3D物体姿态（位置和方向）来放置带有注入文本的物理物体，使攻击既有效又物理可行
- Result: PI3D对多种MLLMs在不同相机轨迹下都有效，现有防御措施无法有效抵御这种攻击
- Conclusion: 3D物理环境中的提示注入攻击是一个新的安全威胁，需要开发新的防御机制来保护MLLMs在物理世界中的应用


### [36] [Ex-Omni: Enabling 3D Facial Animation Generation for Omni-modal Large Language Models](https://arxiv.org/abs/2602.07106)
*Haoyu Zhang,Zhipeng Li,Yiwen Guo,Tianshu Yu*

Main category: cs.CV

TL;DR: Ex-Omni是一个开源的全模态框架，通过解耦语义推理与时间生成，利用语音单元作为时间支架和统一的token-as-query门控融合机制，为全模态大语言模型添加语音伴随的3D面部动画功能。

- Motivation: 当前全模态大语言模型主要关注多模态理解与生成，但语音与3D面部动画的结合仍未被充分探索，而这对于自然交互至关重要。主要挑战在于LLMs的离散token级语义推理与3D面部运动所需的密集细粒度时间动态之间存在表示不匹配。
- Method: 提出Ex-Omni框架，通过解耦语义推理与时间生成来降低学习难度：1) 使用语音单元作为时间支架；2) 采用统一的token-as-query门控融合机制进行受控语义注入；3) 引入InstructEx数据集来支持模型训练。
- Result: 大量实验表明，Ex-Omni在性能上与现有开源全模态大语言模型相当，同时能够稳定生成对齐的语音和面部动画。
- Conclusion: Ex-Omni成功解决了全模态大语言模型中语音与3D面部动画融合的挑战，通过创新的解耦架构和融合机制，实现了稳定的多模态生成能力。


### [37] [Privacy in Image Datasets: A Case Study on Pregnancy Ultrasounds](https://arxiv.org/abs/2602.07149)
*Rawisara Lohanimit,Yankun Wu,Amelia Katirai,Yuta Nakashima,Noa Garcia*

Main category: cs.CV

TL;DR: 研究发现LAION-400M数据集中包含大量敏感怀孕超声图像和个人隐私信息，存在高风险数据泄露问题

- Motivation: 随着生成模型使用大规模网络数据集，缺乏数据筛选导致敏感隐私信息被纳入，特别是包含个人敏感信息的怀孕超声图像
- Method: 使用CLIP嵌入相似性对LAION-400M数据集进行系统检查，检索怀孕超声图像并检测姓名、位置等隐私信息
- Result: 发现数千条包含姓名、位置等隐私信息的实体，多个图像包含高风险信息，可能导致重新识别或身份冒充
- Conclusion: 建议改进数据集筛选、数据隐私保护和公共图像数据集的伦理使用实践


### [38] [DuMeta++: Spatiotemporal Dual Meta-Learning for Generalizable Few-Shot Brain Tissue Segmentation Across Diverse Ages](https://arxiv.org/abs/2602.07174)
*Yongheng Sun,Jun Shu,Jianhua Ma,Fan Wang*

Main category: cs.CV

TL;DR: DuMeta++：无需配对纵向数据的双元学习框架，用于跨年龄脑组织MRI分割，通过元特征学习和元初始化学习实现跨年龄泛化

- Motivation: 脑组织MRI分割在神经科学和临床应用中至关重要，但由于大脑外观和形态随年龄动态变化，实现跨人类生命周期的稳定性能具有挑战性。现有方法依赖配对纵向数据进行自监督正则化，但这类数据在实践中往往难以获取。
- Method: 提出DuMeta++双元学习框架：1）元特征学习提取年龄无关的时空演化脑结构语义表示；2）元初始化学习实现分割模型的数据高效适应；3）基于记忆库的类感知正则化策略，无需显式纵向监督即可强制纵向一致性。理论证明了算法的收敛性。
- Result: 在iSeg-2019、IBIS、OASIS、ADNI等多个数据集上的少样本设置实验中，DuMeta++在跨年龄泛化方面优于现有方法。
- Conclusion: DuMeta++无需配对纵向数据即可实现跨年龄脑组织分割，通过双元学习和记忆库正则化策略有效解决了年龄相关变化带来的挑战，在少样本设置下表现出优越的跨年龄泛化能力。


### [39] [Condition Matters in Full-head 3D GANs](https://arxiv.org/abs/2602.07198)
*Heyuan Li,Huimin Zhang,Yuda Qiu,Zhengwentai Sun,Keru Zheng,Lingteng Qiu,Peihao Li,Qi Zuo,Ce Chen,Yujian Zheng,Yuming Gu,Zilong Dong,Xiaoguang Han*

Main category: cs.CV

TL;DR: 提出使用视角不变语义特征作为条件输入，解决传统3D头部GAN中视角条件导致的生成偏差问题，提升3D头部生成的全局一致性和多样性。

- Motivation: 传统3D头部GAN使用视角角度作为条件输入会导致学习到的3D头部空间存在视角方向偏差，造成条件视角与非条件视角之间生成质量和多样性的显著差异，导致不同头部区域的全局不一致性。
- Method: 1) 使用视角不变语义特征作为条件输入，将3D头部的生成能力与视角方向解耦；2) 创建合成头部图像数据集，利用FLUX.1 Kontext将现有高质量正面人脸数据集扩展到多视角；3) 使用正面视图提取的图像clip特征作为所有扩展图像视图的共享语义条件，确保语义对齐并消除方向偏差。
- Result: 在完整头部合成和单视图GAN反转的广泛实验中，该方法实现了显著更高的保真度、多样性和泛化能力。语义条件监督加速了训练，增强了生成3D头部的全局一致性。
- Conclusion: 通过使用视角不变语义特征作为条件输入，成功解决了传统3D头部GAN中的视角偏差问题，实现了更高质量、更一致且更多样化的3D头部生成，同时语义条件促进了生成器遵循真实语义分布，实现了持续学习和多样化生成。


### [40] [Understanding Real-World Traffic Safety through RoadSafe365 Benchmark](https://arxiv.org/abs/2602.07212)
*Xinyu Liu,Darryl C. Jacob,Yuxin Liu,Xinsong Du,Muchao Ye,Bolei Zhou,Pan He*

Main category: cs.CV

TL;DR: RoadSafe365是一个大规模视觉语言基准，用于细粒度交通安全性分析，包含36,196个标注视频片段和864K候选选项，基于官方安全标准构建

- Motivation: 现有交通基准缺乏与官方安全标准的系统性对齐评估，需要填补这一空白，以连接官方交通安全标准与数据驱动的交通理解系统
- Method: 构建大规模视觉语言基准，采用分层分类法精炼和扩展事故、事件和违规的基础定义，从行车记录仪和监控摄像头收集数据，提供丰富的属性标注和多选题集
- Result: 建立了36,196个标注片段，包含864K候选选项、8.4K独特答案和36K详细场景描述，基准测试显示微调后性能有持续提升，跨域实验验证了有效性
- Conclusion: RoadSafe365为大规模训练和标准化评估提供了全面基准，可推进现实世界交通安全性分析的可重复研究


### [41] [The Double-Edged Sword of Data-Driven Super-Resolution: Adversarial Super-Resolution Models](https://arxiv.org/abs/2602.07251)
*Haley Duba-Sullivan,Steven R. Young,Emma J. Reid*

Main category: cs.CV

TL;DR: AdvSR是一种将对抗行为嵌入超分辨率模型权重的攻击框架，无需推理时访问输入，可在保持图像质量的同时诱导下游分类器误判

- Motivation: 数据驱动的超分辨率模型常作为成像管道预处理步骤，但这类模型引入了一个未被探索的攻击面。传统对抗攻击需要扰动输入或依赖后门触发器，而本文研究是否能在模型层面直接嵌入对抗行为
- Method: 提出AdvSR框架，在训练阶段联合优化重建质量和目标对抗效果，将对抗行为直接嵌入SR模型权重中。该方法不依赖推理时输入访问，评估了三种SR架构（SRCNN、EDSR、SwinIR）与YOLOv11分类器的组合
- Result: AdvSR模型在标准图像质量指标下表现正常，但能有效诱导下游分类器误判，实现高攻击成功率且图像质量下降最小。这揭示了成像管道中新的模型级威胁
- Conclusion: AdvSR展示了模型级对抗攻击的可行性，对安全关键应用中模型来源和验证提出了新的挑战。研究结果强调了在成像管道中需要更严格的模型安全评估


### [42] [3D Transport-based Morphometry (3D-TBM) for medical image analysis](https://arxiv.org/abs/2602.07260)
*Hongyu Kan,Kristofor Pas,Ivan Medri,Naqib Sad Pathan,Natasha Ironside,Shinjini Kundu,Jingjia He,Gustavo Kunde Rohde*

Main category: cs.CV

TL;DR: 3D-TBM是一个用于3D医学图像形态学分析的工具，基于传输形态测量学框架，通过可逆变换将图像嵌入传输域进行分析，并提供可视化工具和完整文档支持。

- Motivation: 促进传输形态测量学（TBM）在临床影像研究中的广泛应用，为研究人员提供一个完整的3D医学图像形态学分析工具，解决传统方法在空间解释性方面的限制。
- Method: 开发3D-TBM工具，包括数据预处理、最优传输嵌入计算、主要传输方向可视化、区分方向识别等分析方法，基于PyTransKit开源实现。
- Result: 提出了一个完整的3D-TBM框架，包含预处理、传输域嵌入、分析方法和可视化工具，提供全面文档和实用教程，源代码已公开。
- Conclusion: 3D-TBM工具为医学影像研究提供了基于传输形态测量学的强大分析框架，通过可逆映射实现结果的空间可解释性，有望促进TBM在临床研究中的广泛应用。


### [43] [TwistNet-2D: Learning Second-Order Channel Interactions via Spiral Twisting for Texture Recognition](https://arxiv.org/abs/2602.07262)
*Junbo Jacob Lian,Feng Xiong,Yujun Sun,Kaichen Ouyang,Mingyang Yu,Shengwei Fu,Zhong Rui,Zhang Yujun,Huiling Chen*

Main category: cs.CV

TL;DR: TwistNet-2D是一个轻量级模块，通过局部成对通道乘积和方向性空间位移来捕捉纹理特征，在少量参数增加下显著提升纹理识别性能。

- Motivation: 现有方法存在根本性矛盾：双线性池化和Gram矩阵捕捉全局通道相关性但破坏空间结构，而自注意力通过加权聚合而非显式成对特征交互来建模空间上下文。需要一种能同时编码特征共现位置和交互方式的方法。
- Method: 提出TwistNet-2D模块，核心是螺旋扭曲通道交互（STCI）：将特征图沿指定方向位移后进行逐元素通道乘法，捕捉结构化周期性纹理的跨位置共现模式。使用四个方向头聚合，通过学习通道重加权和sigmoid门控残差路径注入。
- Result: 在ResNet-18基础上仅增加3.5%参数和2%FLOPs，但在四个纹理和细粒度识别基准上持续超越参数匹配和更大的基线模型，包括ConvNeXt、Swin Transformer和混合CNN-Transformer架构。
- Conclusion: TwistNet-2D通过局部成对通道交互和方向性空间位移，有效解决了纹理识别中全局通道相关性与空间结构保持的矛盾，以极低计算成本显著提升性能。


### [44] [VideoNeuMat: Neural Material Extraction from Generative Video Models](https://arxiv.org/abs/2602.07272)
*Bowen Xue,Saeed Hadadan,Zheng Zeng,Fabrice Rousselle,Zahra Montazeri,Milos Hasan*

Main category: cs.CV

TL;DR: VideoNeuMat：从视频扩散模型中提取可重用神经材质资产的两阶段管道，将视频模型的材质知识转化为独立3D资产

- Motivation: 创建逼真的3D渲染材质需要高超的艺术技能，而生成模型因缺乏高质量训练数据受限。视频生成模型能产生逼真材质外观，但这些知识与几何和光照纠缠在一起，无法直接重用。
- Method: 两阶段方法：1）微调大型视频模型（Wan 2.1 14B）在受控相机和光照轨迹下生成材质样本视频，创建"虚拟测角反射计"；2）通过从较小Wan 1.3B视频主干微调的大型重建模型（LRM），从17个生成视频帧中重建紧凑神经材质参数。
- Result: 生成的材质在真实感和多样性上远超有限的合成训练数据，能够泛化到新的观察和光照条件，成功将互联网规模视频模型的材质知识转化为独立可重用的神经3D资产。
- Conclusion: VideoNeuMat证明可以从视频扩散模型中成功提取材质知识，转化为可重用的神经材质资产，解决了高质量材质训练数据稀缺的问题，为3D内容创作提供了新途径。


### [45] [Cross-View World Models](https://arxiv.org/abs/2602.07277)
*Rishabh Sharma,Gijs Hogervorst,Wayne E. Mackey,David J. Heeger,Stefano Martiniani*

Main category: cs.CV

TL;DR: XVWM通过跨视角预测目标训练世界模型，让智能体能够从不同视角（如鸟瞰图）进行规划，同时保持自我中心视角执行，利用多视角一致性作为几何正则化学习3D环境结构。

- Motivation: 现有世界模型通常只从单一自我中心视角操作，但许多任务（如导航）从其他视角（如鸟瞰图）规划会更有效。需要开发能够跨视角进行预测和规划的世界模型。
- Method: 提出跨视角世界模型（XVWM），通过跨视角预测目标训练：给定一个视角的帧序列，预测执行动作后相同或不同视角的未来状态。使用Aimlabs平台提供的同步多视角游戏数据训练，这些数据包含精确对齐的多相机记录和高频动作标签。
- Result: 模型能够为智能体提供跨视角的并行想象流，使智能体能够在最适合任务的参考系中进行规划，同时从自我中心视角执行。多视角一致性为空间基础表示提供了强大的学习信号。
- Conclusion: 跨视角世界模型通过几何正则化学习环境3D结构，实现多视角规划能力。从他人视角预测自身行动后果可能为多智能体环境中的视角采择奠定基础。


### [46] [Diabetic Retinopathy Lesion Segmentation through Attention Mechanisms](https://arxiv.org/abs/2602.07301)
*Aruna Jithesh,Chinmayi Karumuri,Venkata Kiran Reddy Kotha,Meghana Doddapuneni,Taehee Jeong*

Main category: cs.CV

TL;DR: 提出一种结合注意力机制的DeepLab-V3+模型，用于糖尿病视网膜病变四种病灶的像素级分割，在DDR数据集上取得性能提升，特别是微动脉瘤检测有临床显著改进。

- Motivation: 糖尿病视网膜病变是导致视力丧失和失明的眼病，早期检测至关重要。现有深度学习算法在病灶分割方面的临床应用有限，需要更精确的像素级注释来支持眼科医生筛查。
- Method: 在DeepLab-V3+模型中集成注意力机制，对DDR数据集的757张图像进行四种DR相关病灶的分割：微动脉瘤、软性渗出物、硬性渗出物和出血。
- Result: 注意力-DeepLab模型相比基线模型，平均精度(mAP)从0.3010提升到0.3326，平均交并比(mIoU)从0.1791提升到0.1928。微动脉瘤检测从0.0205提升到0.0763，这是临床显著改进。
- Conclusion: 集成注意力机制的DeepLab-V3+模型在DR病灶分割方面表现更好，特别是对微动脉瘤的检测有重要临床意义，因为微动脉瘤是DR最早可见的症状。


### [47] [Optimization of Precipitate Segmentation Through Linear Genetic Programming of Image Processing](https://arxiv.org/abs/2602.07310)
*Kyle Williams,Andrew Seltzman*

Main category: cs.CV

TL;DR: 开发基于线性遗传编程的图像过滤分割算法，用于自动检测增材制造铌基铜合金显微图中的析出物，替代人工标注，加速合金开发迭代

- Motivation: 当前增材制造铌基铜合金分析依赖人工标注显微图，由于对比度变化、噪声和图像伪影等问题，严重拖慢了合金开发迭代速度
- Method: 使用线性遗传编程优化图像过滤和分割算法，采用特定领域语言构建图像处理流水线，通过遗传算法迭代优化可调参数的图像过滤块序列
- Result: 在理想条件下（种群大小60，最大程序长度5块），系统找到接近人工精度的解决方案，平均评估误差1.8%，处理360万像素图像约需2秒
- Conclusion: 自动化工作实现了更快的迭代周期，促进了材料成分和加工空间的探索，最终有助于开发用于增材制造聚变反应堆部件的强韧、低活化、沉淀硬化铜合金


### [48] [LUCID-SAE: Learning Unified Vision-Language Sparse Codes for Interpretable Concept Discovery](https://arxiv.org/abs/2602.07311)
*Difei Gu,Yunhe Gao,Gerasimos Chatzoudis,Zihan Dong,Guoning Zhang,Bangwei Guo,Yang Zhou,Mu Zhou,Dimitris Metaxas*

Main category: cs.CV

TL;DR: LUCID提出了一种统一的视觉-语言稀疏自编码器，学习图像块和文本标记的共享潜在字典，通过最优传输匹配实现特征对齐，无需标注即可获得可解释的跨模态共享特征。

- Motivation: 当前稀疏自编码器按模态单独训练，产生的特征字典不可直接理解，且解释无法跨域迁移。需要一种统一的方法来学习可解释的跨模态共享表示。
- Method: LUCID采用统一的视觉-语言稀疏自编码器架构，学习共享潜在字典用于图像块和文本标记表示，同时保留私有容量处理模态特定细节。通过最优传输匹配目标实现特征对齐，无需标注数据。
- Result: LUCID产生可解释的共享特征，支持补丁级定位、建立跨模态神经元对应关系，并增强对相似性评估中概念聚类问题的鲁棒性。共享特征捕获了超越对象的多样化语义类别，包括动作、属性和抽象概念。
- Conclusion: LUCID提供了一种全面的可解释多模态表示学习方法，通过统一的稀疏编码实现跨模态概念发现，为自动化的字典解释和跨域理解提供了新途径。


### [49] [Seeing Roads Through Words: A Language-Guided Framework for RGB-T Driving Scene Segmentation](https://arxiv.org/abs/2602.07343)
*Ruturaj Reddy,Hrishav Bakul Barua,Junn Yong Loo,Thanh Thi Nguyen,Ganesh Krishnasamy*

Main category: cs.CV

TL;DR: CLARITY提出了一种动态RGB-热成像融合策略，通过视觉语言模型先验自适应调整模态贡献，在恶劣光照条件下实现鲁棒的道路场景语义分割。

- Motivation: 现有RGB-热成像融合方法采用静态融合策略，无法适应不同光照条件，导致模态特定噪声在网络中传播，影响自动驾驶在恶劣光照、阴影条件下的语义分割性能。
- Method: 1) 基于视觉语言模型先验动态调整融合策略，根据检测到的场景条件调制各模态贡献；2) 保留有效暗物体语义，避免先前噪声抑制方法错误丢弃；3) 引入分层解码器，跨尺度强制执行结构一致性以锐化细长物体边界。
- Result: 在MFNet数据集上达到62.3% mIoU和77.5% mAcc，建立了新的最先进性能。
- Conclusion: CLARITY通过动态融合策略和结构一致性机制，显著提升了在恶劣光照条件下的道路场景语义分割鲁棒性，为自动驾驶应用提供了更可靠的感知解决方案。


### [50] [Optimizing Few-Step Generation with Adaptive Matching Distillation](https://arxiv.org/abs/2602.07345)
*Lichen Bai,Zikai Zhou,Shitong Shao,Wenliang Zhong,Shuo Yang,Shuo Chen,Bojun Chen,Zeke Xie*

Main category: cs.CV

TL;DR: AMD提出自适应匹配蒸馏框架，通过奖励代理检测并逃离"禁区"，提升分布匹配蒸馏的稳定性和生成质量

- Motivation: 传统分布匹配蒸馏(DMD)在"禁区"区域不稳定，教师模型提供不可靠指导而伪教师排斥力不足，导致训练崩溃
- Method: 提出自适应匹配蒸馏(AMD)：1) 使用奖励代理显式检测禁区；2) 通过结构信号分解动态优先校正梯度；3) 引入排斥景观锐化增强能量壁垒防止失败模式坍缩
- Result: 在图像和视频生成任务(SDXL, Wan2.1)上显著提升样本保真度和训练鲁棒性，SDXL的HPSv2分数从30.64提升至31.25，优于现有方法
- Conclusion: 显式修正禁区内的优化轨迹对于提升少步生成模型的性能上限至关重要，AMD为分布匹配蒸馏提供了更稳定的训练框架


### [51] [Row-Column Separated Attention Based Low-Light Image/Video Enhancement](https://arxiv.org/abs/2602.07428)
*Chengqi Dong,Zhiyuan Cao,Tuoshi Qi,Kexin Wu,Yixing Gao,Fan Tang*

Main category: cs.CV

TL;DR: 提出RCSA模块改进U-Net，用于低光照图像/视频增强，通过行列分离注意力机制利用全局信息指导局部信息，减少参数计算量

- Motivation: 传统U-Net在低光照增强中缺乏全局信息指导，导致局部噪声大、细节丢失；注意力机制能更好利用全局信息但参数计算量大
- Method: 提出行列分离注意力模块(RCSA)，输入特征图行列的均值和最大值，利用全局信息指导局部信息；改进U-Net结构；提出两种时间损失函数用于视频增强保持时序一致性
- Result: 在LOL、MIT Adobe FiveK图像数据集和SDSD视频数据集上进行了广泛实验，证明了方法的有效性
- Conclusion: 提出的URCSA方法通过RCSA模块有效利用全局信息指导低光照增强，减少参数计算，在图像和视频增强任务中表现优异


### [52] [Perspective-aware fusion of incomplete depth maps and surface normals for accurate 3D reconstruction](https://arxiv.org/abs/2602.07444)
*Ondrej Hlinka,Georg Kaniak,Christian Kapeller*

Main category: cs.CV

TL;DR: 提出一种透视感知的对数深度融合方法，从深度和法线图重建3D表面，处理透视投影并填补深度缺失

- Motivation: 解决从单视角相机获取的深度和表面法线图重建3D表面的问题，现有基于正交梯度的深度-法线融合方法未考虑透视投影，导致度量精度不足
- Method: 提出透视感知的对数深度融合方法，扩展现有正交梯度方法，显式处理透视投影，同时利用表面法线信息填补深度测量缺失区域
- Result: 在DiLiGenT-MV数据集上的实验证明了方法的有效性，并突出了透视感知深度-法线融合的重要性
- Conclusion: 该方法能够从深度和法线图实现度量准确的3D重建，特别适用于单视角相机系统，通过透视感知融合提高了重建精度


### [53] [PTB-XL-Image-17K: A Large-Scale Synthetic ECG Image Dataset with Comprehensive Ground Truth for Deep Learning-Based Digitization](https://arxiv.org/abs/2602.07446)
*Naqcho Ali Mehdi*

Main category: cs.CV

TL;DR: 研究人员创建了PTB-XL-Image-17K数据集，包含17,271个合成12导联心电图图像，提供图像、分割掩码、时间序列信号、边界框标注和元数据，支持心电图数字化研究。

- Motivation: 心电图数字化对于利用历史临床数据至关重要，但缺乏大规模同时包含心电图图像和对应真实信号的数据集阻碍了研究进展。
- Method: 基于PTB-XL信号数据库，开发开源Python框架生成高质量合成心电图图像，可控制纸张速度、电压比例、采样率、网格外观等参数。
- Result: 成功生成17,271个样本，100%生成成功率，平均处理时间1.35秒/样本，提供五种互补数据类型，填补了心电图数字化研究的关键空白。
- Conclusion: PTB-XL-Image-17K是首个支持完整心电图数字化流程的大规模资源，包括导联检测、波形分割和信号提取，为严格评估提供了完整真实标注。


### [54] [SoulX-FlashHead: Oracle-guided Generation of Infinite Real-time Streaming Talking Heads](https://arxiv.org/abs/2602.07449)
*Tan Yu,Qian Qiao,Le Shen,Ke Zhou,Jincheng Hu,Dian Sheng,Bo Hu,Haoming Qin,Jun Gao,Changhai Zhou,Shunshun Yin,Siyuan Liu*

Main category: cs.CV

TL;DR: SoulX-FlashHead是一个1.3B参数的实时音频驱动肖像生成框架，通过流式感知时空预训练和Oracle引导双向蒸馏技术，在保持高视觉质量的同时实现96 FPS的推理速度。

- Motivation: 现有音频驱动肖像生成方法面临两难：大规模模型计算成本过高，轻量级模型则牺牲面部表示完整性和时间稳定性。需要在高质量视觉输出和低延迟流式处理之间找到平衡。
- Method: 1) 提出1.3B参数统一框架；2) 引入流式感知时空预训练，配备时序音频上下文缓存机制；3) 提出Oracle引导双向蒸馏，利用真实运动先验提供物理指导；4) 构建VividHead数据集（782小时严格对齐视频）。
- Result: 在HDTF和VFHQ基准测试中达到最先进性能，Lite变体在单张RTX 4090上实现96 FPS推理速度，支持超快速交互而不牺牲视觉连贯性。
- Conclusion: SoulX-FlashHead成功解决了音频驱动肖像生成中高保真视觉质量与低延迟流式处理之间的平衡问题，为实时、无限长度、高质量流式视频生成提供了有效解决方案。


### [55] [SpatialReward: Bridging the Perception Gap in Online RL for Image Editing via Explicit Spatial Reasoning](https://arxiv.org/abs/2602.07458)
*Yancheng Long,Yankai Yang,Hongyang Wei,Wei Chen,Tianke Zhang,Haonan fan,Changyi Liu,Kaiyu Jiang,Jiankang Chen,Kaiyu Tang,Bin Wen,Fan Yang,Tingting Gao,Han Li,Shuo Yang*

Main category: cs.CV

TL;DR: SpatialReward是一个通过空间推理增强奖励信号的模型，解决了在线强化学习图像编辑中奖励信号稀缺和现有评估器"注意力崩溃"的问题，在多个基准测试中取得SOTA性能。

- Motivation: 在线强化学习在复杂图像编辑中面临可靠细粒度奖励信号稀缺的问题。现有评估器存在"注意力崩溃"现象，即模型忽视跨图像比较和细粒度细节，导致感知不准确和分数校准错误。
- Method: 提出SpatialReward奖励模型，通过显式空间推理进行精确验证。将推理锚定在预测的编辑区域，使语义判断基于像素级证据。在精心策划的260k空间感知数据集上进行训练。
- Result: 在MMRB2和EditReward-Bench上达到SOTA性能，在提出的MultiEditReward-Bench上超越专有评估器。作为在线RL的鲁棒信号，将OmniGen2在GEdit-Bench上提升+0.90，超越领先判别模型，是GPT-4.1增益的两倍。
- Conclusion: 空间推理对于实现图像编辑中的有效对齐至关重要。SpatialReward通过像素级证据和空间推理显著提高了评估准确性，为在线强化学习图像编辑提供了可靠的奖励信号。


### [56] [GlobalWasteData: A Large-Scale, Integrated Dataset for Robust Waste Classification and Environmental Monitoring](https://arxiv.org/abs/2602.07463)
*Misbah Ijaz,Saif Ur Rehman Khan,Abd Ur Rehman,Tayyaba Asif,Sebastian Vollmer,Andreas Dengel,Muhammad Nabeel Asim*

Main category: cs.CV

TL;DR: 研究人员创建了GlobalWasteData（GWD）数据集，整合了多个公开的垃圾分类数据集，包含89,807张图像、14个主要类别和68个子类，旨在解决现有数据集碎片化、不一致和偏差问题。

- Motivation: 现有垃圾分类数据集存在碎片化、不一致和特定环境偏差问题，类别名称、标注格式、图像条件和类别分布差异导致难以整合数据集或训练泛化能力强的模型。
- Method: 通过合并多个公开数据集创建统一的GWD数据集，进行质量过滤、重复去除和元数据生成等预处理步骤，确保一致的标注、改进的领域多样性和更平衡的类别表示。
- Result: 创建了包含89,807张图像、14个主要类别和68个子类的GWD数据集，提供一致的标注、改进的领域多样性和更平衡的类别表示，为开发鲁棒且可泛化的垃圾识别模型奠定基础。
- Conclusion: GWD数据集为环境监测、回收自动化和垃圾识别的机器学习应用提供了坚实基础，公开可用以促进未来研究和可重复性。


### [57] [Thermal odometry and dense mapping using learned ddometry and Gaussian splatting](https://arxiv.org/abs/2602.07493)
*Tianhao Zhou,Yujia Chen,Zhihao Zhan,Yuhang Ming,Jianzhu Huai*

Main category: cs.CV

TL;DR: TOM-GS：首个基于高斯泼溅的热成像相机SLAM系统，结合学习里程计与稠密建图，在恶劣条件下实现鲁棒运动估计和高质量重建

- Motivation: 热成像传感器在黑暗、灰尘和烟雾中具有鲁棒性，但现有热成像里程计和建图方法主要是几何方法，在不同数据集上表现不佳且无法生成稠密地图。受高斯泼溅技术高效高质量重建能力的启发，需要开发专门的热成像SLAM系统。
- Method: 提出TOM-GS方法，整合学习型里程计与基于高斯泼溅的稠密建图。系统包含专门的热图像增强模块和单目深度集成，是首个为热成像相机定制的高斯泼溅SLAM系统。
- Result: 在运动估计和新视角渲染的广泛实验中，TOM-GS优于现有的学习方法，验证了学习型流程在鲁棒热成像里程计和稠密重建方面的优势。
- Conclusion: TOM-GS成功将高斯泼溅技术应用于热成像SLAM，通过结合学习型里程计和稠密建图，在恶劣条件下实现了鲁棒的运动估计和高质量环境感知。


### [58] [Learning Brain Representation with Hierarchical Visual Embeddings](https://arxiv.org/abs/2602.07495)
*Jiawen Zheng,Haonan Jia,Ming Li,Yuhui Zheng,Yufeng Zeng,Yang Gao,Chen Liang*

Main category: cs.CV

TL;DR: 提出一种利用多预训练视觉编码器进行脑信号-图像对齐的新方法，通过对比学习和融合先验提升视觉解码的准确性和重建质量。

- Motivation: 当前脑信号视觉解码方法大多关注高层语义特征而忽略像素级细节，限制了我们对人类视觉系统的理解，需要更全面的脑-图像对齐策略。
- Method: 使用多个具有不同归纳偏置的预训练视觉编码器捕获层次化和多尺度视觉表示，通过对比学习实现脑信号与视觉嵌入的有效对齐，并引入融合先验增强跨模态分布一致性。
- Result: 大量定量和定性实验表明，该方法在检索准确性和重建保真度之间取得了良好平衡。
- Conclusion: 提出的多编码器对齐策略和融合先验方法能够更全面地解码脑信号中的视觉信息，为理解人类视觉系统提供了新视角。


### [59] [IM-Animation: An Implicit Motion Representation for Identity-decoupled Character Animation](https://arxiv.org/abs/2602.07498)
*Zhufeng Xu,Xuan Gao,Feng-Lin Liu,Haoxian Zhang,Zhixue Fang,Yu-Kun Lai,Xiaoqiang Liu,Pengfei Wan,Lin Gao*

Main category: cs.CV

TL;DR: IM-Animation：一种新颖的隐式运动表示方法，通过将每帧运动压缩为紧凑的1D运动token，解决现有方法的空间不匹配、身份泄漏和运动-外观纠缠问题，实现高质量角色动画生成。

- Motivation: 现有角色动画方法存在明显缺陷：显式方法（如骨架、DWPose）难以处理空间不匹配和身体比例变化；隐式方法虽然能捕捉高级运动语义，但存在身份信息泄漏和运动-外观纠缠问题。
- Method: 提出紧凑的1D运动token表示，放松2D表示的空间约束并防止身份泄漏；设计基于时间一致掩码token的重定向模块，通过时间训练瓶颈减少源图像运动干扰；采用三阶段训练策略提高效率并确保高保真度。
- Result: 大量实验表明，IM-Animation的隐式运动表示和生成能力在性能上优于或与最先进方法相当，能够有效解决身份泄漏和运动-外观纠缠问题。
- Conclusion: 提出的隐式运动表示和IM-Animation框架成功解决了现有角色动画方法的局限性，通过1D运动token和掩码token重定向模块实现了高质量、一致的角色动画生成。


### [60] [Adaptive Image Zoom-in with Bounding Box Transformation for UAV Object Detection](https://arxiv.org/abs/2602.07512)
*Tao Wang,Chenyu Lin,Chenwei Tang,Jizhe Zhou,Deng Xiong,Jianan Li,Jian Zhao,Jiancheng Lv*

Main category: cs.CV

TL;DR: ZoomDet：一种用于无人机图像目标检测的自适应放大框架，通过非均匀放大对象区域来改善小目标检测性能

- Motivation: 无人机图像中的目标通常比普通场景图像中的目标更小、更稀疏，这阻碍了有效目标检测器的优化。需要自适应放大对象以更好地捕获目标特征。
- Method: 提出轻量级偏移预测方案和基于框的放大目标来学习输入图像的非均匀放大。基于学习的放大变换，提出角对齐边界框变换方法，将真实框变换到放大空间进行训练，在推理时将预测框变换回原始空间。
- Result: 在VisDrone、UAVDT和SeaDronesSee三个无人机目标检测数据集上进行了广泛实验。在SeaDronesSee数据集上，ZoomDet使用Faster R-CNN模型带来了超过8.4个绝对mAP增益，仅增加约3ms延迟。
- Conclusion: ZoomDet是一种架构无关的自适应放大框架，可应用于任意目标检测架构，显著提升无人机图像中小目标的检测性能。


### [61] [CA-YOLO: Cross Attention Empowered YOLO for Biomimetic Localization](https://arxiv.org/abs/2602.07523)
*Zhen Zhang,Qing Zhao,Xiuhe Li,Cheng Wang,Guoqiang Zhu,Yu Zhang,Yining Huo,Hongyi Yu,Yi Zhang*

Main category: cs.CV

TL;DR: 提出基于CA-YOLO的仿生稳定定位系统，通过引入小目标检测头和特征融合注意力机制提升目标检测精度，结合仿生云台跟踪控制策略，在COCO和VisDrone数据集上分别提升3.94%和4.90%的平均精度。

- Motivation: 现代复杂环境中，现有目标定位系统在精度和小目标识别能力方面存在局限，需要提升目标定位的准确性和对小目标的识别能力。
- Method: 1. 基于CA-YOLO的仿生稳定定位系统；2. 在YOLO骨干网络中集成仿生模块，包括小目标检测头和特征融合注意力机制(CFAM)；3. 借鉴人类前庭眼反射(VOR)开发仿生云台跟踪控制策略，包含中心定位、稳定性优化、自适应控制系数调整和智能重捕获功能。
- Result: CA-YOLO在标准数据集(COCO和VisDrone)上优于原始模型，平均精度分别提升3.94%和4.90%；时间敏感目标定位实验验证了该仿生稳定定位系统的有效性和实用性。
- Conclusion: 提出的仿生稳定定位系统通过仿生视觉聚焦机制和前庭眼反射原理，有效提升了目标定位精度和小目标识别能力，在复杂环境中具有实用价值。


### [62] [Evaluating Object-Centric Models beyond Object Discovery](https://arxiv.org/abs/2602.07532)
*Krishnakant Singh,Simone Schaub-Meyer,Stefan Roth*

Main category: cs.CV

TL;DR: 该论文提出了一种新的评估框架，用于更全面地评估对象中心学习模型，通过使用指令调优的视觉语言模型作为评估器，并引入统一的任务和指标来联合评估定位能力和表示有用性。

- Motivation: 当前对象中心学习模型的评估存在两个主要问题：1）现有基准测试对模型表示有用性的洞察有限；2）定位能力和表示有用性使用分离的指标进行评估，导致评估不一致。
- Method: 1）使用指令调优的视觉语言模型作为评估器，实现跨多样化视觉问答数据集的可扩展基准测试；2）引入统一评估任务和指标，联合评估定位（where）和表示有用性（what）；3）包含简单的多特征重建基线作为参考点。
- Result: 提出了一个更全面的评估框架，能够更准确地衡量对象中心学习模型在复杂推理任务中的表现，同时解决了现有评估方法中定位和表示评估分离的问题。
- Conclusion: 该论文为对象中心学习模型提供了一个更全面、更一致的评估方法，通过统一评估定位和表示有用性，并使用视觉语言模型作为评估器，能够更好地衡量模型在支持组合泛化和OOD鲁棒性方面的实际效果。


### [63] [Fine-Grained Cat Breed Recognition with Global Context Vision Transformer](https://arxiv.org/abs/2602.07534)
*Mowmita Parvin Hera,Md. Shahriar Mahmud Kallol,Shohanur Rahman Nirob,Md. Badsha Bulbul,Jubayer Ahmed,M. Zhourul Islam,Hazrat Ali,Mohammmad Farhad Bulbul*

Main category: cs.CV

TL;DR: 使用GCViT-Tiny架构在Oxford-IIIT Pet Dataset子集上实现猫品种分类，通过数据增强达到92.00%测试准确率

- Motivation: 猫品种识别具有挑战性，因为不同品种在毛皮图案、面部结构和颜色上差异细微。需要开发准确的方法来支持兽医诊断、动物收容所管理和移动端识别系统等应用。
- Method: 采用全局上下文视觉变换器（GCViT-Tiny）架构进行猫品种识别，使用Oxford-IIIT Pet Dataset的高分辨率图像子集，通过旋转、水平翻转和亮度调整等数据增强技术提升模型泛化能力。
- Result: GCViT-Tiny模型在测试集上达到92.00%准确率，验证集上达到94.54%准确率，证明了基于变换器的架构在细粒度图像分类任务中的有效性。
- Conclusion: 变换器架构在猫品种分类等细粒度视觉任务中表现优异，该方法具有实际应用价值，包括兽医诊断、动物收容所管理和移动端识别系统，并提供了Hugging Face演示。


### [64] [Beyond Core and Penumbra: Bi-Temporal Image-Driven Stroke Evolution Analysis](https://arxiv.org/abs/2602.07535)
*Md Sazidur Rahman,Kjersti Engan,Kathinka Dæhli Kurz,Mahdieh Khanmohammadi*

Main category: cs.CV

TL;DR: 提出双时间点分析框架，利用统计描述符、放射组学纹理特征和深度特征嵌入，分析脑卒中缺血组织的时空演化，区分可挽救与不可挽救组织。

- Motivation: 传统单时间点分割无法捕捉脑卒中生物学异质性和时间演化，需要开发能表征组织状态转变的分析方法。
- Method: 使用双时间点（入院T1和随访T2）CT灌注和DWI数据，提取统计、放射组学纹理和深度特征（mJ-Net和nnU-Net），构建6个ROI区域，在特征空间分析组织演化。
- Result: 在18名成功再灌注患者中，区域级表征呈现有意义的聚类：可恢复的缺血半暗带与健康组织特征相似，梗死区域形成独立分组。深度特征空间（特别是mJ-Net）能显著区分可挽救与不可挽救组织。
- Conclusion: 编码器衍生的特征流形反映了底层组织表型和状态转变，为基于影像的脑卒中演化量化提供了新见解。


### [65] [LLM-Guided Diagnostic Evidence Alignment for Medical Vision-Language Pretraining under Limited Pairing](https://arxiv.org/abs/2602.07540)
*Huimin Yan,Liang Bai,Xian Yang,Long Chen*

Main category: cs.CV

TL;DR: 提出LGDEA方法，通过LLM提取诊断证据构建共享证据空间，实现证据级跨模态对齐，减少对配对数据的依赖

- Motivation: 现有医学视觉-语言预训练方法存在两个问题：全局对齐容易被非诊断信息主导，局部对齐无法整合关键诊断证据，导致难以学习可靠的诊断表示，限制了在配对数据有限场景的应用
- Method: LGDEA方法：利用LLM从放射学报告中提取关键诊断证据，构建共享诊断证据空间，实现证据感知的跨模态对齐，能够有效利用大量未配对的医学图像和报告
- Result: 在短语定位、图像-文本检索和零样本分类任务上取得一致且显著的改进，甚至能与依赖大量配对数据的预训练方法相媲美
- Conclusion: 通过证据级对齐方法，LGDEA能够更符合医学诊断过程，显著减少对配对数据的依赖，在医学视觉-语言预训练中表现出优越性能


### [66] [MUFASA: A Multi-Layer Framework for Slot Attention](https://arxiv.org/abs/2602.07544)
*Sebastian Bock,Leonie Schüßler,Krishnakant Singh,Simone Schaub-Meyer,Stefan Roth*

Main category: cs.CV

TL;DR: MUFASA是一个轻量级即插即用框架，通过在多层ViT特征上执行slot attention来提升无监督物体分割性能，利用各层的语义信息改善分割结果和训练收敛。

- Motivation: 当前基于slot attention的无监督物体中心学习方法仅使用预训练ViT的最后一层特征，忽略了其他层包含的丰富语义信息。为了充分利用这些潜在语义信息，需要开发能够整合多层特征的方法。
- Method: 提出MUFASA框架，在ViT编码器的多个特征层上计算slot attention，充分利用各层的语义丰富性。设计融合策略将多层获得的slot聚合成统一的物体中心表示，可轻松集成到现有OCL方法中。
- Result: 将MUFASA集成到现有OCL方法中，在多个数据集上改善了分割结果，达到了新的最先进水平，同时仅增加少量推理开销就提高了训练收敛速度。
- Conclusion: MUFASA通过利用ViT多层特征中的语义信息，有效提升了基于slot attention的无监督物体分割性能，证明了整合多层特征对物体中心学习的重要性。


### [67] [Revealing the Semantic Selection Gap in DINOv3 through Training-Free Few-Shot Segmentation](https://arxiv.org/abs/2602.07550)
*Hussni Mohd Zakir,Eric Tatt Wei Ho*

Main category: cs.CV

TL;DR: 本文提出FSSDINO，一个无需训练的少样本语义分割基线方法，利用DINOv3的冻结特征、类别原型和Gram矩阵优化，在多个基准测试中表现优异。研究发现"最后层"特征是一个欺骗性强的基线，而中间层存在更高性能潜力，但传统启发式方法难以可靠识别这些高质量特征，揭示了"语义选择鸿沟"。

- Motivation: 研究动机是探索自监督Vision Transformers（如DINOv3）在少样本语义分割任务中的内在能力。虽然DINOv3等基础模型提供了丰富的特征表示，但如何有效利用这些冻结特征进行少样本分割，以及不同层特征的质量差异，尚未得到充分研究。
- Method: 提出FSSDINO方法：1）使用冻结的DINOv3特征；2）基于类别特定原型进行分割；3）通过Gram矩阵优化特征表示。这是一个无需训练的基线方法，仅使用主干网络的最终层特征。
- Result: 在二元、多类别和跨域少样本分割基准测试中，FSSDINO与需要复杂解码器或测试时适应的专门方法表现相当。通过Oracle引导的层分析发现，标准最后层特征与全局最优中间表示之间存在显著性能差距，揭示了"最安全vs最优"的困境。
- Conclusion: 研究确立了"最后层"作为欺骗性强的基线，揭示了DINOv3中潜在的语义能力。传统启发式方法无法可靠识别高质量特征，存在"语义选择鸿沟"。这为未来研究提供了重要诊断，表明基础模型中存在未被充分利用的语义潜力。


### [68] [FlexID: Training-Free Flexible Identity Injection via Intent-Aware Modulation for Text-to-Image Generation](https://arxiv.org/abs/2602.07554)
*Guandong Li,Yijun Ding*

Main category: cs.CV

TL;DR: FlexID是一个无需训练的个人化文生图框架，通过意图感知调制正交解耦身份特征，在保持身份一致性和文本适配性之间实现最佳平衡。

- Motivation: 现有无需训练方法依赖刚性的视觉特征注入，导致身份保真度和文本适配性之间存在冲突。需要一种能动态平衡这两者的解决方案。
- Method: 提出FlexID框架：1) 语义身份投影器(SIP)在语言空间注入高层先验；2) 视觉特征锚点(VFA)在潜在空间确保结构保真度；3) 上下文感知自适应门控(CAG)机制根据编辑意图和扩散时间步动态调制两个流权重。
- Result: 在IBench上的大量实验表明，FlexID在身份一致性和文本遵循性之间实现了最先进的平衡，为复杂叙事生成提供了高效解决方案。
- Conclusion: FlexID通过意图感知调制正交解耦身份特征，能自动放松刚性视觉约束，实现身份保持和语义变化的协同，解决了现有方法的局限性。


### [69] [VISOR: VIsual Spatial Object Reasoning for Language-driven Object Navigation](https://arxiv.org/abs/2602.07555)
*Francesco Taioli,Shiping Yang,Sonia Raychaudhuri,Marco Cristani,Unnat Jain,Angel X Chang*

Main category: cs.CV

TL;DR: 提出一个3B参数的视觉-语言-动作智能体，通过显式图像推理直接回答目标识别和动作选择问题，替代传统多模型管道，提升可解释性、泛化能力和导航效率。

- Motivation: 现有方法存在两个问题：(1)端到端训练模型难以泛化且缺乏动作级可解释性；(2)模块化零样本管道存在错误传播、计算成本高、难以将推理整合到导航策略中。需要一种更紧凑、可解释且泛化能力强的解决方案。
- Method: 提出3B参数的视觉-语言-动作智能体，采用显式图像推理而非原始嵌入匹配。推理过程分为三个阶段："思考"、"思考总结"和"动作"，直接回答"这是目标对象吗？"和"为什么采取这个动作？"
- Result: 该方法实现了改进的可解释性、更强的泛化能力和更高效的导航，消除了多模型管道拼接的需求。
- Conclusion: 通过紧凑的视觉-语言-动作智能体实现人类般的具身推理，在目标识别和动作选择方面优于现有方法，提供更好的可解释性和泛化性能。


### [70] [SIGMA: Selective-Interleaved Generation with Multi-Attribute Tokens](https://arxiv.org/abs/2602.07564)
*Xiaoyan Zhang,Zechen Bai,Haofan Wang,Yiren Song*

Main category: cs.CV

TL;DR: SIGMA是一个基于Bagel统一模型的后训练框架，通过引入选择性多属性令牌，支持在扩散变换器中实现交错多条件生成，提升组合编辑、属性迁移和多模态对齐能力。

- Motivation: 现有统一模型如Bagel虽然能将多个视觉任务对齐到单个扩散变换器中，但仅限于单条件输入，缺乏从多个异构源合成结果的灵活性。需要一种能够处理交错多条件生成的方法。
- Method: 提出SIGMA后训练框架，引入选择性多属性令牌（风格、内容、主题、身份令牌），使模型能够解释和组合交错文本-图像序列中的多个视觉条件。在Bagel统一骨干上使用70万个交错示例进行后训练。
- Result: SIGMA在组合编辑、选择性属性迁移和细粒度多模态对齐方面表现优异，相比Bagel在组合任务上有显著提升，改善了可控性、跨条件一致性和视觉质量。
- Conclusion: SIGMA通过引入多属性令牌和后训练框架，成功扩展了统一扩散变换器的能力，使其能够处理交错多条件生成，为组合视觉编辑和生成任务提供了更灵活的解决方案。


### [71] [Human Identification at a Distance: Challenges, Methods and Results on the Competition HID 2025](https://arxiv.org/abs/2602.07565)
*Jingzhe Ma,Meng Zhang,Jianlong Yu,Kun Liu,Zunxiao Xu,Xue Cheng,Junjie Zhou,Yanfei Wang,Jiahang Li,Zepeng Wang,Kazuki Osamura,Rujie Liu,Narishige Abe,Jingjie Wang,Shunli Zhang,Haojun Xie,Jiajun Wu,Weiming Wu,Wenxiong Kang,Qingshuo Gao,Jiaming Xiong,Xianye Ben,Lei Chen,Lichen Song,Junjian Cui,Haijun Xiong,Junhao Lu,Bin Feng,Mengyuan Liu,Ji Zhou,Baoquan Zhao,Ke Xu,Yongzhen Huang,Liang Wang,Manuel J Marin-Jimenez,Md Atiqur Rahman Ahad,Shiqi Yu*

Main category: cs.CV

TL;DR: 该论文介绍了HID竞赛使用SUSTech-Competition数据集进行步态识别的最新进展，2025年最佳方法达到94.2%准确率，创下新纪录。

- Motivation: 远距离人体识别(HID)具有挑战性，因为传统生物特征如人脸和指纹在真实场景中难以获取。步态识别提供了实用替代方案，可在远距离可靠捕获。HID竞赛旨在促进步态识别进展并提供公平评估平台。
- Method: 自2023年起，竞赛采用具有挑战性的SUSTech-Competition数据集，该数据集包含服装、携带物品和视角的显著变化。不提供专用训练数据，参赛者需使用外部数据集训练模型。每年使用不同随机种子生成不同评估分割，减少过拟合风险并支持跨域泛化的公平评估。
- Result: HID 2025明确检验算法进展是否能超越先前观察到的准确率极限。尽管难度增加，参赛者仍取得进一步改进，最佳方法达到94.2%准确率，在该数据集上创下新基准。
- Conclusion: 论文分析了关键技术趋势，并概述了步态识别未来研究的潜在方向。HID竞赛通过公平评估平台持续推动步态识别领域的发展。


### [72] [Cross-Camera Cow Identification via Disentangled Representation Learning](https://arxiv.org/abs/2602.07566)
*Runcheng Wang,Yaru Chen,Guiguo Zhang,Honghua Jiang,Yongliang Qiao*

Main category: cs.CV

TL;DR: 提出基于解耦表征学习的跨摄像头奶牛识别框架，利用子空间可识别性保证理论，通过特征解耦模块分离身份相关特征，显著提升跨摄像头泛化能力。

- Motivation: 现有动物识别方法在受控单摄像头环境下表现良好，但在跨摄像头场景中面临严重泛化挑战。当模型从源摄像头部署到具有不同光照、背景、视角和成像特性的新监控节点时，识别性能急剧下降，限制了非接触技术在动态真实农场环境中的大规模应用。
- Method: 提出基于解耦表征学习的跨摄像头奶牛识别框架，利用子空间可识别性保证理论，设计原则驱动的特征解耦模块，将观测图像分解为多个正交潜在子空间，有效分离跨摄像头不变的稳定身份相关生物特征。
- Result: 构建了包含五个不同摄像头节点的高质量数据集，涵盖异构采集设备和复杂的光照角度变化。在七个跨摄像头任务上的广泛实验表明，该方法平均准确率达到86.0%，显著优于仅源摄像头基线（51.9%）和最强的跨摄像头基线方法（79.8%）。
- Conclusion: 本研究建立了基于子空间理论的特征解耦框架，用于协同跨摄像头奶牛识别，为不受控智能农场环境中的精确动物监测提供了新范式。


### [73] [Visualizing the Invisible: Enhancing Radiologist Performance in Breast Mammography via Task-Driven Chromatic Encoding](https://arxiv.org/abs/2602.07568)
*Hui Ye,Shilong Yang,Yexuan Xing,Juan Yu,Yaoqin Xie,Wei Zhang,Chulong Zhang*

Main category: cs.CV

TL;DR: MammoColor是一个端到端框架，通过任务驱动的色彩编码将单通道乳腺X光片转换为彩色增强视图，提高致密乳腺的检测性能。

- Motivation: 乳腺X光筛查在致密乳腺中敏感性较低，组织重叠和细微发现增加了感知难度，需要改进检测方法。
- Method: 开发了MammoColor框架，包含任务驱动色彩编码模块，与BI-RADS分类器耦合，在VinDr-Mammo数据集上端到端训练，并在多个数据集和临床队列中评估。
- Result: 在VinDr-Mammo上AUC从0.7669提升到0.8461，致密乳腺提升更大（0.749到0.835）。多读者研究中特异性从0.90提高到0.96，敏感性相当。
- Conclusion: 任务驱动色彩编码提供了优化的色彩表示，可能提高感知显著性并减少乳腺X光分诊中的假阳性召回。


### [74] [ViCA: Efficient Multimodal LLMs with Vision-Only Cross-Attention](https://arxiv.org/abs/2602.07574)
*Wenjie Liu,Hao Wu,Xin Qiu,Yingqi Fan,Yihan Zhang,Anhao Zhao,Yunpu Ma,Xiaoyu Shen*

Main category: cs.CV

TL;DR: ViCA是一种高效的多模态大语言模型架构，通过稀疏跨注意力机制大幅减少视觉处理计算量，仅保留4%的视觉侧计算就能达到98%的基线准确率。

- Motivation: 现有MLLM采用统一的注意力设计，在每个Transformer层都处理视觉和文本token，导致巨大的计算开销。研究发现投影后的视觉嵌入已与语言空间对齐，且有效的视觉-语言交互仅发生在少数层中。
- Method: 提出ViCA架构，视觉token绕过所有自注意力和前馈层，仅通过选定的稀疏跨注意力层与文本交互，形成硬件友好的推理流程。
- Result: 在3个MLLM骨干、9个多模态基准和26个剪枝基线测试中，ViCA保持98%基线准确率，视觉侧计算降至4%，单批次推理加速3.5倍，多批次加速10倍以上，视觉处理开销接近纯文本LLM。
- Conclusion: ViCA通过稀疏跨注意力实现了卓越的性能-效率权衡，提供了硬件友好的推理流程，且与token剪枝方法正交，可进一步组合提升效率。


### [75] [Automated rock joint trace mapping using a supervised learning model trained on synthetic data generated by parametric modelling](https://arxiv.org/abs/2602.07590)
*Jessica Ka Yi Chiu,Tom Frode Hansen,Eivind Magnus Paulsen,Ole Jakob Mengshoel*

Main category: cs.CV

TL;DR: 提出一种地质驱动的机器学习方法，通过合成数据生成和图像分割实现岩石节理迹线自动映射，解决真实数据稀缺和类别不平衡问题。

- Motivation: 解决岩石节理迹线自动映射中真实数据有限、类别不平衡以及地质特征保持的挑战，为地质工程提供可靠的分析工具。
- Method: 结合地质建模、合成数据生成和监督图像分割：1) 使用离散断裂网络模型生成具有地质代表性的合成图像；2) 采用混合训练和预训练后微调的策略训练分割模型。
- Result: 合成数据能有效支持监督节理检测；混合训练在标签一致时表现良好，微调对噪声标签更稳健；少量真实数据微调可实现有用泛化；定性分析显示比定量指标更清晰的地质意义。
- Conclusion: 该方法为可靠节理映射提供基础，支持进一步研究领域适应和评估，展示了地质驱动机器学习在地质工程中的应用潜力。


### [76] [TeleBoost: A Systematic Alignment Framework for High-Fidelity, Controllable, and Robust Video Generation](https://arxiv.org/abs/2602.07595)
*Yuanzhi Liang,Xuan'er Wu,Yirui Liu,Yijie Fang,Yizhen Fan,Ke Hao,Rui Li,Ruiying Liu,Ziqi Ni,Peng Yu,Yanbo Wang,Haibin Huang,Qizhen Weng,Chi Zhang,Xuelong Li*

Main category: cs.CV

TL;DR: 提出一个系统化的视频生成后训练框架，将监督策略塑造、奖励驱动的强化学习和基于偏好的精炼整合到单一稳定性约束优化堆栈中，以提升感知保真度、时间连贯性和提示遵循能力。

- Motivation: 后训练是将预训练视频生成器转化为生产导向模型的关键步骤，需要解决高计算成本、时间累积失败模式以及反馈异质、不确定且弱区分性等实际约束。
- Method: 采用分阶段、诊断驱动的优化方法，将监督策略塑造、奖励驱动的强化学习和基于偏好的精炼整合到稳定性约束优化堆栈中，围绕实际视频生成约束设计框架。
- Result: 框架提供了清晰的蓝图，用于构建可扩展的后训练流程，在保持初始化可控性的同时，提升感知保真度、时间连贯性和提示遵循能力。
- Conclusion: 该系统性后训练框架为构建稳定、可扩展且在实际部署中有效的视频生成后训练流程提供了完整解决方案。


### [77] [Fine-R1: Make Multi-modal LLMs Excel in Fine-Grained Visual Recognition by Chain-of-Thought Reasoning](https://arxiv.org/abs/2602.07605)
*Hulingxiao He,Zijun Geng,Yuxin Peng*

Main category: cs.CV

TL;DR: Fine-R1：针对细粒度视觉识别的MLLM，通过思维链监督微调和三元组增强策略优化，仅需4-shot训练即可超越现有方法

- Motivation: 多模态大语言模型在粗粒度视觉任务上表现良好，但在细粒度视觉识别上存在困难，需要大量标注数据且容易过拟合已见子类别，对新子类别泛化能力差
- Method: 采用R1风格训练框架：1) 思维链监督微调，构建高质量细粒度视觉识别思维链数据集；2) 三元组增强策略优化，包括类内增强和类间增强
- Result: 仅用4-shot训练，Fine-R1在识别已见和未见子类别上都超越了现有通用MLLM、推理MLLM甚至对比学习CLIP模型
- Conclusion: Fine-R1在细粒度视觉识别上表现出色，特别适用于知识密集型领域，其中获取所有子类别的专家标注很困难


### [78] [HistoMet: A Pan-Cancer Deep Learning Framework for Prognostic Prediction of Metastatic Progression and Site Tropism from Primary Tumor Histopathology](https://arxiv.org/abs/2602.07608)
*Yixin Chen,Ziyu Su,Lingbin Meng,Elshad Hasanov,Wei Chen,Anil Parwani,M. Khalid Khan Niazi*

Main category: cs.CV

TL;DR: 提出HistoMet框架，通过两阶段决策流程从原发肿瘤病理图像预测转移风险和转移部位，整合语言定义概念提升临床可解释性

- Motivation: 转移是癌症死亡主要原因，但直接从病理图像预测转移风险和转移部位仍是挑战。现有方法通常孤立处理这两个任务，未建模临床决策流程
- Method: 提出决策感知、概念对齐的MIL框架HistoMet，采用两模块预测流程：先评估转移风险，再对高风险病例预测转移部位；整合语言定义和数据自适应转移概念，使用预训练病理视觉语言模型
- Result: 在6504名患者的多机构泛癌队列中，在95%敏感性设置下显著减少下游工作量；对转移病例实现宏观F1 74.6±1.3，宏观一对多AUC 92.1
- Conclusion: 显式建模临床决策结构能够直接从原发肿瘤病理学实现稳健可部署的转移进展和部位倾向性预后预测


### [79] [AD-MIR: Bridging the Gap from Perception to Persuasion in Advertising Video Understanding via Structured Reasoning](https://arxiv.org/abs/2602.07625)
*Binxiao Xu,Junyu Feng,Xiaopeng Lin,Haodong Li,Zhiyuan Feng,Bohan Zeng,Shaolin Lu,Ming Lu,Qi She,Wentao Zhang*

Main category: cs.CV

TL;DR: AD-MIR是一个用于广告视频理解的两阶段框架，通过结构化记忆构建和结构化推理代理，将像素级感知与高层次营销逻辑连接起来，在AdsQA基准测试中达到SOTA性能。

- Motivation: 现有智能体在广告视频理解方面存在认知鸿沟，难以将像素级感知与高层次营销策略连接起来，需要专门框架来解码广告意图。
- Method: 采用两阶段架构：1) 结构感知记忆构建阶段，将原始视频转换为结构化数据库，整合语义检索和精确关键词匹配，优先处理细粒度品牌细节；2) 结构化推理代理，模拟营销专家通过迭代询问循环分解叙事，推断隐含说服策略，并采用基于证据的自我纠正机制验证洞察。
- Result: 在AdsQA基准测试中，AD-MIR在严格准确率上比最强通用智能体DVD提升1.8%，在宽松准确率上提升9.5%，达到最先进性能。
- Conclusion: 有效的广告理解需要将抽象营销策略明确地基于像素级证据，AD-MIR框架通过结构化记忆和推理实现了这一目标。


### [80] [Uncovering Modality Discrepancy and Generalization Illusion for General-Purpose 3D Medical Segmentation](https://arxiv.org/abs/2602.07643)
*Yichi Zhang,Feiyang Xiao,Le Xue,Wenbo Zhang,Gang Feng,Chenguang Zheng,Yuan Qi,Yuan Cheng,Zixin Hu*

Main category: cs.CV

TL;DR: 该研究通过创建UMD数据集（包含490个PET/CT和464个PET/MRI全身扫描）评估3D医学基础模型，发现从结构成像转向功能成像时存在显著性能差距，表明当前模型远未达到真正通用状态。

- Motivation: 当前3D医学基础模型的验证主要局限于区域性和结构性成像，存在显著的模态差异未被探索。需要提供严谨客观的评估，以了解模型在真实世界应用中的鲁棒性。
- Method: 创建UMD数据集（包含约675k 2D图像和12k 3D器官标注），通过受试者内配对扫描的对照比较，将成像模态作为主要自变量，全面评估代表性3D分割基础模型。
- Result: 评估揭示了文献报道的基准与真实世界效能之间的显著差异，特别是在从结构域转向功能域时。这种系统性失败表明当前3D基础模型远未达到真正通用状态。
- Conclusion: 需要向多模态训练和评估的范式转变，以弥合理想化基准测试与全面临床效用之间的差距。该数据集和分析为开发真正模态无关的医学基础模型奠定了基石。


### [81] [From Dead Pixels to Editable Slides: Infographic Reconstruction into Native Google Slides via Vision-Language Region Understanding](https://arxiv.org/abs/2602.07645)
*Leonardo Gonzalez*

Main category: cs.CV

TL;DR: Images2Slides：基于API的管道，将静态信息图转换为可编辑的Google Slides幻灯片，使用视觉语言模型提取区域级规范并重建元素

- Motivation: 信息图通常导出为图像后内容被锁定在像素中，导致更新、本地化和重用成本高昂，需要一种方法将静态信息图转换为可编辑格式
- Method: 使用基于API的管道，通过视觉语言模型提取区域级规范，将像素几何映射到幻灯片坐标，并使用Google Slides批量更新API重新创建元素
- Result: 在29个程序生成的信息图基准测试中，元素恢复率达到0.989±0.057，文本转录错误CER=0.033±0.149，文本区域布局保真度IoU=0.364±0.161，图像区域为0.644±0.131
- Conclusion: Images2Slides成功将静态信息图转换为可编辑幻灯片，解决了文本大小校准和非均匀背景等工程挑战，为未来工作提供了指导


### [82] [Influence of Geometry, Class Imbalance and Alignment on Reconstruction Accuracy -- A Micro-CT Phantom-Based Evaluation](https://arxiv.org/abs/2602.07658)
*Avinash Kumar K M,Samarth S. Raut*

Main category: cs.CV

TL;DR: 该研究评估了医学影像3D重建流程中的误差，比较了不同分割算法和几何类型的体素与表面精度指标，发现Otsu方法最适用于各种几何形状，Jaccard指数比Dice更适合薄壁结构评估。

- Motivation: 医学扫描创建3D模型的精度受多种因素影响，但几何类型、类别不平衡、体素和点云对齐对精度的影响尚未充分探索。需要全面评估重建流程中的误差，并探索不同分割算法和几何类型的体素与表面精度指标。
- Method: 使用SLA技术打印球体、面罩和AAA模型，通过微CT扫描。采用GMM、Otsu和RG方法进行分割。使用KU算法对齐分割模型和参考模型，评估Dice、Jaccard分数和精度等指标。通过ICP对齐过程配准表面网格，评估Chamfer距离和平均Hausdorff距离。
- Result: Otsu方法对所有几何形状最合适。AAA由于壁薄和对齐问题导致重叠分数低。类别不平衡对AAA的特异性影响最大。表面精度指标与体素指标趋势不同。RG方法对球体表现最好，GMM和Otsu对AAA更好。面罩表面误差最大，可能由于ICP对齐问题。
- Conclusion: 分割精度是重建过程各阶段误差的累积总和。高体素精度指标在类别不平衡和对齐敏感情况下可能误导。Jaccard指数比Dice更严格，更适合薄壁结构精度评估。体素和点云对齐必须确保才能可靠评估重建流程。


### [83] [Looking and Listening Inside and Outside: Multimodal Artificial Intelligence Systems for Driver Safety Assessment and Intelligent Vehicle Decision-Making](https://arxiv.org/abs/2602.07668)
*Ross Greer,Laura Fleig,Maitrayee Keskar,Erika Maquiling,Giovanni Tapia Lopez,Angel Martinez-Sanchez,Parthib Roy,Jake Rattigan,Mira Sur,Alejandra Vidrio,Thomas Marcotte,Mohan Trivedi*

Main category: cs.CV

TL;DR: 提出L-LIO框架，在现有LILO视觉框架基础上加入音频模态，通过多模态融合增强车辆对驾驶员状态和外部环境的理解，提升车辆安全应用。

- Motivation: 现有LILO框架主要依赖视觉信息理解车内驾驶员状态和车外场景，但音频模态（如驾驶员语音、乘客指令、外部声音）能提供重要补充信息，特别是在视觉信号不足或需要语境理解的复杂场景中。
- Method: 扩展LILO为L-LIO框架，整合音频信号进行多模态传感器融合。通过三个案例评估音频增强：1) 驾驶员语音分类潜在损伤状态；2) 乘客自然语言指令分析；3) 音频辅助视觉系统解析外部代理的指导和手势。
- Result: 初步研究显示音频在安全相关场景中提供重要洞察，特别是在需要细微语境理解或视觉信号不足的情况下。收集了真实环境中的车内和外部音频数据集。
- Conclusion: L-LIO框架通过音频和视觉的多模态融合增强了驾驶员和场景理解，为安全干预提供了新途径。面临的挑战包括环境噪声干扰、隐私问题和跨主体鲁棒性，需要在动态现实环境中进一步研究可靠性。


### [84] [Vision and language: Novel Representations and Artificial intelligence for Driving Scene Safety Assessment and Autonomous Vehicle Planning](https://arxiv.org/abs/2602.07680)
*Ross Greer,Maitrayee Keskar,Angel Martinez-Sanchez,Parthib Roy,Shashank Shriram,Mohan Trivedi*

Main category: cs.CV

TL;DR: 该论文研究了视觉语言模型在自动驾驶安全评估和决策中的应用，探索了三种系统级用例：基于CLIP的语义危险筛查、场景级嵌入在轨迹规划中的集成，以及自然语言作为行为约束在运动规划中的应用。

- Motivation: 视觉语言模型能够将视觉观察与自然语言概念对齐，为安全关键自动驾驶中的语义推理提供了新机会。研究者希望探索如何利用视觉语言表示来支持驾驶场景安全评估和决策制定。
- Method: 研究了三种互补的系统级用例：1）基于CLIP图像-文本相似性的轻量级、类别无关的危险筛查方法；2）将场景级视觉语言嵌入集成到基于Transformer的轨迹规划框架中；3）使用自然语言作为运动规划的显式行为约束。
- Result: 1）危险筛查方法能够稳健检测多样化和分布外的道路危险；2）直接将全局嵌入条件化到规划器中不会提高轨迹精度；3）基于视觉场景元素的乘客式指令能够抑制罕见但严重的规划失败，在模糊场景中改善安全对齐行为。
- Conclusion: 视觉语言表示在表达语义风险、意图和行为约束方面对自动驾驶安全具有重要潜力，但实现这一潜力本质上是一个工程问题，需要精心设计的系统架构和结构化基础，而不是简单的特征注入。


### [85] [Process-of-Thought Reasoning for Videos](https://arxiv.org/abs/2602.07689)
*Jusheng Zhang,Kaitong Cai,Jian Wang,Yongsen Zheng,Kwok-Yan Lam,Keze Wang*

Main category: cs.CV

TL;DR: PoT Reasoning for Videos：通过将视频推理分解为可验证的步骤序列，使推理过程显式化，提高事实正确性和时间定位能力。

- Motivation: 视频理解不仅需要识别视觉内容，还需要在长且嘈杂的观察中进行时间定位的多步推理。现有方法往往缺乏显式的推理过程，导致推理不透明且容易产生幻觉解释。
- Method: 提出Process-of-Thought (PoT) Reasoning框架，将视频推理结构化为三个交错的轻量级可验证步骤：(1)时间证据选择，(2)逐步状态更新，(3)约束答案合成。该框架与模型无关，可插入现有视觉语言骨干网络，支持闭卷推理和工具增强推理。
- Result: 在标准视频推理任务上的广泛实验表明，PoT一致地提高了事实正确性和时间定位能力，同时为诊断和下游使用提供了可解释的推理轨迹。
- Conclusion: PoT框架通过使推理过程显式化，显著提升了视频推理的鲁棒性和可解释性，减少幻觉解释，为视频理解提供了有效的结构化推理方法。


### [86] [Semantic-Deviation-Anchored Multi-Branch Fusion for Unsupervised Anomaly Detection and Localization in Unstructured Conveyor-Belt Coal Scenes](https://arxiv.org/abs/2602.07694)
*Wenping Jin,Yuyang Tang,Li Zhu*

Main category: cs.CV

TL;DR: 提出CoalAD基准和互补线索协同感知框架，用于煤矿传送带场景中的无监督异物异常检测与像素级定位

- Motivation: 煤矿传送带场景中的异物异常检测对安全生产至关重要，但由于环境高度非结构化（煤矸石随机堆积、背景复杂多变、异物对比度低、变形遮挡等），传统方法依赖的稳定性假设失效，导致性能下降
- Method: 提出互补线索协同感知框架，从三个角度提取和融合异常证据：1）物体级语义组合建模；2）基于语义属性的全局偏差分析；3）细粒度纹理匹配
- Result: 在CoalAD基准上的实验表明，该方法在图像级和像素级指标上均优于广泛使用的基线方法，消融研究验证了各组件贡献
- Conclusion: 构建了煤矿场景异常检测基准CoalAD，提出的互补线索协同感知框架能有效应对非结构化环境挑战，实现鲁棒的异常检测和精确定位


### [87] [A hybrid Kolmogorov-Arnold network for medical image segmentation](https://arxiv.org/abs/2602.07702)
*Deep Bhattacharyya,Ali Ayub,A. Ben Hamza*

Main category: cs.CV

TL;DR: U-KABS是一个新颖的混合框架，结合Kolmogorov-Arnold网络（KANs）和U型编码器-解码器架构，用于提升医学图像分割性能，通过可学习的Bernstein多项式和B样条激活函数来捕捉复杂的非线性关系。

- Motivation: 医学图像分割在诊断和治疗规划中至关重要，但由于医学图像的固有复杂性和变异性，特别是在捕捉数据中的非线性关系方面仍然具有挑战性。需要更有效的方法来捕捉这些复杂关系以准确分割解剖结构。
- Method: 提出U-KABS混合框架，整合KANs的表达能力和U型编码器-解码器架构。模型包含卷积和挤压-激励阶段（增强通道特征表示）以及KAN Bernstein Spline（KABS）阶段（使用基于Bernstein多项式和B样条的可学习激活函数）。这种混合设计利用了Bernstein多项式的全局平滑性和B样条的局部适应性，能够有效捕捉广泛的上下文趋势和细粒度模式。编码器和解码器层之间的跳跃连接支持有效的多尺度特征融合并保留空间细节。
- Result: 在多个医学成像基准数据集上评估，U-KABS表现出优于强基线的性能，特别是在分割复杂解剖结构方面。
- Conclusion: U-KABS通过整合KANs和U型架构，提供了一种有效的医学图像分割解决方案，能够捕捉复杂的非线性关系，在分割复杂解剖结构方面表现出优越性能。


### [88] [All-Optical Segmentation via Diffractive Neural Networks for Autonomous Driving](https://arxiv.org/abs/2602.07717)
*Yingjie Li,Daniel Robinson,Cunxi Yu*

Main category: cs.CV

TL;DR: 提出了一种基于衍射光学神经网络的全光计算框架，用于自动驾驶中的RGB图像分割和车道线检测，相比传统DNN具有更高的能效和更低的延迟。

- Motivation: 传统深度神经网络在自动驾驶的语义分割和车道检测任务中能耗高，主要因为大量的模数转换和大规模图像计算。需要更节能、低延迟的解决方案。
- Method: 采用衍射光学神经网络（DONNs）构建全光计算框架，通过光衍射进行全光图像处理，避免了传统DNN的模数转换开销，在光速下完成计算。
- Result: 在CityScapes数据集上验证了图像分割的有效性，并在定制室内轨道数据集和CARLA模拟驾驶场景中进行车道检测案例研究，评估了模型在不同环境条件下的泛化能力。
- Conclusion: DONN系统为自动驾驶图像分割和车道检测提供了一种节能、低延迟的全光计算解决方案，在能效和实时响应方面优于传统数字计算方法。


### [89] [PAND: Prompt-Aware Neighborhood Distillation for Lightweight Fine-Grained Visual Classification](https://arxiv.org/abs/2602.07768)
*Qiuming Luo,Yuebing Li,Feng Li,Chang Kong*

Main category: cs.CV

TL;DR: PAND是一个两阶段知识蒸馏框架，通过提示感知语义校准和邻域感知结构蒸馏，将大型视觉语言模型的知识转移到轻量级网络，在细粒度视觉分类任务上取得显著性能提升。

- Motivation: 在细粒度视觉分类中，从大型视觉语言模型蒸馏知识到轻量级网络面临挑战，主要因为固定提示和全局对齐的限制。需要解决语义校准和结构转移的问题。
- Method: 提出PAND两阶段框架：1) 提示感知语义校准生成自适应语义锚点；2) 邻域感知结构蒸馏策略约束学生网络的局部决策结构。
- Result: 在四个细粒度视觉分类基准测试中持续优于最先进方法。ResNet-18学生在CUB-200上达到76.09%准确率，比VL2Lite基线提升3.4%。
- Conclusion: PAND通过解耦语义校准和结构转移，有效解决了细粒度视觉分类中知识蒸馏的挑战，为轻量级网络提供了强大的性能提升。


### [90] [Rolling Sink: Bridging Limited-Horizon Training and Open-Ended Testing in Autoregressive Video Diffusion](https://arxiv.org/abs/2602.07775)
*Haodong Li,Shaoteng Liu,Zhe Lin,Manmohan Chandraker*

Main category: cs.CV

TL;DR: 提出Rolling Sink方法，无需额外训练即可解决自回归视频扩散模型在超出训练时长时的性能退化问题，实现超长视频合成

- Motivation: 自回归视频扩散模型在训练时长有限的情况下，测试时超出训练时长会出现视觉质量快速退化的问题，而长视频训练计算成本高昂，因此需要无训练解决方案
- Method: 基于Self Forcing框架，系统分析自回归缓存维护机制，提出Rolling Sink方法，在测试时无需额外训练即可将视频合成扩展到超长时长
- Result: Rolling Sink在仅用5秒片段训练的基础上，能在测试时合成5-30分钟的超长视频，保持主体一致、颜色稳定、结构连贯、运动平滑，视觉保真度和时间一致性优于现有方法
- Conclusion: Rolling Sink提供了一种有效的无训练解决方案，成功弥合了自回归视频扩散模型在有限训练时长与无限测试时长之间的差距，实现了高质量超长视频合成


### [91] [Uncertainty-Aware Counterfactual Traffic Signal Control with Predictive Safety and Starvation-Avoidance Constraints Using Vision-Based Sensing](https://arxiv.org/abs/2602.07784)
*Jayawant Bodagala,Balaji Bodagala*

Main category: cs.CV

TL;DR: UCATSC是一个基于模型的交通信号控制系统，通过随机决策过程建模路口交通信号控制，考虑视觉感知不确定性，使用硬约束确保安全和防止饥饿，提供可解释的控制策略。

- Motivation: 现实世界中自适应交通信号控制部署有限，主要因为基于视觉感知的不确定性、隐含安全性问题，以及主要在模拟中学习和验证的不可解释控制策略。
- Method: 使用带约束的随机决策过程在部分可观测条件下建模交通信号控制，考虑视觉感知不确定性。在信念空间中进行反事实推演时预测并强制执行与安全和防止饥饿相关的硬约束，而非通过奖励塑造学习安全性。
- Result: 系统设计旨在改善交通延迟和排放，同时防止安全关键错误，并基于显式模型提供可解释的控制策略输出。
- Conclusion: UCATSC通过基于模型的方法解决了自适应交通信号控制在实际部署中的关键挑战，包括不确定性处理、安全保证和策略可解释性。


### [92] [VideoTemp-o3: Harmonizing Temporal Grounding and Video Understanding in Agentic Thinking-with-Videos](https://arxiv.org/abs/2602.07801)
*Wenqi Liu,Yunxiao Wang,Shijie Ma,Meng Liu,Qile Su,Tianke Zhang,Haonan Fan,Changyi Liu,Kaiyu Jiang,Jiankang Chen,Kaiyu Tang,Bin Wen,Fan Yang,Tingting Gao,Han Li,Yinwei Wei,Xuemeng Song*

Main category: cs.CV

TL;DR: VideoTemp-o3：统一的视频理解框架，联合建模视频定位和问答，解决长视频理解中均匀采样导致的性能下降和幻觉问题

- Motivation: 传统均匀帧采样在长视频理解中难以捕捉关键视觉证据，导致性能下降和幻觉增加。现有代理式视频思考方法存在效率低下、定位能力弱、流程僵化等问题
- Method: 提出VideoTemp-o3统一框架，联合建模视频定位和问答。在监督微调阶段设计统一掩码机制，在强化学习阶段引入专用奖励防止奖励攻击，并构建高质量长视频定位QA数据和相应基准
- Result: 实验结果表明，该方法在长视频理解和定位任务上都取得了显著性能提升
- Conclusion: VideoTemp-o3通过统一的代理式视频思考框架，有效解决了长视频理解中的关键问题，具有强大的定位能力、按需裁剪和定位修正功能


### [93] [How well are open sourced AI-generated image detection models out-of-the-box: A comprehensive benchmark study](https://arxiv.org/abs/2602.07814)
*Simiao Ren,Yuchen Zhou,Xingyu Shen,Kidus Zewde,Tommy Duong,George Huang,Hatsanai,Tiangratanakul,Tsang,Ng,En Wei,Jiayu Xue*

Main category: cs.CV

TL;DR: 首次对16种最先进的AI生成图像检测方法进行零样本评估，涵盖23个预训练检测器变体和12个数据集，发现没有通用最佳检测器，性能差异显著，现代商业生成器能击败大多数检测器。

- Motivation: 随着AI生成图像在数字平台泛滥，可靠的检测方法对于打击虚假信息和维护内容真实性至关重要。现有基准主要评估微调模型，忽略了实际部署中最常见的零样本性能评估。
- Method: 对16种最先进的检测方法（23个预训练检测器变体）在12个多样化数据集上进行首次全面的零样本评估，涵盖291个生成器和260万图像样本，包括现代扩散模型。
- Result: 1) 没有通用最佳检测器，排名极不稳定；2) 最佳与最差检测器性能差距达37个百分点；3) 训练数据对齐对泛化影响显著；4) 现代商业生成器能击败大多数检测器；5) 识别出三种系统性失败模式。
- Conclusion: 研究挑战了"一刀切"的检测器范式，表明从业者必须根据具体威胁环境仔细选择检测器，而不能依赖已发布的基准性能。


### [94] [Out of the box age estimation through facial imagery: A Comprehensive Benchmark of Vision-Language Models vs. out-of-the-box Traditional Architectures](https://arxiv.org/abs/2602.07815)
*Simiao Ren*

Main category: cs.CV

TL;DR: VLMs在年龄估计任务中显著优于专用模型，最佳VLM比最佳专用模型MAE低15%，挑战了任务专用架构的必要性假设。

- Motivation: 面部年龄估计对内容审核、年龄验证和深度伪造检测至关重要，但此前缺乏系统比较现代视觉语言模型与专用年龄估计架构的基准测试。
- Method: 创建首个大规模跨范式基准测试，评估34个模型（22个专用架构和12个通用VLMs），在8个标准数据集上总计1,100张测试图像，使用MAE等指标进行系统比较。
- Result: 零样本VLMs显著优于大多数专用模型（平均MAE 5.65年 vs 9.88年），最佳VLM（Gemini 3 Flash Preview，MAE 4.32）比最佳非LLM模型（MiVOLO，MAE 5.10）优15%。VLMs在18岁阈值年龄验证中表现更好（13-25%假成人率 vs 60-100%）。
- Conclusion: 研究挑战了任务专用架构对年龄估计必要的假设，建议领域应转向将VLM能力蒸馏到高效的专用模型中，特别是在极端年龄组（<5岁和65+岁）仍有改进空间。


### [95] [Back to Physics: Operator-Guided Generative Paths for SMS MRI Reconstruction](https://arxiv.org/abs/2602.07820)
*Zhibo Chen,Yu Guan,Yajuan Huang,Chaoqi Chen,XiangJi,Qiuyun Fan,Dong Liang,Qiegen Liu*

Main category: cs.CV

TL;DR: 提出一种基于算子引导的框架，使用双流交互网络（OCDI-Net）显式分离目标切片内容和切片间干扰，通过两阶段链式推理实现同时多切片（SMS）MRI重建

- Motivation: 同时多切片（SMS）成像结合平面内欠采样可实现高度加速的MRI，但会产生强耦合的逆问题，存在确定性切片间干扰和缺失k空间数据。现有基于扩散的重建方法通常围绕高斯噪声设计，需要额外一致性步骤来融入SMS物理，这可能与SMS采集中的算子控制退化不匹配。
- Method: 提出算子引导框架，使用已知采集算子建模退化轨迹并通过确定性更新反转该过程。引入算子条件双流交互网络（OCDI-Net），显式分离目标切片内容与切片间干扰，预测结构化退化以进行算子对齐的反转。将重建实例化为两阶段链式推理：先进行SMS切片分离，再进行平面内补全。
- Result: 在fastMRI脑数据和前瞻性采集的体内扩散MRI数据上的实验表明，相比传统和基于学习的SMS重建方法，该方法提高了保真度并减少了切片泄漏。
- Conclusion: 提出的算子引导框架和OCDI-Net能够有效处理SMS成像中的耦合逆问题，通过显式建模切片间干扰和结构化退化，实现了更准确的重建，减少了切片泄漏问题。


### [96] [Open-Text Aerial Detection: A Unified Framework For Aerial Visual Grounding And Detection](https://arxiv.org/abs/2602.07827)
*Guoting Wei,Xia Yuan,Yang Zhou,Haizhao Jing,Yu Liu,Xianbiao Qi,Chunxia Zhao,Haokui Zhang,Rong Xiao*

Main category: cs.CV

TL;DR: OTA-Det是一个统一框架，首次将开放词汇航空检测（OVAD）和遥感视觉定位（RSVG）两个范式结合，支持丰富的语义理解和多目标检测，在保持实时推理的同时在六个基准测试中达到最先进性能。

- Motivation: OVAD和RSVG是航空场景理解的两个关键范式，但各自存在局限性：OVAD仅限于粗粒度的类别级语义，而RSVG在结构上仅限于单目标定位。这些限制使得现有方法无法同时支持丰富的语义理解和多目标检测。
- Method: 1. 任务重构策略：统一任务目标和监督机制，支持跨范式数据集的联合训练；2. 密集语义对齐策略：建立从整体表达到个体属性的多粒度显式对应关系；3. 基于RT-DETR架构扩展，引入高效模块，从闭集检测扩展到开放文本检测。
- Result: 在OVAD和RSVG任务的六个基准测试中达到最先进性能，同时保持34 FPS的实时推理速度。
- Conclusion: OTA-Det成功统一了OVAD和RSVG两个范式，解决了各自孤立操作的局限性，实现了同时支持丰富语义理解和多目标检测的统一框架，在保持实时效率的同时取得了卓越性能。


### [97] [SPD-Faith Bench: Diagnosing and Improving Faithfulness in Chain-of-Thought for Multimodal Large Language Models](https://arxiv.org/abs/2602.07833)
*Weijiang Lv,Yaoxuan Feng,Xiaobo Xia,Jiayu Wang,Yan Jing,Wenchao Chen,Bo Chen*

Main category: cs.CV

TL;DR: 该论文提出了SPD-Faith Bench基准来评估多模态大语言模型推理过程的忠实性，发现了感知盲区和感知-推理分离两种系统故障模式，并提出了无需训练的SAGE框架来改善视觉证据校准。

- Motivation: 当前多模态大语言模型广泛使用思维链推理来提高可解释性，但生成的推理轨迹的忠实性仍不清楚。先前工作主要关注感知幻觉，而推理层面的不忠实性尚未得到充分探索。
- Method: 引入SPD-Faith Bench诊断基准，基于细粒度图像差异推理来强制显式视觉比较，以隔离语言先验的影响。通过分析发现视觉注意力衰减和残差流中的表示偏移问题，提出了SAGE框架来改善视觉路由并使推理与感知对齐。
- Result: 评估最先进的多模态大语言模型揭示了两种系统故障模式：感知盲区和感知-推理分离。这些故障源于视觉注意力衰减和残差流中的表示偏移。SAGE框架能够改善视觉路由并提升推理忠实性。
- Conclusion: 研究强调了超越响应正确性来显式评估忠实性的重要性。提出的基准和SAGE框架为理解和改善多模态大语言模型的推理忠实性提供了工具。


### [98] [VFace: A Training-Free Approach for Diffusion-Based Video Face Swapping](https://arxiv.org/abs/2602.07835)
*Sanoojan Baliah,Yohan Abeysinghe,Rusiru Thushara,Khan Muhammad,Abhinav Dhall,Karthik Nandakumar,Muhammad Haris Khan*

Main category: cs.CV

TL;DR: VFace是一种无需训练、即插即用的视频人脸交换方法，可与基于扩散模型的图像人脸交换方法无缝集成，通过频率谱注意力插值、目标结构引导和流引导注意力时序平滑三大技术提升时间一致性和视觉质量。

- Motivation: 现有基于扩散模型的图像人脸交换方法在视频应用中存在时间不一致性问题，需要一种无需额外训练或视频特定微调的方法来提升视频人脸交换的时间一致性和视觉保真度。
- Method: 1. 频率谱注意力插值：促进生成并保持关键身份特征；2. 目标结构引导：通过即插即用的注意力注入，将目标帧的结构特征与生成对齐；3. 流引导注意力时序平滑：在不修改底层扩散模型的情况下强制时空一致性，减少逐帧生成中的时间不一致性。
- Result: 实验表明，该方法显著提升了时间一致性和视觉保真度，为视频人脸交换提供了一个实用且模块化的解决方案。
- Conclusion: VFace是一种无需训练、即插即用的视频人脸交换方法，可与现有图像人脸交换方法无缝集成，有效解决了视频应用中时间不一致性的问题，具有实用性和模块化优势。


### [99] [Geometry-Aware Rotary Position Embedding for Consistent Video World Model](https://arxiv.org/abs/2602.07854)
*Chendong Xiang,Jiajun Liu,Jintao Zhang,Xiao Yang,Zhengwei Fang,Shizun Wang,Zijun Wang,Yingtian Zou,Hang Su,Jun Zhu*

Main category: cs.CV

TL;DR: ViewRope通过几何感知的注意力机制解决视频预测模型中空间持久性问题，显著提升长期一致性并降低计算成本

- Motivation: 当前预测性世界模型缺乏空间持久性，在长轨迹中无法保持稳定的场景结构，当相机重新访问先前观察位置时经常产生幻觉细节。这种几何漂移源于对屏幕空间位置嵌入的依赖，这与3D一致性所需的投影几何相冲突。
- Method: 提出ViewRope几何感知编码，将相机射线方向直接注入视频transformer自注意力层；通过相对射线几何而非像素局部性参数化注意力；提出几何感知帧稀疏注意力，利用几何线索选择性关注相关历史帧；建立ViewBench诊断套件测量闭环保真度和几何漂移。
- Result: ViewRope显著改善了长期一致性，同时减少了计算成本，在几何一致性方面表现优异。
- Conclusion: 通过几何感知的注意力机制可以解决预测世界模型中的空间持久性问题，ViewRope为3D一致性提供了模型原生的归纳偏置，是提升长期场景一致性的有效方法。


### [100] [Recovering 3D Shapes from Ultra-Fast Motion-Blurred Images](https://arxiv.org/abs/2602.07860)
*Fei Yu,Shudan Guo,Shiqing Xin,Beibei Wang,Haisen Zhao,Wenzheng Chen*

Main category: cs.CV

TL;DR: 提出一种从超高速运动模糊图像恢复3D形状的逆渲染方法，通过快速重心坐标求解器显著提升计算效率，实现高效逼真的高速运动模拟和3D重建。

- Motivation: 在自然和工业场景中（如运动中的球体或旋转机械），物体高速运动导致图像严重模糊，传统多视角立体视觉等3D重建技术失效，需要解决从极端运动模糊图像恢复几何形状的挑战。
- Method: 提出新颖的逆渲染方法，包含快速重心坐标求解器，显著减少计算开销（速度提升达4.57倍），实现高效逼真的高速运动模拟。方法完全可微分，支持从渲染图像到3D形状的梯度传播。
- Result: 在快速平移和旋转两种典型运动类型上验证，实验表明方法能高效逼真地模拟超高速运动物体，并成功从极端平移和旋转运动的2D图像中恢复3D形状。
- Conclusion: 该方法突破了基于视觉的3D重建边界，实现了从超高速运动模糊图像中恢复3D形状，为处理极端运动场景的几何重建提供了有效解决方案。


### [101] [Thinking in Structures: Evaluating Spatial Intelligence through Reasoning on Constrained Manifolds](https://arxiv.org/abs/2602.07864)
*Chen Yang,Guanxin Lin,Youquan He,Peiyao Chen,Guanghe Liu,Yufan Mo,Zhouyuan Xu,Linhao Wang,Guohui Zhang,Zihang Zhang,Shenxiang Zeng,Chen Wang,Jiansheng Fan*

Main category: cs.CV

TL;DR: SSI-Bench是一个针对视觉语言模型的空间推理基准测试，专注于受约束流形上的空间推理，包含1000个排序问题，评估几何和拓扑推理能力。

- Motivation: 现有基准测试大多评估无约束场景，模型可以利用2D捷径，缺乏对真实物理世界中受几何、拓扑和物理约束的空间推理能力的评估。
- Method: 通过完全人工中心的流程构建：10名研究人员花费400多小时精心挑选图像、标注结构组件、设计问题以最小化像素级线索，包含几何和拓扑推理的排序问题。
- Result: 评估31个广泛使用的VLM显示与人类存在巨大差距：最佳开源模型准确率22.2%，最强闭源模型33.6%，而人类达到91.6%。鼓励模型思考仅带来边际收益，错误分析显示结构基础和约束一致的3D推理失败。
- Conclusion: SSI-Bench揭示了当前VLM在空间推理方面的严重不足，特别是在结构基础和约束一致的3D推理方面，为未来模型改进提供了重要基准。


### [102] [WristMIR: Coarse-to-Fine Region-Aware Retrieval of Pediatric Wrist Radiographs with Radiology Report-Driven Learning](https://arxiv.org/abs/2602.07872)
*Mert Sonmezer,Serge Vasylechko,Duygu Atasoy,Seyda Ertekin,Sila Kurugol*

Main category: cs.CV

TL;DR: WristMIR：基于区域感知的儿科腕部X光片检索框架，通过全局和局部对比编码器实现两阶段检索，显著提升骨折模式检索和诊断性能

- Motivation: 腕部X光片中骨折模式的检索具有挑战性，因为临床重要线索细微、高度局部化，且常被重叠解剖结构或不同成像视角所掩盖。此外，缺乏大型、高质量标注的医学图像检索数据集也限制了进展。
- Method: WristMIR利用密集放射学报告和骨特异性定位，通过MedGemma结构化报告挖掘生成全局和区域级描述，结合预处理的腕部图像和特定骨骼裁剪（远端桡骨、远端尺骨、尺骨茎突），联合训练全局和局部对比编码器，采用两阶段检索：粗粒度全局匹配识别候选检查，然后区域条件重排序对齐预定义解剖骨骼区域。
- Result: WristMIR显著提升检索性能，图像到文本Recall@5从0.82%提高到9.35%；嵌入表示在骨折分类上表现更强（AUROC 0.949，AUPRC 0.953）；在区域感知评估中，两阶段设计显著改善基于检索的骨折诊断，平均F1从0.568提升到0.753；放射科医生评价其检索病例临床相关性更高，平均评分从3.36提高到4.35。
- Conclusion: WristMIR展示了解剖引导检索在增强儿科肌肉骨骼成像诊断推理和临床决策支持方面的潜力，为医学图像检索提供了有效的区域感知框架。


### [103] [Scalable Adaptation of 3D Geometric Foundation Models via Weak Supervision from Internet Video](https://arxiv.org/abs/2602.07891)
*Zihui Gao,Ke Liu,Donny Y. Chen,Duochao Shi,Guosheng Lin,Hao Chen,Chunhua Shen*

Main category: cs.CV

TL;DR: SAGE是一个从原始视频流中自适应几何基础模型的框架，通过分层挖掘管道将视频转换为训练轨迹，结合稀疏几何锚点和密集可微一致性监督，显著提升零样本泛化能力。

- Motivation: 几何基础模型在3D重建方面有潜力，但受到大规模3D标注数据稀缺的限制。互联网视频提供了几乎无限的原始数据，但由于缺乏真实几何标注和存在观测噪声，将其用作几何学习的扩展源具有挑战性。
- Method: SAGE采用分层挖掘管道：1) 信息性训练轨迹选择；2) 通过SfM点云进行稀疏几何锚点，提供全局结构指导；3) 通过3D高斯渲染实现密集可微一致性，提供多视角约束。为防止灾难性遗忘，引入了基于锚点数据的正则化策略。
- Result: 在未见过的基准测试（7Scenes、TUM-RGBD、Matterport3D）上，SAGE显著提升了零样本泛化能力，将Chamfer距离降低了20-42%，优于最先进的基线方法。
- Conclusion: SAGE开创了通过互联网视频自适应几何基础模型的先河，为通用3D学习建立了可扩展的范式。


### [104] [Rethinking Practical and Efficient Quantization Calibration for Vision-Language Models](https://arxiv.org/abs/2602.07899)
*Zhenhao Shang,Haizhao Jing,Guoting Wei,Haokui Zhang,Rong Xiao,Jianqing Gao,Peng Wang*

Main category: cs.CV

TL;DR: TLQ提出了一种针对视觉语言模型的token级重要性感知层量化框架，通过梯度引导的token重要性整合机制和多GPU层校准方案，显著提升了量化性能。

- Motivation: 视觉语言模型中视觉token和文本token在激活分布和量化误差敏感性方面存在显著差异，给PTQ校准带来挑战，需要重新思考VLM中的PTQ校准策略。
- Method: 1) 基于梯度信息设计token级重要性整合机制用于量化误差；2) 构建token级校准集实现细粒度校准；3) 引入多GPU、量化暴露的层校准方案，保持校准与真实量化推理路径一致。
- Result: 在两个模型、三种模型规模和两种量化设置下评估，TLQ在所有设置中均实现性能提升，显示出强大的量化稳定性。
- Conclusion: TLQ框架通过token级重要性感知和层校准优化，有效解决了VLM量化中的校准挑战，为视觉语言模型的部署提供了高效量化方案。


### [105] [Which private attributes do VLMs agree on and predict well?](https://arxiv.org/abs/2602.07931)
*Olena Hrynenko,Darya Baranouskaya,Alina Elena Baia,Andrea Cavallaro*

Main category: cs.CV

TL;DR: 视觉语言模型在隐私相关属性识别中的零样本评估显示，VLM倾向于比人类标注者更频繁地预测隐私属性的存在，但在VLM间高一致性情况下可以补充人类标注

- Motivation: 评估开源视觉语言模型在隐私相关属性识别中的零样本性能，探索VLM与人类标注者之间的差异，以及VLM在大规模图像数据集隐私标注中的潜力
- Method: 对开源VLM进行零样本评估，识别VLM表现出强标注者间一致性的属性，分析VLM与人类标注之间的分歧案例
- Result: VLM倾向于比人类标注者更频繁地预测隐私属性的存在；在VLM间高一致性情况下，VLM可以识别人类标注者忽略的属性，补充人类标注
- Conclusion: VLM在大规模图像数据集的隐私标注中具有支持潜力，特别是在VLM间高一致性的情况下可以作为人类标注的补充


### [106] [Integrating Specialized and Generic Agent Motion Prediction with Dynamic Occupancy Grid Maps](https://arxiv.org/abs/2602.07938)
*Rabbia Asghar,Lukas Rummelhard,Wenqian Liu,Anne Spalanzani,Christian Laugier*

Main category: cs.CV

TL;DR: 提出统一框架，通过动态占据网格地图同时预测未来占据状态、车辆和场景流，解决现有方法在行为复杂性和泛化性方面的局限

- Motivation: 现有驾驶场景预测方法存在局限性：基于占据网格的agent-agnostic方法难以捕捉动态参与者的复杂行为，而agent-specific方法对感知不佳或未识别agent泛化能力差。结合两者可实现更鲁棒安全的运动预测
- Method: 提出统一框架，利用动态占据网格地图在流线化时间解码管道中同时预测未来占据状态网格、车辆网格和场景流网格。基于轻量级时空骨干网络，采用定制化的相互依赖损失函数捕捉网格间依赖关系并实现多样化未来预测
- Result: 在真实世界nuScenes和Woven Planet数据集上评估，相比基线方法在动态车辆和通用动态场景元素预测方面表现出优越性能
- Conclusion: 通过统一框架同时处理agent-agnostic和agent-specific预测，能够预测车辆的具体行为并识别其他动态实体，在复杂场景中实现更鲁棒和安全的运动预测


### [107] [One-Shot Crowd Counting With Density Guidance For Scene Adaptaion](https://arxiv.org/abs/2602.07955)
*Jiwei Chen,Qi Wang,Junyu Gao,Jing Zhang,Dingyi Li,Jing-Jia Luo*

Main category: cs.CV

TL;DR: 提出一种基于少样本学习的跨场景人群计数方法，利用局部和全局密度特征指导模型适应未见过的监控场景

- Motivation: 现有的人群计数模型在不同监控场景间的泛化能力有限，需要一种能够快速适应新监控场景的方法
- Method: 提出多局部密度学习器学习支持场景中不同密度分布的原型，结合局部密度相似性矩阵和全局密度特征进行双重指导
- Result: 在三个监控数据集上的实验表明，该方法能够适应未见过的监控场景，并在少样本人群计数中优于现有方法
- Conclusion: 通过局部和全局密度特征的结合，提出的少样本学习方法有效提升了人群计数模型在新监控场景中的适应能力


### [108] [D-ORCA: Dialogue-Centric Optimization for Robust Audio-Visual Captioning](https://arxiv.org/abs/2602.07960)
*Changli Tang,Tianyi Wang,Fengyun Rao,Jing Lyu,Chao Zhang*

Main category: cs.CV

TL;DR: D-ORCA是一个专注于对话的跨模态大语言模型，用于鲁棒的视听字幕生成，在说话人识别、语音识别和时间定位方面显著优于现有开源模型。

- Motivation: 视频中的对话是主要信息来源，准确识别谁在何时说了什么对于深度视频理解至关重要。当前开源生态中缺乏大规模高质量的多方对话视频数据集。
- Method: 提出了D-ORCA对话中心的全模态大语言模型，并构建了DVD双语数据集（近4万训练视频+2000评估视频）。采用组相对策略优化，包含三个新颖的奖励函数：说话人归属准确性、全局语音内容准确性和句子级时间边界对齐。
- Result: D-ORCA在说话人识别、语音识别和时间定位方面显著优于现有开源模型。尽管只有80亿参数，但在多个通用视听理解基准上与Qwen3-Omni表现相当。
- Conclusion: D-ORCA为对话中心的视听字幕生成提供了有效的解决方案，填补了开源生态的空白，在多项任务上达到了先进性能。


### [109] [EasyTune: Efficient Step-Aware Fine-Tuning for Diffusion-Based Motion Generation](https://arxiv.org/abs/2602.07967)
*Xiaofeng Tan,Wanjiang Weng,Haodong Lei,Hongsong Wang*

Main category: cs.CV

TL;DR: EasyTune提出了一种高效的对齐扩散模型的方法，通过分步微调解决现有方法的内存消耗大和优化粗糙的问题，并引入自精炼偏好学习机制来处理偏好数据稀缺问题。

- Motivation: 现有基于可微分奖励直接对齐扩散模型偏好的方法存在两个主要问题：1) 优化效率低且粒度粗糙；2) 内存消耗高。这些限制源于去噪轨迹中不同步骤之间的递归依赖关系。
- Method: 提出EasyTune方法：1) 在去噪过程的每个步骤分别微调扩散模型，解耦递归依赖；2) 引入自精炼偏好学习(SPL)机制，动态识别偏好对并进行偏好学习，解决偏好运动数据稀缺问题。
- Result: 实验表明，EasyTune在MM-Dist对齐指标上比DRaFT-50提升8.2%，同时仅需其31.16%的额外内存开销，训练速度提升7.3倍。
- Conclusion: EasyTune通过分步微调和自精炼偏好学习机制，实现了对扩散模型的高效、精细对齐，显著降低了内存消耗并提升了训练效率。


### [110] [FSP-Diff: Full-Spectrum Prior-Enhanced DualDomain Latent Diffusion for Ultra-Low-Dose Spectral CT Reconstruction](https://arxiv.org/abs/2602.07979)
*Peng Peng,Xinrui Zhang,Junlin Wang,Lei Li,Shaoyu Wang,Qiegen Liu*

Main category: cs.CV

TL;DR: FSP-Diff：一种用于超低剂量能谱CT重建的全能谱先验增强双域潜在扩散框架，通过互补特征构建、全能谱先验集成和高效潜在扩散合成，显著提升图像质量和计算效率。

- Motivation: 超低剂量条件下，能谱CT的能量特定投影信噪比急剧下降，导致重建图像出现严重伪影和结构细节丢失，需要开发有效的重建方法来应对这一挑战。
- Method: 提出FSP-Diff框架，包含三个核心策略：1）互补特征构建：整合直接图像重建与投影域去噪结果；2）全能谱先验集成：融合多能量投影为高信噪比全能谱图像作为统一结构参考；3）高效潜在扩散合成：将多路径特征嵌入紧凑潜在空间，在低维流形中实现交互特征融合。
- Result: 在模拟和真实数据集上的广泛实验表明，FSP-Diff在图像质量和计算效率方面均显著优于现有最先进方法。
- Conclusion: FSP-Diff框架为临床可行的超低剂量能谱CT成像提供了有前景的解决方案，通过双域特征整合和潜在扩散合成实现了高质量重建。


### [111] [Continuity-driven Synergistic Diffusion with Neural Priors for Ultra-Sparse-View CBCT Reconstruction](https://arxiv.org/abs/2602.07980)
*Junlin Wang,Jiancheng Fang,Peng Peng,Shaoyu Wang,Qiegen Liu*

Main category: cs.CV

TL;DR: 提出CSDN方法，通过神经先验和协同扩散策略解决超稀疏角采样CBCT重建中的伪影和切片不一致问题

- Motivation: CBCT临床应用受限于辐射剂量与图像质量的权衡。超稀疏角采样虽降低剂量，但导致严重欠采样伪影和切片间不一致，现有方法难以平衡角度连续性与空间细节保真度。
- Method: 提出CSDN方法：1) 引入神经先验作为结构基础，编码连续3D衰减表示，从超稀疏测量合成物理一致密集投影；2) 基于神经先验初始化，开发协同扩散策略，包含两个协同精炼路径：正弦图精炼扩散(Sino-RD)恢复角度连续性，数字放射摄影精炼扩散(DR-RD)从投影图像角度强制切片一致性；3) 通过双投影重建融合(DPRF)模块自适应融合两个扩散路径输出，实现连贯体积重建。
- Result: 广泛实验表明，CSDN在超稀疏角条件下有效抑制伪影并恢复精细纹理，优于现有最先进技术。
- Conclusion: CSDN方法通过神经先验和协同扩散策略，成功解决了超稀疏角采样CBCT重建中的关键挑战，实现了高质量、连贯的体积重建。


### [112] [Deepfake Synthesis vs. Detection: An Uneven Contest](https://arxiv.org/abs/2602.07986)
*Md. Tarek Hasan,Sanjay Saha,Shaojing Fan,Swakkhar Shatabda,Terence Sim*

Main category: cs.CV

TL;DR: 最新深度伪造检测模型在面对现代合成技术生成的深度伪造内容时表现显著不佳，甚至人类也难以分辨最高质量的伪造视频，凸显检测技术落后于生成技术发展的严峻现实。

- Motivation: 随着扩散模型、NeRF和增强GAN等深度伪造生成技术的快速发展，合成媒体的真实性和可及性大幅提升，而现有检测方法能否有效应对这些先进生成技术尚不明确，需要系统评估。
- Method: 对最先进的深度伪造检测技术进行全面实证分析，包括使用现代合成方法生成的深度伪造视频进行人类评估实验，通过大量实验比较检测模型性能。
- Result: 研究发现许多最先进的检测模型在面对现代合成技术生成的深度伪造内容时表现显著下降，人类参与者在面对最高质量深度伪造时也难以准确识别，检测与生成技术之间存在严重差距。
- Conclusion: 当前检测方法已落后于深度伪造生成技术的发展，迫切需要持续改进检测模型以跟上快速演进的生成技术，这一领域的研究需要加强投入。


### [113] [MCIE: Multimodal LLM-Driven Complex Instruction Image Editing with Spatial Guidance](https://arxiv.org/abs/2602.07993)
*Xuehai Bai,Xiaoling Gu,Akide Liu,Hangjie Yuan,YiFan Zhang,Jack Ma*

Main category: cs.CV

TL;DR: 提出MCIE-E1方法，通过空间感知交叉注意力和背景一致交叉注意力模块，解决复杂指令图像编辑中的指令遵循不足和背景不一致问题，在CIE-Bench基准上相比SOTA方法提升23.96%的指令遵循能力。

- Motivation: 现有基于指令的图像编辑方法局限于简单操作，难以处理现实应用中需要的复杂组合指令。主要存在两个关键挑战：指令遵循不足和背景不一致。
- Method: 提出MCIE-E1方法，包含两个核心模块：1）空间感知交叉注意力模块，在去噪过程中通过空间引导显式对齐语义指令与空间区域；2）背景一致交叉注意力模块，保持未编辑区域特征以维持背景一致性。构建专门的数据管道，结合强大的MLLM细粒度自动过滤和严格人工验证来解决复杂指令数据集稀缺问题。
- Result: 在提出的CIE-Bench基准上，MCIE-E1在定量和定性评估中均优于先前最先进方法，指令遵循能力提升23.96%。
- Conclusion: MCIE-E1通过创新的架构设计、数据管道和评估协议，有效解决了复杂指令图像编辑中的关键挑战，为现实应用提供了更强大的图像编辑能力。


### [114] [ForecastOcc: Vision-based Semantic Occupancy Forecasting](https://arxiv.org/abs/2602.08006)
*Riya Mohan,Juana Valeria Hurtado,Rohit Mohan,Abhinav Valada*

Main category: cs.CV

TL;DR: ForecastOcc：首个基于视觉的语义占据预测框架，直接从相机图像联合预测未来占据状态和语义类别，无需外部地图，在多个数据集上超越基线方法。

- Motivation: 现有占据预测方法主要关注静态和动态物体的运动类别，缺乏语义信息；而最近的语义占据预测方法依赖于单独网络获取的过去占据预测，导致误差累积且无法直接从图像学习时空特征。
- Method: 提出ForecastOcc框架，包含时间交叉注意力预测模块、2D到3D视图变换器、3D编码器用于占据预测，以及语义占据头用于跨多个时间步的体素级预测。
- Result: 在Occ3D-nuScenes多视图预测和SemanticKITTI单目预测两个数据集上均超越基线方法，建立了首个单目预测基准，实现了语义丰富、未来感知的预测。
- Conclusion: ForecastOcc是首个直接从图像联合预测未来占据状态和语义类别的框架，能够捕捉对自动驾驶至关重要的场景动态和语义信息，性能优于现有方法。


### [115] [PhysDrape: Learning Explicit Forces and Collision Constraints for Physically Realistic Garment Draping](https://arxiv.org/abs/2602.08020)
*Minghai Chen,Mingyuan Liu,Yuxiang Huan*

Main category: cs.CV

TL;DR: PhysDrape：一种混合神经物理求解器，通过显式力和约束实现物理真实的服装悬垂，解决了现有方法在几何可行性与物理合理性之间的权衡问题。

- Motivation: 基于深度学习的服装悬垂方法已成为传统物理模拟的有前景替代方案，但稳健的碰撞处理仍是关键瓶颈。现有方法通过软惩罚来保证物理有效性，导致几何可行性与物理合理性之间存在固有权衡：惩罚碰撞会扭曲网格结构，而保持形状则会导致穿透。
- Method: 提出PhysDrape混合神经物理求解器，将神经推理与显式几何求解器集成在完全可微的流程中。包括：1）基于物理增强图的条件物理信息图神经网络预测残差位移；2）可学习力求解器迭代解决来自StVK模型的不平衡力；3）可微投影严格强制执行与身体表面的碰撞约束。
- Result: PhysDrape实现了最先进的性能，确保可忽略的穿透，与现有基线相比具有显著更低的应变能，在实时性下实现了卓越的物理保真度和鲁棒性。
- Conclusion: PhysDrape通过可微的显式约束设计解决了服装悬垂中几何可行性与物理合理性的冲突，实现了物理一致的预测，为物理真实的服装模拟提供了有效解决方案。


### [116] [FlashVID: Efficient Video Large Language Models via Training-free Tree-based Spatiotemporal Token Merging](https://arxiv.org/abs/2602.08024)
*Ziyang Fan,Keyu Chen,Ruilong Xing,Yulin Li,Li Jiang,Zhuotao Tian*

Main category: cs.CV

TL;DR: FlashVID是一个无需训练的视频大语言模型推理加速框架，通过注意力与多样性令牌选择和树状时空令牌合并技术，仅保留10%视觉令牌即可保持99.1%性能，实现10倍视频帧扩展。

- Motivation: 现有视频大语言模型需要处理大量视觉令牌，计算效率低下。现有加速框架独立压缩空间和时间冗余，忽略了时空关系，导致次优压缩效果。视频的动态特性使得视觉特征在时空维度高度相关且不断变化。
- Method: FlashVID包含两个核心组件：1) 注意力与多样性令牌选择(ADTS)：选择最具代表性的令牌进行基础视频表示；2) 树状时空令牌合并(TSTM)：进行细粒度时空冗余消除。该框架无需训练，即插即用。
- Result: 在三个代表性VLLM和五个视频理解基准测试中验证了方法的有效性和泛化性。仅保留10%视觉令牌即可保持LLaVA-OneVision 99.1%的性能。使Qwen2.5-VL的视频帧输入增加10倍，在相同计算预算下相对提升8.6%。
- Conclusion: FlashVID是一个高效、无需训练的视频大语言模型加速框架，通过有效利用时空关系进行令牌压缩，显著提升推理效率，同时保持模型性能，为长视频处理提供了实用解决方案。


### [117] [MIND: Benchmarking Memory Consistency and Action Control in World Models](https://arxiv.org/abs/2602.08025)
*Yixuan Ye,Xuanyu Lu,Yuxin Jiang,Yuchao Gu,Rui Zhao,Qiwei Liang,Jiachun Pan,Fengda Zhang,Weijia Wu,Alex Jinpeng Wang*

Main category: cs.CV

TL;DR: MIND是首个用于评估世界模型记忆一致性和动作控制能力的开放域闭环重访基准，包含250个高质量视频和多样化动作空间，并提出了MIND-World基线模型。

- Motivation: 目前缺乏统一的基准来评估世界模型在动态视觉环境中的基本能力，特别是记忆一致性和动作控制方面。
- Method: 构建包含250个1080p高清视频的MIND基准，涵盖第一人称和第三人称视角，设计多样化动作空间，并开发高效的评估框架来测量记忆一致性和动作控制能力。
- Result: 实验证明了MIND基准的完整性，并揭示了当前世界模型的关键挑战：难以保持长期记忆一致性和跨动作空间的泛化能力。
- Conclusion: MIND为世界模型评估提供了首个开放域闭环重访基准，有助于推动该领域的发展，并提出了MIND-World作为性能基准。


### [118] [Enhanced Mixture 3D CGAN for Completion and Generation of 3D Objects](https://arxiv.org/abs/2602.08046)
*Yahia Hamdi,Nicolas Andrialovanirina,Kélig Mahé,Emilie Poisson Caillault*

Main category: cs.CV

TL;DR: 提出MoE-DCGAN架构，将深度3D卷积GAN与专家混合框架结合，用于高质量3D模型生成和残缺物体重建，通过动态容量约束机制平衡专业化和计算效率。

- Motivation: 传统GAN在3D物体生成和补全任务中面临挑战：难以捕捉复杂多样的数据分布，特别是在输入不完整或缺失区域较大的情况下。高计算需求和异质结构化数据建模困难限制了实际应用。
- Method: 提出MoE-DCGAN架构：1) 集成深度3D卷积GAN与专家混合框架；2) 使用多个生成器，每个专门捕捉数据集中的不同模态；3) 引入无辅助损失的动态容量约束机制，指导分类生成器选择，平衡专业化、训练稳定性和计算效率。
- Result: 评估模型在不同大小缺失区域的形状生成和补全能力，与最先进方法比较。定量和定性结果均证实MoE-DCGAN在处理复杂3D数据方面的有效性。
- Conclusion: MoE-DCGAN框架成功解决了3D物体生成和补全中的关键挑战，通过专家混合架构和动态容量约束机制，在保持计算效率的同时实现了高质量结果，为复杂3D数据处理提供了有效解决方案。


### [119] [Vanilla Group Equivariant Vision Transformer: Simple and Effective](https://arxiv.org/abs/2602.08047)
*Jiahong Fu,Qi Xie,Deyu Meng,Zongben Xu*

Main category: cs.CV

TL;DR: 提出一种系统化构建等变Vision Transformer的框架，通过使ViT关键组件（包括patch embedding、self-attention、位置编码和采样模块）等变，实现理论保证的等变性，可无缝替换现有ViT架构。

- Motivation: 现有等变ViT难以平衡性能与等变性，主要挑战在于难以在ViT的多样化模块中实现整体等变修改，特别是协调自注意力机制与patch embedding的等变性。
- Method: 提出一个简单框架，系统性地使ViT关键组件等变：包括patch embedding、self-attention、位置编码和Down/Up-Sampling模块，构建具有理论保证等变性的ViT架构，可作为即插即用替换方案，甚至可扩展到Swin Transformers。
- Result: 广泛的实验表明，所提出的等变ViT在各种视觉任务中持续提升性能和数据效率。
- Conclusion: 该框架提供了一个理论扎实且实际通用的等变ViT构建方法，能够无缝替换现有架构，在多种视觉任务中实现性能和数据效率的持续改进。


### [120] [Weak to Strong: VLM-Based Pseudo-Labeling as a Weakly Supervised Training Strategy in Multimodal Video-based Hidden Emotion Understanding Tasks](https://arxiv.org/abs/2602.08057)
*Yufei Wang,Haixu Liu,Tianxiang Xu,Chuancheng Shi,Hongsheng Xing*

Main category: cs.CV

TL;DR: 本文提出多模态弱监督框架识别视频中的"隐藏情绪"，在iMiGUE网球采访数据集上达到SOTA，准确率从0.6提升至0.69+，并验证了简化MLP骨干网络的有效性。

- Motivation: 解决视频中"隐藏情绪"的自动识别问题，现有方法在iMiGUE数据集上准确率不足0.6，需要更有效的多模态融合和弱监督策略。
- Method: 1) YOLO 11x检测裁剪人像，DINOv2-Base提取视觉特征；2) Gemini 2.5 Pro通过CoT+Reflection提示生成伪标签和推理文本作为弱监督；3) OpenPose提取137维关键点序列，用MLP替代GCN建模时空关系；4) 超长序列Transformer编码图像和关键点序列，与BERT编码的文本特征拼接；5) 单模态预训练后联合微调，伪标签样本融入训练集。
- Result: 在严重类别不平衡情况下，准确率从先前工作的不足0.6提升至超过0.69，建立了新的公开基准；验证了"MLP化"关键点骨干网络可匹配甚至超越基于GCN的方法。
- Conclusion: 提出的多模态弱监督框架有效提升了隐藏情绪识别性能，简化MLP骨干网络在该任务中表现出色，为相关研究提供了新思路和基准。


### [121] [Picasso: Holistic Scene Reconstruction with Physics-Constrained Sampling](https://arxiv.org/abs/2602.08058)
*Xihang Yu,Rajat Talak,Lorenzo Shaikewitz,Luca Carlone*

Main category: cs.CV

TL;DR: Picasso是一个物理约束的多物体场景重建系统，通过考虑几何、非穿透和物理约束来构建物理上合理的场景重建，并提出了包含接触丰富场景的数据集和物理合理性评估指标。

- Motivation: 在遮挡和测量噪声存在的情况下，几何准确但物理不合理的场景重建会导致物体穿透或不稳定平衡等问题，这使得难以使用数字孪生预测场景的动态行为，影响基于仿真的接触丰富行为的规划和控制。
- Method: 提出Picasso物理约束重建管道，使用快速拒绝采样方法考虑多物体交互，利用推断的物体接触图指导采样，确保几何、非穿透和物理约束的满足。
- Result: 在新建的Picasso数据集和YCB-V数据集上进行了广泛评估，结果显示Picasso大幅优于现有技术，提供既物理合理又更符合人类直觉的重建结果。
- Conclusion: 物体姿态和形状估计需要对场景进行整体推理（而非孤立考虑每个物体），考虑物体交互和物理合理性，Picasso系统通过物理约束重建实现了这一目标。


### [122] [DICE: Disentangling Artist Style from Content via Contrastive Subspace Decomposition in Diffusion Models](https://arxiv.org/abs/2602.08059)
*Tong Zhang,Ru Zhang,Jianyi Liu*

Main category: cs.CV

TL;DR: DICE是一种无需训练的艺术家风格擦除框架，通过对比子空间分解实现风格与内容的解耦，有效防止扩散模型中的风格模仿侵权问题。

- Motivation: 扩散模型的普及使得风格模仿变得容易，引发了版权和知识产权风险。现有对策要么需要昂贵的权重编辑，要么依赖明确指定的编辑风格，限制了实际部署的实用性。
- Method: 提出DICE框架：1) 构建对比三元组，让模型在潜在空间中区分风格与非风格特征；2) 将解耦过程形式化为可解的广义特征值问题，精确识别风格子空间；3) 引入自适应注意力解耦编辑策略，动态评估每个token的风格浓度，对QKV向量进行差异化抑制和内容增强。
- Result: DICE在风格擦除的彻底性和内容完整性保护之间实现了优越的平衡，仅增加3秒的解耦开销，为遏制风格模仿提供了实用高效的技术。
- Conclusion: DICE通过训练自由的风格净化方法，有效解决了扩散模型中艺术家风格模仿的版权保护问题，具有实际部署的可行性。


### [123] [ReRoPE: Repurposing RoPE for Relative Camera Control](https://arxiv.org/abs/2602.08068)
*Chunyang Li,Yuanbo Yang,Jiahao Shao,Hongyu Zhou,Katja Schwarz,Yiyi Liao*

Main category: cs.CV

TL;DR: ReRoPE：一种即插即用框架，通过将相对相机姿态信息注入预训练视频扩散模型中未充分利用的RoPE低频带，实现精确相机控制，同时保持生成能力。

- Motivation: 现有视频生成方法使用相对于固定参考帧的相机姿态编码，缺乏平移不变性，导致泛化能力差和累积漂移。相对相机姿态嵌入更鲁棒，但难以在不增加训练成本或改变架构的情况下集成到预训练模型中。
- Method: 提出ReRoPE框架，利用现有模型中Rotary Positional Embeddings (RoPE)未充分利用其全频谱带宽（特别是低频分量）的洞察，将相对相机姿态信息无缝注入这些未充分利用的频带。
- Result: 在图像到视频(I2V)和视频到视频(V2V)任务上评估，ReRoPE在相机控制精度和视觉保真度方面表现出色，提供了一种训练高效的精确可控视频生成路径。
- Conclusion: ReRoPE是一种即插即用框架，能够在不损害预训练模型生成能力的前提下，将相对相机信息集成到视频扩散模型中，实现了训练高效、高保真度的可控视频生成。


### [124] [ViT-5: Vision Transformers for The Mid-2020s](https://arxiv.org/abs/2602.08071)
*Feng Wang,Sucheng Ren,Tiezheng Zhang,Predrag Neskovic,Anand Bhattad,Cihang Xie,Alan Yuille*

Main category: cs.CV

TL;DR: ViT-5：通过整合过去五年架构进展对Vision Transformer进行现代化改造，在理解和生成任务上均超越现有ViT变体

- Motivation: 虽然Vision Transformer已成为视觉任务的主流架构，但过去五年的架构进展（如归一化、激活函数、位置编码等）尚未被系统整合到标准ViT中。本研究旨在通过组件级优化来现代化ViT骨干网络。
- Method: 在保持Attention-FFN核心结构的前提下，对归一化、激活函数、位置编码、门控机制和可学习token等组件进行系统优化，形成新一代ViT架构ViT-5。
- Result: ViT-5在ImageNet-1k分类上达到84.2% top-1准确率（超越DeiT-III的83.8%）；在SiT扩散框架中实现1.84 FID（优于原始ViT的2.06 FID），同时在表示学习和空间推理方面表现更优。
- Conclusion: ViT-5通过整合现代架构设计实践，为2020年代中期视觉骨干网络提供了一个简单即插即用的升级方案，在理解和生成任务上均展现出优越性能。


### [125] [VidVec: Unlocking Video MLLM Embeddings for Video-Text Retrieval](https://arxiv.org/abs/2602.08099)
*Issar Tzachor,Dvir Samuel,Rami Ben-Ari*

Main category: cs.CV

TL;DR: 该论文提出了一种利用多模态大语言模型进行视频文本嵌入和检索的新方法，通过中间层分析和文本对齐策略，在无需视觉监督的情况下实现了零样本检索的SOTA性能。

- Motivation: 当前生成式多模态大语言模型在视频任务中的表现不如专门的视频基础模型，特别是在视频文本嵌入和检索方面。研究者希望探索如何更好地利用MLLM进行视频文本表示学习。
- Method: 1. 进行系统性的层间分析，发现MLLM中间层已编码大量任务相关信息；2. 结合中间层嵌入和校准的MLLM头部实现零样本检索；3. 提出轻量级文本对齐策略，将密集视频描述映射到简短摘要，实现无需视觉监督的视频文本嵌入学习。
- Result: 该方法在无需视觉微调的情况下，超越了现有方法，在常见视频检索基准测试中取得了最先进的结果，且优势显著。
- Conclusion: MLLM的中间层包含丰富的任务相关信息，通过适当的层选择和文本对齐策略，可以在无需视觉监督的情况下实现强大的视频文本检索性能，为MLLM在视频任务中的应用提供了新思路。


### [126] [MMLSv2: A Multimodal Dataset for Martian Landslide Detection in Remote Sensing Imagery](https://arxiv.org/abs/2602.08112)
*Sidike Paheding,Abel Reyes-Angulo,Leo Thomas Ramos,Angel D. Sappa,Rajaneesh A.,Hiral P. B.,Sajin Kumar K. S.,Thomas Oommen*

Main category: cs.CV

TL;DR: MMLSv2是一个用于火星表面滑坡分割的多模态数据集，包含7个波段图像，分为训练/验证/测试集和地理隔离测试集，用于评估模型的空间泛化能力。

- Motivation: 现有火星滑坡分割研究缺乏公开的多模态数据集，特别是缺乏评估模型空间泛化能力的地理隔离测试集，限制了滑坡检测模型的鲁棒性评估。
- Method: 构建包含664张图像的多模态数据集，包含RGB、数字高程模型、坡度、热惯性和灰度通道。额外提供276张来自地理隔离区域的测试集。使用多种分割模型进行实验评估。
- Result: 数据集支持稳定训练并达到竞争性性能，但在碎片化、细长和小规模滑坡区域仍存在挑战。地理隔离测试集导致性能显著下降，表明其能有效评估模型泛化能力。
- Conclusion: MMLSv2为火星滑坡分割提供了首个公开的多模态数据集，其地理隔离测试集能有效评估模型的空间泛化能力，对滑坡检测模型的鲁棒性研究具有重要价值。


### [127] [Building Damage Detection using Satellite Images and Patch-Based Transformer Methods](https://arxiv.org/abs/2602.08117)
*Smriti Siva,Jan Cross-Zamirski*

Main category: cs.CV

TL;DR: 本研究评估了Vision Transformer模型在xBD数据集上的建筑损伤分类性能，提出了一种针对性的基于patch的预处理流程和冻结头微调策略，在噪声和不平衡数据上取得了与CNN基线竞争的结果。

- Motivation: 快速建筑损伤评估对灾后响应至关重要，但卫星数据中的标签噪声和严重类别不平衡带来了重大挑战。xBD数据集提供了跨地理区域的标准化基准，需要研究ViT模型在噪声和不平衡数据上区分结构损伤类型的能力。
- Method: 使用DINOv2-small和DeiT进行多类损伤分类，提出针对性的基于patch的预处理流程来隔离结构特征并减少背景噪声，采用冻结头微调策略以控制计算需求，通过准确率、精确率、召回率和宏平均F1分数评估性能。
- Result: 小型ViT架构配合新颖的训练方法在灾害分类任务中取得了与先前CNN基线竞争性的宏平均F1分数。
- Conclusion: ViT模型在建筑损伤分类任务中具有潜力，通过针对性的预处理和微调策略可以有效处理噪声和不平衡数据，为卫星图像损伤评估提供了可扩展的解决方案。


### [128] [MambaFusion: Adaptive State-Space Fusion for Multimodal 3D Object Detection](https://arxiv.org/abs/2602.08126)
*Venkatraman Narayanan,Bala Sai,Rahul Ahuja,Pratik Likhar,Varun Ravi Kumar,Senthil Yogamani*

Main category: cs.CV

TL;DR: MambaFusion：基于选择性状态空间模型（SSM）和窗口Transformer的多模态3D检测框架，实现高效、自适应、物理基础的感知，在nuScenes基准上达到SOTA性能

- Motivation: 自动驾驶需要可靠的3D物体检测，但现有基于BEV的融合框架存在效率低下、空间不变融合和不确定性推理困难等问题。相机提供密集视觉线索但深度信息不准确，LiDAR提供精确3D结构但覆盖稀疏，需要更高效的融合方法
- Method: 1. 交替使用选择性状态空间模型（SSM）和窗口Transformer，在线性时间内传播全局上下文同时保持局部几何保真度；2. 多模态令牌对齐模块和可靠性感知融合门，基于空间置信度和标定一致性动态重加权相机-LiDAR特征；3. 结构条件扩散头，集成基于图的推理和不确定性感知去噪，增强物理合理性和校准置信度
- Result: 在nuScenes基准测试中建立了新的最先进性能，同时保持线性时间复杂度。框架展示了SSM效率与可靠性驱动融合的结合能够为真实世界自动驾驶系统提供鲁棒、时间稳定且可解释的3D感知
- Conclusion: MambaFusion通过将SSM效率与可靠性驱动融合相结合，实现了高效、自适应、物理基础的3D感知，为自动驾驶系统提供了鲁棒且可解释的解决方案，在保持线性复杂度的同时达到SOTA性能


### [129] [Fields of The World: A Field Guide for Extracting Agricultural Field Boundaries](https://arxiv.org/abs/2602.08131)
*Isaac Corley,Hannah Kerner,Caleb Robinson,Jennifer Marcus*

Main category: cs.CV

TL;DR: FTW生态系统提供全球农田边界数据集、预训练模型和工具，支持从局部到国家尺度的农田边界提取、作物分类和森林损失分析。

- Motivation: 农田边界图是农业数据产品的基础，对作物监测、产量估算和疾病评估至关重要。现有方法在覆盖范围和可扩展性方面存在局限。
- Method: 构建Fields of The World生态系统：包含24个国家160万个农田多边形的基准数据集、预训练分割模型和命令行推理工具。使用MOSAIKS随机卷积特征和FTW农田边界进行作物类型分类。
- Result: 作物类型分类的宏观F1分数达到0.65-0.75（使用有限标签）。在五个国家（476万平方公里）展示了预测结果，预测农田中位数面积从0.06公顷（卢旺达）到0.28公顷（瑞士）。
- Conclusion: FTW生态系统为农田边界提取和作物分类提供了可扩展的解决方案，支持从局部到国家尺度的农业监测应用。


### [130] [Robustness of Vision Language Models Against Split-Image Harmful Input Attacks](https://arxiv.org/abs/2602.08136)
*Md Rafi Ur Rashid,MD Sadik Hossain Shanto,Vishnu Asutosh Dasu,Shagufta Mehnaz*

Main category: cs.CV

TL;DR: 本文提出了一种针对视觉语言模型的新型视觉越狱攻击方法SIVA，利用模型在分割图像输入上的安全对齐漏洞，通过对抗知识蒸馏显著提高了跨模型攻击成功率。

- Motivation: 当前视觉语言模型在完整图像上进行了广泛的安全对齐（如RLHF），但对分割图像输入的安全对齐不足。研究发现有害语义分布在多个图像片段中时，模型往往无法检测和拒绝，这构成了新的安全漏洞。
- Method: 提出SIVA分割图像视觉越狱攻击，包括渐进式攻击策略：从简单分割到自适应白盒攻击，最终发展为黑盒迁移攻击。最强策略采用新颖的对抗知识蒸馏算法，显著提升跨模型迁移能力。
- Result: 在三个最先进的现代VLM和三个越狱数据集上的评估显示，最强攻击比现有基线高出60%的迁移成功率。
- Conclusion: 揭示了当前VLM安全对齐在分割图像输入上的关键漏洞，提出了高效的防御方法来解决这一安全风险。


### [131] [DAS-SK: An Adaptive Model Integrating Dual Atrous Separable and Selective Kernel CNN for Agriculture Semantic Segmentation](https://arxiv.org/abs/2602.08168)
*Mei Ling Chee,Thangarajah Akilan,Aparna Ravindra Phalke,Kanchan Keisham*

Main category: cs.CV

TL;DR: DAS-SK是一种轻量级语义分割架构，通过将选择性核卷积集成到双空洞可分离卷积模块中，在农业高分辨率图像分割中实现精度与效率的平衡。

- Motivation: 农业高分辨率图像语义分割需要平衡精度和计算效率的模型，以便在实际系统中部署。现有模型通常面临大数据集需求、有限的光谱泛化能力以及高计算成本等问题，限制了在无人机和边缘设备上的应用。
- Method: 提出DAS-SK架构，将选择性核卷积（SK-Conv）集成到双空洞可分离卷积（DAS-Conv）模块中，增强多尺度特征学习。改进空洞空间金字塔池化（ASPP）模块，同时捕获细粒度局部结构和全局上下文信息。基于改进的DeepLabV3框架，使用MobileNetV3-Large和EfficientNet-B3两个互补骨干网络。
- Result: 在LandCover.ai、VDD和PhenoBench三个基准测试中，DAS-SK始终达到最先进的性能，同时比CNN、Transformer和混合模型更高效。与顶级Transformer模型相比，DAS-SK需要最多21倍更少的参数和19倍更少的GFLOPs。
- Conclusion: DAS-SK为实时农业机器人和高分辨率遥感提供了一个鲁棒、高效且可扩展的解决方案，在其他视觉领域具有广泛的部署潜力。


### [132] [PEGAsus: 3D Personalization of Geometry and Appearance](https://arxiv.org/abs/2602.08198)
*Jingyu Hu,Bin Hu,Ka-Hei Hui,Haipeng Li,Zhengzhe Liu,Daniel Cohen-Or,Chi-Wing Fu*

Main category: cs.CV

TL;DR: PEGAsus是一个生成个性化3D形状的新框架，通过学习几何和外观层面的形状概念，实现从参考形状提取可重用属性并与文本结合生成新形状。

- Motivation: 现有3D形状生成方法在个性化控制方面存在局限，需要能够从参考形状提取可重用概念并与文本描述灵活组合，实现细粒度控制和跨类别生成。
- Method: 1. 将3D形状个性化定义为提取类别无关的几何和外观属性；2. 设计渐进优化策略分离学习几何和外观概念；3. 扩展到区域级概念学习，使用上下文感知和无上下文损失。
- Result: PEGAsus能够从广泛参考形状中有效提取属性，并与文本灵活组合生成新形状，实现细粒度控制，在跨类别场景中产生多样化个性化结果，定量和定性实验均优于现有方法。
- Conclusion: PEGAsus通过几何和外观层面的概念学习框架，实现了有效的3D形状个性化生成，在概念提取、组合控制和跨类别生成方面表现出色，为个性化3D内容创作提供了新方案。


### [133] [Generative Regression for Left Ventricular Ejection Fraction Estimation from Echocardiography Video](https://arxiv.org/abs/2602.08202)
*Jinrong Lv,Xun Gong,Zhaohuan Li,Weili Jiang*

Main category: cs.CV

TL;DR: 该论文提出了一种用于从超声心动图估计左心室射血分数(LVEF)的生成式回归方法，采用多模态条件评分扩散模型来建模连续后验分布，解决了传统回归方法在处理多模态分布时的局限性。

- Motivation: 从超声心动图估计LVEF是一个病态逆问题，存在噪声、伪影和有限视角导致的模糊性。传统深度学习方法采用MSE回归，但这种方法迫使模型学习条件期望，当后验分布是多模态或重尾分布时会产生误导性预测，这在病理场景中很常见。
- Method: 提出了多模态条件评分扩散回归模型(MCSDR)，这是一个概率框架，用于建模以超声心动图视频和患者人口统计属性先验为条件的LVEF连续后验分布。该方法从确定性回归转向生成式回归。
- Result: 在EchoNet-Dynamic、EchoNet-Pediatric和CAMUS数据集上的广泛实验表明，MCSDR实现了最先进的性能。定性分析显示，在高噪声或显著生理变异性的情况下，模型的生成轨迹表现出独特行为，为AI辅助诊断提供了新的可解释性层。
- Conclusion: 该研究展示了从确定性回归向生成式回归的范式转变的有效性，提出的MCSDR框架不仅提高了LVEF估计的准确性，还通过生成轨迹提供了对模型决策过程的可解释性见解，特别是在复杂病理情况下。


### [134] [Geospatial-Reasoning-Driven Vocabulary-Agnostic Remote Sensing Semantic Segmentation](https://arxiv.org/abs/2602.08206)
*Chufeng Zhou,Jian Wang,Xinyuan Liu,Xiaokang Zhang*

Main category: cs.CV

TL;DR: 提出GR-CoT框架，通过地理空间推理链增强MLLMs的场景理解能力，解决遥感开放词汇分割中相似光谱特征但不同语义类别的歧义问题

- Motivation: 现有开放词汇分割方法主要依赖视觉特征和文本嵌入的被动映射，缺乏地理空间上下文感知，导致遇到光谱特征相似但语义属性不同的地物类别时产生严重语义歧义和误分类
- Method: 提出Geospatial Reasoning Chain-of-Thought (GR-CoT)框架，包含离线知识蒸馏流和在线实例推理流。离线流建立细粒度类别解释标准，在线流执行宏观场景锚定、视觉特征解耦和知识驱动决策合成的顺序推理过程
- Result: 在LoveDA和GID5基准测试上进行了广泛实验，证明了方法的优越性
- Conclusion: GR-CoT框架通过增强MLLMs的地理空间推理能力，有效解决了遥感开放词汇分割中的语义歧义问题，实现了更精确的地理语义对齐


### [135] [Chain-of-Caption: Training-free improvement of multimodal large language model on referring expression comprehension](https://arxiv.org/abs/2602.08211)
*Yik Lung Pang,Changjae Oh*

Main category: cs.CV

TL;DR: 提出Chain-of-Caption训练免费框架，通过结合多种视觉和文本上下文，在REC任务上实现5%-30%的性能提升

- Motivation: 尽管多模态大语言模型在指代表达理解任务上已取得高准确率，但通过工具使用提供额外视觉或文本上下文可以进一步提升性能。本文旨在分析不同上下文提供技术对REC任务的影响。
- Method: 提出Chain-of-Caption训练免费框架，分析各种通过工具使用提供额外视觉和文本上下文的技术，并在RefCOCO/RefCOCOg/RefCOCO+和Ref-L4数据集上进行实验。
- Result: 实验表明，单独的文本或视觉上下文无需微调即可提升REC性能。通过结合多种上下文，训练免费框架在多种IoU阈值下的准确率比基线模型提升5%-30%。
- Conclusion: Chain-of-Caption框架有效提升了MLLMs在REC任务上的性能，展示了结合多种上下文信息的价值，且无需额外训练。


### [136] [Efficient-SAM2: Accelerating SAM2 with Object-Aware Visual Encoding and Memory Retrieval](https://arxiv.org/abs/2602.08224)
*Jing Zhang,Zhikai Li,Xuewen Liu,Qingyi Gu*

Main category: cs.CV

TL;DR: 提出Efficient-SAM2方法，通过对象感知的稀疏窗口路由和稀疏内存检索机制，在保持SAM2视频分割性能的同时实现1.68倍加速

- Motivation: SAM2在视频对象分割任务中表现出色，但计算负担重，难以应用于实时视频处理。现有改进方法主要关注重新训练轻量级骨干网络，对训练后加速的探索不足。研究发现SAM2具有类似生物视觉的稀疏感知模式，存在消除冗余计算的机会
- Method: 提出Efficient-SAM2框架：1) 对象感知稀疏窗口路由(SWR)：利用前一帧解码器的连续性和显著性线索，将背景区域路由到轻量级快捷分支；2) 对象感知稀疏内存检索(SMR)：仅让每帧中的显著内存标记参与计算，并重用首次回忆时的显著性模式
- Result: 在SAM2.1-L模型上实现1.68倍加速，在SA-V测试集上仅产生1.0%的准确率下降，额外参数和训练开销极小
- Conclusion: Efficient-SAM2通过自适应聚焦对象区域并消除任务无关计算，显著提高了SAM2的推理效率，为实时视频处理应用提供了可行的解决方案


### [137] [Generating Adversarial Events: A Motion-Aware Point Cloud Framework](https://arxiv.org/abs/2602.08230)
*Hongwei Ren,Youxin Jiang,Qifei Gu,Xiangqian Wu*

Main category: cs.CV

TL;DR: MA-ADV是首个利用点云表示生成对抗性事件的方法，通过扩散平滑扰动并利用时空关系，实现100%攻击成功率且扰动成本最小。

- Motivation: 事件相机在自动驾驶、机器人等安全关键领域广泛应用，但深度神经网络对对抗样本的脆弱性威胁事件系统的可靠性。由于主流事件表示的非可微性，基于梯度的攻击方法难以扩展，导致事件对抗攻击研究稀缺。
- Method: 提出MA-ADV框架：1) 利用点云表示生成对抗事件；2) 考虑事件中的高频噪声，采用基于扩散的方法平滑扰动；3) 充分利用事件间的时空关系；4) 结合样本级Adam优化、迭代精炼和二分搜索寻找最小成本扰动。
- Result: 实验验证MA-ADV能确保100%攻击成功率且扰动成本最小，同时展示了对防御方法的增强鲁棒性，凸显了未来事件感知系统面临的关键安全挑战。
- Conclusion: MA-ADV是首个基于点云表示的事件对抗攻击框架，成功解决了事件表示非可微性带来的挑战，揭示了事件感知系统存在的严重安全漏洞，对未来安全关键应用具有重要意义。


### [138] [When and How Much to Imagine: Adaptive Test-Time Scaling with World Models for Visual Spatial Reasoning](https://arxiv.org/abs/2602.08236)
*Shoubin Yu,Yue Zhang,Zun Wang,Jaehong Yoon,Huaxiu Yao,Mingyu Ding,Mohit Bansal*

Main category: cs.CV

TL;DR: AVIC框架通过自适应控制视觉想象，在空间推理任务中实现高效可靠推理，避免不必要的世界模型调用

- Motivation: 当前多模态大语言模型在视觉空间推理中存在局限性，特别是在需要从未见视角推理时。现有方法使用世界模型进行视觉想象，但缺乏对何时需要想象、需要多少想象以及何时想象有害的系统分析。
- Method: 提出AVIC自适应测试时框架，包含世界模型，在调用视觉想象前显式推理当前视觉证据的充分性，然后选择性调用和缩放视觉想象。
- Result: 在空间推理基准(SAT, MMSI)和具身导航基准(R2R)上，结果显示选择性控制可以匹配或优于固定想象策略，同时显著减少世界模型调用和语言标记数量。
- Conclusion: 研究揭示了视觉想象在空间推理中的关键作用场景，强调分析和控制测试时想象对于高效可靠空间推理的重要性，为自适应视觉推理提供了新方向。


### [139] [Moving Beyond Functional Connectivity: Time-Series Modeling for fMRI-Based Brain Disorder Classification](https://arxiv.org/abs/2602.08262)
*Guoqi Yu,Xiaowei Hu,Angelica I. Aviles-Rivero,Anqi Qiu,Shujun Wang*

Main category: cs.CV

TL;DR: 提出DeCI框架，通过周期-漂移分解和通道独立建模，直接在原始BOLD信号上进行脑疾病分类，优于传统功能连接方法

- Motivation: 现有fMRI脑疾病分类方法主要依赖基于皮尔逊相关的功能连接，将4D BOLD信号简化为静态2D矩阵，丢失了时间动态信息且只能捕捉线性关系
- Method: 提出DeCI框架：1) 周期-漂移分解：将每个ROI的信号分解为周期性和漂移性成分；2) 通道独立：分别建模每个ROI，提高鲁棒性和减少过拟合
- Result: 在五个公开数据集上的实验表明，DeCI在分类准确率和泛化能力上均优于基于功能连接的方法和其他时间序列模型基线
- Conclusion: 研究支持在fMRI分析中转向端到端的时间建模，以更好地捕捉复杂的大脑动态，DeCI框架为此提供了有效解决方案


### [140] [PISCO: Precise Video Instance Insertion with Sparse Control](https://arxiv.org/abs/2602.08277)
*Xiangbo Gao,Renjie Li,Xinghao Chen,Yuheng Wu,Suofei Feng,Qing Yin,Zhengzhong Tu*

Main category: cs.CV

TL;DR: PISCO是一个视频扩散模型，用于通过任意稀疏关键帧控制实现精确的视频实例插入，解决了传统视频编辑中空间-时间定位、物理一致性和原始动态保持的挑战。

- Motivation: AI视频生成正从依赖大量提示工程和筛选的通用生成转向细粒度可控生成和高保真后处理。在专业AI辅助电影制作中，需要对现有素材进行精确、有针对性的修改，视频实例插入是这一转变的关键，需要将特定实例插入现有镜头同时保持场景完整性。
- Method: 提出PISCO视频扩散模型，支持单关键帧、起始-结束关键帧或任意时间戳的稀疏关键帧控制。引入可变信息引导用于鲁棒条件化，分布保持时间掩码用于稳定时间生成，以及几何感知条件化实现真实场景适应。
- Result: 构建了PISCO-Bench基准测试集，包含验证过的实例标注和配对干净背景视频。实验表明PISCO在稀疏控制下持续优于强基线方法（修复和视频编辑），并随着提供额外控制信号展现出清晰、单调的性能提升。
- Conclusion: PISCO通过稀疏关键帧控制实现了精确的视频实例插入，为专业AI辅助电影制作提供了有效的解决方案，推动了AI视频生成向更可控、更精细的方向发展。


### [141] [Tighnari v2: Mitigating Label Noise and Distribution Shift in Multimodal Plant Distribution Prediction via Mixture of Experts and Weakly Supervised Learning](https://arxiv.org/abs/2602.08282)
*Haixu Liu,Yufei Wang,Tianxiang Xu,Chuancheng Shi,Hongsheng Xing*

Main category: cs.CV

TL;DR: 提出多模态融合框架，结合PA和PO数据优势，通过地理对齐和专家混合策略解决植物分布预测中的数据稀疏、偏差和分布偏移问题。

- Motivation: 大规模跨物种植物分布预测对生物多样性保护至关重要，但面临观测数据稀疏、偏差的挑战。PA数据准确但成本高、数量有限；PO数据覆盖广但负样本标签噪声严重。需要充分利用两种数据优势。
- Method: 1) 基于卫星影像地理覆盖的PO数据伪标签聚合策略，实现标签空间与遥感特征空间的地理对齐；2) 多模态架构：Swin Transformer处理卫星影像，TabM网络提取表格特征，Temporal Swin Transformer处理时间序列，串行三模态交叉注意力机制融合异质模态；3) 专家混合策略：根据空间邻近性划分测试样本，在不同分区使用不同数据集训练的模型进行推理和后处理。
- Result: 在GeoLifeCLEF 2025数据集上的实验表明，该方法在PA覆盖有限且分布偏移明显的情况下取得了优越的预测性能。
- Conclusion: 提出的多模态融合框架有效结合了PA和PO数据的优势，通过地理对齐和专家混合策略解决了数据稀疏、标签噪声和分布偏移问题，为大规模植物分布预测提供了有效解决方案。


### [142] [CAE-AV: Improving Audio-Visual Learning via Cross-modal Interactive Enrichment](https://arxiv.org/abs/2602.08309)
*Yunzuo Hu,Wen Li,Jing Zhang*

Main category: cs.CV

TL;DR: CAE-AV框架通过两个互补模块（CASTE和CASE）解决音视频学习中的模态不对齐问题，利用跨模态一致性指导和字幕对齐增强，在多个基准测试中达到SOTA性能。

- Motivation: 音视频学习面临模态不对齐的挑战，包括离屏声源和背景干扰，现有方法常放大不相关区域或时刻，导致训练不稳定和表征质量下降。
- Method: 提出CAE-AV框架，包含两个互补模块：1) CASTE通过评估帧级音视频一致性动态平衡时空关系；2) CASE将跨模态语义指导注入选定的时空位置。还设计了轻量级目标函数：字幕到模态InfoNCE、视觉-音频一致性和熵正则化。
- Result: 在冻结骨干网络的情况下，CAE-AV在AVE、AVVP、AVS和AVQA基准测试中达到最先进性能，定性分析进一步验证了其对音视频不对齐的鲁棒性。
- Conclusion: CAE-AV框架通过跨模态一致性指导和字幕对齐增强有效缓解音视频不对齐问题，提高了音视频学习的表征质量和鲁棒性。


### [143] [Language-Guided Transformer Tokenizer for Human Motion Generation](https://arxiv.org/abs/2602.08337)
*Sheng Yan,Yong Wang,Xin Du,Junsong Yuan,Mengyuan Liu*

Main category: cs.CV

TL;DR: 提出语言引导的标记化方法(LG-Tok)，通过自然语言与运动数据的对齐，在保持高质量重建的同时降低生成复杂度，显著提升运动生成性能。

- Motivation: 现有运动离散标记化方法面临两难：增加标记数量可提高重建质量，但会增加生成模型学习难度。需要一种既能保持高质量重建又能降低生成复杂度的标记化方法。
- Method: 提出语言引导标记化(LG-Tok)，在标记化阶段对齐自然语言与运动数据，生成紧凑的高层语义表示。采用基于Transformer的标记器，利用注意力机制支持全局语言指导，并设计语言丢弃方案，使解标记器支持无语言指导的生成。
- Result: 在HumanML3D和Motion-X基准测试中，LG-Tok获得Top-1分数0.542和0.582，优于SOTA方法(MARDM: 0.500和0.528)；FID分数分别为0.057和0.088，优于0.114和0.147。LG-Tok-mini仅使用一半标记仍保持竞争力。
- Conclusion: 语言引导的标记化方法有效解决了运动标记化的质量与复杂度矛盾，通过语义对齐实现了高效的运动表示，显著提升了运动生成性能。


### [144] [UrbanGraphEmbeddings: Learning and Evaluating Spatially Grounded Multimodal Embeddings for Urban Science](https://arxiv.org/abs/2602.08342)
*Jie Zhang,Xingtong Yu,Yuan Fang,Rudi Stouffs,Zdravko Trivic*

Main category: cs.CV

TL;DR: UGData数据集将街景图像与空间图对齐，UGE训练策略通过指令引导对比学习和图编码对齐图像、文本与空间结构，UGBench基准评估空间嵌入在多种城市理解任务中的表现，实验显示显著提升。

- Motivation: 城市理解本质上是空间性的，但现有数据集缺乏街景图像与城市结构的明确对齐，这限制了可迁移多模态嵌入的学习。
- Method: 1) 引入UGData数据集，将街景图像锚定到结构化空间图，提供空间推理路径和空间上下文描述；2) 提出UGE两阶段训练策略，结合指令引导对比学习和基于图的空间编码，逐步对齐图像、文本和空间结构；3) 使用LoRA微调在多个VLM骨干上训练固定维度空间嵌入。
- Result: 基于Qwen2.5-VL-7B骨干的UGE在训练城市上图像检索提升44%，地理位置排序提升30%；在未见城市上分别提升30%和22%，证明显式空间接地对空间密集型城市任务的有效性。
- Conclusion: 显式空间接地对于学习可迁移的城市多模态嵌入至关重要，UGData、UGE和UGBench为空间密集型城市理解任务提供了有效的数据集、训练策略和评估基准。


### [145] [What, Whether and How? Unveiling Process Reward Models for Thinking with Images Reasoning](https://arxiv.org/abs/2602.08346)
*Yujin Zhou,Pengcheng Wen,Jiale Chen,Boqin Yin,Han Zhu,Jiaming Ji,Juntao Dai,Chi-Min Chan,Sirui Han*

Main category: cs.CV

TL;DR: 该研究提出了首个专门针对"图像思维"范式的过程奖励模型（PRM）基准，包含1,206条人工标注的推理轨迹，定义了7种细粒度错误类型，并发现当前LVLM作为PRM存在显著不足。

- Motivation: 随着大型视觉语言模型（LVLM）的发展，"图像思维"范式允许模型在推理过程中动态编辑和重新编码视觉信息，但这引入了推理过程中的多样化错误。现有的PRM基准主要是文本中心的，缺乏针对这一新范式的全面评估。
- Method: 1. 通过分析推理轨迹和PRM引导搜索实验，定义了7种细粒度错误类型；2. 构建包含1,206条人工标注推理轨迹的基准，涵盖4个类别和16个子类别；3. 实验分析当前LVLM作为PRM的性能。
- Result: 当前LVLM作为PRM表现不足：视觉推理过程评估能力有限，在不同错误类型间性能差异显著，存在正向评估偏差，且对推理步骤位置敏感。基准验证了专门PRM的必要性和改进潜力。
- Conclusion: 该研究为LVLM中PRM的评估和发展建立了重要基础，提出的基准有效揭示了当前模型的局限性，为未来PRM的改进提供了关键指导。


### [146] [E-VAds: An E-commerce Short Videos Understanding Benchmark for MLLMs](https://arxiv.org/abs/2602.08355)
*Xianjie Liu,Yiman Hu,Liang Wu,Ping Hu,Yixiong Zou,Jian Xu,Bo Zheng*

Main category: cs.CV

TL;DR: 该论文提出了首个针对电商短视频理解的基准数据集E-VAds，包含3,961个高质量视频和19,785个问答对，并开发了基于强化学习的推理模型E-VAds-R1，在商业意图推理任务上取得了109.2%的性能提升。

- Motivation: 电商短视频作为在线视频行业的高收入细分领域，具有目标驱动和多模态信号密集的特点。现有模型在处理这类视频时面临困难，因为现有基准主要关注通用任务，忽视了商业意图推理。电商内容在视觉、音频和文本模态上的信息密度远高于主流数据集，为视频理解带来了更大挑战。
- Method: 1. 提出多模态信息密度评估框架来量化电商领域的复杂性；2. 构建E-VAds基准数据集，包含3,961个淘宝高质量视频，使用多智能体系统生成19,785个开放式问答对，组织为感知与认知推理两个维度五个任务；3. 开发E-VAds-R1模型，采用基于强化学习的推理框架，设计了多粒度奖励策略MG-GRPO，为早期探索提供平滑指导，同时为专家级精度创建非线性激励。
- Result: 实验结果表明，E-VAds-R1在仅使用数百个训练样本的情况下，在商业意图推理任务上实现了109.2%的性能提升。评估显示电商内容在视觉、音频和文本模态上的信息密度显著高于主流数据集，证实了该领域的挑战性。
- Conclusion: 该工作填补了电商短视频理解领域的空白，通过构建专门的基准数据集E-VAds和开发高效的推理模型E-VAds-R1，为电商视频理解建立了新的研究前沿。提出的多粒度奖励策略MG-GRPO在少量样本下实现了显著性能提升，为电商短视频的商业意图理解提供了有效解决方案。


### [147] [Geometric Image Editing via Effects-Sensitive In-Context Inpainting with Diffusion Transformers](https://arxiv.org/abs/2602.08388)
*Shuo Zhang,Wenzhuo Wu,Huayu Zhang,Jiarong Cheng,Xianghao Zang,Chao Ban,Hao Sun,Zhongjiang He,Tianwei Cao,Kongming Liang,Zhanyu Ma*

Main category: cs.CV

TL;DR: GeoEdit：基于扩散变换器的几何编辑框架，通过上下文生成和效果敏感注意力机制，实现精确的物体平移、旋转、缩放编辑，并生成逼真的光影效果。

- Motivation: 当前扩散模型在图像编辑方面取得进展，但在处理几何变换（平移、旋转、缩放）时仍面临挑战，特别是在复杂场景中。现有方法存在两个主要局限：1）难以实现准确的几何编辑；2）对复杂光影效果建模不足，导致结果不真实。
- Method: 提出GeoEdit框架，包含：1）基于扩散变换器的上下文生成模块，集成几何变换实现精确物体编辑；2）效果敏感注意力机制，增强复杂光影效果建模；3）构建RS-Objects大规模几何编辑数据集（12万+高质量图像对）用于训练。
- Result: 在公开基准测试上的大量实验表明，GeoEdit在视觉质量、几何精度和真实感方面持续优于最先进方法。
- Conclusion: GeoEdit通过创新的扩散变换器架构和效果敏感注意力机制，成功解决了复杂场景中几何编辑的挑战，实现了精确的物体变换和逼真的光影效果生成。


### [148] [D$^2$-VR: Degradation-Robust and Distilled Video Restoration with Synergistic Optimization Strategy](https://arxiv.org/abs/2602.08395)
*Jianfeng Liang,Shaocheng Shen,Botao Xu,Qiang Hu,Xiaoyun Zhang*

Main category: cs.CV

TL;DR: D²-VR：一种基于单图像扩散的视频修复框架，通过降噪鲁棒流对齐和对抗蒸馏实现12倍加速，在保持感知质量的同时提升时间稳定性

- Motivation: 现有基于扩散先验和时间对齐的视频修复方法虽然能提供出色的感知质量，但在处理复杂真实世界退化时面临推理延迟高和时间不稳定的问题，限制了实际部署
- Method: 1. 设计降噪鲁棒流对齐模块，利用置信度感知注意力过滤不可靠运动线索；2. 采用对抗蒸馏范式将扩散采样轨迹压缩到快速少步机制；3. 设计协同优化策略平衡感知质量与时间一致性
- Result: D²-VR在广泛实验中达到最先进性能，同时将采样过程加速12倍
- Conclusion: 该方法有效解决了基于扩散的视频修复框架在实际部署中的延迟和稳定性问题，为高质量视频修复提供了高效实用的解决方案


### [149] [RealSynCol: a high-fidelity synthetic colon dataset for 3D reconstruction applications](https://arxiv.org/abs/2602.08397)
*Chiara Lena,Davide Milesi,Alessandro Casella,Luca Carlini,Joseph C. Norton,James Martin,Bruno Scaglioni,Keith L. Obstein,Roberto De Sire,Marco Spadaccini,Cesare Hassan,Pietro Valdastri,Elena De Momi*

Main category: cs.CV

TL;DR: RealSynCol是一个高度逼真的合成结肠镜数据集，用于解决深度学习在结肠镜3D重建中缺乏大规模真实数据的问题，显著提升了在临床图像上的泛化性能。

- Motivation: 深度学习有潜力通过3D重建结肠来改进结肠镜检查，提供全面的黏膜表面和病变视图，并帮助识别未探索区域。然而，缺乏大规模真实数据限制了稳健方法的发展。
- Method: 从10个CT扫描中提取结肠几何结构，导入到模拟术中条件的虚拟环境中，使用真实血管纹理进行渲染。数据集包含28,130帧图像，配有深度图、光流、3D网格和相机轨迹等真实标签。
- Result: 基准研究表明，RealSynCol的高真实性和变异性显著提升了在临床图像上的泛化性能，证明它是开发支持内镜诊断的深度学习算法的强大工具。
- Conclusion: RealSynCol合成数据集为解决结肠镜深度学习中的数据稀缺问题提供了有效解决方案，其高真实性和丰富标注使其成为开发临床适用算法的有力工具。


### [150] [Understanding and Optimizing Attention-Based Sparse Matching for Diverse Local Features](https://arxiv.org/abs/2602.08430)
*Qiang Wang*

Main category: cs.CV

TL;DR: 重新审视基于注意力的稀疏图像匹配模型训练，发现关键设计选择影响LightGlue性能，检测器比描述符对性能影响更大，提出用多种检测器关键点微调的通用模型，在零样本匹配中达到或超过专用训练模型的效果。

- Motivation: 重新审视基于注意力的稀疏图像匹配模型训练问题，识别之前被忽视的关键设计选择，研究检测器和描述符在基于transformer的匹配框架中的作用，旨在开发通用的、检测器无关的图像匹配模型。
- Method: 首先识别影响LightGlue模型性能的关键设计选择；然后分析检测器和描述符在transformer匹配框架中的角色；最后提出使用多种检测器的关键点对现有图像匹配模型进行微调的方法，创建通用的检测器无关模型。
- Result: 发现检测器（而非描述符）通常是性能差异的主要原因；提出的通用模型在作为零样本匹配器用于新检测器时，能够达到或超过专门为这些特征训练的模型的准确性。
- Conclusion: 研究结果为基于transformer的匹配模型的部署和未来局部特征设计提供了有价值的见解，证明了开发通用、检测器无关的图像匹配模型的可行性。


### [151] [Demo-ICL: In-Context Learning for Procedural Video Knowledge Acquisition](https://arxiv.org/abs/2602.08439)
*Yuhao Dong,Shulin Tian,Shuai Liu,Shuangrui Ding,Yuhang Zang,Xiaoyi Dong,Yuhang Cao,Jiaqi Wang,Ziwei Liu*

Main category: cs.CV

TL;DR: 提出Demo-driven Video In-Context Learning任务和Demo-ICL-Bench基准，用于评估MLLMs从少量视频示例中学习的能力，并开发了Demo-ICL模型来解决这一挑战。

- Motivation: 现有视频基准主要评估模型基于静态内部知识理解视频的能力，而非从动态、新颖上下文中进行少量示例学习的能力，需要填补这一空白。
- Method: 1) 提出Demo-driven Video In-Context Learning任务；2) 构建Demo-ICL-Bench基准，包含1200个教学YouTube视频及相关问题；3) 开发Demo-ICL模型，采用两阶段训练策略：视频监督微调和信息辅助直接偏好优化。
- Result: 实验表明Demo-ICL-Bench对现有最先进MLLMs具有挑战性，Demo-ICL模型在该基准上表现出有效性，揭示了未来研究方向。
- Conclusion: 该工作填补了视频上下文学习评估的空白，提出的任务、基准和模型为视频理解中的少样本学习能力评估提供了新方向。


### [152] [Vista: Scene-Aware Optimization for Streaming Video Question Answering under Post-Hoc Queries](https://arxiv.org/abs/2602.08448)
*Haocheng Lu,Nan Zhang,Wei Tao,Xiaoyang Qu,Guokuan Li,Jiguang Wan,Jianzong Wang*

Main category: cs.CV

TL;DR: Vista是一个用于流式视频问答的新型框架，通过场景感知的分割、压缩和召回机制，实现高效可扩展的连续视频流推理。

- Motivation: 流式视频问答对多模态大语言模型提出独特挑战，现有基于固定大小内存或简单压缩的方法常导致上下文丢失或内存溢出，限制了在长时、实时场景中的有效性。
- Method: Vista包含三个创新方面：1) 场景感知分割：动态聚类输入帧为时空和视觉连贯的场景单元；2) 场景感知压缩：将每个场景压缩为紧凑令牌表示存储在GPU内存，全分辨率帧卸载到CPU内存；3) 场景感知召回：查询时选择性召回相关场景并重新整合到模型输入。
- Result: 在StreamingBench上的大量实验表明，Vista实现了最先进的性能，为现实世界流式视频理解建立了强大基线。
- Conclusion: Vista是一个模型无关的框架，可无缝集成多种视觉语言骨干网络，在不影响延迟或内存效率的情况下实现长上下文推理，为流式视频问答提供了高效可扩展的解决方案。


### [153] [TriC-Motion: Tri-Domain Causal Modeling Grounded Text-to-Motion Generation](https://arxiv.org/abs/2602.08462)
*Yiyang Cao,Yunze Deng,Ziyu Lin,Bin Feng,Xinggang Wang,Wenyu Liu,Dandan Zheng,Jingdong Chen*

Main category: cs.CV

TL;DR: TriC-Motion：基于扩散模型的文本到动作生成框架，通过空间-时间-频率三域联合建模与因果干预，解决现有方法在多域信息融合不足和噪声纠缠问题，在HumanML3D数据集上达到SOTA性能。

- Motivation: 当前文本到动作生成方法主要关注空间-时间建模或独立的频率域分析，缺乏跨空间、时间和频率域的统一联合优化框架。这限制了模型同时利用所有域信息的能力，导致生成质量不理想。此外，动作生成框架中，噪声引起的动作无关线索常常与有益特征纠缠，导致动作失真。
- Method: 提出TriC-Motion框架，包含三个核心建模模块：时间动作编码、空间拓扑建模和混合频率分析。通过评分引导的三域融合模块整合三域有价值信息，确保时间一致性、空间拓扑、动作趋势和动态特性。同时设计基于因果关系的反事实动作解耦器，暴露动作无关线索以消除噪声，解耦各域的真实建模贡献。
- Result: 在HumanML3D数据集上达到最先进性能，R@1指标为0.612。实验结果表明TriC-Motion能够生成高保真、连贯、多样且与文本对齐的动作序列。
- Conclusion: TriC-Motion通过空间-时间-频率三域联合建模与因果干预，有效解决了多域信息融合不足和噪声纠缠问题，显著提升了文本到动作生成的性能和质量。


### [154] [Gesture Matters: Pedestrian Gesture Recognition for AVs Through Skeleton Pose Evaluation](https://arxiv.org/abs/2602.08479)
*Alif Rizqullah Mahdi,Mahdi Rezaei,Natasha Merat*

Main category: cs.CV

TL;DR: 提出基于2D姿态估计的手势分类框架，用于自动驾驶车辆理解行人手势，在真实交通视频上实现87%的分类准确率

- Motivation: 手势是交通中非语言交流的关键组成部分，有助于行人与驾驶员互动，但自动驾驶车辆难以解释这些手势，需要专门的手势识别系统来改善AV系统的感知能力
- Method: 使用2D姿态估计处理WIVW数据集的真实世界视频序列，将手势分为四类（停止、前进、感谢问候、无手势），从归一化的关键点提取76个静态和动态特征
- Result: 分析显示手部位置和运动速度对区分手势类别特别有效，分类准确率达到87%，显著提升了自动驾驶系统的感知能力
- Conclusion: 该框架不仅提高了自动驾驶系统的手势理解能力，还为更广泛地理解交通场景中的行人行为做出了贡献


### [155] [Enhanced Food Category Recognition under Illumination-Induced Domain Shift](https://arxiv.org/abs/2602.08491)
*Keonvin Park,Aditya Pal,Jin Hong Mok*

Main category: cs.CV

TL;DR: 该研究探讨了光照变化对多类别食物识别系统的影响，通过合成光照增强数据集和跨数据集评估，提出了提升光照鲁棒性的方法。

- Motivation: 现实世界中的视觉食物识别系统（如自动传送带检测）对光照变化引起的域偏移非常敏感。现有研究通常局限于单一食物类别或受控环境，且大多数公共食物数据集缺乏明确的光照标注，因此需要研究光照引起的域偏移问题。
- Method: 使用Food-101和Fruits-360两个广泛采用的数据集，通过系统变化光温和强度构建合成光照增强数据集，进行跨数据集评估、迁移学习和域泛化研究，特别关注苹果类等光照敏感目标类别。
- Result: 实验结果显示，在跨数据集评估中由于视觉条件不匹配导致准确率显著下降，而光照感知的数据增强显著提高了域偏移下的识别鲁棒性，同时保持了实时性能。
- Conclusion: 光照鲁棒性对于在现实世界检测场景中部署可靠的食物识别系统至关重要，光照感知的数据增强提供了实用的解决方案，能够显著提升系统在光照变化下的性能。


### [156] [Learning Self-Correction in Vision-Language Models via Rollout Augmentation](https://arxiv.org/abs/2602.08503)
*Yi Ding,Ziliang Qiu,Bolian Li,Ruqi Zhang*

Main category: cs.CV

TL;DR: Octopus框架通过重组现有rollouts合成密集的自校正示例，解决RL中自校正行为稀疏的问题，并引入响应掩码策略解耦自校正与直接推理，实现了可控自校正的VLM模型。

- Motivation: 现有强化学习方法在视觉语言模型中学习自校正行为时面临挑战，因为有效的自校正行为出现频率极低，导致学习信号极其稀疏，难以有效学习。
- Method: 提出correction-specific rollouts (Octopus)框架：1）通过重组现有rollouts合成密集的自校正示例；2）引入响应掩码策略，解耦自校正与直接推理；3）基于此构建Octopus-8B模型，具备可控自校正能力。
- Result: 在7个基准测试中，Octopus-8B在开源VLM中达到最先进性能，比最佳RLVR基线提高1.0分，同时每个训练步骤仅需0.72倍的时间。
- Conclusion: Octopus框架通过rollout重组和响应掩码策略，有效解决了自校正学习中的稀疏信号问题，实现了高效可控的自校正能力，为复杂推理问题提供了新的解决方案。


### [157] [Are Vision Foundation Models Foundational for Electron Microscopy Image Segmentation?](https://arxiv.org/abs/2602.08505)
*Caterina Fuster-Barceló,Virginie Uhlmann*

Main category: cs.CV

TL;DR: 研究评估了视觉基础模型在生物医学图像分析中的迁移能力，发现虽然单个电子显微镜数据集上能获得良好分割性能，但跨异构数据集训练会导致性能显著下降，当前参数高效微调策略不足以实现跨域鲁棒模型。

- Motivation: 尽管视觉基础模型越来越多地用于生物医学图像分析，但尚不清楚其潜在表示是否足够通用，能够有效支持跨异构显微镜图像数据集的迁移和重用。本研究针对电子显微镜图像中的线粒体分割问题，探究这一关键问题。
- Method: 使用两个公共电子显微镜数据集（Lucchi++和VNC）和三个代表性视觉基础模型（DINOv2、DINOv3和OpenCLIP）。评估两种实际模型适应机制：冻结骨干网络仅训练轻量分割头，以及通过低秩适应的参数高效微调。采用多种技术（PCA、Fréchet Dinov2距离、线性探针）探索潜在表示空间。
- Result: 在所有骨干网络上，单个EM数据集训练可获得良好分割性能（前景交并比），LoRA持续提升域内性能。然而，跨多个EM数据集训练会导致所有模型性能显著下降，PEFT仅带来边际改善。潜在表示空间分析显示两个EM数据集间存在显著且持续的域不匹配，尽管它们视觉相似。
- Conclusion: 视觉基础模型在轻量适应下可在单个域内为EM分割提供有竞争力的结果，但当前PEFT策略不足以获得跨异构EM数据集的单一鲁棒模型，需要额外的域对齐机制。


### [158] [GeoFocus: Blending Efficient Global-to-Local Perception for Multimodal Geometry Problem-Solving](https://arxiv.org/abs/2602.08524)
*Linger Deng,Yuliang Liu,Wenwen Yu,Zujia Zhang,Jianzhong Ju,Zhenbo Luo,Xiang Bai*

Main category: cs.CV

TL;DR: GeoFocus是一个解决几何问题的多模态模型框架，通过关键局部感知器和VertexLang拓扑语言，显著提升几何问题求解能力。

- Motivation: 几何问题求解对大型多模态模型具有挑战性，需要全局形状识别和关注与几何理论相关的复杂局部关系。现有方法在局部特征覆盖和全局拓扑表示方面存在不足。
- Method: 提出GeoFocus框架，包含两个核心模块：1) 关键局部感知器，通过13个基于理论的感知模板自动识别和强调关键局部结构；2) VertexLang，一种紧凑的拓扑形式语言，通过顶点坐标和连接关系编码全局图形。
- Result: 在Geo3K、GeoQA和FormalGeo7K数据集上，GeoFocus比领先的专用模型准确率提升4.7%；关键局部特征覆盖比先前方法提高61%；全局感知训练时间减少20%同时提升拓扑识别准确率；在MATHVERSE中表现出优越的鲁棒性。
- Conclusion: GeoFocus通过结合理论驱动的局部感知和紧凑的拓扑表示，显著提升了多模态模型在几何问题求解中的性能，为几何推理提供了有效的解决方案。


### [159] [Automatic regularization parameter choice for tomography using a double model approach](https://arxiv.org/abs/2602.08528)
*Chuyang Wu,Samuli Siltanen*

Main category: cs.CV

TL;DR: 提出一种基于双网格离散化的自动正则化参数选择方法，通过反馈控制算法动态调整参数，使两个网格上的重建结果达到足够相似度

- Motivation: X射线断层扫描重建是病态逆问题，特别是在数据有限的情况下。正则化至关重要，但其效果取决于正则化参数的选择，需要在数据保真度和先验信息之间取得平衡。传统参数选择方法通常需要手动调整或复杂的计算。
- Method: 提出基于两个不同计算离散化的自动参数选择方法：使用反馈控制算法动态调整正则化强度，驱动迭代重建过程，寻找能使两个网格上重建结果达到足够相似度的最小参数值。
- Result: 该方法在实际断层扫描数据上证明了有效性，能够自动选择适当的正则化参数，改善重建质量。
- Conclusion: 提出的双网格离散化方法为X射线断层扫描中的正则化参数选择提供了一种有效的自动化解决方案，减少了手动调参的需求，提高了重建的可靠性和效率。


### [160] [Thegra: Graph-based SLAM for Thermal Imagery](https://arxiv.org/abs/2602.08531)
*Anastasiia Kornilova,Ivan Moskalenko,Arabella Gromova,Gonzalo Ferrer,Alexander Menshchikov*

Main category: cs.CV

TL;DR: 提出一种基于稀疏单目图的热成像SLAM系统，利用在可见光谱数据上训练的通用学习特征（SuperPoint检测器和LightGlue匹配器），通过预处理增强热数据适应性，并引入置信度加权因子图提高鲁棒性。

- Motivation: 热成像在视觉退化环境（如低光照、烟雾、恶劣天气）中为视觉SLAM提供了实用的感知方式，但热图像通常具有低纹理、低对比度和高噪声的特点，这使得基于特征的SLAM变得复杂。
- Method: 1. 使用在可见光谱数据上训练的SuperPoint检测器和LightGlue匹配器作为通用学习特征；2. 引入预处理流程增强热数据输入适应性；3. 修改核心SLAM模块以处理稀疏和异常值较多的特征匹配；4. 将SuperPoint的关键点置信度分数整合到置信度加权因子图中。
- Result: 在公开热成像数据集上的评估表明，所提出的系统实现了可靠的性能，无需特定数据集的训练或微调特征检测器，解决了高质量热数据稀缺的问题。
- Conclusion: 该系统展示了利用可见光谱训练的通用学习特征进行热成像SLAM的可行性，通过预处理和置信度加权机制有效应对热图像的挑战，为视觉退化环境下的SLAM提供了实用解决方案。


### [161] [TIBR4D: Tracing-Guided Iterative Boundary Refinement for Efficient 4D Gaussian Segmentation](https://arxiv.org/abs/2602.08540)
*He Wu,Xia Yan,Yanghui Xu,Liegang Xia,Jiazhou Chen*

Main category: cs.CV

TL;DR: 提出TIBR4D框架，通过两阶段迭代边界精化实现动态4D高斯场景的高效无学习对象分割

- Motivation: 动态4D高斯场景中的对象级分割面临复杂运动、遮挡和模糊边界的挑战，现有方法难以处理这些问题
- Method: 提出两阶段迭代边界精化框架：1) IGIT阶段通过迭代追踪精化高斯-实例概率，提取更完整的对象点云；2) RCC阶段通过抑制边界附近不确定高斯来获得更准确边界；同时提出时间分割合并策略平衡身份一致性和动态感知
- Result: 在HyperNeRF和Neu3D数据集上实验表明，相比SOTA方法，该方法能生成边界更清晰、更准确的对象高斯点云，且效率更高
- Conclusion: TIBR4D框架通过两阶段边界精化和时间分割策略，有效解决了动态4D高斯场景中的对象分割问题，在准确性和效率上均优于现有方法


### [162] [GOT-Edit: Geometry-Aware Generic Object Tracking via Online Model Editing](https://arxiv.org/abs/2602.08550)
*Shih-Fang Chen,Jun-Cheng Chen,I-Hong Jhuo,Yen-Yu Lin*

Main category: cs.CV

TL;DR: GOT-Edit：一种在线跨模态模型编辑方法，通过将几何感知线索整合到通用目标跟踪器中，结合2D语义和3D几何推理，显著提升跟踪性能

- Motivation: 人类感知利用先验3D知识和语义推理进行有效目标跟踪，而现有通用目标跟踪方法主要依赖2D特征，忽略了3D几何线索，导致对部分遮挡、干扰物以及几何和外观变化的鲁棒性不足
- Method: 提出GOT-Edit在线跨模态模型编辑方法：1）利用预训练的视觉几何基础Transformer从少量2D图像推断几何线索；2）通过零空间约束更新进行在线模型编辑，在保持语义区分能力的同时整合几何信息
- Result: 在多个通用目标跟踪基准测试中，GOT-Edit展现出优越的鲁棒性和准确性，特别是在遮挡和杂乱场景下表现突出，为结合2D语义和3D几何推理建立了新范式
- Conclusion: 通过将几何感知线索整合到通用目标跟踪器中，GOT-Edit成功解决了现有方法忽略3D几何信息的问题，在保持语义区分能力的同时显著提升了跟踪性能，特别是在挑战性场景下


### [163] [FLAG-4D: Flow-Guided Local-Global Dual-Deformation Model for 4D Reconstruction](https://arxiv.org/abs/2602.08558)
*Guan Yuan Tan,Ngoc Tuan Vu,Arghya Pal,Sailaja Rajanala,Raphael Phan C. -W.,Mettu Srinivas,Chee-Ming Ting*

Main category: cs.CV

TL;DR: FLAG-4D是一个用于动态场景新视角生成的框架，通过双变形网络建模3D高斯原语在时空中的演化，结合瞬时变形网络和全局运动网络，并利用预训练光流特征确保时空一致性。

- Motivation: 现有方法通常使用单个MLP建模时间变形，难以捕捉复杂的点运动和细粒度动态细节，特别是在稀疏输入视角下。需要一种能更准确建模时空变形并保持时间一致性的方法。
- Method: 采用双变形网络动态扭曲规范3D高斯集：瞬时变形网络(IDN)建模细粒度局部变形，全局运动网络(GMN)捕捉长程动态，通过互学习进行精炼。结合预训练光流骨干的密集运动特征，使用变形引导注意力机制对齐光流信息与3D高斯状态。
- Result: 实验表明FLAG-4D相比现有方法实现了更高保真度、更时间一致的重建，能更好地保留细节。
- Conclusion: FLAG-4D通过双变形网络和光流特征融合，有效解决了动态场景建模中复杂运动和细粒度细节的挑战，实现了高质量的时空一致新视角生成。


### [164] [SemiNFT: Learning to Transfer Presets from Imitation to Appreciation via Hybrid-Sample Reinforcement Learning](https://arxiv.org/abs/2602.08582)
*Melany Yang,Yuhang Yu,Diwang Weng,Jinwei Chen,Wei Dong*

Main category: cs.CV

TL;DR: SemiNFT是一个基于扩散Transformer的调色框架，模仿人类艺术训练过程：从刚性模仿到直觉创作，通过配对数据学习和强化学习实现语义感知的调色

- Motivation: 现有基于参考的调色方法通常只进行全局颜色映射，缺乏对语义上下文和人类美学的真正理解，无法像专业艺术家那样进行智能调色
- Method: 采用两阶段训练：1）使用配对三元组学习基本结构保持和颜色映射技能；2）在无配对数据上进行强化学习培养细腻美学感知，设计混合在线-离线奖励机制防止灾难性遗忘
- Result: 在标准预设转移基准测试中优于现有方法，在零样本任务（如黑白照片着色和跨域预设转移）中表现出色，证明超越了简单的统计匹配
- Conclusion: SemiNFT通过模仿人类艺术训练轨迹，实现了对美学理解的复杂层次，超越了传统统计匹配方法，在调色任务中展现出智能的语义感知能力


### [165] [Overview and Comparison of AVS Point Cloud Compression Standard](https://arxiv.org/abs/2602.08613)
*Wei Gao,Wenxu Gao,Xingming Mu,Changhao Peng,Ge Li*

Main category: cs.CV

TL;DR: 本文综述了中国AVS PCC点云压缩标准，从技术和性能比较两个角度分析了该标准的特点和优势。

- Motivation: 点云数据量大，传输和存储面临挑战，需要高效的压缩技术。虽然MPEG已有G-PCC和V-PCC标准，但中国AVS工作组开发了新一代点云压缩标准AVS PCC，采用了许多新的编码工具和技术。
- Method: 从两个视角综述AVS PCC标准：1) 相关技术分析，介绍标准采用的新编码工具和技术；2) 性能比较，与其他标准（如MPEG的G-PCC和V-PCC）进行对比分析。
- Result: AVS PCC标准采用了与MPEG标准不同的新编码工具和技术，在点云压缩方面展现出独特的性能特点。
- Conclusion: AVS PCC作为中国自主开发的点云压缩标准，通过采用创新技术，为点云压缩提供了新的解决方案，对推动点云技术在实际应用中的部署具有重要意义。


### [166] [Inspiration Seeds: Learning Non-Literal Visual Combinations for Generative Exploration](https://arxiv.org/abs/2602.08615)
*Kfir Goldberg,Elad Richardson,Yael Vinker*

Main category: cs.CV

TL;DR: 提出Inspiration Seeds框架，将图像生成从最终执行转向探索性构思，通过视觉方式连接输入图像，无需文本提示

- Motivation: 现有生成模型主要针对精心设计的文本提示进行优化，缺乏对开放式视觉探索的支持，而设计师通常从松散连接的视觉参考中寻找灵感，寻求激发新想法的涌现性连接
- Method: 使用前馈模型，在合成三元组上训练，通过CLIP稀疏自编码器提取CLIP潜在空间中的编辑方向，完全通过视觉方式分解视觉方面并隔离概念对
- Result: 模型能够给定两个输入图像，生成多样化、视觉连贯的组合，揭示输入之间的潜在关系，无需依赖用户指定的文本提示
- Conclusion: 通过消除对语言的依赖并实现快速直观的重组，该方法支持创意工作早期和模糊阶段的视觉构思


### [167] [Improving Reconstruction of Representation Autoencoder](https://arxiv.org/abs/2602.08620)
*Siyu Liu,Chujie Qin,Hubery Yin,Qixin Yan,Zheng-Peng Duan,Chen Li,Jing Lyu,Chun-Le Guo,Chongyi Li*

Main category: cs.CV

TL;DR: LV-RAE是一种表示自编码器，通过增强语义特征的低级信息来提升潜在扩散模型的生成质量，同时保持语义对齐。

- Motivation: 现有视觉基础模型作为图像编码器虽然提升了潜在扩散模型的生成性能，但其语义特征缺乏低级信息（如颜色和纹理），导致重建保真度下降，成为进一步扩展LDMs的主要瓶颈。
- Method: 提出LV-RAE表示自编码器，通过增强语义特征的低级信息实现高保真重建；同时通过微调解码器增强鲁棒性，并通过受控噪声注入平滑生成潜在表示。
- Result: 实验表明LV-RAE显著提高了重建保真度，同时保持了语义抽象能力，并实现了强大的生成质量。
- Conclusion: LV-RAE通过解决语义特征缺乏低级信息的问题，有效提升了潜在扩散模型的生成性能，为LDMs的进一步扩展提供了有效解决方案。


### [168] [Revisiting [CLS] and Patch Token Interaction in Vision Transformers](https://arxiv.org/abs/2602.08626)
*Alexis Marouani,Oriane Siméoni,Hervé Jégou,Piotr Bojanowski,Huy V. Vo*

Main category: cs.CV

TL;DR: 论文提出通过专门处理路径分离CLS类token和patch token的计算流，特别在归一化层和早期QKV投影中，显著提升密集预测任务的性能。

- Motivation: Vision Transformers中，可学习的[CLS]类token和patch token虽然性质不同，但在整个模型中却以相同方式处理。作者研究了不同预训练策略下全局和局部特征学习之间的摩擦，发现标准归一化层在这两种token类型之间引入了隐式区分。
- Method: 基于分析发现，提出专门的处理路径，选择性地解耦类token和patch token的计算流，特别是在归一化层和早期查询-键-值投影中。这种针对性专门化显著提升了patch表示质量。
- Result: 实验显示在标准基准测试中分割性能提升超过2 mIoU点，同时保持强分类准确率。提出的修改仅增加8%的参数，没有额外计算开销。通过全面消融研究，提供了哪些架构组件从专门化中获益最多以及该方法如何在不同模型规模和学框架中泛化的见解。
- Conclusion: 通过专门处理类token和patch token，特别是解耦它们在归一化层和早期QKV投影中的计算流，可以显著提升Vision Transformers在密集预测任务中的性能，同时保持分类能力，且计算开销极小。


### [169] [Deep Learning-Based Fixation Type Prediction for Quality Assurance in Digital Pathology](https://arxiv.org/abs/2602.08652)
*Oskar Thaeter,Tanja Niedermair,Johannes Raffler,Ralf Huss,Peter J. Schüffler*

Main category: cs.CV

TL;DR: 提出基于深度学习模型，使用低分辨率预扫描缩略图预测病理切片固定类型，实现高效质量控制

- Motivation: 病理切片固定类型（FFPE/FS）的手动标注容易出错，影响下游分析和诊断准确性。现有方法需要全分辨率WSI，限制了高通量质量控制的扩展性
- Method: 开发深度学习模型，使用低分辨率预扫描缩略图像预测固定类型。在TUM病理研究所的WSI上训练（n=1,200），在TCGA、奥格斯堡和雷根斯堡数据集上评估
- Result: 模型在TCGA上AUROC达到0.88，比同类预扫描方法提升4.8%；在雷根斯堡和奥格斯堡数据集上AUROC为0.72。处理每张切片仅需21毫秒，比现有高倍率全分辨率方法快400倍
- Conclusion: 该方法为检测标注错误提供了高效解决方案，无需依赖高倍率扫描，是病理高通量工作流程中有价值的质量控制工具。未来将改进模型对不同扫描仪类型的泛化能力


### [170] [WiFlow: A Lightweight WiFi-based Continuous Human Pose Estimation Network with Spatio-Temporal Feature Decoupling](https://arxiv.org/abs/2602.08661)
*Yi Dao,Lankai Zhang,Hao Liu,Haiwei Zhang,Wenbo Wang*

Main category: cs.CV

TL;DR: WiFlow是一个基于WiFi信号的连续人体姿态估计框架，采用编码器-解码器架构，在自收集数据集上达到97.00% PCK@20和99.48% PCK@50的精度，模型参数仅4.82M，显著降低了计算复杂度。

- Motivation: 人体姿态估计是物联网智能感知的基础，但现有WiFi方法在连续运动和高计算开销方面存在不足。传统视觉方法将CSI视为图像处理，未能充分利用信号的原始序列结构。
- Method: 提出WiFlow框架，采用编码器-解码器架构。编码器使用时序和非对称卷积捕捉CSI的时空特征，保持信号原始序列结构；通过轴向注意力机制精炼人体关键点特征并捕捉结构依赖关系；解码器将编码的高维特征映射为关键点坐标。
- Result: 在5名受试者执行8种日常活动的360,000个同步CSI-姿态样本数据集上，WiFlow达到PCK@20为97.00%，PCK@50为99.48%，平均关节位置误差0.008m。模型参数仅4.82M，显著降低了计算复杂度。
- Conclusion: WiFlow为实用的WiFi人体姿态估计建立了新的性能基准，通过保持信号原始序列结构和降低模型复杂度，实现了高精度、低计算开销的连续姿态估计。


### [171] [A Machine Learning accelerated geophysical fluid solver](https://arxiv.org/abs/2602.08670)
*Yang Bai*

Main category: cs.CV

TL;DR: 该论文研究如何将机器学习应用于求解偏微分方程，特别是通过数据驱动的离散化方法改进结构化网格上的传统PDE求解器，并在浅水方程和欧拉方程上验证了ML求解器的有效性。

- Motivation: 机器学习在图像分类和自然语言处理等领域取得了成功，但如何将其应用于具有数学约束的领域（如求解偏微分方程）仍是一个待解决的问题。传统数值方法在低分辨率模拟中存在精度和稳定性限制，需要探索ML方法来加速和改进现有PDE求解器。
- Method: 采用数据驱动的离散化方法，在结构化网格上预测准线性模板的系数，用于计算给定位置处的函数值或导数值。实现了浅水方程和欧拉方程的传统求解器，并提出了四种不同的深度神经网络架构用于ML求解器。
- Result: 实验表明，传统求解器性能优于Pyclaw求解器。在提出的四种ML求解器中，有两种方法能够输出令人满意的解，验证了ML方法在改进PDE求解精度和稳定性方面的潜力。
- Conclusion: 数据驱动的离散化方法为将机器学习应用于偏微分方程求解提供了有前景的途径，能够结合传统数值方法的优势（如守恒律），在低分辨率模拟中实现比传统有限差分或有限体积格式更好的精度和稳定性。


### [172] [ALIVE: Animate Your World with Lifelike Audio-Video Generation](https://arxiv.org/abs/2602.08682)
*Ying Guo,Qijun Gan,Yifu Zhang,Jinlai Liu,Yifei Hu,Pan Xie,Dongjun Qian,Yu Zhang,Ruiqi Li,Yuqi Zhang,Ruibiao Lu,Xiaofeng Mei,Bo Han,Xiang Yin,Bingyue Peng,Zehuan Yuan*

Main category: cs.CV

TL;DR: ALIVE是一个音频-视频生成模型，通过改造预训练的文本到视频模型，实现了类似Sora的音频视频生成和动画功能，在音频视觉同步和参考动画方面表现出色。

- Motivation: 视频生成正快速向统一的音频-视频生成发展，需要将现有的文本到视频模型扩展到支持音频视频同步生成和参考动画的能力。
- Method: 1) 在MMDiT架构基础上增加联合音频-视频分支，包含TA-CrossAttn用于时间对齐的跨模态融合和UniTemp-RoPE用于精确的音频视觉对齐；2) 设计全面的数据管道进行高质量微调数据收集；3) 引入新的基准测试进行模型评估。
- Result: 在百万级别高质量数据上进行持续预训练和微调后，ALIVE表现出色，一致优于开源模型，匹配或超越最先进的商业解决方案。
- Conclusion: ALIVE通过详细的方法和基准测试，帮助社区更高效地开发音频-视频生成模型，推动了统一音频视频生成的发展。


### [173] [OneVision-Encoder: Codec-Aligned Sparsity as a Foundational Principle for Multimodal Intelligence](https://arxiv.org/abs/2602.08683)
*Feilong Tang,Xiang An,Yunyao Yan,Yin Xie,Bin Qin,Kaicheng Yang,Yifei Shen,Yuanhan Zhang,Chunyuan Li,Shikun Feng,Changrui Chen,Huajie Tan,Ming Hu,Manyuan Zhang,Bo Li,Ziyong Feng,Ziwei Liu,Zongyuan Ge,Jiankang Deng*

Main category: cs.CV

TL;DR: 论文提出OneVision-Encoder，一种基于信息论压缩原理的视频编码架构，通过关注信号熵丰富的稀疏区域（3.1%-25%），在减少计算量的同时提升视觉理解性能。

- Motivation: 现代视觉架构偏离了信息论基本原则：视觉信号高度冗余，而判别信息稀疏。当前模型均匀处理密集像素网格，浪费大量计算在静态背景而非定义运动和意义的预测残差上。需要将架构与视频的信息论原理（编解码器）对齐。
- Method: 采用Codec Patchification技术，放弃均匀计算，专注于信号熵丰富的区域（3.1%-25%）。使用共享3D RoPE统一空间和时间推理，通过大规模聚类判别目标在超过100万个语义概念上进行训练，联合捕捉物体持久性和运动动态。
- Result: 在16个图像、视频和文档理解基准测试中，OV-Encoder持续优于Qwen3-ViT和SigLIP2等强视觉骨干网络，尽管使用更少的视觉token和预训练数据。在视频理解任务上，平均比Qwen3-ViT提升4.1%。
- Conclusion: 效率和准确性不是权衡关系，而是正相关的。编解码器对齐的补丁级稀疏性是基础原则，使OV-Encoder成为下一代视觉通用模型的可扩展引擎。


### [174] [Low-Light Video Enhancement with An Effective Spatial-Temporal Decomposition Paradigm](https://arxiv.org/abs/2602.08699)
*Xiaogang Xu,Kun Zhou,Tao Hu,Jiafei Wu,Ruixing Wang,Hao Peng,Bei Yu*

Main category: cs.CV

TL;DR: 提出VLLVE和VLLVE++框架，通过视图无关和视图相关分量分解策略增强低光视频，引入残差项和双向学习机制提升性能。

- Motivation: 低光视频增强面临严重不可见性和噪声问题，现有方法难以处理动态场景和复杂退化。需要一种能够分解视频内容、保持一致性并处理场景自适应退化的框架。
- Method: 1. VLLVE：视图无关分量（捕捉内在外观）使用动态跨帧对应关系，视图相关分量（描述光照条件）施加场景级连续性约束。2. 双结构增强网络：跨帧交互机制监督不同帧获得匹配分解特征。3. VLLVE++：引入加性残差项模拟场景自适应退化，支持增强和退化感知对应关系细化的双向学习。
- Result: 在广泛认可的低光视频增强基准测试上进行大量实验，VLLVE++在处理真实世界场景和高动态视频等挑战性案例时表现出强大能力。
- Conclusion: 提出的视频分解策略和框架有效提升了低光视频增强性能，特别是通过残差项和双向学习机制，能够更好地处理复杂场景和动态内容。


### [175] [TimeChat-Captioner: Scripting Multi-Scene Videos with Time-Aware and Structural Audio-Visual Captions](https://arxiv.org/abs/2602.08711)
*Linli Yao,Yuancheng Wei,Yaojie Zhang,Lei Li,Xinlong Chen,Feifan Song,Ziyue Wang,Kun Ouyang,Yuanxin Liu,Lingpeng Kong,Qi Liu,Pengfei Wan,Kun Gai,Yuanxing Zhang,Xu Sun*

Main category: cs.CV

TL;DR: 提出Omni Dense Captioning新任务，构建高质量基准数据集OmniDCBench和训练数据集TimeChatCap-42K，开发TimeChat-Captioner-7B模型，在密集描述生成和下游任务上取得SOTA性能。

- Motivation: 现有视频描述任务通常生成简短、概括性的描述，缺乏连续、细粒度、结构化的视听叙事。需要一种能够生成类似电影剧本的详细描述，让读者能够逐场景生动想象视频内容。
- Method: 1) 提出六维结构模式创建"脚本式"描述；2) 构建高质量人工标注基准OmniDCBench；3) 提出SodaM评估指标；4) 构建训练数据集TimeChatCap-42K；5) 开发TimeChat-Captioner-7B模型，使用SFT和GRPO训练。
- Result: TimeChat-Captioner-7B在密集描述生成上超越Gemini-2.5-Pro达到SOTA，其生成的密集描述显著提升视听推理（DailyOmni和WorldSense）和时间定位（Charades-STA）等下游任务能力。
- Conclusion: Omni Dense Captioning是一个有前景的新任务，提出的基准、指标和模型为连续、细粒度、结构化的视听叙事生成提供了有效解决方案，具有实际应用价值。


### [176] [Towards Understanding Multimodal Fine-Tuning: Spatial Features](https://arxiv.org/abs/2602.08713)
*Lachin Naghashyar,Hunar Batra,Ashkan Khakzar,Philip Torr,Ronald Clark,Christian Schroeder de Witt,Constantin Venhoff*

Main category: cs.CV

TL;DR: 该论文提出了首个视觉语言模型(VLM)适应过程的机制分析，通过阶段式模型差异技术揭示语言模型如何学习"看"的能力，识别出在微调过程中出现或重新定向的视觉偏好特征，并追踪这些特征到特定注意力头。

- Motivation: 尽管当代视觉语言模型在各种任务上表现出色，但语言主干网络在多模态训练中如何适应以及视觉特定能力何时出现仍不清楚。需要理解预训练语言模型如何获得视觉基础能力的内在机制。
- Method: 使用阶段式模型差异技术，该方法能够隔离多模态微调过程中引入的表征变化。通过识别视觉偏好特征，分析这些特征如何编码空间关系，并追踪这些特征的因果激活到特定的注意力头。
- Result: 研究发现：1) 识别出在微调过程中出现或重新定向的视觉偏好特征；2) 这些特征的一个选择性子集能够可靠地编码空间关系；3) 这些特征的因果激活可追溯到一小群注意力头。
- Conclusion: 阶段式模型差异技术揭示了空间基础多模态特征何时何地出现，展示了视觉基础如何重塑原本仅用于文本的特征，增强了多模态训练的可解释性，为理解和改进预训练语言模型获取视觉基础能力提供了基础。


### [177] [Zero-shot System for Automatic Body Region Detection for Volumetric CT and MR Images](https://arxiv.org/abs/2602.08717)
*Farnaz Khun Jush,Grit Werner,Mark Klemens,Matthias Lenga*

Main category: cs.CV

TL;DR: 提出三种无需训练的零样本方法用于CT/MR图像体部区域检测，其中基于分割的规则方法表现最佳，在887个扫描上达到加权F1分数0.947(CT)和0.914(MR)。

- Motivation: 现有体部区域识别方法严重依赖不可靠的DICOM元数据，且主要使用监督学习，限制了在实际场景中的应用。需要探索零样本方法利用预训练基础模型的知识。
- Method: 提出三种无需训练的零样本流水线：1) 基于预训练多器官分割模型的规则系统；2) 放射科医生规则指导的多模态大语言模型(MLLM)；3) 结合视觉输入和解剖证据的分割感知MLLM。
- Result: 在887个CT和MR扫描上评估，基于分割的规则方法表现最佳且最稳定，加权F1分数为0.947(CT)和0.914(MR)，在不同模态和非典型扫描范围下均稳健。MLLM在视觉特征明显区域表现良好，但分割感知MLLM存在根本性限制。
- Conclusion: 基于分割的规则方法实现了可靠的零样本体部区域检测，证明了预训练基础模型知识的有效性，为医学影像工作流提供了不依赖DICOM元数据的解决方案。


### [178] [Rotated Lights for Consistent and Efficient 2D Gaussians Inverse Rendering](https://arxiv.org/abs/2602.08724)
*Geng Lin,Matthias Zwicker*

Main category: cs.CV

TL;DR: RotLight：通过旋转物体减少反渲染中的模糊性，结合代理网格提升反照率估计质量

- Motivation: 当前基于神经辐射场和高斯泼溅的反渲染方法在估计材质和光照时存在模糊性，导致反照率估计中出现不准确的颜色和烘焙阴影，尽管有正则化处理但仍存在问题。
- Method: 提出RotLight简单采集设置，要求物体在采集过程中旋转多次（最少两次）以减少模糊性；同时引入代理网格，支持精确入射光追踪、残差约束和改进全局光照处理。
- Result: 在合成和真实世界数据集上验证，该方法实现了更优的反照率估计，同时保持计算效率。
- Conclusion: RotLight通过简单的旋转采集设置和代理网格，有效解决了反渲染中的模糊性问题，提升了材质分解的准确性。


### [179] [FusionEdit: Semantic Fusion and Attention Modulation for Training-Free Image Editing](https://arxiv.org/abs/2602.08725)
*Yongwen Lai,Chaoqun Wang,Shaobo Min*

Main category: cs.CV

TL;DR: FusionEdit是一个无需训练的文本引导图像编辑框架，通过软掩码和注意力融合实现精确可控的编辑，避免硬掩码边界带来的伪影问题。

- Motivation: 现有文本引导图像编辑方法使用显式二进制掩码来约束编辑区域，但硬掩码边界会引入伪影并降低编辑能力。需要一种既能精确控制编辑区域，又能保持自然过渡的方法。
- Method: 1. 通过测量源提示词和目标提示词语义差异自动识别编辑和保留区域；2. 在区域边界进行距离感知的潜在融合生成软掩码，并使用总变差损失确保平滑过渡；3. 在DiT注意力层中采用AdaIN调制进行统计注意力融合，增强编辑能力同时保持全局一致性。
- Result: 大量实验表明，FusionEdit在文本引导图像编辑任务上显著优于现有最先进方法，能够实现更精确、更自然的编辑效果。
- Conclusion: FusionEdit通过软掩码生成和注意力融合机制，有效解决了硬掩码边界带来的伪影问题，实现了精确可控的图像编辑，同时保持了编辑结果的视觉自然性。


### [180] [SynSacc: A Blender-to-V2E Pipeline for Synthetic Neuromorphic Eye-Movement Data and Sim-to-Real Spiking Model Training](https://arxiv.org/abs/2602.08726)
*Khadija Iddrisu,Waseem Shariff,Suzanne Little,Noel OConnor*

Main category: cs.CV

TL;DR: 使用Blender生成合成事件相机数据集模拟眼动，结合脉冲神经网络实现高效的眼动分类，准确率达0.83，计算效率优于传统神经网络

- Motivation: 传统帧相机存在运动模糊问题，而事件相机（DVS）能异步记录光强变化，消除运动模糊并提供更高时间分辨率。需要准确分类眼动（扫视和注视）来理解人类认知机制，但缺乏合适的合成数据集。
- Method: 1. 使用Blender生成合成数据集模拟扫视和注视的受控条件；2. 采用脉冲神经网络（SNN）架构；3. 在真实事件数据上进行微调；4. 评估模型在不同时间分辨率下的鲁棒性。
- Result: 1. 模型准确率达到0.83；2. 在不同时间分辨率下保持稳定性能；3. 相比人工神经网络（ANN），SNN结合合成事件流带来显著计算效率提升；4. 证明了合成数据增强在事件视觉中的实用性。
- Conclusion: 合成数据集与脉冲神经网络的结合为眼动分类提供了有效解决方案，展示了事件相机在生物视觉研究中的潜力，同时开源代码和数据集促进该领域发展。


### [181] [Artifact Reduction in Undersampled 3D Cone-Beam CTs using a Hybrid 2D-3D CNN Framework](https://arxiv.org/abs/2602.08727)
*Johannes Thalhammer,Tina Dorosti,Sebastian Peterhansl,Daniela Pfeiffer,Franz Pfeiffer,Florian Schaff*

Main category: cs.CV

TL;DR: 提出一种结合2D和3D模型的混合深度学习框架，用于从欠采样CT体积中去除伪影，平衡计算效率与体积一致性。

- Motivation: 欠采样CT体积虽然减少了采集时间和辐射暴露，但会引入伪影，降低图像质量和诊断价值。需要高效去除这些伪影以获得高质量3D CT图像。
- Method: 采用两阶段混合框架：首先使用2D U-Net处理欠采样CT体积的单个切片提取特征图，然后将这些切片特征图堆叠成体积，输入到3D解码器中，利用切片间的上下文信息预测无伪影的3D CT体积。
- Result: 在冠状面和矢状面方向上显著改善了切片间一致性，同时保持了较低的计算开销。该框架为高质量3D CT图像后处理提供了鲁棒且高效的解决方案。
- Conclusion: 提出的混合深度学习框架成功平衡了2D处理的计算效率和3D建模的体积一致性，为欠采样CT体积的伪影去除提供了有效且实用的解决方案。


### [182] [Closing the Confusion Loop: CLIP-Guided Alignment for Source-Free Domain Adaptation](https://arxiv.org/abs/2602.08730)
*Shanshan Wang,Ziying Feng,Xiaozheng Shen,Xun Yang,Pichao Wang,Zhenwei He,Xingyi Zhang*

Main category: cs.CV

TL;DR: CGA提出了一种基于CLIP的源自由域自适应方法，通过建模和缓解类别混淆问题，在细粒度场景中显著提升性能。

- Motivation: 现有SFDA方法在细粒度场景中表现不佳，主要原因是忽略了类别间的不对称动态混淆模式，导致伪标签噪声大和目标判别性差。
- Method: 提出CLIP-Guided Alignment框架，包含三个模块：MCA检测混淆对，MCC利用CLIP构建混淆感知文本提示，FAM通过对比学习对齐特征空间以减少模糊性。
- Result: 在多个数据集上的实验表明，CGA在易混淆和细粒度场景中显著优于现有SFDA方法，验证了显式建模类别间混淆的重要性。
- Conclusion: 显式建模类别间混淆对有效的源自由域自适应至关重要，CGA通过CLIP引导的混淆缓解策略在细粒度场景中取得了显著改进。


### [183] [From Correspondence to Actions: Human-Like Multi-Image Spatial Reasoning in Multi-modal Large Language Models](https://arxiv.org/abs/2602.08735)
*Masanari Oi,Koki Maeda,Ryuto Koike,Daisuke Oba,Nakamasa Inoue,Naoaki Okazaki*

Main category: cs.CV

TL;DR: HATCH是一个训练框架，通过补丁级空间对齐和行动-答案推理两个互补目标，提升多模态大语言模型在多图像空间推理任务中的表现。

- Motivation: 现有MLLM在单图像空间推理上取得进展，但在需要整合多个视角信息的多图像空间推理上仍面临挑战。人类通过跨视角对应和逐步视角变换两种机制解决这类任务，但现有研究只部分且隐式地结合这些机制，缺乏对两者的显式监督。
- Method: 提出HATCH训练框架，包含两个互补目标：1) 补丁级空间对齐：鼓励不同视角中空间对应区域的补丁表示对齐；2) 行动-答案推理：要求模型在预测最终答案前生成显式的视角转换行动。
- Result: 在三个基准测试上，HATCH始终以明显优势超越同等规模基线模型，并与更大模型取得竞争性结果，同时保持单图像推理能力。
- Conclusion: 通过显式建模跨视角对应和逐步视角变换这两种人类认知机制，HATCH有效提升了多模态大语言模型在多图像空间推理任务中的性能。


### [184] [Shifting the Breaking Point of Flow Matching for Multi-Instance Editing](https://arxiv.org/abs/2602.08749)
*Carmine Zaccagnino,Fabio Quattrini,Enis Simsar,Marta Tintoré Gazulla,Rita Cucchiara,Alessio Tonioni,Silvia Cascianelli*

Main category: cs.CV

TL;DR: 提出Instance-Disentangled Attention机制，解决现有流匹配模型在多实例编辑中语义干扰的问题，实现单次推理的实例级编辑

- Motivation: 现有基于流的图像编辑器主要支持全局或单指令编辑，在多实例场景中难以独立编辑多个部分而不产生语义干扰，这源于全局条件化的速度场和联合注意力机制导致编辑纠缠
- Method: 引入Instance-Disentangled Attention机制，通过分割联合注意力操作，在速度场估计期间强制绑定实例特定的文本指令与空间区域
- Result: 实验结果表明，该方法在自然图像编辑和文本密集信息图编辑中都能促进编辑解耦和局部性，同时保持全局输出一致性
- Conclusion: 提出的方法能够实现单次推理的实例级编辑，解决了多实例编辑中的语义干扰问题


### [185] [MVAnimate: Enhancing Character Animation with Multi-View Optimization](https://arxiv.org/abs/2602.08753)
*Tianyu Sun,Zhoujie Fu,Bang Zhang,Guosheng Lin*

Main category: cs.CV

TL;DR: MVAnimate是一个利用多视角先验信息生成高质量2D和3D角色动画的新框架，解决了现有方法输出质量低和训练数据不足的问题。

- Motivation: 当前基于2D或3D人体姿态建模的动画生成算法存在输出质量低、训练数据不足等问题，无法生成高质量的动画视频。现实且多功能的角色动画需求在各个领域都在增长。
- Method: MVAnimate是一个新颖的框架，基于多视角先验信息合成动态人物的2D和3D信息。它利用多视角先验信息生成时间一致和空间连贯的动画输出，并优化目标角色的多视角视频，从不同视角提升视频质量。
- Result: 实验结果表明，该方法在多种数据集上表现出对各类运动模式和外观的鲁棒性，相比现有动画方法有所改进。
- Conclusion: MVAnimate通过整合多视角信息有效提升了动画生成质量，为高质量角色动画生成提供了新的解决方案。


### [186] [VedicTHG: Symbolic Vedic Computation for Low-Resource Talking-Head Generation in Educational Avatars](https://arxiv.org/abs/2602.08775)
*Vineet Kumar Rakesh,Ahana Bhattacharjee,Soumya Mazumdar,Tapas Samanta,Hemendra Kumar Pandey,Amitabha Das,Sarbajit Pal*

Main category: cs.CV

TL;DR: 提出一种基于符号吠陀计算的轻量级说话头像生成框架，可在CPU上实时运行，适用于资源受限的教育环境

- Motivation: 当前说话头像生成方法依赖GPU渲染、大训练集或高容量扩散模型，难以在离线或资源受限的学习环境中部署，需要一种轻量级CPU解决方案
- Method: 采用符号吠陀计算框架：1) 语音转时间对齐音素流 2) 音素映射到紧凑视素库 3) 基于吠陀经Urdhva Tiryakbhyam启发的符号协同发音生成平滑视素轨迹 4) 轻量2D渲染器进行ROI扭曲和嘴部合成稳定
- Result: 在仅CPU执行下实现了可接受的唇同步质量，显著降低计算负载和延迟，支持在低端硬件上部署实用的教育头像
- Conclusion: 符号吠陀计算方法为资源受限环境提供了可行的说话头像生成方案，平衡了质量与计算效率，支持教育技术中的离线部署


### [187] [Multimodal Learning for Arcing Detection in Pantograph-Catenary Systems](https://arxiv.org/abs/2602.08792)
*Hao Dong,Eleni Chatzi,Olga Fink*

Main category: cs.CV

TL;DR: 提出多模态框架结合视觉与力学数据，改进受电弓-接触网接口电弧检测，解决数据稀缺、噪声干扰等问题

- Motivation: 受电弓-接触网接口的电弧现象对铁路供电系统构成严重威胁，包括加速部件磨损、性能下降和服务中断。电弧检测面临瞬态特性、噪声环境、数据稀缺以及与其他瞬态现象难以区分等挑战。
- Method: 提出多模态框架结合高分辨率图像和力学测量数据。构建两个电弧检测数据集（SBB数据和公开视频+合成力学数据）。提出MultiDeepSAD算法，扩展DeepSAD以支持多模态，并引入新的损失函数。针对每种数据类型设计专门的伪异常生成技术，如图像中的合成电弧伪影和模拟力学异常，以增强训练数据。
- Result: 通过大量实验和消融研究，证明该框架显著优于基线方法，即使在领域偏移和真实电弧观测数据有限的情况下，对真实电弧事件也表现出增强的敏感性。
- Conclusion: 提出的多模态框架通过结合视觉和力学数据，有效解决了受电弓-接触网电弧检测的挑战，提高了检测准确性和鲁棒性，为铁路供电系统的可靠运行提供了有力支持。


### [188] [MOVA: Towards Scalable and Synchronized Video-Audio Generation](https://arxiv.org/abs/2602.08794)
*SII-OpenMOSS Team,:,Donghua Yu,Mingshu Chen,Qi Chen,Qi Luo,Qianyi Wu,Qinyuan Cheng,Ruixiao Li,Tianyi Liang,Wenbo Zhang,Wenming Tu,Xiangyu Peng,Yang Gao,Yanru Huo,Ying Zhu,Yinze Luo,Yiyang Zhang,Yuerong Song,Zhe Xu,Zhiyu Zhang,Chenchen Yang,Cheng Chang,Chushu Zhou,Hanfu Chen,Hongnan Ma,Jiaxi Li,Jingqi Tong,Junxi Liu,Ke Chen,Shimin Li,Songlin Wang,Wei Jiang,Zhaoye Fei,Zhiyuan Ning,Chunguo Li,Chenhui Li,Ziwei He,Zengfeng Huang,Xie Chen,Xipeng Qiu*

Main category: cs.CV

TL;DR: MOVA是一个开源的音频-视频联合生成模型，采用混合专家架构，支持图像/文本到视频/音频的生成任务，能够生成高质量、同步的视听内容。

- Motivation: 当前视频生成模型大多忽视音频组件，现有方法依赖级联管道导致成本高、误差累积和质量下降。现有系统如Veo 3和Sora 2虽然强调同时生成，但存在架构、数据和训练挑战，且闭源特性限制了领域进展。
- Method: 采用混合专家架构，总参数量320亿，推理时激活180亿参数。支持IT2VA任务，能够生成唇语同步的语音、环境感知音效和内容对齐的音乐。
- Result: 开发出能够生成高质量同步视听内容的开源模型，包括逼真的唇语同步语音、环境感知音效和内容对齐音乐。
- Conclusion: 通过发布模型权重和代码，旨在推动研究发展并培育创作者社区。代码库支持高效推理、LoRA微调和提示增强。


### [189] [Addressing data annotation scarcity in Brain Tumor Segmentation on 3D MRI scan Using a Semi-Supervised Teacher-Student Framework](https://arxiv.org/abs/2602.08797)
*Jiaming Liu,Cheng Ding,Daoqiang Zhang*

Main category: cs.CV

TL;DR: 提出半监督师生框架，结合不确定性感知伪标签教师和基于置信度的渐进课程学习，在有限标注下实现高效脑肿瘤分割

- Motivation: 脑肿瘤MRI分割面临标注成本高和数据异质性（不同扫描仪和站点）的挑战，需要开发在有限监督下鲁棒的分割方法
- Method: 1) 不确定性感知教师模型生成概率掩码和逐像素不确定性；2) 基于置信度的渐进课程：按图像级置信度对未标注扫描排序并分阶段引入；3) 双重损失目标：学生从高置信区域学习，从低置信区域"忘记"；4) 基于一致性的伪标签细化
- Result: 在BraTS 2021上：验证DSC从0.393（10%数据）提升到0.872（100%），早期阶段提升最大；教师DSC达0.922，学生在肿瘤亚区超越教师（NCR/NET 0.797，Edema 0.980），特别是在教师失败的增强类别上恢复DSC 0.620
- Conclusion: 置信度驱动的课程学习和选择性"忘记"机制能够在有限监督和噪声伪标签下提供鲁棒的分割性能，显著提高数据效率


### [190] [Omni-Video 2: Scaling MLLM-Conditioned Diffusion for Unified Video Generation and Editing](https://arxiv.org/abs/2602.08820)
*Hao Yang,Zhiyu Tan,Jia Gong,Luozheng Qin,Hesen Chen,Xiaomeng Yang,Yuqing Sun,Yuetan Lin,Mengping Yang,Hao Li*

Main category: cs.CV

TL;DR: Omni-Video 2是一个可扩展的高效视频生成编辑模型，通过连接预训练多模态大语言模型和视频扩散模型，利用MLLM的理解推理能力生成目标描述来指导生成过程，实现高质量视频生成和复杂编辑任务。

- Motivation: 现有视频生成和编辑模型在处理复杂组合指令时存在局限性，需要开发能够理解用户指令并执行精细编辑的统一模型。
- Method: 1. 利用预训练MLLM的理解推理能力生成显式目标描述来解释用户指令；2. 开发轻量级适配器将多模态条件标记注入预训练文本到视频扩散模型；3. 在精心策划的训练数据上扩展到14B参数规模。
- Result: 在FiVE基准测试中展示了处理复杂组合指令的卓越能力，在VBench基准测试中实现了竞争性或更优的视频生成质量，支持高质量文本到视频生成和多种编辑任务。
- Conclusion: Omni-Video 2通过连接MLLM理解和视频扩散生成能力，实现了参数高效、可扩展的统一视频生成编辑框架，在复杂编辑任务中表现出色。


### [191] [Any-to-All MRI Synthesis: A Unified Foundation Model for Nasopharyngeal Carcinoma and Its Downstream Applications](https://arxiv.org/abs/2602.08822)
*Yao Pu,Yiming Shi,Zhenxi Zhang,Peixin Yu,Yitao Zhuang,Xiang Wang,Hongzhao Chen,Jing Cai,Ge Ren*

Main category: cs.CV

TL;DR: 开发了一个统一的基础模型，通过对比视觉表示学习和视觉语言对齐，实现任意到所有MRI合成，提升鼻咽癌放疗规划准确性。

- Motivation: MRI对鼻咽癌放疗至关重要，但实际临床中常因患者不适、扫描时间长、成本高等因素导致模态不完整，影响放疗规划准确性。传统MRI合成方法存在模态特异性、解剖适应性有限、缺乏临床可解释性等问题，无法满足鼻咽癌放疗需求。
- Method: 开发统一基础模型，整合对比视觉表示学习和视觉语言对齐。使用对比编码器提取模态不变表示，基于CLIP的文本信息解码器进行语义一致的合成，通过一个统一模型支持任意到所有MRI合成。
- Result: 在13个机构的40,825张图像上训练，在26个内部/外部验证站点（15,748张图像）上实现一致高性能（平均SSIM 0.90，PSNR 27），具有优异的合成保真度以及对噪声和域偏移的鲁棒性。统一表示还增强了下游放疗相关任务（如分割）的性能。
- Conclusion: 这项工作通过利用基础模型桥接技术合成和临床实用性，推进了鼻咽癌护理的数字医学解决方案。模型为临床实践提供了更准确、鲁棒的MRI合成能力，支持更精准的放疗规划。


### [192] [VideoVeritas: AI-Generated Video Detection via Perception Pretext Reinforcement Learning](https://arxiv.org/abs/2602.08828)
*Hao Tan,Jun Lan,Senyuan Shi,Zichang Tan,Zijian Yu,Huijia Zhu,Weiqiang Wang,Jun Wan,Zhen Lei*

Main category: cs.CV

TL;DR: VideoVeritas框架通过联合偏好对齐和感知预文本强化学习，结合细粒度感知和事实推理来检测生成视频，在MintVid数据集上表现优于现有方法。

- Motivation: 视频生成能力增强带来安全风险，需要可靠的检测方法。现有多模态大语言模型推理能力强但细粒度感知能力有限。
- Method: 提出VideoVeritas框架，包含联合偏好对齐和感知预文本强化学习(PPRL)。通过时空定位和自监督物体计数等感知预任务增强检测性能，而非直接优化检测任务。
- Result: 在MintVid数据集(包含9个SOTA生成器的3K视频和真实世界错误内容子集)上测试，VideoVeritas在多样化基准上实现更平衡的性能，优于偏向表面推理或机械分析的现有方法。
- Conclusion: VideoVeritas通过结合细粒度感知和事实推理，为生成视频检测提供了更有效的解决方案，能够应对日益增长的视频生成安全风险。


### [193] [FlattenGPT: Depth Compression for Transformer with Layer Flattening](https://arxiv.org/abs/2602.08858)
*Ruihan Xu,Qingpei Guo,Yao Zhu,Xiangyang Ji,Ming Yang,Shiliang Zhang*

Main category: cs.CV

TL;DR: FlattenGPT是一种新颖的Transformer深度压缩方法，通过扁平化相邻块来减少深度冗余，同时保留所有块学到的知识，在保持性能的同时提升模型效率。

- Motivation: 现有深度压缩方法（整块剪枝）会丢弃块中有意义的线索导致性能下降，而通道剪枝虽然能更好保留性能但无法减少模型深度且面临各层剪枝比例不一致的挑战。需要一种既能压缩深度又能更好保留性能的方法。
- Method: 提出FlattenGPT方法，通过将两个相邻的Transformer块扁平化为一个块来压缩网络深度。这种方法能够更有效地检测和移除参数冗余，保留所有块学到的知识，同时保持与原始Transformer架构的一致性。
- Result: 在LLaMA-2/3和Qwen-1.5等模型上，FlattenGPT在20%压缩比下能保留90-96%的零样本性能。在零样本准确率和WikiText-2困惑度方面均优于现有剪枝方法，同时在加速LLM推理方面也表现更好。
- Conclusion: FlattenGPT通过扁平化相邻块实现了更好的深度压缩，在性能和效率之间取得了良好平衡，为提升Transformer效率提供了有前景的解决方案。


### [194] [TiFRe: Text-guided Video Frame Reduction for Efficient Video Multi-modal Large Language Models](https://arxiv.org/abs/2602.08861)
*Xiangtian Zheng,Zishuo Wang,Yuxin Peng*

Main category: cs.CV

TL;DR: TiFRe是一个文本引导的视频帧减少框架，通过智能帧采样和帧匹配合并机制，在降低计算成本的同时保持视频语义信息，提升视频多模态大语言模型的效率。

- Motivation: 视频多模态大语言模型在处理大量视频帧时面临高计算成本问题，特别是注意力计算开销巨大。传统的固定帧率关键帧选择方法会丢失非关键帧中的有价值信息，导致性能下降。
- Method: 提出TiFRe框架：1) 文本引导帧采样(TFS)：利用LLM生成CLIP风格提示，通过CLIP编码器计算提示与每帧的语义相似度，选择最相关的关键帧；2) 帧匹配合并(FMM)：将非关键帧信息整合到选定的关键帧中，最小化信息损失。
- Result: 实验表明TiFRe能有效降低计算成本，同时在视频语言任务上提升性能。
- Conclusion: TiFRe通过文本引导的智能帧选择和语义保留机制，解决了视频MLLMs的计算效率问题，在减少输入帧数的同时保持了视频理解能力。


### [195] [Analysis of Converged 3D Gaussian Splatting Solutions: Density Effects and Prediction Limit](https://arxiv.org/abs/2602.08909)
*Zhendong Wang,Cihan Ruan,Jingchuan Xiao,Chuqing Shi,Wei Jiang,Wei Wang,Wenjie Liu,Nam Ling*

Main category: cs.CV

TL;DR: 论文分析了3D高斯泼溅（3DGS）优化中出现的结构模式，称为渲染最优参考（RORs），揭示了其统计特性：混合结构尺度和双峰辐射分布。研究发现密度分层现象——密集区域参数可预测，稀疏区域需要多视角约束。

- Motivation: 研究标准多视角优化下3D高斯泼溅（3DGS）解决方案中自然出现的结构模式，理解这些模式的形成机制，以及如何利用这些理解改进训练鲁棒性和系统架构。
- Method: 1）分析3DGS优化产生的渲染最优参考（RORs）的统计特性；2）使用可学习性探针训练预测器从点云重建RORs；3）通过方差分解形式化分析密度分层现象；4）提出密度感知策略改进训练。
- Result: 发现RORs具有稳定的统计模式：混合结构尺度和双峰辐射分布。揭示了密度分层现象：密集区域参数与几何相关且可预测，稀疏区域参数受可见性异质性主导，需要多视角约束。提出了改进训练鲁棒性的策略。
- Conclusion: RORs具有双重特性：在密集区域表现为几何基元（点云足够），在稀疏区域表现为视图合成基元（需要多视角约束）。这为自适应平衡前馈预测和基于渲染优化的系统架构提供了理论基础。


### [196] [Grow with the Flow: 4D Reconstruction of Growing Plants with Gaussian Flow Fields](https://arxiv.org/abs/2602.08958)
*Weihan Luo,Lily Goli,Sherwin Bahmani,Felix Taubner,Andrea Tagliasacchi,David B. Lindell*

Main category: cs.CV

TL;DR: 提出了一种用于植物生长建模的3D高斯流场表示方法，通过时间变化的高斯参数导数来模拟非线性连续生长动态，优于现有方法。

- Motivation: 植物生长建模面临独特挑战：植物会随时间生成新几何结构，而现有动态场景建模技术（如变形场和4D高斯泼溅）无法处理这种几何生成问题。
- Method: 引入3D高斯流场表示，将植物生长建模为高斯参数（位置、尺度、方向、颜色、不透明度）的时间变化导数；通过重建成熟植物并学习反向生长过程来初始化高斯基元。
- Result: 在植物生长的多视角时间序列数据集上，该方法在图像质量和几何精度方面优于现有方法。
- Conclusion: 该方法为生长中的3D结构外观建模提供了新途径，能够有效模拟植物的非线性连续生长动态。


### [197] [MotionCrafter: Dense Geometry and Motion Reconstruction with a 4D VAE](https://arxiv.org/abs/2602.08961)
*Ruijie Zhu,Jiahao Lu,Wenbo Hu,Xiaoguang Han,Jianfei Cai,Ying Shan,Chuanxia Zheng*

Main category: cs.CV

TL;DR: MotionCrafter：基于视频扩散的框架，从单目视频联合重建4D几何并估计稠密运动，无需后优化即可实现最先进的性能。

- Motivation: 现有方法强制3D值和潜在空间与RGB VAE潜在空间严格对齐，尽管它们的分布根本不同，这导致次优性能。需要一种更好的方法来联合表示4D几何和运动。
- Method: 提出新颖的联合表示方法：在共享坐标系中表示稠密3D点图和3D场景流；开发新的4D VAE来有效学习这种表示；引入数据归一化和VAE训练策略，更好地传递扩散先验。
- Result: 在多个数据集上的实验表明，MotionCrafter在几何重建和稠密场景流估计方面都达到了最先进的性能，几何重建提升38.64%，运动重建提升25.0%，且无需任何后优化。
- Conclusion: MotionCrafter证明了强制3D值与RGB VAE潜在空间对齐是不必要的，通过新的联合表示和训练策略，可以显著提升4D重建质量，为单目视频的4D理解提供了有效解决方案。


### [198] [Modeling 3D Pedestrian-Vehicle Interactions for Vehicle-Conditioned Pose Forecasting](https://arxiv.org/abs/2602.08962)
*Guangxun Zhu,Xuan Liu,Nicolas Pugeault,Chongfeng Wei,Edmond S. L. Ho*

Main category: cs.CV

TL;DR: 提出一个3D车辆条件行人姿态预测框架，通过显式结合周围车辆信息来提升自动驾驶场景中的行人运动预测准确性。

- Motivation: 准确预测行人运动对于复杂城市环境中自动驾驶的安全性和可靠性至关重要。现有方法通常忽略车辆对行人行为的影响，需要显式建模行人-车辆交互。
- Method: 1. 增强Waymo-3DSkelMo数据集，添加对齐的3D车辆边界框；2. 提出采样方案按行人和车辆数量分类场景；3. 基于TBIFormer架构，添加专用车辆编码器和行人-车辆交互交叉注意力模块，融合行人和车辆特征。
- Result: 实验显示预测准确性显著提升，验证了不同行人-车辆交互建模方法的有效性，强调了车辆感知的3D姿态预测对自动驾驶的重要性。
- Conclusion: 提出的3D车辆条件行人姿态预测框架通过显式结合车辆信息，显著提升了行人运动预测的准确性，为自动驾驶系统提供了更可靠的行人行为理解能力。


### [199] [WorldArena: A Unified Benchmark for Evaluating Perception and Functional Utility of Embodied World Models](https://arxiv.org/abs/2602.08971)
*Yu Shang,Zhuohang Li,Yiding Ma,Weikang Su,Xin Jin,Ziyou Wang,Xin Zhang,Yinzhou Tang,Chen Gao,Wei Wu,Xihui Liu,Dhruv Shah,Zhaoxiang Zhang,Zhibo Chen,Jun Zhu,Yonghong Tian,Tat-Seng Chua,Wenwu Zhu,Yong Li*

Main category: cs.CV

TL;DR: WorldArena：首个统一评估具身世界模型的基准，同时衡量感知质量和功能效用，揭示感知与功能之间存在显著差距

- Motivation: 当前具身世界模型的评估主要关注感知保真度（如视频生成质量），忽视了这些模型在下游决策任务中的功能效用，评估体系碎片化
- Method: 提出WorldArena基准，从三个维度评估模型：视频感知质量（16个指标覆盖6个子维度）、具身任务功能（作为数据引擎、策略评估器和动作规划器），并引入EWMScore综合指标
- Result: 对14个代表性模型的实验揭示了显著的感知-功能差距：高视觉质量不一定转化为强大的具身任务能力
- Conclusion: WorldArena为追踪具身AI中真正功能性世界模型的进展提供了框架，公开排行榜已发布在https://worldarena.ai


### [200] [Generalizing Sports Feedback Generation by Watching Competitions and Reading Books: A Rock Climbing Case Study](https://arxiv.org/abs/2602.08996)
*Arushi Rai,Adriana Kovashka*

Main category: cs.CV

TL;DR: 提出利用辅助网络数据提升体育反馈生成性能，并设计新的评估指标解决传统指标不适用的问题

- Motivation: 现有视频-LLMs在体育反馈生成任务上表现不佳，需要昂贵的微调数据且泛化能力差；传统文本生成评估指标无法有效衡量体育反馈质量
- Method: 以攀岩为例，利用目标领域的免费网络数据（比赛视频和教练手册）以及源领域的现有体育反馈数据；提出特异性(specificity)和可操作性(actionability)两个新评估指标
- Result: 该方法能够在有限标注下实现更有意义和实用的体育反馈生成
- Conclusion: 通过利用辅助网络数据和设计针对性的评估指标，可以有效提升体育反馈生成的质量和实用性


### [201] [ArcFlow: Unleashing 2-Step Text-to-Image Generation via High-Precision Non-Linear Flow Distillation](https://arxiv.org/abs/2602.09014)
*Zihan Yang,Shuyuan Tu,Licheng Zhang,Qi Dai,Yu-Gang Jiang,Zuxuan Wu*

Main category: cs.CV

TL;DR: ArcFlow：一种使用非线性流轨迹逼近教师模型轨迹的少步蒸馏框架，仅需微调不到5%参数即可实现40倍加速且保持生成质量

- Motivation: 扩散模型虽然生成质量出色，但需要大量去噪步骤导致推理成本高。现有蒸馏方法使用线性捷径逼近教师轨迹，难以匹配随时间步变化的切线方向，导致质量下降。
- Method: 提出ArcFlow框架，将推理轨迹的底层速度场参数化为连续动量过程的混合，捕捉速度演化并外推连贯速度形成非线性轨迹。该参数化允许对非线性轨迹进行解析积分，避免数值离散误差。通过轻量适配器在预训练教师模型上进行轨迹蒸馏训练。
- Result: 在Qwen-Image-20B和FLUX.1-dev等大规模模型上，仅微调不到5%参数，使用2个NFE即可实现40倍加速，且无明显质量下降。基准测试显示ArcFlow在定性和定量上均有效。
- Conclusion: ArcFlow通过非线性流轨迹逼近教师轨迹，解决了现有线性蒸馏方法的局限性，实现了高效少步蒸馏，在保持生成质量的同时大幅提升推理速度。


### [202] [Raster2Seq: Polygon Sequence Generation for Floorplan Reconstruction](https://arxiv.org/abs/2602.09016)
*Hao Phung,Hadar Averbuch-Elor*

Main category: cs.CV

TL;DR: Raster2Seq：将楼层平面图重建视为序列到序列任务，通过自回归解码器预测多边形角点，在多个基准测试中达到SOTA性能

- Motivation: 现有技术难以从复杂楼层平面图图像中准确重建结构和语义，特别是对于包含大量房间和不同多边形角点数量的室内空间
- Method: 将楼层平面图重建框架化为序列到序列任务，使用自回归解码器学习在图像特征和先前生成角点条件下预测下一个角点，引入可学习锚点引导注意力机制聚焦信息丰富的图像区域
- Result: 在Structure3D、CubiCasa5K和Raster2Graph等标准基准测试中达到最先进性能，同时在包含多样房间结构和复杂几何变化的WAFFLE数据集上表现出强大的泛化能力
- Conclusion: Raster2Seq通过序列化表示和自回归机制，能够灵活处理复杂楼层平面图，有效重建结构和语义信息，为自动化理解和CAD工作流程提供了可靠的前置处理方案


### [203] [WorldCompass: Reinforcement Learning for Long-Horizon World Models](https://arxiv.org/abs/2602.09022)
*Zehan Wang,Tengfei Wang,Haiyu Zhang,Xuhui Zuo,Junta Wu,Haoyuan Wang,Wenqiang Sun,Zhenwei Wang,Chenjie Cao,Hengshuang Zhao,Chunchao Guo,Zhou Zhao*

Main category: cs.CV

TL;DR: WorldCompass是一个用于长时程交互视频世界模型的强化学习后训练框架，通过创新的剪辑级策略、互补奖励函数和高效RL算法，显著提升了世界模型的交互准确性和视觉保真度。

- Motivation: 现有的长时程交互视频世界模型在探索世界时存在准确性和一致性问题，需要一种有效的后训练框架来基于交互信号引导模型更准确、一致地探索世界。
- Method: 提出了三个核心创新：1) 剪辑级策略：在单个目标剪辑生成和评估多个样本，提高效率并提供细粒度奖励信号；2) 互补奖励函数：设计交互跟随准确性和视觉质量的奖励函数，提供直接监督并抑制奖励黑客行为；3) 高效RL算法：采用负感知微调策略配合多种效率优化，有效增强模型能力。
- Result: 在SoTA开源世界模型WorldPlay上的评估表明，WorldCompass在各种场景下显著提升了交互准确性和视觉保真度。
- Conclusion: WorldCompass是一个有效的强化学习后训练框架，能够显著提升长时程交互视频世界模型的探索准确性和视觉质量，为世界模型的实际应用提供了重要支持。


### [204] [Autoregressive Image Generation with Masked Bit Modeling](https://arxiv.org/abs/2602.09024)
*Qihang Yu,Qihao Liu,Ju He,Xinyang Zhang,Yang Liu,Liang-Chieh Chen,Xi Chen*

Main category: cs.CV

TL;DR: 本文挑战视觉生成中连续管道的统治地位，证明离散方法通过扩大码本规模可以匹配甚至超越连续方法，并提出BAR框架实现最佳性能。

- Motivation: 挑战视觉生成领域连续方法的统治地位，系统研究离散与连续方法之间的性能差距，揭示离散方法性能不足的根本原因并非内在缺陷，而是压缩比问题。
- Method: 提出掩码比特自回归建模(BAR)框架，通过自回归变换器配合掩码比特建模头，支持任意码本大小，通过逐步生成比特来预测离散标记。
- Result: BAR在ImageNet-256上达到0.99的gFID新纪录，超越了连续和离散方法的领先方法，同时显著降低采样成本，收敛速度比先前连续方法更快。
- Conclusion: 离散标记器通过扩大码本规模可以匹配甚至超越连续方法，BAR框架成功解决了现有离散方法在扩大码本时的性能下降或训练成本过高问题，为视觉生成提供了高效的新范式。
## cs.AI

### [205] [VGAS: Value-Guided Action-Chunk Selection for Few-Shot Vision-Language-Action Adaptation](https://arxiv.org/abs/2602.07399)
*Changhua Xu,Jie Lu,Junyu Xuan,En Yu*

Main category: cs.AI

TL;DR: VGAS框架通过生成-选择机制解决VLA模型在少样本适应中的几何模糊问题，使用价值引导的动作块选择提升任务成功率

- Motivation: 现有VLA模型在少样本适应任务中不可靠，虽然能生成语义合理的轨迹，但常因几何模糊性导致执行失败，需要解决有限监督下的几何精度问题
- Method: 提出VGAS框架：1) 微调VLA作为高召回率提议生成器；2) 引入Q-Chunk-Former作为几何基础的Transformer批评器；3) 提出显式几何正则化(EGR)保持动作排序分辨率
- Result: 实验和理论分析表明VGAS在有限演示和分布偏移下能持续提高成功率和鲁棒性
- Conclusion: VGAS通过生成-选择视角解决VLA少样本适应问题，有效处理几何模糊性，为VLA模型的实际应用提供了可靠解决方案


### [206] [Selective Fine-Tuning for Targeted and Robust Concept Unlearning](https://arxiv.org/abs/2602.07919)
*Mansi,Avinash Kori,Francesca Toni,Soteris Demetriou*

Main category: cs.AI

TL;DR: TRUST是一种针对扩散模型的概念遗忘方法，通过动态定位目标概念神经元并进行选择性微调，结合Hessian正则化，实现高效、鲁棒的概念遗忘。

- Motivation: 文本引导扩散模型易被利用生成有害内容，现有概念遗忘方法存在以下问题：1) 传统方法主要针对单个概念，而现实需要处理概念组合；2) 最先进方法依赖完全微调，计算成本高；3) 现有概念定位方法是静态的，导致效果不佳。
- Method: 提出TRUST方法：1) 动态估计目标概念神经元；2) 通过选择性微调进行概念遗忘；3) 采用基于Hessian的正则化增强鲁棒性。
- Result: 实验表明TRUST：1) 对对抗性提示具有鲁棒性；2) 显著保持生成质量；3) 比现有最先进方法显著更快；4) 能够遗忘单个概念、概念组合和条件概念，无需特定正则化。
- Conclusion: TRUST提供了一种高效、鲁棒的概念遗忘解决方案，能够处理现实世界中的复杂概念组合问题，同时保持模型性能。


### [207] [Do MLLMs Really See It: Reinforcing Visual Attention in Multimodal LLMs](https://arxiv.org/abs/2602.08241)
*Siqu Ou,Tianrui Wan,Zhiyuan Zhao,Junyu Gao,Xuelong Li*

Main category: cs.AI

TL;DR: SAYO是一个通过强化学习框架训练的多模态推理模型，引入区域级视觉注意力奖励机制，解决现有MLLMs视觉注意力不稳定的问题，提升复杂推理任务的性能。

- Motivation: 现有基于思维链的多模态大语言模型存在视觉注意力不稳定的问题：早期视觉对齐错误很少在后续推理中被纠正，导致错误传播和推理失败。这种限制源于训练过程中对视觉注意力的信用分配不足。
- Method: 提出SAYO模型，采用强化学习框架训练，引入区域级视觉注意力奖励机制。该奖励明确将优化信号与基于视觉的推理步骤对齐，使模型能够学习更可靠的注意力行为。
- Result: 在多个多模态基准测试上的广泛实验表明，SAYO在多样化的推理和感知任务上持续提升性能。
- Conclusion: 通过强化学习框架和区域级视觉注意力奖励机制，SAYO能够学习更稳定的视觉注意力策略，有效解决现有MLLMs视觉注意力不稳定的问题，提升复杂推理任务的性能。


### [208] [CoTZero: Annotation-Free Human-Like Vision Reasoning via Hierarchical Synthetic CoT](https://arxiv.org/abs/2602.08339)
*Chengyi Du,Yazhe Niu,Dazhong Shen,Luxin Xu*

Main category: cs.AI

TL;DR: CoTZero：无需标注的视觉语言模型训练范式，通过双阶段数据合成和认知对齐训练，提升视觉推理的逻辑一致性和可验证性

- Motivation: 当前视觉语言模型依赖表面相关性而非逻辑一致的结构化表示，导致高层次语义结构和非因果关系理解不足，阻碍组合式和可验证推理
- Method: 1) 双阶段数据合成：自底向上提取原子视觉基元并组合成结构化问题推理形式；自顶向下利用全局结构指导局部细节和因果关系解释。2) 认知对齐训练：在强化微调中引入认知一致可验证奖励，提供推理一致性和事实正确性的逐步反馈
- Result: 在包含词汇扰动负例的多层次语义不一致基准测试中，CoTZero在域内和域外设置下达到83.33%的F1分数，各组件均对提升可解释性和人类对齐的视觉推理有贡献
- Conclusion: CoTZero通过引入人类认知模型到推理过程，有效解决了视觉语言模型在结构化表示和逻辑推理方面的局限性，实现了更可解释和人类对齐的视觉推理能力


### [209] [GEBench: Benchmarking Image Generation Models as GUI Environments](https://arxiv.org/abs/2602.09007)
*Haodong Li,Jingwei Wu,Quan Sun,Guopeng Li,Juanxi Tian,Huanyu Zhang,Yanlin Lai,Ruichuan An,Hongbo Peng,Yuhong Dai,Chenxi Li,Chunmei Qing,Jia Wang,Ziyang Meng,Zheng Ge,Xiangyu Zhang,Daxin Jiang*

Main category: cs.AI

TL;DR: 提出了GEBench基准测试，用于评估GUI生成中的动态交互和时间一致性，包含700个样本和五维度的GE-Score评估指标。

- Motivation: 现有图像生成模型能预测未来GUI状态，但现有基准主要关注通用视觉保真度，缺乏对GUI特定场景中状态转换和时间一致性的评估。
- Method: 构建GEBench基准，包含700个精心策划的样本，涵盖5个任务类别；提出GE-Score五维度评估指标（目标达成、交互逻辑、内容一致性、UI合理性、视觉质量）。
- Result: 当前模型在单步转换上表现良好，但在保持长时间交互序列的时间一致性和空间定位方面存在显著困难；图标解释、文本渲染和定位精度是关键瓶颈。
- Conclusion: 该工作为系统评估提供了基础，并为构建高保真生成GUI环境指明了有前景的研究方向。
## cs.HC

### [210] [Designing Multi-Robot Ground Video Sensemaking with Public Safety Professionals](https://arxiv.org/abs/2602.08882)
*Puqi Zhou,Ali Asgarov,Aafiya Hussain,Wonjoon Park,Amit Paudyal,Sameep Shrestha,Chia-wei Tang,Michael F. Lighthiser,Michael R. Hieb,Xuesu Xiao,Chris Thomas,Sungsoo Ray Hong*

Main category: cs.HC

TL;DR: 该研究开发了一个多机器人地面视频感知测试平台和MRVS工具，通过与警方合作改进公共安全中的多机器人视频分析工作流程。

- Motivation: 地面机器人舰队视频可提升公共安全态势感知能力，但目前缺乏如何将多机器人视频集成到公共安全工作流程中的设计知识。通过与六个警察机构合作，研究如何使这类视频分析变得实用。
- Method: 研究分为两个部分：研究1创建了首个多机器人地面视频感知测试平台，包含38个公共安全相关事件、20个机器人巡逻视频数据集和6个设计需求；研究2开发了MRVS工具，通过提示工程视频理解模型增强多机器人巡逻视频流。
- Result: 参与者报告使用LLM解释减少了手动工作量并增强了信心，但也注意到误报和隐私问题。测试平台已在GitHub上开源。
- Conclusion: 研究为设计未来多机器人视频感知工具提供了启示，强调了自动化分析在减轻专业人员负担方面的潜力，同时需要解决误报和隐私问题。
## cs.RO

### [211] [Learning to Anchor Visual Odometry: KAN-Based Pose Regression for Planetary Landing](https://arxiv.org/abs/2602.06968)
*Xubo Luo,Zhaojin Li,Xue Wan,Wei Zhang,Leizheng Shu*

Main category: cs.RO

TL;DR: KANLoc：基于KAN的月球着陆单目定位框架，通过耦合视觉里程计与轻量级绝对位姿回归器，实现无漂移的实时6-DoF定位

- Motivation: 现有月球着陆定位方法存在局限：视觉里程计会无界漂移，而基于地图的绝对定位在纹理稀疏或低光照地形中失效。需要一种既能消除漂移又能适应月球特殊环境的实时定位方案。
- Method: 提出KANLoc框架，核心是使用Kolmogorov-Arnold Network学习从图像特征到地图坐标的复杂映射，生成稀疏但高度可靠的全局位姿锚点。将这些锚点融合到光束法平差框架中，有效消除漂移同时保持局部运动精度。还包括针对传感器遮挡的定制数据增强策略。
- Result: 在合成和真实月球着陆数据集上，KANLoc将平均平移和旋转误差分别降低32%和45%，单轨迹增益最高达45%/48%，以≥15 FPS实现全局一致的实时轨迹，优于强基线方法。
- Conclusion: KANLoc通过KAN网络的高效位姿回归和VO-绝对定位的紧密耦合，为月球着陆提供了准确、实时且无漂移的单目定位解决方案，在参数效率和鲁棒性方面均有显著优势。


### [212] [FeudalNav: A Simple Framework for Visual Navigation](https://arxiv.org/abs/2602.06974)
*Faith Johnson,Bryan Bo Cao,Shubham Jain,Ashwin Ashok,Kristin Dana*

Main category: cs.RO

TL;DR: 提出分层视觉导航框架，通过视觉相似性组织记忆，无需里程计，支持交互式导航增强性能

- Motivation: 在未知、无地图或GPS受限环境中，传统基于度量地图的方法失效，需要转向基于学习的方法，以最小化探索实现导航
- Method: 分层框架将导航决策分解为多个层级，使用可转移的航点选择网络选择子目标，关键组件是基于视觉相似性组织的潜在空间记忆模块，替代基于图的拓扑表示
- Result: 在Habitat AI环境中与SOTA方法竞争，无需训练或推理中使用里程计，框架可解释性支持交互导航，少量人工干预能显著提升导航成功率
- Conclusion: 基于视觉相似性的潜在空间记忆模块为导航任务提供紧凑、轻量、易训练的方法，在陌生环境中能导航至目标，交互式增强进一步提升性能


### [213] [LangGS-SLAM: Real-Time Language-Feature Gaussian Splatting SLAM](https://arxiv.org/abs/2602.06991)
*Seongbo Ha,Sibaek Lee,Kyungsu Kang,Joonyeol Choi,Seungjun Tak,Hyeonwoo Yu*

Main category: cs.RO

TL;DR: 提出一个RGB-D SLAM系统，能重建语言对齐的密集特征场，同时保持低延迟跟踪与建图，实现15FPS实时运行

- Motivation: 现有系统难以同时实现高几何保真度、语义保真度和实时性能，需要弥合3D感知与语言推理之间的差距
- Method: 1) Top-K渲染管道高效渲染高维特征图；2) 多准则地图管理策略修剪冗余或不一致的高斯分布；3) 混合场优化框架按频率解耦几何与语义场优化
- Result: 系统在几何保真度上优于纯几何基线，语义保真度与离线方法相当，同时以15FPS实时运行
- Conclusion: 在线SLAM结合密集、未压缩的语言对齐特征场是可行且有效的，为3D感知与语言推理的融合提供了新途径


### [214] [When Simultaneous Localization and Mapping Meets Wireless Communications: A Survey](https://arxiv.org/abs/2602.06995)
*Konstantinos Gounis,Sotiris A. Tegos,Dimitrios Tyrovolas,Panagiotis D. Diamantoulakis,George K. Karagiannidis*

Main category: cs.RO

TL;DR: 本文综述了SLAM与无线通信交叉领域的最新进展，重点探讨视觉SLAM与无线通信的双向影响关系，分析相关技术挑战与未来方向。

- Motivation: 商业无线通信与传感设备的普及以及智能自主系统的发展，为实现鲁棒的联合通信与同时定位与建图（SLAM）创造了条件。本文旨在调查SLAM与无线通信交叉领域的最新研究进展，特别关注视觉SLAM与无线通信的集成。
- Method: 1. 综述无线信号传播、几何信道建模、RF定位与感知等关键概念；2. 分析图像处理技术用于检测地标和预测无线信道最优路径；3. 从先决条件、技术、背景、未来方向等多个维度考察SLAM与无线通信的交叉；4. 分析概率模型、空间信号处理方法等数学方法；5. 探讨实现自主机器人状态高效检索的技术要素。
- Result: 研究发现：1. 单目视觉SLAM可从RF相关信息中受益，RF信息可作为尺度模糊性解析的代理；2. 5G及以后的无线通信可从SLAM中的视觉里程计中受益；3. 除了相机之外的其他SLAM源与无线通信存在双重关系；4. 联合通信与SLAM的集成解决方案仍处于起步阶段。
- Conclusion: 联合通信与SLAM的集成解决方案尚不成熟，需要在理论和实践上进一步发展，为RF和多天线技术增加更高层次的定位和语义感知能力。未来研究需解决技术挑战，推动该交叉领域的深入发展。


### [215] [A Distributed Multi-Modal Sensing Approach for Human Activity Recognition in Real-Time Human-Robot Collaboration](https://arxiv.org/abs/2602.07024)
*Valerio Belcamino,Nhat Minh Dinh Le,Quan Khanh Luu,Alessandro Carfì,Van Anh Ho,Fulvio Mastrogiovanni*

Main category: cs.RO

TL;DR: 该论文提出了一种结合数据手套和视觉触觉传感器的人体活动识别系统，用于人机协作场景中的手部活动识别，并在多种条件下验证了其高准确性。

- Motivation: 人体活动识别是人机协作的基础，能使机器人理解和适应人类意图。当前需要一种能够准确识别手部活动（特别是与机器人接触时）的多模态系统。
- Method: 开发了一个多模态HAR系统，结合了配备惯性测量单元的模块化数据手套和基于视觉的触觉传感器，以捕捉手部活动。在三种条件下测试：离线分类分割序列、静态条件下的实时分类、以及真实的人机协作场景。
- Result: 实验结果显示所有任务都取得了高准确率，表明这种多模态方法适用于多种协作场景。
- Conclusion: 提出的多模态HAR系统在人机协作中有效，能够准确识别手部活动，为多种协作设置提供了有益的技术方案。


### [216] [Global Symmetry and Orthogonal Transformations from Geometrical Moment $n$-tuples](https://arxiv.org/abs/2602.07736)
*Omar Tahri*

Main category: cs.RO

TL;DR: 该论文提出使用几何矩检测物体对称性并估计正交变换的方法，通过矩n元组在n维空间中识别旋转、反射等对称变换，并与迭代优化方法结合获得更好的对称平面检测效果。

- Motivation: 检测对称性对于物体抓取至关重要，因为识别物体的对称特征或轴线有助于制定高效的抓取策略，沿着这些轴线抓取通常能获得更稳定平衡的握持，从而促进成功的操作。
- Method: 采用几何矩来识别对称性并估计正交变换（包括旋转和镜像变换），为以坐标系原点为中心的物体提供独特的对称性检测和正交变换估计度量。开发了在n维空间中获取这些函数（矩n元组）的全面方法。
- Result: 在2D和3D物体上进行了广泛的验证测试，确保方法的鲁棒性和可靠性。与使用迭代优化检测多个对称平面的最先进方法进行比较，结果表明将本文方法与迭代方法结合在检测到的对称平面数量和计算时间方面都能获得满意结果。
- Conclusion: 基于几何矩的对称性检测方法有效，与迭代优化方法结合能够提高对称平面检测的性能，为物体抓取和操作提供了实用的对称性分析工具。


### [217] [Research on a Camera Position Measurement Method based on a Parallel Perspective Error Transfer Model](https://arxiv.org/abs/2602.07888)
*Ning Hu,Shuai Li,Jindong Tan*

Main category: cs.RO

TL;DR: 提出基于平行透视近似的几何误差传播框架，用于改善近场相机位姿估计的鲁棒性，通过误差感知加权和Gauss-Newton优化提升精度

- Motivation: 近场场景中，强烈的透视效应和异构测量噪声会显著降低传统PnP方法的稳定性，需要更鲁棒的位姿估计方法
- Method: 建立几何误差传播框架，通过平行透视近似显式建模图像测量误差在透视几何中的传播，推导误差传递模型，结合平行透视初始化和误差感知加权的Gauss-Newton优化
- Result: 在合成数据和真实图像（强光照、手术照明、水下低光等多样条件）上的实验表明，该方法在保持高计算效率的同时，达到与最先进解析和迭代PnP方法相当的精度和鲁棒性
- Conclusion: 显式几何误差建模对于挑战性近场设置中的可靠相机位姿估计至关重要，提出的框架能有效提升近场操作的鲁棒性


### [218] [Self-Supervised Bootstrapping of Action-Predictive Embodied Reasoning](https://arxiv.org/abs/2602.08167)
*Milan Ganai,Katie Luo,Jonas Frey,Clark Barrett,Marco Pavone*

Main category: cs.RO

TL;DR: R&B-EnCoRe：通过自监督精炼从互联网规模知识中引导具身推理，无需外部奖励或人工标注，在多种机器人任务中显著提升性能。

- Motivation: 当前具身思维链方法依赖固定模板指定推理原语，这会强制策略处理无关信息，分散关键动作预测信号。这形成了一个瓶颈：没有成功的策略就无法验证推理质量，没有高质量的推理就无法构建鲁棒的策略。
- Method: 将推理视为重要性加权变分推断中的隐变量，模型可以生成并精炼一个具身特定策略的训练数据集，无需外部奖励、验证器或人工标注。通过自监督精炼从互联网规模知识中引导具身推理。
- Result: 在操作任务（仿真和硬件）、腿部导航（双足、轮式、自行车、四足）和自动驾驶等多种具身环境中验证，使用1B到30B参数的VLA架构。相比无差别推理所有可用原语的模型，实现了28%的操作成功率提升、101%的导航分数改进和21%的碰撞率降低。
- Conclusion: R&B-EnCoRe使模型能够精炼出对成功控制具有预测性的推理，绕过手动标注工程，同时将互联网规模的知识扎根于物理执行中。


### [219] [Chamelion: Reliable Change Detection for Long-Term LiDAR Mapping in Transient Environments](https://arxiv.org/abs/2602.08189)
*Seoyeon Jang,Alex Junho Lee,I Made Aswin Nahrendra,Hyun Myung*

Main category: cs.RO

TL;DR: 提出一个用于在线变化检测和长期地图维护的双头网络，通过数据增强策略合成结构变化来训练模型，在真实建筑工地和室内环境中验证了有效性。

- Motivation: 移动机器人在动态环境中导航需要在线变化检测，但在瞬态环境（如建筑工地、频繁重新配置的室内空间）中，由于频繁遮挡和时空变化，现有方法难以检测变化并更新地图。
- Method: 提出一个双头网络用于在线变化检测和长期地图维护，开发数据增强策略通过从不同场景导入元素来合成结构变化，无需大量真实标注即可有效训练模型。
- Result: 在真实建筑工地和室内办公环境的实验表明，该方法在不同场景中泛化良好，实现了高效准确的地图更新。
- Conclusion: 该方法解决了动态环境中在线变化检测和地图维护的挑战，通过数据增强策略克服了真实数据收集和对齐的困难，在实际应用中表现出色。


### [220] [Informative Object-centric Next Best View for Object-aware 3D Gaussian Splatting in Cluttered Scenes](https://arxiv.org/abs/2602.08266)
*Seunghoon Jeong,Eunho Lee,Jeongyun Kim,Ayoung Kim*

Main category: cs.RO

TL;DR: 提出了一种基于实例感知的Next Best View策略，利用物体特征优先探索未充分观测区域，显著降低深度误差并提升重建质量。

- Motivation: 在遮挡和观测不完整的杂乱场景中，选择信息丰富的视角对于构建可靠表示至关重要。现有方法仅依赖几何线索，忽略了与操作相关的语义信息，且倾向于利用而非探索。
- Method: 提出实例感知的NBV策略：1) 物体感知的3D高斯泼溅将实例级信息蒸馏为独热物体向量；2) 计算置信度加权的信息增益，指导识别与错误和不确定高斯相关的区域；3) 可轻松适应物体中心的NBV，专注于目标物体的视角选择。
- Result: 在合成数据集上深度误差降低达77.14%，在真实世界GraspNet数据集上降低34.10%。针对特定物体的NBV相比整个场景，可额外降低25.60%的深度误差。在真实机器人操作任务中验证了有效性。
- Conclusion: 提出的实例感知NBV策略通过利用物体特征优先探索未充分观测区域，显著提升了3D高斯泼溅在杂乱场景中的重建质量，并展示了在机器人操作任务中的实用性。


### [221] [BiManiBench: A Hierarchical Benchmark for Evaluating Bimanual Coordination of Multimodal Large Language Models](https://arxiv.org/abs/2602.08392)
*Xin Wu,Zhixuan Liang,Yue Ma,Mengkang Hu,Zhiyuan Qin,Xiu Li*

Main category: cs.RO

TL;DR: 该论文提出了BiManiBench基准测试，用于评估多模态大语言模型在双臂机器人操作任务中的性能，发现现有模型在空间推理和协调控制方面存在不足。

- Motivation: 现有MLLM基准测试主要局限于单臂操作，无法评估双臂任务所需的时空协调能力，如抬起重锅等需要双臂协作的任务。
- Method: 提出BiManiBench分层基准测试框架，包含三个层级：基础空间推理、高层动作规划和低层末端执行器控制，专门针对双臂操作中的独特挑战（如手臂可达性和运动学约束）进行设计。
- Result: 对30多个最先进模型的分析显示，尽管MLLMs在高层推理方面表现良好，但在双臂空间定位和控制方面存在困难，经常出现相互干扰和序列错误。
- Conclusion: 当前MLLM范式缺乏对双臂运动学约束的深入理解，未来研究需要关注双臂碰撞避免和细粒度时序规划。


### [222] [Reliability-aware Execution Gating for Near-field and Off-axis Vision-guided Robotic Alignment](https://arxiv.org/abs/2602.08466)
*Ning Hu,Senhao Cao,Maochen Li*

Main category: cs.RO

TL;DR: 论文提出了一种可靠性感知的执行门控机制，通过评估几何一致性和配置风险来筛选高风险的姿态更新，从而在保持姿态估计精度的同时提高视觉引导机器人系统的执行可靠性。

- Motivation: 虽然姿态估计的数值精度已有显著提升，但实际机器人系统在执行视觉对齐任务时仍频繁失败，特别是在近场和离轴配置下。这表明仅靠姿态精度不足以保证执行层面的可靠性，需要解决几何误差放大机制带来的执行失败问题。
- Method: 提出可靠性感知执行门控机制，不修改姿态估计算法，而是在执行层面操作。该方法在执行前评估几何一致性和配置风险，选择性地拒绝或缩放高风险的姿态更新，从而避免由小误差放大导致的不稳定或失败对齐。
- Result: 在UR5机器人平台上进行实验验证，结果表明执行门控显著提高了任务成功率，减少了执行方差，抑制了尾部风险行为，同时保持了平均姿态精度基本不变。该方法与姿态估计器无关，可轻松集成到基于几何和学习的姿态估计流程中。
- Conclusion: 执行层面的可靠性建模对于提高视觉引导机器人系统的鲁棒性至关重要。提出的执行门控机制提供了一种实用解决方案，能够在不改变姿态估计精度的情况下显著改善执行可靠性，特别适用于近场视觉引导机器人系统。


### [223] [Dexterous Manipulation Policies from RGB Human Videos via 4D Hand-Object Trajectory Reconstruction](https://arxiv.org/abs/2602.09013)
*Hongyi Chen,Tony Dong,Tiancheng Wu,Liquan Wang,Yash Jangir,Yaru Niu,Yufei Ye,Homanga Bharadhwaj,Zackory Erickson,Jeffrey Ichnowski*

Main category: cs.RO

TL;DR: VIDEOMANIP：无需穿戴设备的框架，直接从RGB人类视频学习灵巧操作，通过重建4D机器人-物体轨迹和接触优化实现通用策略学习

- Motivation: 多指机器人手操作和抓取面临高维动作空间和大规模训练数据获取困难的问题。现有方法依赖穿戴设备或专用传感设备进行人类遥操作，限制了可扩展性。
- Method: 提出VIDEOMANIP框架：1) 从单目视频重建显式4D机器人-物体轨迹（估计人手姿态、物体网格）；2) 通过接触优化和交互中心抓取建模改进重建数据；3) 演示合成策略从单个视频生成多样化训练轨迹。
- Result: 仿真中：在Inspire Hand上对20个不同物体实现70.25%成功率。真实世界：在LEAP Hand上对7个任务平均成功率62.86%，比基于重定向的方法提升15.87%。
- Conclusion: VIDEOMANIP展示了从RGB人类视频直接学习灵巧机器人操作的可行性，无需额外机器人演示，为可扩展的机器人学习提供了新途径。


### [224] [Robustness Is a Function, Not a Number: A Factorized Comprehensive Study of OOD Robustness in Vision-Based Driving](https://arxiv.org/abs/2602.09018)
*Amir Mallak,Alaa Maalouf*

Main category: cs.RO

TL;DR: 该研究系统分解自动驾驶OOD鲁棒性，通过5个环境维度（场景、季节、天气、时间、智能体组合）和k因子扰动测试，发现ViT策略比CNN/FC更鲁棒，FM特征表现最佳但延迟高，多帧输入不优于单帧，环境变化影响非线性，训练数据规模和多样性是关键。

- Motivation: 自动驾驶中的分布外（OOD）鲁棒性通常被简化为单一数字指标，掩盖了策略失效的具体原因。研究者希望系统性地分解环境变化因素，理解不同因素如何影响策略性能，为设计更鲁棒的驾驶策略提供指导。
- Method: 将环境分解为5个维度：场景（乡村/城市）、季节、天气、时间（白天/夜晚）、智能体组合；使用k因子扰动（k∈{0,1,2,3}）进行控制测试；在VISTA模拟器中测试FC、CNN、ViT策略；在冻结的基础模型特征上训练紧凑ViT头；改变训练数据的规模、多样性和时间上下文。
- Result: 1) ViT策略比同等规模的CNN/FC更鲁棒，FM特征达到SOTA但延迟较高；2) 多帧输入不优于最佳单帧基线；3) 最大性能下降来自乡村→城市和白天→夜晚（各约31%）；4) FM特征策略在3个同时变化下仍保持85%以上性能；5) 环境变化影响非线性；6) 冬季/雪天训练对单因素变化最鲁棒；7) 增加数据轨迹可提升鲁棒性；8) 多环境训练可提升覆盖范围。
- Conclusion: 研究提供了自动驾驶OOD鲁棒性的可操作设计规则：优先使用ViT架构和FM特征，关注数据多样性和规模，理解环境变化的非线性交互效应，针对特定环境变化进行针对性训练，平衡单环境峰值性能与多环境覆盖范围。


### [225] [$χ_{0}$: Resource-Aware Robust Manipulation via Taming Distributional Inconsistencies](https://arxiv.org/abs/2602.09021)
*Checheng Yu,Chonghao Sima,Gangcheng Jiang,Hai Zhang,Haoguang Mai,Hongyang Li,Huijie Wang,Jin Chen,Kaiyang Wu,Li Chen,Lirui Zhao,Modi Shi,Ping Luo,Qingwen Bu,Shijia Peng,Tianyu Li,Yibo Yuan*

Main category: cs.RO

TL;DR: 提出χ₀框架，通过模型算术、阶段优势估计和训练-部署对齐三个技术支柱，解决机器人操作中的分布偏移问题，实现24小时连续运行的高可靠性双手机器人服装操作。

- Motivation: 传统高可靠性长时程机器人操作依赖大规模数据和计算，但真正的瓶颈是演示分布、策略学习偏置和执行分布之间的系统性不一致，导致多阶段任务中的累积误差。
- Method: 1) 模型算术：权重空间合并策略，高效吸收不同演示的多样化分布；2) 阶段优势：阶段感知的优势估计器，提供稳定密集的进度信号；3) 训练-部署对齐：通过时空增强、启发式DAgger校正和时间分块平滑来弥合分布差距。
- Result: χ₀使双手机器人能够协作完成服装操作任务（铺平、折叠、悬挂），实现24小时连续运行。实验表明，χ₀在成功率上比最先进的π₀.5高出近250%，仅需20小时数据和8个A100 GPU。
- Conclusion: χ₀框架通过解决分布不一致问题，以资源高效的方式实现了生产级别的机器人操作鲁棒性，为长时程多阶段任务提供了可靠解决方案。
## cs.IR

### [226] [Reasoning-Augmented Representations for Multimodal Retrieval](https://arxiv.org/abs/2602.07125)
*Jianrui Zhang,Anirudh Sundara Rajan,Brandon Han,Soochahn Lee,Sukanta Ganguly,Yong Jae Lee*

Main category: cs.IR

TL;DR: UMR提出数据增强框架，通过外部化推理来改善多模态检索，在M-BEIR基准上取得显著提升

- Motivation: 当前多模态检索模型在需要潜在推理（如解决模糊引用或匹配组合约束）时表现脆弱，这种脆弱性源于数据问题：图像包含"沉默"证据而查询隐含关键语义，导致单次嵌入需要同时完成推理和压缩，容易产生虚假特征匹配
- Method: 提出数据中心的框架，将推理与检索解耦：1）使用强视觉语言模型为语料库条目生成密集描述，使视觉证据显式化；2）解析查询中的模糊多模态引用；3）将冗长指令重写为简洁检索约束。同时训练检索器在这些语义密集表示上，避免分布偏移
- Result: 在M-BEIR基准上，推理增强训练方法相比强基线取得一致提升，消融实验显示：语料增强主要帮助知识密集型查询，而查询增强对组合修改请求至关重要
- Conclusion: 通过外部化推理并将检索器训练在语义密集表示上，可以有效解决多模态检索中的潜在推理问题，提升模型鲁棒性
## gr-qc

### [227] [Dynamic Black-hole Emission Tomography with Physics-informed Neural Fields](https://arxiv.org/abs/2602.08029)
*Berthy T. Feng,Andrew A. Chael,David Bromley,Aviad Levis,William T. Freeman,Katherine L. Bouman*

Main category: gr-qc

TL;DR: PI-DEF：一种物理信息化的可微分神经渲染方法，用于从稀疏射电测量中重建黑洞周围的动态3D气体分布，相比之前的方法显著提高了重建精度。

- Motivation: 随着静态黑洞成像的成功，下一个前沿是黑洞的动态3D成像。恢复黑洞附近的动态3D气体分布将揭示宇宙中前所未见的部分并指导新物理模型。然而，只能从单一视角获取稀疏的射电测量数据，使得动态3D重建问题严重不适定。之前的BH-NeRF方法假设气体遵循开普勒动力学，但这个假设在黑洞附近失效，因为强引力场和电磁活动使流体动力学变得复杂。
- Method: 提出PI-DEF方法，采用物理信息化的可微分神经渲染技术，给定EHT测量数据拟合4D（时间+3D）发射率场。该方法联合重建3D速度场和4D发射率场，并将速度作为发射率动力学的软约束。
- Result: 在模拟数据实验中，相比BH-NeRF和物理无关方法，PI-DEF显著提高了重建精度。该方法还可用于估计黑洞的其他物理参数，如自旋。
- Conclusion: PI-DEF通过物理约束的可微分神经渲染，克服了先前方法对气体动力学的限制性假设，为黑洞附近的动态3D成像提供了更准确的重建方法，并能提取黑洞的物理参数。
## cs.LG

### [228] [AVERE: Improving Audiovisual Emotion Reasoning with Preference Optimization](https://arxiv.org/abs/2602.07054)
*Ashutosh Chaubey,Jiacheng Pang,Maksim Siniukov,Mohammad Soleymani*

Main category: cs.LG

TL;DR: 本文提出EmoReAlM基准测试来评估多模态大语言模型在情感理解中的虚假关联和幻觉问题，并提出AVEm-DPO偏好优化方法来解决这些问题，在多个数据集上取得显著性能提升。

- Motivation: 当前多模态大语言模型在情感理解任务中存在两个关键挑战：1）情感与无关视听线索之间的虚假关联；2）语言模型主干中的文本先验驱动的视听线索幻觉。这些问题限制了模型在社交智能体中的实际应用效果。
- Method: 首先引入EmoReAlM基准测试来评估模型在线索-情感关联、幻觉和模态一致性方面的表现。然后提出AVEm-DPO偏好优化技术，通过构建对虚假关联或幻觉响应的偏好，以及基于文本提示的视听输入对偏好来对齐模型响应。还包括一个正则化项来惩罚对文本先验的依赖，从而减轻模态特定线索的幻觉。
- Result: 在DFEW、RAVDESS和EMER数据集上的实验结果表明，该方法显著提高了参考基线模型的性能，在零样本设置中获得了6-19%的相对性能提升。
- Conclusion: 通过提供严格的基准测试和稳健的优化框架，这项工作为情感理解和社交AI的多模态大语言模型的评估和改进提供了原则性方法。代码、模型和基准测试将在指定网站发布。


### [229] [Video-based Music Generation](https://arxiv.org/abs/2602.07063)
*Serkan Sulun*

Main category: cs.LG

TL;DR: EMSYNC是一个快速、免费、自动的视频配乐生成系统，通过情感分类、情感MIDI生成和时序边界对齐技术，为视频生成情感和节奏同步的音乐。

- Motivation: 随着网络视频内容快速增长，寻找合适的配乐成为重大挑战。内容创作者需要无需作曲或授权即可增强视频质量的音乐解决方案。
- Method: 1) 新颖的视频情感分类器，使用预训练深度网络提取特征，仅训练融合层；2) 构建大规模情感标注MIDI数据集；3) 首个基于连续情感值而非离散类别的MIDI生成器；4) 引入"边界偏移编码"实现音乐和弦与场景变化的时序对齐。
- Result: 在Ekman-6和MovieNet数据集上取得最先进结果；用户研究表明，在音乐丰富度、情感对齐、时序同步和整体偏好方面均优于现有方法，建立了视频配乐生成的新标杆。
- Conclusion: EMSYNC作为一个全自动视频配乐生成系统，通过情感分类、情感音乐生成和时序同步技术的结合，为内容创作者提供了高效、优质的配乐解决方案，推动了视频配乐生成领域的发展。


### [230] [Mimetic Initialization of MLPs](https://arxiv.org/abs/2602.07156)
*Asher Trockman,J. Zico Kolter*

Main category: cs.LG

TL;DR: 提出首个将模仿初始化应用于通道混合层（MLP）的方法，通过给第一层赋予非零均值来加速小规模视觉任务的训练

- Motivation: 模仿初始化先前只应用于空间混合层（卷积、自注意力、状态空间层），但尚未应用于通道混合层（MLP），需要探索MLP的初始化方法
- Method: 给多层感知机（MLP）的第一层赋予非零均值，这是一种极其简单的初始化技术
- Result: 该方法在CIFAR-10和ImageNet-1k等小规模视觉任务上加速了训练，虽然效果比空间混合初始化小，但可以与它们结合使用获得额外增益
- Conclusion: 成功将模仿初始化扩展到通道混合层，为MLP提供了简单有效的初始化方法，可与现有空间混合初始化技术互补使用


### [231] [Reliable and Responsible Foundation Models: A Comprehensive Survey](https://arxiv.org/abs/2602.08145)
*Xinyu Yang,Junlin Han,Rishi Bommasani,Jinqi Luo,Wenjie Qu,Wangchunshu Zhou,Adel Bibi,Xiyao Wang,Jaehong Yoon,Elias Stengel-Eskin,Shengbang Tong,Lingfeng Shen,Rafael Rafailov,Runjia Li,Zhaoyang Wang,Yiyang Zhou,Chenhang Cui,Yu Wang,Wenhao Zheng,Huichi Zhou,Jindong Gu,Zhaorun Chen,Peng Xia,Tony Lee,Thomas Zollo,Vikash Sehwag,Jixuan Leng,Jiuhai Chen,Yuxin Wen,Huan Zhang,Zhun Deng,Linjun Zhang,Pavel Izmailov,Pang Wei Koh,Yulia Tsvetkov,Andrew Wilson,Jiaheng Zhang,James Zou,Cihang Xie,Hao Wang,Philip Torr,Julian McAuley,David Alvarez-Melis,Florian Tramèr,Kaidi Xu,Suman Jana,Chris Callison-Burch,Rene Vidal,Filippos Kokkinos,Mohit Bansal,Beidi Chen,Huaxiu Yao*

Main category: cs.LG

TL;DR: 该论文是一篇关于基础模型可靠性与责任性的综述，涵盖偏见公平、安全隐私、不确定性、可解释性、分布偏移等关键问题，以及幻觉、对齐、AIGC检测等方法和挑战。

- Motivation: 随着基础模型（LLMs、MLLMs、图像生成模型、视频生成模型）在现实世界中的广泛应用，确保其可靠性和责任性已成为学术界、工业界和政府的关键需求。这些模型在医疗、法律、教育、金融、科学等领域的部署需要解决伦理、信任和社会责任问题。
- Method: 采用文献综述方法，系统性地探讨基础模型可靠性与责任性的多个关键领域：偏见与公平、安全与隐私、不确定性、可解释性、分布偏移。同时研究模型局限性（如幻觉）以及对齐和AIGC检测等方法。对每个领域进行现状梳理并规划具体未来研究方向。
- Result: 论文提供了基础模型可靠性与责任性研究的全面综述，识别了当前研究现状和未来方向。通过分析各领域之间的交叉联系，揭示了共享挑战和相互关联性，为开发更负责任的基础模型提供了系统框架。
- Conclusion: 该综述旨在促进基础模型的开发不仅追求强大性能，更要确保其符合伦理、可信赖、可靠且对社会负责。通过系统梳理关键问题和研究方向，为构建更负责任的人工智能生态系统提供指导。
## q-bio.TO

### [232] [retinalysis-vascx: An explainable software toolbox for the extraction of retinal vascular biomarkers](https://arxiv.org/abs/2602.08580)
*Jose D. Vargas Quiros,Michael J. Beyeler,Sofia Ortin Vela,EyeNED Reading Center,Sven Bergmann,Caroline C. W. Klaver,Bart Liefers*

Main category: q-bio.TO

TL;DR: VascX是一个开源Python工具箱，用于从眼底彩色图像中自动提取视网膜血管生物标志物，支持大规模视网膜血管研究。

- Motivation: 大规模视网膜血管研究需要从眼底彩色图像中自动提取血管生物标志物，现有工具缺乏标准化、可重复的解决方案。
- Method: 将血管分割掩码处理为骨架图，构建无向和有向血管图，解析连续血管段，利用黄斑、视盘等解剖标志进行空间标准化测量。
- Result: 开发了VascX工具箱，能够计算血管密度、分叉角度、视网膜中央等效值、迂曲度、时间角度等综合生物标志物，并提供图像质量指标。
- Conclusion: VascX为眼组学研究提供了可解释、可修改的框架，支持可重复的血管研究，为大规模临床和流行病学数据库提供了高效解决方案。
## cs.CY

### [233] [We Should Separate Memorization from Copyright](https://arxiv.org/abs/2602.08632)
*Adi Haviv,Niva Elkin-Koren,Uri Hacohen,Roi Livni,Shay Moran*

Main category: cs.CY

TL;DR: 论文认为当前关于基础模型版权问题的技术文献过度依赖传统重建技术，将记忆与复制混为一谈，主张记忆不应等同于复制或作为版权侵权的代理指标，提倡基于输出的风险评估方法。

- Motivation: 基础模型的广泛使用带来了新的版权风险因素，当前数据科学界和法律学界对此存在活跃但混乱的讨论，技术文献中的主张和结果常被不同解读并导致不同含义。
- Method: 分析当前技术文献中使用的传统重建技术，区分真正表明侵权风险的技术信号与反映合法泛化或高频内容的技术信号，提出输出层面的风险评估框架。
- Result: 论文论证了记忆（如数据科学中常研究的）不应等同于复制，也不应作为版权侵权的代理指标，需要区分不同技术信号的实际含义。
- Conclusion: 提倡基于输出的风险评估流程，使技术评估与既定的版权标准保持一致，为研究、审计和政策制定提供更有原则的基础。
## q-bio.NC

### [234] [SurfAge-Net: A Hierarchical Surface-Based Network for Interpretable Fine-Grained Brain Age Prediction](https://arxiv.org/abs/2602.06994)
*Rongzhao He,Dalin Zhu,Ying Wang,Songhong Yue,Leilei Zhao,Yu Fu,Dan Wu,Bin Hu,Weihao Zheng*

Main category: q-bio.NC

TL;DR: 提出SurfAge-Net网络，利用球面表面形态学指标进行区域特异性脑年龄预测，通过建模半球内和半球间依赖关系，在胎儿和新生儿数据上实现高精度预测并识别异常发育模式。

- Motivation: 现有脑年龄预测方法主要关注全脑水平，忽略了大脑发育的区域异质性，而区域特异性成熟模式对于检测局部异常发育轨迹至关重要。
- Method: 提出球面表面脑年龄预测网络(SurfAge-Net)，整合多种形态学指标，通过空间-通道混合和侧化感知注意力机制，显式建模半球内和半球间依赖关系，捕捉每个目标区域的协调成熟模式。
- Result: 在三个胎儿和新生儿数据集上验证，SurfAge-Net优于现有方法（全局MAE=0.54，区域MAE=0.45孕周），跨队列泛化能力强，提供空间精确且生物学可解释的皮层成熟图谱。
- Conclusion: 细粒度脑年龄预测是推进神经发育研究和支持早期临床评估的有前景范式，SurfAge-Net能有效识别非典型发育人群的异质性延迟和区域特异性异常。


### [235] [How does longer temporal context enhance multimodal narrative video processing in the brain?](https://arxiv.org/abs/2602.07570)
*Prachi Jindal,Anant Khandelwal,Manish Gupta,Bapi S. Raju,Subba Reddy Oota,Tanmoy Chakraborty*

Main category: q-bio.NC

TL;DR: 研究探讨视频片段时长（3-12秒）和叙事任务提示如何影响大脑与AI模型在观看自然电影时的对齐，发现长片段能提升多模态大语言模型的大脑对齐，且不同时长对应不同脑区，叙事任务提示能引发特定脑区对齐模式。

- Motivation: 理解人类和AI系统如何处理复杂叙事视频是神经科学和机器学习的交叉挑战。研究旨在探究视频片段时长和叙事任务提示如何影响大脑与模型在自然电影观看过程中的对齐，为研究生物相关的时间整合和可解释表征提供测试平台。
- Method: 使用fMRI记录参与者观看完整电影时的脑活动，分析不同时长视频片段（3-12秒）和不同叙事任务提示（多场景摘要、叙事摘要、角色动机、事件边界检测）下，大脑与模型特征的对齐情况，特别关注多模态大语言模型和单模态视频模型的表现差异。
- Result: 增加视频片段时长能显著提升多模态大语言模型的大脑对齐，但对单模态视频模型影响很小；短时间窗口与感知和早期语言区域对齐，长时间窗口与高阶整合区域对齐；不同叙事任务提示能引发任务特异性、区域依赖的大脑对齐模式，并在高阶区域引起上下文依赖的片段级调谐变化。
- Conclusion: 长形式叙事电影可作为研究生物相关时间整合和长上下文多模态大语言模型中可解释表征的原则性测试平台，研究揭示了大脑与AI模型在复杂叙事处理中的动态对齐机制。
## cs.NE

### [236] [Stochastic Spiking Neuron Based SNN Can be Inherently Bayesian](https://arxiv.org/abs/2602.07037)
*Huannan Zheng,Jingli Liu,Kezhou Yang*

Main category: cs.NE

TL;DR: 提出SBNN框架，将磁性隧道结器件随机性与随机阈值神经元统一建模，将噪声转化为贝叶斯计算资源，实现高精度、高效训练和强鲁棒性。

- Motivation: 生物神经系统的随机性具有计算优势，但神经形态计算系统的器件变异性通常限制性能。需要将器件随机性转化为计算资源而非障碍。
- Method: 提出脉冲贝叶斯神经网络(SBNN)框架，统一磁性隧道结器件随机性模型和随机阈值神经元模型，利用噪声作为贝叶斯计算资源，采用速率估计方法加速训练。
- Result: SBNN在MNIST上达到99.16%准确率，CIFAR10上94.84%（8位精度）；训练速度提升约20倍；在突触权重噪声下准确率提升67%，输入噪声下提升12%；硬件验证显示物理实现与算法模型几乎无精度损失。
- Conclusion: 将器件随机性转化为神经元不确定性，为紧凑、高能效的不确定性神经形态计算提供了可行路径，实现了噪声从障碍到计算资源的转变。
## cs.MM

### [237] [Federated Prompt-Tuning with Heterogeneous and Incomplete Multimodal Client Data](https://arxiv.org/abs/2602.07081)
*Thu Hang Phung,Duong M. Nguyen,Thanh Trung Huynh,Quoc Viet Hung Nguyen,Trong Nghia Hoang,Phi Le Nguyen*

Main category: cs.MM

TL;DR: 提出一个联邦提示调优框架，用于处理多模态、特征缺失分布不同的本地数据集场景，通过客户端调优和服务器聚合设计优化、对齐和聚合提示指令。

- Motivation: 现有联邦学习和多模态提示调优主要关注单模态或集中式数据，而实际场景中本地数据集往往多模态且输入层特征缺失模式分布不同，需要解决跨客户端相似缺失模式提示指令的语义对齐问题。
- Method: 提出专门的客户端调优和服务器聚合设计，同时优化、对齐和聚合跨客户端和数据模态的提示调优指令，使提示指令能够相互补充并有效结合。
- Result: 在多种多模态基准数据集上的广泛评估表明，该方法始终优于最先进的基线方法。
- Conclusion: 该框架成功填补了联邦学习与多模态提示调优之间的空白，解决了实际场景中多模态、特征缺失分布不同的本地数据集的联邦学习问题。
## cs.CL

### [238] [UReason: Benchmarking the Reasoning Paradox in Unified Multimodal Models](https://arxiv.org/abs/2602.08336)
*Cheng Yang,Chufan Shi,Bo Shui,Yaokang Wu,Muzi Tao,Huijuan Wang,Ivan Yee Lee,Yong Liu,Xuezhe Ma,Taylor Berg-Kirkpatrick*

Main category: cs.CL

TL;DR: UReason是一个诊断性基准测试，用于评估推理在图像生成中的实际效果，揭示了"推理悖论"：推理痕迹通常能提升性能，但将中间思考作为条件上下文反而会阻碍视觉合成。

- Motivation: 当前统一多模态模型采用思维链推理来指导图像生成，但推理对视觉合成的实际效果尚不明确。需要评估推理是否能在像素层面忠实执行。
- Method: 提出了UReason基准测试，包含2,000个实例，涵盖代码、算术、空间、属性和文本推理五个任务家族。引入评估框架比较直接生成、推理引导生成和去上下文化生成（仅基于精炼提示）。
- Result: 在八个开源统一模型中观察到一致的"推理悖论"：推理痕迹通常比直接生成表现更好，但保留中间思考作为条件上下文会阻碍视觉合成，而仅基于精炼提示的条件能带来显著提升。
- Conclusion: 瓶颈在于上下文干扰而非推理能力不足。UReason为研究统一模型中的推理提供了原则性测试平台，并激励未来方法在有效整合推理进行视觉生成的同时减轻干扰。


### [239] [Prism: Spectral-Aware Block-Sparse Attention](https://arxiv.org/abs/2602.08426)
*Xinghao Wang,Pengyu Wang,Xiaoran Liu,Fangxu Liu,Jason Chu,Kai Song,Xipeng Qiu*

Main category: cs.CL

TL;DR: Prism通过频谱感知方法解决块稀疏注意力中块选择不准确的问题，利用能量温度校准恢复位置信息，实现纯块级操作，在保持精度的同时获得5.1倍加速。

- Motivation: 现有块稀疏注意力方法使用粗粒度注意力作为块重要性估计的代理，但通常需要昂贵的token级搜索或评分，导致显著的选择开销。标准粗粒度注意力（通过平均池化）的不准确性源于其与RoPE的相互作用，平均池化作为低通滤波器会破坏高频维度中的局部位置信息。
- Method: 提出Prism方法：1）理论分析表明平均池化与RoPE相互作用会破坏高频维度中的局部位置信息；2）将块选择分解为高频和低频分支；3）应用基于能量的温度校准，直接从池化表示中恢复衰减的位置信号；4）实现纯块级操作的块重要性估计。
- Result: 广泛评估证实Prism在保持与完整注意力精度相当的同时，实现了高达5.1倍的加速。
- Conclusion: Prism通过频谱感知方法有效解决了块稀疏注意力中块选择不准确的问题，通过纯块级操作提高了效率，为长上下文LLM预填充提供了有效的加速方案。
## eess.IV

### [240] [Condition Errors Refinement in Autoregressive Image Generation with Diffusion Loss](https://arxiv.org/abs/2602.07022)
*Yucheng Zhou,Hao Li,Jianbing Shen*

Main category: eess.IV

TL;DR: 本文对扩散模型和自回归扩散模型进行理论分析，提出基于最优传输的条件精炼方法，解决条件不一致问题，实验证明优于现有方法。

- Motivation: 近期研究探索了自回归模型用于图像生成，并将扩散模型与自回归框架结合以通过扩散损失优化图像生成。本文旨在从理论上分析扩散模型和带扩散损失的自回归模型，揭示后者的优势，并解决条件不一致问题。
- Method: 1. 理论分析扩散模型和带扩散损失的自回归模型；2. 提出基于最优传输理论的条件精炼方法，将条件精炼表述为Wasserstein梯度流；3. 通过实验验证方法有效性。
- Result: 理论分析表明：自回归模型中的块去噪优化能有效缓解条件误差，导致稳定的条件分布；自回归条件生成能精炼条件，使条件误差影响呈指数衰减。基于OT的条件精炼方法能确保收敛到理想条件分布，有效缓解条件不一致问题。实验证明该方法优于扩散模型和带扩散损失的自回归模型。
- Conclusion: 本文通过理论分析和实验验证，展示了自回归扩散模型在条件生成中的优势，并提出基于最优传输的条件精炼方法，有效解决了条件不一致问题，为图像生成提供了更优的解决方案。


### [241] [Guidestar-Free Adaptive Optics with Asymmetric Apertures](https://arxiv.org/abs/2602.07029)
*Weiyun Jiang,Haiyun Guo,Christopher A. Metzler,Ashok Veeraraghavan*

Main category: eess.IV

TL;DR: 首个无需导星和波前传感器的闭环自适应光学系统，利用非对称孔径和机器学习实现实时像差校正

- Motivation: 传统自适应光学系统依赖导星和波前传感器，限制了其在自然场景中的应用。本文旨在开发无需导星的实时自适应光学系统，解决自然场景成像中的像差问题
- Method: 结合三个关键要素：1) 光学路径中的非对称孔径实现相位恢复；2) 机器学习算法从自然场景测量估计点扩散函数并重建相位像差；3) 空间光调制器进行光学校正
- Result: 在未知遮挡物的密集自然场景成像实验中验证了该框架，相比最先进的无导星波前整形方法，测量次数减少一个数量级，计算量减少三个数量级
- Conclusion: 成功实现了首个无需导星和波前传感器的闭环自适应光学系统，为自然场景实时像差校正提供了高效解决方案


### [242] [MTS-CSNet: Multiscale Tensor Factorization for Deep Compressive Sensing on RGB Images](https://arxiv.org/abs/2602.07056)
*Mehmet Yamac,Lei Xu,Serkan Kiranyaz,Moncef Gabbouj*

Main category: eess.IV

TL;DR: MTSCSNet提出基于多尺度张量求和分解的压缩感知框架，通过模式线性变换和多尺度求和实现大感受野和跨维度相关性建模，在RGB图像重建中达到SOTA性能。

- Motivation: 现有深度学习方法使用卷积或块状全连接层学习采样算子，感受野受限且对高维数据扩展性差，需要更有效的多维信号处理算子。
- Method: 提出多尺度张量求和分解作为结构化算子，执行模式线性变换和多尺度求和，用于可学习的压缩感知算子（线性降维）和重建阶段直接细化估计，形成简单前馈架构。
- Result: 在标准压缩感知基准测试中，MTSCSNet在RGB图像重建上达到最先进性能，PSNR显著提升且推理更快，即使相比最近的扩散方法，同时使用更紧凑的前馈架构。
- Conclusion: MTSCSNet通过多尺度张量求和分解实现了参数和计算效率高的压缩感知框架，无需迭代或近端优化，在图像重建质量和速度方面均表现出色。


### [243] [U-Net Based Image Enhancement for Short-time Muon Scattering Tomography](https://arxiv.org/abs/2602.07060)
*Haochen Wang,Pei Yu,Liangwen Chen,Weibo He,Yu Zhang,Yuhong Yu,Xueheng Zhang,Lei Yang,Zhiyu Sun*

Main category: eess.IV

TL;DR: 使用U-Net框架增强低统计量μ子散射断层扫描图像质量，显著提升SSIM从0.7232到0.9699，降低LPIPS从0.3604到0.0270

- Motivation: μ子散射断层扫描(MST)是一种有前景的非侵入式检测技术，但实际应用中短时间MST因μ子通量有限导致图像质量差，限制了其实际应用
- Method: 提出基于U-Net的框架，使用模拟MST数据重建的最接近点(PoCA)图像进行训练，用于增强实验MST数据的图像质量
- Result: 框架显著提升了图像质量：结构相似性指数从0.7232提高到0.9699，学习感知图像块相似性从0.3604降低到0.0270
- Conclusion: 该方法能有效增强低统计量MST图像，为短时间MST的实际部署铺平了道路


### [244] [MRI Cross-Modal Synthesis: A Comparative Study of Generative Models for T1-to-T2 Reconstruction](https://arxiv.org/abs/2602.07068)
*Ali Alqutayfi,Sadam Al-Azani*

Main category: eess.IV

TL;DR: 该研究比较了三种生成模型（Pix2Pix GAN、CycleGAN、VAE）在T1到T2 MRI图像合成任务上的性能，发现CycleGAN在PSNR和SSIM指标上表现最佳，而Pix2Pix GAN的MSE最低，VAE则在潜在空间表示方面有优势。

- Motivation: MRI跨模态合成能够减少扫描时间同时保持诊断信息，具有重要临床价值。本研究旨在比较三种先进的生成模型在T1到T2 MRI重建任务上的性能，为研究人员和临床医生提供模型选择的参考依据。
- Method: 使用BraTS 2020数据集（11,439个训练切片和2,000个测试切片），对Pix2Pix GAN、CycleGAN和变分自编码器（VAE）三种生成模型进行系统比较。评估指标包括均方误差（MSE）、峰值信噪比（PSNR）和结构相似性指数（SSIM）。
- Result: 所有模型都能成功从T1输入合成T2图像：CycleGAN获得最高PSNR（32.28 dB）和SSIM（0.9008），Pix2Pix GAN提供最低MSE（0.005846），VAE定量性能较低（MSE: 0.006949，PSNR: 24.95 dB，SSIM: 0.6573）但在潜在空间表示和采样能力方面有优势。
- Conclusion: 这项比较研究为研究人员和临床医生根据特定需求和数据约束选择适当的MRI合成生成模型提供了有价值的见解。不同模型各有优劣，选择应基于具体应用需求。


### [245] [Exploring Polarimetric Properties Preservation during Reconstruction of PolSAR images using Complex-valued Convolutional Neural Networks](https://arxiv.org/abs/2602.07094)
*Quentin Gabot,Joana Frontera-Pons,Jérémy Fix,Chengfang Ren,Jean-Philippe Ovarlez*

Main category: eess.IV

TL;DR: 该论文提出使用复数神经网络处理极化SAR数据，通过复数卷积自编码器有效压缩和重建数据，同时保持物理特性，优于实数神经网络。

- Motivation: 极化SAR数据本质上是复数，但深度学习社区对此探索不足，许多研究将复数信号转换到实数域再处理。需要专门算法直接处理复数表示。
- Method: 采用复数神经网络，研究复数卷积自编码器的性能，用于压缩和重建全极化SAR数据，并通过Pauli、Krogager、Cameron相干分解以及非相干H-α分解验证物理特性保持。
- Result: 复数神经网络能有效压缩和重建极化SAR数据，同时保持重要的物理特性，在多个分解方法中表现良好，且优于实数神经网络。
- Conclusion: 复数神经网络在极化SAR数据处理中具有优势，为开发鲁棒的、物理信息驱动的复数生成模型铺平了道路。


### [246] [Extracting Root-Causal Brain Activity Driving Psychopathology from Resting State fMRI](https://arxiv.org/abs/2602.07233)
*Eric V. Strobl*

Main category: eess.IV

TL;DR: SOURCE方法通过双层因果模型，将症状维度与局部BOLD扰动直接关联，识别根因性神经活动模式，提高了解释性和解剖特异性。

- Motivation: 传统神经影像研究通常将影像模式与诊断标签或综合症状评分关联，导致关联性分散，掩盖了潜在的病理机制。需要识别能够引发病理级联的根因性BOLD扰动，并将其与特定症状维度选择性关联。
- Method: 提出双层结构因果模型，通过具有局部直接效应的独立潜在源，将受试者间的症状结构与受试者内的静息态fMRI连接。基于此模型开发SOURCE方法，将可解释的症状轴与一组简约的局部驱动因素关联。
- Result: 实验表明，SOURCE能够恢复与根因性BOLD驱动一致的局部映射图，相对于现有比较方法，提高了可解释性和解剖特异性。
- Conclusion: SOURCE方法通过识别根因性神经活动模式并将其与特定症状维度关联，为理解精神疾病的神经机制提供了更精确、更具解释性的框架。


### [247] [Wavelet-Domain Masked Image Modeling for Color-Consistent HDR Video Reconstruction](https://arxiv.org/abs/2602.07393)
*Yang Zhang,Zhangkai Ni,Wenhan Yang,Hanli Wang*

Main category: eess.IV

TL;DR: WMNet提出了一种基于小波域掩码图像建模的HDR视频重建网络，采用两阶段训练策略，通过T-MoE和DMM模块提升时间一致性，并在重构的HDRTV4K-Scene数据集上实现SOTA性能。

- Motivation: 现有HDR视频重建方法存在颜色不准确和时间不一致的问题，需要一种能够同时恢复精细亮度、颜色和细节，并保持时间连贯性的解决方案。
- Method: 提出WMNet网络，采用小波域掩码图像建模(W-MIM)进行自重建预训练，使用课程学习策略。第二阶段微调模型。引入T-MoE模块自适应融合相邻帧减少闪烁，DMM模块捕获长距离依赖确保运动平滑。重构HDRTV4K数据集为HDRTV4K-Scene提供场景分割基准。
- Result: WMNet在多个评估指标上达到最先进性能，显著改善了颜色保真度、时间一致性和感知质量。
- Conclusion: WMNet通过小波域掩码建模和两阶段训练策略，结合时间一致性模块，有效解决了HDR视频重建中的颜色不准确和时间不一致问题，为HDR视频重建提供了新的解决方案。


### [248] [Surveillance Facial Image Quality Assessment: A Multi-dimensional Dataset and Lightweight Model](https://arxiv.org/abs/2602.07403)
*Yanwei Jiang,Wei Sun,Yingjie Zhou,Xiangyang Zhu,Yuqin Cao,Jun Jia,Yunhao Li,Sijing Wu,Dandan Zhu,Xingkuo Min,Guangtao Zhai*

Main category: eess.IV

TL;DR: 该论文提出了首个针对监控人脸图像的质量评估研究，构建了包含5004张真实监控图像的基准数据集，并开发了轻量级多任务质量评估模型，在视觉质量和身份保真度方面优于现有方法。

- Motivation: 现有的人脸图像质量评估方法主要关注视觉质量或识别性能，但监控场景需要同时考虑视觉质量和身份保真度。当前缺乏专门针对监控人脸图像的质量评估研究，无法满足监控应用中可靠身份验证的需求。
- Method: 1. 构建SFIQA-Bench基准数据集：包含5004张由三种常用监控摄像头在真实场景中捕获的图像，通过主观实验收集噪声、清晰度、色彩丰富度、对比度、保真度和整体质量六个维度的评分。
2. 提出SFIQA-Assessor模型：轻量级多任务FIQA模型，通过跨视图特征交互利用互补的面部视图信息，使用可学习任务令牌指导多个质量维度的统一回归。
- Result: 在提出的数据集上，SFIQA-Assessor模型在监控人脸图像质量评估任务上表现最佳，优于现有的通用图像质量评估和FIQA方法，验证了其在真实监控应用中的有效性。
- Conclusion: 该研究填补了监控人脸图像质量评估领域的空白，提出的基准数据集和评估模型能够同时考虑视觉质量和身份保真度，为监控应用中可靠的身份验证提供了有效解决方案。


### [249] [DINO-Mix: Distilling Foundational Knowledge with Cross-Domain CutMix for Semi-supervised Class-imbalanced Medical Image Segmentation](https://arxiv.org/abs/2602.07819)
*Xinyu Liu,Guolei Sun*

Main category: eess.IV

TL;DR: 提出DINO-Mix框架，通过外部视觉基础模型DINOv3的知识蒸馏和渐进式类别不平衡感知数据增强，解决医学图像分割中半监督学习在类别不平衡下的确认偏误问题。

- Motivation: 当前半监督学习框架是"内向型"的，仅从目标数据集内部循环利用信息和偏误，在类别不平衡情况下会陷入确认偏误的恶性循环，导致无法识别少数类别。需要打破这种系统性局限。
- Method: 提出多层次"外向型"框架DINO-Mix：1) 基础知识蒸馏(FKD)：引入预训练视觉基础模型DINOv3作为无偏外部语义教师，蒸馏其高语义独特性的理解；2) 渐进式不平衡感知CutMix(PIC)：创建动态课程，自适应地迫使模型关注标记和未标记子集中的少数类别。
- Result: 在具有挑战性的半监督类别不平衡医学图像分割基准测试Synapse和AMOS上取得了显著性能提升，打破了偏误的恶性循环。
- Conclusion: 通过向外寻找外部基础模型知识和数据内部增强策略，DINO-Mix框架成功解决了半监督学习在医学图像分割中的类别不平衡问题，为相关领域提供了新的范式。


### [250] [A Unified Framework for Multimodal Image Reconstruction and Synthesis using Denoising Diffusion Models](https://arxiv.org/abs/2602.08249)
*Weijie Gan,Xucheng Wang,Tongyao Wang,Wenshang Wang,Chunwei Ying,Yuyang Hu,Yasheng Chen,Hongyu An,Ulugbek S. Kamilov*

Main category: eess.IV

TL;DR: Any2all是一个统一的图像重建与合成框架，将多模态成像任务转化为虚拟修复问题，使用单一无条件扩散模型处理任意输入组合

- Motivation: 现有方法需要针对不同任务训练多个专用模型，增加了训练和部署的复杂性，需要一种统一框架来处理不完整多模态成像数据
- Method: 将多模态图像重建和合成任务统一为虚拟修复问题，在完整多模态数据栈上训练单一无条件扩散模型，推理时通过"修复"方式从任意可用输入生成目标模态
- Result: 在PET/MR/CT脑部数据集上验证，Any2all在多模态重建和合成任务上均表现出色，在失真度指标上具有竞争力，在感知质量上优于专用方法
- Conclusion: Any2all提供了一个统一的解决方案，能够用单一模型处理多种多模态成像任务，简化了工作流程并保持了高质量输出


### [251] [Efficient Brain Extraction of MRI Scans with Mild to Moderate Neuropathology](https://arxiv.org/abs/2602.08764)
*Hjalti Thrastarson,Lotta M. Ellingsen*

Main category: eess.IV

TL;DR: 提出一种基于改进U-net和符号距离变换损失函数的鲁棒性头骨剥离方法，用于T1加权MRI图像，能一致性地分割大脑外表面并排除蛛网膜下腔。

- Motivation: 现有头骨剥离方法在神经病理学存在时容易失败，且在大脑掩模边界定义上不一致，需要一种更鲁棒和一致的方法来准确分割大脑外表面。
- Method: 使用改进的U-net架构，基于银标准ground truth数据训练，采用基于符号距离变换(SDT)的新型损失函数，旨在一致分割大脑外表面（包括脑沟脑脊液）并排除蛛网膜下腔和脑膜。
- Result: 在保留测试数据上获得平均Dice相似系数0.964±0.006和平均对称表面距离1.4mm±0.2mm；在外部数据集上获得DSC 0.958±0.006和ASSD 1.7±0.2mm，性能与现有最先进方法相当或更好。
- Conclusion: 该方法在头骨剥离任务中表现出色，特别是在大脑外表面的一致性保留方面，代码已在GitHub上公开。
