[[toc]]

## cs.CV

### [1] [EfficientQuant: An Efficient Post-Training Quantization for CNN-Transformer Hybrid Models on Edge Devices](https://arxiv.org/abs/2506.11093)
*Shaibal Saha,Lanyu Xu*

Main category: cs.CV

TL;DR: EfficientQuant是一种针对混合模型的结构感知后训练量化方法，显著降低延迟并保持精度。

- Motivation: 混合模型在计算机视觉任务中表现优异，但资源消耗大，后训练量化在混合模型中的应用有限。
- Method: 采用均匀量化处理卷积块，对数量化处理Transformer块。
- Result: 在ImageNet-1K数据集上实现2.5倍至8.7倍的延迟降低，精度损失极小。
- Conclusion: EfficientQuant在边缘设备上表现出低延迟和高内存效率，适合实际部署。


### [2] [Adaptive Object Detection with ESRGAN-Enhanced Resolution & Faster R-CNN](https://arxiv.org/abs/2506.11122)
*Divya Swetha K,Ziaul Haque Choudhury,Hemanta Kumar Bhuyan,Biswajit Brahma,Nilayam Kumar Kamila*

Main category: cs.CV

TL;DR: 提出了一种结合ESRGAN和Faster R-CNN的方法，用于提升低分辨率图像中的目标检测性能。

- Motivation: 解决低分辨率图像中目标检测性能下降的问题，提供一种适用于图像质量不一致场景的解决方案。
- Method: 使用ESRGAN作为预处理步骤增强图像质量，再通过Faster R-CNN进行目标检测。
- Result: 实验表明，该方法在低分辨率图像上的检测性能优于传统方法。
- Conclusion: 该框架在图像质量受限的场景下提供了更鲁棒的目标检测解决方案。


### [3] [Technical Report for Argoverse2 Scenario Mining Challenges on Iterative Error Correction and Spatially-Aware Prompting](https://arxiv.org/abs/2506.11124)
*Yifei Chen,Ross Greer*

Main category: cs.CV

TL;DR: 论文提出了一种改进的RefAV框架，通过迭代代码生成和专用提示工程，解决了LLM生成代码的运行时错误和空间关系函数参数不准确的问题，显著提升了场景挖掘的精度。

- Motivation: 从大规模自动驾驶数据集中挖掘场景对开发和验证自动驾驶系统至关重要，但现有方法存在LLM生成代码的运行时错误和空间关系函数参数不准确的问题。
- Method: 引入两种改进：1）容错的迭代代码生成机制，通过错误反馈重新提示LLM优化代码；2）专用提示工程，提升LLM对空间关系函数的理解和正确应用。
- Result: 在Argoverse 2验证集上的实验显示，使用不同LLM（如Qwen2.5-VL-7B、Gemini 2.5 Flash和Gemini 2.5 Pro）均取得一致提升，Gemini 2.5 Pro在官方测试集上的HOTA-Temporal得分为52.37。
- Conclusion: 提出的技术显著提高了场景挖掘的可靠性和精度，为自动驾驶系统的开发和验证提供了有效支持。


### [4] [Image-Based Method For Measuring And Classification Of Iron Ore Pellets Using Star-Convex Polygons](https://arxiv.org/abs/2506.11126)
*Artem Solomko,Oleg Kartashev,Andrey Golov,Mikhail Deulin,Vadim Valynkin,Vasily Kharin*

Main category: cs.CV

TL;DR: 研究提出了一种基于StarDist算法的图像测量方法，用于铁矿石球团的分类和质量检测，解决了传统方法在密集和不稳定环境中的不足。

- Motivation: 准确识别和分析密集且不稳定环境中的物体，以提升铁矿石球团的质量分类和尺寸测量精度。
- Method: 采用StarDist算法进行物体分割、轮廓确定、分类和尺寸测量，解决了传统图像分类和实例分割方法的局限性。
- Result: 开发了一种新方法，能够检测边界平滑的物体，显著提高了尺寸测量的准确性和球团大小分布的分析精度。
- Conclusion: 通过StarDist算法，研究为复杂的球团分类和测量问题提供了有效的解决方案。


### [5] [Segment This Thing: Foveated Tokenization for Efficient Point-Prompted Segmentation](https://arxiv.org/abs/2506.11131)
*Tanner Schmidt,Richard Newcombe*

Main category: cs.CV

TL;DR: STT是一种高效图像分割模型，通过聚焦输入图像和使用可变分辨率补丁标记化减少计算成本，同时保持模型大小。

- Motivation: 提高图像分割效率，避免通过减小模型规模来提升效率的传统方法。
- Method: 使用聚焦输入图像和可变分辨率补丁标记化，减少图像标记数量。
- Result: STT在保持分割性能的同时显著降低计算成本，适用于交互式应用。
- Conclusion: STT是一种高效且实用的工具，适用于增强现实和机器人应用。


### [6] [Gender Fairness of Machine Learning Algorithms for Pain Detection](https://arxiv.org/abs/2506.11132)
*Dylan Green,Yuting Shang,Jiaee Cheong,Yang Liu,Hatice Gunes*

Main category: cs.CV

TL;DR: 论文研究了基于机器学习和深度学习的自动疼痛检测模型在性别公平性上的表现，发现所有模型均存在性别偏见，强调了在医疗系统中平衡准确性与公平性的重要性。

- Motivation: 自动疼痛检测在医疗领域潜力巨大，但现有算法在不同人口群体（如性别）中的准确性和公平性研究不足。
- Method: 使用UNBC-McMaster Shoulder Pain Expression Archive Database，比较了传统ML算法（L SVM、RBF SVM）和DL方法（CNN、ViT）的性能与公平性。
- Result: ViT在准确性和部分公平性指标上表现最佳，但所有模型均显示性别偏见。
- Conclusion: 研究揭示了准确性与公平性之间的权衡，需采用公平性感知技术以减少医疗系统中的偏见。


### [7] [Monocular 3D Hand Pose Estimation with Implicit Camera Alignment](https://arxiv.org/abs/2506.11133)
*Christos Pantazopoulos,Spyridon Thermos,Gerasimos Potamianos*

Main category: cs.CV

TL;DR: 提出了一种从2D关键点输入估计3D手部关节的优化流程，无需相机参数知识，并在多个基准测试中表现优异。

- Motivation: 解决单张彩色图像中3D手部关节估计的挑战，如深度信息缺失、遮挡和关节复杂性。
- Method: 采用关键点对齐步骤和指尖损失函数，避免对相机参数的依赖。
- Result: 在EgoDexter和Dexter+Object基准测试中表现优异，且对“野外”图像具有鲁棒性。
- Conclusion: 该方法在无需相机参数的情况下实现了与SotA竞争的性能，但2D关键点估计精度对结果敏感。


### [8] [ContextLoss: Context Information for Topology-Preserving Segmentation](https://arxiv.org/abs/2506.11134)
*Benedict Schacht,Imke Greving,Simone Frintrop,Berit Zeller-Plumhoff,Christian Wilms*

Main category: cs.CV

TL;DR: 提出了一种新的损失函数ContextLoss（CLoss），通过考虑关键像素掩码中的拓扑错误及其上下文，提高了图像分割的拓扑正确性。

- Motivation: 在图像分割中，保持分割结构（如血管、膜或道路）的拓扑结构至关重要，因为拓扑错误（如道路网络中的错误）会严重影响导航。
- Method: 提出了CLoss损失函数，通过考虑关键像素掩码中的拓扑错误及其上下文，改进拓扑正确性；同时提出了两种直观的指标来验证连通性的改进。
- Result: 在三个公共数据集（2D和3D）及自有的3D纳米成像数据集上验证，CLoss在拓扑感知指标上表现更优，修复了比其他先进方法多44%的缺失连接。
- Conclusion: CLoss显著提升了拓扑正确性，修复了更多缺失连接，代码已公开。


### [9] [JAFAR: Jack up Any Feature at Any Resolution](https://arxiv.org/abs/2506.11136)
*Paul Couairon,Loick Chambon,Louis Serrano,Jean-Emmanuel Haugeard,Matthieu Cord,Nicolas Thome*

Main category: cs.CV

TL;DR: JAFAR是一种轻量级、灵活的特征上采样器，能够将基础视觉编码器的低分辨率特征提升到任意目标分辨率，无需高分辨率监督即可泛化到更高输出尺度。

- Motivation: 基础视觉编码器的低分辨率特征输出需要上采样以满足下游任务的高分辨率需求，现有方法效果有限。
- Method: JAFAR采用基于注意力的模块，通过空间特征变换（SFT）调制，将高分辨率查询与语义丰富的低分辨率键对齐。
- Result: 实验表明，JAFAR能有效恢复细粒度空间细节，并在多种下游任务中优于现有方法。
- Conclusion: JAFAR是一种高效的特征上采样解决方案，适用于广泛的下游任务。


### [10] [Autonomous Computer Vision Development with Agentic AI](https://arxiv.org/abs/2506.11140)
*Jin Kim,Muhammad Wahi-Anwa,Sangyun Park,Shawn Shin,John M. Hoffman,Matthew S. Brown*

Main category: cs.CV

TL;DR: 论文展示了一种基于Agentic AI方法的自主构建计算机视觉系统的能力，通过自然语言提示生成SimpleMind工作流，实现肺部、心脏和肋骨的分割任务。

- Motivation: 探索Agentic AI系统在复杂推理、规划和工具利用方面的潜力，特别是在医学图像分析领域的应用。
- Method: 扩展SimpleMind（SM）环境，结合LLM代理（OpenManus），通过自然语言提示自动生成工具配置（YAML文件），并执行训练和推理脚本。
- Result: 系统在50张胸部X光图像上自动配置、训练和测试，肺部、心脏和肋骨的Dice分数分别为0.96、0.82和0.83。
- Conclusion: 研究表明Agentic AI能够自主完成传统上由数据科学家执行的规划和工具配置任务，为计算机视觉应用开发提供了新方向。


### [11] [FARCLUSS: Fuzzy Adaptive Rebalancing and Contrastive Uncertainty Learning for Semi-Supervised Semantic Segmentation](https://arxiv.org/abs/2506.11142)
*Ebenezer Tarubinga,Jenifer Kalafatovich*

Main category: cs.CV

TL;DR: 提出了一种新的半监督语义分割框架，通过模糊伪标签、不确定性感知动态加权、自适应类别再平衡和轻量级对比正则化，有效利用未标记数据并提升分割性能。

- Motivation: 解决半监督语义分割中未标记数据利用率低、类别不平衡偏差加剧以及预测不确定性被忽视的问题。
- Method: 采用模糊伪标签、不确定性感知动态加权、自适应类别再平衡和轻量级对比正则化四种组件。
- Result: 在基准测试中表现优于现有方法，显著提升了低代表性类别和模糊区域的分割效果。
- Conclusion: 该框架通过将不确定性转化为学习资源，有效提升了半监督语义分割的性能。


### [12] [On the development of an AI performance and behavioural measures for teaching and classroom management](https://arxiv.org/abs/2506.11143)
*Andreea I. Niculescu,Jochen Ehnen,Chen Yi,Du Jiawei,Tay Chiat Pin,Joey Tianyi Zhou,Vigneshwaran Subbaraju,Teh Kah Kuan,Tran Huy Dat,John Komar,Gi Soong Chee,Kenneth Kwok*

Main category: cs.CV

TL;DR: 该论文介绍了一个为期两年的研究项目，利用AI技术分析课堂动态，重点是通过多模态传感器数据捕捉教师行为，并开发了支持教师发展的工具。

- Motivation: 研究旨在通过AI技术减轻人工分析负担，提供客观的课堂互动数据，帮助教师改进教学策略。
- Method: 利用实时课堂传感器数据和AI技术，提取有意义的行为指标，并开发了一个教学回顾仪表盘。
- Result: 生成了一个音频-视觉数据集、新的行为测量指标，并通过初步评估验证了系统的清晰性和实用性。
- Conclusion: 该系统为教师提供了非评判性的自动化分析，支持教学改进，并为AI教育分析领域贡献了文化背景相关的方法。


### [13] [AlignHuman: Improving Motion and Fidelity via Timestep-Segment Preference Optimization for Audio-Driven Human Animation](https://arxiv.org/abs/2506.11144)
*Chao Liang,Jianwen Jiang,Wang Liao,Jiaqi Yang,Zerong zheng,Weihong Zeng,Han Liang*

Main category: cs.CV

TL;DR: AlignHuman框架通过偏好优化和分治训练策略，优化了人类视频生成中运动自然性和视觉保真度的权衡，实现了3.3倍的速度提升。

- Motivation: 当前人类视频生成在运动自然性和视觉保真度之间存在权衡，难以同时优化。
- Method: 提出AlignHuman框架，结合偏好优化和分治策略，利用时间步分段偏好优化（TPO）和专用LoRAs模块。
- Result: 实验表明AlignHuman显著提升基线性能，推理速度提升3.3倍（从100 NFEs降至30 NFEs），且生成质量影响极小。
- Conclusion: AlignHuman通过分治策略和偏好优化，有效解决了人类视频生成中的关键挑战，实现了高效高质量的生成。


### [14] [3D-RAD: A Comprehensive 3D Radiology Med-VQA Dataset with Multi-Temporal Analysis and Diverse Diagnostic Tasks](https://arxiv.org/abs/2506.11147)
*Xiaotang Gai,Jiaxiang Liu,Yichen Li,Zijie Meng,Jian Wu,Zuozhu Liu*

Main category: cs.CV

TL;DR: 3D-RAD是一个基于CT扫描的大规模3D医学视觉问答数据集，支持多样化的任务和复杂推理，旨在推动3D医学视觉理解的研究。

- Motivation: 现有Med-VQA研究主要集中在2D影像且任务多样性有限，3D-RAD旨在填补这一空白，提供更全面的3D医学视觉问答基准。
- Method: 构建了包含六种任务的3D-RAD数据集，支持开放和封闭问题，并引入复杂推理任务（如计算和多阶段时间分析）。
- Result: 评估显示现有视觉语言模型（尤其是医学VLM）在3D多时间任务中泛化能力有限，但微调3D-RAD-T数据集可显著提升性能。
- Conclusion: 3D-RAD为多模态医学AI研究提供了高质量数据，推动了3D医学视觉理解的进展。


### [15] [LLM-to-Phy3D: Physically Conform Online 3D Object Generation with LLMs](https://arxiv.org/abs/2506.11148)
*Melvin Wong,Yueming Lyu,Thiago Rios,Stefan Menzel,Yew-Soon Ong*

Main category: cs.CV

TL;DR: LLM-to-Phy3D是一种新型方法，通过结合视觉和物理评估，使大型语言模型（LLMs）生成符合物理约束的3D对象，显著提升了生成设计的物理性能。

- Motivation: 现有LLM-to-3D模型缺乏物理知识，导致生成的3D对象脱离现实物理约束，限制了其在工程设计中的应用。
- Method: 提出LLM-to-Phy3D，采用在线黑盒细化循环，通过迭代反馈优化提示，生成物理性能更强的3D对象。
- Result: 在车辆设计优化中，LLM-to-Phy3D比传统模型提升了4.5%至106.7%的物理符合性。
- Conclusion: LLM-to-Phy3D为科学和工程应用中的物理AI提供了潜在通用解决方案。


### [16] [Self-Calibrating BCIs: Ranking and Recovery of Mental Targets Without Labels](https://arxiv.org/abs/2506.11151)
*Jonathan Grizou,Carlos de la Torre-Ortiz,Tuukka Ruotsalo*

Main category: cs.CV

TL;DR: 论文提出了一种名为CURSOR的算法，首次实现了无需标注数据或预训练解码器的情况下，从EEG和图像数据中恢复未知心理目标。

- Motivation: 研究动机是解决在无标注数据的情况下，如何从EEG和图像数据中恢复心理目标的问题，此前的研究依赖于标注数据。
- Method: 方法是通过自校准框架CURSOR，利用EEG和图像数据学习恢复未知心理目标，无需标注信息或预训练解码器。
- Result: 实验结果表明，CURSOR能预测与人类感知判断相关的图像相似度分数，并生成与心理目标无法区分的新刺激。
- Conclusion: 结论是CURSOR为无标注数据下的心理目标恢复提供了有效解决方案。


### [17] [SLRNet: A Real-Time LSTM-Based Sign Language Recognition System](https://arxiv.org/abs/2506.11154)
*Sharvari Kamble*

Main category: cs.CV

TL;DR: SLRNet是一个基于MediaPipe Holistic和LSTM网络的实时手语识别系统，用于识别ASL字母和功能词，验证准确率为86.7%。

- Motivation: 解决听力障碍群体与社会的沟通障碍。
- Method: 使用MediaPipe Holistic和LSTM网络处理视频流，实现实时识别。
- Result: 验证准确率达到86.7%。
- Conclusion: SLRNet展示了硬件无关的包容性手势识别的可行性。


### [18] [Evaluating Multimodal Large Language Models on Video Captioning via Monte Carlo Tree Search](https://arxiv.org/abs/2506.11155)
*Linhao Yu,Xinguang Ji,Yahui Liu,Fanheng Kong,Chenxi Sun,Jingyuan Zhang,Hongzhi Zhang,V. W.,Fuzheng Zhang,Deyi Xiong*

Main category: cs.CV

TL;DR: 论文提出了一种名为AutoCaption的自动框架，利用蒙特卡洛树搜索（MCTS）生成多样化的视频描述句子，以解决现有视频字幕评测的不足。

- Motivation: 现有视频字幕评测存在关键点不足、数据创建成本高和评测范围有限的问题。
- Method: 采用蒙特卡洛树搜索（MCTS）迭代生成多样化描述句子，构建细粒度视频字幕评测基准MCTS-VCB。
- Result: 在MCTS-VCB上评测了20多个MLLMs，Gemini-1.5-Pro得分最高（F1=71.2）。通过AutoCaption生成的数据微调InternVL2.5-8B，性能显著提升。
- Conclusion: AutoCaption能有效提升视频字幕评测的全面性，并增强模型性能。


### [19] [Digitization of Document and Information Extraction using OCR](https://arxiv.org/abs/2506.11156)
*Rasha Sinha,Rekha B S*

Main category: cs.CV

TL;DR: 提出了一种结合OCR和LLM的文本提取框架，显著提升了传统方法的灵活性和语义精度。

- Motivation: 从扫描图像和数字格式文档中准确提取信息的需求日益增长，传统方法在灵活性和语义理解上存在不足。
- Method: 使用OCR处理扫描文件，布局感知库解析数字文件，LLM分析提取的文本以识别关键信息并消除歧义。
- Result: 通过比较不同OCR工具，证明了该方法在准确性、布局识别和处理速度上的优势。
- Conclusion: 该框架在多种文档类型中表现优异，优于传统的基于规则和模板的方法。


### [20] [VIBE: Can a VLM Read the Room?](https://arxiv.org/abs/2506.11162)
*Tania Chakraborty,Eylon Caplan,Dan Goldwasser*

Main category: cs.CV

TL;DR: 论文探讨了视觉语言模型（VLMs）在社会推理中的能力，发现其存在视觉社会-语用推理的局限性，并提出新任务和数据集进行测试。

- Motivation: 理解人类社交行为（如情绪识别和社会动态）是一个重要但具有挑战性的问题，现有LLMs局限于文本领域，无法捕捉非语言线索的作用。
- Method: 提出新任务“视觉社会-语用推理”，构建高质量数据集，并测试多个VLMs的性能。
- Result: 发现VLMs在视觉社会-语用推理方面存在局限性。
- Conclusion: VLMs在社交推理中仍有改进空间，需进一步研究以填补这一能力缺口。


### [21] [Synthetic Geology -- Structural Geology Meets Deep Learning](https://arxiv.org/abs/2506.11164)
*Simon Ghyselincks,Valeriia Okhmak,Stefano Zampini,George Turkiyyah,David Keyes,Eldad Haber*

Main category: cs.CV

TL;DR: 利用深度学习生成合成数据填补地下数据空白，通过神经网络从地表地质数据生成3D地下图像。

- Motivation: 解决地下数据稀缺问题，推动资源勘探、灾害评估等应用。
- Method: 结合生成式AI和合成数据生成器，训练神经网络从地表数据推断地下结构。
- Result: 模型能生成高保真3D地下图像，随钻孔数据增加精度提升。
- Conclusion: 该方法为资源勘探等应用提供新工具，未来可通过区域数据微调优化。


### [22] [Evaluating BiLSTM and CNN+GRU Approaches for Human Activity Recognition Using WiFi CSI Data](https://arxiv.org/abs/2506.11165)
*Almustapha A. Wakili,Babajide J. Asaju,Woosub Jung*

Main category: cs.CV

TL;DR: 比较BiLSTM和CNN+GRU在WiFi CSI数据集上的性能，CNN+GRU在UT-HAR表现更好，BiLSTM在NTU-Fi HAR更优，强调数据集特性和预处理的重要性。

- Motivation: 探索不同深度学习模型在WiFi CSI数据上的活动识别性能，以提升模型选择和实际应用效果。
- Method: 使用BiLSTM和CNN+GRU模型在UT-HAR和NTU-Fi HAR数据集上进行实验。
- Result: CNN+GRU在UT-HAR准确率95.20%，BiLSTM在NTU-Fi HAR准确率92.05%。
- Conclusion: 数据集特性和预处理对模型性能至关重要，模型在医疗和智能家居中有实际应用潜力。


### [23] [Test-Time-Scaling for Zero-Shot Diagnosis with Visual-Language Reasoning](https://arxiv.org/abs/2506.11166)
*Ji Young Byun,Young-Jin Park,Navid Azizan,Rama Chellappa*

Main category: cs.CV

TL;DR: 提出了一种零样本框架，通过测试时缩放增强大语言模型（LLMs）在医学影像诊断中的推理能力，提高诊断准确性。

- Motivation: 临床决策对患者结果至关重要，但LLMs在医学影像视觉问答中的应用尚未充分探索，且监督微调因数据有限和标注成本高而不实用。
- Method: 结合视觉语言模型和LLM，通过测试时缩放整合多个候选输出生成可靠诊断。
- Result: 在多模态医学影像中验证了方法的有效性，提高了诊断准确性和分类可靠性。
- Conclusion: 该方法通过无偏提示和测试时缩放，显著提升了LLM在临床诊断中的可靠性和准确性。


### [24] [Towards a general-purpose foundation model for fMRI analysis](https://arxiv.org/abs/2506.11167)
*Cheng Wang,Yu Jiang,Zhihao Peng,Chenxin Li,Changbae Bang,Lin Zhao,Jinglei Lv,Jorge Sepulcre,Carl Yang,Lifang He,Tianming Liu,Daniel Barron,Quanzheng Li,Randy Hirschtick,Byung-Hoon Kim,Xiang Li,Yixuan Yuan*

Main category: cs.CV

TL;DR: NeuroSTORM是一个通用框架，直接从4D fMRI数据学习，解决了现有方法的可重复性和可迁移性问题。

- Motivation: 当前fMRI分析方法因复杂的预处理和任务特定模型而面临可重复性和可迁移性问题。
- Method: NeuroSTORM采用Mamba骨干和移位扫描策略处理4D fMRI数据，提出空间-时间优化预训练和任务特定提示调优。
- Result: 在五个任务中表现优于现有方法，展示了在临床数据集上的强实用性。
- Conclusion: NeuroSTORM为fMRI临床研究提供了标准化、开源的基础模型，提升了可重复性和可迁移性。


### [25] [WaveFormer: A Lightweight Transformer Model for sEMG-based Gesture Recognition](https://arxiv.org/abs/2506.11168)
*Yanlong Chen,Mattia Orlandi,Pierangelo Maria Rapa,Simone Benatti,Luca Benini,Yawei Li*

Main category: cs.CV

TL;DR: 论文提出了一种轻量级Transformer架构WaveFormer，用于解决sEMG手势识别中相似手势分类的挑战，通过结合时域和频域特征，实现了高效且紧凑的模型。

- Motivation: 传统深度学习模型在sEMG手势识别中计算量大且难以部署于资源受限的嵌入式系统，同时相似手势的分类准确率较低。
- Method: 提出WaveFormer，结合可学习小波变换和多级小波分解层WaveletConv，提取时域和频域特征。
- Result: 模型仅310万参数，在EPN612数据集上达到95%分类准确率，INT8量化后在Intel CPU上实现6.75毫秒推理延迟。
- Conclusion: WaveFormer在轻量化和高效性上表现优异，适合实时部署。


### [26] [Teaching in adverse scenes: a statistically feedback-driven threshold and mask adjustment teacher-student framework for object detection in UAV images under adverse scenes](https://arxiv.org/abs/2506.11175)
*Hongyu Chen,Jiping Liu,Yong Wang,Jun Zhu,Dejun Feng,Yakun Xie*

Main category: cs.CV

TL;DR: 该论文提出了一种名为SF-TMAT的无监督域适应方法，用于无人机在恶劣场景下的目标检测，通过动态调整掩码比和伪标签阈值来提升性能。

- Motivation: 现有UDA方法主要基于自然图像或清晰无人机图像，对恶劣条件下的无人机图像研究不足，且现有方法在特征对齐和伪标签质量上存在问题。
- Method: 提出SF-TMAT框架，包括DSFMA（动态调整掩码比和特征重建）和VFST（动态调整伪标签阈值）。
- Result: 实验表明SF-TMAT在恶劣场景下的无人机目标检测中表现出色，具有优越性和泛化能力。
- Conclusion: SF-TMAT为恶劣场景下的无人机目标检测提供了有效解决方案，并通过动态调整策略提升了性能。


### [27] [BrainMAP: Multimodal Graph Learning For Efficient Brain Disease Localization](https://arxiv.org/abs/2506.11178)
*Nguyen Linh Dan Le,Jing Ren,Ciyuan Peng,Chengyao Xie,Bowen Li,Feng Xia*

Main category: cs.CV

TL;DR: BrainMAP是一种新型多模态图学习框架，专注于高效识别神经退行性疾病相关脑区，显著降低计算开销。

- Motivation: 现有图学习方法无法精确定位神经退行性疾病相关的脑区，且多模态脑图模型计算复杂度高，限制了实际应用。
- Method: BrainMAP采用AAL图谱驱动的过滤方法提取关键脑子图，并结合跨节点注意力和自适应门控机制融合fMRI和DTI数据。
- Result: 实验表明，BrainMAP在计算效率上优于现有方法，且不牺牲预测准确性。
- Conclusion: BrainMAP为神经退行性疾病的精准识别提供了一种高效且实用的解决方案。


### [28] [Enhanced Vehicle Speed Detection Considering Lane Recognition Using Drone Videos in California](https://arxiv.org/abs/2506.11239)
*Amirali Ataee Naeini,Ashkan Teymouri,Ghazaleh Jafarsalehi,Michael Zhang*

Main category: cs.CV

TL;DR: 该研究提出了一种基于YOLOv11的改进模型，用于提高车辆速度和车道检测的准确性，特别针对加州交通监控需求。

- Motivation: 加州车辆数量增加，交通系统不足和测速摄像头稀疏，需要更有效的车辆速度检测方法，尤其是区分车道和车辆类型。
- Method: 研究使用改进的YOLOv11模型，训练了800张鸟瞰图，检测车辆速度和车道，并分类为轿车和重型车辆。
- Result: 模型在测试中表现优异，平均绝对误差为0.97 mph，均方误差为0.94 mph²。
- Conclusion: 改进的YOLOv11模型在车辆速度和分类检测中表现高效，适用于交通监控和法规执行。


### [29] [Lifting Data-Tracing Machine Unlearning to Knowledge-Tracing for Foundation Models](https://arxiv.org/abs/2506.11253)
*Yuwen Tan,Boqing Gong*

Main category: cs.CV

TL;DR: 提出将数据追踪的机器遗忘提升为针对基础模型的知识追踪遗忘，以满足多样化的遗忘需求，并更接近人类大脑的遗忘方式。

- Motivation: 基础模型的多样化遗忘需求（如监管机构、企业用户等）无法通过数据追踪满足，而知识追踪遗忘更符合实际需求和认知研究。
- Method: 提出知识追踪遗忘范式，并通过视觉语言基础模型的具体案例说明其实施方式。
- Result: 知识追踪遗忘更灵活且接近人类遗忘机制，适用于基础模型的多样化需求。
- Conclusion: 知识追踪遗忘是基础模型机器遗忘的可行方向，具有实际应用潜力。


### [30] [TARDIS STRIDE: A Spatio-Temporal Road Image Dataset for Exploration and Autonomy](https://arxiv.org/abs/2506.11302)
*Héctor Carrión,Yutong Bai,Víctor A. Hernández Castro,Kishan Panaganti,Ayush Zenith,Matthew Trang,Tony Zhang,Pietro Perona,Jitendra Malik*

Main category: cs.CV

TL;DR: 论文介绍了STRIDE数据集和TARDIS模型，用于建模时空动态，提升智能体的环境理解和行为表现。

- Motivation: 现实世界环境具有时空动态变化的复杂性，需要新的方法来捕捉这些动态关系。
- Method: 通过STRIDE数据集将360度全景图像转化为观察、状态和动作节点，并开发TARDIS模型（基于Transformer的生成世界模型）进行训练。
- Result: 模型在可控图像合成、指令跟随、自主控制和地理定位等任务中表现优异。
- Conclusion: 该方法为开发具备时空理解能力的通用智能体提供了有前景的方向。


### [31] [HyBiomass: Global Hyperspectral Imagery Benchmark Dataset for Evaluating Geospatial Foundation Models in Forest Aboveground Biomass Estimation](https://arxiv.org/abs/2506.11314)
*Aaron Banze,Timothée Stassin,Nassim Ait Ali Braham,Rıdvan Salih Kuzu,Simon Besnard,Michael Schmitt*

Main category: cs.CV

TL;DR: 本文介绍了一个全球分布的高光谱数据集，用于评估地理空间基础模型（Geo-FMs）在森林地上生物量（AGB）估计任务中的表现。实验表明，Geo-FMs在某些情况下优于基线U-Net模型，并强调了数据集规模和视觉Transformer的token patch大小对性能的影响。

- Motivation: 现有基准数据集多局限于特定地理区域或任务类型，缺乏全球分布的高光谱数据集，限制了Geo-FMs的全面评估。
- Method: 通过结合EnMAP卫星的高光谱影像和GEDI激光雷达的AGB密度估计，构建了一个覆盖七大洲的像素级回归任务数据集。
- Result: 实验显示，Geo-FMs在部分情况下表现优于U-Net，性能差异与数据集规模和Transformer的token patch大小相关。
- Conclusion: 发布该数据集旨在促进Geo-FMs在高光谱应用中的发展和评估，并支持地理偏差和泛化能力的研究。


### [32] [GynSurg: A Comprehensive Gynecology Laparoscopic Surgery Dataset](https://arxiv.org/abs/2506.11356)
*Sahar Nasirihaghighi,Negin Ghamsarian,Leonie Peschek,Matteo Munari,Heinrich Husslein,Raphael Sznitman,Klaus Schoeffmann*

Main category: cs.CV

TL;DR: GynSurg是一个大规模、多任务的妇科腹腔镜手术数据集，旨在解决现有数据集的局限性，支持手术场景理解和动作识别等任务。

- Motivation: 现有妇科腹腔镜手术数据集规模小、任务单一或注释不足，限制了全面工作流分析的实用性。
- Method: 引入GynSurg数据集，提供丰富的多任务注释，并基于标准化训练协议对先进模型进行基准测试。
- Result: GynSurg展示了高质量和多功能性，支持动作识别、语义分割等多种应用。
- Conclusion: GynSurg的公开发布旨在推动妇科腹腔镜手术领域的进步。


### [33] [A Watermark for Auto-Regressive Image Generation Models](https://arxiv.org/abs/2506.11371)
*Yihan Wu,Xuehao Cui,Ruibo Chen,Georgios Milis,Heng Huang*

Main category: cs.CV

TL;DR: 本文提出了一种名为C-reweight的新型无失真水印方法，专为图像生成模型设计，解决了传统水印技术中的retokenization mismatch问题。

- Motivation: 图像生成模型的快速发展带来了潜在的滥用风险（如深度伪造、钓鱼攻击等），因此需要可靠的验证机制。传统水印技术因retokenization mismatch问题难以直接应用于图像生成模型。
- Method: 提出C-reweight方法，采用基于聚类的策略，将同一聚类内的token视为等效，从而解决retokenization mismatch问题，同时保持图像质量。
- Result: 在主流图像生成平台上的评估表明，C-reweight不仅保持了生成图像的视觉质量，还提高了水印的可检测性，优于现有无失真水印技术。
- Conclusion: C-reweight为安全可靠的图像合成设定了新标准，解决了图像生成模型中的水印技术难题。


### [34] [Scalable Context-Preserving Model-Aware Deep Clustering for Hyperspectral Images](https://arxiv.org/abs/2506.11377)
*Xianlu Li,Nicolas Nadisic,Shaoguang Huang,Nikos Deligiannis,Aleksandra Pižurica*

Main category: cs.CV

TL;DR: 提出了一种基于基表示的、可扩展且保留上下文信息的深度聚类方法，用于高效的高光谱图像聚类，同时捕捉局部和非局部结构。

- Motivation: 现有方法计算复杂度高（O(n^2)），且仅关注局部或非局部结构约束，无法有效监督整个聚类过程。
- Method: 采用一阶段框架，结合空间平滑约束（局部结构）和基于小簇的方案（非局部结构），联合优化。
- Result: 时间和空间复杂度为O(n)，适用于大规模数据，实验表明优于现有技术。
- Conclusion: 该方法高效且性能优越，适用于高光谱图像聚类。


### [35] [Enhance Multimodal Consistency and Coherence for Text-Image Plan Generation](https://arxiv.org/abs/2506.11380)
*Xiaoxin Lu,Ranran Haoran Zhang,Yusen Zhang,Rui Zhang*

Main category: cs.CV

TL;DR: 提出了一种生成文本-图像计划的框架，解决多模态一致性和视觉步骤连贯性问题，并在多个骨干模型上验证了有效性。

- Motivation: 现有研究主要关注文本计划的生成，而文本-图像多模态计划的潜力尚未充分研究。
- Method: 提出分步生成和优化框架，包括文本步骤生成、视觉步骤编辑、视觉信息提取和计划细化。
- Result: 在1100个任务的基准测试中，框架在多模态一致性和连贯性上表现优异。
- Conclusion: 该框架为多模态计划生成提供了有效解决方案，并支持多种骨干模型。


### [36] [Dynamic Double Space Tower](https://arxiv.org/abs/2506.11394)
*Weikai Sun,Shijie Song,Han Wang*

Main category: cs.CV

TL;DR: 论文提出了一种动态双向空间塔方法，替代传统注意力机制，以增强模型在视觉问答任务中的推理能力和空间关系理解。

- Motivation: 现有方法在复杂推理场景中表现不佳，主要由于跨模态交互不足和实体空间关系捕捉不充分。
- Method: 提出动态双向空间塔，分为四层模拟人类格式塔视觉原理，为实体间的空间组织提供结构先验。
- Result: 实验表明该模块可应用于任何多模态模型并取得先进结果，尤其在空间关系问答数据集上表现突出。
- Conclusion: 所提出的方法显著提升了模型对空间关系的处理能力，训练出的模型July在仅3B参数下达到最先进水平。


### [37] [Stop learning it all to mitigate visual hallucination, Focus on the hallucination target](https://arxiv.org/abs/2506.11417)
*Dokyoon Yoon,Youngsook Song,Woomyong Park*

Main category: cs.CV

TL;DR: 提出了一种偏好学习方法（\mymethod）来减少多模态大语言模型（MLLMs）中的幻觉问题，通过专注于特定目标区域来纠正错误。

- Motivation: MLLMs在视觉语言任务中经常产生幻觉（即生成输入图像中不存在的对象信息），这影响了模型的可靠性。
- Method: 构建包含幻觉响应、正确响应和目标信息的数据集，并应用偏好学习方法专注于纠正特定目标区域的幻觉。
- Result: 实验表明，该方法有效减少了幻觉问题，提升了MLLMs的可靠性和性能，同时不影响整体表现。
- Conclusion: \mymethod 通过针对性学习显著减少了MLLMs的幻觉问题，提升了模型的实用性。


### [38] [Auto-Connect: Connectivity-Preserving RigFormer with Direct Preference Optimization](https://arxiv.org/abs/2506.11430)
*Jingfeng Guo,Jian Liu,Jinnan Chen,Shiwei Mao,Changrong Hu,Puhua Jiang,Junlin Yu,Jing Xu,Qi Liu,Lixin Xu,Zhuo Chen,Chunchao Guo*

Main category: cs.CV

TL;DR: Auto-Connect通过连接保持的标记化方案和拓扑感知奖励函数，显著提升了骨骼绑定的拓扑准确性和变形质量。

- Motivation: 传统方法在骨骼绑定中难以保持骨骼连接性，导致拓扑结构不准确。Auto-Connect旨在通过直接集成连接信息解决这一问题。
- Method: 采用连接保持的标记化方案定义关节连接关系，结合拓扑感知奖励函数和隐式测地线特征优化骨骼选择。
- Result: 模型能生成更符合解剖学的骨骼结构，显著减少皮肤变形中的常见问题。
- Conclusion: Auto-Connect通过创新方法提升了骨骼绑定的质量和效率。


### [39] [Auditing Data Provenance in Real-world Text-to-Image Diffusion Models for Privacy and Copyright Protection](https://arxiv.org/abs/2506.11434)
*Jie Zhu,Leye Wang*

Main category: cs.CV

TL;DR: 提出了一种黑盒审计框架FSCA，用于文本到图像扩散模型的数据来源审计，无需访问内部知识，实验表明其优于现有方法。

- Motivation: 现有文本到图像扩散模型依赖大规模数据集，可能涉及版权和隐私问题，但现有审计方法假设不现实或不可靠。
- Method: 利用文本到图像扩散模型中的两种语义连接进行审计，提出FSCA框架。
- Result: FSCA在多个数据集和指标上优于基线方法，用户级准确率达90%（仅需10样本/用户）。
- Conclusion: FSCA在现实应用中具有强大审计潜力，代码已开源。


### [40] [TAViS: Text-bridged Audio-Visual Segmentation with Foundation Models](https://arxiv.org/abs/2506.11436)
*Ziyang Luo,Nian Liu,Xuguang Yang,Salman Khan,Rao Muhammad Anwer,Hisham Cholakkal,Fahad Shahbaz Khan,Junwei Han*

Main category: cs.CV

TL;DR: TAViS框架通过结合多模态基础模型（ImageBind）和分割基础模型（SAM2），解决了音频-视觉分割中的跨模态对齐问题，并引入文本桥接设计提升性能。

- Motivation: 音频-视觉分割（AVS）面临跨模态对齐的挑战，现有方法未能有效结合多模态知识。
- Method: 提出TAViS框架，结合ImageBind和SAM2，引入文本桥接设计和对齐监督策略。
- Result: 在单源、多源、语义数据集及零样本设置中表现优异。
- Conclusion: TAViS通过文本桥接设计有效解决了跨模态对齐和知识转移问题，显著提升了性能。


### [41] [Uncertainty Awareness Enables Efficient Labeling for Cancer Subtyping in Digital Pathology](https://arxiv.org/abs/2506.11439)
*Nirhoshan Sivaroopan,Chamuditha Jayanga Galappaththige,Chalani Ekanayake,Hasindri Watawana,Ranga Rodrigo,Chamira U. S. Edussooriya,Dushan N. Wadduwage*

Main category: cs.CV

TL;DR: 提出一种自监督对比学习模型，通过不确定性评分优化癌症亚型分类，仅需少量标注即可达到最佳性能。

- Motivation: 解决癌症亚型分类中标注数据稀缺的问题，提高模型预测的可靠性。
- Method: 在自监督对比学习模型中引入不确定性感知，通过证据向量计算不确定性评分，选择性标注关键图像。
- Result: 仅需1-10%的标注数据，即可在基准数据集上实现最优性能。
- Conclusion: 该方法显著减少标注需求，提升分类精度，为数字病理学中的有限标注场景提供新方向。


### [42] [On the Natural Robustness of Vision-Language Models Against Visual Perception Attacks in Autonomous Driving](https://arxiv.org/abs/2506.11472)
*Pedram MohajerAnsari,Amir Salarpour,Michael Kühr,Siyu Huang,Mohammad Hamad,Sebastian Steinhorst,Habeeb Olufowobi,Mert D. Pesé*

Main category: cs.CV

TL;DR: 论文提出了一种名为V2LMs的视觉语言模型，用于提升自动驾驶车辆（AV）感知任务的鲁棒性，对抗未见攻击。相比传统DNN，V2LMs在不牺牲良性准确率的情况下显著提高了对抗攻击的抵抗力。

- Motivation: 传统DNN在自动驾驶任务中易受攻击，且现有防御机制（如对抗训练）会降低良性准确率且无法泛化到未见攻击。因此，需要一种更鲁棒的解决方案。
- Method: 通过微调视觉语言模型（V2LMs）专门用于AV感知任务，并提出了两种部署策略：Solo Mode（单任务）和Tandem Mode（多任务统一）。
- Result: 实验显示，传统DNN在攻击下性能下降33%-46%，而V2LMs仅下降不到8%。Tandem Mode在内存效率上更优，且鲁棒性与Solo Mode相当。
- Conclusion: V2LMs为AV感知系统提供了一种更安全、更鲁棒的解决方案，具有实际应用潜力。


### [43] [FAME: A Lightweight Spatio-Temporal Network for Model Attribution of Face-Swap Deepfakes](https://arxiv.org/abs/2506.11477)
*Wasim Ahmad,Yan-Tsung Peng,Yuan-Hao Chang*

Main category: cs.CV

TL;DR: FAME是一种轻量级时空框架，用于识别Deepfake视频的来源模型，通过多级嵌入捕捉生成伪影，优于现有方法。

- Motivation: Deepfake视频对数字安全、隐私和媒体完整性构成威胁，现有研究多关注二进制检测，模型溯源任务研究不足。
- Method: FAME结合空间和时间注意力机制，高效捕捉不同换脸模型的生成伪影。
- Result: 在DFDM、FaceForensics++和FakeAVCeleb数据集上，FAME在准确性和运行时间上均优于现有方法。
- Conclusion: FAME在现实取证和信息安全应用中具有潜力。


### [44] [Environmental Change Detection: Toward a Practical Task of Scene Change Detection](https://arxiv.org/abs/2506.11481)
*Kyusik Cho,Suhan Woo,Hongje Seong,Euntai Kim*

Main category: cs.CV

TL;DR: 论文提出了一种名为环境变化检测（ECD）的新任务，解决了传统场景变化检测（SCD）中依赖理想化对齐参考图像的局限性，通过利用未对齐的环境线索和多参考候选方法实现更实用的变化检测。

- Motivation: 传统SCD依赖理想化的对齐参考图像，而现实中参考图像通常视角不匹配。论文旨在解决这一不切实际的假设，提出更实用的ECD任务。
- Method: 提出了一种联合理解空间环境和检测变化的框架，通过多参考候选和语义丰富的表征聚合来解决视角不对齐和有限视野覆盖的问题。
- Result: 在三个标准基准测试中，该方法显著优于现有方法的简单组合，并达到与理想设置相当的性能。
- Conclusion: ECD任务和提出的框架为实际场景中的变化检测提供了更实用的解决方案，代码将在接受后公开。


### [45] [Composite Data Augmentations for Synthetic Image Detection Against Real-World Perturbations](https://arxiv.org/abs/2506.11490)
*Efthymia Amarantidou,Christos Koutlis,Symeon Papadopoulos,Panagiotis C. Petrantonakis*

Main category: cs.CV

TL;DR: 论文提出了一种改进合成图像检测（SID）的方法，通过数据增强组合和遗传算法优化选择，显著提升了模型在真实扰动下的性能。

- Motivation: 生成式AI工具的普及导致合成图像在社交媒体上广泛传播，威胁信息真实性，而现有SID方法对经过压缩等操作的网络图像效果不佳。
- Method: 研究采用数据增强组合，利用遗传算法选择最优增强策略，并引入双标准优化方法。
- Result: 最佳模型在平均精度上比未增强模型提升了22.53%。
- Conclusion: 该方法为开发能识别不同质量和变换的合成图像的检测模型提供了重要参考。


### [46] [Preserving Clusters in Prompt Learning for Unsupervised Domain Adaptation](https://arxiv.org/abs/2506.11493)
*Tung-Long Vuong,Hoang Phan,Vy Vo,Anh Bui,Thanh-Toan Do,Trung Le,Dinh Phung*

Main category: cs.CV

TL;DR: 论文提出了一种新方法，通过利用视觉和文本嵌入的几何关系，改进无监督域适应（UDA）中的伪标签和目标提示学习。

- Motivation: 现有基于多模态预训练模型（如CLIP）的UDA方法在性能上表现优异，但视觉嵌入分布可能偏离预训练模型，导致误导信号。
- Method: 提出利用源提示的参考预测，并通过最优传输理论增强文本嵌入的聚类特性，以改进目标域的对齐。
- Result: 实验验证了方法的有效性，展示了性能提升和目标提示表示质量的改进。
- Conclusion: 该方法通过几何关系优化伪标签和目标提示学习，显著提升了UDA的效果。


### [47] [Manager: Aggregating Insights from Unimodal Experts in Two-Tower VLMs and MLLMs](https://arxiv.org/abs/2506.11515)
*Xiao Xu,Libo Qin,Wanxiang Che,Min-Yen Kan*

Main category: cs.CV

TL;DR: 论文提出了一种名为Manager的轻量级插件，用于增强视觉-语言模型（VLM）的性能。通过自适应聚合不同层次单模态专家的知识，ManagerTower在多种下游任务中表现优异，并进一步扩展到多模态大语言模型（MLLM）架构中。

- Motivation: 现有BridgeTower模型在单模态表示利用、语义知识灵活性和低分辨率数据集评估方面存在局限性。
- Method: 提出ManagerTower，在跨模态层中引入Manager插件，自适应聚合单模态专家知识。
- Result: ManagerTower在4个下游任务中超越基线模型，LLaVA-OV-Manager在20个数据集上显著提升零样本性能。
- Conclusion: Manager插件和多网格算法协同作用，从深度和宽度两个正交角度提升视觉表示，减少语义模糊性。


### [48] [GNSS-inertial state initialization by distance residuals](https://arxiv.org/abs/2506.11534)
*Samuel Cerezo,Javier Civera*

Main category: cs.CV

TL;DR: 提出了一种新的GNSS-惯性初始化策略，通过延迟使用全局GNSS测量数据，直到有足够信息准确估计GNSS与惯性坐标系之间的转换，从而避免初始估计不佳。

- Motivation: 传感器平台的初始状态估计常因初始测量信息有限而导致估计不准确，容易陷入局部最优解。
- Method: 方法初期依赖GNSS相对距离残差，通过Hessian矩阵奇异值的演化确定切换到全局测量的最佳时机。
- Result: 在EuRoC和GVINS数据集上的实验表明，该方法比从一开始就使用全局GNSS数据的策略更准确和鲁棒。
- Conclusion: 延迟使用全局GNSS测量数据，结合Hessian矩阵分析，能显著提升初始化的准确性和鲁棒性。


### [49] [FIMA-Q: Post-Training Quantization for Vision Transformers by Fisher Information Matrix Approximation](https://arxiv.org/abs/2506.11543)
*Zhuguanyu Wu,Shihe Wang,Jiayi Zhang,Jiaxin Chen,Yunhong Wang*

Main category: cs.CV

TL;DR: 提出了一种名为FIMA-Q的新型后训练量化方法，用于解决Vision Transformers在低比特量化下的精度下降问题。

- Motivation: 现有后训练量化方法在Vision Transformers上表现不佳，尤其是在低比特量化时精度下降显著。
- Method: 通过分析Hessian-guided量化损失的局限性，提出基于KL散度与Fisher信息矩阵（FIM）连接的快速计算量化损失方法，并采用对角加低秩（DPLR-FIM）近似FIM。
- Result: 实验表明，FIMA-Q在多种视觉任务和ViT架构上显著提升了低比特量化下的精度。
- Conclusion: FIMA-Q是一种高效的后训练量化方法，尤其在低比特量化下表现优于现有技术。


### [50] [Leveraging Satellite Image Time Series for Accurate Extreme Event Detection](https://arxiv.org/abs/2506.11544)
*Heng Fang,Hossein Azizpour*

Main category: cs.CV

TL;DR: SITS-Extreme框架利用卫星图像时间序列检测极端天气事件，通过多时相观测提高准确性，优于传统双时相基线。

- Motivation: 气候变化导致极端天气事件增多，早期检测对灾害响应至关重要。
- Method: 提出SITS-Extreme框架，结合多时相卫星图像数据，过滤无关变化并提取灾害相关信号。
- Result: 实验验证了框架的有效性，显著优于传统方法，并分析了关键组件和时相数量的影响。
- Conclusion: SITS-Extreme具有可扩展性，适用于大规模灾害监测。


### [51] [Linearly Solving Robust Rotation Estimation](https://arxiv.org/abs/2506.11547)
*Yinlong Liu,Tianyu Huang,Zhi-Xin Yang*

Main category: cs.CV

TL;DR: 论文提出了一种新的旋转估计方法，将其转化为线性模型拟合问题，并利用GPU实现高效并行计算，表现出极强的鲁棒性和高效性。

- Motivation: 旋转估计在计算机视觉和机器人任务中至关重要，但传统方法复杂且易受噪声和异常值影响，需要更鲁棒且高效的解决方案。
- Method: 将旋转估计问题重新表述为线性模型拟合问题，利用四元数球面上的大圆表示旋转运动，提出基于投票的并行计算方法。
- Result: 方法在噪声和异常值（99%异常比例）下表现优异，能在0.5秒内处理大规模（10^6）问题。
- Conclusion: 通过理论和实验验证，该方法在旋转估计问题中表现出高效性和鲁棒性。


### [52] [EyeSim-VQA: A Free-Energy-Guided Eye Simulation Framework for Video Quality Assessment](https://arxiv.org/abs/2506.11549)
*Zhaoyang Wang,Wen Lu,Jie Li,Lihuo He,Maoguo Gong,Xinbo Gao*

Main category: cs.CV

TL;DR: 论文提出了一种名为EyeSimVQA的新型视频质量评估框架，结合自由能自修复机制，通过双分支架构和生物启发设计，在性能与可解释性上优于现有方法。

- Motivation: 视频质量评估（VQA）中，时空动态性和预训练模型的限制使得自由能自修复机制的应用面临挑战。
- Method: 采用双分支架构（美学分支和技术分支），结合自由能自修复模块和生物启发的预测头设计。
- Result: 在五个公开VQA基准测试中表现优异，性能与可解释性均优于现有方法。
- Conclusion: EyeSimVQA为视频质量评估提供了一种高效且可解释的新方法。


### [53] [DaMO: A Data-Efficient Multimodal Orchestrator for Temporal Reasoning with Video LLMs](https://arxiv.org/abs/2506.11558)
*Bo-Cheng Chiu,Jen-Jee Chen,Yu-Chee Tseng,Feng-Chi Chen*

Main category: cs.CV

TL;DR: DaMO是一种数据高效的视频大语言模型，专注于精细时间推理和多模态理解，通过分层双流架构和全局残差设计提升性能。

- Motivation: 现有视频大语言模型在精细时间推理上存在局限，难以准确关联视频时刻与响应，尤其是在有限监督下。
- Method: 提出Temporal-aware Fuseformer，采用分层双流架构捕获时间动态并融合视觉与音频信息，结合全局残差设计提升效率。通过四阶段渐进训练范式增强多模态对齐、语义基础和推理能力。
- Result: 在时间定位和视频问答任务中，DaMO显著优于现有方法，尤其在精确时间对齐和推理任务中表现突出。
- Conclusion: DaMO为数据高效的视频-语言建模提供了有前景的方向。


### [54] [VFaith: Do Large Multimodal Models Really Reason on Seen Images Rather than Previous Memories?](https://arxiv.org/abs/2506.11571)
*Jiachen Yu,Yufei Zhan,Ziheng Wu,Yousong Zhu,Jinqiao Wang,Minghui Qiu*

Main category: cs.CV

TL;DR: 论文提出了一种自动编辑视觉线索的流程和VFaith-Bench基准，用于评估多模态大语言模型（MLLMs）的视觉推理能力和视觉忠实性。

- Motivation: 现有方法通过长链思维（CoT）提升MLLMs解决复杂问题的能力，但其有效性原因尚不明确，尤其是视觉线索提取与推理过程对性能的贡献难以量化。
- Method: 提出基于GPT-Image-1的自动编辑流程，精确修改视觉线索；构建VFaith-Bench基准，包含755个条目和人类标注的感知任务。
- Result: 通过编辑测试集图像，比较问题-答案对的准确性差异，揭示模型推理能力与视觉感知的关系。
- Conclusion: VFaith-Bench为分析MLLMs的视觉推理能力提供了工具，揭示了其性能提升的来源。


### [55] [Camera-based method for the detection of lifted truck axles using convolutional neural networks](https://arxiv.org/abs/2506.11574)
*Bachir Tchana Tankeu,Mohamed Bouteldja,Nicolas Grignard,Bernard Jacob*

Main category: cs.CV

TL;DR: 提出了一种基于YOLOv8s卷积神经网络的方法，用于检测卡车抬升轴，精度87%，召回率91.7%，推理时间1.4毫秒，适合实时应用。

- Motivation: 现有技术难以准确分类抬升轴的车辆，缺乏商业和技术方法检测抬升轴。
- Method: 使用YOLOv8s卷积神经网络，通过垂直于交通方向的摄像头图像检测卡车抬升轴。
- Result: 精度87%，召回率91.7%，推理时间1.4毫秒。
- Conclusion: 方法适合实时应用，未来可通过增加数据集或图像增强进一步改进。


### [56] [OV-MAP : Open-Vocabulary Zero-Shot 3D Instance Segmentation Map for Robots](https://arxiv.org/abs/2506.11585)
*Juno Kim,Yesol Park,Hye-Jung Yoon,Byoung-Tak Zhang*

Main category: cs.CV

TL;DR: OV-MAP通过将开放特征集成到3D地图中，提升移动机器人的物体识别能力，解决了特征重叠导致精度下降的问题。

- Motivation: 解决3D地图中特征重叠导致的实例级精度下降问题，提升开放世界中的物体识别能力。
- Method: 使用类无关分割模型将2D掩码投影到3D空间，结合原始和合成深度图像，并采用3D掩码投票机制。
- Result: 在ScanNet200和Replica数据集上表现出卓越的零样本性能、鲁棒性和适应性。
- Conclusion: OV-MAP在开放世界3D映射中实现了高精度的零样本实例分割，适用于多样化环境。


### [57] [EasyARC: Evaluating Vision Language Models on True Visual Reasoning](https://arxiv.org/abs/2506.11595)
*Mert Unsal,Aylin Akkus*

Main category: cs.CV

TL;DR: 论文提出EasyARC，一个多模态推理基准，结合视觉和语言，支持多图像、多步骤推理和自我修正，用于评估视觉语言模型的真实推理能力。

- Motivation: 现有基准主要测试视觉提取与文本推理的结合，缺乏视觉与语言复杂交互的真实推理能力。
- Method: 通过程序化生成EasyARC基准，包含渐进难度级别，支持强化学习流程，并开源数据集和评估代码。
- Result: 评估了最先进的视觉语言模型，并分析了其失败模式。
- Conclusion: EasyARC为视觉语言模型的真实推理和测试时扩展能力设定了新标准。


### [58] [A$^2$LC: Active and Automated Label Correction for Semantic Segmentation](https://arxiv.org/abs/2506.11599)
*Youjin Jeon,Kyusik Cho,Suhan Woo,Euntai Kim*

Main category: cs.CV

TL;DR: A$^2$LC是一种高效的主动标签校正框架，通过自动化校正和自适应平衡采集函数，显著提升了语义分割的标签校正效率和性能。

- Motivation: 解决语义分割中手动像素级标注的高成本和易错问题，通过选择性校正错误标签。
- Method: 提出A$^2$LC框架，结合自动化校正阶段和自适应平衡采集函数，扩展校正范围并优化尾类处理。
- Result: 在Cityscapes和PASCAL VOC 2012上显著优于现有方法，仅用20%预算即可超越，性能提升27.23%。
- Conclusion: A$^2$LC高效且有效，为语义分割标签校正提供了新思路。


### [59] [Wi-CBR: WiFi-based Cross-domain Behavior Recognition via Multimodal Collaborative Awareness](https://arxiv.org/abs/2506.11616)
*Ruobei Zhang,Shengeng Tang,Huan Yan,Xiang Zhang,Richang Hong*

Main category: cs.CV

TL;DR: 提出了一种基于WiFi信号的多模态协作感知方法，通过融合相位数据和多普勒频移数据，提升行为识别的准确性。

- Motivation: 现有方法通常仅关注单一数据类型，忽略了多特征的交互与融合，导致识别精度受限。
- Method: 采用双分支自注意力模块捕获模态内的时空线索，并通过组注意力机制挖掘关键特征，进一步通过门控机制优化信息熵。
- Result: 在两个公开数据集上的实验表明，该方法在领域内和跨领域场景下均表现优异。
- Conclusion: 多模态协作感知方法显著提升了WiFi行为识别的准确性和鲁棒性。


### [60] [SignAligner: Harmonizing Complementary Pose Modalities for Coherent Sign Language Generation](https://arxiv.org/abs/2506.11621)
*Xu Wang,Shengeng Tang,Lechao Cheng,Feng Li,Shuo Wang,Richang Hong*

Main category: cs.CV

TL;DR: 论文提出SignAligner方法，通过多阶段生成和修正，提升手语视频的准确性和表现力。

- Motivation: 手语生成因涉及复杂手势、表情和身体动作，难以实现自然生成。
- Method: SignAligner包括三阶段：文本驱动姿势生成、多模态在线协作修正和视频合成。
- Result: 实验表明SignAligner显著提升生成手语视频的质量。
- Conclusion: SignAligner为手语生成提供了高效且表现力强的方法。


### [61] [Evaluating Fairness and Mitigating Bias in Machine Learning: A Novel Technique using Tensor Data and Bayesian Regression](https://arxiv.org/abs/2506.11627)
*Kuniko Paxton,Koorosh Aslansefat,Dhavalkumar Thakker,Yiannis Papadopoulos*

Main category: cs.CV

TL;DR: 论文提出了一种新的机器学习公平性评估方法，专注于图像分类任务中的肤色处理，避免传统分类的局限性，通过概率分布和统计距离度量实现更细粒度的公平性分析。

- Motivation: 肤色在计算机视觉中以张量数据表示，而非传统的分类或数值特征，现有公平性研究多关注分类特征（如性别、种族），忽视了肤色的特殊性。
- Method: 将肤色张量数据转换为概率分布，应用统计距离度量；提出基于贝叶斯回归和多项式函数的训练方法，减少传统肤色分类中的潜在偏差。
- Result: 新方法能够捕捉传统分类无法识别的细粒度公平性差异，并在肤色处理上实现更公平的模型预测。
- Conclusion: 该技术为机器学习公平性提供了更灵活和精确的评估工具，特别适用于肤色等复杂敏感属性的处理。


### [62] [DISCO: Mitigating Bias in Deep Learning with Conditional Distance Correlation](https://arxiv.org/abs/2506.11653)
*Emre Kavak,Tom Nuno Wolf,Christian Wachinger*

Main category: cs.CV

TL;DR: 论文提出了一种标准反因果预测模型（SAM）和正则化策略DISCO，用于解决预测任务中模型依赖无关信号的问题。

- Motivation: 在预测任务中，模型可能利用无关的因果信号（如光照条件）进行预测，导致结果不可靠。本文旨在解决这一问题。
- Method: 提出SAM模型，通过因果框架分析预测器在反因果设置中的信息路径；并设计DISCO正则化策略，利用条件距离相关性优化回归任务中的条件独立性。
- Result: 实验表明，DISCO在不同偏置缓解任务中表现优异，可作为传统核方法的替代方案。
- Conclusion: SAM和DISCO为反因果预测问题提供了有效解决方案，能够减少无关信号的影响，提升模型可靠性。


### [63] [Prohibited Items Segmentation via Occlusion-aware Bilayer Modeling](https://arxiv.org/abs/2506.11661)
*Yunhan Ren,Ruihuang Li,Lingbo Liu,Changwen Chen*

Main category: cs.CV

TL;DR: 提出了一种针对X射线图像中违禁物品的遮挡感知实例分割方法，结合Segment Anything Model（SAM）和双层掩码解码器模块，显著提升了分割效果。

- Motivation: X射线图像中违禁物品的外观与自然物体差异大，且物体间重叠严重，导致分割任务困难。
- Method: 集成SAM模型利用其先验知识和零样本泛化能力，设计遮挡感知的双层掩码解码器模块，并标注了两个大规模遮挡数据集（PIDray-A和PIXray-A）。
- Result: 在遮挡标注数据集上的实验验证了方法的有效性。
- Conclusion: 提出的方法有效解决了X射线图像中违禁物品的分割问题，相关数据和代码已开源。


### [64] [Dynamic Mixture of Curriculum LoRA Experts for Continual Multimodal Instruction Tuning](https://arxiv.org/abs/2506.11672)
*Chendi Ge,Xin Wang,Zeyang Zhang,Hong Chen,Jiapei Fan,Longtao Huang,Hui Xue,Wenwu Zhu*

Main category: cs.CV

TL;DR: 提出了一种动态混合课程LoRA专家（D-MoLE）方法，通过动态调整MLLM架构以适应新任务，解决了任务架构冲突和模态不平衡问题，实验显示性能提升15%。

- Motivation: 现有方法因固定架构难以适应新任务，需动态调整架构以解决任务冲突和模态不平衡。
- Method: 提出D-MoLE方法，包括动态层专家分配器和梯度驱动的跨模态课程，以优化架构和模态更新。
- Result: D-MoLE显著优于现有基线，平均性能提升15%。
- Conclusion: 首次从架构角度研究MLLM的持续学习，D-MoLE为动态任务适应提供了有效解决方案。


### [65] [Cross-Modal Clustering-Guided Negative Sampling for Self-Supervised Joint Learning from Medical Images and Reports](https://arxiv.org/abs/2506.11674)
*Libin Lan,Hongxing Li,Zunhui Xia,Juan Zhou,Xiaofei Zhu,Yongmei Li,Yudong Zhang,Xin Luo*

Main category: cs.CV

TL;DR: 论文提出了一种跨模态聚类引导负采样方法（CM-CGNS），通过改进负样本选择和增强局部细节提取，提升了医学视觉表示学习的效果。

- Motivation: 现有方法存在负样本选择不当、忽略局部细节和低层特征的问题，影响了医学图像识别的准确性。
- Method: 采用跨模态注意力扩展k-means聚类到多模态领域，并引入跨模态掩码图像重建模块（CM-MIR）增强局部特征交互。
- Result: 在五个下游数据集上的分类、检测和分割任务中，CM-CGNS在多项指标上优于现有方法。
- Conclusion: CM-CGNS通过优化负样本选择和局部特征提取，显著提升了医学视觉表示学习的性能。


### [66] [Predicting Patient Survival with Airway Biomarkers using nn-Unet/Radiomics](https://arxiv.org/abs/2506.11677)
*Zacharia Mesbah,Dhruv Jain,Tsiry Mayet,Romain Modzelewski,Romain Herault,Simon Bernard,Sebastien Thureau,Clement Chatelain*

Main category: cs.CV

TL;DR: 该研究通过三阶段方法评估气道相关影像生物标志物对肺纤维化患者生存结果的预测意义，包括气道分割、特征提取和分类，取得了较高的评分。

- Motivation: 研究旨在探索气道影像生物标志物对肺纤维化患者生存结果的预测价值，以期为临床决策提供支持。
- Method: 采用三阶段方法：1) 使用nn-Unet分割气道结构；2) 从气管和气道周围提取关键特征；3) 将特征输入SVM分类器。
- Result: Task 1的分割评分为0.8601，Task 2的分类评分为0.7346。
- Conclusion: 该方法在气道影像生物标志物分析中表现出较高的预测能力，为肺纤维化患者的生存评估提供了有效工具。


### [67] [Pose Matters: Evaluating Vision Transformers and CNNs for Human Action Recognition on Small COCO Subsets](https://arxiv.org/abs/2506.11678)
*MingZe Tang,Madiha Kazi*

Main category: cs.CV

TL;DR: 本研究通过对比不同模型在三类COCO数据集上的人体动作识别表现，发现二元视觉Transformer（ViT）表现最佳，准确率达90%，显著优于其他模型。

- Motivation: 探索不同模型在人体动作识别任务中的表现，尤其是Transformer架构的潜力。
- Method: 使用三类COCO数据集，对比了全连接网络、卷积网络、CLIP模型和ViT的性能，并通过统计分析和可视化技术（如SHAP和LeGrad）解释模型行为。
- Result: ViT在测试集上达到90%的准确率，显著优于其他模型（卷积网络约35%，CLIP模型约62-64%）。统计分析和可视化表明ViT能更精准地定位动作相关区域。
- Conclusion: Transformer架构在数据效率和性能上表现优越，可视化技术有助于诊断模型错误，强调了可解释性在动作识别中的重要性。


### [68] [MTabVQA: Evaluating Multi-Tabular Reasoning of Language Models in Visual Space](https://arxiv.org/abs/2506.11684)
*Anshul Singh,Chris Biemann,Jan Strich*

Main category: cs.CV

TL;DR: 论文提出了MTabVQA基准，用于评估视觉语言模型在多表格图像上的推理能力，并通过微调提升了模型性能。

- Motivation: 现有基准无法评估模型在多表格图像上的解析和推理能力，MTabVQA填补了这一空白。
- Method: 引入MTabVQA基准和MTabVQA-Instruct微调数据集，对现有视觉语言模型进行测试和优化。
- Result: 实验显示现有模型在多表格推理上表现有限，但通过微调显著提升了性能。
- Conclusion: MTabVQA为多表格视觉问答提供了有效评估工具，微调方法显著提升了模型能力。


### [69] [DMAF-Net: An Effective Modality Rebalancing Framework for Incomplete Multi-Modal Medical Image Segmentation](https://arxiv.org/abs/2506.11691)
*Libin Lan,Hongxing Li,Zunhui Xia,Yudong Zhang*

Main category: cs.CV

TL;DR: 提出了一种动态模态感知融合网络（DMAF-Net），用于解决多模态医学图像分割中的模态不平衡问题，通过动态融合模块、关系蒸馏框架和动态训练监控策略，显著提升了性能。

- Motivation: 现有方法在多模态医学图像分割中依赖完整模态假设，无法动态平衡模态贡献或处理模态缺失，导致实际临床场景中性能不佳。
- Method: DMAF-Net采用动态模态感知融合模块、关系与原型蒸馏框架以及动态训练监控策略，通过注意力机制和自适应调整优化模态贡献与训练稳定性。
- Result: 在BraTS2020和MyoPS2020数据集上的实验表明，DMAF-Net性能优于现有方法。
- Conclusion: DMAF-Net通过动态平衡模态贡献和优化训练策略，有效解决了多模态医学图像分割中的模态不平衡问题。


### [70] [Quizzard@INOVA Challenge 2025 -- Track A: Plug-and-Play Technique in Interleaved Multi-Image Model](https://arxiv.org/abs/2506.11737)
*Dinh Viet Cuong,Hoang-Bao Le,An Pham Ngoc Nguyen,Liting Zhou,Cathal Gurrin*

Main category: cs.CV

TL;DR: 论文展示了LLaVA-NeXT-interleave在22个数据集上的优异表现，并比较了标准模型与DCI增强版的性能。

- Motivation: 研究LLaVA-NeXT-interleave在多任务中的表现，并探索DCI连接器对模型性能的影响。
- Method: 在标准模型基础上加入DCI连接器，并在22个数据集上进行多任务测试。
- Result: 标准模型在视觉任务中表现最佳，而DCI增强版在语义连贯性和结构化变化理解任务中更优。
- Conclusion: 结合基础模型与即插即用技术具有潜力，代码已开源。


### [71] [AgriPotential: A Novel Multi-Spectral and Multi-Temporal Remote Sensing Dataset for Agricultural Potentials](https://arxiv.org/abs/2506.11740)
*Mohammad El Sakka,Caroline De Pourtales,Lotfi Chaari,Josiane Mothe*

Main category: cs.CV

TL;DR: AgriPotential是一个基于Sentinel-2卫星图像的农业潜力预测数据集，覆盖法国南部的多种作物类型，支持多种机器学习任务。

- Motivation: 遥感技术在大规模地球监测和土地管理中至关重要，但缺乏专门用于农业潜力预测的公开数据集。
- Method: 数据集包含多个月的Sentinel-2图像，提供三种主要作物类型的像素级标注，分为五个有序类别。
- Result: AgriPotential支持序数回归、多标签分类和时空建模等任务，为可持续土地利用规划提供数据支持。
- Conclusion: AgriPotential填补了农业潜力预测数据集的空白，推动了数据驱动的土地利用规划方法。


### [72] [DiffFuSR: Super-Resolution of all Sentinel-2 Multispectral Bands using Diffusion Models](https://arxiv.org/abs/2506.11764)
*Muhammad Sarmad,Arnt-Børre Salberg,Michael Kampffmeyer*

Main category: cs.CV

TL;DR: DiffFuSR是一个模块化管道，用于将Sentinel-2 Level-2A影像的12个光谱波段超分辨率统一到2.5米地面采样距离（GSD）。方法包括扩散模型和融合网络，性能优于现有技术。

- Motivation: 解决Sentinel-2影像多光谱波段分辨率不统一的问题，提升超分辨率的精度和一致性。
- Method: 两阶段方法：1）基于扩散模型的RGB超分辨率；2）融合网络利用超分辨率RGB图像作为空间先验提升其他波段。
- Result: 在OpenSR基准测试中表现优于现有技术，反射率保真度、光谱一致性、空间对齐和幻觉抑制均更优。
- Conclusion: 通过生成先验和融合策略的协调学习，创建了模块化的Sentinel-2超分辨率框架。


### [73] [MambaVSR: Content-Aware Scanning State Space Model for Video Super-Resolution](https://arxiv.org/abs/2506.11768)
*Linfeng He,Meiqin Liu,Qi Tang,Chao Yao,Yao Zhao*

Main category: cs.CV

TL;DR: MambaVSR是一种基于状态空间模型的视频超分辨率框架，通过动态时空交互和内容感知机制解决现有方法在大运动位移和长视频序列中的局限性。

- Motivation: 现有视频超分辨率方法在处理非局部依赖和大运动位移时效率低下，且难以平衡计算效率与性能。
- Method: 提出MambaVSR框架，结合共享罗盘构建（SCC）和内容感知序列化（CAS）模块，动态处理时空交互，并通过全局-局部状态空间块（GLSSB）整合局部细节与全局依赖。
- Result: 在REDS数据集上，MambaVSR比基于Transformer的方法PSNR提升0.58 dB，且参数减少55%。
- Conclusion: MambaVSR通过创新的内容感知机制和状态空间模型，显著提升了视频超分辨率的性能与效率。


### [74] [CLIP Meets Diffusion: A Synergistic Approach to Anomaly Detection](https://arxiv.org/abs/2506.11772)
*Byeongchan Lee,John Won,Seunghyun Lee,Jinwoo Shin*

Main category: cs.CV

TL;DR: CLIPFUSION结合判别式和生成式基础模型，通过多模态融合解决异常检测问题，显著优于基线方法。

- Motivation: 异常检测因定义模糊、类型多样且数据稀缺而复杂，需能捕捉多层次特征的模型。
- Method: 利用CLIP判别模型捕捉全局特征，扩散生成模型捕捉局部细节，并引入跨注意力图和特征图方法。
- Result: 在MVTec-AD和VisA数据集上表现优异，异常分割和分类性能突出。
- Conclusion: 多模态和多模型融合有效解决异常检测挑战，为实际应用提供可扩展方案。


### [75] [AgentSense: Virtual Sensor Data Generation Using LLM Agent in Simulated Home Environments](https://arxiv.org/abs/2506.11773)
*Zikang Leng,Megha Thukral,Yaqi Liu,Hrudhai Rajasekhar,Shruthi K. Hiremath,Thomas Plötz*

Main category: cs.CV

TL;DR: AgentSense利用大型语言模型生成虚拟数据，解决智能家居中人类活动识别（HAR）系统缺乏多样化标注数据的问题，显著提升模型性能。

- Motivation: 智能家居HAR系统因缺乏大规模、多样化的标注数据而难以泛化，且家庭布局、传感器配置和用户行为的多样性增加了复杂性。
- Method: 通过AgentSense生成虚拟数据：利用大型语言模型创建多样化用户角色，模拟日常活动，并在扩展的VirtualHome环境中记录虚拟传感器数据。
- Result: 在五个基准HAR数据集上，虚拟数据显著提升了模型性能，尤其是在真实数据有限时。少量真实数据结合虚拟数据即可达到与完整真实数据集相当的效果。
- Conclusion: 虚拟数据能有效解决环境感知中大规模标注数据缺乏的问题，无需人工数据收集。


### [76] [Real-Time Feedback and Benchmark Dataset for Isometric Pose Evaluation](https://arxiv.org/abs/2506.11774)
*Abhishek Jaiswal,Armeet Singh Luthra,Purav Jangir,Bhavya Garg,Nisheeth Srivastava*

Main category: cs.CV

TL;DR: 论文提出了一种实时反馈系统，用于评估等长运动姿势，解决了依赖不可靠数字媒体内容的问题，并发布了最大的多类等长运动视频数据集。

- Motivation: 等长运动因其便利性和隐私性受欢迎，但依赖不可靠数字媒体内容可能导致姿势错误、受伤和缺乏反馈。
- Method: 开发了实时反馈系统，发布了包含3,600多个视频片段的数据集，并评估了包括图网络在内的先进模型。
- Result: 提出了新的三部分度量标准，提高了智能个性化家庭锻炼系统的可行性。
- Conclusion: 该系统可扩展应用于康复、物理治疗等领域，提供专家级诊断。


### [77] [Self-supervised Learning of Echocardiographic Video Representations via Online Cluster Distillation](https://arxiv.org/abs/2506.11777)
*Divyanshu Mishra,Mohammadreza Salehi,Pramit Saha,Olga Patey,Aris T. Papageorghiou,Yuki M. Asano,J. Alison Noble*

Main category: cs.CV

TL;DR: DISCOVR是一种自监督双分支框架，用于心脏超声视频表示学习，通过结合聚类视频编码器和在线图像编码器，显著提升性能。

- Motivation: 现有自监督学习方法在心脏超声领域表现不佳，因样本相似性高、输入质量低或增强失真临床特征。
- Method: DISCOVR结合聚类视频编码器和在线图像编码器，通过语义聚类蒸馏损失传递知识。
- Result: 在六个超声数据集上，DISCOVR在零样本、线性探测和分割任务中优于现有方法。
- Conclusion: DISCOVR通过双分支设计和知识蒸馏，显著提升了心脏超声视频的表示学习效果。


### [78] [GPLQ: A General, Practical, and Lightning QAT Method for Vision Transformers](https://arxiv.org/abs/2506.11784)
*Guang Liang,Xinyao Liu,Jianxin Wu*

Main category: cs.CV

TL;DR: GPLQ是一种高效且有效的ViT量化框架，通过分阶段量化激活和权重，显著提升了4位量化模型的性能，同时降低了计算成本和内存占用。

- Motivation: 现有PTQ和QAT方法在ViT量化中存在显著局限性，如精度下降、计算成本高、泛化能力差等。
- Method: GPLQ采用两阶段策略：第一阶段量化激活并保持权重为FP32，第二阶段量化权重。
- Result: GPLQ比现有QAT方法快100倍，内存占用低于FP32训练，4位量化模型性能接近FP32模型。
- Conclusion: GPLQ为ViT量化提供了一种高效、实用的解决方案，并计划开源工具包。


### [79] [Teleoperated Driving: a New Challenge for 3D Object Detection in Compressed Point Clouds](https://arxiv.org/abs/2506.11804)
*Filippo Bragato,Michael Neri,Paolo Testolina,Marco Giordani,Federica Battisti*

Main category: cs.CV

TL;DR: 论文研究了通过点云数据检测车辆和行人以支持远程驾驶（TD）的安全操作，利用扩展的SELMA数据集评估了压缩算法和物体检测器的性能，并分析了其对V2X网络的影响。

- Motivation: 随着互联设备的普及和传感器技术的进步，远程驾驶（TD）成为可能。然而，如何高效检测车辆和行人以确保安全操作是一个关键问题。
- Method: 利用扩展的SELMA数据集（包含3D物体的真实边界框），评估了多种压缩算法和物体检测器的性能，包括压缩效率、处理时间和检测精度。
- Result: 分析了压缩和检测对V2X网络数据速率和延迟的影响，并与3GPP的TD应用要求进行了对比。
- Conclusion: 研究为远程驾驶中的物体检测和数据处理提供了实用的性能评估，有助于优化系统设计以满足实时性和安全性需求。


### [80] [Rethinking Multilingual Vision-Language Translation: Dataset, Evaluation, and Adaptation](https://arxiv.org/abs/2506.11820)
*Xintong Wang,Jingheng Pan,Yixiao Liu,Xiaohu Zhao,Chenyang Lyu,Minghao Wu,Chris Biemann,Longyue Wang,Linlong Xu,Weihua Luo,Kaifu Zhang*

Main category: cs.CV

TL;DR: 该论文系统评估了视觉语言翻译（VLT）任务，提出了新数据集AibTrans、对比了多种模型架构，并提出了更可靠的评估指标DA Score。

- Motivation: 现有大型视觉语言模型（LVLM）在VLT任务上缺乏系统性评估，研究旨在填补这一空白。
- Method: 从数据质量、模型架构和评估指标三个角度分析，提出新数据集、对比模型性能，并设计DA Score。
- Result: 发现高资源语言对微调会损害跨语言性能，提出平衡多语言微调策略。
- Conclusion: 建立了VLT新评估基准，并提出了改进模型性能的方法。


### [81] [Vision-based Lifting of 2D Object Detections for Automated Driving](https://arxiv.org/abs/2506.11839)
*Hendrik Königshof,Kun Li,Christoph Stiller*

Main category: cs.CV

TL;DR: 提出了一种仅使用摄像头将2D检测结果提升为3D检测的管道，作为LiDAR的经济替代方案，适用于所有道路使用者，计算效率高。

- Motivation: 由于LiDAR成本高且摄像头已广泛配备，需要一种经济高效的3D物体检测方法。
- Method: 利用2D CNN处理点云数据，将现有2D算法结果提升为3D检测。
- Result: 在KITTI基准测试中表现与现有图像方法相当，但运行时间仅为三分之一。
- Conclusion: 该方法为低成本3D检测提供了可行方案，适用于自动驾驶。


### [82] [SphereDrag: Spherical Geometry-Aware Panoramic Image Editing](https://arxiv.org/abs/2506.11863)
*Zhiao Feng,Xuewei Li,Junjie Yang,Yuxin Peng,Xi Li*

Main category: cs.CV

TL;DR: SphereDrag是一个新颖的全景图像编辑框架，通过自适应重投影、大圆轨迹调整和球形搜索区域跟踪解决边界不连续性、轨迹变形和像素密度不均问题，并在PanoBench上验证了其优越性。

- Motivation: 全景图像编辑因球形几何和投影变形面临边界不连续性、轨迹变形和像素密度不均的挑战，现有方法未能有效解决。
- Method: 提出SphereDrag框架，包括自适应重投影（AR）、大圆轨迹调整（GCTA）和球形搜索区域跟踪（SSRT）。
- Result: 实验表明，SphereDrag在几何一致性和图像质量上显著优于现有方法，相对提升达10.5%。
- Conclusion: SphereDrag通过结合球形几何知识，实现了更准确和可控的全景图像编辑。


### [83] [Methods for evaluating the resolution of 3D data derived from satellite images](https://arxiv.org/abs/2506.11876)
*Christina Selby,Holden Bindl,Tyler Feldman,Andrew Skow,Nicolas Norena Acosta,Shea Hagstrom,Myron Brown*

Main category: cs.CV

TL;DR: 该论文研究了如何评估卫星图像衍生的3D数据（点云、数字表面模型和3D网格模型）的分辨率，并提出了基于高分辨率参考激光雷达的自动化评估工具和工作流程。

- Motivation: 卫星图像衍生的3D数据在大规模覆盖或难以通过机载激光雷达或相机获取的区域中至关重要，但其分辨率的评估方法尚不完善。
- Method: 论文提出了3D度量评估工具和工作流程，利用高分辨率参考机载激光雷达实现自动化评估。
- Result: 通过不同质量数据的分析，展示了评估工具的有效性。
- Conclusion: 该研究为卫星图像衍生的3D数据分辨率评估提供了实用工具和方法。


### [84] [O2Former:Direction-Aware and Multi-Scale Query Enhancement for SAR Ship Instance Segmentation](https://arxiv.org/abs/2506.11913)
*F. Gao,Y Li,X He,J Sun,J Wang*

Main category: cs.CV

TL;DR: O2Former是一种针对SAR图像的实例分割框架，通过优化查询生成器和方向感知嵌入模块，解决了SAR图像中目标尺度变化、密度和模糊边界的问题，显著提升了性能。

- Motivation: SAR图像中的船舶实例分割对海事监控、环境分析和国家安全至关重要，但现有方法未能充分解决尺度变化、目标密度和模糊边界等挑战。
- Method: O2Former基于Mask2Former框架，引入优化查询生成器（OQG）和多尺度特征交互，以及方向感知嵌入模块（OAEM）增强方向敏感性。
- Result: 实验表明，O2Former在SAR船舶数据集上优于现有基线方法，验证了其有效性和泛化能力。
- Conclusion: O2Former通过针对性设计显著提升了SAR图像中船舶实例分割的精度和效率。


### [85] [Aligned Novel View Image and Geometry Synthesis via Cross-modal Attention Instillation](https://arxiv.org/abs/2506.11924)
*Min-Seop Kwak,Junho Kim,Sangdoo Yun,Dongyoon Han,Taekyoung Kim,Seungryong Kim,Jin-Hwa Kim*

Main category: cs.CV

TL;DR: 提出了一种基于扩散的框架，通过变形和修复方法实现对齐的新视角图像和几何生成。

- Motivation: 现有方法需要密集的姿态图像或局限于域内视角的姿态嵌入生成模型，而本文方法利用现成的几何预测器预测部分几何，并将新视角合成任务转化为图像和几何的修复任务。
- Method: 采用跨模态注意力蒸馏，将图像扩散分支的注意力图注入几何扩散分支，并提出基于邻近的网格条件化以整合深度和法线线索。
- Result: 在未见场景中实现了高保真的外推视角合成，在插值设置下具有竞争力的重建质量，并生成了几何对齐的彩色点云。
- Conclusion: 该方法在多任务协同下实现了几何鲁棒的图像合成和明确的几何预测。


### [86] [Evaluating Sensitivity Parameters in Smartphone-Based Gaze Estimation: A Comparative Study of Appearance-Based and Infrared Eye Trackers](https://arxiv.org/abs/2506.11932)
*Nishan Gunawardena,Gough Yumu Lui,Jeewani Anupama Ginige,Bahman Javadi*

Main category: cs.CV

TL;DR: 研究比较了基于智能手机的深度学习眼动追踪算法与商用红外眼动追踪器Tobii Pro Nano的性能，探讨了外观基视线估计在移动使用条件下的可行性。

- Motivation: 研究动机是评估外观基视线估计在现实移动使用条件下的性能，并分析关键敏感因素（如年龄、性别、视力矫正等）的影响。
- Method: 方法包括使用轻量级卷积神经网络（MobileNet-V3）和循环结构（LSTM）从灰度面部图像预测视线坐标，并通过51名参与者的动态视觉刺激数据测量准确性。
- Result: 深度学习模型的平均误差为17.76 mm，略高于Tobii Pro Nano的16.53 mm，但对光照、视力矫正和年龄等因素更敏感。
- Conclusion: 结论是外观基方法在移动眼动追踪中具有潜力，并提供了评估不同使用条件下视线估计系统的参考框架。


### [87] [How Visual Representations Map to Language Feature Space in Multimodal LLMs](https://arxiv.org/abs/2506.11976)
*Constantin Venhoff,Ashkan Khakzar,Sonia Joseph,Philip Torr,Neel Nanda*

Main category: cs.CV

TL;DR: 论文提出了一种通过线性适配器连接冻结的视觉和语言模型的方法，研究了视觉与语言表征的对齐机制。

- Motivation: 探索视觉语言模型（VLMs）中视觉与语言表征对齐的机制，以改进跨模态表示学习。
- Method: 使用冻结的大型语言模型（LLM）和视觉变换器（ViT），仅通过训练线性适配器进行视觉指令调整。
- Result: 实验表明，视觉表征在LLM的中后层逐渐与语言表征对齐，揭示了ViT输出与早期LLM层之间的不匹配。
- Conclusion: 当前基于适配器的架构可能未最优地支持跨模态表示学习，需进一步研究改进。


### [88] [Simple Radiology VLLM Test-time Scaling with Thought Graph Traversal](https://arxiv.org/abs/2506.11989)
*Yue Yao,Zelin Wen,Yan Tong,Xinyu Tian,Xuqing Li,Xiao Ma,Dongliang Xu,Tom Gedeon*

Main category: cs.CV

TL;DR: 论文提出了一种轻量级的Thought Graph Traversal（TGT）框架，通过测试时缩放提升视觉语言大模型（VLLMs）在放射学报告生成中的推理性能，无需额外训练。

- Motivation: 提升视觉语言大模型在放射学报告生成中的推理能力，无需修改模型本身。
- Method: 引入TGT框架，结合医学先验知识，动态调整推理深度，生成更准确的报告。
- Result: 方法在标准基准测试中优于基线提示方法，并能通过可追踪的推理路径揭示数据集偏差。
- Conclusion: TGT框架是一种简单有效的方法，可显著提升VLLMs在放射学报告生成中的性能。


### [89] [VGR: Visual Grounded Reasoning](https://arxiv.org/abs/2506.11991)
*Jiacong Wang,Zijiang Kang,Haochen Wang,Haiyong Jiang,Jiawen Li,Bohong Wu,Ya Wang,Jiao Ran,Xiao Liang,Chao Feng,Jun Xiao*

Main category: cs.CV

TL;DR: VGR是一种新型多模态推理模型，通过结合视觉定位和语言推理，提升细粒度视觉感知能力，显著优于纯语言空间的推理方法。

- Motivation: 现有方法主要依赖纯语言空间推理，存在语言偏见且局限于数学或科学领域，难以处理复杂视觉推理任务。
- Method: VGR通过检测相关图像区域并基于这些区域提供精确答案，引入VGR-SFT数据集和推理流程，结合视觉参考和重放阶段。
- Result: 在LLaVA-NeXT-7B基准上，VGR在多项多模态任务中表现优异，仅使用30%的图像标记，性能提升显著。
- Conclusion: VGR通过结合视觉和语言推理，有效解决了复杂视觉任务中的语言偏见问题，显著提升了多模态理解能力。


### [90] [Improving Surgical Risk Prediction Through Integrating Automated Body Composition Analysis: a Retrospective Trial on Colectomy Surgery](https://arxiv.org/abs/2506.11996)
*Hanxue Gu,Yaqian Chen,isoo Lee,Diego Schaps,Regina Woody,Roy Colglazier,Maciej A. Mazurowski,Christopher Mantyh*

Main category: cs.CV

TL;DR: 研究评估术前CT扫描自动提取的身体组成指标是否能单独或结合临床变量预测结肠切除术后结果，重点关注1年全因死亡率。

- Motivation: 探索术前身体组成指标对术后结果的预测能力，以优化手术风险评估。
- Method: 使用Cox比例风险模型和逻辑回归，评估300多个CT特征（如肌肉面积、脂肪面积）与术后结果的关系。
- Result: 通过C指数和综合Brier评分评估预测性能，同时分析术后并发症等次要结果。
- Conclusion: 术前CT身体组成指标可能为结肠切除术后结果提供有价值的预测信息。


### [91] [Affogato: Learning Open-Vocabulary Affordance Grounding with Automated Data Generation at Scale](https://arxiv.org/abs/2506.12009)
*Junha Lee,Eunha Park,Chunghyun Park,Dahyun Kang,Minsu Cho*

Main category: cs.CV

TL;DR: Affogato是一个大规模基准数据集，用于解决基于自然语言描述的交互进行物体区域定位的挑战，并开发了高效的视觉语言模型。

- Motivation: 解决交互描述中的细粒度部分级定位、多有效交互区域的模糊性以及大规模数据集稀缺的问题。
- Method: 利用预训练的部分感知视觉主干和文本条件热图解码器构建视觉语言模型。
- Result: 模型在现有2D和3D基准测试中表现优异，并展示了开放词汇跨域泛化的有效性。
- Conclusion: Affogato数据集和模型为解决交互描述中的定位问题提供了有效工具。
## q-bio.NC

### [92] [Sparse Autoencoders Bridge The Deep Learning Model and The Brain](https://arxiv.org/abs/2506.11123)
*Ziming Mao,Jia Xu,Zeqi Zheng,Haofang Zheng,Dabing Sheng,Yaochu Jin,Guoyuan Yang*

Main category: q-bio.NC

TL;DR: SAE-BrainMap框架通过稀疏自编码器（SAE）将深度学习视觉模型与fMRI信号对齐，揭示了模型与人类视觉皮层的层级映射关系。

- Motivation: 研究旨在建立深度学习模型与人类视觉皮层之间的直接联系，以增强模型的可解释性。
- Method: 训练层间SAE，计算SAE单元与fMRI信号的相似性，构建体素词典，并可视化信息转换。
- Result: SAE单元与fMRI信号强相关（相似度达0.76），ViT-B/16$_{CLIP}$在早期层利用低层信息生成高层语义。
- Conclusion: SAE-BrainMap为深度学习模型与人类视觉皮层提供了无下游任务的桥梁，提升了模型的可解释性。


### [93] [Voxel-Level Brain States Prediction Using Swin Transformer](https://arxiv.org/abs/2506.11455)
*Yifei Sun,Daniel Chahine,Qinghao Wen,Tianming Liu,Xiang Li,Yixuan Yuan,Fernando Calamante,Jinglei Lv*

Main category: q-bio.NC

TL;DR: 该研究提出了一种基于4D Swin Transformer的架构，用于预测人类静息状态下的脑活动，展示了高精度和潜在的应用价值。

- Motivation: 理解脑动力学对神经科学和心理健康至关重要，而fMRI技术为测量脑状态提供了可能。本研究旨在利用fMRI预测未来的脑状态。
- Method: 采用4D Swin Transformer作为编码器学习时空信息，结合卷积解码器，以保持输入fMRI数据的时空分辨率。使用HCP的100名受试者数据进行训练和测试。
- Result: 模型在基于23.04秒fMRI时间序列预测7.2秒静息态脑活动时表现出高准确性，预测结果与BOLD信号高度相似。
- Conclusion: 研究表明Swin Transformer能高效学习人脑的时空组织，为减少fMRI扫描时间和未来脑机接口开发提供了潜力。
## eess.IV

### [94] [Grids Often Outperform Implicit Neural Representations](https://arxiv.org/abs/2506.11139)
*Namhoon Kim,Sara Fridovich-Keil*

Main category: eess.IV

TL;DR: 研究比较了隐式神经表示（INRs）与网格表示在不同任务和信号类型中的性能，发现网格表示在大多数情况下表现更优，但INRs在低维结构信号（如形状轮廓）中表现更好。

- Motivation: 探索INRs的基本能力、隐式偏差和扩展行为，以填补当前对其理解不足的空白。
- Method: 通过多样化的INRs和网格表示，在2D和3D真实与合成信号上进行实验，包括过拟合和泛化任务（如断层扫描、超分辨率和去噪）。
- Result: 网格表示在大多数任务中训练更快且质量更高，而INRs在低维结构信号中表现更优。
- Conclusion: INRs在特定低维结构信号中具有优势，未来应用应针对这些场景。代码和合成信号已开源。


### [95] [ADAgent: LLM Agent for Alzheimer's Disease Analysis with Collaborative Coordinator](https://arxiv.org/abs/2506.11150)
*Wenlong Hou,Gangqian Yang,Ye Du,Yeung Lau,Lihao Liu,Junjun He,Ling Long,Shujun Wang*

Main category: eess.IV

TL;DR: ADAgent是一个基于大语言模型的AI代理，用于阿尔茨海默病（AD）的多模态诊断和预后任务，显著提升了准确率。

- Motivation: 早期和精确诊断AD至关重要，但现有方法多为单模态，无法处理多模态或缺失数据，需要更灵活的系统。
- Method: ADAgent结合推理引擎、专业医疗工具和协作结果协调器，支持多模态输入和任务。
- Result: 实验显示ADAgent优于现有方法，多模态诊断准确率提升2.7%，预后提升0.7%，MRI和PET诊断也有改进。
- Conclusion: ADAgent为AD分析提供了首个专用AI代理，支持多模态任务，显著提升了诊断和预后性能。


### [96] [Vector Representations of Vessel Trees](https://arxiv.org/abs/2506.11163)
*James Batten,Michiel Schaap,Matthew Sinclair,Ying Bai,Ben Glocker*

Main category: eess.IV

TL;DR: 提出了一种名为VeTTA的新型框架，用于学习树状几何数据（如3D血管网络）的向量表示，通过两阶段Transformer自编码器实现高效建模。

- Motivation: 传统3D卷积模型在GPU内存需求上较高，难以支持大规模训练，因此需要一种更高效的方法来建模树状结构的几何数据。
- Method: 采用两阶段Transformer自编码器：第一阶段（Vessel Autoencoder）学习单个血管段的几何细节；第二阶段（Vessel Tree Autoencoder）编码血管网络的拓扑结构，并通过递归解码确保重建的树结构有效。
- Result: 在2D合成树数据集和3D冠状动脉数据集上，VeTTA表现出更高的重建保真度、拓扑结构准确性和潜在空间插值能力。
- Conclusion: VeTTA框架为医学影像中的树状结构提供了精确、灵活且拓扑一致的建模方法，显著降低了GPU内存需求。


### [97] [DiffPR: Diffusion-Based Phase Reconstruction via Frequency-Decoupled Learning](https://arxiv.org/abs/2506.11183)
*Yi Zhang*

Main category: eess.IV

TL;DR: 论文提出DiffPR框架，通过消除高频跳跃连接和引入扩散模型，解决了定量相位成像中的过平滑问题，显著提升了性能。

- Motivation: 深度学习中过平滑问题导致定量相位成像（QPI）丢失高频细节，传统U-Net因频谱偏差而表现不佳。
- Method: 提出两阶段框架DiffPR：第一阶段用取消高频跳跃的U-Net预测低分辨率相位图；第二阶段用扩散模型恢复高频细节。
- Result: 在四个QPI数据集上，DiffPR比U-Net基线PSNR提升1.1 dB，MAE降低11%，细节更清晰。
- Conclusion: 消除高频跳跃连接并利用扩散模型合成细节，是解决频谱偏差的有效方法。


### [98] [Joint Denoising of Cryo-EM Projection Images using Polar Transformers](https://arxiv.org/abs/2506.11283)
*Joakim Andén,Justus Sagemüller*

Main category: eess.IV

TL;DR: 提出了一种基于Transformer的神经网络架构，用于同时聚类、对齐和去噪冷冻电镜图像，显著优于单图像DNN方法。

- Motivation: 传统DNN在高噪声环境下（如冷冻电镜图像）效果有限，但此类数据具有冗余信息，可通过聚类和对齐提升去噪效果。
- Method: 基于Transformer的架构，同时实现图像聚类、对齐和去噪。
- Result: 在合成数据上，相对MSE比单图像DNN降低了45%（SNR=0.03）。
- Conclusion: 该方法有效利用了数据冗余，显著提升了高噪声环境下的去噪性能。


### [99] [FAD-Net: Frequency-Domain Attention-Guided Diffusion Network for Coronary Artery Segmentation using Invasive Coronary Angiography](https://arxiv.org/abs/2506.11454)
*Nan Mu,Ruiqi Song,Xiaoning Li,Zhihui Xu,Jingfeng Jiang,Chen Zhao*

Main category: eess.IV

TL;DR: 提出了一种基于频域分析的深度学习模型FAD-Net，用于提高冠状动脉分割和狭窄检测的准确性。

- Motivation: 冠状动脉疾病是全球主要死因之一，精确分割冠状动脉对临床决策至关重要。
- Method: FAD-Net结合频域注意力机制和级联扩散策略，利用多级自注意力和低频扩散模块优化分割精度。
- Result: FAD-Net在分割中达到0.8717的Dice系数，狭窄检测的阳性预测值为0.6398，优于现有方法。
- Conclusion: FAD-Net在CAD的精确诊断和治疗规划中具有重要潜力。


### [100] [Taming Stable Diffusion for Computed Tomography Blind Super-Resolution](https://arxiv.org/abs/2506.11496)
*Chunlei Li,Yilei Shi,Haoxi Hu,Jingliang Hu,Xiao Xiang Zhu,Lichao Mou*

Main category: eess.IV

TL;DR: 提出了一种基于Stable Diffusion的CT盲超分辨率框架，结合退化模型和视觉语言模型，显著提升图像质量并降低辐射剂量。

- Motivation: 高分辨率CT成像对医疗诊断至关重要，但辐射剂量与图像质量之间存在矛盾。现有深度学习方法在复杂退化和有限医学数据下表现不佳。
- Method: 利用退化模型合成低质量图像，结合预训练视觉语言模型生成描述，通过Stable Diffusion实现超分辨率。
- Result: 实验表明，该方法优于现有方法，能在降低辐射剂量的同时获得高质量CT图像。
- Conclusion: 该框架为高质量CT成像提供了一种有效解决方案，代码将公开。


### [101] [FCA2: Frame Compression-Aware Autoencoder for Modular and Fast Compressed Video Super-Resolution](https://arxiv.org/abs/2506.11545)
*Zhaoyang Wang,Jie Li,Wen Lu,Lihuo He,Maoguo Gong,Xinbo Gao*

Main category: eess.IV

TL;DR: 提出了一种基于压缩驱动的降维策略，用于高效视频超分辨率（VSR），显著减少计算复杂度和推理时间。

- Motivation: 现有压缩视频超分辨率（CVSR）模型存在推理时间长、训练流程复杂、依赖辅助信息等问题，且传统帧间信息利用方法难以满足需求。
- Method: 受高光谱图像（HSI）与视频数据的结构相似性启发，采用压缩驱动的降维策略，设计模块化架构以提升时间信息提取效率。
- Result: 实验表明，该方法性能与或优于当前SOTA模型，同时显著减少推理时间。
- Conclusion: 该方法为VSR技术提供了一种高效实用的解决方案，代码已公开。


### [102] [Brain Network Analysis Based on Fine-tuned Self-supervised Model for Brain Disease Diagnosis](https://arxiv.org/abs/2506.11671)
*Yifei Tang,Hongjie Jiang,Changhong Jing,Hieu Pham,Shuqiang Wang*

Main category: eess.IV

TL;DR: 提出了一种基于多维度扩展的微调脑网络模型，用于脑疾病诊断，提升了模型的泛化能力，并在实验中表现出优越性能。

- Motivation: 现有脑网络基础模型研究有限且局限于单一维度，限制了其在神经科学中的广泛应用。
- Method: 模型包含两个关键模块：一个适配器模块用于多维度扩展脑区特征，以及一个基于自监督学习和预训练的微调基础脑网络模型，利用Transformer块提取特征和计算区域关联。
- Result: 下游实验表明，该模型在脑疾病诊断中表现出优越性能。
- Conclusion: 该模型为脑网络分析研究提供了一种有前景的方法。


### [103] [Exploring the Effectiveness of Deep Features from Domain-Specific Foundation Models in Retinal Image Synthesis](https://arxiv.org/abs/2506.11753)
*Zuzanna Skorniewska,Bartlomiej W. Papiez*

Main category: eess.IV

TL;DR: 论文探讨了在医学影像中，基于深度激活层的距离损失函数是否优于感知损失和边缘检测损失函数，发现传统边缘检测滤波器在提升合成样本血管结构清晰度上更有效。

- Motivation: 医学影像生成面临隐私、数据稀缺、成本高和偏见问题，深度生成模型提供解决方案，但需验证形态和临床准确性。
- Method: 研究了基于深度激活层的距离损失函数与感知损失、边缘检测损失函数的对比。
- Result: 领域特定的深度特征未提升自编码器图像生成效果，传统边缘检测滤波器在血管结构清晰度上表现更优。
- Conclusion: 传统边缘检测滤波器在医学影像合成中更有效，领域特定深度特征未带来显著优势。


### [104] [Framework of a multiscale data-driven digital twin of the muscle-skeletal system](https://arxiv.org/abs/2506.11821)
*Martina Paccini,Simone Cammarasana,Giuseppe Patanè*

Main category: eess.IV

TL;DR: 论文提出了一种基于数字孪生（MS-DT）的框架，用于整合多尺度生物力学数据，为肌肉骨骼系统提供个性化评估和治疗工具。

- Motivation: 肌肉骨骼疾病（MSDs）是全球致残的主要原因，需要先进的诊断和治疗工具。数字孪生范式因其能整合异构数据源而成为有效管理MSDs的有价值选择。
- Method: 通过结合运动捕捉、超声成像、肌电图和医学影像，MS-DT框架创建了患者特定的肌肉骨骼系统模型，并提供了交互式可视化平台。
- Result: 结果表明，MS-DT能够精确提取运动学和动态组织特征，为脊柱生物力学监测和康复提供了全面工具。
- Conclusion: MS-DT框架通过高保真建模和实时可视化，改善了患者特定的诊断和干预计划。


### [105] [Structural Similarity-Inspired Unfolding for Lightweight Image Super-Resolution](https://arxiv.org/abs/2506.11823)
*Zhangkai Ni,Yang Zhang,Wenhan Yang,Hanli Wang,Shiqi Wang,Sam Kwong*

Main category: eess.IV

TL;DR: 提出了一种基于结构相似性展开的高效图像超分辨率方法SSIU，结合数据驱动和模型驱动的优势，通过模块化设计实现高性能和低复杂度。

- Motivation: 现有数据驱动方法通过增加模型深度或使用注意力机制扩展感受野，但导致模型复杂度过高；模型驱动方法通过展开范式在保持紧凑性的同时提升性能。
- Method: SSIU方法通过展开受结构相似性约束的优化函数设计，包含混合尺度门控模块（MSGM）和高效稀疏注意力模块（ESAM），并利用专家混合特征选择器（MoE-FS）整合多级特征。
- Result: 实验表明，SSIU在性能上优于当前最优模型，同时参数更少、内存占用更低。
- Conclusion: SSIU成功结合数据驱动和模型驱动的优势，实现了高效且高性能的图像超分辨率。


### [106] [MindGrab for BrainChop: Fast and Accurate Skull Stripping for Command Line and Browser](https://arxiv.org/abs/2506.11860)
*Armina Fani,Mike Doan,Isabelle Le,Alex Fedorov,Malte Hoffmann,Chris Rorden,Sergey Plis*

Main category: eess.IV

TL;DR: MindGrab是一种参数和内存高效的深度全卷积模型，用于多模态头图像的颅骨剥离，性能优于传统方法，且资源需求显著降低。

- Motivation: 开发一种高效且适用于多模态头图像的颅骨剥离方法，以解决现有方法在资源需求和性能上的不足。
- Method: 基于频谱解释的扩张卷积架构，仅使用模态无关的合成数据进行训练。
- Result: 在606例多模态脑扫描数据上，MindGrab的平均Dice得分为95.9，显著优于ROBEX和BET，与SynthStrip性能相当或更优，同时参数减少95%，推理速度更快，内存占用更低。
- Conclusion: MindGrab在保持高精度的同时，显著降低了资源需求，适用于更广泛的硬件环境。


### [107] [crossMoDA Challenge: Evolution of Cross-Modality Domain Adaptation Techniques for Vestibular Schwannoma and Cochlea Segmentation from 2021 to 2023](https://arxiv.org/abs/2506.12006)
*Navodini Wijethilake,Reuben Dorent,Marina Ivory,Aaron Kujawa,Stefan Cornelissen,Patrick Langenhuizen,Mohamed Okasha,Anna Oviedova,Hexin Dong,Bogyeong Kang,Guillaume Sallé,Luyi Han,Ziyuan Zhao,Han Liu,Tao Yang,Shahad Hardan,Hussain Alasmawi,Santosh Sanjeev,Yuzhou Zhuang,Satoshi Kondo,Maria Baldeon Calisto,Shaikh Muhammad Uzair Noman,Cancan Chen,Ipek Oguz,Rongguo Zhang,Mina Rezaei,Susana K. Lai-Yuen,Satoshi Kasai,Chih-Cheng Hung,Mohammad Yaqub,Lisheng Wang,Benoit M. Dawant,Cuntai Guan,Ritse Mann,Vincent Jaouen,Ji-Wung Han,Li Zhang,Jonathan Shapey,Tom Vercauteren*

Main category: eess.IV

TL;DR: 跨模态域适应挑战（crossMoDA）系列聚焦于无监督跨模态分割，从对比增强T1 MRI迁移到T2 MRI，旨在自动化前庭神经鞘瘤和耳蜗分割。挑战目标逐年演进，数据集扩大和多样性增加提升了性能，但耳蜗分割得分下降。

- Motivation: 为临床提供更经济的前庭神经鞘瘤管理方案，通过跨模态分割自动化T2 MRI中的肿瘤和耳蜗分割。
- Method: 利用多机构数据和Koos分级，逐步增加数据异质性，包括肿瘤子分割。
- Result: 数据集扩大减少了异常值，但耳蜗分割性能因复杂性增加而下降。2023年获胜方法在早期测试数据上表现更好。
- Conclusion: 尽管进展显著，仍需改进以达到临床标准。未来可能需要更具挑战性的跨模态任务作为基准。
## cs.MA

### [108] [AutoGen Driven Multi Agent Framework for Iterative Crime Data Analysis and Prediction](https://arxiv.org/abs/2506.11475)
*Syeda Kisaa Fatima,Tehreem Zubair,Noman Ahmed,Asifullah Khan*

Main category: cs.MA

TL;DR: LUCID-MA是一个多AI代理协作分析犯罪数据的框架，包含分析、反馈和预测组件，通过离线运行和自我改进实现高效分析。

- Motivation: 解决犯罪数据分析中的隐私和效率问题，探索多代理协作在社会科学领域的潜力。
- Method: 使用LLaMA-2-13B-Chat-GPTQ模型，设计三个核心组件（分析、反馈、预测），并通过100轮通信实现自我改进。
- Result: 系统能够高效分析犯罪数据，预测未来趋势，并通过可视化跟踪学习进度。
- Conclusion: LUCID-MA展示了多代理系统在社会科学中的自主、可扩展和隐私保护的分析潜力。
## cs.CL

### [109] [CLAIM: Mitigating Multilingual Object Hallucination in Large Vision-Language Models with Cross-Lingual Attention Intervention](https://arxiv.org/abs/2506.11073)
*Zekai Ye,Qiming Li,Xiaocheng Feng,Libo Qin,Yichong Huang,Baohang Li,Kui Jiang,Yang Xiang,Zhirui Zhang,Yunfei Lu,Duyu Tang,Dandan Tu,Bing Qin*

Main category: cs.CL

TL;DR: CLAIM提出了一种无需训练的跨语言注意力干预方法，显著减少了多语言对象幻觉问题。

- Motivation: 大型视觉语言模型在多语言查询中容易产生与视觉输入不一致的响应，现有方法依赖资源密集的预训练或微调。
- Method: CLAIM通过识别语言特定的跨模态注意力头，估计语言转移向量，并在推理时干预注意力输出，实现跨语言视觉感知对齐。
- Result: 实验显示CLAIM在POPE和MME基准上分别平均提升13.56%和21.75%，西班牙语最高提升30%。
- Conclusion: CLAIM有效缓解多语言对象幻觉，中间层注意力在多语言场景中起关键作用。
## cs.RO

### [110] [Poutine: Vision-Language-Trajectory Pre-Training and Reinforcement Learning Post-Training Enable Robust End-to-End Autonomous Driving](https://arxiv.org/abs/2506.11234)
*Luke Rowe,Rodrigue de Schaetzen,Roger Girgis,Christopher Pal,Liam Paull*

Main category: cs.RO

TL;DR: Poutine是一个3B参数的视觉语言模型，专为长尾驾驶场景的端到端自动驾驶设计。通过两阶段训练（自监督VLT预训练和GRPO微调），在Waymo挑战赛中表现优异。

- Motivation: 解决长尾驾驶场景中的自动驾驶问题，提升模型的鲁棒性和泛化能力。
- Method: 两阶段训练：1）自监督VLT预训练；2）GRPO微调。
- Result: Poutine-Base验证集RFS为8.12，最终模型在Waymo测试集RFS为7.99，排名第一。
- Conclusion: VLT预训练和轻量级RL微调是实现鲁棒自动驾驶的有效方法。


### [111] [Gondola: Grounded Vision Language Planning for Generalizable Robotic Manipulation](https://arxiv.org/abs/2506.11261)
*Shizhe Chen,Ricardo Garcia,Paul Pacaud,Cordelia Schmid*

Main category: cs.RO

TL;DR: 论文提出Gondola模型，基于多视角图像和历史计划生成机器人操作的下一个动作计划，解决了现有LLM方法在视觉环境中生成接地计划不足的问题。

- Motivation: 机器人操作在泛化到未见过的对象、环境和任务时面临挑战，现有LLM方法在视觉接地和单视角输入上表现不足。
- Method: 引入Gondola模型，结合多视角图像和历史计划，生成包含文本和目标对象分割掩码的动作计划，并构建三类数据集支持训练。
- Result: Gondola在GemBench数据集的四个泛化级别上均优于现有LLM方法。
- Conclusion: Gondola通过多视角输入和视觉接地显著提升了机器人操作的泛化能力。


### [112] [Control Architecture and Design for a Multi-robotic Visual Servoing System in Automated Manufacturing Environment](https://arxiv.org/abs/2506.11387)
*Rongfei Li*

Main category: cs.RO

TL;DR: 论文探讨了机器人技术在制造中的应用，提出多机器人控制系统和相机移动策略以减少不确定性。

- Motivation: 人类在微尺度制造中仍优于机器人，机器人需应对环境不确定性（如测量噪声、模型不准确等）。
- Method: 设计多机器人控制系统模拟定位过程，并提出相机移动策略以优化图像噪声。
- Result: 多机器人系统显著减少不确定性，相机移动策略找到噪声最小化的最佳位置。
- Conclusion: 提出的控制算法和相机策略为自动化制造提供了经济高效的解决方案。
## cs.AI

### [113] [VLM@school -- Evaluation of AI image understanding on German middle school knowledge](https://arxiv.org/abs/2506.11604)
*René Peinl,Vincent Tischler*

Main category: cs.AI

TL;DR: 论文介绍了一个新的德语视觉语言模型（VLM）基准数据集，用于评估模型在结合视觉推理与学科背景知识任务中的表现。数据集基于真实中学课程，包含2000多个开放式问题和486张图像，测试了13个先进VLM模型，结果显示模型整体准确率低于45%，尤其在音乐、数学和对抗性问题中表现较差。

- Motivation: 现有英语基准数据集常依赖人为困难或脱离上下文的问题，而该研究旨在通过真实中学课程内容，更全面地评估VLM在非英语环境中的多模态理解能力。
- Method: 研究构建了一个包含9个学科（如数学、历史、生物等）的数据集，设计了2000多个开放式问题，并基于486张图像测试模型的视觉与事实推理能力。评估了13个先进VLM模型在多个维度上的表现。
- Result: 最强模型的整体准确率低于45%，在音乐、数学和对抗性问题中表现尤其差。结果表明，流行基准测试的成功与实际多模态理解能力存在显著差异。
- Conclusion: 中学水平的任务是测试VLM的有意义且未被充分利用的途径，尤其在非英语环境中。该数据集和评估协议为未来AI系统的视觉与语言推理能力提供了严格的测试平台。
## quant-ph

### [114] [HQFNN: A Compact Quantum-Fuzzy Neural Network for Accurate Image Classification](https://arxiv.org/abs/2506.11146)
*Jianhong Yao,Yangming Guo*

Main category: quant-ph

TL;DR: 提出了一种结合模糊推理和量子计算的新型神经网络HQFNN，在图像分类任务中表现优于传统方法，且具有参数高效性和噪声鲁棒性。

- Motivation: 解决深度学习在噪声输入和模型解释性上的不足，结合模糊推理的透明性和量子计算的高效性。
- Method: 通过浅层量子电路实现模糊推理流程，结合轻量级CNN特征提取器，利用量子信号进行分类。
- Result: HQFNN在标准图像基准测试中优于传统方法，参数更少且对噪声鲁棒。
- Conclusion: HQFNN是一种紧凑、可解释且噪声鲁棒的视觉模型，为未来量子模糊学习框架提供了模板。
## cs.AR

### [115] [Real-World Deployment of a Lane Change Prediction Architecture Based on Knowledge Graph Embeddings and Bayesian Inference](https://arxiv.org/abs/2506.11925)
*M. Manzour,Catherine M. Elias,Omar M. Shehata,R. Izquierdo,M. A. Sotelo*

Main category: cs.AR

TL;DR: 论文提出了一种基于知识图谱嵌入（KGEs）和贝叶斯推理的车道变换预测系统，并通过真实硬件实验验证其有效性。

- Motivation: 当前车道变换预测研究多局限于仿真或数据集，缺乏实际道路部署的验证，本文旨在填补这一空白。
- Method: 系统分为感知模块和预测模块：感知模块提取环境特征并转换为语言类别；预测模块通过KGE和贝叶斯推理预测目标车辆行为，并触发纵向制动。
- Result: 实验证明，系统能提前3-4秒预测车道变换，为自车提供充足反应时间，确保安全。
- Conclusion: 该研究为车道变换预测的实际应用提供了可行方案，验证了其安全性和有效性。
## cs.LG

### [116] [Developing a Dyslexia Indicator Using Eye Tracking](https://arxiv.org/abs/2506.11004)
*Kevin Cogan,Vuong M. Ngo,Mark Roantree*

Main category: cs.LG

TL;DR: 该论文研究了眼动追踪技术与机器学习算法结合作为低成本早期阅读障碍诊断方法的有效性，准确率达88.58%。

- Motivation: 阅读障碍影响全球10%至20%的人口，亟需创新且易获取的诊断方法。
- Method: 通过分析眼动模式（如注视时间延长和不规则扫视），提出改进方案，并采用随机森林分类器和层次聚类方法。
- Result: 随机森林分类器准确率为88.58%，层次聚类成功识别不同严重程度的阅读障碍。
- Conclusion: 眼动追踪与机器学习结合为非侵入性诊断提供了高精度且易用的方法，具有临床研究潜力。


### [117] [When Algorithms Play Favorites: Lookism in the Generation and Perception of Faces](https://arxiv.org/abs/2506.11025)
*Miriam Doh,Aditya Gulati,Matei Mancas,Nuria Oliver*

Main category: cs.LG

TL;DR: 论文探讨了合成人脸和基于机器学习的性别分类算法中存在的算法外貌主义（偏好外貌的现象），发现文本到图像系统将外貌吸引力与无关正面特质（如智力、可信度）关联，且性别分类模型在“不太吸引人”的面孔上错误率更高，尤其是非白人女性。

- Motivation: 研究旨在揭示算法外貌主义对合成人脸和性别分类的影响，关注其公平性问题。
- Method: 通过实验分析13,200张合成人脸，研究文本到图像系统和性别分类模型的表现。
- Result: 文本到图像系统将外貌吸引力与无关正面特质关联；性别分类模型在“不太吸引人”面孔上错误率更高，尤其是非白人女性。
- Conclusion: 研究结果引发对数字身份系统公平性的担忧。


### [118] [Tversky Neural Networks: Psychologically Plausible Deep Learning with Differentiable Tversky Similarity](https://arxiv.org/abs/2506.11035)
*Moussa Koulako Bala Doumbouya,Dan Jurafsky,Christopher D. Manning*

Main category: cs.LG

TL;DR: 论文提出了一种可微分的Tversky相似性参数化方法，用于深度学习中的非几何相似性建模，通过实验验证其在图像分类和语言建模中的优越性。

- Motivation: 传统深度学习的几何相似性模型与人类心理感知不符，而Tversky的基于特征的相似性理论尚未在深度学习中应用。
- Method: 开发了可微分的Tversky相似性参数化方法，并设计了Tversky投影层作为神经网络构建模块。
- Result: 在NABirds图像分类任务中，Tversky投影层相对线性层提升了24.7%的准确率；在GPT-2中，困惑度降低7.5%，参数减少34.8%。
- Conclusion: Tversky投影层提供了一种新的相似性建模范式，增强了模型的解释性，并验证了其有效性。


### [119] [RollingQ: Reviving the Cooperation Dynamics in Multimodal Transformer](https://arxiv.org/abs/2506.11465)
*Haotian Ni,Yake Wei,Hang Liu,Gong Chen,Chong Peng,Hao Lin,Di Hu*

Main category: cs.LG

TL;DR: 论文提出RollingQ方法，通过旋转查询打破自强化循环，恢复多模态Transformer的动态适应性。

- Motivation: 多模态学习中动态融合策略（如注意力机制）常因偏好某一模态而失效，导致动态适应性下降。
- Method: 提出RollingQ方法，通过旋转查询平衡注意力分配，缓解键分布差距。
- Result: 实验验证RollingQ能有效恢复动态适应性，提升多模态Transformer性能。
- Conclusion: RollingQ通过打破自强化循环，为多模态Transformer的动态融合提供了简单有效的解决方案。


### [120] [Visual Pre-Training on Unlabeled Images using Reinforcement Learning](https://arxiv.org/abs/2506.11967)
*Dibya Ghosh,Sergey Levine*

Main category: cs.LG

TL;DR: 将无标签图像预训练问题转化为强化学习问题，通过学习通用价值函数提升特征学习效果。

- Motivation: 观察到自监督图像预训练方法与强化学习中的价值学习存在相似性，希望通过强化学习框架改进特征学习。
- Method: 将图像预训练建模为强化学习问题，通过代理变换图像（如裁剪或增强）学习通用价值函数。
- Result: 在EpicKitchens、COCO和CC12M等数据集上表现出改进的特征学习效果。
- Conclusion: 强化学习框架为无标签图像预训练提供了有效方法，并能通过奖励函数调整特征学习。


### [121] [SIMSHIFT: A Benchmark for Adapting Neural Surrogates to Distribution Shifts](https://arxiv.org/abs/2506.12007)
*Paul Setinek,Gianluca Galletti,Thomas Gross,Dominik Schnürer,Johannes Brandstetter,Werner Zellinger*

Main category: cs.LG

TL;DR: 论文提出SIMSHIFT基准数据集，并扩展领域自适应方法以提升神经代理模型在未见问题配置下的性能。

- Motivation: 神经代理模型在未见问题配置下性能下降，而领域自适应技术在视觉和语言处理中表现良好，因此尝试将其应用于工业仿真任务。
- Method: 引入SIMSHIFT数据集，扩展领域自适应方法，结合源配置的参数描述和真实仿真数据，预测目标配置的仿真结果。
- Result: 实验表明，领域自适应在仿真任务中具有潜力，但分布偏移下神经代理模型的鲁棒性仍存在问题。
- Conclusion: 领域自适应可提升神经代理模型的泛化能力，但在工业场景中仍需解决分布偏移的挑战。


### [122] [EMLoC: Emulator-based Memory-efficient Fine-tuning with LoRA Correction](https://arxiv.org/abs/2506.12015)
*Hsi-Che Lin,Yu-Chu Yu,Kai-Po Chang,Yu-Chiang Frank Wang*

Main category: cs.LG

TL;DR: EMLoC是一个基于模拟器的内存高效微调框架，通过LoRA校正技术，实现在推理所需内存预算内完成模型微调。

- Motivation: 开源基础模型虽强大，但针对特定领域或个性化任务的微调因内存开销大而昂贵，限制了广泛应用。
- Method: EMLoC利用激活感知SVD构建轻量级模拟器，通过LoRA微调，并采用补偿算法校正模块，支持灵活压缩比和标准训练流程。
- Result: 实验表明，EMLoC在多个数据集和模态上优于基线方法，且能在24GB消费级GPU上微调38B模型。
- Conclusion: EMLoC为个体用户提供了高效、实用的模型适配方案。
## cs.CR

### [123] [GaussMarker: Robust Dual-Domain Watermark for Diffusion Models](https://arxiv.org/abs/2506.11444)
*Kecen Li,Zhicong Huang,Xinwen Hou,Cheng Hong*

Main category: cs.CR

TL;DR: 本文提出了一种双域扩散模型水印方法（GaussMarker），通过空间和频率域嵌入水印，并引入高斯噪声恢复器（GNR）提升鲁棒性。

- Motivation: 随着扩散模型生成图像的真实性提升，版权和滥用问题日益突出，现有水印方法在单域嵌入中鲁棒性不足。
- Method: 采用双域水印嵌入（空间和频率域），结合模型无关的高斯噪声恢复器（GNR）增强检测鲁棒性。
- Result: 在多种图像失真和高级攻击下，GaussMarker在三个Stable Diffusion版本中表现最优，召回率高且误报率低。
- Conclusion: GaussMarker通过双域嵌入和GNR显著提升了水印的鲁棒性，适用于实际应用。
## cs.GR

### [124] [Anti-Aliased 2D Gaussian Splatting](https://arxiv.org/abs/2506.11252)
*Mae Younes,Adnane Boukhayma*

Main category: cs.GR

TL;DR: AA-2DGS提出了一种抗锯齿的2D高斯泼溅方法，解决了2DGS在不同采样率下的锯齿问题，提升了渲染质量。

- Motivation: 2DGS在训练和渲染采样率不一致时会产生严重锯齿，限制了其实际应用。
- Method: 引入世界空间平滑核和对象空间Mip滤波器，约束频率内容并高效抗锯齿。
- Result: AA-2DGS显著提升了渲染质量，消除了高频锯齿。
- Conclusion: AA-2DGS在保持几何优势的同时，有效解决了2DGS的锯齿问题。


### [125] [CGVQM+D: Computer Graphics Video Quality Metric and Dataset](https://arxiv.org/abs/2506.11546)
*Akshay Jindal,Nabil Sadaka,Manu Mathew Thomas,Anton Sochenov,Anton Kaplanyan*

Main category: cs.GR

TL;DR: 论文提出了一个专注于高级渲染技术引入的失真的视频质量数据集，并开发了新的质量评估指标CGVQM，显著优于现有方法。

- Motivation: 现有视频和图像质量数据集主要研究自然视频和传统失真，而对合成内容和现代渲染失真的感知研究不足。
- Method: 提出了一个新型视频质量数据集，评估了多种高级渲染技术引入的失真，并基于预训练的3D CNN特征空间开发了CGVQM指标。
- Result: 现有全参考质量指标在这些失真上表现不佳（最大Pearson相关系数为0.78），CGVQM显著优于现有指标。
- Conclusion: CGVQM在合成内容的质量评估中表现优异，数据集和指标实现已开源。
## nlin.AO

### [126] [Solving Inverse Problems in Stochastic Self-Organising Systems through Invariant Representations](https://arxiv.org/abs/2506.11796)
*Elias Najarro,Nicolas Bessone,Sebastian Risi*

Main category: nlin.AO

TL;DR: 论文提出了一种新的逆向建模方法，用于处理可观测空间中的随机性，利用视觉嵌入生成鲁棒表示以捕捉感知不变性，从而有效恢复未知因果参数。

- Motivation: 自组织系统通过简单局部规则生成复杂随机模式，但传统逆向方法难以处理具有强随机性的观测数据。
- Method: 通过将模式表示映射到不变嵌入空间，无需手工设计目标函数或启发式方法，即可恢复未知因果参数。
- Result: 在反应扩散系统和基于代理的社会隔离模型上验证了方法的有效性，并成功应用于真实生物模式。
- Conclusion: 该方法为理论和实验研究者提供了研究复杂随机模式形成动态的有力工具。
