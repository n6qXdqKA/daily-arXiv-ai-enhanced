[[toc]]

## cs.CV

### [1] [MAT-Agent: Adaptive Multi-Agent Training Optimization](https://arxiv.org/abs/2510.17845)
*Jusheng Zhang,Kaitong Cai,Yijia Fan,Ningyuan Liu,Keze Wang*

Main category: cs.CV

TL;DR: 提出了MAT-Agent多智能体框架，通过自主智能体动态调整数据增强、优化器、学习率和损失函数，使用非平稳多臂老虎机算法平衡探索与利用，在多标签图像分类任务中实现优越性能。

- Motivation: 传统多标签图像分类方法依赖静态配置，在动态环境中表现不佳，需要自适应训练策略来应对复杂的视觉-语义场景变化。
- Method: MAT-Agent框架部署自主智能体动态调优训练参数，采用非平稳多臂老虎机算法，结合双速率指数移动平均平滑和混合精度训练，确保鲁棒性和效率。
- Result: 在Pascal VOC上达到97.4 mAP，COCO上92.8 mAP，VG-256上60.9 mAP，均优于基线方法，并实现加速收敛和跨域泛化。
- Conclusion: MAT-Agent为复杂视觉模型优化提供了可扩展的智能解决方案，推动了自适应深度学习的进步。


### [2] [CoIDO: Efficient Data Selection for Visual Instruction Tuning via Coupled Importance-Diversity Optimization](https://arxiv.org/abs/2510.17847)
*Yichen Yan,Ming Zhong,Qi Zhu,Xiaoling Gu,Jinpeng Chen,Huan Li*

Main category: cs.CV

TL;DR: CoIDO是一个新颖的双目标框架，通过联合优化数据重要性和多样性来解决多模态大语言模型指令调优中的计算瓶颈问题。

- Motivation: 现有数据选择方法存在两个关键缺陷：处理整个数据集的计算开销高，以及重要性评估和多样性选择分离导致次优选择。多模态大语言模型指令调优在大规模数据集上的训练计算成本仍然是一个主要瓶颈。
- Method: CoIDO采用轻量级插件评分器，仅需在小规模随机数据样本上训练来学习候选集的分布，大幅降低计算需求。通过同方差不确定性公式，在训练过程中有效平衡重要性和多样性，实现高效可扩展的数据选择。
- Result: 实验中使用仅20%随机采样数据训练CoIDO评分器，然后应用于整个数据集选择20%子集进行指令调优。在LLaVA-1.5-7B模型上的十个下游任务中，所选子集平均达到了全数据微调性能的98.2%。
- Conclusion: CoIDO框架能够显著降低多模态大语言模型指令调优的计算成本，同时保持接近全数据训练的性能，为高效数据选择提供了有效解决方案。


### [3] [Pre to Post-Treatment Glioblastoma MRI Prediction using a Latent Diffusion Model](https://arxiv.org/abs/2510.17851)
*Alexandre G. Leclercq,Sébastien Bougleux,Noémie N. Moreau,Alexis Desmonts,Romain Hérault,Aurélien Corroyer-Dulmont*

Main category: cs.CV

TL;DR: 提出一种基于潜在扩散模型的早期视觉治疗反应预测方法，通过将治疗前MRI和肿瘤定位信息作为条件，生成治疗后MRI来预测胶质母细胞瘤的治疗反应。

- Motivation: 胶质母细胞瘤患者对标准治疗的反应高度异质，通常需要至少两个月才能通过MRI观察到治疗效果。早期预测治疗反应对于推进个性化医疗至关重要。
- Method: 使用潜在扩散模型，以治疗前MRI和肿瘤定位信息作为条件输入，采用分类器自由引导来增强生成质量，并利用生存信息来指导模型学习。
- Result: 模型在包含140名胶质母细胞瘤患者的本地数据集上进行了训练和测试，数据集包括治疗前后T1-Gd MRI、专家手动勾画的肿瘤定位以及生存信息。
- Conclusion: 该方法能够通过生成治疗后MRI来早期预测胶质母细胞瘤的治疗反应，为个性化医疗提供支持。


### [4] [Provenance of AI-Generated Images: A Vector Similarity and Blockchain-based Approach](https://arxiv.org/abs/2510.17854)
*Jitendra Sharma,Arthur Carvalho,Suman Bhunia*

Main category: cs.CV

TL;DR: 提出基于嵌入向量的AI图像检测框架，通过图像嵌入和向量相似度区分AI生成图像与真实图像

- Motivation: 生成式AI和大型语言模型的快速发展使得AI生成图像难以与人类创作区分，这对数字内容认证构成挑战，需要验证数字数据的完整性和来源
- Method: 使用五个基准嵌入模型处理AI生成和人类创作图像的多样化数据集，基于假设：AI生成图像在嵌入空间中更接近其他AI生成内容，而人类创作图像在其领域内聚集
- Result: 实验证明该方法具有鲁棒性，中等至高程度扰动对嵌入签名影响最小，扰动图像与原始版本保持高度相似性匹配
- Conclusion: 该解决方案提供了一个可泛化的AI生成图像检测框架，在准确性和计算效率之间取得平衡


### [5] [CMIS-Net: A Cascaded Multi-Scale Individual Standardization Network for Backchannel Agreement Estimation](https://arxiv.org/abs/2510.17855)
*Yuxuan Huang,Kangzhong Wang,Eugene Yujun Fu,Grace Ngai,Peter H. F. Ng*

Main category: cs.CV

TL;DR: 提出CMIS-Net网络，通过多尺度个体标准化处理个体差异，在反馈信号检测中实现最先进性能

- Motivation: 反馈信号在对话中很重要，但个体表达差异大，现有情感识别方法难以处理多尺度行为线索的互补性
- Method: 使用级联多尺度个体标准化网络，在帧级和序列级去除个体特定中性基线，提取相对变化特征，并引入隐式数据增强模块
- Result: CMIS-Net有效处理个体差异和数据不平衡，在反馈信号一致性检测中达到最先进性能
- Conclusion: 多尺度个体标准化方法能更好地处理个体差异，提高模型泛化能力


### [6] [Shortcutting Pre-trained Flow Matching Diffusion Models is Almost Free Lunch](https://arxiv.org/abs/2510.17858)
*Xu Cai,Yang Wu,Qianli Chen,Haoran Wu,Lichuan Xiang,Hongkai Wen*

Main category: cs.CV

TL;DR: 提出了一种超高效的后训练方法，通过新颖的速度场自蒸馏技术，将大规模预训练流匹配扩散模型转化为高效的少步采样器。

- Motivation: 现有的流匹配捷径方法需要专门的步长嵌入，与现有模型不兼容，从头重新训练成本几乎与预训练本身一样高。
- Method: 利用独特的蒸馏原理，在速度场而非样本空间工作，通过在线自引导蒸馏快速学习，无需步长嵌入。
- Result: 该方法训练效率高，例如在不到一个A100天的时间内产生3步Flux模型，并能实现首次针对数十亿参数扩散模型的少样本蒸馏。
- Conclusion: 该方法不仅能在后训练阶段应用，还能融入预训练阶段本身，产生固有学习高效少步流而不牺牲质量的模型，以几乎零成本提供最先进性能。


### [7] [Robotic Classification of Divers' Swimming States using Visual Pose Keypoints as IMUs](https://arxiv.org/abs/2510.17863)
*Demetrious T. Kutzke,Ying-Kun Wu,Elizabeth Terveen,Junaed Sattar*

Main category: cs.CV

TL;DR: 提出了一种用于监测潜水员安全的混合方法，通过计算机视觉从3D人体关节点生成伪IMU数据，解决了水下无线信号衰减问题，用于识别医疗紧急情况。

- Motivation: 传统的人类活动识别方法在水下环境中效果不佳，特别是潜水员佩戴的传感器与AUV通信时存在无线信号衰减问题，需要一种新的方法来监测潜水员安全。
- Method: 利用计算机视觉从3D人体关节点流生成高保真运动数据，创建伪IMU，绕过水下无线通信限制，并将分类器集成到AUV上进行异常行为检测。
- Result: 通过在模拟紧急场景中进行实验，证明了该方法在机器人监测和潜水员安全方面的实用性和有效性。
- Conclusion: 该方法成功解决了水下环境中的潜水员安全监测问题，为预防潜水事故提供了有效的技术方案。


### [8] [InsideOut: Integrated RGB-Radiative Gaussian Splatting for Comprehensive 3D Object Representation](https://arxiv.org/abs/2510.17864)
*Jungmin Lee,Seonghyuk Hong,Juyong Lee,Jaeyoon Lee,Jongwon Choi*

Main category: cs.CV

TL;DR: InsideOut扩展3D高斯泼溅技术，融合RGB表面细节和X射线内部结构，解决多模态数据表示差异和配对数据集有限的问题

- Motivation: RGB和X射线成像融合在医疗诊断、文化遗产修复和制造等领域具有重要价值，但现有技术难以同时呈现高保真表面细节和内部结构
- Method: 收集新的配对RGB和X射线数据，进行分层拟合来对齐RGB和X射线辐射高斯泼溅，并提出X射线参考损失确保内部结构一致性
- Result: 有效解决了两种模态间数据表示差异和配对数据集有限的挑战
- Conclusion: 该方法显著扩展了3D高斯泼溅技术的应用范围，增强了各领域的可视化、模拟和无损检测能力


### [9] [MUSE: Model-based Uncertainty-aware Similarity Estimation for zero-shot 2D Object Detection and Segmentation](https://arxiv.org/abs/2510.17866)
*Sungmin Cho,Sungbum Park,Insoo Oh*

Main category: cs.CV

TL;DR: MUSE是一个无需训练、基于模型的零样本2D目标检测与分割框架，通过多视角模板渲染、联合相似度度量和不确定性感知优化，在BOP Challenge 2025中取得最先进性能。

- Motivation: 解决零样本2D目标检测与分割中的挑战，特别是在未见过的3D对象上实现准确检测，而无需额外训练或微调。
- Method: 使用3D未见对象的2D多视角模板渲染和查询图像的2D目标提议；集成类别和补丁嵌入，通过广义均值池化归一化；采用绝对和相对相似度联合度量；通过不确定性感知目标先验优化相似度得分。
- Result: 在BOP Challenge 2025中，在Classic Core、H3和Industrial赛道上均排名第一，实现了最先进的性能。
- Conclusion: MUSE提供了一个强大且可泛化的零样本2D目标检测与分割框架，无需额外训练即可取得优异结果。


### [10] [GAN-based Content-Conditioned Generation of Handwritten Musical Symbols](https://arxiv.org/abs/2510.17869)
*Gerard Asbert,Pau Torras,Lei Kang,Alicia Fornés,Josep Lladós*

Main category: cs.CV

TL;DR: 该研究使用GAN生成手写音乐符号，并通过Smashcima排版软件合成完整乐谱，以解决历史手写乐谱标注数据稀缺的问题。

- Motivation: 光学音乐识别领域面临历史手写乐谱真实标注数据稀缺的挑战，借鉴手写文本识别领域的经验，希望通过图像生成技术产生合成样本来训练更好的识别模型。
- Method: 实现了一个音乐符号级的生成对抗网络(GAN)来生成逼真的手写风格音乐符号，然后使用Smashcima排版软件将这些符号组装成完整乐谱。
- Result: 系统评估了生成样本的视觉保真度，发现生成的符号具有高度真实感，在合成乐谱生成方面取得了显著进展。
- Conclusion: 该方法能够生成逼真的手写风格音乐符号，为光学音乐识别领域提供了有价值的合成数据解决方案。


### [11] [Auditing and Mitigating Bias in Gender Classification Algorithms: A Data-Centric Approach](https://arxiv.org/abs/2510.17873)
*Tadesse K Bahiru,Natnael Tilahun Sinshaw,Teshager Hailemariam Moges,Dheeraj Kumar Singh*

Main category: cs.CV

TL;DR: 该论文分析了性别分类系统中的数据偏见问题，构建了BalancedFace平衡数据集来减少种族和性别偏见，显著提升了分类公平性。

- Motivation: 现有性别分类数据集存在显著的人口统计不平衡问题，导致训练出的模型存在性别和种族偏见，需要构建更平衡的数据集来解决这些问题。
- Method: 首先审计了五个广泛使用的数据集，发现都存在交叉代表性不足问题；然后构建BalancedFace数据集，通过混合FairFace和UTKFace的图像，并补充其他数据来填补人口统计空白，确保189个年龄、种族和性别交叉子组的平衡。
- Result: 在BalancedFace上训练的标准分类器将种族子组间的最大真阳性率差距减少了50%以上，平均差异影响得分比次优数据集更接近理想值1.0（改善63%），且整体准确率损失最小。
- Conclusion: 数据中心的干预措施具有重要价值，BalancedFace为公平性别分类研究提供了公开可用的资源，证明了通过精心设计的数据集可以有效减少模型偏见。


### [12] [3D Weakly Supervised Semantic Segmentation via Class-Aware and Geometry-Guided Pseudo-Label Refinement](https://arxiv.org/abs/2510.17875)
*Xiaoxu Xu,Xuexun Liu,Jinlong Li,Yitian Yuan,Qiudan Zhang,Lin Ma,Nicu Sebe,Xu Wang*

Main category: cs.CV

TL;DR: 提出了一种集成3D几何先验的弱监督语义分割方法，通过类感知和几何感知的标签细化机制生成高质量伪标签，在ScanNet和S3DIS基准上达到最先进性能。

- Motivation: 解决3D弱监督语义分割中伪标签质量低和3D几何先验利用不足的技术瓶颈，减少对密集点级标注的依赖。
- Method: 设计了类感知标签细化模块和几何感知标签细化组件，结合自训练策略迭代提升伪标签质量并扩展标签覆盖范围。
- Result: 在ScanNet和S3DIS基准测试中实现了最先进的性能，并在无监督设置下展现出优异的泛化能力。
- Conclusion: 该方法通过有效整合3D几何先验和类感知机制，成功解决了3D弱监督语义分割的关键挑战，为开发高性能模型提供了有效途径。


### [13] [Investigating Demographic Bias in Brain MRI Segmentation: A Comparative Study of Deep-Learning and Non-Deep-Learning Methods](https://arxiv.org/abs/2510.17999)
*Ghazal Danaee,Marc Niethammer,Jarrett Rushmore,Sylvain Bouix*

Main category: cs.CV

TL;DR: 评估三种分割模型和传统图谱方法在MRI图像中分割伏隔核时的公平性问题，发现种族匹配训练能提高某些模型的准确性，而nnU-Net表现稳健不受人口统计匹配影响。

- Motivation: 医学图像分割算法存在内在数据偏见，基于种族和性别等敏感属性的性能差异日益受到关注，需要评估分割模型在不同人口统计子组中的公平性。
- Method: 使用包含四个种族-性别子组的数据集，评估UNesT、nnU-Net、CoTr和ANTs模型在伏隔核分割中的表现，采用公平性指标和线性混合模型分析人口统计变量对分割准确性和体积测量的影响。
- Result: 种族匹配训练显著提高了ANTs和UNesT的分割准确性，但nnU-Net表现稳健不受人口统计匹配影响。手动分割观察到的性别效应在偏置模型中也能观察到，但种族效应在除一个模型外都消失了。
- Conclusion: 分割模型存在种族相关的性能差异，某些模型对训练数据的种族组成敏感，而nnU-Net表现出更好的公平性。偏置模型能保留性别效应但可能掩盖种族效应。


### [14] [ManzaiSet: A Multimodal Dataset of Viewer Responses to Japanese Manzai Comedy](https://arxiv.org/abs/2510.18014)
*Kazuki Kawamura,Kengo Nakai,Jun Rekimoto*

Main category: cs.CV

TL;DR: ManzaiSet是首个大规模日本漫才喜剧观众反应多模态数据集，包含241名参与者的面部视频和音频数据，揭示了三种观众类型和正向观看顺序效应。

- Motivation: 解决情感计算领域的西方中心主义偏见，为开发文化感知的情感AI和非西方背景的个性化娱乐系统提供数据支持。
- Method: 收集241名参与者观看10个专业漫才表演的多模态数据，使用k-means聚类分析观众类型，进行个体层面观看顺序效应分析，以及自动化幽默分类和观众反应建模。
- Result: 识别出三种观众类型：高稳定欣赏者(72.8%)、低可变下降者(13.2%)和可变改善者(14.0%)；发现正向观看顺序效应；自动化幽默分类未发现类型间显著差异。
- Conclusion: 该数据集支持文化感知情感AI开发，挑战了疲劳假说，强调了非西方文化背景下情感计算研究的重要性。


### [15] [ViBED-Net: Video Based Engagement Detection Network Using Face-Aware and Scene-Aware Spatiotemporal Cues](https://arxiv.org/abs/2510.18016)
*Prateek Gothwal,Deeptimaan Banerjee,Ashis Kumer Biswas*

Main category: cs.CV

TL;DR: 提出ViBED-Net深度学习框架，通过双流架构从视频数据评估学生参与度，在DAiSEE数据集上达到73.43%准确率，优于现有方法。

- Motivation: 在线学习环境中的参与度检测对于改善学生成果和个性化教学至关重要。
- Method: 使用双流架构，通过EfficientNetV2提取面部裁剪和完整视频帧的空间特征，然后使用LSTM和Transformer编码器进行时间建模，并应用针对性数据增强技术。
- Result: 在DAiSEE数据集上，ViBED-Net with LSTM变体达到73.43%准确率，优于现有最先进方法。
- Conclusion: 结合面部感知和场景感知的时空线索显著提高了参与度检测准确性，模块化设计使其可灵活应用于教育、用户体验研究和内容个性化等领域。


### [16] [SAVANT: Semantic Analysis with Vision-Augmented Anomaly deTection](https://arxiv.org/abs/2510.18034)
*Roberto Brusnicki,David Pop,Yuan Gao,Mattia Piccinini,Johannes Betz*

Main category: cs.CV

TL;DR: SAVANT是一个结构化推理框架，通过分层场景分析和两阶段流程，显著提升了自动驾驶系统中语义异常检测的准确性和召回率，使小型开源模型性能超越大型专有模型。

- Motivation: 解决自动驾驶系统在罕见、分布外语义异常场景中的脆弱性，以及现有视觉语言模型方法不可靠、依赖昂贵专有模型的问题。
- Method: 采用结构化推理框架，包含分层场景描述提取（街道、基础设施、可移动对象、环境）和多模态评估的两阶段流程。
- Result: 在真实驾驶场景中达到89.6%召回率和88.0%准确率；微调的7B参数开源模型达到90.8%召回率和93.8%准确率，超越所有评估模型。
- Conclusion: SAVANT框架解决了异常检测中的数据稀缺问题，为自动驾驶系统提供了可靠、可访问的语义监控实用路径。


### [17] [TriggerNet: A Novel Explainable AI Framework for Red Palm Mite Detection and Multi-Model Comparison and Heuristic-Guided Annotation](https://arxiv.org/abs/2510.18038)
*Harshini Suresha,Kavitha SH*

Main category: cs.CV

TL;DR: 本研究评估了多种机器学习和深度学习模型对红棕榈螨感染的植物分类和病害检测，并提出了TriggerNet可解释AI框架来生成视觉解释。

- Motivation: 红棕榈螨感染已成为棕榈种植区的严重问题，导致生产力下降和经济损失。准确早期识别受感染植物对有效管理至关重要。
- Method: 使用TriggerNet框架整合Grad-CAM、RISE、FullGrad和TCAV生成视觉解释。采用CNN、EfficientNet、MobileNet、ViT、ResNet50、InceptionV3等深度学习模型，以及随机森林、SVM、KNN等机器学习分类器。使用Snorkel通过启发式规则高效标注病害类别。
- Result: 研究涵盖了11种植物物种的图像数据集，将病害分为健康、黄斑、红褐色铜化和丝网四个类别进行训练和评估。
- Conclusion: 该研究为红棕榈螨感染检测提供了有效的可解释AI解决方案，有助于提高植物病害管理的准确性和效率。


### [18] [HouseTour: A Virtual Real Estate A(I)gent](https://arxiv.org/abs/2510.18054)
*Ata Çelen,Marc Pollefeys,Daniel Barath,Iro Armeni*

Main category: cs.CV

TL;DR: HouseTour方法从图像集合生成3D相机轨迹和自然语言描述，结合扩散模型和3D高斯泼溅技术，创建专业质量的房产展示视频。

- Motivation: 现有视觉语言模型在几何推理方面存在困难，无法生成平滑的3D相机轨迹和空间感知的描述，限制了在房地产和旅游应用中的自动化视频创建。
- Method: 使用扩散过程生成受已知相机位姿约束的平滑视频轨迹，将3D信息集成到视觉语言模型中，通过3D高斯泼溅技术渲染新视角，并构建了包含1200多个房屋游览视频的数据集。
- Result: 实验表明，将3D相机轨迹整合到文本生成过程中，相比独立处理每个任务的方法性能更好，提出了新的联合评估指标。
- Conclusion: 该方法能够在不需要专业知识和设备的情况下，为房地产和旅游应用自动创建专业质量的视频。


### [19] [Chimera: Compositional Image Generation using Part-based Concepting](https://arxiv.org/abs/2510.18083)
*Shivam Singh,Yiming Chen,Agneet Chatterjee,Amit Raj,James Hays,Yezhou Yang,Chitra Baral*

Main category: cs.CV

TL;DR: Chimera是一个个性化图像生成模型，能够根据文本指令将不同源图像的特定部分组合生成新对象，无需用户提供掩码或注释。

- Motivation: 现有个性化图像生成模型缺乏对多源图像特定部分组合的显式控制能力，需要用户提供掩码或注释。
- Method: 构建基于464个独特(部分，主体)对的语义原子数据集，生成37k提示并使用高保真文本到图像模型合成图像。训练带有部分条件引导的自定义扩散先验模型，引导图像条件特征以强制语义一致性和空间布局。
- Result: Chimera在部分对齐和组合准确性方面比基线方法提升14%，在视觉质量方面提升21%。
- Conclusion: Chimera能够有效组合多源图像的特定部分生成新对象，在组合准确性和视觉质量方面显著优于现有方法。


### [20] [Big Data, Tiny Targets: An Exploratory Study in Machine Learning-enhanced Detection of Microplastic from Filters](https://arxiv.org/abs/2510.18089)
*Paul-Tiberiu Miclea,Martin Sboron,Hardik Vaghasiya,Hoang Thinh Nguyen,Meet Gadara,Thomas Schmid*

Main category: cs.CV

TL;DR: 本研究探索了结合SEM成像和机器学习（特别是YOLO模型）进行微塑料检测的潜力、局限性和未来方向，重点关注具有对称重复背景图案的过滤场景。

- Motivation: 微塑料作为普遍污染物对生态系统和人类健康构成威胁，但传统检测方法需要手动分析，无法满足大规模筛查需求。机器学习为微塑料检测提供了新的解决方案。
- Method: 使用SEM成像结合基于YOLO的机器学习目标检测方法，在具有对称重复背景图案的过滤场景中进行微塑料颗粒和纤维的检测与量化。
- Result: 研究发现不同YOLO模型在检测任务中表现存在差异，预处理优化对检测效果至关重要，同时面临专家标注数据不足的挑战。
- Conclusion: 机器学习与SEM成像结合在微塑料检测中具有潜力，但需要解决数据标注不足等挑战，并优化预处理流程以提高检测可靠性。


### [21] [Accelerating Vision Transformers with Adaptive Patch Sizes](https://arxiv.org/abs/2510.18091)
*Rohan Choudhury,JungEun Kim,Jinhyung Park,Eunho Yang,László A. Jeni,Kris M. Kitani*

Main category: cs.CV

TL;DR: APT通过在同一图像中使用多种不同大小的补丁来优化ViT，在均匀区域使用大补丁、复杂区域使用小补丁，显著减少输入令牌数量，实现40-50%的推理加速，同时保持下游任务性能。

- Motivation: 传统ViT对高分辨率图像使用统一大小的补丁，导致输入序列过长，计算效率低下。需要一种能根据图像内容自适应调整补丁大小的方法来提高效率。
- Method: 提出自适应补丁变换器(APT)，在同一图像中根据内容复杂度使用多种不同大小的补丁：均匀区域用大补丁，复杂区域用小补丁，从而减少总输入令牌数量。
- Result: 在ViT-L和ViT-H上分别实现40%和50%的吞吐量提升，下游任务性能保持不变；可在已微调的ViT上应用，仅需1个epoch收敛；在视觉问答、目标检测和语义分割等密集视觉任务中训练和推理时间减少30%。
- Conclusion: APT通过自适应补丁分配策略，在不损失性能的前提下显著提升了ViT的计算效率，为高分辨率视觉任务提供了高效的解决方案。


### [22] [From Volume Rendering to 3D Gaussian Splatting: Theory and Applications](https://arxiv.org/abs/2510.18101)
*Vitor Pereira Matias,Daniel Perazzo,Vinicius Silva,Alberto Raposo,Luiz Velho,Afonso Paiva,Tiago Novello*

Main category: cs.CV

TL;DR: 本教程对3D高斯泼溅(3DGS)技术进行了全面概述，涵盖其基本原理、现有局限性的解决方案以及各种应用场景。

- Motivation: 3DGS虽然实现了实时渲染和新视角合成，但存在内存占用高、光照效果被直接烘焙到表示中以及次生射线效果支持有限等问题，需要系统性地梳理和解决这些挑战。
- Method: 从泼溅公式出发，探索解决3DGS局限性的主要方法，包括减少内存占用、分离光照效果和改进次生射线处理等技术。
- Result: 3DGS在表面重建、虚拟化身建模、动画和内容生成等应用中展现出高效渲染能力和前馈管道的适用性。
- Conclusion: 3D高斯泼溅技术正在推动3D重建领域的根本性变革，通过显式建模场景为3D高斯集合，实现了与通用图形管道的无缝集成，具有广阔的应用前景。


### [23] [Online In-Context Distillation for Low-Resource Vision Language Models](https://arxiv.org/abs/2510.18117)
*Zhiqi Kang,Rahaf Aljundi,Vaggelis Dorovatas,Karteek Alahari*

Main category: cs.CV

TL;DR: 提出了一种在线上下文蒸馏方法，让小规模视觉语言模型在推理时通过稀疏演示与强教师模型协作，在低资源环境下显著提升性能。

- Motivation: 解决视觉语言模型在低资源、预算受限环境中的部署问题，避免小模型需要昂贵微调才能缩小与大模型性能差距的困境。
- Method: 基于上下文学习框架，提出在线上下文蒸馏方法，包括跨模态演示选择策略、教师测试时缩放减少噪声、学生不确定性条件化动态填充演示池。
- Result: 小模型性能提升高达33%，仅需稀缺的教师标注（低至4%），能与教师的零样本性能竞争。
- Conclusion: 该方法为低资源环境下视觉语言模型的部署提供了有效解决方案，显著缩小了大小模型之间的性能差距。


### [24] [SafeCoop: Unravelling Full Stack Safety in Agentic Collaborative Driving](https://arxiv.org/abs/2510.18123)
*Xiangbo Gao,Tzu-Hsiang Lin,Ruojing Song,Yuheng Wu,Kuan-Ru Huang,Zicheng Jin,Fangzhou Lin,Shinan Liu,Zhengzhong Tu*

Main category: cs.CV

TL;DR: 该论文研究了基于自然语言的协作驾驶系统的安全与安全问题，提出了攻击分类和防御框架SafeCoop，在CARLA仿真中验证了有效性。

- Motivation: 传统V2X系统存在高带宽需求、语义丢失和互操作性等问题，自然语言作为通信媒介具有语义丰富、决策级推理等优势，但也引入了新的安全漏洞。
- Method: 开发了全面的攻击策略分类，并提出了SafeCoop防御框架，包括语义防火墙、语言-感知一致性检查和多源共识机制，通过智能体转换函数实现跨帧空间对齐。
- Result: 在CARLA仿真中32个关键场景下测试，恶意攻击下驾驶分数提升69.15%，恶意检测F1分数最高达67.32%。
- Conclusion: 该研究为推进交通运输系统中安全、可靠的语言驱动协作研究提供了指导。


### [25] [World-in-World: World Models in a Closed-Loop World](https://arxiv.org/abs/2510.18135)
*Jiahan Zhang,Muqing Jiang,Nanru Dai,Taiming Lu,Arda Uzunoglu,Shunchi Zhang,Yana Wei,Jiahao Wang,Vishal M. Patel,Paul Pu Liang,Daniel Khashabi,Cheng Peng,Rama Chellappa,Tianmin Shu,Alan Yuille,Yilun Du,Jieneng Chen*

Main category: cs.CV

TL;DR: World-in-World平台首次在闭环环境中评估生成世界模型对具身智能体的决策效用，发现视觉质量不等于任务成功率，可控性更重要，且推理时计算资源分配能显著提升性能。

- Motivation: 现有基准测试主要采用开环协议，孤立评估视觉质量，未能解决世界模型是否真正帮助具身智能体完成任务的核心问题。
- Method: 构建World-in-World开放平台，提供统一在线规划策略和标准化动作API，在四个闭环环境中评估多样化世界模型，以任务成功率为主要指标。
- Result: 发现三个意外结果：视觉质量不保证任务成功，可控性更重要；动作-观测数据后训练比升级预训练视频生成器更有效；增加推理时计算能大幅提升闭环性能。
- Conclusion: 世界模型在具身决策中的价值需要通过闭环评估来验证，可控性和推理优化比单纯视觉质量更重要。


### [26] [Adapting Stereo Vision From Objects To 3D Lunar Surface Reconstruction with the StereoLunar Dataset](https://arxiv.org/abs/2510.18172)
*Clementine Grethen,Simone Gasparini,Geraldine Morin,Jeremy Lebreton,Lucas Marti,Manuel Sanchez-Gestido*

Main category: cs.CV

TL;DR: 提出了LunarStereo数据集和基于MASt3R模型的月球3D重建方法，解决了月球表面缺乏纹理、光照变化和轨道轨迹异常等挑战。

- Motivation: 现有立体视觉重建方法在月球环境中表现不佳，因为月球缺乏纹理、光照变化复杂且轨道轨迹特殊。现有深度学习模型在行星图像上测试不足，无法直接应用于月球条件。
- Method: 创建了首个月球立体图像对数据集LunarStereo，使用光线追踪基于高分辨率地形和反射率模型模拟。通过在该数据集上微调MASt3R模型来适应月球领域。
- Result: 在合成和真实月球数据上的广泛实验验证了该方法，在3D表面重建和相对姿态估计方面相比零样本基线有显著改进。
- Conclusion: 该方法为地外环境中稳健的跨尺度泛化铺平了道路，显著提升了月球3D重建的性能。


### [27] [VelocityNet: Real-Time Crowd Anomaly Detection via Person-Specific Velocity Analysis](https://arxiv.org/abs/2510.18187)
*Fatima AlGhamdi,Omar Alharbi,Abdullah Aldwyish,Raied Aljadaany,Muhammad Kamran J Khan,Huda Alamri*

Main category: cs.CV

TL;DR: VelocityNet是一个双管道框架，结合头部检测和密集光流来提取个体速度，通过分层聚类将速度分类为语义运动类别，并使用百分位异常评分系统检测密集人群中的异常运动模式。

- Motivation: 解决现有方法在拥挤场景中由于严重遮挡和动态运动模式而难以适应不同人群密度、缺乏可解释异常指标的问题。
- Method: 结合头部检测和密集光流提取个体速度，使用分层聚类将速度分类为语义运动类别（停止、慢速、正常、快速），采用百分位异常评分系统衡量与学习到的正常模式的偏差。
- Result: 实验证明该框架在密集拥挤环境中能有效实时检测各种异常运动模式。
- Conclusion: VelocityNet框架能够有效解决拥挤场景中的异常检测挑战，提供可解释的异常指标并适应不同人群密度。


### [28] [RadDiagSeg-M: A Vision Language Model for Joint Diagnosis and Multi-Target Segmentation in Radiology](https://arxiv.org/abs/2510.18188)
*Chengrun Li,Corentin Royer,Haozhe Luo,Bastian Wittmann,Xia Li,Ibrahim Hamamci,Sezgin Er,Anjany Sekuboyina,Bjoern Menze*

Main category: cs.CV

TL;DR: 提出了RadDiagSeg-D数据集和RadDiagSeg-M模型，能够同时生成诊断文本和像素级分割掩码，解决医疗视觉语言模型在多模态输出方面的局限性。

- Motivation: 当前医疗视觉语言模型难以同时生成诊断文本和像素级分割掩码，这限制了在临床应用中的价值。
- Method: 首先创建RadDiagSeg-D数据集，整合异常检测、诊断和多目标分割任务；然后基于该数据集开发RadDiagSeg-M模型，实现联合异常检测、诊断和灵活分割。
- Result: RadDiagSeg-M在所有多目标文本和掩码生成任务组件上表现出色，建立了强大且具有竞争力的基准。
- Conclusion: 该方法有效解决了为辅助诊断提供丰富上下文信息的需求，为医疗视觉语言模型提供了实用的多模态输出能力。


### [29] [EMA-SAM: Exponential Moving-average for SAM-based PTMC Segmentation](https://arxiv.org/abs/2510.18213)
*Maryam Dialameh,Hossein Rajabzadeh,Jung Suk Sim,Hyock Ju Kwon*

Main category: cs.CV

TL;DR: EMA-SAM是一个轻量级扩展的SAM-2模型，通过引入置信度加权的指数移动平均指针来提供跨帧的稳定肿瘤潜在原型，显著提升了甲状腺微小乳头状癌超声视频分割的稳定性和准确性。

- Motivation: 甲状腺微小乳头状癌(PTMC)越来越多地使用射频消融(RFA)治疗，但超声视频中的病灶分割由于低对比度、探头引起的运动和热相关伪影而困难。SAM-2在静态图像上表现良好，但其帧独立设计在介入超声中产生不稳定预测和时间漂移。
- Method: EMA-SAM在SAM-2的基础上引入了一个轻量级的置信度加权指数移动平均指针到记忆库中，提供跨帧的稳定肿瘤潜在原型。该设计通过探头压力和气泡遮挡保持时间一致性，同时在清晰证据重新出现时快速适应。
- Result: 在PTMC-RFA数据集上，EMA-SAM将maxDice从0.82提升到0.86，maxIoU从0.72提升到0.76，同时减少29%的假阳性。在外部基准测试中，EMA-SAM相比SAM-2在Dice指标上获得2-5个百分点的稳定提升，且EMA指针仅增加<0.1%的FLOPs，在单个A100 GPU上保持约30FPS的实时吞吐量。
- Conclusion: EMA-SAM建立了一个稳健高效的肿瘤跟踪框架，弥合了基础模型与介入超声严格需求之间的差距。


### [30] [VLSU: Mapping the Limits of Joint Multimodal Understanding for AI Safety](https://arxiv.org/abs/2510.18214)
*Shruti Palaskar,Leon Gatys,Mona Abdelrahman,Mar Jacobo,Larry Lindsey,Rutika Moharir,Gunnar Lund,Yang Xu,Navid Shiee,Jeffrey Bigham,Charles Maalouf,Joseph Yitan Cheng*

Main category: cs.CV

TL;DR: VLSU框架系统评估多模态模型安全理解能力，发现模型在联合图像-文本推理时性能显著下降，存在组合推理能力缺失问题。

- Motivation: 现有安全评估方法将视觉和语言输入分开处理，忽略了联合解释中良性内容组合可能产生有害影响的风险，且无法清晰区分明确不安全内容和边界案例。
- Method: 提出VLSU框架，通过细粒度严重程度分类和17种安全模式的组合分析，使用多阶段流水线和真实图像构建包含8,187个样本的大规模基准数据集。
- Result: 评估11个最先进模型发现：模型在清晰单模态安全信号上准确率达90%以上，但在需要联合图像-文本推理时性能降至20-55%；34%的联合分类错误发生在各模态单独分类正确的情况下。
- Conclusion: 该框架揭示了当前模型在联合图像-文本理解和对齐方面的弱点，为稳健视觉语言安全研究的下一里程碑提供了关键测试平台。


### [31] [Beyond Frequency: Scoring-Driven Debiasing for Object Detection via Blueprint-Prompted Image Synthesis](https://arxiv.org/abs/2510.18229)
*Xinhao Cai,Liulei Li,Gensheng Pei,Tao Chen,Jinshan Pan,Yazhou Yao,Wenguan Wang*

Main category: cs.CV

TL;DR: 提出基于生成的物体检测去偏框架，通过表示分数诊断表示差距，使用视觉蓝图和生成对齐策略生成高质量无偏布局，显著提升罕见物体检测性能。

- Motivation: 现有去偏方法受限于样本表示多样性，单纯生成更多罕见类别数据效果不佳，因为实例频率不能完全反映模型真实需求，且现有布局到图像合成缺乏保真度和控制能力。
- Method: 引入表示分数诊断表示差距，创建无偏布局；用精确视觉蓝图替代模糊文本提示，采用生成对齐策略促进检测器和生成器之间的通信。
- Result: 显著缩小了代表性不足物体组的性能差距，大/罕见实例mAP分别提升4.4/3.6，布局准确性比现有L2I合成模型提升15.9 mAP。
- Conclusion: 该生成去偏框架能有效解决物体检测中的偏差问题，通过表示分数和生成对齐策略实现了高质量的无偏数据合成。


### [32] [DeepSeek-OCR: Contexts Optical Compression](https://arxiv.org/abs/2510.18234)
*Haoran Wei,Yaofeng Sun,Yukun Li*

Main category: cs.CV

TL;DR: DeepSeek-OCR是一个通过光学2D映射压缩长上下文的模型，包含DeepEncoder编码器和DeepSeek3B-MoE-A570M解码器，在保持高压缩比的同时实现97%的OCR精度。

- Motivation: 研究长上下文压缩的可行性，特别是在历史文档压缩和LLM内存遗忘机制等领域的应用潜力。
- Method: 使用DeepEncoder作为核心引擎，在高分辨率输入下保持低激活，同时实现高压缩比，确保视觉令牌数量可控。
- Result: 当文本令牌数量在视觉令牌10倍以内时，OCR精度达97%；压缩比20倍时精度仍保持约60%。在OmniDocBench上超越现有方法，仅用100视觉令牌超越GOT-OCR2.0，少于800令牌超越MinerU2.0。
- Conclusion: DeepSeek-OCR在长上下文压缩方面展现出巨大潜力，具有高实用价值，可每天生成20万+页的训练数据，代码和模型已开源。


### [33] [BlendCLIP: Bridging Synthetic and Real Domains for Zero-Shot 3D Object Classification with Multimodal Pretraining](https://arxiv.org/abs/2510.18244)
*Ajinkya Khoche,Gergő László Nagy,Maciej Wozniak,Thomas Gustafsson,Patric Jensfelt*

Main category: cs.CV

TL;DR: BlendCLIP是一个多模态预训练框架，通过结合合成数据和真实数据来解决3D物体分类中的领域差距问题，在nuScenes基准上实现了27%的零样本准确率提升。

- Motivation: 解决3D物体分类中合成训练数据与真实稀疏、噪声LiDAR扫描之间的领域差距问题，同时避免对大规模真实世界标注的依赖。
- Method: 提出一个生成对象级三元组（点云、图像、文本描述）的数据管道，并采用基于课程的数据混合策略，先在语义丰富的合成CAD数据上训练模型，然后逐步适应真实世界扫描特征。
- Result: 在nuScenes基准上零样本准确率提升27%，在nuScenes和TruckScenes数据集上达到最先进性能，比之前最佳方法提升19.3%，同时在合成基准上保持强泛化能力。
- Conclusion: 有效的领域适应而非全规模真实世界标注是实现鲁棒开放词汇3D感知的关键。


### [34] [OpenInsGaussian: Open-vocabulary Instance Gaussian Segmentation with Context-aware Cross-view Fusion](https://arxiv.org/abs/2510.18253)
*Tianyu Huang,Runnan Chen,Dongting Hu,Fengming Huang,Mingming Gong,Tongliang Liu*

Main category: cs.CV

TL;DR: OpenInsGaussian是一个开放词汇的3D高斯实例分割框架，通过上下文感知特征提取和注意力驱动的多视图特征融合，解决了现有方法在上下文信息不足和特征融合不一致方面的问题。

- Motivation: 现有的语义高斯喷洒方法存在两个主要限制：(1) 预处理过程中单个掩码的上下文线索不足；(2) 从2D模型融合多视图特征时存在不一致性和细节缺失。
- Method: 方法包含两个模块：上下文感知特征提取（为每个掩码增强丰富的语义上下文）和注意力驱动特征聚合（选择性融合多视图特征以减少对齐错误和不完整性）。
- Result: 在基准数据集上的广泛实验表明，OpenInsGaussian在开放词汇3D高斯分割方面取得了最先进的结果，大幅优于现有基线方法。
- Conclusion: 这些发现证明了所提出方法的鲁棒性和通用性，标志着在3D场景理解及其在实际部署方面迈出了重要一步。


### [35] [Hyperbolic Space Learning Method Leveraging Temporal Motion Priors for Human Mesh Recovery](https://arxiv.org/abs/2510.18256)
*Xiang Zhang,Suping Wu,Weibin Qiu,Zhaocheng Jin,Sheng Yang*

Main category: cs.CV

TL;DR: 提出了一种基于双曲空间学习的视频3D人体网格恢复方法，利用时间运动先验和双曲空间优化策略来准确捕捉人体层次结构，提高网格重建质量。

- Motivation: 现有视频3D人体网格恢复方法在欧几里得空间中学习网格特征，难以准确捕捉人体的层次结构（如躯干-肢体-手指），导致重建错误。
- Method: 设计时间运动先验提取模块，分别从3D姿态序列和图像特征序列提取时间运动特征并融合；提出双曲空间优化学习策略，利用时间运动先验在双曲空间中分别优化3D姿态和姿态运动信息；引入双曲网格优化损失确保学习过程稳定有效。
- Result: 在大型公开数据集上的广泛实验结果表明，该方法在性能上优于大多数最先进的方法。
- Conclusion: 通过将时间运动先验与双曲空间学习相结合，能够有效捕捉人体层次结构，生成准确平滑的3D人体网格。


### [36] [UWBench: A Comprehensive Vision-Language Benchmark for Underwater Understanding](https://arxiv.org/abs/2510.18262)
*Da Zhang,Chenggang Rong,Bingyu Li,Feiyu Wang,Zhiyuan Zhao,Junyu Gao,Xuelong Li*

Main category: cs.CV

TL;DR: 提出了UWBench，一个专门用于水下视觉语言理解的综合基准，包含15,003张高分辨率水下图像和丰富的标注数据，用于评估模型在水下环境中的表现。

- Motivation: 大型视觉语言模型在自然场景理解方面取得了显著成功，但在水下环境中的应用仍未被充分探索。水下图像存在严重的光衰减、颜色失真和悬浮粒子散射等独特挑战，且需要专门的海洋生态系统和生物分类学知识。
- Method: 构建了包含15,003张高分辨率水下图像的数据集，涵盖海洋、珊瑚礁和深海栖息地等多样化水生环境。每张图像都配备了人工验证的标注，包括15,281个物体指代表达式和124,983个问答对，覆盖从物体识别到生态关系理解的各种推理能力。
- Result: 基于UWBench建立了三个综合基准：详细图像描述、视觉定位和视觉问答。在最先进的视觉语言模型上的广泛实验表明，水下理解仍然具有挑战性，存在很大的改进空间。
- Conclusion: 该基准为推进水下环境中的视觉语言研究提供了重要资源，支持海洋科学、生态监测和自主水下探索等应用。


### [37] [Latent-Info and Low-Dimensional Learning for Human Mesh Recovery and Parallel Optimization](https://arxiv.org/abs/2510.18267)
*Xiang Zhang,Suping Wu,Sheng Yang*

Main category: cs.CV

TL;DR: 提出了一种基于潜在信息和低维学习的两阶段3D人体网格恢复网络，通过挖掘全局和局部信息，设计低维网格姿态交互方法，在降低计算成本的同时提升重建精度。

- Motivation: 现有3D人体网格恢复方法未能充分利用潜在信息（如人体运动、形状对齐），导致肢体错位和局部细节不足的问题，且基于注意力机制的交互方法计算成本高。
- Method: 两阶段网络：第一阶段从图像特征的低频和高频分量中挖掘全局和局部信息，聚合为混合潜在频率域特征；第二阶段利用这些特征，通过降维和并行优化的低维网格姿态交互方法优化人体网格的姿态和形状。
- Result: 在大型公开数据集上的广泛实验结果表明，该方法在重建精度和计算效率方面优于现有最先进方法。
- Conclusion: 提出的两阶段网络和低维交互方法有效解决了现有3D人体网格恢复中的信息利用不足和计算成本高的问题，实现了更好的重建效果。


### [38] [TreeFedDG: Alleviating Global Drift in Federated Domain Generalization for Medical Image Segmentation](https://arxiv.org/abs/2510.18268)
*Yucheng Song,Chenxi Li,Haokang Ding,Zhining Liao,Zhifang Liao*

Main category: cs.CV

TL;DR: 提出TreeFedDG框架解决联邦学习中的全局漂移问题，通过树形拓扑结构、参数差异风格混合和渐进式个性化融合策略，提升医学图像分割的跨域泛化性能。

- Motivation: 传统联邦学习方法在跨域场景下存在信息聚合不平衡问题，导致全局漂移和模型泛化性能下降，特别是在医学图像分割任务中需要保护隐私和处理数据异构性。
- Method: 1. 基于树形拓扑的分层参数聚合方法；2. 基于参数差异的风格混合方法(FedStyle)；3. 渐进式个性化融合策略；4. 推理阶段使用特征相似度检索相关模型链进行集成决策。
- Result: 在两个公开数据集上的实验表明，该方法优于其他最先进的域泛化方法，在跨域性能上取得了更好的平衡。
- Conclusion: TreeFedDG框架有效解决了联邦域泛化中的全局漂移问题，通过分层知识利用提升了医学图像分割的泛化性能。


### [39] [StreamingTOM: Streaming Token Compression for Efficient Video Understanding](https://arxiv.org/abs/2510.18269)
*Xueyi Chen,Keda Tao,Kele Shao,Huan Wang*

Main category: cs.CV

TL;DR: StreamingTOM是一个无需训练、即插即用的两阶段框架，通过因果时间缩减和在线量化内存技术，解决了流式视频视觉语言模型中的因果性和累积性问题，显著降低了计算和内存开销。

- Motivation: 流式视频视觉语言模型面临两个基本约束：因果性（无法访问未来帧）和累积性（令牌无限增长导致效率瓶颈）。现有方法只调节后LLM的kv缓存，而忽略了成本高昂的前LLM预填充阶段。
- Method: 1. 因果时间缩减：基于相邻帧变化和令牌显著性选择令牌，每帧只处理紧凑的视觉令牌子集；2. 在线量化内存：以4位格式存储令牌，按需检索相关组并反量化，保持活跃kv缓存有界。
- Result: 实现了15.7倍的kv缓存压缩，峰值内存降低1.2倍，TTFT（首次令牌时间）提升2倍。在离线基准测试中平均准确率达到63.8%，在RVS上达到55.8%/3.7，在无需训练的方法中保持最先进的准确性。
- Conclusion: StreamingTOM的两阶段方法为高效流式视频理解提供了实用优势，实现了有界增长的计算效率。


### [40] [Efficient Few-shot Identity Preserving Attribute Editing for 3D-aware Deep Generative Models](https://arxiv.org/abs/2510.18287)
*Vishal Vinod*

Main category: cs.CV

TL;DR: 提出了一种基于3D感知生成模型和2D人像编辑技术的少样本身份保持属性编辑方法，仅需10个或更少的标记图像即可在潜在空间中估计3D感知属性编辑方向。

- Motivation: 解决3D人脸身份保持编辑的挑战，包括多视角一致性、高分辨率编辑的灵活性不足，以及需要大规模属性标记数据集的问题。
- Method: 利用3D感知深度生成模型和2D人像编辑技术，通过少量标记图像估计潜在空间编辑方向，使用现有带掩码的人脸数据集生成合成图像。
- Result: 实验结果表明仅需10个或更少的标记图像即可实现3D感知属性编辑，展示了编辑的线性特性，并探索了连续风格流形用于3D一致的身份保持人脸老化。
- Conclusion: 该方法有效缓解了3D人脸编辑的约束，实现了高效的身份保持属性编辑，为3D生成模型提供了实用的编辑能力。


### [41] [GeoDiff: Geometry-Guided Diffusion for Metric Depth Estimation](https://arxiv.org/abs/2510.18291)
*Tuan Pham,Thanh-Tung Le,Xiaohui Xie,Stephan Mandt*

Main category: cs.CV

TL;DR: 提出一种结合立体视觉引导的度量深度估计框架，通过预训练扩散模型和立体几何约束解决单图像深度估计的尺度模糊问题，无需重新训练即可在各种环境中实现准确度量深度恢复。

- Motivation: 现有基于扩散的单目深度估计方法在相对深度预测方面表现优异，但由于单图像场景中的尺度模糊问题，估计绝对度量深度仍然具有挑战性。
- Method: 将深度估计重新定义为逆问题，利用预训练的潜在扩散模型结合RGB图像条件，并通过立体几何约束学习尺度和偏移参数，实现准确的深度恢复。
- Result: 在室内、室外和复杂环境中的广泛实验表明，该方法匹配或超越了最先进的方法，特别是在涉及半透明和镜面表面的挑战性场景中。
- Conclusion: 该免训练解决方案能够无缝集成到现有DB-MDE框架中，并在各种环境中实现泛化，为解决度量深度估计的尺度模糊问题提供了有效途径。


### [42] [Proactive Reasoning-with-Retrieval Framework for Medical Multimodal Large Language Models](https://arxiv.org/abs/2510.18303)
*Lehan Wang,Yi Qin,Honglong Yang,Xiaomeng Li*

Main category: cs.CV

TL;DR: 提出了首个多模态医学推理检索框架Med-RwR，通过主动检索外部知识来提升多模态大语言模型在医学诊断中的推理能力，解决了现有模型仅依赖内部知识导致的幻觉推理问题。

- Motivation: 现有医学多模态大语言模型仅依赖内部知识进行推理，当遇到超出训练范围的病例时会产生幻觉推理和事实错误。虽然现有检索增强生成方法能激发模型的主动检索能力，但仅限于单模态语言模型，忽略了关键的视觉信息。
- Method: 设计了基于强化学习的两阶段策略，通过定制奖励机制激励模型同时利用视觉诊断发现和文本临床信息进行有效检索。还提出了置信度驱动的图像再检索方法，在检测到低预测置信度时进行测试时扩展。
- Result: 在多个公共医学基准测试中，Med-RwR相比基线模型有显著改进，证明了通过外部知识整合增强推理能力的有效性。在提出的超声心动图基准测试上获得了8.8%的性能提升，显示出对陌生领域的出色泛化能力。
- Conclusion: Med-RwR框架通过主动检索外部知识有效提升了多模态医学模型的推理能力，解决了幻觉推理问题，并展现出强大的领域泛化能力，为医学诊断提供了更可靠的解决方案。


### [43] [The Impact of Image Resolution on Biomedical Multimodal Large Language Models](https://arxiv.org/abs/2510.18304)
*Liangyu Chen,James Burgess,Jeffrey J Nirschl,Orr Zohar,Serena Yeung-Levy*

Main category: cs.CV

TL;DR: 研究发现图像分辨率对生物医学多模态大语言模型性能至关重要，原生分辨率训练和推理能显著提升性能，分辨率不匹配会严重降低性能，混合分辨率训练能有效缓解此问题。

- Motivation: 现有MLLM主要针对通用低分辨率图像设计，在生物医学高分辨率图像分析中可能导致关键信息丢失，需要研究分辨率对性能的影响。
- Method: 通过实验研究图像分辨率对MLLM性能的影响，比较原生分辨率训练推理、分辨率不匹配情况以及混合分辨率训练的效果。
- Result: 原生分辨率训练推理显著提升多任务性能；训练与推理分辨率不匹配会严重降低性能；混合分辨率训练能有效缓解不匹配问题并平衡计算约束与性能需求。
- Conclusion: 建议优先采用原生分辨率推理和混合分辨率数据集，以优化生物医学MLLM在科学研究和临床应用中的表现。


### [44] [OmniNWM: Omniscient Driving Navigation World Models](https://arxiv.org/abs/2510.18313)
*Bohan Li,Zhuang Ma,Dalong Du,Baorui Peng,Zhujin Liang,Zhenqiang Liu,Chao Ma,Yueming Jin,Hao Zhao,Wenjun Zeng,Xin Jin*

Main category: cs.CV

TL;DR: OmniNWM是一个全景导航世界模型，在状态、动作和奖励三个维度上统一处理，能够生成全景视频并实现精确控制。

- Motivation: 现有的自动驾驶世界模型在状态模态、视频序列长度、动作控制和奖励感知方面存在限制，需要更全面的解决方案。
- Method: 使用全景Plucker射线图表示动作，联合生成RGB、语义、深度和3D占据图，并基于生成的3D占据定义规则化密集奖励。
- Result: 在视频生成、控制精度和长时稳定性方面达到最先进性能，提供可靠的闭环评估框架。
- Conclusion: OmniNWM在自动驾驶世界模型的三个核心维度上实现了统一且有效的处理，为自动驾驶提供了更全面的解决方案。


### [45] [Beyond Single Models: Mitigating Multimodal Hallucinations via Adaptive Token Ensemble Decoding](https://arxiv.org/abs/2510.18321)
*Jinlin Li,Yuran Wang,Yifei Yuan,Xiao Zhou,Yingying Zhang,Xixian Yong,Yefeng Zheng,Xian Wu*

Main category: cs.CV

TL;DR: 提出了一种名为自适应令牌集成解码（ATED）的训练免费方法，通过集成多个大型视觉语言模型的输出来减少对象幻觉问题，在保持流畅性和相关性的同时显著降低幻觉率。

- Motivation: 大型视觉语言模型在图像描述和视觉问答等任务中表现出色，但容易产生对象幻觉——描述不存在或识别错误的物体。现有方法存在可扩展性、适应性和模型独立性方面的挑战。
- Method: 提出自适应令牌集成解码框架，在推理过程中动态计算基于不确定性的权重来聚合多个模型的预测，并集成不同的解码路径以改善上下文基础和语义一致性。
- Result: 在标准幻觉检测基准测试中，ATED显著优于最先进的方法，在不影响流畅性或相关性的情况下减少了幻觉。
- Conclusion: 自适应集成方法为提升大型视觉语言模型在高风险应用中的鲁棒性提供了有前景的方向。


### [46] [Enhancing Few-Shot Classification of Benchmark and Disaster Imagery with ATTBHFA-Net](https://arxiv.org/abs/2510.18326)
*Gao Yu Lee,Tanmoy Dam,Md Meftahul Ferdaus,Daniel Puiu Poenar,Vu Duong*

Main category: cs.CV

TL;DR: 提出ATTBHFA-Net网络，结合Bhattacharyya系数和Hellinger距离来增强少样本学习在灾害图像分类中的性能，解决了灾害图像数据稀缺、类内差异大和类间相似性高的问题。

- Motivation: 灾害频发需要先进的视觉识别技术，但灾害图像数据稀缺且质量参差不齐，传统少样本学习方法在灾害场景中效果有限，因为灾害图像具有高类内变异和类间相似性。
- Method: 提出ATTBHFA-Net网络，线性结合Bhattacharyya系数和Hellinger距离来比较和聚合特征概率分布，形成鲁棒原型。Bhattacharyya系数增强类间可分性，Hellinger距离正则化同类对齐。
- Result: 在四个少样本学习基准和两个灾害图像数据集上的实验表明，ATTBHFA-Net相比现有方法具有更优的有效性和泛化能力。
- Conclusion: ATTBHFA-Net通过概率分布层面的对比学习，显著提升了少样本学习在灾害图像分类中的性能，为解决灾害视觉识别中的数据稀缺问题提供了有效方案。


### [47] [ViSE: A Systematic Approach to Vision-Only Street-View Extrapolation](https://arxiv.org/abs/2510.18341)
*Kaiyuan Tan,Yingying Shen,Haiyang Sun,Bing Wang,Guang Chen,Hangjun Ye*

Main category: cs.CV

TL;DR: 提出一个四阶段管道用于街景外推，在RealADSim-NVS基准测试中获得第一名，解决了自动驾驶闭环模拟中的视图外推挑战。

- Motivation: 当前的新视角合成方法在原始轨迹之外会产生扭曲和不一致的图像，无法满足自动驾驶闭环模拟对真实视图外推的需求。
- Method: 四阶段管道：1) 数据驱动初始化生成伪LiDAR点云；2) 使用降维2D-SDF建模道路表面几何先验；3) 利用生成先验创建外推视点的伪真值；4) 数据驱动适应网络去除时间特定伪影。
- Result: 在RealADSim-NVS基准测试中获得最终得分0.441，在所有参与者中排名第一。
- Conclusion: 该方法通过结合几何先验和生成先验，有效解决了街景外推的挑战，为自动驾驶闭环模拟提供了高质量的视图外推解决方案。


### [48] [GPTFace: Generative Pre-training of Facial-Linguistic Transformer by Span Masking and Weakly Correlated Text-image Data](https://arxiv.org/abs/2510.18345)
*Yudong Li,Hao Li,Xianxu Hou,Linlin Shen*

Main category: cs.CV

TL;DR: 提出了一种基于大规模网络数据的生成式预训练模型，用于面部知识学习，通过自监督任务训练，并在生成阶段利用图像-文本匹配损失实现可控的图像/文本生成。

- Motivation: 当前面部知识学习的大规模预训练模型研究有限，主要依赖人工标注数据集，存在标注成本高和模型扩展性有限的问题。
- Method: 使用从互联网爬取的包含人脸的文本和图像数据，进行自监督预训练，包括掩码图像/语言建模和图像-文本匹配。在生成阶段利用图像-文本匹配损失控制生成分布。
- Result: 模型在各种面部下游任务（如属性分类和表情识别）上达到与最先进预训练模型相当的性能，并适用于多种面部编辑任务。
- Conclusion: 该方法通过利用大规模网络数据解决了人工标注的限制，实现了有效的面部知识学习和可控生成。


### [49] [AV-Master: Dual-Path Comprehensive Perception Makes Better Audio-Visual Question Answering](https://arxiv.org/abs/2510.18346)
*Jiayu Zhang,Qilang Ye,Shuo Ye,Xun Lin,Zihan Song,Zitong Yu*

Main category: cs.CV

TL;DR: 提出了AV-Master框架，通过动态建模时间和模态维度来增强从复杂音视频场景中提取关键信息的能力，显著提升了音视频问答性能。

- Motivation: 现有方法在时间采样和模态偏好感知方面缺乏足够的灵活性和动态适应性，难以根据问题聚焦关键信息，限制了在复杂场景中的推理能力。
- Method: 1) 时间维度：动态自适应聚焦采样机制，逐步关注与问题最相关的音视频片段；2) 模态维度：偏好感知策略，独立建模各模态贡献；3) 双路径对比损失，增强跨维度一致性和互补性。
- Result: 在四个大规模基准测试中，AV-Master显著优于现有方法，特别是在复杂推理任务中表现突出。
- Conclusion: AV-Master通过动态建模时间和模态维度，有效解决了音视频问答中的冗余内容和片段碎片化问题，提升了模型在复杂场景下的推理能力。


### [50] [Ranking-based Preference Optimization for Diffusion Models from Implicit User Feedback](https://arxiv.org/abs/2510.18353)
*Yi-Lun Wu,Bo-Kai Ruan,Chiang Tseng,Hong-Han Shuai*

Main category: cs.CV

TL;DR: 提出了Diffusion-DRO框架，通过逆强化学习将偏好学习转化为排序问题，解决了DPO方法中的非线性估计问题，并整合了离线专家演示和在线策略生成的负样本。

- Motivation: 现有的DPO方法在文本到图像扩散模型对齐中面临非线性sigmoid函数导致的图像概率估计不准确和离线数据多样性有限的问题。
- Method: 基于逆强化学习，将偏好学习转化为排序问题，简化训练目标为去噪公式，并整合离线专家演示和在线策略生成的负样本。
- Result: 在多个具有挑战性和未见过的提示上实现了改进的生成质量，在定量指标和用户研究中均优于最先进的基线方法。
- Conclusion: Diffusion-DRO通过消除对奖励模型的依赖并有效整合离线在线数据，为文本到图像扩散模型的偏好对齐提供了更有效的方法。


### [51] [Learning Human-Object Interaction as Groups](https://arxiv.org/abs/2510.18357)
*Jiajun Hong,Jianan Wei,Wenguan Wang*

Main category: cs.CV

TL;DR: GroupHOI是一个从群体视角重新审视关系建模的HOI检测框架，通过几何邻近性和语义相似性来传播上下文信息，在多个基准测试中优于现有方法。

- Motivation: 现有HOI检测方法主要关注成对关系，忽略了现实场景中交互往往来自集体行为（多人和物体参与联合活动）的事实。
- Method: 提出GroupHOI框架：1）使用基于边界框空间特征的可学习邻近性估计器将人和物体分组；2）在每个组内通过自注意力计算软对应关系来聚合和分发上下文线索；3）用HO对特征的局部上下文线索增强基于transformer的交互解码器。
- Result: 在HICO-DET和V-COCO基准测试中表现出优于现有方法的性能，在更具挑战性的非语言交互检测（NVI-DET）任务中也表现出领先性能。
- Conclusion: 从群体视角建模关系能有效处理现实场景中的集体行为交互，GroupHOI框架在HOI检测任务中表现出卓越性能。


### [52] [FeatureFool: Zero-Query Fooling of Video Models via Feature Map](https://arxiv.org/abs/2510.18362)
*Duoxun Tang,Xi Xiao,Guangwu Hu,Kangkang Sun,Xiao Yang,Dongyang Chen,Qing Li,Yongjie Yin,Jiyao Wang*

Main category: cs.CV

TL;DR: FeatureFool是一种针对视频模型的零查询黑盒攻击方法，通过利用DNN提取的特征信息来改变干净视频的特征空间，无需多次模型交互即可实现高效攻击。

- Motivation: 现有黑盒攻击方法需要多轮模型交互和大量查询，这在现实世界中不实用且难以扩展到新兴的Video-LLMs。视频领域缺乏直接利用特征映射来改变特征空间的攻击方法。
- Method: 提出FeatureFool攻击方法，通过提取DNN的信息来直接改变干净视频的特征空间，实现零查询攻击。该方法利用特征映射的可转移性来生成对抗性视频。
- Result: 实验显示FeatureFool对传统视频分类器的攻击成功率超过70%且无需任何查询。生成的对抗视频在SSIM、PSNR和时序一致性指标上质量很高，攻击几乎不可察觉。
- Conclusion: FeatureFool证明了在视频领域实现高效零查询黑盒攻击的可行性，能够绕过Video-LLM识别并生成高质量的对抗内容，为视频模型安全性研究提供了新视角。


### [53] [Cross-Modal Scene Semantic Alignment for Image Complexity Assessment](https://arxiv.org/abs/2510.18377)
*Yuqing Luo,Yixiao Li,Jiang Liu,Jun Fu,Hadi Amirpour,Guanghui Yue,Baoquan Zhao,Padraig Corcoran,Hantao Liu,Wei Zhou*

Main category: cs.CV

TL;DR: 提出了一种基于跨模态场景语义对齐的图像复杂度评估方法CM-SSA，通过结合视觉和文本模态信息来提升复杂度预测与人类主观感知的一致性。

- Motivation: 现有ICA方法主要依赖单模态视觉特征，无法充分捕捉与图像复杂度相关的感知表示。跨模态场景语义信息在感知理解任务中具有重要作用，但在ICA领域尚未被探索。
- Method: CM-SSA包含复杂度回归分支和场景语义对齐分支。回归分支在语义对齐分支的指导下估计图像复杂度，语义对齐分支通过成对学习将图像与包含丰富场景语义的文本提示对齐。
- Result: 在多个ICA数据集上的实验表明，CM-SSA显著优于现有最先进方法。
- Conclusion: 跨模态场景语义对齐能有效提升图像复杂度评估性能，使预测结果更符合人类主观感知。


### [54] [S2AP: Score-space Sharpness Minimization for Adversarial Pruning](https://arxiv.org/abs/2510.18381)
*Giorgio Piras,Qi Zhao,Fabio Brau,Maura Pintor,Christian Wressnegger,Battista Biggio*

Main category: cs.CV

TL;DR: 提出了一种新的对抗剪枝方法S2AP，通过在分数空间引入锐度感知优化来稳定掩码选择，提高剪枝后模型的鲁棒性。

- Motivation: 现有对抗剪枝方法在分数空间优化时容易陷入尖锐的局部极小值，导致掩码选择不稳定，从而降低剪枝后模型的鲁棒性。
- Method: 提出分数空间锐度感知对抗剪枝(S2AP)，在掩码搜索过程中通过扰动重要性分数并最小化相应的鲁棒损失来实现分数空间锐度最小化。
- Result: 在多个数据集、模型和稀疏度水平上的实验表明，S2AP能有效最小化分数空间锐度，稳定掩码选择，最终提高对抗剪枝方法的鲁棒性。
- Conclusion: S2AP方法通过分数空间锐度最小化解决了对抗剪枝中的掩码选择不稳定问题，显著提升了剪枝后模型的鲁棒性。


### [55] [Entropy-Enhanced Conformal Features from Ricci Flow for Robust Alzheimer's Disease Classification](https://arxiv.org/abs/2510.18396)
*F. Ahmadi,B. Bidabad,H. Nasiri*

Main category: cs.CV

TL;DR: 提出了一种基于共形几何特征熵的局部表面表示方法，用于阿尔茨海默病的自动诊断，在ADNI数据集上达到98.62%的分类准确率。

- Motivation: 阿尔茨海默病与显著的皮层萎缩相关，几何表面模型对于分析解剖结构的3D形状至关重要，需要开发准确的诊断工具。
- Method: 使用ADNI的160名参与者T1加权MRI数据，通过Freesurfer重建皮层表面模型，计算面积畸变、共形因子和高斯曲率等几何属性，应用香农熵创建特征向量，训练多种分类器。
- Result: 方法在区分AD患者和健康对照方面非常有效，MLP和逻辑回归分类器表现最佳，准确率和F1分数均达到98.62%。
- Conclusion: 共形几何特征的熵为皮层形态测量提供了强大而稳健的度量，高分类准确性表明该方法有潜力增强阿尔茨海默病的研究和诊断。


### [56] [Bayesian Fully-Connected Tensor Network for Hyperspectral-Multispectral Image Fusion](https://arxiv.org/abs/2510.18400)
*Linsong Shan,Zecan Yang,Laurence T. Yang,Changlong Li,Honglu Zhao,Xin Nie*

Main category: cs.CV

TL;DR: 提出了贝叶斯全连接张量网络(BFCTN)方法，通过概率框架和层次稀疏先验来改进高光谱-多光谱图像融合，减少人工参数调优需求，提高融合精度和鲁棒性。

- Motivation: 现有基于张量分解的融合方法存在数据向量化破坏空间-光谱结构、因子张量排列约束严格、需要大量人工参数调优以及对噪声和空间退化鲁棒性有限等问题。
- Method: 使用贝叶斯FCTN框架，引入层次稀疏先验来建模因子张量间的物理耦合关系，开发基于变分贝叶斯推理和EM算法的参数估计方法。
- Result: BFCTN在融合精度和鲁棒性方面达到最先进水平，在复杂真实场景中具有实际应用价值。
- Conclusion: BFCTN方法有效解决了传统张量分解融合方法的局限性，实现了更好的空间-光谱结构保持和跨维度相关性建模，同时显著减少了人工参数调优需求。


### [57] [Automated Wicket-Taking Delivery Segmentation and Weakness Detection in Cricket Videos Using OCR-Guided YOLOv8 and Trajectory Modeling](https://arxiv.org/abs/2510.18405)
*Mst Jannatun Ferdous,Masum Billah,Joy Karmoker,Mohd Ruhul Ameen,Akif Islam,Md. Omar Faruqe*

Main category: cs.CV

TL;DR: 基于深度学习的板球视频分析系统，使用YOLOv8进行球场和球检测，结合OCR提取记分卡信息，自动识别三柱门时刻并建模球轨迹。

- Motivation: 开发自动化板球视频分析系统，为教练和战略决策提供数据驱动的洞察，识别击球弱点。
- Method: 采用YOLOv8架构进行球场和球检测，结合OCR技术提取记分卡信息，通过灰度变换、幂变换和形态学操作等图像预处理技术增强文本提取效果。
- Result: 球场检测模型达到99.5% mAP50精度，精度0.999；球检测模型达到99.18% mAP50，精度0.968，召回率0.978。系统在多个板球比赛视频中验证有效。
- Conclusion: 该系统在自动化板球分析方面表现出色，具有显著的教练和战略决策应用潜力。


### [58] [ScaleNet: Scaling up Pretrained Neural Networks with Incremental Parameters](https://arxiv.org/abs/2510.18431)
*Zhiwei Hao,Jianyuan Guo,Li Shen,Kai Han,Yehui Tang,Han Hu,Yunhe Wang*

Main category: cs.CV

TL;DR: ScaleNet是一种高效的ViT模型扩展方法，通过在预训练模型中插入共享参数的附加层，实现快速模型扩展，显著降低训练成本。

- Motivation: 解决大型ViT模型训练计算成本高的问题，提供一种经济高效的模型扩展方案。
- Method: 在预训练ViT中插入附加层，采用层间权重共享保持参数效率，并通过并行适配器模块引入调整参数来缓解共享权重带来的性能下降。
- Result: 在ImageNet-1K上，2倍深度扩展的DeiT-Base模型相比从头训练准确率提升7.42%，且仅需三分之一的训练周期。
- Conclusion: ScaleNet为ViT模型扩展提供了高效解决方案，在图像分类和目标检测等下游任务中具有广泛应用潜力。


### [59] [ImageGem: In-the-wild Generative Image Interaction Dataset for Generative Model Personalization](https://arxiv.org/abs/2510.18433)
*Yuanhe Guo,Linxi Xie,Zhuoran Chen,Kangrui Yu,Ryan Po,Guandao Yang,Gordon Wetztein,Hongyi Wen*

Main category: cs.CV

TL;DR: ImageGem是一个用于研究理解细粒度个人偏好的生成模型的数据集，包含57K用户的真实交互数据，包括242K定制LoRAs、3M文本提示和5M生成图像。

- Motivation: 阻碍理解个人偏好的生成模型发展的关键挑战是缺乏真实世界和细粒度的用户偏好标注。
- Method: 利用用户偏好标注训练更好的偏好对齐模型，研究检索模型和视觉语言模型在个性化图像检索和生成模型推荐中的性能，提出在潜在权重空间中编辑定制扩散模型以对齐个人用户偏好的端到端框架。
- Result: 能够训练更好的偏好对齐模型，并首次实现了生成模型个性化的新范式。
- Conclusion: ImageGem数据集首次实现了生成模型个性化的新范式。


### [60] [Beyond Single Images: Retrieval Self-Augmented Unsupervised Camouflaged Object Detection](https://arxiv.org/abs/2510.18437)
*Ji Du,Xin Wang,Fangwei Hao,Mingyang Yu,Chunyuan Chen,Jiesheng Wu,Bin Wang,Jing Xu,Ping Li*

Main category: cs.CV

TL;DR: RISE是一种检索自增强的伪装目标检测方法，通过利用整个训练数据集生成伪标签来训练COD模型，无需人工标注。

- Motivation: 现有COD方法主要依赖图像级建模或基于标注的优化，难以利用数据集级别的上下文信息且依赖人工标注。
- Method: 提出RISE范式：1) 使用无标注训练图像构建环境和伪装对象的原型库；2) 采用聚类-检索策略生成高质量原型；3) 多视图KNN检索生成鲁棒的伪掩码。
- Result: 在广泛实验中，RISE在无监督和基于提示的方法中表现优于现有最优方法。
- Conclusion: RISE通过检索自增强范式有效利用数据集级信息，为伪装目标检测提供了无需标注的高质量训练方案。


### [61] [LAND: Lung and Nodule Diffusion for 3D Chest CT Synthesis with Anatomical Guidance](https://arxiv.org/abs/2510.18446)
*Anna Oliveras,Roger Marí,Rafael Redondo,Oriol Guardià,Ana Tost,Bhalaji Nagarajan,Carolina Migliorelli,Vicent Ribas,Petia Radeva*

Main category: cs.CV

TL;DR: 提出了一种新的潜在扩散模型，用于生成基于3D解剖掩码的高质量胸部CT扫描，显著降低了计算成本。

- Motivation: 现有方法生成3D CT扫描计算成本高，需要开发能在中等GPU上运行的高质量3D CT生成方法，为AI模型训练和医疗专业人员提供工具。
- Method: 使用潜在扩散模型，以3D解剖掩码（肺部和结节区域）为条件，生成256x256x256体积的CT图像，分辨率1mm各向同性。
- Result: 实验表明仅使用结节掩码会导致解剖结构错误，必须结合全局肺部结构才能实现准确的合成。该方法能生成具有不同属性肺结节的多样化CT体积。
- Conclusion: 该方法成功实现了在单块中等GPU上生成高质量3D胸部CT扫描，为AI训练和医疗教育提供了有价值的工具，并强调了全局解剖结构在条件合成中的重要性。


### [62] [Vision Foundation Models Can Be Good Tokenizers for Latent Diffusion Models](https://arxiv.org/abs/2510.18457)
*Tianci Bi,Xiaoyi Zhang,Yan Lu,Nanning Zheng*

Main category: cs.CV

TL;DR: 提出VFM-VAE直接集成视觉基础模型到潜在扩散模型，避免蒸馏方法导致的语义偏差问题，通过多尺度潜在融合和渐进分辨率重建实现高质量重构，并引入SE-CKNNA指标优化训练策略。

- Motivation: 现有基于蒸馏的方法会削弱与原始视觉基础模型的语义对齐鲁棒性，导致分布偏移时潜在表示发生语义偏差，需要更直接的集成方法。
- Method: 设计VFM-VAE变分自编码器，采用多尺度潜在融合和渐进分辨率重建模块，从空间粗糙的VFM特征实现高质量重构，并提出SE-CKNNA指标分析表示动态，开发联合分词器-扩散对齐策略。
- Result: 在80个epoch内达到gFID 2.20（无CFG），比先前分词器快10倍；在640个epoch后达到gFID 1.62，证明了直接VFM集成的优越性。
- Conclusion: 直接集成视觉基础模型是潜在扩散模型的更优范式，在性能和效率上均显著优于蒸馏方法。


### [63] [Mono4DGS-HDR: High Dynamic Range 4D Gaussian Splatting from Alternating-exposure Monocular Videos](https://arxiv.org/abs/2510.18489)
*Jinfeng Liu,Lingtong Kong,Mi Zhou,Jinwen Chen,Dan Xu*

Main category: cs.CV

TL;DR: Mono4DGS-HDR是首个从无位姿的单目LDR视频重建可渲染4D HDR场景的系统，采用两阶段高斯泼溅优化方法，无需相机位姿即可实现HDR视频重建。

- Motivation: 解决从无位姿单目LDR视频重建4D HDR场景的挑战性问题，这是此前未被研究过的任务。
- Method: 两阶段优化框架：第一阶段在正交相机坐标系学习视频HDR高斯表示；第二阶段将视频高斯转换到世界空间，联合优化世界高斯和相机位姿，并提出时间亮度正则化策略增强HDR外观的时间一致性。
- Result: 构建了新的评估基准，实验表明在渲染质量和速度上显著优于现有方法的适配方案。
- Conclusion: Mono4DGS-HDR成功实现了从无位姿单目LDR视频重建4D HDR场景，在质量和效率上表现优异。


### [64] [Zero-Shot Vehicle Model Recognition via Text-Based Retrieval-Augmented Generation](https://arxiv.org/abs/2510.18502)
*Wei-Chia Chang,Yan-Ann Chen*

Main category: cs.CV

TL;DR: 提出了一种结合视觉语言模型和检索增强生成的零样本车辆品牌型号识别方法，避免了大规模重新训练，通过文本推理实现可扩展的识别

- Motivation: 现有车辆品牌型号识别方法难以适应新发布车型，CLIP模型的固定预训练权重需要昂贵的图像特定微调才能获得良好性能
- Method: 使用视觉语言模型将车辆图像转换为描述性属性，与文本特征数据库进行比对检索，结合检索结果形成提示，通过语言模型推理出品牌型号
- Result: 实验表明该方法比CLIP基线提高了近20%的识别准确率
- Conclusion: 该方法展示了检索增强生成的语言模型推理在智能城市应用中实现可扩展车辆品牌型号识别的潜力


### [65] [DWaste: Greener AI for Waste Sorting using Mobile and Edge Devices](https://arxiv.org/abs/2510.18513)
*Suman Kunwar*

Main category: cs.CV

TL;DR: 开发了DWaste平台，使用计算机视觉在资源受限设备上实现实时垃圾分类，比较了多种模型发现轻量级目标检测模型在速度、模型大小和碳排放方面表现更优。

- Motivation: 便利包装导致大量垃圾产生，需要高效的垃圾分类系统来支持可持续垃圾管理。
- Method: 开发DWaste平台，在智能手机和边缘设备上实现实时垃圾分类，测试多种图像分类和目标检测模型，使用自定义标注工具Annotated Lab处理数据集。
- Result: EfficientNetV2S分类器准确率高(96%)但延迟高(0.22s)且碳排放高；轻量级目标检测模型性能良好(77% mAP)，推理速度快(0.03s)，模型小(<7MB)；模型量化可减少75%模型大小和VRAM使用。
- Conclusion: 成功实现了"更环保AI"模型，支持在边缘设备上进行实时、可持续的垃圾分类。


### [66] [RayPose: Ray Bundling Diffusion for Template Views in Unseen 6D Object Pose Estimation](https://arxiv.org/abs/2510.18521)
*Junwen Huang,Shishir Reddy Vutukur,Peter KT Yu,Nassir Navab,Slobodan Ilic,Benjamin Busam*

Main category: cs.CV

TL;DR: 将基于模板的物体姿态估计重新表述为射线对齐问题，使用扩散变换器架构对齐查询图像与姿态模板，通过粗到细的训练策略提升性能

- Motivation: 传统基于模板的方法在检索错误模板时会导致姿态预测不准确，需要改进模板匹配机制
- Method: 将物体姿态估计重新表述为射线对齐问题，使用扩散变换器架构，重新参数化物体旋转为物体中心相机射线，扩展尺度不变平移估计为密集平移偏移
- Result: 在多个基准数据集上的广泛实验显示，该方法在未见物体姿态估计方面与最先进方法相比具有竞争力
- Conclusion: 提出的射线对齐公式和扩散变换器架构有效提升了基于模板的物体姿态估计性能


### [67] [GBlobs: Local LiDAR Geometry for Improved Sensor Placement Generalization](https://arxiv.org/abs/2510.18539)
*Dušan Malić,Christian Fruhwirth-Reisinger,Alexander Prutsch,Wei Lin,Samuel Schulter,Horst Possegger*

Main category: cs.CV

TL;DR: 该技术报告介绍了在RoboSense 2025 Track 3中取得最佳排名的解决方案，通过使用GBlobs局部点云特征描述符来提升3D目标检测模型在不同LiDAR配置下的泛化能力。

- Motivation: 当前基于LiDAR的3D检测器在使用传统全局特征（如绝对笛卡尔坐标）训练时存在"几何捷径"问题，导致模型过度依赖绝对位置而非物体形状特征，限制了在不同传感器配置下的泛化能力。
- Method: 使用GBlobs作为网络输入特征，这是一种专门设计的局部点云特征描述符，能够有效规避几何捷径，迫使网络学习鲁棒的、以物体为中心的表示。
- Result: 该方法显著提升了模型的泛化能力，在挑战中展现了卓越的性能，实现了最先进的3D目标检测效果。
- Conclusion: GBlobs特征描述符通过避免几何捷径，使模型能够学习更鲁棒的物体表示，从而在不同传感器配置下实现优异的泛化性能。


### [68] [Descriptor: Occluded nuScenes: A Multi-Sensor Dataset for Evaluating Perception Robustness in Automated Driving](https://arxiv.org/abs/2510.18552)
*Sanjay Kumar,Tim Brophy,Reenu Mohandas,Eoin Martino Grua,Ganesh Sistu,Valentina Donzella,Ciaran Eising*

Main category: cs.CV

TL;DR: 提出了Occluded nuScenes数据集，这是对广泛使用的nuScenes基准测试的扩展，为相机、雷达和LiDAR提供参数化的遮挡脚本，支持在部分传感器故障和环境干扰下对感知模型进行一致、可重复的评估。

- Motivation: 现有自动驾驶数据集虽然包含传感器噪声和环境变化，但很少能提供跨多个传感模态的受控、参数化和可重复的退化，这限制了系统评估感知和融合架构在明确定义的不利条件下性能的能力。
- Method: 为相机模态发布了完整版和迷你版，包含四种类型的遮挡；为雷达和LiDAR提供了参数化遮挡脚本，每种实现三种类型的退化，能够灵活、可重复地生成遮挡数据。
- Result: 创建了首个具有受控和可重复退化的多传感器遮挡数据集，支持对感知模型在部分传感器故障和环境干扰下的性能进行一致、可重复的评估。
- Conclusion: 通过发布首个具有受控和可重复退化的多传感器遮挡数据集，旨在推进自动驾驶中鲁棒传感器融合、弹性分析和安全关键感知的研究。


### [69] [Kaleido: Open-Sourced Multi-Subject Reference Video Generation Model](https://arxiv.org/abs/2510.18573)
*Zhenxing Zhang,Jiayan Teng,Zhuoyi Yang,Tiankun Cao,Cheng Wang,Xiaotao Gu,Jie Tang,Dan Guo,Meng Wang*

Main category: cs.CV

TL;DR: Kaleido是一个主题到视频生成框架，通过专用数据构建流程和参考旋转位置编码，解决了多主题一致性和背景解耦问题，显著提升了参考保真度和语义一致性。

- Motivation: 现有主题到视频生成方法在多主题一致性和背景解耦方面存在不足，导致参考保真度低和语义漂移，主要原因是训练数据缺乏多样性和高质量样本，以及多参考图像集成机制不完善。
- Method: 提出专用数据构建流程（包括低质量样本过滤和多样化数据合成）来生成一致性保持的训练数据，并引入参考旋转位置编码来稳定精确地处理多参考图像。
- Result: 在多个基准测试上的广泛实验表明，Kaleido在一致性、保真度和泛化能力方面显著优于先前方法。
- Conclusion: Kaleido在主题到视频生成领域取得了重要进展，通过改进的数据构建和编码机制有效解决了多主题一致性和背景解耦的挑战。


### [70] [CovMatch: Cross-Covariance Guided Multimodal Dataset Distillation with Trainable Text Encoder](https://arxiv.org/abs/2510.18583)
*Yongmin Lee,Hye Won Chung*

Main category: cs.CV

TL;DR: CovMatch是一个可扩展的多模态数据集蒸馏框架，通过对齐真实和合成特征的跨协方差并正则化模态内特征分布，实现了双编码器的联合优化，在仅使用500个合成图像-文本对的情况下，在检索任务上取得了显著性能提升。

- Motivation: 现有的多模态数据集蒸馏方法为了降低计算成本而冻结文本编码器，但这严重限制了语义对齐能力，成为性能扩展的瓶颈。需要开发能够同时优化两个编码器的更有效方法。
- Method: 提出CovMatch框架，通过对齐真实和合成特征的跨协方差来学习跨模态对齐，同时对每个模态内的特征分布进行正则化，实现了图像和文本编码器的联合优化。
- Result: 在Flickr30K和COCO数据集上的评估表明，CovMatch优于现有的多模态蒸馏方法，仅使用500个合成图像-文本对就能在检索准确率上获得高达6.8%的绝对提升。
- Conclusion: CovMatch通过跨协方差对齐和特征分布正则化，成功解决了多模态数据集蒸馏中的跨模态对齐挑战，为高效训练大规模视觉语言模型提供了有效解决方案。


### [71] [Think with 3D: Geometric Imagination Grounded Spatial Reasoning from Limited Views](https://arxiv.org/abs/2510.18632)
*Zhangquan Chen,Manyuan Zhang,Xinlei Yu,Xufang Luo,Mingze Sun,Zihao Pan,Yan Feng,Peng Pei,Xunliang Cai,Ruqi Huang*

Main category: cs.CV

TL;DR: 3DThinker是一个无需3D先验输入就能在推理过程中进行3D心理建模的框架，通过两阶段训练有效利用图像中的几何信息，在多个基准测试中优于现有方法。

- Motivation: 现有的视觉语言模型在理解3D空间关系方面存在局限，主要依赖纯文本或2D视觉线索，无法满足需要3D空间想象的任务需求。
- Method: 采用两阶段训练：首先通过监督训练将VLM生成的3D潜在空间与3D基础模型对齐，然后基于结果信号优化整个推理轨迹来改进3D心理建模。
- Result: 在多个基准测试中，3DThinker始终优于强基线方法，为将3D表示统一到多模态推理提供了新视角。
- Conclusion: 3DThinker框架首次实现了无需3D先验输入的3D心理建模推理，展示了将3D表示整合到多模态推理中的可行性。


### [72] [C-SWAP: Explainability-Aware Structured Pruning for Efficient Neural Networks Compression](https://arxiv.org/abs/2510.18636)
*Baptiste Bauvin,Loïc Baret,Ola Ahmad*

Main category: cs.CV

TL;DR: 提出一种基于可解释深度学习的新型一次性剪枝框架，通过因果感知方法在剪枝过程中利用模型预测与结构间的因果关系，实现无需微调的高效模型压缩。

- Motivation: 解决传统结构化剪枝方法需要迭代重训练的计算成本问题，以及现有一次性剪枝方法性能下降明显的问题。
- Method: 采用因果感知剪枝方法，在渐进式剪枝过程中利用模型预测与结构间的因果关系，确保被移除的结构不会影响模型性能。
- Result: 在卷积神经网络和视觉Transformer基准模型上的实验表明，该方法能显著减小模型尺寸，对性能影响最小，且无需微调。
- Conclusion: 该方法优于现有方法，提供了最佳的性能与模型压缩权衡，代码已在GitHub开源。


### [73] [ε-Seg: Sparsely Supervised Semantic Segmentation of Microscopy Data](https://arxiv.org/abs/2510.18637)
*Sheida Rahnamai Kordasiabi,Damian Dalle Nogare,Florian Jug*

Main category: cs.CV

TL;DR: 提出了ε-Seg方法，使用分层变分自编码器和中心区域掩码、稀疏标签对比学习等技术，在仅有0.05%或更少标注数据的情况下实现生物电子显微镜图像的语义分割。

- Motivation: 电子显微镜图像中的生物结构语义分割在生命科学中具有挑战性，数据复杂度高，即使人类观察者也难以处理。需要开发能够在极稀疏标注下有效学习的方法。
- Method: 基于分层变分自编码器，采用中心区域掩码、稀疏标签对比学习、高斯混合模型先验和无聚类标签预测。通过掩码和修复损失学习鲁棒嵌入，使用对比学习和GMM先验塑造潜在空间，最后用MLP分割头直接预测类别标签。
- Result: 在2个密集EM生物组织数据集上的实验表明，ε-Seg在复杂生物图像数据上能够实现具有竞争力的稀疏监督分割结果，即使在训练标签数量有限的情况下。
- Conclusion: ε-Seg方法能够在极稀疏标注数据（0.05%或更少）下有效进行生物图像的语义分割，为生命科学研究提供了实用的解决方案。


### [74] [Binary Quadratic Quantization: Beyond First-Order Quantization for Real-Valued Matrix Compression](https://arxiv.org/abs/2510.18650)
*Kyo Kuroki,Yasuyuki Okoshi,Thiem Van Chu,Kazushi Kawamura,Masato Motomura*

Main category: cs.CV

TL;DR: 提出了一种新的矩阵量化方法BQQ，使用二元二次表达式进行矩阵近似，在矩阵压缩和神经网络后训练量化中表现出色，在2位量化下优于现有方法。

- Motivation: 传统的一阶量化方法（如均匀量化和二进制编码量化）通过二进制基的线性组合来近似实值矩阵，表达能力有限。BQQ旨在利用二元二次表达式的表达能力，同时保持极紧凑的数据格式。
- Method: BQQ方法采用二元二次表达式进行矩阵量化，不同于传统的一阶线性方法。该方法不依赖特定的二进制矩阵优化，而是通过二元二次表达式实现高效的矩阵近似。
- Result: 在矩阵压缩基准测试和后训练量化实验中，BQQ在内存效率和重构误差之间实现了优于传统方法的平衡。在ImageNet数据集上，2位量化下比最先进的方法分别提升2.2%（基于校准）和59.1%（数据无关场景）。
- Conclusion: 二元二次表达式在高效矩阵近似和神经网络压缩方面具有显著的有效性，BQQ方法为矩阵量化提供了新的思路和解决方案。


### [75] [Image augmentation with invertible networks in interactive satellite image change detection](https://arxiv.org/abs/2510.18660)
*Hichem Sahbi*

Main category: cs.CV

TL;DR: 提出基于主动学习的交互式卫星图像变化检测算法，通过可逆网络增强显示样本，在潜在空间进行线性数据增强，提升变化检测性能

- Motivation: 传统变化检测方法需要大量标注数据，本文旨在通过主动学习减少人工标注成本，通过交互式查询用户获取关键样本标签
- Method: 使用可逆网络将非线性输入空间映射到潜在空间进行线性数据增强，然后映射回输入空间，迭代更新变化检测模型
- Result: 实验结果表明该方法相比相关工作具有优越性能
- Conclusion: 提出的基于可逆网络和主动学习的交互式变化检测框架能有效减少标注成本并提升检测精度


### [76] [Beyond the Pipeline: Analyzing Key Factors in End-to-End Deep Learning for Historical Writer Identification](https://arxiv.org/abs/2510.18671)
*Hanif Rasyidi,Moshiur Farazi*

Main category: cs.CV

TL;DR: 本文研究了影响历史笔迹识别端到端深度学习方法的多种因素，发现大多数模型在零样本场景下泛化能力差，但识别出一种简单设计能达到最佳系统性能的端到端配置。

- Motivation: 历史笔迹识别面临笔迹风格多样、文档退化、标注样本有限等挑战，传统方法依赖手工特征提取，而端到端方法旨在直接从文档图像学习特征，但在真实场景下泛化能力不足。
- Method: 探索了不同预处理方法、骨干网络架构和后处理策略的组合，包括文本分割、补丁采样和特征聚合等技术。
- Result: 大多数配置因低层视觉特征捕获弱、补丁表示不一致和对内容噪声敏感而表现不佳，但发现一种端到端设置能达到与最佳系统相当的结果。
- Conclusion: 研究揭示了构建鲁棒端到端系统的关键挑战，并为提高历史文档笔迹识别性能的设计选择提供了见解。


### [77] [MoGA: Mixture-of-Groups Attention for End-to-End Long Video Generation](https://arxiv.org/abs/2510.18692)
*Weinan Jia,Yuning Lu,Mengqi Huang,Hualiang Wang,Binyuan Huang,Nan Chen,Mu Liu,Jidong Jiang,Zhendong Mao*

Main category: cs.CV

TL;DR: 提出Mixture-of-Groups Attention (MoGA)稀疏注意力机制，通过轻量级可学习token路由器实现精确token匹配，解决长视频生成中注意力计算复杂度问题，支持生成分钟级480p视频。

- Motivation: 长视频生成中扩散变换器的全注意力机制存在二次复杂度问题，现有稀疏方法依赖块状粗估计，精度-效率权衡受限于块大小。
- Method: 提出MoGA稀疏注意力机制，使用轻量级可学习token路由器进行语义感知路由，无需块状估计即可实现精确token匹配，兼容FlashAttention和序列并行化。
- Result: 构建了高效长视频生成模型，能够端到端生成分钟级、多镜头、480p、24fps的视频，上下文长度约580k，在多种视频生成任务中验证有效性。
- Conclusion: MoGA通过语义感知路由实现了高效的长程交互，解决了长视频生成中的注意力计算瓶颈，为长序列生成提供了有效的解决方案。


### [78] [UniGenBench++: A Unified Semantic Evaluation Benchmark for Text-to-Image Generation](https://arxiv.org/abs/2510.18701)
*Yibin Wang,Zhimin Li,Yuhang Zang,Jiazi Bu,Yujie Zhou,Yi Xin,Junjun He,Chunyu Wang,Qinglin Lu,Cheng Jin,Jiaqi Wang*

Main category: cs.CV

TL;DR: 提出了UniGenBench++，一个用于文本到图像生成的统一语义评估基准，解决了现有基准在多样性、多语言支持和细粒度评估方面的不足。

- Motivation: 现有基准缺乏多样化的提示场景和多语言支持，且只能进行粗粒度的评估，无法满足真实世界应用的需求。
- Method: 构建包含600个提示的分层基准，涵盖5个主要主题和20个子主题，提供英文和中文的短长版本。利用Gemini-2.5-Pro MLLM开发评估流程，并训练离线评估模型。
- Result: 通过全面基准测试，系统揭示了开源和闭源T2I模型在不同方面的优势和弱点。
- Conclusion: UniGenBench++为T2I生成提供了更全面、细粒度的语义一致性评估基准，促进了该领域的发展。


### [79] [Exploring a Unified Vision-Centric Contrastive Alternatives on Multi-Modal Web Documents](https://arxiv.org/abs/2510.18703)
*Yiqi Lin,Alex Jinpeng Wang,Linjie Li,Zhengyuan Yang,Mike Zheng Shou*

Main category: cs.CV

TL;DR: VC2L是一个统一的视觉中心对比学习框架，通过将文本、图像及其组合全部渲染为图像，在像素空间中进行多模态表示学习，无需OCR、文本标记化或模态融合策略。

- Motivation: 解决CLIP等对比视觉语言模型在处理复杂网页文档时的局限性，特别是当文本和图像交错排列、松散对齐或以视觉形式嵌入时。
- Method: 使用单一视觉变换器在像素空间中建模所有输入，采用片段级对比学习目标对齐连续多模态片段，利用文档的内在连贯性。
- Result: 在提出的三个检索基准测试中表现优异，在M-BEIR和MTEB等现有数据集上达到或超越CLIP风格模型的性能。
- Conclusion: 证明了多模态网页数据作为对比学习训练资源的潜力，展示了统一视觉中心方法在多模态表示学习中的可扩展性。


### [80] [A Renaissance of Explicit Motion Information Mining from Transformers for Action Recognition](https://arxiv.org/abs/2510.18705)
*Peiqin Zhuang,Lei Bai,Yichao Wu,Ding Liang,Luping Zhou,Yali Wang,Wanli Ouyang*

Main category: cs.CV

TL;DR: 提出EMIM模块，将传统动作识别中的cost volume思想整合到transformer中，通过构建类似cost volume的亲和矩阵来增强运动建模能力，在运动敏感数据集上表现优异。

- Motivation: 现有的基于transformer的动作识别方法在场景相关数据集上表现良好，但在运动敏感数据集上表现不佳，因为它们缺乏精细的运动建模设计。
- Method: 提出EMIM模块，以滑动窗口方式从下一帧的查询邻域采样关键候选token，构建类似cost volume的亲和矩阵，用于上下文聚合和运动特征提取。
- Result: 在四个广泛使用的数据集上验证了方法的运动建模能力，特别是在Something-Something V1 & V2等运动敏感数据集上优于现有最先进方法。
- Conclusion: 通过将cost volume的运动建模特性整合到transformer中，EMIM模块有效提升了动作识别在运动敏感场景下的性能。


### [81] [PLANA3R: Zero-shot Metric Planar 3D Reconstruction via Feed-Forward Planar Splatting](https://arxiv.org/abs/2510.18714)
*Changkun Liu,Bin Tan,Zeran Ke,Shangzhan Zhang,Jiachen Liu,Ming Qian,Nan Xue,Yujun Shen,Tristan Braud*

Main category: cs.CV

TL;DR: PLANA3R是一个无需相机位姿的度量平面3D重建框架，从无位姿的双视图图像中重建室内场景的度量3D结构，无需3D平面标注监督。

- Motivation: 利用室内场景固有的几何规律性，通过紧凑的平面3D基元表示来重建度量3D结构，避免了对3D平面标注的依赖。
- Method: 使用Vision Transformers提取稀疏平面基元，估计相对相机位姿，通过平面溅射监督几何学习，在高分辨率渲染的深度和法线图中传播梯度。
- Result: 在多个室内场景数据集上验证了方法的有效性，展示了在域外室内环境中的强泛化能力，支持3D表面重建、深度估计和相对位姿估计等任务。
- Conclusion: PLANA3R通过平面3D表示实现了无监督的度量3D重建，具有准确的平面分割能力，可在大规模立体数据集上进行可扩展训练。


### [82] [SSD: Spatial-Semantic Head Decoupling for Efficient Autoregressive Image Generation](https://arxiv.org/abs/2510.18716)
*Siyong Jian,Huan Wang*

Main category: cs.CV

TL;DR: 提出了一种针对自回归图像生成模型的KV缓存压缩框架，通过识别空间局部性和语义汇聚现象，将注意力头分为两类分别处理，显著降低了内存使用并提升了生成速度。

- Motivation: 自回归图像生成模型如Janus-Pro虽然能生成高质量图像，但需要大量视觉token，导致高内存和计算需求。KV缓存在语言模型中已有压缩研究，但在图像生成领域仍待探索。
- Method: 识别出空间局部性和语义汇聚现象，将注意力头分为两类：空间局部性头保持短时token窗口，语义汇聚头策略性保留高度关注token的紧凑集合。
- Result: 实验表明该方法实现了5倍内存使用减少和6.6倍整体吞吐量提升，视觉质量损失极小。
- Conclusion: 该方法使资源受限硬件上能够高效进行原生自回归图像生成。


### [83] [IF-VidCap: Can Video Caption Models Follow Instructions?](https://arxiv.org/abs/2510.18726)
*Shihao Li,Yuanxing Zhang,Jiangtao Wu,Zhide Lei,Yiwen He,Runzhe Wen,Chenxi Liao,Chengkang Jiang,An Ping,Shuo Gao,Suhan Wang,Zhaozhou Bian,Zijun Zhou,Jingyi Xie,Jiayi Zhou,Jing Wang,Yifan Yao,Weihao Xie,Yingshui Tan,Yanghai Wang,Qianqian Xie,Zhaoxiang Zhang,Jiaheng Liu*

Main category: cs.CV

TL;DR: 提出了IF-VidCap基准，用于评估可控视频字幕生成，包含1400个高质量样本，从格式正确性和内容正确性两个维度评估字幕质量。

- Motivation: 现有基准主要评估描述全面性，但忽视了指令跟随能力，而实际应用需要根据用户特定指令生成字幕。
- Method: 引入IF-VidCap基准，采用系统性框架评估字幕的格式正确性和内容正确性，对20多个主流模型进行全面评估。
- Result: 专有模型仍占主导地位，但性能差距正在缩小，顶级开源解决方案已接近同等水平；专用于密集字幕的模型在复杂指令上表现不如通用MLLMs。
- Conclusion: 未来工作应同时推进描述丰富性和指令跟随保真度的发展。


### [84] [Moving Light Adaptive Colonoscopy Reconstruction via Illumination-Attenuation-Aware 3D Gaussian Splatting](https://arxiv.org/abs/2510.18739)
*Hao Wang,Ying Zhou,Haoyu Zhao,Rui Wang,Qiang Hu,Xing Zhang,Qiang Li,Zhiwei Wang*

Main category: cs.CV

TL;DR: 提出了ColIAGS，一种针对结肠镜场景改进的3D高斯泼溅框架，通过改进的外观建模和几何建模来解决动态光照下的渲染和重建问题。

- Motivation: 传统3DGS假设静态光照，与结肠镜场景中动态光源/相机引起的光度变化不兼容，导致重建质量下降。
- Method: 引入改进的外观建模（包含两种光照衰减因子）和改进的几何建模（使用高维视图嵌入），通过余弦嵌入隐式生成光照衰减解。
- Result: 在标准基准测试中，ColIAGS在视图合成和几何重建方面均表现出色，显著降低了深度MSE，渲染保真度优于现有方法。
- Conclusion: ColIAGS成功解决了结肠镜场景中的动态光照问题，实现了高质量的视图合成和精确的几何重建。


### [85] [SEAL: Semantic-Aware Hierarchical Learning for Generalized Category Discovery](https://arxiv.org/abs/2510.18740)
*Zhenqi He,Yuanpei Liu,Kai Han*

Main category: cs.CV

TL;DR: 提出SEAL框架，通过语义感知的层次化学习解决广义类别发现问题，利用自然层次结构生成软负样本并保持跨粒度一致性，在多个细粒度和粗粒度数据集上达到SOTA性能。

- Motivation: 现有GCD方法依赖单层语义或人工设计的抽象层次结构，限制了泛化性和可扩展性，需要利用自然层次结构来改进。
- Method: SEAL框架包含层次语义引导的软对比学习和跨粒度一致性模块，利用层次相似性生成信息丰富的软负样本，并对齐不同粒度级别的预测。
- Result: 在SSB基准、Oxford-Pet和Herbarium19等细粒度数据集上持续达到最先进性能，并在粗粒度数据集上展现出良好的泛化能力。
- Conclusion: SEAL通过利用自然层次结构和软对比学习，有效解决了GCD问题，在多个数据集上表现出优越性能。


### [86] [Detection and Simulation of Urban Heat Islands Using a Fine-Tuned Geospatial Foundation Model for Microclimate Impact Prediction](https://arxiv.org/abs/2510.18773)
*Jannis Fleckenstein,David Kreismann,Tamara Rosemary Govindasamy,Thomas Brunschwiler,Etienne Vos,Mattia Rigotti*

Main category: cs.CV

TL;DR: 该研究利用地理空间基础模型预测城市热岛效应，通过微调模型来预测未来气候情景下的地表温度，并展示了其在缓解策略评估中的实用价值。

- Motivation: 随着城市化和气候变化加剧，城市热岛效应日益严重。传统机器学习模型在数据有限时预测不准确，特别是在服务不足地区。地理空间基础模型提供了更好的泛化能力。
- Method: 建立城市热模式的实证基准，量化绿地的降温效应并与模型预测进行对比评估。随后对基础模型进行微调，预测未来气候情景下的地表温度，并通过模拟修复展示其实用性。
- Result: 基础模型能够准确评估城市热岛缓解策略，在数据稀缺地区表现出强大的预测能力，支持建设更具气候韧性的城市。
- Conclusion: 地理空间基础模型为数据稀缺地区评估城市热岛缓解策略提供了有力工具，有助于支持气候适应性城市建设。


### [87] [UltraGen: High-Resolution Video Generation with Hierarchical Attention](https://arxiv.org/abs/2510.18775)
*Teng Hu,Jiangning Zhang,Zihan Su,Ran Yi*

Main category: cs.CV

TL;DR: UltraGen是一个新颖的视频生成框架，通过层次化双分支注意力架构实现高效端到端原生高分辨率视频合成，解决了现有扩散变换器模型因注意力机制计算复杂度而局限于低分辨率的问题。

- Motivation: 现有基于扩散变换器的视频生成模型由于注意力机制的二次计算复杂度，只能生成低分辨率视频（≤720P），无法实现原生高分辨率（1080P/2K/4K）视频生成，这限制了在内容创作、娱乐和虚拟现实等领域的应用。
- Method: 提出层次化双分支注意力架构，基于全局-局部注意力分解，将完整注意力解耦为局部注意力分支（用于高保真区域内容）和全局注意力分支（用于整体语义一致性）。采用空间压缩全局建模策略高效学习全局依赖，以及层次化跨窗口局部注意力机制降低计算成本并增强不同局部窗口间的信息流。
- Result: 实验表明UltraGen能够有效将预训练低分辨率视频模型扩展到1080P甚至4K分辨率，在定性和定量评估中均优于现有最先进方法和基于超分辨率的两阶段流程。
- Conclusion: UltraGen首次实现了将预训练低分辨率视频模型扩展到1080P和4K分辨率，为原生高分辨率视频生成提供了高效可行的解决方案。


### [88] [Rebellious Student: A Complementary Learning Framework for Background Feature Enhancement in Hyperspectral Anomaly Detection](https://arxiv.org/abs/2510.18781)
*Wenping Jin,Yuyang Tang,Li Zhu,Fei Guo*

Main category: cs.CV

TL;DR: 提出了一种新颖的"叛逆学生"框架，通过故意让空间分支与光谱教师网络产生分歧来学习互补特征，实现了无需场景重训练或参数调优的通用高光谱异常检测。

- Motivation: 现有的一次训练即可通用部署的高光谱异常检测方法虽然高效，但在光谱和空间线索的整合方面仍有改进空间。本文旨在通过互补特征学习来提升检测性能。
- Method: 采用两阶段学习策略：首先通过反向蒸馏训练光谱增强网络获取鲁棒的光谱背景表示；然后使用去相关损失优化空间网络（叛逆学生），强制特征正交性同时保持重建保真度。
- Result: 在HAD100基准测试上的广泛实验表明，相比多个基线方法有显著改进，且计算开销最小，验证了互补学习范式的有效性和通用性。
- Conclusion: 提出的叛逆学生框架成功实现了光谱和空间特征的互补学习，为高光谱异常检测提供了一种高效且通用的解决方案。


### [89] [ProCLIP: Progressive Vision-Language Alignment via LLM-based Embedder](https://arxiv.org/abs/2510.18795)
*Xiaoxing Hu,Kaicheng Yang,Ziyong Feng,Qi Ming,Zonghao Guo,Xiang An,Ziyong Feng,Junchi Yan,Xue Yang*

Main category: cs.CV

TL;DR: ProCLIP是一个基于课程学习的渐进式视觉-语言对齐框架，旨在将CLIP图像编码器与基于LLM的嵌入器有效对齐，以解决CLIP文本编码器在长文本处理、多语言理解和细粒度语义理解方面的局限性。

- Motivation: 原始CLIP文本编码器受限于77个token的最大输入长度，无法有效处理长文本和进行细粒度语义理解，同时缺乏多语言输入支持。虽然已有研究尝试用基于LLM的嵌入器替换CLIP文本编码器，但由于LLM表示空间与CLIP视觉-语言空间独立预训练，直接对齐会破坏CLIP图像编码器的内在视觉-语言对齐，导致预训练知识利用不足。
- Method: ProCLIP采用课程学习策略：首先通过知识蒸馏将CLIP文本编码器的知识迁移到LLM嵌入器中，建立初始对齐；然后通过图像-文本对比调优进一步对齐CLIP图像编码器与LLM嵌入器，使用自蒸馏正则化防止过拟合；在表示继承和对比调优阶段使用实例语义对齐损失和嵌入结构对齐损失。
- Result: 该方法有效解决了CLIP文本编码器的局限性，同时避免了直接对齐对CLIP图像编码器视觉-语言对齐的破坏，充分利用了预训练知识。
- Conclusion: ProCLIP通过渐进式对齐框架成功将CLIP图像编码器与基于LLM的嵌入器对齐，显著提升了长文本处理、多语言理解和细粒度语义理解能力，同时保持了CLIP原有的视觉-语言对齐特性。


### [90] [A Geometric Approach to Steerable Convolutions](https://arxiv.org/abs/2510.18813)
*Soumyabrata Kundu,Risi Kondor*

Main category: cs.CV

TL;DR: 本文提供了一种基于几何论证和模式匹配基本原理的直观推导方法，用于构建d维可操纵卷积神经网络，并提出了使用插值核的新方法。

- Motivation: 现有方法多采用抽象的群论方法，缺乏直观性，因此需要一种更直观的推导方式来理解可操纵卷积神经网络。
- Method: 基于几何论证和模式匹配基本原理进行推导，提出使用插值核构建可操纵卷积层的新方法。
- Result: 提供了对Clebsch-Gordan分解和球谐基函数出现的直观解释，新方法相比现有实现具有改进，对噪声数据具有更好的鲁棒性。
- Conclusion: 通过几何直观的推导方法，不仅更好地理解了可操纵卷积神经网络的理论基础，还提出了更优的实现方案。


### [91] [An Explainable Hybrid AI Framework for Enhanced Tuberculosis and Symptom Detection](https://arxiv.org/abs/2510.18819)
*Neel Patel,Alexander Wong,Ashkan Ebadi*

Main category: cs.CV

TL;DR: 提出了一种教师-学生框架，通过集成两个监督头和一个自监督头来增强胸部X光片中的疾病和症状检测，在COVID-19、结核病和正常病例分类中达到98.85%的准确率，在症状检测中达到90.09%的宏F1分数。

- Motivation: 解决资源有限和偏远地区结核病早期检测的挑战，由于缺乏熟练的放射科医生，需要开发可靠的人工智能筛查工具，但获取大规模高质量数据集成本高昂。
- Method: 采用教师-学生框架，集成两个监督头（用于疾病分类和症状检测）和一个自监督头，通过多任务学习提升模型性能。
- Result: 在疾病分类任务中达到98.85%的准确率，在症状检测任务中达到90.09%的宏F1分数，显著优于基线方法，可解释性评估显示模型基于相关解剖特征进行预测。
- Conclusion: 该模型在临床筛查和分诊环境中具有部署潜力，能够有效辅助结核病等疾病的早期检测。


### [92] [SAM 2++: Tracking Anything at Any Granularity](https://arxiv.org/abs/2510.18822)
*Jiaming Zhang,Cheng Liang,Yichun Yang,Chenkai Zeng,Yutao Cui,Xinwen Zhang,Xin Zhou,Kai Ma,Gangshan Wu,Limin Wang*

Main category: cs.CV

TL;DR: SAM 2++是一个统一视频跟踪模型，能够在任何粒度（掩码、边界框、点）上进行跟踪，通过任务特定提示、统一解码器和任务自适应记忆机制实现多粒度跟踪的统一。

- Motivation: 现有跟踪器通常针对单一任务设计，依赖于特定任务的定制模块，导致泛化能力受限，模型设计和参数冗余。需要统一不同粒度的视频跟踪任务。
- Method: 1. 设计任务特定提示将不同任务输入编码为通用提示嵌入；2. 使用统一解码器将多样化任务结果统一为预输出形式；3. 引入任务自适应记忆机制统一不同粒度的记忆；4. 构建Tracking-Any-Granularity数据集支持多粒度跟踪训练。
- Result: 在多个基准测试上的综合实验证实，SAM 2++在不同粒度的多样化跟踪任务中均达到了新的最先进水平。
- Conclusion: SAM 2++建立了一个统一且鲁棒的跟踪框架，能够有效处理不同粒度的视频跟踪任务，解决了现有方法的泛化限制和冗余问题。


### [93] [Unifying and Enhancing Graph Transformers via a Hierarchical Mask Framework](https://arxiv.org/abs/2510.18825)
*Yujie Xing,Xiao Wang,Bin Wu,Hai Huang,Chuan Shi*

Main category: cs.CV

TL;DR: 提出统一的层次掩码框架，揭示模型架构与注意力掩码构建的等价性，并基于此设计M3Dphormer图变换器，通过多级掩码和双注意力计算实现高效图表示学习。

- Motivation: 现有图变换器依赖特定交互的复杂架构设计，缺乏灵活性。需要统一框架来捕捉多样节点交互。
- Method: 提出层次掩码框架，将模型架构等价于注意力掩码构建。设计M3Dphormer，包含三个理论基础的层次掩码，采用双级专家路由机制自适应整合多级交互信息，并通过双注意力计算方案确保可扩展性。
- Result: 在多个基准测试上的广泛实验表明，M3Dphormer实现了最先进的性能。
- Conclusion: 统一框架和模型设计有效，层次掩码提供互补优势，M3Dphormer验证了该方法的有效性。


### [94] [FedDEAP: Adaptive Dual-Prompt Tuning for Multi-Domain Federated Learning](https://arxiv.org/abs/2510.18837)
*Yubin Zheng,Pak-Hei Yeung,Jing Xia,Tianjie Ju,Peng Tang,Weidong Qiu,Jagath C. Rajapakse*

Main category: cs.CV

TL;DR: 提出FedDEAP框架，通过解耦语义和领域特征、双提示设计以及文本视觉表示对齐，在联邦学习中增强CLIP在多领域场景下的泛化能力。

- Motivation: 联邦学习中领域偏移和标签异质性阻碍全局模型的泛化能力，需要有效在多领域场景下微调CLIP模型。
- Method: 1) 使用语义和领域转换网络解耦图像特征；2) 设计全局语义提示和局部领域提示的双提示机制；3) 在两种转换下对齐文本和视觉表示以保持一致性。
- Result: 在四个数据集上的实验证明该方法能有效提升CLIP在联邦图像识别中的多领域泛化性能。
- Conclusion: FedDEAP框架通过特征解耦、双提示设计和表示对齐，成功解决了联邦学习中CLIP模型的多领域泛化问题。


### [95] [See the Text: From Tokenization to Visual Reading](https://arxiv.org/abs/2510.18840)
*Ling Xing,Alex Jinpeng Wang,Rui Yan,Hongyu Qu,Zechao Li,Jinhui Tang*

Main category: cs.CV

TL;DR: SeeTok提出了一种视觉中心的文本处理方法，将文本渲染为图像，利用预训练多模态大语言模型的OCR和文本-视觉对齐能力来理解文本，相比传统子词分词方法显著减少了计算量并提升了性能。

- Motivation: 传统LLMs依赖子词分词，对低资源语言过度分割产生无意义长序列，计算效率低。人类阅读是基于视觉对象识别，能有效处理错字、变形字体等。
- Method: 将文本渲染为图像，利用预训练多模态LLMs的OCR和文本-视觉对齐能力来理解视觉文本，避免传统分词过程。
- Result: 在三个语言任务中，SeeTok性能相当或优于子词分词器，同时减少4.43倍token数量和70.5%的FLOPs，在跨语言泛化、抗噪性和语言层次结构方面表现更好。
- Conclusion: SeeTok标志着从符号化分词向人类视觉阅读的转变，为构建更自然、认知启发的语言模型迈出了一步。


### [96] [DP$^2$O-SR: Direct Perceptual Preference Optimization for Real-World Image Super-Resolution](https://arxiv.org/abs/2510.18851)
*Rongyuan Wu,Lingchen Sun,Zhengqiang Zhang,Shihao Wang,Tianhe Wu,Qiaosi Yi,Shuai Li,Lei Zhang*

Main category: cs.CV

TL;DR: DP²O-SR是一个无需人工标注的直接感知偏好优化框架，通过结合全参考和无参考图像质量评估模型构建混合奖励信号，利用生成模型的随机性来提升真实图像超分辨率性能。

- Motivation: 预训练的文本到图像扩散模型虽然能为真实图像超分辨率合成丰富细节，但其固有的随机性导致输出质量不稳定。这种随机性虽然常被视为限制，但也提供了更广的感知质量范围，可被利用来提升Real-ISR性能。
- Method: 构建混合奖励信号结合全参考和无参考IQA模型；超越标准最佳-最差选择，从同一模型输出构建多个偏好对；提出分层偏好优化，基于组内奖励差距和组间多样性自适应加权训练对。
- Result: 在扩散和流式T2I骨干网络上的广泛实验表明，DP²O-SR显著提高了感知质量，并在真实世界基准上表现出良好的泛化能力。
- Conclusion: DP²O-SR成功地将生成模型与感知偏好对齐，无需昂贵的人工标注，通过利用感知多样性和自适应优化策略，有效提升了真实图像超分辨率的性能。


### [97] [DSI-Bench: A Benchmark for Dynamic Spatial Intelligence](https://arxiv.org/abs/2510.18873)
*Ziang Zhang,Zehan Wang,Guanghao Zhang,Weilong Dai,Yan Xia,Ziang Yan,Minjie Hong,Zhou Zhao*

Main category: cs.CV

TL;DR: 提出了动态空间智能概念和DSI-Bench基准，包含近1000个动态视频和1700多个手动标注问题，用于评估模型在动态3D场景中的空间推理能力。

- Motivation: 现有的视觉语言模型和视觉专家模型在2D任务和静态场景中表现出色，但在理解动态3D场景方面能力有限，特别是当观察者和物体同时移动时。
- Method: 创建DSI-Bench基准，包含九个解耦的观察者和物体运动模式，采用时空对称设计减少偏见，系统评估模型对自身运动和物体运动的推理能力。
- Result: 评估14个VLMs和专家模型发现关键局限性：模型经常混淆观察者和物体运动，存在语义偏见，无法准确推断动态场景中的相对关系。
- Conclusion: DSI-Bench为开发具有动态空间智能的通用和专家模型提供了有价值的发现和见解。


### [98] [Grasp Any Region: Towards Precise, Contextual Pixel Understanding for Multimodal LLMs](https://arxiv.org/abs/2510.18876)
*Haochen Wang,Yuhao Wang,Tao Zhang,Yikang Zhou,Yanwei Li,Jiacong Wang,Ye Tian,Jiahao Meng,Zilong Huang,Guangcan Mai,Anran Wang,Yunhai Tong,Zhuochen Wang,Xiangtai Li,Zhaoxiang Zhang*

Main category: cs.CV

TL;DR: GAR是一个区域级多模态大语言模型，通过RoI对齐特征重放技术，能够利用全局上下文进行精确感知，建模多提示间的交互，实现高级组合推理。

- Motivation: 现有MLLM在复杂场景中难以进行细粒度分析和对象关系理解，区域级MLLM通常孤立理解给定区域而忽略全局上下文。
- Method: 引入GAR模型，采用RoI对齐特征重放技术，支持利用全局上下文进行精确感知，并建模多提示间的交互。
- Result: GAR-1B在DLC-Bench上超越DAM-3B 4.5分，在GAR-Bench-VQA上甚至超过InternVL3-78B。零样本GAR-8B在VideoRefer-BenchQ上优于领域内VideoRefer-7B。
- Conclusion: GAR实现了从被动描述到主动对话的范式转变，展示了强大的区域级视觉理解能力，并能轻松迁移到视频领域。
## cs.RO

### [99] [Robobench: A Comprehensive Evaluation Benchmark for Multimodal Large Language Models as Embodied Brain](https://arxiv.org/abs/2510.17801)
*Yulin Luo,Chun-Kai Fan,Menghang Dong,Jiayu Shi,Mengdi Zhao,Bo-Wen Zhang,Cheng Chi,Jiaming Liu,Gaole Dai,Rongyu Zhang,Ruichuan An,Kun Wu,Zhengping Che,Shaoxuan Xie,Guocai Yao,Zhongxia Zhao,Pengwei Wang,Guang Liu,Zhongyuan Wang,Tiejun Huang,Shanghang Zhang*

Main category: cs.RO

TL;DR: RoboBench是一个系统评估多模态大语言模型作为具身大脑的基准测试，包含5个维度、14种能力、25个任务和6092个问答对，旨在全面评估机器人在动态非结构化环境中的认知能力。

- Motivation: 现有基准测试主要关注执行成功率，或针对高级推理时存在维度不完整和任务真实性有限的问题，无法全面评估认知能力。需要建立一个系统性的评估框架来填补这一空白。
- Method: 定义了五个关键维度：指令理解、感知推理、泛化规划、可供性预测和失败分析；引入了MLLM-as-world-simulator评估框架，通过模拟预测计划是否能实现关键对象状态变化来评估具身可行性；基于大规模真实机器人数据构建多样化数据集。
- Result: 对14个MLLM的实验揭示了基本局限性：在隐式指令理解、时空推理、跨场景规划、细粒度可供性理解和执行失败诊断方面存在困难。
- Conclusion: RoboBench为量化高级认知提供了全面的框架，将指导下一代具身MLLM的开发。
## cs.LG

### [100] [NeuCo-Bench: A Novel Benchmark Framework for Neural Embeddings in Earth Observation](https://arxiv.org/abs/2510.17914)
*Rikard Vinge,Isabelle Wittmann,Jannik Schneider,Michael Marszalek,Luis Gilch,Thomas Brunschwiler,Conrad M Albrecht*

Main category: cs.LG

TL;DR: NeuCo-Bench是一个用于评估地球观测领域神经压缩和表示学习的新基准框架，包含可重用嵌入评估管道、隐藏任务排行榜和平衡精度与稳定性的评分系统。

- Motivation: 为地球观测领域的神经压缩和表示学习提供社区驱动的标准化评估框架，解决预训练偏差问题。
- Method: 基于固定大小嵌入构建任务无关表示，包含评估管道、隐藏任务挑战模式和评分系统，并发布SSL4EO-S12-downstream数据集。
- Result: 在2025 CVPR EARTHVISION研讨会上进行了公开挑战，并与最先进的基础模型进行了消融实验。
- Conclusion: NeuCo-Bench为地球观测及其他领域的神经嵌入评估提供了首个社区驱动的标准化基准框架。


### [101] [Demystifying Transition Matching: When and Why It Can Beat Flow Matching](https://arxiv.org/abs/2510.17991)
*Jaihoon Kim,Rajarshi Saha,Minhyuk Sung,Youngsuk Park*

Main category: cs.LG

TL;DR: 本文分析了Transition Matching(TM)何时以及为何优于Flow Matching(FM)，发现在单峰高斯分布中TM能达到更低的KL散度，在混合高斯分布中当模式分离良好且方差不可忽略时TM表现更优。

- Motivation: 尽管Flow Matching支撑了许多最先进的生成模型，但最近结果表明Transition Matching可以用更少的采样步骤实现更高质量。本文旨在回答TM何时以及为何优于FM的问题。
- Method: 首先在单峰高斯分布场景下证明TM获得更低的KL散度，分析其随机差异潜在更新如何保持目标协方差。然后扩展到高斯混合分布，识别局部单峰性机制，并分析近似误差与模式分离距离的关系。
- Result: 理论证明在单峰高斯分布中TM达到严格更低的KL散度且收敛更快；在高斯混合分布中，当模式分离良好且方差不可忽略时TM优于FM，但随着目标方差趋近于零，TM优势减弱。
- Conclusion: TM在目标分布具有良好分离的模式且方差不可忽略时优于FM，这一结论在控制实验和真实世界图像视频生成应用中得到了验证。


### [102] [From Competition to Synergy: Unlocking Reinforcement Learning for Subject-Driven Image Generation](https://arxiv.org/abs/2510.18263)
*Ziwei Huang,Ying Shu,Hao Fang,Quanyu Long,Wenya Wang,Qiushi Guo,Tiezheng Ge,Leilei Gan*

Main category: cs.LG

TL;DR: 提出了Customized-GRPO框架，通过协同感知奖励塑造和时间感知动态加权来解决主题驱动图像生成中身份保真度与提示遵循度之间的权衡问题，显著优于朴素GRPO基线。

- Motivation: 主题驱动图像生成模型面临身份保真度与提示遵循度的基本权衡。在线强化学习（特别是GRPO）提供了有前景的解决方案，但朴素应用会导致竞争性退化，因为简单的线性奖励聚合会产生冲突的梯度信号，并与扩散过程的时间动态不匹配。
- Method: Customized-GRPO框架包含两个关键创新：(1) 协同感知奖励塑造(SARS)：非线性机制，明确惩罚冲突奖励信号并放大协同信号，提供更清晰、更决定性的梯度；(2) 时间感知动态加权(TDW)：通过早期优先提示遵循、后期优先身份保真度，使优化压力与模型时间动态对齐。
- Result: 广泛实验表明，该方法显著优于朴素GRPO基线，成功缓解了竞争性退化。模型实现了更优的平衡，生成的图像既保留了关键身份特征，又准确遵循复杂文本提示。
- Conclusion: Customized-GRPO通过创新的奖励塑造和动态加权机制，有效解决了主题驱动图像生成中的保真度-可编辑性权衡问题，为在线强化学习在图像生成领域的应用提供了更优的解决方案。


### [103] [Ensembling Pruned Attention Heads For Uncertainty-Aware Efficient Transformers](https://arxiv.org/abs/2510.18358)
*Firas Gabetni,Giuseppe Curci,Andrea Pilzer,Subhankar Roy,Elisa Ricci,Gianni Franchi*

Main category: cs.LG

TL;DR: 提出了Hydra Ensembles，一种高效的基于Transformer的集成方法，通过剪枝注意力头创建多样化成员，并使用分组全连接层合并，在保持接近单网络推理速度的同时，达到或超越Deep Ensembles的不确定性量化性能。

- Motivation: 深度神经网络在安全关键场景中需要不确定性量化，但现有方法如Deep Ensembles计算和内存成本高，难以扩展到大型模型。
- Method: 剪枝Transformer的注意力头来创建多样化的集成成员，然后通过新的多头注意力和分组全连接层将它们合并成一个紧凑模型，无需从头重新训练。
- Result: 在图像和文本分类任务上，与Deep Ensembles相比获得了一致的性能提升。在ImageNet-1k的零样本分类中，即使不需要额外训练也超越了现有最先进方法。
- Conclusion: Hydra Ensembles提供了一种计算高效的不确定性量化方法，在保持高性能的同时显著降低了计算和内存开销。


### [104] [Prototyping an End-to-End Multi-Modal Tiny-CNN for Cardiovascular Sensor Patches](https://arxiv.org/abs/2510.18668)
*Mustafa Fuad Rifet Ibrahim,Tunc Alkanat,Maurice Meijer,Felix Manthey,Alexander Schlaefer,Peer Stelldinger*

Main category: cs.LG

TL;DR: 该研究提出了一种用于心电和心音信号分类的轻量级卷积神经网络，在资源受限的边缘医疗设备上实现了三个数量级的内存和计算成本降低，同时保持竞争力精度。

- Motivation: 心血管疾病早期检测至关重要，可穿戴传感器设备可实现连续监测，但需要高效准确的自动化数据分析方法，以减轻临床医生负担并支持边缘设备部署。
- Method: 采用具有早期数据融合的卷积神经网络，对同步的心电图和心音图记录进行二分类，在Physionet Challenge 2016数据集上训练和验证。
- Result: 相比现有技术，该方法将内存占用和计算成本降低了三个数量级，同时在微控制器和实验传感器设备上验证了其能效优势，证明设备端推理比持续数据流更节能。
- Conclusion: 所提出的轻量级深度学习模型适用于资源受限的医疗边缘设备，为心血管监测提供了高效、节能的自动化解决方案。
## cs.SE

### [105] [CUARewardBench: A Benchmark for Evaluating Reward Models on Computer-using Agent](https://arxiv.org/abs/2510.18596)
*Haojia Lin,Xiaoyu Tan,Yulei Qin,Zihan Xu,Yuchen Shi,Zongyi Li,Gang Li,Shaofei Cai,Siqi Cai,Chaoyou Fu,Ke Li,Xing Sun*

Main category: cs.SE

TL;DR: 提出了CUARewardBench，首个用于评估计算机使用代理（CUA）奖励模型的基准，包含轨迹级和步骤级评估，并通过Unanimous Prompt Ensemble方法显著提升奖励模型的可靠性。

- Motivation: 解决现有基于脚本的验证器在CUA评估中扩展性有限且无法提供逐步评估的问题，探索奖励模型在CUA评估中的有效性。
- Method: 构建包含10个软件类别和7种代理架构的多样化数据集，设计专家标注协议，通过7个视觉语言模型和3种提示模板进行实验分析，并提出Unanimous Prompt Ensemble集成方法。
- Result: 揭示了当前CUA奖励模型的关键局限性，包括视觉推理能力不足和知识缺陷。UPE方法在ORM上达到89.8%精确度和93.3%负预测值，在PRM上达到81.7%精确度和85.1%负预测值。
- Conclusion: 通用视觉语言模型在奖励评估中优于专门的CUA模型，提出的UPE方法显著提升了奖励模型的可靠性，为CUA评估提供了有效的解决方案。
## eess.IV

### [106] [Conformal Lesion Segmentation for 3D Medical Images](https://arxiv.org/abs/2510.17897)
*Binyu Tan,Zhiyuan Wang,Jinhao Duan,Kaidi Xu,Heng Tao Shen,Xiaoshuang Shi,Fumin Shen*

Main category: eess.IV

TL;DR: 提出了一个风险约束框架CLS，通过保形化校准数据驱动阈值，确保测试时假阴性率低于目标容差ε，为医学图像分割提供统计保证。

- Motivation: 现有医学图像分割模型使用固定阈值区分病灶和背景，缺乏对假阴性率等关键指标的统计保证，限制了在高风险临床应用中的可靠部署。
- Method: CLS框架保留校准集分析FNR容差下的阈值设置，定义FNR特定损失函数，识别满足目标容差的临界阈值，然后确定校准集中临界阈值的近似1-α分位数作为测试时置信阈值。
- Result: 在六个3D病灶分割数据集和五个骨干模型上验证了CLS的统计合理性和预测性能，提供了更精确可靠的分割结果。
- Conclusion: CLS通过保形化临界阈值，将校准集观察到的统计规律推广到新测试数据，提供严格的FNR约束，为临床实践中部署风险感知分割提供了可行见解。
## cs.CL

### [107] [LightMem: Lightweight and Efficient Memory-Augmented Generation](https://arxiv.org/abs/2510.18866)
*Jizhan Fang,Xinle Deng,Haoming Xu,Ziyan Jiang,Yuqi Tang,Ziwen Xu,Shumin Deng,Yunzhi Yao,Mengru Wang,Shuofei Qiao,Huajun Chen,Ningyu Zhang*

Main category: cs.CL

TL;DR: LightMem是一个为大型语言模型设计的高效记忆系统，通过三阶段记忆架构（感官记忆、短时记忆、长时记忆）在保持高性能的同时显著降低计算开销。

- Motivation: 现有记忆系统在处理动态复杂环境时存在显著的时间和计算开销问题，需要一种平衡性能与效率的解决方案。
- Method: 受人类记忆模型启发，LightMem采用三阶段架构：感官记忆快速过滤无关信息，短时记忆按主题组织内容，长时记忆使用离线更新机制。
- Result: 在LongMemEval基准测试中，LightMem相比基线方法准确率提升达10.9%，同时token使用减少117倍，API调用减少159倍，运行时间减少12倍以上。
- Conclusion: LightMem成功实现了记忆系统性能与效率的良好平衡，为LLMs在动态环境中的应用提供了实用解决方案。
## eess.SY

### [108] [DMTrack: Deformable State-Space Modeling for UAV Multi-Object Tracking with Kalman Fusion and Uncertainty-Aware Association](https://arxiv.org/abs/2510.17860)
*Zenghuang Fu,Xiaofeng Han,Mingda Jia,Jin ming Yang,Qi Zeng,Muyang Zahng,Changwei Wang,Weiliang Meng,Xiaopeng Zhang*

Main category: eess.SY

TL;DR: DMTrack是一个针对无人机多目标跟踪的变形运动跟踪框架，通过DeformMamba动态聚合历史运动状态、MotionGate融合卡尔曼和Mamba预测、以及不确定性感知关联策略，在无外观模型的情况下实现了最先进的跟踪性能。

- Motivation: 无人机多目标跟踪面临物体运动不可预测、频繁遮挡和外观线索有限等挑战，传统运动模型在捕捉线性和非线性动态方面表现不足，导致轨迹估计不可靠和身份切换问题。
- Method: 提出DMTrack框架，包含三个核心组件：DeformMamba（变形状态空间预测器）、MotionGate（轻量级门控模块）和不确定性感知关联策略，专注于运动建模而不依赖外观信息。
- Result: 在VisDrone-MOT和UAVDT基准测试中，DMTrack在身份一致性和跟踪精度方面达到最先进水平，特别是在高速和非线性运动场景下表现优异，同时保持竞争性效率。
- Conclusion: DMTrack证明了仅基于运动建模的方法在无人机多目标跟踪中的有效性，为鲁棒的无人机跟踪提供了实用解决方案，无需外观模型即可实现高性能。
## cs.PF

### [109] [Metrics and evaluations for computational and sustainable AI efficiency](https://arxiv.org/abs/2510.17885)
*Hongyuan Liu,Xinyang Liu,Guosheng Hu*

Main category: cs.PF

TL;DR: 提出一种统一且可复现的AI模型推理评估方法，整合计算和环境指标，在保持精度约束下系统测量延迟、吞吐量、能耗和碳排，建立严谨的基准测试框架。

- Motivation: AI快速发展对计算能力需求激增，但现有评估方法碎片化，难以在异构硬件、软件栈和数值精度下提供整体性能视图和系统比较。
- Method: 开发统一可复现的方法论，在真实服务条件下系统测量延迟和吞吐量分布、能耗、位置调整的碳排放，同时保持匹配的精度约束。应用于从数据中心加速器到消费级GPU的多精度模型。
- Result: 建立了严谨的基准测试框架，生成决策就绪的帕累托前沿，阐明精度、延迟、能耗和碳排之间的权衡关系。
- Conclusion: 该框架通过开源代码支持独立验证，赋能研究者和从业者基于证据做出可持续AI部署决策。
## eess.SP

### [110] [Cross-Domain Multi-Person Human Activity Recognition via Near-Field Wi-Fi Sensing](https://arxiv.org/abs/2510.17816)
*Xin Li,Jingzhi Hu,Yinghui He,Hongbo Wang,Jin Gan,Jun Luo*

Main category: eess.SP

TL;DR: WiAnchor是一个用于Wi-Fi多人体活动识别的训练框架，通过近场主导效应和锚点匹配机制，在活动类别不完整的情况下实现高效的跨域适应。

- Motivation: Wi-Fi人体活动识别面临多用户区分困难的问题，且由于近场信号的特异性和不规则模式，神经网络模型需要跨域微调，这在某些活动类别不可用时尤为挑战。
- Method: 三步训练框架：预训练阶段扩大类间特征间距增强活动可分性；微调阶段创新锚点匹配机制进行跨域适应，基于不完整活动类别过滤主体特异性干扰；最后基于输入样本与锚点的特征相似性改进识别。
- Result: 构建了综合数据集进行充分评估，在活动类别缺失的情况下实现了超过90%的跨域准确率。
- Conclusion: WiAnchor框架有效解决了Wi-Fi多人体活动识别中跨域适应和类别不完整的挑战，实现了高精度的识别性能。
## cs.AI

### [111] [FST.ai 2.0: An Explainable AI Ecosystem for Fair, Fast, and Inclusive Decision-Making in Olympic and Paralympic Taekwondo](https://arxiv.org/abs/2510.18193)
*Keivan Shariatmadar,Ahmad Osman,Ramin Ray,Usman Dildar,Kisam Kim*

Main category: cs.AI

TL;DR: FST.ai 2.0是一个可解释的AI生态系统，用于支持跆拳道比赛和训练中的实时决策，通过姿态识别、不确定性建模和可视化解释减少决策时间并提高裁判信任度。

- Motivation: 解决奥林匹克和残奥会格斗运动中公平、透明和可解释决策的挑战，支持裁判、教练和运动员的实时决策需求。
- Method: 集成基于图卷积网络的姿态动作识别、通过置信集进行认知不确定性建模、可视化解释叠加层和交互式仪表板，实现人机协作。
- Result: 在比赛数据上的实验验证显示决策审查时间减少85%，AI辅助决策的裁判信任度达到93%。
- Conclusion: 该框架建立了一个透明且可扩展的管道，用于可信赖的数据驱动裁判和运动员评估，代表了体育领域公平、负责任和以人为本的AI发展方向。


### [112] [Seg the HAB: Language-Guided Geospatial Algae Bloom Reasoning and Segmentation](https://arxiv.org/abs/2510.18751)
*Patterson Hsieh,Jerry Yeh,Mao-Chi He,Wen-Han Hsieh,Elvis Hsieh*

Main category: cs.AI

TL;DR: 提出了ALGOS系统，结合遥感图像理解和严重程度估计，用于有害藻华监测，在分割和严重程度估计方面表现稳健。

- Motivation: 气候变化加剧了有害藻华的发生，传统监测方法劳动密集且覆盖范围有限，需要可扩展的AI驱动解决方案。
- Method: 集成GeoSAM辅助人工评估进行高质量分割掩码整理，并使用NASA的CAML数据集微调视觉语言模型进行严重程度预测。
- Result: ALGOS在分割和严重程度级别估计方面实现了稳健性能。
- Conclusion: 为实用和自动化的蓝藻监测系统铺平了道路。
## cs.GR

### [113] [A Generalizable Light Transport 3D Embedding for Global Illumination](https://arxiv.org/abs/2510.18189)
*Bing Xu,Mukund Varma T,Cheng Wang,Tzumao Li,Lifan Wu,Bartlomiej Wronski,Ravi Ramamoorthi,Marco Salvi*

Main category: cs.GR

TL;DR: 提出了一种可泛化的3D光传输嵌入方法，直接从3D场景配置近似全局光照，无需使用光栅化或路径追踪线索。

- Motivation: 全局光照对真实感渲染至关重要但计算昂贵。现有神经方法主要依赖逐场景优化或停留在2D屏幕空间，存在视角不一致和空间理解有限的问题。
- Method: 将场景表示为具有几何和材质特征的点云，使用可扩展transformer建模全局点对点交互，将特征编码为神经基元。渲染时通过最近邻搜索和交叉注意力聚合特征来预测渲染量。
- Result: 在多样化室内场景中展示了漫反射全局光照预测结果，训练好的嵌入可以快速适应新的渲染任务，还展示了光泽材质的空间-方向辐射场估计。
- Conclusion: 该方法为将学习先验集成到渲染管线提供了一条路径，无需显式的光线追踪光照线索。
## math.OC

### [114] [DualHash: A Stochastic Primal-Dual Algorithm with Theoretical Guarantee for Deep Hashing](https://arxiv.org/abs/2510.18218)
*Luxuan Li,Xiao Wang,Chunfeng Cui*

Main category: math.OC

TL;DR: 提出DualHash算法，通过Fenchel对偶将W型正则化的非凸优化问题部分转换到对偶空间，获得闭式近端解，提供严格复杂度保证。

- Motivation: 深度哈希中的离散量化挑战：现有方法直接优化W型正则化缺乏收敛保证，而近端梯度方法因正则器与神经网络输出的耦合导致缺乏闭式解。
- Method: 使用随机原始-对偶哈希算法，通过Fenchel对偶将非凸W型正则化优化部分转换到对偶空间，获得可闭式求解的近端算子。
- Result: 提出两个算法实例：动量加速版本复杂度为O(ε⁻⁴)，使用方差减少的改进版本复杂度为O(ε⁻³)。在三个图像检索数据库上表现优异。
- Conclusion: DualHash算法通过原始-对偶框架有效解决了深度哈希中的离散优化问题，提供了理论保证和实际性能优势。
