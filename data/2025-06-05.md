[[toc]]

## cs.CV

### [1] [Dual Branch VideoMamba with Gated Class Token Fusion for Violence Detection](https://arxiv.org/abs/2506.03162)
*Damith Chamalke Senadeera,Xiaoyun Yang,Dimitrios Kollias,Gregory Slabaugh*

Main category: cs.CV

TL;DR: 提出了一种结合双分支设计和状态空间模型（SSM）的高效架构Dual Branch VideoMamba，用于视频暴力检测，性能优于现有方法。

- Motivation: 随着监控摄像头的快速普及，自动化暴力检测需求增加，但现有方法（如CNN和Transformer）在长时依赖和计算效率上存在不足。
- Method: 采用双分支设计，一支捕获空间特征，另一支关注时序动态，通过门控机制实现连续融合；并整合多个数据集建立新基准。
- Result: 模型在新基准上达到最优性能，平衡了准确性和计算效率。
- Conclusion: 证明了SSM在可扩展、实时监控暴力检测中的潜力。


### [2] [Farm-LightSeek: An Edge-centric Multimodal Agricultural IoT Data Analytics Framework with Lightweight LLMs](https://arxiv.org/abs/2506.03168)
*Dawen Jiang,Zhishu Shen,Qiushi Zheng,Tiehua Zhang,Wei Xiang,Jiong Jin*

Main category: cs.CV

TL;DR: Farm-LightSeek是一个基于边缘计算和多模态数据处理的农业物联网框架，结合大语言模型（LLMs）解决智能农业中的实时决策和动态环境适应问题。

- Motivation: 全球人口增长和气候变化对农业提出挑战，传统农业物联网系统在数据处理、实时决策和动态环境适应方面存在不足，需要更高效的解决方案。
- Method: 提出Farm-LightSeek框架，集成LLMs与边缘计算，通过多源数据采集、跨模态推理和边缘节点决策，实现低延迟管理和云协作。
- Result: 实验表明，Farm-LightSeek在边缘计算资源有限的情况下，仍能可靠完成关键任务。
- Conclusion: Farm-LightSeek推动了实时智能农业的发展，展示了农业物联网与LLMs深度融合的潜力。


### [3] [Improvement of human health lifespan with hybrid group pose estimation methods](https://arxiv.org/abs/2506.03169)
*Arindam Chaudhuri*

Main category: cs.CV

TL;DR: 提出了一种混合集成群体姿态估计方法，结合改进的群体姿态估计和实时姿态估计，提升多人姿态检测效果，优化实时性能。

- Motivation: 人类姿态估计在健康监测等应用中需求增长，现有方法需改进以应对遮挡和密集回归问题。
- Method: 开发混合集成方法，融合群体姿态估计和实时姿态估计，通过姿态变换提取特征并训练定制预训练模型。
- Result: 在基准数据集上表现优异，实时性能优化，抗遮挡能力增强，密集回归精度提高。
- Conclusion: 该方法在实时应用中潜力显著，有望改善人类健康监测效果。


### [4] [PALADIN : Robust Neural Fingerprinting for Text-to-Image Diffusion Models](https://arxiv.org/abs/2506.03170)
*Murthy L,Subarna Tripathi*

Main category: cs.CV

TL;DR: 本文提出了一种利用循环纠错码理论的神经指纹技术，以提高文本到图像扩散模型的归属准确性。

- Motivation: 由于开源文本到图像生成模型可能被恶意使用，神经指纹技术成为风险缓解策略，但现有方法无法达到100%的归属准确性。
- Method: 利用循环纠错码理论，提出了一种新的神经指纹技术。
- Result: 该方法显著提高了归属准确性。
- Conclusion: 通过结合编码理论，本文方法为神经指纹技术提供了更高的准确性，解决了现有方法的不足。


### [5] [EdgeVidSum: Real-Time Personalized Video Summarization at the Edge](https://arxiv.org/abs/2506.03171)
*Ghulam Mujtaba,Eun-Seok Ryu*

Main category: cs.CV

TL;DR: EdgeVidSum是一种轻量级方法，直接在边缘设备上生成长视频的个性化快进摘要，通过本地数据处理保护隐私，并利用创新的缩略图技术和高效神经架构。

- Motivation: 解决传统视频摘要方法计算复杂度高、无法在边缘设备上实时处理以及用户隐私保护不足的问题。
- Method: 使用缩略图容器减少计算复杂度，采用轻量级2D CNN模型从缩略图中识别用户偏好内容，并生成时间戳以创建快进摘要。
- Result: 能够在资源受限的设备（如Jetson Nano）上实时生成个性化视频摘要，适用于电影、体育赛事和电视节目等长视频。
- Conclusion: EdgeVidSum在计算效率、个性化和隐私保护方面解决了现代视频消费环境中的关键挑战。


### [6] [FOLIAGE: Towards Physical Intelligence World Models Via Unbounded Surface Evolution](https://arxiv.org/abs/2506.03173)
*Xiaoyi Liu,Hao Tang*

Main category: cs.CV

TL;DR: FOLIAGE是一个物理信息多模态世界模型，用于无界增长表面，通过统一编码器和物理感知预测器生成模态无关的生长嵌入（MAGE），并在SURF-BENCH评估中表现优异。

- Motivation: 为下一代世界模型提供物理智能，通过多模态观察预测和塑造世界。
- Method: 采用统一上下文编码器处理多模态输入，物理感知预测器生成MAGE，结合Accretive Graph Network（AGN）和多种增强技术。
- Result: 在SURF-BENCH评估中，FOLIAGE优于专用基线模型，并在动态环境中表现稳健。
- Conclusion: FOLIAGE为物理智能提供了一种新的多模态世界模型路径，具有广泛的应用潜力。


### [7] [Multimodal Foundation Model for Cross-Modal Retrieval and Activity Recognition Tasks](https://arxiv.org/abs/2506.03174)
*Koki Matsuishi,Kosuke Ukita,Tsuyoshi Okita*

Main category: cs.CV

TL;DR: 论文提出AURA-MFM多模态基础模型，整合第三人称视频、动作捕捉、IMU和文本数据，提升人体活动分析的全面性和性能。

- Motivation: 现有多模态基础模型未能全面分析全身活动，需结合更多视角和数据模态。
- Method: 整合四种模态数据，采用基于Transformer的IMU编码器。
- Result: 在检索和活动识别任务中表现优异，零样本分类F1-score达0.6226，准确率0.7320。
- Conclusion: AURA-MFM显著优于现有方法，为多模态人体活动分析提供更全面的解决方案。


### [8] [Vid-SME: Membership Inference Attacks against Large Video Understanding Models](https://arxiv.org/abs/2506.03179)
*Qi Li,Runpeng Yu,Xinchao Wang*

Main category: cs.CV

TL;DR: Vid-SME是一种针对视频理解大语言模型（VULLMs）的成员推理方法，通过计算Sharma-Mittal熵（SME）差异来检测训练数据中的敏感视频内容。

- Motivation: 多模态大语言模型（MLLMs）在视频理解中应用广泛，但训练数据可能包含敏感视频内容，现有成员推理方法（MIAs）在视频领域效果不佳。
- Method: 提出Vid-SME方法，利用模型输出置信度和自适应参数化计算SME，通过自然视频帧与时间反转帧的SME差异生成成员分数。
- Result: 实验表明，Vid-SME在多种VULLMs中表现优异，能有效检测训练数据中的视频成员。
- Conclusion: Vid-SME解决了视频领域成员推理的挑战，为数据隐私保护提供了有效工具。


### [9] [TerraIncognita: A Dynamic Benchmark for Species Discovery Using Frontier Models](https://arxiv.org/abs/2506.03182)
*Shivani Chiranjeevi,Hossein Zaremehrjerdi,Zi K. Deng,Talukder Z. Jubery,Ari Grele,Arti Singh,Asheesh K Singh,Soumik Sarkar,Nirav Merchant,Harold F. Greeney,Baskar Ganapathysubramanian,Chinmay Hegde*

Main category: cs.CV

TL;DR: TerraIncognita是一个动态基准测试，用于评估多模态模型在识别未知昆虫物种方面的能力，结合已知和罕见物种图像，模拟真实生态发现场景。

- Motivation: 全球生物多样性快速丧失，尤其是昆虫，亟需高效物种发现方法以支持及时保护行动。
- Method: 构建包含已知和罕见物种图像的基准数据集，评估模型在分类、检测新物种及生成专家级解释的能力。
- Result: 模型在已知物种的Order级别F1超过90%，但Species级别低于2%，显示从粗到细分类的难度梯度。
- Conclusion: TerraIncognita将定期更新，为前沿AI方法提供持续评估平台，助力生态保护。


### [10] [Impact of Tuning Parameters in Deep Convolutional Neural Network Using a Crack Image Dataset](https://arxiv.org/abs/2506.03184)
*Mahe Zabin,Ho-Jin Choi,Md. Monirul Islam,Jia Uddin*

Main category: cs.CV

TL;DR: 研究了深度卷积神经网络（DCNN）中不同调参对性能的影响，发现使用maxpooling、adam优化器和tanh激活函数时性能最佳。

- Motivation: 探讨DCNN中调参对分类器性能的影响，以优化模型表现。
- Method: 使用包含2个卷积层、2个池化层、1个dropout层和1个密集层的DCNN，通过实验评估池化、激活函数和优化器的调参效果。
- Result: 实验结果表明，maxpooling、adam优化器和tanh激活函数的组合性能最优。
- Conclusion: 调参对DCNN性能有显著影响，maxpooling、adam和tanh的组合是优化选择。


### [11] [Continual Learning in Vision-Language Models via Aligned Model Merging](https://arxiv.org/abs/2506.03189)
*Ghada Sokar,Gintare Karolina Dziugaite,Anurag Arnab,Ahmet Iscen,Pablo Samuel Castro,Cordelia Schmid*

Main category: cs.CV

TL;DR: 提出了一种基于模型合并的持续学习方法，通过合并新任务参数与旧任务参数，平衡稳定性和可塑性，减少遗忘并提升泛化能力。

- Motivation: 传统持续学习方法通过顺序微调倾向于可塑性而非稳定性，导致对近期任务的偏见和遗忘问题。
- Method: 采用模型合并策略，将新训练的任务参数与先前学习的参数合并，并通过机制学习对齐权重以避免干扰。
- Result: 在大型视觉语言模型上验证，有效减少遗忘、增强对任务顺序和相似性的鲁棒性，并提升泛化能力。
- Conclusion: 模型合并方法为持续学习提供了新的视角，平衡了稳定性和可塑性，具有实际应用潜力。


### [12] [MINT: Memory-Infused Prompt Tuning at Test-time for CLIP](https://arxiv.org/abs/2506.03190)
*Jiaming Yi,Ruirui Pan,Jishen Yang,Xiulong Yang*

Main category: cs.CV

TL;DR: 提出了一种名为MINT的新框架，通过记忆提示库（MPB）动态调整视觉语言预训练模型（VLMs）以适应测试时的数据分布变化。

- Motivation: 现有测试时适应（TTA）方法未能充分利用模型内部知识，特别是在动态适应复杂和分层的视觉语义信息方面。
- Method: MINT引入记忆提示库（MPB），存储可学习的键值提示对，通过测试图像的分层视觉特征检索相关提示对，动态组装关联提示，并注入图像编码器。
- Result: MINT无需源数据或重新训练，即可实现快速、精确的VLM适应。
- Conclusion: MINT通过记忆提示库有效提升了VLMs在测试时的泛化能力。


### [13] [Multimodal Generative AI with Autoregressive LLMs for Human Motion Understanding and Generation: A Way Forward](https://arxiv.org/abs/2506.03191)
*Muhammad Islam,Tao Huang,Euijoon Ahn,Usman Naseem*

Main category: cs.CV

TL;DR: 本文综述了多模态生成式人工智能（GenAI）和自回归大语言模型（LLMs）在人体运动理解与生成中的应用，探讨了新兴方法、架构及其在提升运动合成逼真度和多样性方面的潜力。

- Motivation: 研究旨在探索如何通过文本描述指导生成复杂、类人的运动序列，以推动文本到运动生成技术的发展。
- Method: 分析了多种生成方法，包括自回归模型、扩散模型、生成对抗网络（GANs）、变分自编码器（VAEs）和基于Transformer的模型，评估其在运动质量、计算效率和适应性方面的优劣。
- Result: 研究表明，文本条件运动生成技术能够更精确地控制运动输出，而LLMs的引入进一步提升了语义对齐能力，增强了运动的连贯性和上下文相关性。
- Conclusion: 文本到运动的GenAI和LLM架构在医疗、人形机器人、游戏、动画和辅助技术等领域具有变革潜力，但仍需解决生成高效且逼真运动的挑战。


### [14] [Human Fall Detection using Transfer Learning-based 3D CNN](https://arxiv.org/abs/2506.03193)
*Ekram Alam,Abu Sufian,Paramartha Dutta,Marco Leo*

Main category: cs.CV

TL;DR: 本文提出了一种基于预训练3D CNN的视觉跌倒检测系统，通过提取时空特征并利用SVM分类器实现高效分类。

- Motivation: 老年人跌倒是一个严重的健康问题，随着老年人口增加，需要自动化的跌倒检测系统。
- Method: 使用预训练的3D CNN提取时空特征，仅训练SVM分类器以减少时间成本，采用分层五折交叉验证。
- Result: 在GMDCSA和CAUCAFall数据集上进行了实验，模型表现良好。
- Conclusion: 该方法通过预训练模型和SVM分类器实现了高效的跌倒检测，代码已开源。


### [15] [HueManity: Probing Fine-Grained Visual Perception in MLLMs](https://arxiv.org/abs/2506.03194)
*Rynaa Grover,Jayant Sravan Tamarapalli,Sahiti Yerramilli,Nilay Pande*

Main category: cs.CV

TL;DR: HueManity是一个评估多模态大语言模型（MLLMs）视觉感知能力的基准测试，结果显示MLLMs在精细感知任务上表现显著低于人类和传统计算机视觉模型。

- Motivation: 当前MLLMs在高层次视觉推理上表现优异，但在精细感知任务上存在明显不足，需要量化评估和改进。
- Method: 构建HueManity数据集，包含83,850张Ishihara风格点阵图像，测试MLLMs的精确模式识别能力。
- Result: MLLMs在数字“简单”任务上最高准确率为33.6%，字母数字“困难”任务仅为3%，远低于人类（100%和95.6%）和ResNet50模型（96.5%和94.5%）。
- Conclusion: MLLMs在视觉感知能力上存在显著缺陷，需改进架构和训练范式。HueManity数据集开源以促进相关研究。


### [16] [Unlabeled Data Improves Fine-Grained Image Zero-shot Classification with Multimodal LLMs](https://arxiv.org/abs/2506.03195)
*Yunqi Hong,Sohyun An,Andrew Bai,Neil Y. C. Lin,Cho-Jui Hsieh*

Main category: cs.CV

TL;DR: AutoSEP是一个自监督提示学习框架，旨在提升多模态大语言模型（MLLMs）在细粒度图像分类任务中的性能，无需标注数据。

- Motivation: 细粒度图像分类需要关注细微视觉差异，而现有MLLMs缺乏显式指导，容易忽略这些细节。
- Method: 提出AutoSEP框架，通过无标签数据迭代优化描述提示，引导MLLMs识别关键判别特征，无需训练或微调。
- Result: 在多个细粒度分类数据集上，AutoSEP平均比零样本分类提升13%，优于其他无监督基线方法。
- Conclusion: AutoSEP通过自监督优化显著提升了MLLMs的细粒度分类能力，且无需额外训练。


### [17] [Infinity Parser: Layout Aware Reinforcement Learning for Scanned Document Parsing](https://arxiv.org/abs/2506.03197)
*Baode Wang,Biao Wu,Weizhen Li,Meng Fang,Yanjie Liang,Zuming Huang,Haozhe Wang,Jun Huang,Ling Chen,Wei Chu,Yuan Qi*

Main category: cs.CV

TL;DR: 论文提出了一种名为layoutRL的端到端强化学习框架，用于解决文档解析中的布局感知问题，并通过新数据集Infinity-Doc-55K验证其性能。

- Motivation: 传统多阶段文档解析方法存在错误传播和布局适应性问题，亟需一种更高效且适应性强的解决方案。
- Method: 采用强化学习框架layoutRL，结合归一化编辑距离、段落计数准确性和阅读顺序保持的复合奖励，基于Infinity-Doc-55K数据集训练模型。
- Result: Infinity-Parser在OCR、表格和公式提取及阅读顺序检测任务中表现优异，超越现有专用管道和通用视觉语言模型。
- Conclusion: layoutRL框架和Infinity-Parser展示了在文档理解任务中的优越性能，相关代码和数据集将公开以推动研究进展。


### [18] [FLEX: A Large-Scale Multi-Modal Multi-Action Dataset for Fitness Action Quality Assessment](https://arxiv.org/abs/2506.03198)
*Hao Yin,Lijun Gu,Paritosh Parmar,Lin Xu,Tianxiao Guo,Weiwei Fu,Yang Zhang,Tianyou Zheng*

Main category: cs.CV

TL;DR: 论文提出了FLEX数据集，首个多模态、多动作的大规模数据集，结合表面肌电信号（sEMG）用于动作质量评估（AQA），填补了现有AQA在健身领域的空白。

- Motivation: 健身训练中潜在的风险需要专业评估和指导，而现有AQA方法和数据集局限于单视角竞技体育场景和RGB模态，无法满足健身动作的评估需求。
- Method: 构建FLEX数据集，包含多视角RGB视频、3D姿态、sEMG和生理信息，并引入知识图谱和惩罚函数进行细粒度标注。
- Result: 实验表明，多模态、多视角数据和细粒度标注显著提升了模型性能。
- Conclusion: FLEX推动了AQA方法向多模态和多动作场景发展，促进了人工智能在健身领域的应用。


### [19] [Channel-adaptive Cross-modal Generative Semantic Communication for Point Cloud Transmission](https://arxiv.org/abs/2506.03211)
*Wanting Yang,Zehui Xiong,Qianqian Yang,Ping Zhang,Merouane Debbah,Rahim Tafazolli*

Main category: cs.CV

TL;DR: 提出了一种名为GenSeC-PC的新型通道自适应跨模态生成语义通信方法，用于点云传输，结合图像与点云语义编码，实现高效压缩和高质量重建。

- Motivation: 随着自动驾驶和扩展现实的快速发展，高效的点云传输需求日益增长，现有方法在压缩效率和重建性能上存在不足。
- Method: 采用跨模态设计，融合图像与点云语义编码，结合通道自适应联合语义-信道编码架构，并利用修正的去噪扩散隐式模型加速解码。
- Result: 仿真结果表明，该方法在低信噪比、带宽限制等多样条件下表现稳健，支持完全模拟传输，显著提升压缩效率。
- Conclusion: GenSeC-PC通过生成先验和跨模态设计，实现了高效、鲁棒的点云传输，优于现有方法。


### [20] [ConMamba: Contrastive Vision Mamba for Plant Disease Detection](https://arxiv.org/abs/2506.03213)
*Abdullah Al Mamun,Miaohua Zhang,David Ahmedt-Aristizabal,Zeeshan Hayder,Mohammad Awrangjeb*

Main category: cs.CV

TL;DR: ConMamba是一种新型自监督学习框架，专为植物病害检测设计，通过双向状态空间模型和动态对比损失优化性能。

- Motivation: 现有深度学习方法依赖大量标注数据，成本高；自监督学习虽能利用未标注数据，但计算成本高且难以捕捉长程依赖。
- Method: 提出ConMamba框架，结合Vision Mamba Encoder（双向SSM）和动态双级对比损失，优化特征对齐。
- Result: 在三个基准数据集上显著优于现有方法。
- Conclusion: ConMamba为植物病害检测提供了高效且鲁棒的解决方案。


### [21] [OpenCarbon: A Contrastive Learning-based Cross-Modality Neural Approach for High-Resolution Carbon Emission Prediction Using Open Data](https://arxiv.org/abs/2506.03224)
*Jinwei Zeng,Yu Liu,Guozhen Zhang,Jingtao Ding,Yuming Lin,Jian Yuan,Yong Li*

Main category: cs.CV

TL;DR: 论文提出OpenCarbon模型，利用卫星图像和POI数据预测高分辨率城市碳排放，解决了功能性和空间连续性的挑战，性能显著提升。

- Motivation: 高分辨率碳排放估算对减排规划至关重要，但传统方法数据收集成本高，开放数据和先进学习技术提供了解决方案。
- Method: 结合卫星图像和POI数据，设计跨模态信息提取与融合模块及邻域信息聚合模块。
- Result: 模型性能显著提升（R2提高26.6%），泛化测试和案例研究验证了其有效性。
- Conclusion: OpenCarbon能捕捉城市功能与碳排放的内在关系，支持高效碳治理和减排规划。


### [22] [Pre-trained Vision-Language Models Assisted Noisy Partial Label Learning](https://arxiv.org/abs/2506.03229)
*Qian-Wei Wang,Yuqiu Xie,Letian Zhang,Zimo Liu,Shu-Tao Xia*

Main category: cs.CV

TL;DR: 本文提出了一种名为Co-Reg的创新方法，用于从预训练视觉语言模型（VLMs）生成的噪声部分标签中学习，通过协同伪标签机制和一致性正则化约束提升模型性能。

- Motivation: 预训练VLMs（如CLIP、LLaVa和GPT-4V）可以替代耗时的手动标注，但其生成的噪声标签具有实例依赖性，增加了学习难度。本文旨在解决这一问题。
- Method: 通过同时训练两个神经网络，利用协同伪标签机制净化训练标签，并在标签空间和特征表示空间施加一致性正则化约束。还可利用少量手动标注标签进一步提升性能。
- Result: 实验表明，该方法在去噪和消歧任务中优于其他算法，验证了其有效性，并展示了弱监督学习与预训练模型知识蒸馏结合的潜力。
- Conclusion: Co-Reg方法有效解决了预训练VLMs生成的噪声标签问题，为弱监督学习与预训练模型的结合提供了新思路。


### [23] [Chipmunk: Training-Free Acceleration of Diffusion Transformers with Dynamic Column-Sparse Deltas](https://arxiv.org/abs/2506.03275)
*Austin Silveria,Soham V. Govande,Daniel Y. Fu*

Main category: cs.CV

TL;DR: 本文提出了一种名为Chipmunk的方法，通过动态稀疏化减少Diffusion Transformers（DiTs）推理时的计算冗余，从而在不影响生成质量的情况下显著提升推理速度。

- Motivation: DiTs在高质量图像和视频生成中表现出色，但推理时计算成本高。研究发现DiT的潜在噪声向量在推理步骤中变化缓慢，表明计算存在冗余。
- Method: Chipmunk利用动态稀疏化技术，仅重新计算变化最快的中间激活值，同时缓存其余部分。通过输入令牌的体素重排序和稀疏核实现高效计算，并重叠计算与缓存更新以减少延迟。
- Result: 实验表明，Chipmunk在HunyuanVideo和FLUX.1-dev上分别实现了2.16倍和1.41倍的加速，且生成质量不受影响。结合全步骤缓存后，加速效果进一步提升。
- Conclusion: Chipmunk通过动态稀疏化有效减少了DiTs推理时的冗余计算，显著提升了速度，同时保持了生成质量。


### [24] [Learning Optical Flow Field via Neural Ordinary Differential Equation](https://arxiv.org/abs/2506.03290)
*Leyla Mirvakhabova,Hong Cai,Jisoo Jeong,Hanno Ackermann,Farhad Zanjani,Fatih Porikli*

Main category: cs.CV

TL;DR: 论文提出了一种基于神经ODE的动态调整计算步数的光流估计方法，显著提升了性能。

- Motivation: 传统方法使用固定步数的迭代优化可能因不适应输入数据而导致性能不佳。
- Method: 采用神经ODE模型动态预测光流导数，根据数据动态调整计算步数。
- Result: 在光流基准测试中表现优异，仅需单步优化即可超越现有模型。
- Conclusion: 神经ODE方法为光流估计提供了更灵活高效的解决方案。


### [25] [SportMamba: Adaptive Non-Linear Multi-Object Tracking with State Space Models for Team Sports](https://arxiv.org/abs/2506.03335)
*Dheeraj Khanna,Jerrin Bright,Yuhao Chen,John S. Zelek*

Main category: cs.CV

TL;DR: SportMamba是一种自适应混合多目标跟踪技术，专为动态团队运动设计，通过mamba-attention机制和高度自适应空间关联度量解决快速运动和遮挡问题。

- Motivation: 团队运动中的多目标跟踪因快速运动和频繁遮挡而具有挑战性，现有方法依赖检测和外观跟踪，难以应对复杂场景。
- Method: 提出mamba-attention机制建模非线性运动，引入高度自适应空间关联度量减少ID切换，扩展检测搜索空间以改进快速运动关联。
- Result: 在SportsMOT数据集上表现优异，并在冰球数据集VIP-HTD上展示了零样本迁移能力。
- Conclusion: SportMamba在复杂运动场景中实现了最先进的性能，并具备良好的泛化能力。


### [26] [Seeing the Arrow of Time in Large Multimodal Models](https://arxiv.org/abs/2506.03340)
*Zihui Xue,Mi Luo,Kristen Grauman*

Main category: cs.CV

TL;DR: 论文提出ArrowRL，一种基于强化学习的训练策略，通过逆向奖励机制提升大型多模态模型对时间方向性的感知能力，并在新基准AoTBench上验证其有效性。

- Motivation: 现代大型多模态模型（LMMs）在视频理解中难以感知和利用时间方向性，阻碍了更深层次的时间理解。
- Method: 提出ArrowRL，一种基于强化学习的训练策略，通过逆向奖励机制鼓励模型在正向和反向视频帧中产生不同的解释。
- Result: ArrowRL在AoTBench和标准视频问答基准上分别实现了超过20%和10%的准确率提升。
- Conclusion: ArrowRL验证了时间方向性理解在LMMs中的重要性，并显著提升了模型性能。


### [27] [Semiconductor SEM Image Defect Classification Using Supervised and Semi-Supervised Learning with Vision Transformers](https://arxiv.org/abs/2506.03345)
*Chien-Fu,Huang,Katherine Sieg,Leonid Karlinksy,Nash Flores,Rebekah Sheraw,Xin Zhang*

Main category: cs.CV

TL;DR: 该论文提出了一种基于视觉变换器（ViT）的自动缺陷分类方法，用于半导体晶圆缺陷的SEM图像分析，实现了90%以上的分类准确率。

- Motivation: 半导体工艺中的缺陷控制对提高产量、降低成本和预防故障至关重要，但传统人工分类方法存在效率低和偏差问题。
- Method: 采用ViT神经网络，结合DinoV2的迁移学习和半监督学习，对7400多张SEM图像中的11种缺陷类型进行分类。
- Result: 在每类缺陷少于15张图像的情况下，分类准确率超过90%。
- Conclusion: 该方法展示了快速、灵活且平台无关的缺陷分类工具的潜力。


### [28] [Toward Reliable VLM: A Fine-Grained Benchmark and Framework for Exposure, Bias, and Inference in Korean Street Views](https://arxiv.org/abs/2506.03371)
*Xiaonan Wang,Bo Shao,Hansaem Kim*

Main category: cs.CV

TL;DR: 论文介绍了KoreaGEO Bench，首个针对韩国街景的细粒度多模态地理定位基准数据集，填补了现有评测的不足。

- Motivation: 现有地理定位评测存在粗粒度、语言偏见和缺乏多模态及隐私意识的问题，需改进。
- Method: 构建包含1,080张高分辨率图像的韩国街景数据集，采用三路径评测协议评估十种主流视觉语言模型。
- Result: 结果显示模型定位精度受输入模态影响，且存在对核心城市的预测偏见。
- Conclusion: KoreaGEO Bench为地理定位研究提供了更全面的评测工具，揭示了模型的模态依赖性和空间偏见。


### [29] [A Foundation Model for Spatial Proteomics](https://arxiv.org/abs/2506.03373)
*Muhammad Shaban,Yuzhou Chang,Huaying Qiu,Yao Yu Yeo,Andrew H. Song,Guillaume Jaume,Yuchen Wang,Luca L. Weishaupt,Tong Ding,Anurag Vaidya,Abdallah Lamane,Daniel Shao,Mohammed Zidane,Yunhao Bai,Paige McCallum,Shuli Luo,Wenrui Wu,Yang Wang,Precious Cramer,Chi Ngai Chan,Pierre Stephan,Johanna Schaffenrath,Jia Le Lee,Hendrik A. Michel,Caiwei Tian,Cristina Almagro-Perez,Sophia J. Wagner,Sharifa Sahai,Ming Y. Lu,Richard J. Chen,Andrew Zhang,Mark Edward M. Gonzales,Ahmad Makky,Jia-Ying Joey Lee,Hao Cheng,Nourhan El Ahmar,Sayed Matar,Maximilian Haist,Darci Phillips,Yuqi Tan,Garry P. Nolan,W. Richard Burack,Jacob D. Estes,Jonathan T. C. Liu,Toni K Choueiri,Neeraj Agarwal,Marc Barry,Scott J. Rodig,Long Phi Le,Georg Gerber,Christian M. Schürch,Fabian J. Theis,Youn H Kim,Joe Yeong,Sabina Signoretti,Brooke E. Howitt,Lit-Hsin Loo,Qin Ma,Sizun Jiang,Faisal Mahmood*

Main category: cs.CV

TL;DR: KRONOS是一个为空间蛋白质组学设计的基础模型，通过自监督学习在多平台数据上训练，支持多种下游任务，性能优越且高效。

- Motivation: 空间蛋白质组学在基础模型的应用上仍有限，KRONOS旨在填补这一空白，提供灵活且可扩展的分析工具。
- Method: 采用自监督学习，训练于47百万图像块，涵盖175种蛋白质标记、16种组织类型和8种成像平台，并针对多通道高维数据优化架构。
- Result: 在11个独立队列中，KRONOS在细胞表型分析、治疗反应预测等任务中表现优异，且数据效率高。
- Conclusion: KRONOS为空间蛋白质组学提供了高效、可扩展的分析范式，支持跨机构比较和图像反向搜索。


### [30] [Cross-Modal Urban Sensing: Evaluating Sound-Vision Alignment Across Street-Level and Aerial Imagery](https://arxiv.org/abs/2506.03388)
*Pengyu Chen,Xiao Huang,Teng Fei,Sicheng Wang*

Main category: cs.CV

TL;DR: 研究探讨了城市声音与视觉场景的对应关系，通过多模态方法比较了不同视觉表示策略在捕捉声音语义上的效果，发现街景嵌入与声音对齐更强，而遥感分割在生态分类上更有效。

- Motivation: 探索城市声景在生态和社会信息传递中的潜力，填补大规模地理分析中声音数据的空白。
- Method: 采用多模态方法，结合地理参考声音记录、街景和遥感图像，使用AST、CLIP、RemoteCLIP等模型提取特征并评估跨模态相似性。
- Result: 街景嵌入与声音对齐更强，遥感分割在生态分类（BGA框架）上更有效。
- Conclusion: 嵌入模型提供更好的语义对齐，分割方法则在视觉结构与声学生态间建立可解释联系，推动了多模态城市感知领域的发展。


### [31] [Temporal Vegetation Index-Based Unsupervised Crop Stress Detection via Eigenvector-Guided Contrastive Learning](https://arxiv.org/abs/2506.03394)
*Shafqaat Ahmad*

Main category: cs.CV

TL;DR: EigenCL是一种无监督对比学习框架，利用NDRE时间动态和特征分解，实现作物早期胁迫检测，无需标记数据，效果优于传统方法。

- Motivation: 传统NDRE方法依赖标记数据且检测滞后，无法满足精准农业的早期干预需求。
- Method: 基于Sentinel-2 NDRE图像构建时间序列，通过特征分解提取主特征向量，用于对比学习嵌入。
- Result: 实现76%的早期胁迫检测（提前12天），聚类和分类性能优异（Silhouette: 0.748，分类准确率95%）。
- Conclusion: EigenCL提供了一种无标记、可扩展的早期胁迫检测方法，适用于数据稀缺的农业环境。


### [32] [ViT-Split: Unleashing the Power of Vision Foundation Models via Efficient Splitting Heads](https://arxiv.org/abs/2506.03433)
*Yifan Li,Xin Li,Tianqin Li,Wenbin He,Yu Kong,Liu Ren*

Main category: cs.CV

TL;DR: ViT-Split是一种新的视觉基础模型（VFM）适配方法，通过分离VFM的提取器和适配器组件，减少训练时间和参数调优，同时提升性能。

- Motivation: 现有VFM适配器存在梯度反向传播效率低、参数调优复杂及未充分利用先验知识的问题。
- Method: 提出ViT-Split方法，将VFM分为提取器和适配器两部分，引入任务头和先验头，冻结VFM主干以减少调优参数。
- Result: 在多个任务（如分割、检测等）上验证了ViT-Split的高效性，训练时间减少4倍，性能优于其他适配器。
- Conclusion: ViT-Split通过优化结构和减少调优需求，显著提升了VFM适配的效率和性能。


### [33] [Geometric Visual Fusion Graph Neural Networks for Multi-Person Human-Object Interaction Recognition in Videos](https://arxiv.org/abs/2506.03440)
*Tanqiu Qiao,Ruochen Li,Frederick W. B. Li,Yoshiki Kubotani,Shigeo Morishima,Hubert P. H. Shum*

Main category: cs.CV

TL;DR: 论文提出GeoVis-GNN模型，通过双注意力特征融合和实体图学习，有效结合视觉和几何特征，提升视频中的人-物交互识别性能，并在新数据集MPHOI-120上验证了其优越性。

- Motivation: 人-物交互识别需要结合视觉和几何特征，但如何在不损害各自特性的情况下融合多模态特征仍具挑战性。
- Method: 提出GeoVis-GNN模型，采用双注意力特征融合和实体图学习，从实体表示逐步构建高层次交互理解。
- Result: 在多种人-物交互场景（如双人交互、单手操作等）中表现优异，达到最先进水平。
- Conclusion: GeoVis-GNN通过多模态特征融合和实体图学习，显著提升了人-物交互识别的性能，适用于复杂现实场景。


### [34] [RefEdit: A Benchmark and Method for Improving Instruction-based Image Editing Model on Referring Expressions](https://arxiv.org/abs/2506.03448)
*Bimsara Pathiraja,Maitreya Patel,Shivam Singh,Yezhou Yang,Chitta Baral*

Main category: cs.CV

TL;DR: 论文提出RefEdit模型，用于解决复杂场景中多实体编辑问题，并在RefEdit-Bench基准上优于现有方法。

- Motivation: 现有方法在编辑复杂场景中的多实体时表现不佳，需要改进。
- Method: 引入RefEdit-Bench基准，并提出基于指令的RefEdit模型，使用合成数据训练。
- Result: RefEdit在少量数据训练下优于基于Flux/SD3的基线模型，并在多个基准上达到SOTA。
- Conclusion: RefEdit在复杂场景编辑中表现优异，数据与模型已开源。


### [35] [The effects of using created synthetic images in computer vision training](https://arxiv.org/abs/2506.03449)
*John W. Smutny*

Main category: cs.CV

TL;DR: 研究探讨了使用Unreal Engine 4生成合成图像补充数据集对深度学习模型的影响，发现合成图像可显著减少真实图像需求。

- Motivation: 解决真实图像数据稀缺、成本高及潜在毒化问题，提供廉价、可复制的替代方案。
- Method: 通过UE4生成合成图像，测试其在猫狗分类和焊接缺陷检测任务中的效果，并评估图像质量。
- Result: 合成图像可减少真实图像需求至10%，且对模型性能影响有限。
- Conclusion: 合成图像为数据稀缺项目提供了有效解决方案，并提出了使用指南和限制。


### [36] [RoNFA: Robust Neural Field-based Approach for Few-Shot Image Classification with Noisy Labels](https://arxiv.org/abs/2506.03461)
*Nan Xiang,Lifeng Xing,Dequan Jin*

Main category: cs.CV

TL;DR: 提出了一种鲁棒的神经场方法（RoNFA）用于小样本图像分类，具有抗标签噪声能力。

- Motivation: 小样本学习中标签错误不可避免，影响分类准确性，需提升模型鲁棒性。
- Method: RoNFA通过两个神经场分别表示特征和类别，利用软聚类生成类别代表神经元，并通过自适应感受野调整预测。
- Result: 在真实数据集上显著优于现有方法，抗噪性能强，甚至优于干净标签训练的结果。
- Conclusion: RoNFA在小样本学习中表现出色，对标签噪声具有强鲁棒性。


### [37] [MamFusion: Multi-Mamba with Temporal Fusion for Partially Relevant Video Retrieval](https://arxiv.org/abs/2506.03473)
*Xinru Ying,Jiaqi Mo,Jingyang Lin,Canghong Jin,Fangfang Wang,Lina Wei*

Main category: cs.CV

TL;DR: 本文提出了一种名为MamFusion的多Mamba模块框架，用于解决部分相关视频检索（PRVR）任务中的长序列视频内容理解问题，通过时间融合技术提升检索效果。

- Motivation: 部分相关视频检索（PRVR）任务中存在信息冗余问题，需要更高效的长序列视频内容理解方法。
- Method: 利用Mamba模块的长时状态空间建模能力和线性可扩展性，设计了多Mamba模块的时间融合框架（MamFusion），并引入Temporal T-to-V和V-to-T Fusion技术建模文本查询与视频片段的时间关系。
- Result: 在大规模数据集上的实验表明，MamFusion在检索效果上达到了最先进的性能。
- Conclusion: MamFusion通过时间融合技术显著提升了PRVR任务的检索准确性和上下文感知能力。


### [38] [Heterogeneous Skeleton-Based Action Representation Learning](https://arxiv.org/abs/2506.03481)
*Hongsong Wang,Xiaoyan Ma,Jidong Kuang,Jie Gui*

Main category: cs.CV

TL;DR: 该论文提出了一种处理异构骨架数据的框架，通过异构骨架处理和统一表示学习两部分，解决了骨架数据在关节维度和拓扑结构上的差异问题。

- Motivation: 骨架数据因来源不同具有异构性，而现有方法仅针对同构骨架设计模型，忽略了这种差异。
- Method: 框架包括异构骨架处理（通过辅助网络将二维骨架转为三维，并构建统一骨架）和统一表示学习（使用共享主干网络处理异构骨架）。
- Result: 在NTU-60、NTU-120和PKU-MMD II数据集上的实验验证了方法的有效性。
- Conclusion: 该方法适用于不同人形结构的机器人动作识别。


### [39] [CHIME: Conditional Hallucination and Integrated Multi-scale Enhancement for Time Series Diffusion Model](https://arxiv.org/abs/2506.03502)
*Yuxuan Chen,Haipeng Xie*

Main category: cs.CV

TL;DR: CHIME是一个用于时间序列扩散模型的条件幻觉和多尺度增强框架，解决了多尺度特征对齐和生成能力的挑战。

- Motivation: 扩散模型在时间序列任务中的应用面临多尺度特征对齐和跨实体、长时间尺度生成能力的挑战。
- Method: CHIME通过多尺度分解和自适应集成捕获时间序列特征，并引入特征幻觉模块实现时间特征迁移。
- Result: 在公开数据集上，CHIME实现了最先进的性能，并在少样本场景中表现出优秀的生成泛化能力。
- Conclusion: CHIME框架在时间序列生成任务中表现出卓越的性能和泛化能力。


### [40] [EDCFlow: Exploring Temporally Dense Difference Maps for Event-based Optical Flow Estimation](https://arxiv.org/abs/2506.03512)
*Daikun Liu,Lei Cheng,Teng Wang,changyin Sun*

Main category: cs.CV

TL;DR: EDCFlow是一个轻量级事件光流网络，通过结合时间密集特征差异和成本体积，实现高分辨率下的高质量光流估计。

- Motivation: 现有基于事件的光流估计方法存在计算冗余和高分辨率扩展性问题，EDCFlow旨在解决这些问题。
- Method: 开发了基于注意力的多尺度时间特征差异层，高效捕获高分辨率运动模式，并自适应融合高低分辨率运动特征。
- Result: EDCFlow在性能和复杂度上优于现有方法，具有更好的泛化能力。
- Conclusion: EDCFlow可作为RAFT类方法的插件模块，提升光流细节估计能力。


### [41] [DenseDPO: Fine-Grained Temporal Preference Optimization for Video Diffusion Models](https://arxiv.org/abs/2506.03517)
*Ziyi Wu,Anil Kag,Ivan Skorokhodov,Willi Menapace,Ashkan Mirzaei,Igor Gilitschenski,Sergey Tulyakov,Aliaksandr Siarohin*

Main category: cs.CV

TL;DR: DenseDPO改进DPO方法，通过生成对齐的视频对和分段标注偏好，减少运动偏差并提高标注效率，同时支持自动标注。

- Motivation: 传统DPO方法在文本到视频扩散模型中存在运动偏差和标注效率低的问题。
- Method: DenseDPO通过生成对齐的视频对、分段标注偏好，并利用VLMs自动标注。
- Result: DenseDPO用三分之一的数据显著提升运动生成效果，同时保持文本对齐和视觉质量。
- Conclusion: DenseDPO有效解决DPO的局限性，支持高效自动标注，性能接近人工标注。


### [42] [Target Semantics Clustering via Text Representations for Robust Universal Domain Adaptation](https://arxiv.org/abs/2506.03521)
*Weinan He,Zilei Wang,Yixin Zhang*

Main category: cs.CV

TL;DR: 本文提出了一种基于视觉语言模型的通用域适应方法（UniDA），通过文本表示空间搜索语义中心，实现简单且鲁棒的域对齐。

- Motivation: 解决通用域适应中因域偏移和未知类别偏移导致的复杂对齐问题，提出在语义明确的离散文本空间中搜索语义中心。
- Method: 提出TASC方法，分两阶段：1）基于贪婪搜索在文本表示空间寻找目标语义中心；2）固定搜索结果，通过梯度下降优化编码器。同时提出UniMS评分函数检测开放集样本。
- Result: 在四个基准测试中验证了方法的有效性和鲁棒性，取得了最先进的性能。
- Conclusion: 通过文本表示空间的语义中心搜索，实现了简单且鲁棒的通用域适应，显著提升了性能。


### [43] [Video-Skill-CoT: Skill-based Chain-of-Thoughts for Domain-Adaptive Video Reasoning](https://arxiv.org/abs/2506.03525)
*Daeun Lee,Jaehong Yoon,Jaemin Cho,Mohit Bansal*

Main category: cs.CV

TL;DR: Video-SKoT框架通过自动构建技能感知的CoT监督，提升了视频理解的领域适应性。

- Motivation: 现有CoT方法在适应不同视频内容中的领域特定技能（如事件检测、空间关系理解等）时表现不佳。
- Method: 1. 构建基于技能的CoT标注；2. 引入技能特定的专家学习框架。
- Result: 在三个视频理解基准测试中，Video-SKoT表现优于基线方法。
- Conclusion: Video-SKoT通过技能感知的CoT监督和专家学习，显著提升了视频理解的领域适应性。


### [44] [Robust Neural Rendering in the Wild with Asymmetric Dual 3D Gaussian Splatting](https://arxiv.org/abs/2506.03538)
*Chengqi Li,Zhihao Shi,Yangdi Lu,Wenbo He,Xiangyu Xu*

Main category: cs.CV

TL;DR: 提出了一种名为Asymmetric Dual 3DGS的新框架，通过并行训练两个3D高斯模型并引入一致性约束，减少视觉伪影，同时采用动态EMA代理提高效率。

- Motivation: 解决野外图像3D重建中因光照不一致和瞬态干扰导致的低质量数据问题，现有方法难以生成稳定结果。
- Method: 并行训练两个3D高斯模型，引入一致性约束和互补掩码策略防止模型崩溃，使用动态EMA代理提高效率。
- Result: 在真实数据集上表现优于现有方法，同时保持高效。
- Conclusion: Asymmetric Dual 3DGS框架有效减少了伪影并提高了重建质量，代码和模型将开源。


### [45] [WIFE-Fusion:Wavelet-aware Intra-inter Frequency Enhancement for Multi-model Image Fusion](https://arxiv.org/abs/2506.03555)
*Tianpei Zhang,Jufeng Zhao,Yiming Zhu,Guangmang Cui*

Main category: cs.CV

TL;DR: 提出了一种基于频域交互的多模态图像融合框架WIFE-Fusion，通过频域自注意力机制和频域间交互提升融合效果。

- Motivation: 现有方法忽视频域特征探索和交互关系，限制了融合效果。
- Method: 提出Intra-Frequency Self-Attention (IFSA)和Inter-Frequency Interaction (IFI)机制，分别提取和增强频域特征。
- Result: 在五个数据集上的实验表明，WIFE-Fusion优于现有专用和统一融合方法。
- Conclusion: WIFE-Fusion通过频域交互实现了更精确的特征提取和融合建模。


### [46] [DiagNet: Detecting Objects using Diagonal Constraints on Adjacency Matrix of Graph Neural Network](https://arxiv.org/abs/2506.03571)
*Chong Hyun Lee,Kibae Lee*

Main category: cs.CV

TL;DR: DaigNet是一种新的目标检测方法，通过图卷积网络（GCN）的邻接矩阵对角线约束来检测物体边界框，无需设计锚框。

- Motivation: 传统目标检测方法需要设计锚框，而DaigNet通过GCN的对角线约束简化了这一过程。
- Method: 提出两种基于硬约束和软约束的对角化算法，以及两种损失函数（对角线约束和互补约束），并采用YOLO模型的检测头。
- Result: 在Pascal VOC上比YOLOv1高7.5% mAP50，在MS COCO上比YOLOv3u高5.1% mAP，比YOLOv5u高3.7%，比YOLOv8高2.9%。
- Conclusion: DaigNet通过GCN的对角线约束有效提升了目标检测性能，且无需锚框设计。


### [47] [ViTSGMM: A Robust Semi-Supervised Image Recognition Network Using Sparse Labels](https://arxiv.org/abs/2506.03582)
*Rui Yann,Xianglei Xing*

Main category: cs.CV

TL;DR: ViTSGMM是一种高效的半监督学习图像识别网络，通过优化特征表示与目标类之间的互信息，构建分层混合密度分类决策机制，显著提升了在有限标注数据下的泛化能力。

- Motivation: 现有方法依赖复杂训练技术和架构，但在处理极有限标注数据时泛化能力不足。
- Method: 构建分层混合密度分类决策机制，优化特征表示与目标类的互信息，压缩冗余信息并保留关键判别成分。
- Result: 在STL-10和CIFAR-10/100数据集上，使用极少标注样本即达到最先进性能，并揭示了STL-10数据集中的数据泄漏问题。
- Conclusion: ViTSGMM在有限标注数据下表现出色，同时解决了数据泄漏问题，提升了实验可靠性。


### [48] [A Large-Scale Referring Remote Sensing Image Segmentation Dataset and Benchmark](https://arxiv.org/abs/2506.03583)
*Zhigang Yang,Huiguang Yao,Linmao Tian,Xuezhi Zhao,Qiang Li,Qi Wang*

Main category: cs.CV

TL;DR: 论文介绍了NWPU-Refer数据集和MRSNet模型，解决了现有RRSIS数据集的局限性，并在实验中验证了MRSNet的优越性能。

- Motivation: 现有RRSIS数据集在分辨率、场景多样性和类别覆盖上存在不足，限制了模型的泛化和实际应用。
- Method: 提出NWPU-Refer数据集和MRSNet模型，后者包含IFIM和HFIM模块，用于多尺度特征交互。
- Result: MRSNet在NWPU-Refer数据集上实现了最先进的性能。
- Conclusion: NWPU-Refer和MRSNet为RRSIS领域的发展提供了重要支持。


### [49] [BiMa: Towards Biases Mitigation for Text-Video Retrieval via Scene Element Guidance](https://arxiv.org/abs/2506.03589)
*Huy Le,Nhat Chung,Tung Kieu,Anh Nguyen,Ngan Le*

Main category: cs.CV

TL;DR: BiMa框架通过视觉和文本去偏方法提升文本-视频检索性能，在多个基准测试中表现优异。

- Motivation: 解决文本-视频检索系统中视觉-语言偏见问题，避免预训练模型忽略关键细节。
- Method: 生成场景元素增强视频嵌入（视觉去偏），解耦文本特征为内容和偏见部分（文本去偏）。
- Result: 在五个主要TVR基准测试中表现优异，并在分布外检索任务中验证了去偏能力。
- Conclusion: BiMa有效缓解了视觉和文本偏见，提升了检索性能。


### [50] [Resolving Task Objective Conflicts in Unified Multimodal Understanding and Generation via Task-Aware Mixture-of-Experts](https://arxiv.org/abs/2506.03591)
*Jiaxing Zhang,Xinyi Zeng,Hao Tang*

Main category: cs.CV

TL;DR: 论文提出了一种名为UTAMoE的新方法，通过解耦自回归（AR）内部组件来解决多模态大语言模型（MLLMs）中任务目标冲突的问题，并在多模态基准测试中取得了最优性能。

- Motivation: 现有基于自回归变换器的统一多模态大语言模型在理解和生成任务中存在任务目标冲突，导致性能不佳。现有解决方案未能从根本上解决这一问题。
- Method: 设计了UTAMoE框架，通过任务感知的混合专家（MoE）层解耦AR内部模块，并引入两阶段训练策略以增强任务区分和协调。
- Result: 在多模态基准测试中，UTAMoE有效缓解了任务目标冲突，实现了最优性能。可视化和消融研究验证了方法的有效性。
- Conclusion: UTAMoE通过解耦AR内部组件和两阶段训练策略，成功解决了任务目标冲突，为多模态大语言模型的优化提供了新思路。


### [51] [ControlThinker: Unveiling Latent Semantics for Controllable Image Generation through Visual Reasoning](https://arxiv.org/abs/2506.03596)
*Feng Han,Yang Jiao,Shaoxiang Chen,Junhao Xu,Jingjing Chen,Yu-Gang Jiang*

Main category: cs.CV

TL;DR: ControlThinker提出了一种基于视觉推理的图像生成框架，通过丰富文本提示的语义来缩小与目标图像的语义差距。

- Motivation: 现有方法在稀疏语义的文本提示与目标图像之间存在语义鸿沟，且过度依赖低层控制信号。
- Method: 采用“理解后生成”范式，利用MLLM挖掘控制图像的潜在语义，并通过ORM选择最佳推理轨迹。
- Result: 实验表明，ControlThinker显著改善了视觉质量和语义一致性。
- Conclusion: ControlThinker有效解决了语义差距问题，提升了生成图像的质量。


### [52] [Generating 6DoF Object Manipulation Trajectories from Action Description in Egocentric Vision](https://arxiv.org/abs/2506.03605)
*Tomoya Yoshida,Shuhei Kurita,Taichi Nishimura,Shinsuke Mori*

Main category: cs.CV

TL;DR: 提出一种框架，利用大规模视频数据集提取多样化操作轨迹，并基于视觉和点云语言模型生成轨迹。

- Motivation: 开发交互式机器人需要大量多样化操作演示，但收集这些数据成本高昂。
- Method: 利用Exo-Ego4D数据集提取操作轨迹，结合文本描述，基于视觉和点云语言模型生成轨迹。
- Result: 在HOT3D数据集上验证了模型能生成有效的6DoF操作轨迹。
- Conclusion: 为基于视觉生成操作轨迹的任务提供了数据集和基准模型。


### [53] [Analyzing Transformer Models and Knowledge Distillation Approaches for Image Captioning on Edge AI](https://arxiv.org/abs/2506.03607)
*Wing Man Casca Kwok,Yip Chiu Tung,Kunal Bhagchandani*

Main category: cs.CV

TL;DR: 研究探讨了在边缘计算设备上部署基于Transformer的图像描述模型，通过知识蒸馏技术提升推理速度并保持性能。

- Motivation: 边缘设备计算资源有限，但需满足实时性要求，传统深度学习模型难以适用。
- Method: 评估资源高效的Transformer模型，并应用知识蒸馏技术。
- Result: 在资源受限设备上加速推理的同时保持模型性能。
- Conclusion: 知识蒸馏和高效Transformer模型可有效支持边缘设备的实时AI应用。


### [54] [PDSE: A Multiple Lesion Detector for CT Images using PANet and Deformable Squeeze-and-Excitation Block](https://arxiv.org/abs/2506.03608)
*Di Fan,Heng Yu,Zhiyuan Xu*

Main category: cs.CV

TL;DR: PDSE是一种基于Retinanet改进的单阶段病灶检测框架，通过引入低层特征图和自适应SE模块，显著提升了多模态CT图像中病灶检测的准确性和效率。

- Motivation: 由于CT扫描中病灶类型、大小和位置的多样性，病灶检测是一项具有挑战性的任务。现有的一阶段和两阶段框架在病灶定位方面仍有改进空间。
- Method: 通过重新设计Retinanet，引入低层特征图增强路径聚合流，并采用自适应SE模块和通道特征图注意力机制，提升模型表示能力。
- Result: 在公共DeepLesion基准测试中，PDSE的mAP超过0.20，显著优于其他先进算法，尤其是在小目标和多尺度目标检测方面表现突出。
- Conclusion: PDSE框架通过改进特征融合和注意力机制，实现了病灶检测的新SOTA性能，为医学图像处理提供了高效解决方案。


### [55] [VLMs Can Aggregate Scattered Training Patches](https://arxiv.org/abs/2506.03614)
*Zhanhui Zhou,Lingjie Chen,Chao Yang,Chaochao Lu*

Main category: cs.CV

TL;DR: 论文研究了视觉语言模型（VLMs）中的视觉拼接能力，展示了如何通过分散有害图像的碎片绕过数据审核，并在推理时重建有害内容。

- Motivation: 研究动机是揭示VLMs中视觉拼接能力的安全风险，即模型可能通过分散的良性碎片学习并生成有害内容。
- Method: 方法包括在三个数据集上测试VLMs的视觉拼接能力，通过将图像分割为小块并标记唯一ID，模拟对抗性数据中毒场景。
- Result: 结果表明，VLMs能够通过视觉拼接从分散的碎片中重建完整信息，从而绕过数据审核并生成有害内容。
- Conclusion: 结论指出视觉拼接能力对VLM安全性构成严重威胁，需进一步研究防御措施。


### [56] [Isharah: A Large-Scale Multi-Scene Dataset for Continuous Sign Language Recognition](https://arxiv.org/abs/2506.03615)
*Sarah Alyami,Hamzah Luqman,Sadam Al-Azani,Maad Alowaifeer,Yazeed Alharbi,Yaser Alonaizan*

Main category: cs.CV

TL;DR: Isharah是一个大型多场景连续手语识别（CSLR）数据集，首次在非受控环境中收集，包含30,000个视频片段，用于开发鲁棒的CSLR和手语翻译系统。

- Motivation: 现有CSLR数据集在受控环境中收集，限制了其在真实场景中的有效性，Isharah旨在填补这一空白。
- Method: 通过智能手机摄像头在非受控环境中收集数据，提供丰富的语言注释和多场景变化。
- Result: 数据集包含30,000个视频片段，支持多种手语理解基准测试，如独立手语识别和未见句子识别。
- Conclusion: Isharah为开发鲁棒的CSLR和SLT系统提供了重要资源，并推动了真实场景手语识别的研究。


### [57] [Negative-Guided Subject Fidelity Optimization for Zero-Shot Subject-Driven Generation](https://arxiv.org/abs/2506.03621)
*Chaehun Shin,Jooyoung Choi,Johan Barthelemy,Jungbeom Lee,Sungroh Yoon*

Main category: cs.CV

TL;DR: SFO是一种新的比较学习框架，通过引入合成负样本和优化扩散时间步，显著提升了零样本主题驱动生成的主题保真度和文本对齐。

- Motivation: 现有方法仅依赖正样本和预训练阶段的扩散损失，无法有效提升主题保真度。
- Method: SFO通过Condition-Degradation Negative Sampling（CDNS）生成负样本，并通过成对比较优化模型；同时重新加权扩散时间步以关注中间步骤。
- Result: 实验表明，SFO在主题保真度和文本对齐上显著优于基线方法。
- Conclusion: SFO为提升主题驱动生成性能提供了有效解决方案。


### [58] [FingerVeinSyn-5M: A Million-Scale Dataset and Benchmark for Finger Vein Recognition](https://arxiv.org/abs/2506.03635)
*Yinfan Wang,Jie Gui,Baosheng Yu,Qi Li,Zhenan Sun,Juho Kannala,Guoying Zhao*

Main category: cs.CV

TL;DR: 论文提出FVeinSyn合成生成器，创建了包含500万样本的FingerVeinSyn-5M数据集，解决了指静脉识别领域数据不足的问题，显著提升了模型性能。

- Motivation: 指静脉识别领域缺乏大规模公开数据集，现有数据集样本少且变化有限，限制了深度学习方法的发展。
- Method: 使用FVeinSyn生成器合成多样化的指静脉模式，创建包含500万样本的FingerVeinSyn-5M数据集，并支持深度学习应用。
- Result: 在多个基准测试中，使用FingerVeinSyn-5M预训练并微调的模型平均性能提升53.91%。
- Conclusion: FingerVeinSyn-5M填补了数据空白，显著提升了指静脉识别性能，推动了该领域的发展。


### [59] [Spatial Understanding from Videos: Structured Prompts Meet Simulation Data](https://arxiv.org/abs/2506.03642)
*Haoyu Zhang,Meng Liu,Zaijing Li,Haokun Wen,Weili Guan,Yaowei Wang,Liqiang Nie*

Main category: cs.CV

TL;DR: 提出了一种增强预训练视觉语言模型（VLM）3D空间推理能力的统一框架，结合结构化提示策略和自动化构建的数据集。

- Motivation: 现有方法在3D空间推理中存在空间不确定性和数据稀缺问题，限制了VLM的能力。
- Method: 框架包括SpatialMind（结构化提示策略）和ScanForgeQA（自动化构建的数据集），无需修改VLM架构。
- Result: 实验证明提示和微调策略单独及联合有效，为视觉空间理解提供新思路。
- Conclusion: 该框架提升了VLM的3D空间推理能力，并为未来研究提供启发。


### [60] [Images are Worth Variable Length of Representations](https://arxiv.org/abs/2506.03643)
*Lingjun Mao,Rodolfo Corona,Xin Liang,Wenhao Yan,Zineng Tang*

Main category: cs.CV

TL;DR: DOVE是一种动态视觉编码器，根据图像信息量动态生成可变数量的视觉标记，显著减少标记数量同时保持高质量重建，并在多项任务中优于固定长度编码方法。

- Motivation: 现有视觉编码器将图像映射为固定长度的标记序列，忽略了不同图像信息量的差异，导致效率低下。
- Method: 提出DOVE动态视觉编码器，生成可变数量的视觉标记以重建图像，并扩展为查询条件化标记化以聚焦查询相关区域。
- Result: DOVE显著减少平均标记数量且保持高重建质量，在多项任务中优于现有方法，提取更具表达力的语义特征。
- Conclusion: DOVE通过动态标记化和查询条件化，实现了更高效和有针对性的语义提取，优于固定长度编码方法。


### [61] [YOND: Practical Blind Raw Image Denoising Free from Camera-Specific Data Dependency](https://arxiv.org/abs/2506.03645)
*Hansen Feng,Lizhi Wang,Yiqi Huang,Tong Li,Lin Zhu,Hua Huang*

Main category: cs.CV

TL;DR: YOND是一种新型盲原始图像去噪方法，通过合成数据训练，能泛化到未知相机的噪声图像。其核心模块包括CNE、EM-VST和SNR-Net，分别用于噪声估计、消除相机依赖性和可控去噪。

- Motivation: 现有学习去噪方法依赖特定相机数据，泛化能力差。YOND旨在解决这一问题，提供一种实用且泛化能力强的盲去噪方法。
- Method: YOND包含三个模块：CNE用于噪声参数估计，EM-VST消除相机依赖性，SNR-Net实现可控去噪。
- Result: 实验表明，YOND在未知相机数据上表现优异，具有高实用性和灵活性。
- Conclusion: YOND通过创新模块设计，解决了盲去噪的泛化问题，为实际应用提供了有效解决方案。


### [62] [EmoArt: A Multidimensional Dataset for Emotion-Aware Artistic Generation](https://arxiv.org/abs/2506.03652)
*Cheng Zhang,Hongxia xie,Bin Wen,Songhan Zuo,Ruoxuan Zhang,Wen-huang Cheng*

Main category: cs.CV

TL;DR: 论文提出了EmoArt数据集，用于解决情感表达和抽象艺术图像生成的挑战，并评估了现有文本到图像扩散模型的情感对齐能力。

- Motivation: 当前文本到图像生成模型在情感表达和抽象艺术图像生成方面存在不足，主要原因是缺乏大规模、细粒度的情感数据集。
- Method: 构建了EmoArt数据集，包含132,664件艺术品，涵盖56种绘画风格，每张图像有结构化标注（如情感类别、视觉属性等），并评估了流行扩散模型的情感对齐能力。
- Result: EmoArt数据集为情感驱动的图像合成提供了重要数据和基准，推动了情感计算、多模态学习和计算艺术的发展。
- Conclusion: EmoArt数据集填补了情感数据集的空白，为艺术治疗和创意设计等应用提供了支持。


### [63] [MambaNeXt-YOLO: A Hybrid State Space Model for Real-time Object Detection](https://arxiv.org/abs/2506.03654)
*Xiaochun Lei,Siqi Wu,Weilin Wu,Zetao Jiang*

Main category: cs.CV

TL;DR: MambaNeXt-YOLO是一种新型目标检测框架，结合CNN与Mamba模型，平衡精度与效率，适用于边缘设备。

- Motivation: 实时目标检测在计算资源有限时具有挑战性，现有Transformer架构计算复杂度高，Mamba模型提供了线性复杂度的替代方案。
- Method: 提出MambaNeXt Block（CNN与Mamba混合设计）、MAFPN（多尺度特征融合）和边缘优化，实现高效检测。
- Result: 在PASCAL VOC数据集上达到66.6% mAP和31.9 FPS，支持边缘设备部署。
- Conclusion: MambaNeXt-YOLO通过混合设计和优化，有效平衡了实时目标检测的精度与效率。


### [64] [INP-Former++: Advancing Universal Anomaly Detection via Intrinsic Normal Prototypes and Residual Learning](https://arxiv.org/abs/2506.03660)
*Wei Luo,Haiming Yao,Yunkang Cao,Qiyu Chen,Ang Gao,Weiming Shen,Weihang Zhang,Wenyong Yu*

Main category: cs.CV

TL;DR: INP-Former是一种新颖的异常检测方法，通过从测试图像中提取内在正常原型（INPs），避免依赖外部训练集，显著提升了检测精度，并在多种任务中表现优异。

- Motivation: 现有异常检测方法依赖训练集中的正常参考图像，但图像外观和位置的差异导致对齐困难，限制了检测精度。作者观察到异常通常表现为局部变化，测试图像中仍包含有价值的正常信息，可用于更准确的检测。
- Method: 提出INP-Former，包括INP提取器和INP一致性损失，直接从测试图像中提取INPs，并通过INP引导的解码器重构正常区域，以重建误差作为异常分数。还提出软挖掘损失优化训练样本。
- Result: INP-Former在单类、多类和少样本异常检测任务中达到最先进性能，并在MVTec-AD、VisA和Real-IAD数据集上验证了其通用性。INP-Former++进一步提升了性能。
- Conclusion: INP-Former是一种通用且高效的异常检测方法，通过利用测试图像中的内在正常信息，显著提升了检测性能，并展示了零样本检测潜力。


### [65] [Zero-Shot Temporal Interaction Localization for Egocentric Videos](https://arxiv.org/abs/2506.03662)
*Erhang Zhang,Junyi Ma,Yin-Dong Zheng,Yixuan Zhou,Hesheng Wang*

Main category: cs.CV

TL;DR: 论文提出了一种名为EgoLoc的零样本时序交互定位方法，用于在自我中心视频中定位人-物交互的抓取动作时间。通过自适应采样策略和闭环反馈，显著提高了定位精度和效率。

- Motivation: 当前时序动作定位方法依赖标注数据，导致领域偏差和部署效率低。现有零样本方法虽利用视觉语言模型，但粗粒度估计和开环流程限制了性能提升。
- Method: EgoLoc采用自适应采样策略生成视觉提示，结合2D和3D观测，根据3D手部速度采样高质量初始猜测，并通过闭环反馈优化结果。
- Result: 在公开数据集和新基准测试中，EgoLoc优于现有基线方法，实现了更高的时序交互定位精度。
- Conclusion: EgoLoc通过创新方法解决了零样本时序交互定位的挑战，为相关下游任务提供了高效解决方案。


### [66] [Intersectional Bias in Pre-Trained Image Recognition Models](https://arxiv.org/abs/2506.03664)
*Valerie Krug,Sebastian Stober*

Main category: cs.CV

TL;DR: 研究探讨了ImageNet分类器在面部图像中对年龄、种族和性别等敏感变量的偏见，发现模型对年龄区分明显，对种族和性别的区分较弱。

- Motivation: 深度学习模型常基于预训练模型加速训练，但可能延续编码偏见，因此研究ImageNet分类器在面部图像中的偏见。
- Method: 使用线性分类器探针和地形图可视化激活，评估模型对年龄、种族和性别的区分能力。
- Result: 模型对年龄区分显著，对种族和性别的区分较弱，尤其在中年群体中。
- Conclusion: ImageNet分类器在面部图像中存在偏见，需进一步关注模型公平性。


### [67] [Accelerating SfM-based Pose Estimation with Dominating Set](https://arxiv.org/abs/2506.03667)
*Joji Joseph,Bharadwaj Amrutur,Shalabh Bhatnagar*

Main category: cs.CV

TL;DR: 提出了一种基于图论支配集的预处理技术，显著提升SfM姿态估计速度，同时保持高精度。

- Motivation: 解决实时应用（如AR、VR和机器人）中SfM姿态估计的速度问题。
- Method: 利用图论中的支配集概念预处理SfM模型。
- Result: 处理速度提升1.5-14.48倍，参考图像和点云大小分别减少17-23倍和2.27-4倍。
- Conclusion: 该方法在速度和精度之间取得平衡，为实时3D姿态估计提供了高效解决方案。


### [68] [BiXFormer: A Robust Framework for Maximizing Modality Effectiveness in Multi-Modal Semantic Segmentation](https://arxiv.org/abs/2506.03675)
*Jialei Chen,Xu Zheng,Danda Pani Paudel,Luc Van Gool,Hiroshi Murase,Daisuke Deguchi*

Main category: cs.CV

TL;DR: 论文提出BiXFormer，通过统一模态匹配（UMM）和跨模态对齐（CMA）优化多模态语义分割，提升模态利用效率并处理缺失模态问题。

- Motivation: 现有方法在融合多模态特征时限制了各模态的优势发挥，且难以处理模态缺失情况。
- Method: BiXFormer将多模态输入分为RGB和非RGB（X），分别处理，并提出UMM（含MAM和CM）和CMA，以最大化模态效果。
- Result: 在合成和真实多模态基准测试中，mIoU分别提升2.75%和22.74%。
- Conclusion: BiXFormer通过UMM和CMA有效提升多模态语义分割性能，尤其在模态缺失情况下表现优异。


### [69] [How PARTs assemble into wholes: Learning the relative composition of images](https://arxiv.org/abs/2506.03682)
*Melika Ayoughi,Samira Abnar,Chen Huang,Chris Sandino,Sayeri Lala,Eeshan Gunesh Dhekane,Dan Busbridge,Shuangfei Zhai,Vimal Thilak,Josh Susskind,Pascal Mettes,Paul Groth,Hanlin Goh*

Main category: cs.CV

TL;DR: PART是一种自监督学习方法，通过连续相对变换学习图像部分的相对组合，优于基于网格的方法。

- Motivation: 现有基于网格的方法无法捕捉真实世界物体组合的连续性和流动性，限制了表示学习的效果。
- Method: PART利用连续空间中非网格补丁的相对变换，建模部分之间的关系，实现更灵活的结构学习。
- Result: 在需要精确空间理解的任务（如目标检测和时间序列预测）中，PART优于MAE和DropPos等网格方法，同时在全局分类任务中表现竞争性。
- Conclusion: PART突破了网格限制，为跨数据类型的通用自监督预训练提供了新方向，具有广泛的应用潜力。


### [70] [PRJ: Perception-Retrieval-Judgement for Generated Images](https://arxiv.org/abs/2506.03683)
*Qiang Fu,Zonglei Jing,Zonghao Ying,Xiaoqian Li*

Main category: cs.CV

TL;DR: 论文提出了一种名为PRJ的框架，通过感知-检索-判断的三阶段设计，改进AI生成视觉内容的安全性检测，提升了解释性和检测准确性。

- Motivation: 生成式AI的快速发展带来了视觉内容的安全隐患，现有系统缺乏上下文理解和动态评估能力。
- Method: PRJ框架通过语言描述、外部知识检索和规则评估三阶段，检测显性和隐性危害。
- Result: 实验表明PRJ在检测准确性和鲁棒性上优于现有系统，并支持结构化毒性解释。
- Conclusion: PRJ为AI生成内容的安全检测提供了一种更灵活、可解释的解决方案。


### [71] [DSSAU-Net:U-Shaped Hybrid Network for Pubic Symphysis and Fetal Head Segmentation](https://arxiv.org/abs/2506.03684)
*Zunhui Xia,Hongxing Li,Libin Lan*

Main category: cs.CV

TL;DR: 提出了一种名为DSSAU-Net的稀疏自注意力网络架构，用于胎儿头部和耻骨联合的准确分割，以提高分娩过程中的诊断准确性。

- Motivation: 传统分娩诊断方法主观且不准确，超声辅助诊断通过客观参数（AoP和HSD）提供更可靠的评估，但需要精确的分割技术。
- Method: 设计了DSSAU-Net，采用对称U形编码器-解码器架构，结合双稀疏选择注意力块（DSSA）和多尺度特征融合，减少计算复杂度并提升特征提取效率。
- Result: 在MICCAI IUGC 2024竞赛中，DSSAU-Net在分类和分割任务中排名第四，验证了其有效性。
- Conclusion: DSSAU-Net是一种高效且性能优越的分割方法，适用于分娩过程中的超声诊断。


### [72] [Advancements in Artificial Intelligence Applications for Cardiovascular Disease Research](https://arxiv.org/abs/2506.03698)
*Yuanlin Mo,Haishan Huang,Bocheng Liang,Weibo Ma*

Main category: cs.CV

TL;DR: AI在心血管医学中的革命性进展，通过深度学习提升诊断精度和工作效率，但仍需解决数据验证问题。

- Motivation: 探讨AI在心血管医学中的应用潜力及其挑战，推动精准诊断发展。
- Method: 利用卷积神经网络和生成对抗网络等深度学习架构，自动化分析医学影像和生理信号。
- Result: AI在诊断准确性和效率上超越人类，但数据验证问题可能导致诊断错误。
- Conclusion: 未来需开发混合模型和自适应算法，结合多模态数据，提升个性化心血管护理的可靠性。


### [73] [OV-COAST: Cost Aggregation with Optimal Transport for Open-Vocabulary Semantic Segmentation](https://arxiv.org/abs/2506.03706)
*Aditya Gandhamal,Aniruddh Sikdar,Suresh Sundaram*

Main category: cs.CV

TL;DR: 论文提出了一种基于最优传输理论的开集语义分割方法OV-COAST，通过两阶段优化策略提升模型性能。

- Motivation: 提升开集语义分割（OVSS）的跨域泛化能力。
- Method: 使用成本体积构建成本矩阵，通过Sinkhorn距离解决最优传输问题，并指导CAT-Seg模型训练。
- Result: 在MESS基准测试中，OV-COAST显著优于CAT-Seg和SAN-B，分别提升1.72%和4.9% mIoU。
- Conclusion: OV-COAST通过最优传输理论有效提升了开集语义分割的性能。


### [74] [AetherVision-Bench: An Open-Vocabulary RGB-Infrared Benchmark for Multi-Angle Segmentation across Aerial and Ground Perspectives](https://arxiv.org/abs/2506.03709)
*Aniruddh Sikdar,Aditya Gandhamal,Suresh Sundaram*

Main category: cs.CV

TL;DR: 论文提出了AetherVision-Bench基准，用于评估多视角语义分割模型的性能，并分析了零样本迁移模型的关键影响因素。

- Motivation: 开放词汇语义分割（OVSS）在实际应用中面临跨域泛化的挑战，限制了其有效性。
- Method: 通过创建AetherVision-Bench基准，评估不同视角和传感器模态下的OVSS模型性能，并分析零样本迁移的关键因素。
- Result: 研究提供了对零样本迁移模型性能的深入分析，并建立了鲁棒性基准。
- Conclusion: 该工作为未来研究提供了基础，并揭示了提升OVSS模型性能的关键方向。


### [75] [OSGNet @ Ego4D Episodic Memory Challenge 2025](https://arxiv.org/abs/2506.03710)
*Yisen Feng,Haoyu Zhang,Qiaohui Chu,Meng Liu,Weili Guan,Yaowei Wang,Liqiang Nie*

Main category: cs.CV

TL;DR: 本文介绍了在CVPR 2025 Ego4D挑战赛中，针对三个自我中心视频定位任务的冠军解决方案，采用早期融合策略提升定位精度。

- Motivation: 现有统一视频定位方法多依赖后期融合策略，效果不佳，需改进。
- Method: 采用早期融合的视频定位模型处理三项任务。
- Result: 在自然语言查询、目标步骤和时刻查询三个赛道中均获得第一名。
- Conclusion: 早期融合策略有效提升了视频定位的准确性。


### [76] [PlückeRF: A Line-based 3D Representation for Few-view Reconstruction](https://arxiv.org/abs/2506.03713)
*Sam Bahrami,Dylan Campbell*

Main category: cs.CV

TL;DR: 本文提出了一种基于多视角信息的3D重建模型，通过改进3D表示方法（PlückeRF），显著提升了重建质量。

- Motivation: 现有单视角和少视角3D重建方法在利用多视角信息方面仍有提升空间。
- Method: 提出一种新机制，将3D表示与输入视角的像素射线连接，优先共享邻近3D位置和像素射线的信息，采用PlückeRF表示。
- Result: 相比现有的三平面表示和前沿前馈重建方法，重建质量有所提升。
- Conclusion: PlückeRF表示在多视角3D重建中具有优势，为未来研究提供了新方向。


### [77] [FSHNet: Fully Sparse Hybrid Network for 3D Object Detection](https://arxiv.org/abs/2506.03714)
*Shuai Liu,Mingyue Cui,Boyang Li,Quanmin Liang,Tinghe Hong,Kai Huang,Yunxiao Shan,Kai Huang*

Main category: cs.CV

TL;DR: FSHNet提出了一种全稀疏混合网络，通过SlotFormer块增强长程特征提取能力，动态稀疏标签分配策略优化网络，稀疏上采样模块保留细节，显著提升3D检测性能。

- Motivation: 稀疏3D检测器仅从非空体素提取特征，导致长程交互能力弱和中心特征缺失，影响特征提取和网络优化。
- Method: 引入SlotFormer块增强稀疏编码器的长程特征提取能力，采用动态稀疏标签分配策略优化网络，并设计稀疏上采样模块保留细节。
- Result: 在Waymo、nuScenes和Argoverse2基准测试中表现优异。
- Conclusion: FSHNet通过改进特征提取和网络优化，显著提升了全稀疏3D检测器的性能。


### [78] [ComRoPE: Scalable and Robust Rotary Position Embedding Parameterized by Trainable Commuting Angle Matrices](https://arxiv.org/abs/2506.03737)
*Hao Yu,Tangyu Jiang,Shuning Jia,Shannan Yan,Shunning Liu,Haolong Qian,Guanghao Li,Shuting Dong,Huaisong Zhang,Chun Yuan*

Main category: cs.CV

TL;DR: ComRoPE提出了一种可训练的旋转角度矩阵方法，改进了传统的RoPE，提升了模型的性能和灵活性。

- Motivation: 传统的位置编码方法（如RoPE）因旋转矩阵的固定性和有限性限制了模型能力，需要更灵活和可训练的解决方案。
- Method: 通过定义可训练的交换角度矩阵，ComRoPE扩展了RoPE，确保位置偏移的一致性和鲁棒性。
- Result: 在ImageNet-1K数据集上，ComRoPE在训练分辨率和高分辨率下分别比现有方法提升了1.6%和2.9%。
- Conclusion: ComRoPE不仅改进了RoPE，还为未来位置编码研究提供了新的思路和框架。


### [79] [SAAT: Synergistic Alternating Aggregation Transformer for Image Super-Resolution](https://arxiv.org/abs/2506.03740)
*Jianfeng Wu,Nannan Xu*

Main category: cs.CV

TL;DR: 论文提出了一种新型模型SAAT，通过结合通道和空间注意力机制，提升了单图像超分辨率任务的性能。

- Motivation: 当前基于Transformer的超分辨率方法在计算自注意力时忽略了跨通道和中间过程的空间结构信息，而通道和空间注意力的协同关系尚未充分探索。
- Method: 提出SAAT模型，包含CWSAG（高效通道与窗口协同注意力组）和SWSAG（空间与窗口协同注意力组），分别增强非局部特征融合和结构特征提取。
- Result: SAAT在超分辨率任务中表现优异，性能与现有SOTA模型相当。
- Conclusion: SAAT通过协同注意力机制有效利用了特征信息，为超分辨率任务提供了新思路。


### [80] [HUMOF: Human Motion Forecasting in Interactive Social Scenes](https://arxiv.org/abs/2506.03753)
*Caiyi Sun,Yujing Sun,Xiao Han,Zemin Yang,Jiawei Liu,Xinge Zhu,Siu Ming Yiu,Yuexin Ma*

Main category: cs.CV

TL;DR: 提出了一种用于复杂交互场景中人体运动预测的分层特征表示和粗到细的推理模块，显著提升了预测准确性。

- Motivation: 复杂场景中的人体行为预测因交互信息丰富而具有挑战性，现有方法难以应对。
- Method: 设计了分层交互特征表示，结合粗到细的交互推理模块，从空间和频率角度利用特征。
- Result: 在四个公开数据集上实现了最先进的性能。
- Conclusion: 该方法有效提升了复杂交互场景中的人体运动预测准确性。


### [81] [CoLa: Chinese Character Decomposition with Compositional Latent Components](https://arxiv.org/abs/2506.03798)
*Fan Shi,Haiyang Yu,Bin Li,Xiangyang Xue*

Main category: cs.CV

TL;DR: 论文提出了一种名为CoLa的深度潜在变量模型，通过学习汉字的分层潜在组件，无需依赖人工定义的分解方案，实现了零样本汉字识别。

- Motivation: 汉字识别中的零样本问题源于数据的长尾分布，现有方法依赖人工定义的分解方案，忽略了学习能力。论文受组合性和学习能力的启发，提出新方法。
- Method: 采用深度潜在变量模型（CoLa），学习汉字的组合潜在组件，并在潜在空间中进行识别和匹配。
- Result: CoLa在零样本汉字识别中优于现有方法，且学习到的组件具有可解释性，还能跨数据集泛化。
- Conclusion: CoLa通过组合性和学习能力解决了零样本汉字识别问题，展示了高效泛化和跨数据集能力。


### [82] [ConText: Driving In-context Learning for Text Removal and Segmentation](https://arxiv.org/abs/2506.03799)
*Fei Zhang,Pei Zhang,Baosong Yang,Fei Huang,Yanfeng Wang,Ya Zhang*

Main category: cs.CV

TL;DR: 本文首次将视觉上下文学习（V-ICL）范式应用于光学字符识别任务，提出任务链式组合器和上下文感知聚合方法，显著提升了模型性能。

- Motivation: 现有V-ICL方法采用直接提示的单步推理方式，限制了模型性能。本文旨在通过任务链式组合器和上下文感知聚合，增强模型的上下文推理能力。
- Method: 提出任务链式组合器（image-removal-segmentation）和上下文感知聚合方法，并结合自提示策略解决视觉异质性问题。
- Result: ConText模型在领域内和领域外基准测试中均达到最新最优性能。
- Conclusion: 通过任务链式组合器和上下文感知聚合，显著提升了视觉上下文学习在字符识别任务中的表现。


### [83] [Animal Pose Labeling Using General-Purpose Point Trackers](https://arxiv.org/abs/2506.03868)
*Zhuoyang Pan,Boxiao Pan,Guandao Yang,Adam W. Harley,Leonidas Guibas*

Main category: cs.CV

TL;DR: 提出一种基于测试时优化的动物姿态标注方法，通过微调预训练模型在稀疏标注帧上，实现高效自动标注。

- Motivation: 现有方法因训练数据集不足，难以全面捕捉动物行为，而收集全面数据集又因动物形态多样性而困难。
- Method: 在稀疏标注帧上微调预训练的通用点跟踪器，生成轻量级外观嵌入，用于自动标注其余帧。
- Result: 方法以合理标注成本达到最优性能。
- Conclusion: 该流程为动物行为自动量化提供了实用工具。


### [84] [JointSplat: Probabilistic Joint Flow-Depth Optimization for Sparse-View Gaussian Splatting](https://arxiv.org/abs/2506.03872)
*Yang Xiao,Guoan Xu,Qiang Wu,Wenjing Jia*

Main category: cs.CV

TL;DR: JointSplat提出了一种联合光流和深度的概率优化框架，解决了稀疏视角3D重建中的几何不一致和噪声问题。

- Motivation: 稀疏视角3D重建存在几何不一致和噪声问题，传统方法在低纹理或重复区域表现不佳。
- Method: 通过概率优化机制联合光流和深度信息，并提出多视角深度一致性损失。
- Result: 在RealEstate10K和ACID数据集上表现优于现有方法。
- Conclusion: JointSplat框架有效提升了稀疏视角3D重建的精度和鲁棒性。


### [85] [Video, How Do Your Tokens Merge?](https://arxiv.org/abs/2506.03885)
*Sam Pollard,Michael Wray*

Main category: cs.CV

TL;DR: 视频Transformer模型因输入时空扩展需大量计算资源。本文探讨无需训练的token合并方法，在复杂视频数据集上验证其效果，实现约2.5倍加速且精度损失小。

- Motivation: 视频Transformer计算成本高，现有方法多针对图像模型，视频领域尚未充分验证。
- Method: 提出无需训练的token合并方法，适用于多种视频Transformer，并在多数据集上测试。
- Result: 实现约2.5倍加速，精度损失平均仅-0.55%（ViViT）。
- Conclusion: 视频token合并高效且通用，显著降低计算成本，几乎不影响精度。


### [86] [Joint Video Enhancement with Deblurring, Super-Resolution, and Frame Interpolation Network](https://arxiv.org/abs/2506.03892)
*Giyong Choi,HyunWook Park*

Main category: cs.CV

TL;DR: 提出了一种联合视频增强方法DSFN，同时解决多种视频降质问题，优于现有顺序处理方法。

- Motivation: 视频质量常受多种因素共同影响，现有顺序处理方法效率低且效果不佳。
- Method: 设计DSFN网络，包含联合去模糊和超分辨率模块（JDSR）及三帧插值模块（TFBFI），直接生成高质量视频。
- Result: 在公共数据集上表现优于现有技术，网络更小且处理更快。
- Conclusion: DSFN是一种高效且性能优越的联合视频增强方法。


### [87] [Learning from Noise: Enhancing DNNs for Event-Based Vision through Controlled Noise Injection](https://arxiv.org/abs/2506.03918)
*Marcin Kowalczyk,Kamil Jeziorek,Tomasz Kryjak*

Main category: cs.CV

TL;DR: 提出了一种新的噪声注入训练方法，提升神经网络对事件噪声的鲁棒性，优于传统滤波方法。

- Motivation: 事件数据常受噪声影响，传统滤波方法可能丢失有用信息，需要更鲁棒的解决方案。
- Method: 在训练数据中直接注入可控噪声，使模型学习抗噪声表示。
- Result: 在多个数据集和网络架构上验证，性能稳定且优于滤波方法，分类准确率最高。
- Conclusion: 噪声注入训练是事件数据分类系统中传统滤波方法的可行替代方案。


### [88] [Multiple Stochastic Prompt Tuning for Practical Cross-Domain Few Shot Learning](https://arxiv.org/abs/2506.03926)
*Debarshi Brahma,Soma Biswas*

Main category: cs.CV

TL;DR: 提出了一种实用的跨域少样本学习任务pCDFSL，利用大模型CLIP在目标数据集上分类未见类别，仅需少量标注样本。

- Motivation: 现有CDFSL框架依赖人工设计的训练和测试模式，pCDFSL更贴近实际应用，更具挑战性。
- Method: 提出MIST框架，通过多个随机提示处理域和语义偏移，将提示权重建模为高斯分布以减少过拟合。
- Result: 在四个CDFSL基准测试中，MIST框架表现优于现有方法。
- Conclusion: MIST框架在跨域少样本学习中有效，适用于实际场景。


### [89] [Vision Remember: Alleviating Visual Forgetting in Efficient MLLM with Vision Feature Resample](https://arxiv.org/abs/2506.03928)
*Ze Feng,Jiang-Jiang Liu,Sen Yang,Lingyu Xiao,Xiaofan Li,Wankou Yang,Jingdong Wang*

Main category: cs.CV

TL;DR: 提出Vision Remember方法，通过在LLM解码层间插入模块，保留多级视觉特征并重新采样，提升视觉任务性能。

- Motivation: 解决现有视觉投影器中压缩视觉标记导致信息丢失的问题，尤其是对OCR和图表理解等依赖细粒度空间关系的任务。
- Method: 在LLM解码层间插入Vision Remember模块，保留多级视觉特征并通过局部注意力重新采样，增强细粒度信息。
- Result: 在多个视觉理解基准测试中验证了方法的有效性，LLaVA-VR仅2B参数即优于更大模型。
- Conclusion: Vision Remember在不牺牲效率的情况下提升了性能，适用于多种高效视觉投影器。


### [90] [DiffCAP: Diffusion-based Cumulative Adversarial Purification for Vision Language Models](https://arxiv.org/abs/2506.03933)
*Jia Fu,Yongtao Wu,Yihang Chen,Kunyu Peng,Xiao Zhang,Volkan Cevher,Sepideh Pashami,Anders Holst*

Main category: cs.CV

TL;DR: DiffCAP是一种基于扩散的净化策略，能有效中和视觉语言模型（VLMs）中的对抗性扰动，显著提升模型在对抗环境中的可靠性。

- Motivation: VLMs在多模态理解中表现出色，但对扰动的敏感性威胁其实际应用的可靠性。对抗性扰动虽对人眼不可见，却会显著改变模型输出，导致错误决策。
- Method: DiffCAP通过逐步注入高斯噪声至对抗性扰动数据，直到连续噪声图像的嵌入达到预设相似度阈值，再用预训练扩散模型去噪，恢复干净表示。
- Result: 在六大数据集、三种VLMs和多种攻击强度下的实验中，DiffCAP显著优于现有防御技术，同时降低了超参数调优复杂度和去噪时间。
- Conclusion: DiffCAP为对抗环境中安全部署VLMs提供了高效、稳健的解决方案，兼具理论和实证支持。


### [91] [Average Calibration Losses for Reliable Uncertainty in Medical Image Segmentation](https://arxiv.org/abs/2506.03942)
*Theodore Barfoot,Luis C. Garcia-Peraza-Herrera,Samet Akcay,Ben Glocker,Tom Vercauteren*

Main category: cs.CV

TL;DR: 论文提出了一种可微分的mL1-ACE损失函数，用于改善医学图像分割的校准性能，实验表明其显著降低了校准误差，同时保持了分割性能。

- Motivation: 医学图像分割中深度神经网络的过度自信问题影响了其可靠性和临床实用性，因此需要改进校准性能。
- Method: 提出了硬分箱和软分箱的mL1-ACE损失函数，并在四个数据集上进行了实验验证。
- Result: 软分箱mL1-ACE显著改善了校准性能，但可能影响分割性能；硬分箱mL1-ACE保持了分割性能，但校准改进较弱。
- Conclusion: 该方法提高了分割预测的可信度，有助于深度学习在临床工作流程中的安全应用。


### [92] [MS-YOLO: A Multi-Scale Model for Accurate and Efficient Blood Cell Detection](https://arxiv.org/abs/2506.03972)
*Guohua Wu,Shengqi Chen,Pengchao Deng,Wenting Yu*

Main category: cs.CV

TL;DR: MS-YOLO是一种基于YOLOv11的血液细胞检测模型，通过多尺度扩张残差模块、动态跨路径特征增强模块和轻量自适应权重下采样模块提升检测性能，在CBC基准测试中表现优异，mAP@50达97.4%。

- Motivation: 传统手动显微镜方法效率低且准确性不足，现有自动化方法成本高且精度欠佳，深度学习在检测重叠细胞和多尺度目标方面仍有挑战。
- Method: 提出MS-YOLO模型，包含多尺度扩张残差模块（MS-DRM）、动态跨路径特征增强模块（DCFEM）和轻量自适应权重下采样模块（LADS）。
- Result: 在CBC基准测试中mAP@50达97.4%，在WBCDD数据集上验证了泛化能力，且具备轻量级架构和实时推理效率。
- Conclusion: MS-YOLO满足临床部署需求，为标准化血液病理评估提供可靠技术支持。


### [93] [RAID: A Dataset for Testing the Adversarial Robustness of AI-Generated Image Detectors](https://arxiv.org/abs/2506.03988)
*Hicham Eddoubi,Jonas Ricker,Federico Cocchi,Lorenzo Baraldi,Angelo Sotgiu,Maura Pintor,Marcella Cornia,Lorenzo Baraldi,Asja Fischer,Rita Cucchiara,Battista Biggio*

Main category: cs.CV

TL;DR: 论文提出了一种评估AI生成图像检测器鲁棒性的方法RAID，通过生成对抗样本揭示现有检测器的脆弱性。

- Motivation: AI生成图像的质量已高到人类难以区分真伪，检测其真实性成为迫切需求，但现有方法在对抗条件下的鲁棒性常被忽视。
- Method: 提出RAID数据集，包含72k对抗样本，通过攻击7种先进检测器和4种文本生成图像模型生成。
- Result: 实验表明，RAID生成的对抗样本能高效欺骗未见过的新检测器，揭示现有检测器易受攻击。
- Conclusion: 现有AI生成图像检测器鲁棒性不足，需开发更稳健的方法。数据集和代码已开源。


### [94] [Vocabulary-free few-shot learning for Vision-Language Models](https://arxiv.org/abs/2506.04005)
*Maxime Zanella,Clément Fuchs,Ismail Ben Ayed,Christophe De Vleeschouwer*

Main category: cs.CV

TL;DR: 论文提出了一种无需词汇表的少样本学习方法（SiM），通过相似性映射分类目标实例，无需精心设计的提示。

- Motivation: 现有方法依赖预定义的类别名称，限制了适用性，尤其是在类别名称不可用或难以指定的场景。
- Method: 提出Similarity Mapping（SiM），基于通用提示（文本或视觉）的相似性分数分类目标实例。
- Result: SiM表现优异，计算高效（学习映射通常不到一秒），且具有可解释性。
- Conclusion: SiM为无需词汇表的少样本学习提供了重要基线，未来研究可基于此展开。


### [95] [Rex-Thinker: Grounded Object Referring via Chain-of-Thought Reasoning](https://arxiv.org/abs/2506.04034)
*Qing Jiang,Xingyu Chen,Zhaoyang Zeng,Junzhi Yu,Lei Zhang*

Main category: cs.CV

TL;DR: Rex-Thinker将目标引用任务建模为显式的思维链推理任务，通过分步验证候选对象是否匹配描述，提升模型的解释性和可信度。

- Motivation: 现有方法将目标引用视为直接预测边界框的任务，缺乏解释性且难以拒绝无匹配对象的描述。
- Method: 提出Rex-Thinker模型，分阶段验证候选对象，并构建HumanRef-CoT数据集支持推理。训练包括监督微调和GRPO强化学习。
- Result: 在域内评估中表现优于基线，同时提升了拒绝幻觉输出的能力和域外泛化性。
- Conclusion: Rex-Thinker通过显式推理和结构化训练，显著提升了目标引用任务的解释性和性能。


### [96] [Mitigating Hallucinations in Large Vision-Language Models via Entity-Centric Multimodal Preference Optimization](https://arxiv.org/abs/2506.04039)
*Jiulong Wu,Zhengliang Shi,Shuaiqiang Wang,Jizhou Huang,Dawei Yin,Lingyong Yan,Min Cao,Min Zhang*

Main category: cs.CV

TL;DR: 论文提出Entity-centric Multimodal Preference Optimization (EMPO)，通过增强模态对齐减少大型视觉语言模型（LVLM）的幻觉问题，并在实验中显著降低了幻觉率。

- Motivation: 大型视觉语言模型（LVLM）在多任务中表现优异，但其可信度常因幻觉问题受到质疑，主要源于模态不对齐和底层大型语言模型（LLM）的固有幻觉。现有偏好对齐方法忽视图像-文本模态对齐，导致对LLM的过度依赖和幻觉。
- Method: 提出EMPO方法，通过自动构建高质量多模态偏好数据（涵盖图像、指令和响应三方面），增强模态对齐。
- Result: 在两个人类偏好数据集和五个多模态幻觉基准测试中，EMPO显著降低幻觉率（如Object-HalBench降低85.9%，MM-HalBench降低49.8%）。
- Conclusion: EMPO通过改进模态对齐，有效减少LVLM的幻觉问题，为多模态模型的可信度提供了新解决方案。


### [97] [EV-Flying: an Event-based Dataset for In-The-Wild Recognition of Flying Objects](https://arxiv.org/abs/2506.04048)
*Gabriele Magrini,Federico Becattini,Giovanni Colombo,Pietro Pala*

Main category: cs.CV

TL;DR: 论文提出了一种基于事件相机的飞行物体检测与识别方法，解决了传统RGB方法的局限性，并发布了EV-Flying数据集。

- Motivation: 传统RGB方法在检测飞行物体时面临尺度变化、运动模糊和高速运动等挑战，尤其是对昆虫和无人机等小物体。事件相机因其高时间分辨率和抗运动模糊特性，成为更优选择。
- Method: 使用事件相机采集数据，构建EV-Flying数据集，并采用基于PointNet的轻量级点云处理方法处理异步事件流。
- Result: 提出了EV-Flying数据集和点云事件表示方法，为飞行物体分类提供了高效可靠的解决方案。
- Conclusion: 该方法为现实场景中的飞行物体识别提供了更高效和可靠的途径。


### [98] [Video Deblurring with Deconvolution and Aggregation Networks](https://arxiv.org/abs/2506.04054)
*Giyong Choi,HyunWook Park*

Main category: cs.CV

TL;DR: 本文提出了一种用于视频去模糊的解卷积和聚合网络（DAN），通过三个子网络有效利用相邻帧信息，显著提升了性能。

- Motivation: 现有视频去模糊算法未能充分利用相邻帧信息，导致性能不佳。
- Method: DAN包含预处理网络（PPN）、基于对齐的解卷积网络（ABDN）和帧聚合网络（FAN），分别负责预处理、解卷积和聚合。
- Result: 实验表明，DAN在公开数据集上定量和定性评估均优于现有方法。
- Conclusion: DAN通过合理结合三个子网络，有效利用相邻帧信息，实现了优越的视频去模糊性能。


### [99] [Point Cloud Quality Assessment Using the Perceptual Clustering Weighted Graph (PCW-Graph) and Attention Fusion Network](https://arxiv.org/abs/2506.04081)
*Abdelouahed Laazoufi,Mohammed El Hassouni,Hocine Cherifi*

Main category: cs.CV

TL;DR: NR-PCQA方法用于评估无参考模型的3D内容质量。

- Motivation: 在现实应用中，参考模型往往不可用，因此需要无参考的3D内容质量评估方法。
- Method: 未提及具体方法。
- Result: 未提及具体结果。
- Conclusion: NR-PCQA对于无参考模型的3D内容质量评估至关重要。


### [100] [GlobalBuildingAtlas: An Open Global and Complete Dataset of Building Polygons, Heights and LoD1 3D Models](https://arxiv.org/abs/2506.04106)
*Xiao Xiang Zhu,Sining Chen,Fahong Zhang,Yilei Shi,Yuanyuan Wang*

Main category: cs.CV

TL;DR: GlobalBuildingAtlas是一个公开数据集，提供全球建筑多边形、高度和LoD1 3D模型，覆盖全面且质量高。

- Motivation: 填补全球高质量建筑数据的空白，支持高分辨率的建筑分析。
- Method: 利用机器学习从卫星数据提取建筑多边形和高度，并通过质量融合策略优化数据。
- Result: 数据集包含27.5亿建筑，高度分辨率达3x3米，LoD1模型覆盖97%建筑。
- Conclusion: GlobalBuildingAtlas为全球建筑分析提供新视角，支持可持续发展目标监测。


### [101] [Multi-view Surface Reconstruction Using Normal and Reflectance Cues](https://arxiv.org/abs/2506.04115)
*Robin Bruneau,Baptiste Brument,Yvain Quéau,Jean Mélou,François Bernard Lauze,Jean-Denis Durou,Lilian Calvet*

Main category: cs.CV

TL;DR: 提出了一种结合多视角法线和反射率图的框架，用于高保真3D表面重建，特别适用于复杂反射材料和稀疏视角场景。

- Motivation: 在复杂反射材料和稀疏视角条件下，实现高保真3D表面重建并保留细节仍具挑战性。
- Method: 采用像素级联合重参数化反射率和表面法线，将其表示为模拟光照下的辐射向量，并兼容传统和现代重建框架。
- Result: 在多个基准数据集上达到最优性能，尤其在细节重建和复杂可见性条件下表现突出。
- Conclusion: 该方法扩展了先前会议论文，提供了更快速、更鲁棒的算法和更广泛的实验评估。


### [102] [Contour Errors: An Ego-Centric Metric for Reliable 3D Multi-Object Tracking](https://arxiv.org/abs/2506.04122)
*Sharang Kaul,Mario Berk,Thiemo Gerbich,Abhinav Valada*

Main category: cs.CV

TL;DR: 论文提出了一种新的匹配度量方法Contour Errors（CEs），用于提升3D场景中多目标跟踪的可靠性，相比传统2D指标（如IoU和CPD），显著减少了功能失败率。

- Motivation: 在自动驾驶等安全关键应用中，传统2D匹配指标（如IoU和CPD）在复杂3D场景中表现不佳，导致感知错误。因此，需要一种更功能相关的度量方法来提升匹配可靠性。
- Method: 提出了一种基于车辆或目标中心视角的Contour Errors（CEs）度量方法，通过比较边界框在车辆坐标系中的轮廓误差来评估匹配质量。
- Result: 在nuScenes数据集上的实验表明，CEs显著优于传统2D指标，在3D车辆跟踪中，功能失败率（FPs/FNs）在近距离和远距离分别减少了80%和60%。
- Conclusion: Contour Errors是一种更有效的匹配度量方法，适用于复杂3D场景，显著提升了多目标跟踪的可靠性和安全性。


### [103] [UniCUE: Unified Recognition and Generation Framework for Chinese Cued Speech Video-to-Speech Generation](https://arxiv.org/abs/2506.04134)
*Jinting Wang,Shan Yang,Li Liu*

Main category: cs.CV

TL;DR: UniCUE框架直接生成语音，避免中间文本依赖，显著提升CS视频到语音转换的性能。

- Motivation: 解决现有方法依赖中间文本导致的错误传播和时序不对齐问题。
- Method: 提出UniCUE框架，整合CSR任务，引入语义对齐池、VisioPhonetic适配器和姿态感知视觉处理器。
- Result: 在中文CS数据集上，词错误率降低78.3%，唇语同步性提升32%。
- Conclusion: UniCUE通过直接生成语音和跨任务整合，显著优化了CS视频到语音的转换效果。


### [104] [MMR-V: What's Left Unsaid? A Benchmark for Multimodal Deep Reasoning in Videos](https://arxiv.org/abs/2506.04141)
*Kejian Zhu,Zhuoran Jin,Hongbang Yuan,Jiachun Li,Shangqing Tu,Pengfei Cao,Yubo Chen,Kang Liu,Jun Zhao*

Main category: cs.CV

TL;DR: MMR-V是一个新的视频多模态深度推理基准，要求模型进行长距离多帧推理和隐藏信息分析，现有模型表现不佳。

- Motivation: 现有视频基准主要关注理解任务，缺乏对多帧证据定位和多模态推理能力的测试。
- Method: 提出MMR-V基准，包含长距离多帧推理、超越感知的问题、人工标注任务和干扰项设计。
- Result: 当前模型在多模态推理上表现较差，最佳模型准确率仅52.5%，推理增强策略效果有限。
- Conclusion: MMR-V可推动多模态推理能力的研究，现有模型仍需改进。


### [105] [Person Re-Identification System at Semantic Level based on Pedestrian Attributes Ontology](https://arxiv.org/abs/2506.04143)
*Ngoc Q. Ly,Hieu N. M. Cao,Thi T. Nguyen*

Main category: cs.CV

TL;DR: 提出了一种统一的Re-ID系统，结合PAO、Local MDCNN和IDS模块，解决属性不平衡和语义特征利用问题，在Market1501数据集上表现优异。

- Motivation: 解决Re-ID任务中属性不平衡、语义特征利用不足等问题，提升性能。
- Method: 系统包含PAO、Local MDCNN和IDS模块，利用属性内组关联和语义信息预筛选候选。
- Result: 在Market1501数据集上表现优于现有方法。
- Conclusion: 统一系统有效解决了Re-ID中的关键挑战，性能显著提升。


### [106] [Image Editing As Programs with Diffusion Models](https://arxiv.org/abs/2506.04158)
*Yujia Hu,Songhua Liu,Zhenxiong Tan,Xingyi Yang,Xinchao Wang*

Main category: cs.CV

TL;DR: 论文提出了一种基于扩散变换器（DiT）的统一图像编辑框架IEAP，通过将复杂编辑指令分解为原子操作序列，解决了扩散模型在结构不一致编辑中的挑战。

- Motivation: 扩散模型在文本到图像生成中表现优异，但在指令驱动的图像编辑（尤其是涉及大幅布局变化的结构不一致编辑）中存在显著困难。
- Method: IEAP框架通过轻量级适配器实现原子操作，由基于视觉语言模型（VLM）的代理编程，支持任意和结构不一致的变换。
- Result: 实验表明，IEAP在多种编辑场景下显著优于现有方法，尤其在复杂多步指令中表现出更高的准确性和语义保真度。
- Conclusion: IEAP通过模块化和序列化编辑操作，实现了对广泛编辑任务的鲁棒性，为复杂图像编辑提供了有效解决方案。


### [107] [FlexGS: Train Once, Deploy Everywhere with Many-in-One Flexible 3D Gaussian Splatting](https://arxiv.org/abs/2506.04174)
*Hengyu Liu,Yuehao Wang,Chenxin Li,Ruisi Cai,Kevin Wang,Wuyang Li,Pavlo Molchanov,Peihao Wang,Zhangyang Wang*

Main category: cs.CV

TL;DR: 提出了一种弹性推理方法，通过选择和变换高斯子集，无需微调即可适应不同设备的特定内存需求。

- Motivation: 3D高斯溅射（3DGS）在3D场景表示和新视角合成中应用广泛，但对GPU内存需求较高，限制了其在资源受限设备上的使用。现有方法通常需要微调且缺乏适应性。
- Method: 引入了一个小型可学习模块，根据输入百分比控制高斯选择，并通过变换模块调整所选高斯以补充性能。
- Result: 在ZipNeRF、MipNeRF和Tanks&Temples场景上的实验验证了方法的有效性。
- Conclusion: 该方法无需微调即可显著提升渲染性能，适应不同设备的特定需求。


### [108] [Language-Image Alignment with Fixed Text Encoders](https://arxiv.org/abs/2506.04209)
*Jingfeng Yang,Ziyang Wu,Yue Zhao,Yi Ma*

Main category: cs.CV

TL;DR: 论文提出了一种简化框架LIFT，通过固定预训练的大型语言模型（LLM）作为文本编码器，仅训练图像编码器，实现了高效的语言-图像对齐。

- Motivation: 质疑当前主流的联合训练方法（如CLIP）是否必要，探索预训练的固定LLM是否能作为足够好的文本编码器指导视觉表示学习。
- Method: 提出LIFT框架，固定LLM的文本编码器，仅训练图像编码器，通过对比学习实现语言-图像对齐。
- Result: LIFT在涉及组合理解和长标题的场景中优于CLIP，同时显著提升计算效率。
- Conclusion: LIFT为探索LLM文本嵌入如何指导视觉学习提供了新思路，并提出了学习语言对齐视觉表示的替代设计选择。


### [109] [Diffusion Domain Teacher: Diffusion Guided Domain Adaptive Object Detector](https://arxiv.org/abs/2506.04211)
*Boyong He,Yuxiang Ji,Zhuoyue Tan,Liaoni Wu*

Main category: cs.CV

TL;DR: 论文提出了一种基于扩散模型的跨域目标检测方法（DDT），通过冻结权重的扩散模型生成伪标签，显著提升了跨域检测性能。

- Motivation: 目标检测器在训练数据（源域）和真实数据（目标域）之间存在性能下降问题，扩散模型具有提取跨域特征的潜力。
- Method: 使用冻结权重的扩散模型在源域训练检测器，作为教师模型在目标域生成伪标签，指导学生模型学习。
- Result: 在6个数据集上平均mAP提升21.2%，超越现有方法5.7% mAP。
- Conclusion: DDT方法简单有效，适用于复杂模型，具有广泛的域适应能力。


### [110] [FullDiT2: Efficient In-Context Conditioning for Video Diffusion Transformers](https://arxiv.org/abs/2506.04213)
*Xuanhua He,Quande Liu,Zixuan Ye,Wecai Ye,Qiulin Wang,Xintao Wang,Qifeng Chen,Pengfei Wan,Di Zhang,Kun Gai*

Main category: cs.CV

TL;DR: FullDiT2提出了一种高效的上下文条件框架，通过动态令牌选择和选择性上下文缓存机制，显著降低了计算开销，同时保持了视频生成质量。

- Motivation: 现有方法（如FullDiT）在视频生成中面临二次计算开销的问题，限制了实际应用。研究旨在解决这一效率瓶颈。
- Method: FullDiT2通过动态令牌选择减少冗余令牌，并通过选择性上下文缓存优化条件令牌与视频潜在空间的交互。
- Result: 实验表明，FullDiT2在六种任务中实现了计算量显著减少和2-3倍的速度提升，同时生成质量几乎无损。
- Conclusion: FullDiT2为视频生成和编辑任务提供了一种高效且通用的可控性框架。


### [111] [Sounding that Object: Interactive Object-Aware Image to Audio Generation](https://arxiv.org/abs/2506.04214)
*Tingle Li,Baihe Huang,Xiaobin Zhuang,Dongya Jia,Jiawei Chen,Yuping Wang,Zhuo Chen,Gopala Anumanchipalli,Yuxuan Wang*

Main category: cs.CV

TL;DR: 提出了一种交互式对象感知音频生成模型，通过多模态注意力将图像区域与对应声音关联，实现用户选择对象的精准声音生成。

- Motivation: 解决复杂视听场景中多对象和多声源下的精准声音生成问题。
- Method: 结合对象中心学习和条件潜在扩散模型，通过多模态注意力关联图像区域与声音，并利用图像分割实现交互式对象级声音生成。
- Result: 定量和定性评估表明，模型优于基线方法，实现了对象与声音的更好对齐。
- Conclusion: 理论验证了注意力机制与测试时分割掩模的功能近似性，确保生成音频与选定对象对齐。


### [112] [UNIC: Unified In-Context Video Editing](https://arxiv.org/abs/2506.04216)
*Zixuan Ye,Xuanhua He,Quande Liu,Qiulin Wang,Xintao Wang,Pengfei Wan,Di Zhang,Kun Gai,Qifeng Chen,Wenhan Luo*

Main category: cs.CV

TL;DR: UNIC是一个统一的视频编辑框架，通过将不同编辑任务表示为三种令牌类型，并利用DiT的注意力机制实现任务统一，无需特定适配器。

- Motivation: 现有方法依赖任务特定架构或定制化，限制了编辑条件的多样性和任务统一性。
- Method: 将输入表示为源视频令牌、噪声视频潜在和多模态条件令牌，通过任务感知RoPE和条件偏置解决任务混淆。
- Result: 在六个视频编辑任务上表现优异，并展现出任务组合能力。
- Conclusion: UNIC框架简单有效，统一了多种视频编辑任务，具有灵活性和高性能。


### [113] [Struct2D: A Perception-Guided Framework for Spatial Reasoning in Large Multimodal Models](https://arxiv.org/abs/2506.04220)
*Fangrui Zhu,Hanhui Wang,Yiming Xie,Jing Gu,Tianye Ding,Jianwei Yang,Huaizu Jiang*

Main category: cs.CV

TL;DR: 论文提出Struct2D框架，通过结构化2D输入（如鸟瞰图和物体标记）增强大型多模态模型（LMMs）的空间推理能力，无需显式3D输入。实验表明LMMs在零样本任务中表现优异，并构建了大规模数据集Struct2D-Set，微调后模型在多个任务中表现竞争力。

- Motivation: 探索LMMs是否仅通过结构化2D输入（如鸟瞰图）就能进行3D空间推理，避免依赖显式3D输入或专用架构。
- Method: 提出Struct2D框架，结合鸟瞰图、物体标记和元数据，生成结构化2D输入。构建Struct2D-Set数据集（200K QA对），用于微调LMMs。
- Result: 实验显示LMMs在零样本任务中表现优异，微调后模型在3D问答、密集描述和物体定位等任务中具有竞争力。
- Conclusion: 结构化2D输入能有效连接感知与语言推理，无需显式3D输入，为未来研究提供了代码和数据集支持。


### [114] [Seeing in the Dark: Benchmarking Egocentric 3D Vision with the Oxford Day-and-Night Dataset](https://arxiv.org/abs/2506.04224)
*Zirui Wang,Wenjing Bian,Xinghui Li,Yifu Tao,Jianeng Wang,Maurice Fallon,Victor Adrian Prisacariu*

Main category: cs.CV

TL;DR: Oxford Day-and-Night数据集是一个大规模、以自我为中心的视觉数据集，用于挑战性光照条件下的新视角合成和视觉重定位研究。

- Motivation: 现有数据集通常缺乏真实3D几何、广泛光照变化和完整6DoF运动的组合，该数据集填补了这一空白。
- Method: 利用Meta ARIA眼镜采集视频，通过多会话SLAM估计相机位姿、重建3D点云，并对齐不同光照条件下的序列。
- Result: 数据集覆盖30公里轨迹和40,000平方米区域，支持新视角合成和重定位两个核心基准测试。
- Conclusion: 该数据集为自我中心3D视觉研究提供了丰富且多样化的平台。


### [115] [Voyager: Long-Range and World-Consistent Video Diffusion for Explorable 3D Scene Generation](https://arxiv.org/abs/2506.04225)
*Tianyu Huang,Wangguandong Zheng,Tengfei Wang,Yuhao Liu,Zhenwei Wang,Junta Wu,Jie Jiang,Hui Li,Rynson W. H. Lau,Wangmeng Zuo,Chunchao Guo*

Main category: cs.CV

TL;DR: Voyager是一种新型视频扩散框架，通过单张图像和用户定义的相机路径生成世界一致的3D点云序列，无需传统3D重建流程。

- Motivation: 现实应用（如视频游戏和虚拟现实）需要生成可沿自定义相机轨迹探索的3D场景，而现有方法在长范围、3D一致性和可探索性方面仍面临挑战。
- Method: Voyager结合了三个关键组件：1）世界一致视频扩散，2）长范围世界探索，3）可扩展数据引擎，实现端到端场景生成与重建。
- Result: 在视觉质量和几何精度上显著优于现有方法，具有广泛的应用潜力。
- Conclusion: Voyager通过创新的视频扩散框架解决了3D场景生成的复杂问题，为未来研究提供了新方向。


### [116] [LayerFlow: A Unified Model for Layer-aware Video Generation](https://arxiv.org/abs/2506.04228)
*Sihui Ji,Hao Luo,Xi Chen,Yuanpeng Tu,Yiyang Wang,Hengshuang Zhao*

Main category: cs.CV

TL;DR: LayerFlow是一种统一的层感知视频生成方法，支持透明前景、干净背景和混合场景的生成，并能分解混合视频或为给定前景生成背景。

- Motivation: 解决缺乏高质量分层训练视频的问题，并支持多种分层视频生成任务。
- Method: 基于文本到视频扩散变换器，通过分层嵌入区分不同层的子片段，采用多阶段训练策略（低质量视频数据训练、运动LoRA调整、高质量分层图像数据训练）。
- Result: 能够生成平滑的分层视频，支持多种变体任务。
- Conclusion: LayerFlow通过统一框架和多阶段训练策略，有效解决了分层视频生成问题。
## cs.AI

### [117] [mRAG: Elucidating the Design Space of Multi-modal Retrieval-Augmented Generation](https://arxiv.org/abs/2505.24073)
*Chan-Wei Hu,Yueqi Wang,Shuo Xing,Chia-Ju Chen,Zhengzhong Tu*

Main category: cs.AI

TL;DR: 论文探讨了检索增强生成（RAG）如何提升大型视觉语言模型（LVLMs）的性能，通过系统分析检索、重排序和生成阶段，并提出统一的自反思框架，实现5%的性能提升。

- Motivation: LVLMs在动态现实应用中受限于静态训练数据、幻觉问题和无法验证最新外部证据，RAG通过检索机制提供解决方案。
- Method: 系统分析RAG流程，包括检索阶段的模态配置和策略、重排序阶段的去偏和相关性提升，以及生成阶段的候选整合。提出自反思的统一框架。
- Result: 平均性能提升5%，无需微调。
- Conclusion: RAG能有效提升LVLMs性能，自反思框架进一步优化证据选择和生成。
## eess.AS

### [118] [SNIFR : Boosting Fine-Grained Child Harmful Content Detection Through Audio-Visual Alignment with Cascaded Cross-Transformer](https://arxiv.org/abs/2506.03378)
*Orchid Chetia Phukan,Mohd Mujtaba Akhtar,Girish,Swarup Ranjan Behera,Abu Osama Siddiqui,Sarthak Jain,Priyabrata Mallick,Jaya Sai Kiran Patibandla,Pailla Balakrishna Reddy,Arun Balaji Buduru,Rajesh Sharma*

Main category: eess.AS

TL;DR: 论文提出SNIFR框架，结合音频与视觉特征，用于儿童有害内容检测，性能优于单模态和基线融合方法。

- Motivation: 随着视频平台儿童观众增加，恶意用户通过嵌入少量有害帧规避检测，现有研究多关注视觉特征，音频特征研究不足。
- Method: 提出SNIFR框架，使用Transformer编码器进行模态内交互，级联跨模态Transformer进行模态间对齐。
- Result: 方法在儿童有害内容检测中表现优异，超越单模态和基线融合方法，达到新SOTA。
- Conclusion: 结合音频与视觉特征的SNIFR框架显著提升有害内容检测效果。
## cs.GR

### [119] [Multi-Spectral Gaussian Splatting with Neural Color Representation](https://arxiv.org/abs/2506.03407)
*Lukas Meyer,Josef Grün,Maximilian Weiherer,Bernhard Egger,Marc Stamminger,Linus Franke*

Main category: cs.GR

TL;DR: MS-Splatting是一个多光谱3D高斯泼溅框架，能够从不同光谱域的多相机图像生成多视角一致的新视图，无需跨模态相机校准，支持多种光谱（如热红外和近红外）。

- Motivation: 现有方法通常独立处理每种光谱模态，未能利用光谱和空间相关性，限制了多光谱渲染的质量和灵活性。
- Method: 提出一种神经颜色表示方法，将多光谱信息编码为紧凑的每泼溅特征嵌入，并通过浅层MLP解码为光谱颜色值，实现联合学习。
- Result: 实验表明，该方法提升了多光谱渲染质量，并在单光谱渲染上优于现有技术，适用于农业植被指数（如NDVI）渲染。
- Conclusion: MS-Splatting通过统一表示和联合学习，显著提升了多光谱渲染的灵活性和质量。


### [120] [Facial Appearance Capture at Home with Patch-Level Reflectance Prior](https://arxiv.org/abs/2506.03478)
*Yuxuan Han,Junfeng Lyu,Kuan Sheng,Minghao Que,Qixuan Zhang,Lan Xu,Feng Xu*

Main category: cs.GR

TL;DR: 本文提出了一种基于智能手机和闪光灯的低成本面部反射捕捉方法，通过扩散先验和补丁级后验采样技术，显著提升了重建质量。

- Motivation: 现有智能手机视频捕捉的面部反射重建质量远低于基于工作室录制的方法，本文旨在填补这一差距。
- Method: 使用智能手机和闪光灯在暗室中捕捉视频，学习基于Light Stage扫描的扩散先验，并通过补丁级后验采样生成高质量反射图。
- Result: 实验表明，该方法大幅缩小了低成本与工作室录制之间的质量差距。
- Conclusion: 该方法为日常用户提供了高质量的数字克隆解决方案，代码已开源。


### [121] [SplArt: Articulation Estimation and Part-Level Reconstruction with 3D Gaussian Splatting](https://arxiv.org/abs/2506.03594)
*Shengjie Lin,Jiading Fang,Muhammad Zubair Irshad,Vitor Campagnolo Guizilini,Rares Andrei Ambrus,Greg Shakhnarovich,Matthew R. Walter*

Main category: cs.GR

TL;DR: SplArt是一个自监督、类别无关的框架，利用3D高斯泼溅技术从两组不同关节状态的RGB图像中重建关节物体并推断运动学，实现实时逼真渲染。

- Motivation: 现有方法在可扩展性、鲁棒性和渲染效果上存在不足，SplArt旨在解决这些问题。
- Method: 通过为每个高斯添加可微分移动参数，采用多阶段优化策略逐步处理重建、部件分割和关节估计。
- Result: 在基准测试和实际应用中，SplArt表现出色，无需3D标注或类别先验。
- Conclusion: SplArt在性能和应用性上达到了先进水平，代码已开源。
## cond-mat.stat-mech

### [122] [Dreaming up scale invariance via inverse renormalization group](https://arxiv.org/abs/2506.04016)
*Adam Rançon,Ulysse Rançon,Tomislav Ivek,Ivan Balog*

Main category: cond-mat.stat-mech

TL;DR: 最小神经网络能逆向重整化群（RG）粗粒化过程，生成二维Ising模型的微观构型，无需依赖微观输入即可重建尺度不变分布。

- Motivation: 探索神经网络是否能逆向RG过程，从粗粒化状态生成微观构型，并研究其是否能够捕捉临界现象。
- Method: 使用仅含三个可训练参数的神经网络，生成临界构型，并通过实空间RG分析验证其尺度不变性和RG变换特征值。
- Result: 简单神经网络能成功生成临界构型，捕捉尺度不变性和RG特征值，增加网络复杂度无显著提升。
- Conclusion: 简单局部规则足以编码临界现象的普适性，为物理统计系综的高效生成模型提供了可能。
## eess.SY

### [123] [Urban Visibility Hotspots: Quantifying Building Vertex Visibility from Connected Vehicle Trajectories using Spatial Indexing](https://arxiv.org/abs/2506.03365)
*Artur Grigorev,Adriana-Simona Mihaita*

Main category: eess.SY

TL;DR: 论文提出了一种基于车辆轨迹数据的户外广告和街道家具位置优化方法，通过动态驾驶员视野建模和空间索引技术，量化视觉曝光并识别高曝光热点。

- Motivation: 传统选址方法依赖静态交通数据或主观评估，缺乏客观性。研究旨在通过数据驱动方法，利用车辆轨迹数据准确量化位置视觉曝光。
- Method: 利用车辆轨迹数据建模动态驾驶员视野，结合OpenStreetMap建筑顶点数据，构建BallTree空间索引高效计算视觉曝光。
- Result: 发现视觉曝光高度集中，存在显著高曝光的视觉热点；顶点视觉曝光符合对数正态分布。
- Conclusion: 方法显著提升了选址效率，为户外广告和街道家具的优化布局提供了数据支持。
## cs.RO

### [124] [Pseudo-Simulation for Autonomous Driving](https://arxiv.org/abs/2506.04218)
*Wei Cao,Marcel Hallgarten,Tianyu Li,Daniel Dauner,Xunjiang Gu,Caojun Wang,Yakov Miron,Marco Aiello,Hongyang Li,Igor Gilitschenski,Boris Ivanovic,Marco Pavone,Andreas Geiger,Kashyap Chitta*

Main category: cs.RO

TL;DR: 提出了一种名为伪模拟的新评估范式，结合了真实数据和合成观测，解决了现有AV评估方法的局限性。

- Motivation: 现有AV评估方法存在安全性、真实性和计算成本等问题，需要一种更高效的解决方案。
- Method: 使用3D高斯散射生成合成观测，并通过基于邻近性的加权方案评估AV行为。
- Result: 伪模拟与闭环模拟的相关性（R²=0.8）优于现有开环方法（R²=0.7）。
- Conclusion: 伪模拟是一种高效且相关性强的AV评估方法，为社区提供了新的基准平台。


### [125] [Object-centric 3D Motion Field for Robot Learning from Human Videos](https://arxiv.org/abs/2506.04227)
*Zhao-Heng Yin,Sherry Yang,Pieter Abbeel*

Main category: cs.RO

TL;DR: 论文提出了一种基于物体中心3D运动场的动作表示方法，用于从人类视频中学习机器人控制策略，并通过新框架实现零样本控制。

- Motivation: 现有动作表示方法（如视频帧、像素流等）存在建模复杂或信息丢失的问题，需更高效的动作表示方法。
- Method: 提出物体中心3D运动场表示，包含去噪3D运动场估计器和密集预测架构，支持跨具身迁移和背景泛化。
- Result: 实验显示，3D运动估计误差降低50%以上，任务平均成功率55%，优于现有方法（<10%）。
- Conclusion: 物体中心3D运动场是一种高效的动作表示方法，适用于机器人学习，尤其在精细操作任务中表现优异。
## cs.MM

### [126] [How Far Are We from Predicting Missing Modalities with Foundation Models?](https://arxiv.org/abs/2506.03530)
*Guanzhou Ke,Yi Xie,Xiaoli Wang,Guoqing Chao,Bo Wang,Shengfeng He*

Main category: cs.MM

TL;DR: 论文研究了多模态基础模型在缺失模态预测中的潜力，提出了一个动态框架和自我优化机制，显著提升了预测性能。

- Motivation: 探索多模态基础模型作为即插即用解决方案在缺失模态预测中的潜力，并解决现有模型在语义提取和验证方面的不足。
- Method: 提出了一个动态的代理框架和自我优化机制，以提取更丰富的语义特征并验证生成的模态。
- Result: 实验结果显示，该方法在缺失图像预测中FID降低了至少14%，在缺失文本预测中MER降低了至少10%。
- Conclusion: 提出的框架显著提升了缺失模态预测的准确性和鲁棒性，为多模态任务提供了更有效的解决方案。
## cs.LG

### [127] [DUAL: Dynamic Uncertainty-Aware Learning](https://arxiv.org/abs/2506.03158)
*Jiahao Qin,Bei Peng,Feng Liu,Guangliang Cheng,Lu Zong*

Main category: cs.LG

TL;DR: 提出了动态不确定性感知学习（DUAL）框架，有效处理单模态和多模态场景中的特征不确定性，显著提升模型性能。

- Motivation: 深度学习模型在多样学习场景中常面临特征不确定性问题，影响性能和可靠性，多模态场景尤为复杂。
- Method: DUAL框架包含动态特征不确定性建模、自适应分布感知调制和不确定性感知跨模态关系学习三大创新。
- Result: 在计算机视觉和多模态学习任务中，DUAL显著提升了准确率，如CIFAR-10提升7.1%，CMU-MOSEI提升4.1%。
- Conclusion: DUAL通过动态处理特征不确定性，在多领域任务中表现出色，为不确定性感知学习提供了统一解决方案。


### [128] [Robustness in Both Domains: CLIP Needs a Robust Text Encoder](https://arxiv.org/abs/2506.03355)
*Elias Abad Rocamora,Christian Schlarmann,Naman Deep Singh,Yongtao Wu,Matthias Hein,Volkan Cevher*

Main category: cs.LG

TL;DR: LEAF是一种高效的对抗性微调方法，用于提升CLIP文本编码器的鲁棒性，同时保持视觉性能。

- Motivation: 对抗性输入攻击可能导致CLIP嵌入显著偏移，影响下游模型的鲁棒性，而文本编码器的鲁棒性尚未被充分研究。
- Method: 提出LEAF方法，通过对抗性微调提升文本编码器的鲁棒性，适用于大规模CLIP模型。
- Result: 显著提高文本域的零样本对抗准确性，改善对抗噪声下的生成质量和多模态检索任务中的召回率。
- Conclusion: 鲁棒的文本编码器有助于通过直接优化更好地重建输入文本，提升整体性能。


### [129] [Rethinking the Stability-Plasticity Trade-off in Continual Learning from an Architectural Perspective](https://arxiv.org/abs/2506.03951)
*Aojun Lu,Hangjie Yuan,Tao Feng,Yanan Sun*

Main category: cs.LG

TL;DR: 论文提出了一种名为Dual-Arch的新框架，通过结合深度和宽度网络的互补优势，解决了持续学习中稳定性与可塑性之间的架构级冲突。

- Motivation: 持续学习需要平衡稳定性与可塑性，现有方法多关注参数层面，忽视了网络架构的影响。本文旨在从架构层面解决这一问题。
- Method: 提出Dual-Arch框架，包含两个独立网络：一个专注于可塑性（深度网络），另一个专注于稳定性（宽度网络）。每个网络采用轻量级专用架构。
- Result: 实验表明，Dual-Arch显著提升了现有持续学习方法的性能，同时参数规模减少了87%。
- Conclusion: Dual-Arch通过架构级优化，有效解决了持续学习中的稳定性与可塑性冲突，具有高效和紧凑的特点。


### [130] [Adapt before Continual Learning](https://arxiv.org/abs/2506.03956)
*Aojun Lu,Tao Feng,Hangjie Yuan,Chunhui Ding,Yanan Sun*

Main category: cs.LG

TL;DR: 论文提出了一种名为ACL的新框架，通过在核心持续学习（CL）过程之前对预训练模型（PTM）进行适应性调整，以平衡稳定性和可塑性。

- Motivation: 现有方法在持续学习中冻结PTM主干以保持稳定性，但限制了可塑性；而完全微调PTM则可能导致灾难性遗忘。ACL旨在解决这一稳定性与可塑性的权衡问题。
- Method: ACL框架在每学习新任务前，通过一个即插即用的适应性阶段调整PTM主干，例如通过提示调优（prompt tuning）等方法。
- Result: 实验表明，ACL显著提升了持续学习性能，并在多个基准测试和集成方法中表现优异。
- Conclusion: ACL为基于PTM的持续学习提供了一个通用解决方案，有效平衡了稳定性和可塑性。


### [131] [Solving Inverse Problems via Diffusion-Based Priors: An Approximation-Free Ensemble Sampling Approach](https://arxiv.org/abs/2506.03979)
*Haoxuan Chen,Yinuo Ren,Martin Renqiang Min,Lexing Ying,Zachary Izzo*

Main category: cs.LG

TL;DR: 提出了一种基于扩散模型的无启发式近似的后验采样算法，通过结合SMC方法，改进了现有方法。

- Motivation: 现有基于扩散模型的后验采样方法依赖启发式近似，限制了其生成能力。
- Method: 提出了一种基于SMC的集成算法，通过分析扩散过程中先验的演化，推导出修正的PDE，并利用加权粒子方法模拟。
- Result: 理论证明后验分布误差可被预训练得分函数误差和粒子数限制，实验验证了算法在成像问题中的优越性。
- Conclusion: 新算法避免了启发式近似，提高了后验采样的准确性。


### [132] [Optimal Transport-based Domain Alignment as a Preprocessing Step for Federated Learning](https://arxiv.org/abs/2506.04071)
*Luiz Manella Pereira,M. Hadi Amini*

Main category: cs.LG

TL;DR: 论文提出了一种基于最优传输的预处理算法，用于解决联邦学习中的数据集不平衡问题，通过最小化边缘设备间的数据分布差异，提升全局模型性能。

- Motivation: 联邦学习中数据集不平衡会导致全局模型性能下降，影响本地模型更新和决策准确性。
- Method: 利用Wasserstein重心计算通道平均值，生成目标RGB空间，通过投影最小化全局分布差异。
- Result: 在CIFAR-10数据集上验证了该方法能在更少通信轮次内实现更高的泛化能力。
- Conclusion: 提出的方法有效解决了联邦学习中的数据分布不平衡问题，提升了模型性能。


### [133] [Multimodal Tabular Reasoning with Privileged Structured Information](https://arxiv.org/abs/2506.04088)
*Jun-Peng Jiang,Yu Xia,Hai-Long Sun,Shiyin Lu,Qing-Guo Chen,Weihua Luo,Kaifu Zhang,De-Chuan Zhan,Han-Jia Ye*

Main category: cs.LG

TL;DR: 论文提出了一种名为Turbo的新框架，用于解决表格图像的多模态推理问题，通过利用训练时的结构化信息提升模型性能。

- Motivation: 现实场景中表格通常以图像形式出现，缺乏高质量文本表示，导致推理困难。
- Method: Turbo框架结合结构化信息和视觉表示，通过生成高质量模态桥接数据和优化推理路径提升性能。
- Result: 实验表明，Turbo在有限数据（9k）下性能提升7.2%，达到SOTA。
- Conclusion: Turbo有效解决了表格图像推理的模态对齐和结构化推理迁移问题。


### [134] [Advancing Multimodal Reasoning: From Optimized Cold Start to Staged Reinforcement Learning](https://arxiv.org/abs/2506.04207)
*Shuang Chen,Yue Guo,Zhaochen Su,Yafu Li,Yulun Wu,Jiacheng Chen,Jiayu Chen,Weijie Wang,Xiaoye Qu,Yu Cheng*

Main category: cs.LG

TL;DR: 论文提出了一种分阶段训练方法，通过优化初始化和解决梯度停滞问题，显著提升了多模态大语言模型的推理能力。

- Motivation: 受Deepseek-R1在复杂文本任务中的推理能力启发，研究试图通过强化学习激活多模态大语言模型的类似能力，但效果不佳。
- Method: 分析了当前训练流程，提出三点关键发现：1）冷启动初始化的重要性；2）标准GRPO在多模态强化学习中的梯度停滞问题；3）分阶段训练（先多模态强化学习，后纯文本强化学习）。基于此，提出了ReVisual-R1模型。
- Result: ReVisual-R1在多个挑战性基准测试中达到开源7B MLLMs的最新水平。
- Conclusion: 分阶段训练方法有效平衡了感知基础和认知推理，显著提升了多模态推理能力。
## eess.IV

### [135] [Adaptive and Robust Image Processing on CubeSats](https://arxiv.org/abs/2506.03152)
*Robert Bayer,Julian Priest,Daniel Kjellberg,Jeppe Lindhard,Nikolaj Sørenesen,Nicolaj Valsted,Ívar Óli,Pınar Tözün*

Main category: eess.IV

TL;DR: 论文提出DIPP和DISH系统，解决CubeSat资源受限下图像处理管道的灵活性和复杂性问题。DIPP提供模块化框架，DISH是专用语言和运行时系统。实验证明DIPP高效且稳健，DISH比Lua内存需求更低。

- Motivation: 解决CubeSat在资源受限环境下图像处理管道的灵活性和复杂性问题。
- Method: 引入DIPP（模块化图像处理框架）和DISH（专用语言及运行时系统）。
- Result: DIPP减少网络需求且稳健，DISH比Lua内存需求更低。
- Conclusion: DIPP和DISH有效提升CubeSat图像处理能力。


### [136] [Super-temporal-resolution Photoacoustic Imaging with Dynamic Reconstruction through Implicit Neural Representation in Sparse-view](https://arxiv.org/abs/2506.03175)
*Youshen Xiao,Yiling Shi,Ruixi Sun,Hongjiang Wei,Fei Gao,Yuyao Zhang*

Main category: eess.IV

TL;DR: 提出了一种基于隐式神经表示（INR）的动态光声图像重建方法，解决了稀疏传感器数据下的图像伪影问题，并提高了时间分辨率。

- Motivation: 传统光声图像重建方法在稀疏数据下产生严重伪影，且未考虑动态成像中的帧间关系。高功率激光技术的低重复率和高成本限制了时间分辨率。
- Method: 利用INR将动态光声图像表示为隐式函数，并通过神经网络编码，仅需时空坐标输入，无需外部训练数据或先验图像。结合低秩和稀疏性显式正则化。
- Result: 在两种稀疏条件下优于传统方法，有效抑制伪影并确保图像质量。
- Conclusion: INR方法为稀疏数据动态光声成像提供了高质量重建方案，具有潜力。


### [137] [Deep Learning-Based Breast Cancer Detection in Mammography: A Multi-Center Validation Study in Thai Population](https://arxiv.org/abs/2506.03177)
*Isarun Chamveha,Supphanut Chaiyungyuen,Sasinun Worakriangkrai,Nattawadee Prasawang,Warasinee Chaisangmongkon,Pornpim Korpraphong,Voraparee Suvannarerg,Shanigarn Thiravit,Chalermdej Kannawat,Kewalin Rungsinaporn,Suwara Issaragrisil,Payia Chadbunchachai,Pattiya Gatechumpol,Chawiporn Muktabhant,Patarachai Sereerat*

Main category: eess.IV

TL;DR: 该研究提出了一种基于改进的EfficientNetV2架构和增强注意力机制的深度学习系统，用于乳腺X光检查中的乳腺癌检测，并在多个数据集上验证了其性能。

- Motivation: 旨在开发一种高效且可靠的深度学习系统，以辅助乳腺X光检查中的乳腺癌检测，提升临床筛查效率。
- Method: 采用改进的EfficientNetV2架构，结合增强注意力机制，在泰国某医疗中心的乳腺X光片上进行训练，并在三个不同数据集上验证性能。
- Result: 模型在癌症检测上的AUROC分别为0.89、0.96和0.94，病灶定位性能稳健，临床验证显示与放射科医生的一致性较高。
- Conclusion: 该系统在乳腺X光检查中表现出高效性和临床实用性，有望提升乳腺癌筛查的工作流程。


### [138] [LLaMA-XR: A Novel Framework for Radiology Report Generation using LLaMA and QLoRA Fine Tuning](https://arxiv.org/abs/2506.03178)
*Md. Zihad Bin Jahangir,Muhammad Ashad Kabir,Sumaiya Akter,Israt Jahan,Minh Chau*

Main category: eess.IV

TL;DR: LLaMA-XR是一种结合LLaMA 3.1和DenseNet-121图像嵌入的新型框架，通过QLoRA微调提升放射学报告生成的准确性和效率。

- Motivation: 减少放射科医生的工作量并提高诊断准确性，但现有模型在保持准确性和上下文相关性方面存在挑战。
- Method: 整合LLaMA 3.1与DenseNet-121图像嵌入，采用QLoRA微调，优化参数利用和内存开销。
- Result: 在IU X-ray数据集上，ROUGE-L得分0.433，METEOR得分0.336，超越现有方法。
- Conclusion: LLaMA-XR在自动放射学报告生成中表现出高效和临床实用性。


### [139] [Dc-EEMF: Pushing depth-of-field limit of photoacoustic microscopy via decision-level constrained learning](https://arxiv.org/abs/2506.03181)
*Wangting Zhou,Jiangshan He,Tong Cai,Lin Wang,Zhen Yuan,Xunbin Wei,Xueli Chen*

Main category: eess.IV

TL;DR: 提出了一种决策级约束端到端多焦点图像融合方法（Dc-EEMF），用于突破光声显微镜（PAM）的景深限制，提高深度方向的分辨率。

- Motivation: 传统光学分辨率光声显微镜（OR-PAM）因高斯光束的有限景深（DoF）无法在深度方向解析足够细节，限制了其在生物医学研究中的应用。
- Method: Dc-EEMF是一种轻量级孪生网络，结合了抗伪影的通道空间频率特征融合规则，并设计了基于U-Net的感知损失函数，实现端到端融合。
- Result: 实验和数值分析表明，该方法在保持横向分辨率的同时，显著提升了PAM图像的融合效果。
- Conclusion: Dc-EEMF驱动的PAM有望成为需要扩展景深的临床和临床前研究的实用工具。


### [140] [Edge Computing for Physics-Driven AI in Computational MRI: A Feasibility Study](https://arxiv.org/abs/2506.03183)
*Yaşar Utku Alçalar,Yu Cao,Mehmet Akçakaya*

Main category: eess.IV

TL;DR: 提出了一种针对FPGA边缘计算优化的PD-AI MRI重建方法，通过8位复数数据量化和消除冗余FFT/IFFT操作，提高计算效率并保持重建质量。

- Motivation: 高分辨率MRI扫描产生大量数据，导致传输、存储和实时处理挑战，尤其是在功能MRI中。边缘计算和FPGA为解决这些问题提供了可能，但需要优化PD-AI模型以适应硬件效率。
- Method: 采用8位复数数据量化并消除冗余FFT/IFFT操作，优化PD-AI模型以适配FPGA边缘计算设备。
- Result: 该方法在计算效率上有所提升，重建质量与传统PD-AI方法相当，并优于标准临床方法。
- Conclusion: 该方法为资源受限设备上的高分辨率MRI重建提供了可能，具有实际部署潜力。


### [141] [DLiPath: A Benchmark for the Comprehensive Assessment of Donor Liver Based on Histopathological Image Dataset](https://arxiv.org/abs/2506.03185)
*Liangrui Pan,Xingchen Li,Zhongyi Chen,Ling Chu,Shaoliang Peng*

Main category: eess.IV

TL;DR: DLiPath是一个基于组织病理学图像数据集的供体肝脏评估基准，旨在解决供体肝脏活检评估中的快速准确性问题。

- Motivation: 供体肝脏活检评估对移植结果至关重要，但快速准确的术中评估存在挑战，且评估指标存在观察者间和观察者内变异性。
- Method: 收集并公开了304名供体肝脏患者的636张全切片图像，标注关键病理特征，并基于此数据集评估了九种多实例学习模型。
- Result: 实验表明，多种MIL模型在DLiPath数据集上对供体肝脏评估指标达到了高准确率。
- Conclusion: DLiPath为未来自动化智能供体肝脏评估研究提供了明确方向，数据和代码已公开。


### [142] [Lightweight Convolutional Neural Networks for Retinal Disease Classification](https://arxiv.org/abs/2506.03186)
*Duaa Kareem Qasim,Sabah Abdulazeez Jebur,Lafta Raheem Ali,Abdul Jalil M. Khalaf,Abir Jaafar Hussain*

Main category: eess.IV

TL;DR: 论文使用MobileNet和NASNetMobile两种轻量级CNN架构，对正常、糖尿病视网膜病变（DR）和黄斑裂孔（MH）的视网膜图像进行分类，MobileNetV2达到90.8%的准确率。

- Motivation: 早期检测DR和MH对视网膜疾病的诊断至关重要，AI辅助诊断可提高效率和准确性。
- Method: 使用MobileNet和NASNetMobile模型，基于RFMiD数据集，通过预处理、迁移学习和数据增强提升性能。
- Result: MobileNetV2准确率90.8%，优于NASNetMobile的89.5%。
- Conclusion: CNN在视网膜疾病分类中表现优异，为AI辅助眼科诊断提供了基础。


### [143] [Multi-Analyte, Swab-based Automated Wound Monitor with AI](https://arxiv.org/abs/2506.03188)
*Madhu Babu Sikha,Lalith Appari,Gurudatt Nanjanagudu Ganesh,Amay Bandodkar,Imon Banerjee*

Main category: eess.IV

TL;DR: 开发了一种低成本、多分析物的3D打印检测装置和iOS应用，用于早期识别糖尿病足溃疡（DFUs），并通过计算机视觉技术自动分析伤口严重程度。

- Motivation: 糖尿病足溃疡（DFUs）每年影响大量患者，早期识别非愈合性溃疡可降低治疗成本和截肢风险。
- Method: 结合3D打印的多分析物检测装置和iOS应用，通过计算机视觉技术比较伤口暴露前后的图像密度变化。
- Result: 实现了伤口严重程度的自动分析，并克服了相机配置和环境变化的挑战。
- Conclusion: 该集成传感器和iOS应用可帮助医疗专业人员实时监测伤口状况，跟踪愈合进度。


### [144] [Encoding of Demographic and Anatomical Information in Chest X-Ray-based Severe Left Ventricular Hypertrophy Classifiers](https://arxiv.org/abs/2506.03192)
*Basudha Pal,Rama Chellappa,Muhammad Umair*

Main category: eess.IV

TL;DR: 提出了一种基于胸片直接预测严重左心室肥厚的分类框架，无需依赖解剖测量或人口统计输入，具有高AUROC和AUPRC表现。

- Motivation: 超声心动图和MRI是评估心脏结构的临床标准，但其成本高且可及性有限。
- Method: 采用互信息神经估计量化特征表达性，揭示临床有意义的属性编码，支持透明模型解释。
- Result: 模型表现优异，AUROC和AUPRC高。
- Conclusion: 该框架为心脏疾病的低成本、高效诊断提供了新途径。


### [145] [A combined Machine Learning and Finite Element Modelling tool for the surgical planning of craniosynostosis correction](https://arxiv.org/abs/2506.03202)
*Itxasne Antúnez Sáenz,Ane Alberdi Aramendi,David Dunaway,Juling Ong,Lara Deliège,Amparo Sáenz,Anita Ahmadi Birjandi,Noor UI Owase Jeelani,Silvia Schievano,Alessandro Borghi*

Main category: eess.IV

TL;DR: 研究开发了一种基于3D照片和机器学习的实时预测工具，用于颅缝早闭手术结果，减少CT扫描需求。

- Motivation: 当前颅缝早闭手术结果难以预测，依赖医生经验和婴儿年龄，缺乏高效术前规划工具。
- Method: 利用3D照片创建个性化合成头骨，结合人群平均数据，使用机器学习模型预测手术结果。
- Result: 多输出支持向量回归模型的R2达到0.95，MSE和MAE低于0.13。
- Conclusion: 该工具可减少辐射暴露，未来还能模拟手术场景并提供最优参数。


### [146] [A Survey of Deep Learning Video Super-Resolution](https://arxiv.org/abs/2506.03216)
*Arbind Agrahari Baniya,Tsz-Kwan Lee,Peter Eklund,Sunil Aryal*

Main category: eess.IV

TL;DR: 本文综述了基于深度学习的视频超分辨率（VSR）模型，分析了其组件、技术及挑战，并提出了多级分类法以指导未来研究。

- Motivation: 由于VSR在多个领域具有潜在影响，但现有方法的使用和决策往往缺乏充分解释，因此需要对VSR研究中的深度学习方法和组件进行全面分析。
- Method: 通过系统调查和分类现有VSR模型的组件和技术，分析其趋势、需求和挑战。
- Result: 提出了首个基于深度学习的VSR模型综述，建立了多级分类法，为未来研究提供指导。
- Conclusion: 该工作有助于VSR实践的成熟和解释，为特定应用需求定制模型提供依据。


### [147] [petBrain: A New Pipeline for Amyloid, Tau Tangles and Neurodegeneration Quantification Using PET and MRI](https://arxiv.org/abs/2506.03217)
*Pierrick Coupé,Boris Mansencal,Floréal Morandat,Sergio Morell-Ortega,Nicolas Villain,Jose V. Manjón,Vincent Planche*

Main category: eess.IV

TL;DR: petBrain是一个新型端到端处理管道，用于淀粉样蛋白PET、tau-PET和结构MRI，通过深度学习实现快速、标准化的生物标志物量化。

- Motivation: 现有管道在处理时间、示踪剂类型变异性和多模态整合方面存在局限性，需要更高效的解决方案。
- Method: 利用深度学习分割、标准化生物标志物量化（如Centiloid、CenTauR、HAVAs），并通过基于网络的平台实现A、T2和N生物标志物的同步估计。
- Result: petBrain提供可靠且快速的生物标志物量化，结果与现有管道相当，并与ADNI数据库数据及CSF/血浆生物标志物、临床状态和认知表现一致。
- Conclusion: petBrain是一个强大且开放的平台，为标准化AD生物标志物分析提供了便利，适用于临床研究。


### [148] [Rethinking Whole-Body CT Image Interpretation: An Abnormality-Centric Approach](https://arxiv.org/abs/2506.03238)
*Ziheng Zhao,Lisong Dai,Ya Zhang,Yanfeng Wang,Weidi Xie*

Main category: eess.IV

TL;DR: 论文提出了一种自动化CT图像解释方法，通过分类系统、数据集、模型开发和基准测试，显著提升了异常检测和描述的性能。

- Motivation: 解决临床放射学中多平面和全身CT图像异常定位和描述的自动化挑战。
- Method: 提出分层分类系统、构建数据集、开发OminiAbnorm-CT模型，并设计三项临床评估任务。
- Result: OminiAbnorm-CT在所有任务和指标上显著优于现有方法。
- Conclusion: 该方法为临床CT图像自动化解释提供了有效解决方案。


### [149] [Hybrid Ensemble of Segmentation-Assisted Classification and GBDT for Skin Cancer Detection with Engineered Metadata and Synthetic Lesions from ISIC 2024 Non-Dermoscopic 3D-TBP Images](https://arxiv.org/abs/2506.03420)
*Muhammad Zubair Hasan,Fahmida Yasmin Rifat*

Main category: eess.IV

TL;DR: 提出一种混合机器学习和深度学习方法，用于分类恶性与良性皮肤病变，结合了视觉Transformer和卷积ViT混合模型，通过分割辅助分类管道提升定位能力，最终在部分AUC指标上表现最佳。

- Motivation: 皮肤癌是全球高发且危及生命的疾病，早期检测对患者结果至关重要。
- Method: 结合视觉Transformer（EVA02）和设计的卷积ViT混合模型（EdgeNeXtSAC），采用分割辅助分类管道，融合梯度提升决策树（GBDT）集成，并利用合成数据和诊断信息重新标记策略。
- Result: 在部分AUC（pAUC）高于80%真阳性率（TPR）的评估指标下，达到0.1755的最高值。
- Conclusion: 混合可解释AI系统在远程医疗和资源有限环境中具有皮肤癌分诊潜力。


### [150] [Identifying Alzheimer's Disease Prediction Strategies of Convolutional Neural Network Classifiers using R2* Maps and Spectral Clustering](https://arxiv.org/abs/2506.03890)
*Christian Tinauer,Maximilian Sackl,Stefan Ropele,Christian Langkammer*

Main category: eess.IV

TL;DR: 该研究通过LRP和谱聚类分析深度学习模型在AD分类中的决策策略，发现预处理和训练选择对模型影响显著，谱聚类有助于揭示分类策略差异。

- Motivation: 深度学习模型在AD分类中表现优异但缺乏可解释性，且可能存在偏差，需进一步分析其决策策略。
- Method: 使用3D卷积神经网络训练R2*图像，通过LRP生成热图，应用谱聚类和t-SNE可视化分析决策模式。
- Result: 谱聚类揭示了明显的决策模式，LRP引导的模型在AD和NC病例间分离最清晰，t-SNE验证了热图分组与病例组的对应关系。
- Conclusion: 预处理和训练选择对模型影响显著，谱聚类为分类策略差异提供了结构化方法，强调了医学AI中可解释性的重要性。


### [151] [Conformal coronary calcification volume estimation with conditional coverage via histogram clustering](https://arxiv.org/abs/2506.04030)
*Olivier Jaubert,Salman Mohammadi,Keith A. Goatman,Shadia S. Mikhael,Conor Bradley,Rebecca Hughes,Richard Good,John H. Hipwell,Sonia Dahdouh*

Main category: eess.IV

TL;DR: 提出了一种基于聚类的条件共形预测框架，用于从训练好的分割网络中提供校准覆盖的分数区间，无需重新训练。

- Motivation: 通过CT扫描偶然检测和量化冠状动脉钙化可以早期引入挽救生命的临床干预，但过度报告可能对患者健康和医疗系统造成负担。
- Method: 采用基于聚类的条件共形预测框架，校准3D UNet模型（确定性、MCDropout和深度集成）的预测区间。
- Result: 与传统共形预测相比，实现了相似的覆盖率和更好的分流指标。
- Conclusion: 钙化分数的有意义预测区间有助于根据风险类别预测的置信度对患者进行分流。


### [152] [Towards generating more interpretable counterfactuals via concept vectors: a preliminary study on chest X-rays](https://arxiv.org/abs/2506.04058)
*Bulat Maksudov,Kathleen Curran,Alessandra Mileo*

Main category: eess.IV

TL;DR: 论文提出了一种将临床概念映射到生成模型潜在空间的方法，通过概念激活向量（CAVs）实现无需显式标签训练的视觉解释。

- Motivation: 确保医学影像模型与临床知识对齐并具有可解释性。
- Method: 使用简单的重建自编码器，将用户定义的概念与图像级特征关联，提取稳定的概念并生成视觉解释。
- Result: 在胸部X光片中，对大病理（如心脏肥大）效果显著，但对小病理因重建限制仍有挑战。
- Conclusion: 该方法虽未超越基线，但为临床知识对齐的可解释性提供了新途径。


### [153] [A Diffusion-Driven Temporal Super-Resolution and Spatial Consistency Enhancement Framework for 4D MRI imaging](https://arxiv.org/abs/2506.04116)
*Xuanru Zhou,Jiarun Liu,Shoujun Yu,Hao Yang,Cheng Li,Tao Tan,Shanshan Wang*

Main category: eess.IV

TL;DR: TSSC-Net是一种新型框架，通过扩散模型和长程上下文信息解决4D MRI中的时空分辨率矛盾，提升动态成像质量。

- Motivation: 传统方法在处理大变形时易产生误配准和伪影，TSSC-Net旨在解决这些问题，同时提升时空分辨率。
- Method: 结合扩散模型生成中间帧，并引入三向Mamba模块增强空间一致性。
- Result: 在ACDC和动态膝关节数据集上验证，TSSC-Net实现了6倍时间超分辨率，并保持了结构保真度。
- Conclusion: TSSC-Net能有效生成高质量动态MRI，适用于快速运动场景。


### [154] [A Comprehensive Study on Medical Image Segmentation using Deep Neural Networks](https://arxiv.org/abs/2506.04121)
*Loan Dao,Ngoc Quoc Ly*

Main category: eess.IV

TL;DR: 本文综述了基于深度神经网络的医学图像分割（MIS）的研究进展，重点探讨了DIKIW框架下的技术发展，并强调了可解释人工智能（XAI）和早期预测的重要性。

- Motivation: 医学图像分割在疾病诊断和早期检测中具有重要作用，尤其是提高癌症患者的生存率。研究旨在推动MIS技术的发展并解决其透明性和伦理问题。
- Method: 通过DIKIW框架评估现有MIS技术，并引入XAI以提升模型的可解释性。
- Result: 研究表明XAI和早期预测是从“智能”到“智慧”的关键步骤，同时提出了提升DNN-based MIS效率的潜在解决方案。
- Conclusion: MIS技术在未来具有广阔前景，但需进一步解决透明性和效率问题，XAI和早期预测是重要发展方向。


### [155] [Recent Advances in Medical Image Classification](https://arxiv.org/abs/2506.04129)
*Loan Dao,Ngoc Quoc Ly*

Main category: eess.IV

TL;DR: 论文综述了医学图像分类领域的最新进展，重点关注基础、特定和应用三个层面的解决方案，并探讨了深度学习和视觉语言模型的应用。

- Motivation: 医学图像分类对诊断和治疗至关重要，人工智能的进步为其提供了显著支持。
- Method: 论文回顾了传统方法（如CNN和Vision Transformers）和前沿方法（如视觉语言模型），并利用可解释人工智能增强和解释预测结果。
- Result: 这些方法解决了标记数据有限的问题，并提升了预测结果的准确性和可解释性。
- Conclusion: 论文总结了医学图像分类领域的进展，强调了深度学习和可解释人工智能的重要性。
## physics.optics

### [156] [Structural Vibration Monitoring with Diffractive Optical Processors](https://arxiv.org/abs/2506.03317)
*Yuntian Wang,Zafer Yilmaz,Yuhang Li,Edward Liu,Eric Ahlberg,Farid Ghahari,Ertugrul Taciroglu,Aydogan Ozcan*

Main category: physics.optics

TL;DR: 提出了一种基于衍射振动监测系统的低成本、低功耗、可扩展的3D结构振动监测方案，通过联合优化的衍射层和浅层神经网络后端实现高效数据提取。

- Motivation: 当前结构健康监测（SHM）方案在成本、功耗、可扩展性和数据处理复杂性方面存在局限，亟需一种更高效的解决方案。
- Method: 结合空间优化的被动衍射层和浅层神经网络后端，将3D结构位移编码为调制光信号，通过少量探测器实时解码。
- Result: 系统在毫米波照明下通过实验室建筑模型验证，精度比传统光学或独立训练模块提高一个数量级。
- Conclusion: 该框架为结构的高通量3D监测奠定了基础，并在灾害韧性、航空航天诊断和自主导航等领域具有潜在应用。
## cs.CL

### [157] [Trajectory Prediction Meets Large Language Models: A Survey](https://arxiv.org/abs/2506.03408)
*Yi Xu,Ruining Yang,Yitian Zhang,Yizhou Wang,Jianglin Lu,Mingyuan Zhang,Lili Su,Yun Fu*

Main category: cs.CL

TL;DR: 这篇综述探讨了如何利用大语言模型（LLMs）改进轨迹预测，总结了五个研究方向及其挑战。

- Motivation: 随着大语言模型的发展，研究者希望利用其语义和推理能力提升轨迹预测的准确性和可解释性。
- Method: 综述将相关研究分为五类：基于语言建模的预测、直接使用预训练模型、语言引导的场景理解、语言驱动的数据生成以及基于语言的推理和可解释性。
- Result: 文章总结了每类方法的代表性研究、设计核心和未解决问题。
- Conclusion: 该综述为自然语言处理与轨迹预测的结合提供了统一视角，展示了语言如何丰富轨迹预测领域。


### [158] [ROSA: Addressing text understanding challenges in photographs via ROtated SAmpling](https://arxiv.org/abs/2506.03665)
*Hernán Maina,Guido Ivetta,Mateo Lione Stuto,Julian Martin Eisenschlos,Jorge Sánchez,Luciana Benotti*

Main category: cs.CL

TL;DR: 论文提出ROSA解码策略，提升视觉问答系统在文本方向错误图像中的表现。

- Motivation: 视觉障碍人士拍摄的照片中文本方向常不准确，现有VQA系统对此表现不佳。
- Method: 通过访谈识别问题，提出ROSA解码策略优化文本识别。
- Result: ROSA在最佳模型中比Greedy解码提升11.7个百分点。
- Conclusion: ROSA有效解决了视觉障碍用户拍摄图像中文本方向问题。


### [159] [Kinship in Speech: Leveraging Linguistic Relatedness for Zero-Shot TTS in Indian Languages](https://arxiv.org/abs/2506.03884)
*Utkarsh Pathak,Chandra Sai Krishna Gunda,Anusha Prakash,Keshav Agarwal,Hema A. Murthy*

Main category: cs.CL

TL;DR: 该论文提出了一种零样本合成方法，通过共享音素表示和调整文本解析规则，为资源稀缺的印度语言生成可理解和自然的语音。

- Motivation: 印度有1369种语言，其中许多缺乏数字资源，传统TTS系统需要高质量数据和准确转录，难以覆盖这些语言。
- Method: 通过增强共享音素表示并修改文本解析规则，以适应目标语言的音位规则，降低合成器开销并实现快速适配。
- Result: 成功为梵语、马哈拉施特拉语、卡纳拉孔卡尼语、迈蒂利语和库鲁克语生成了可理解和自然的语音。
- Conclusion: 该方法有效扩展了语音技术对资源稀缺语言的支持，具有广泛应用潜力。


### [160] [DynTok: Dynamic Compression of Visual Tokens for Efficient and Effective Video Understanding](https://arxiv.org/abs/2506.03990)
*Hongzhi Zhang,Jingyuan Zhang,Xingguang Ji,Qi Wang,Fuzheng Zhang*

Main category: cs.CL

TL;DR: DynTok是一种动态视频令牌压缩策略，通过自适应分组和合并视觉令牌，显著减少计算开销，同时保持性能。

- Motivation: 现有视频建模方法（如LLava）生成大量视觉令牌，尤其是长视频，导致计算负担。需要一种方法在保留关键信息的同时减少令牌数量。
- Method: DynTok动态将视觉令牌分组并在组内合并，对信息密度低的区域实现高压缩，保留关键内容。
- Result: 令牌数量减少至原大小的44.4%，性能接近；在Video-MME和MLVU上分别达到65.3%和72.5%。
- Conclusion: DynTok揭示了视频令牌表示的冗余性，为设计更高效视频建模技术提供了思路。


### [161] [Seeing What Tastes Good: Revisiting Multimodal Distributional Semantics in the Billion Parameter Era](https://arxiv.org/abs/2506.03994)
*Dan Oneata,Desmond Elliott,Stella Frank*

Main category: cs.CL

TL;DR: 论文研究了大规模模型如何表示具体物体概念的语义特征，通过探测任务评估图像编码器和语言模型在预测属性评分上的表现，发现多模态模型略优于纯语言模型，纯图像编码器在非视觉属性上也表现良好。

- Motivation: 探究大规模模型是否能够像人类一样基于感知运动经验表示具体物体概念的语义特征。
- Method: 使用探测任务评估图像编码器（纯图像、多模态）和纯语言模型在预测McRae和Binder数据集属性评分上的表现。
- Result: 多模态图像编码器略优于纯语言模型，纯图像编码器在非视觉属性上表现与语言模型相当。
- Conclusion: 研究揭示了单模态学习的潜力以及多模态的互补性。
## physics.med-ph

### [162] [Analytical Reconstruction of Periodically Deformed Objects in Time-resolved CT](https://arxiv.org/abs/2506.03792)
*Qianwei Qu,Christian M. Schlepütz,Marco Stampanoni*

Main category: physics.med-ph

TL;DR: 论文提出了两种新的时间分辨CT重建方法，解决了传统门控方法辐射剂量利用效率低的问题，并通过实验验证了其有效性。

- Motivation: 传统门控方法在时间周期性重建中仅利用部分投影数据，忽略了不同集合间的相关性，导致辐射剂量利用效率低。
- Method: 提出了两种分析性重建流程，利用所有投影数据并考虑不同集合间的相关性。
- Result: 新方法显著减少了重建图像中的随机噪声，同时保留了对象的锐利特征，可在更低辐射剂量下达到与传统方法相同的重建质量。
- Conclusion: 新方法在时间分辨CT重建中具有更高的效率和更低的辐射剂量需求。


### [163] [Personalized MR-Informed Diffusion Models for 3D PET Image Reconstruction](https://arxiv.org/abs/2506.03804)
*George Webber,Alexander Hammers,Andrew P. King,Andrew J. Reader*

Main category: physics.med-ph

TL;DR: 提出一种基于多主体PET-MR扫描数据生成个性化伪PET图像的方法，通过图像配准转换解剖结构，提升低计数数据重建精度。

- Motivation: 利用扩散模型提升PET图像重建质量，但现有方法依赖预训练模型且缺乏个性化数据。本文旨在通过生成个性化伪PET图像改进重建效果。
- Method: 通过图像配准从多主体PET-MR扫描数据生成个性化伪PET图像，保留MR扫描信息，用于预训练扩散模型。
- Result: 在模拟和真实[$^{18}$F]FDG数据中，该方法显著提升低计数数据重建精度，平衡PET与MR特征的保留。
- Conclusion: 生成个性化伪PET图像的方法有效且无需依赖生成式深度学习或大数据集，适用于其他医学影像任务。
## cs.DL

### [164] [Knowledge Graphs for Digitized Manuscripts in Jagiellonian Digital Library Application](https://arxiv.org/abs/2506.03180)
*Jan Ignatowicz,Krzysztof Kutt,Grzegorz J. Nalepa*

Main category: cs.DL

TL;DR: 论文探讨了结合计算机视觉、人工智能和语义网技术，以丰富数字化文化遗产元数据并构建知识图谱的方法。

- Motivation: 数字化文化遗产的元数据通常不完整且缺乏标准化，限制了其可搜索性和潜在关联。
- Method: 采用计算机视觉（CV）、人工智能（AI）和语义网技术，对数字化手稿和古版书进行元数据增强和知识图谱构建。
- Result: 提出了一种集成方法，旨在解决元数据不完整和标准化问题。
- Conclusion: 该方法有望提升数字化文化遗产的搜索性和关联性。
