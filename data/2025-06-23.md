[[toc]]

## cs.CV

### [1] [A Strong View-Free Baseline Approach for Single-View Image Guided Point Cloud Completion](https://arxiv.org/abs/2506.15747)
*Fangzhou Lin,Zilin Dai,Rigved Sanku,Songlin Hou,Kazunori D Yamada,Haichong K. Zhang,Ziming Zhang*

Main category: cs.CV

TL;DR: 论文提出了一种基于注意力机制的多分支编码器-解码器网络，用于单视图图像引导点云补全任务，仅需部分点云输入且无需视图依赖。实验表明该方法优于现有技术。

- Motivation: 探索单视图图像引导在点云补全任务中的必要性，并提出一种无需图像输入的强基线方法。
- Method: 采用基于注意力的多分支编码器-解码器网络，结合层次自融合机制（交叉注意力和自注意力层）整合多流信息。
- Result: 在ShapeNet-ViPC数据集上的实验表明，该方法优于现有单视图图像引导点云补全方法。
- Conclusion: 研究为多模态学习在点云补全任务中的应用提供了新见解，且无需依赖图像输入。


### [2] [VLMInferSlow: Evaluating the Efficiency Robustness of Large Vision-Language Models as a Service](https://arxiv.org/abs/2506.15755)
*Xiasi Wang,Tianliang Yao,Simin Chen,Runqi Wang,Lei YE,Kuofeng Gao,Yi Huang,Yuan Yao*

Main category: cs.CV

TL;DR: 提出了一种名为VLMInferSlow的新方法，用于在现实黑盒设置中评估视觉语言模型（VLM）的效率鲁棒性。

- Motivation: 现有研究主要关注VLM的准确性，而效率问题未充分探索，且现有评估方法在现实场景中不实用。
- Method: VLMInferSlow结合了细粒度效率建模和零阶优化，以生成对抗性示例。
- Result: 实验表明，VLMInferSlow生成的对抗性图像可增加计算成本高达128.47%。
- Conclusion: 该研究旨在提高社区对VLM效率鲁棒性的关注。


### [3] [Weakly-supervised VLM-guided Partial Contrastive Learning for Visual Language Navigation](https://arxiv.org/abs/2506.15757)
*Ruoyu Wang,Tong Yu,Junda Wu,Yao Liu,Julian McAuley,Lina Yao*

Main category: cs.CV

TL;DR: 论文提出了一种弱监督部分对比学习（WPCL）方法，用于提升视觉语言导航（VLN）任务中代理的动态视角对象识别能力，无需微调预训练视觉语言模型（VLM），同时保持计算效率。

- Motivation: 现有VLN方法依赖预训练模型，但存在动态视角适应差、未微调模型性能有限、微调计算成本高的问题。
- Method: 提出WPCL方法，通过弱监督部分对比学习，将预训练VLM知识有效整合到感知过程中，无需微调。
- Result: 实验表明，WPCL在多个基准测试中优于基线方法，验证了其有效性、鲁棒性和泛化性。
- Conclusion: WPCL为VLN任务提供了一种高效且性能优越的解决方案，解决了现有方法的局限性。


### [4] [Implicit 3D scene reconstruction using deep learning towards efficient collision understanding in autonomous driving](https://arxiv.org/abs/2506.15806)
*Akarshani Ramanayake,Nihal Kodikara*

Main category: cs.CV

TL;DR: 本文提出了一种基于学习的方法，利用LiDAR数据和深度神经网络构建静态符号距离函数（SDF）地图，以解决密集交通环境中3D场景重建的边界精度问题。

- Motivation: 在密集城市交通环境中，现有技术难以精确导航，而3D场景重建的边界精度问题尚未完全解决。符号距离函数（SDF）因其高效存储特性成为潜在解决方案。
- Method: 结合LiDAR数据和深度神经网络，开发了一种学习型的3D场景重建方法，生成静态SDF地图，以替代传统的多边形表示。
- Result: 初步结果显示，该方法能显著提升碰撞检测性能，尤其在拥堵和动态环境中。
- Conclusion: 该方法为密集交通环境中的3D障碍物形状重建提供了更高边界精度的解决方案。


### [5] [ADAM-Dehaze: Adaptive Density-Aware Multi-Stage Dehazing for Improved Object Detection in Foggy Conditions](https://arxiv.org/abs/2506.15837)
*Fatmah AlHindaassi,Mohammed Talha Alam,Fakhri Karray*

Main category: cs.CV

TL;DR: ADAM-Dehaze是一种自适应去雾框架，通过动态路由和密度感知优化图像恢复和目标检测，显著提升性能。

- Motivation: 雾天严重影响视觉信息，对自动驾驶和监控系统等安全关键应用构成挑战。
- Method: 使用轻量级HDEN网络分类雾密度，动态路由至三个CORUN分支，结合自适应损失平衡物理模型和感知保真度。
- Result: 在Cityscapes和RTTS基准上，PSNR提升2.1 dB，FADE降低30%，目标检测mAP提升13点，推理时间减少20%。
- Conclusion: ADAM-Dehaze证明了强度特定处理和与下游视觉任务无缝集成的重要性。


### [6] [EchoShot: Multi-Shot Portrait Video Generation](https://arxiv.org/abs/2506.15838)
*Jiahao Wang,Hualian Sheng,Sijia Cai,Weizhan Zhang,Caixia Yan,Yachuang Feng,Bing Deng,Jieping Ye*

Main category: cs.CV

TL;DR: EchoShot是一个基于视频扩散模型的多镜头肖像定制框架，通过创新的位置嵌入机制和数据集支持，实现身份一致性和内容可控性。

- Motivation: 现有视频生成模型局限于单镜头创作，而实际应用需要多镜头且身份一致的视频生成。
- Method: 提出基于视频扩散变换器的镜头感知位置嵌入机制，并构建大规模数据集PortraitGala。
- Result: EchoShot在多镜头肖像视频生成中表现出卓越的身份一致性和属性级可控性。
- Conclusion: EchoShot为通用多镜头视频建模提供了潜在的基础范式。


### [7] [Assessing the impact of Binarization for Writer Identification in Greek Papyrus](https://arxiv.org/abs/2506.15852)
*Dominic Akt,Marco Peer,Florian Kleber*

Main category: cs.CV

TL;DR: 论文研究了希腊纸草文献的作者识别任务，重点分析了图像二值化预处理对模型性能的影响，比较了传统方法与深度学习模型的效果，并探讨了数据增强的作用。

- Motivation: 希腊纸草文献的背景复杂（不均匀、碎片化、变色且有纤维结构），传统二值化方法效果有限，需探索深度学习模型及其优化方法。
- Method: 比较传统二值化方法与深度学习模型，评估数据增强和模型选择标准的影响，并在DIBCO 2019数据集上测试性能。
- Result: 数据增强对深度学习模型效果显著，二值化质量与后续作者识别性能强相关。
- Conclusion: 深度学习结合数据增强在复杂背景的二值化任务中表现优异，对作者识别任务有重要影响。


### [8] [Privacy-Preserving in Connected and Autonomous Vehicles Through Vision to Text Transformation](https://arxiv.org/abs/2506.15854)
*Abdolazim Rezaei,Mehdi Sookhak,Ahmad Patooghy*

Main category: cs.CV

TL;DR: 本文提出了一种基于反馈强化学习和视觉语言模型的新框架，用于保护AI摄像头捕获的隐私敏感数据，将图像转换为语义等效的文本描述，显著提升了隐私保护和文本质量。

- Motivation: AI摄像头在CAV中广泛应用，但捕获的图像可能被滥用，传统隐私保护方法（如模糊处理）仍存在隐私泄露风险。
- Method: 采用反馈强化学习和视觉语言模型，将图像转换为语义等效的文本描述，并通过分层RL策略迭代优化文本生成。
- Result: 实验结果显示，隐私保护和文本质量显著提升，Unique Word Count增加约77%，Detail Density提升约50%。
- Conclusion: 该框架在保留场景信息的同时有效保护隐私，优于现有方法。


### [9] [Visual symbolic mechanisms: Emergent symbol processing in vision language models](https://arxiv.org/abs/2506.15871)
*Rim Assouel,Declan Campbell,Taylor Webb*

Main category: cs.CV

TL;DR: 研究发现视觉语言模型（VLMs）通过内容无关的空间索引机制解决特征绑定问题，并揭示了绑定错误的根源。

- Motivation: 探讨视觉语言模型是否采用类似语言模型的符号化机制解决特征绑定问题，以解释其在此类任务中的持续失败。
- Method: 识别并分析VLMs中支持绑定的内容无关空间索引机制。
- Result: 发现VLMs通过符号化机制实现绑定，且绑定错误源于这些机制的失效。
- Conclusion: 研究揭示了VLMs的符号化处理机制，为改善其绑定失败问题提供了方向。


### [10] [Pediatric Pancreas Segmentation from MRI Scans with Deep Learning](https://arxiv.org/abs/2506.15908)
*Elif Keles,Merve Yazol,Gorkem Durak,Ziliang Hong,Halil Ertugrul Aktas,Zheyuan Zhang,Linkai Peng,Onkar Susladkar,Necati Guzelyel,Oznur Leman Boyunaga,Cemal Yazici,Mark Lowe,Aliye Uc,Ulas Bagci*

Main category: cs.CV

TL;DR: PanSegNet是一种深度学习算法，用于儿童胰腺MRI分割，在健康和疾病状态下表现优异。

- Motivation: 评估和验证PanSegNet在儿童急性胰腺炎、慢性胰腺炎和健康对照中的胰腺分割效果。
- Method: 回顾性收集84例MRI扫描，手动分割胰腺后使用PanSegNet生成分割结果，通过DSC和HD95评估性能。
- Result: PanSegNet在健康儿童中DSC为88%，AP为81%，CP为80%，HD95分别为3.98mm、9.85mm和15.67mm，表现出高可靠性和一致性。
- Conclusion: PanSegNet是首个经过验证的胰腺MRI分割深度学习工具，性能达到专家水平，开源促进协作研究。


### [11] [MoiréXNet: Adaptive Multi-Scale Demoiréing with Linear Attention Test-Time Training and Truncated Flow Matching Prior](https://arxiv.org/abs/2506.15929)
*Liangyan Li,Yimo Ning,Kevin Le,Wei Dong,Yunzhe Li,Jun Chen,Xiaohong Liu*

Main category: cs.CV

TL;DR: 提出了一种结合MAP估计和深度学习的图像和视频去摩尔纹框架，通过混合方法解决了传统方法的局限性。

- Motivation: 传统监督学习方法无法完全去除摩尔纹或导致过度平滑，生成模型在非线性退化（如去摩尔纹）中表现不佳。
- Method: 提出混合MAP框架，结合监督学习模型（带线性注意力TTT模块）和TFMP先验，提升非线性映射和细节恢复能力。
- Result: 框架结合了线性注意力的计算效率和生成模型的细化能力，显著提升了恢复性能。
- Conclusion: 混合MAP框架有效解决了去摩尔纹中的非线性退化问题，实现了更好的图像恢复效果。


### [12] [Beyond Audio and Pose: A General-Purpose Framework for Video Synchronization](https://arxiv.org/abs/2506.15937)
*Yosub Shin,Igor Molybog*

Main category: cs.CV

TL;DR: VideoSync是一个独立于特定特征提取方法的视频同步框架，适用于多种场景，并通过新数据集和严格评估框架证明其优于现有方法。

- Motivation: 现有视频同步方法依赖音频或特定视觉事件，适用性受限；现有基准缺乏通用性和可重复性。
- Method: 提出VideoSync框架，不依赖特定特征提取方法，使用CNN模型预测同步偏移。
- Result: VideoSync在新数据集上表现优于现有方法，纠正了SeSyn-Net的偏差，并提供了可重复的基准。
- Conclusion: VideoSync提升了视频同步的通用性和鲁棒性，适用于现实应用。


### [13] [Polyline Path Masked Attention for Vision Transformer](https://arxiv.org/abs/2506.15940)
*Zhongchen Zhao,Chaodong Xiao,Hui Lin,Qi Xie,Lei Zhang,Deyu Meng*

Main category: cs.CV

TL;DR: 提出了一种结合ViTs自注意力机制和Mamba2结构化掩码的PPMA方法，通过改进的2D折线路径掩码建模空间邻接关系，在多个视觉任务中表现优异。

- Motivation: 结合ViTs的全局依赖建模能力和Mamba2的空间邻接先验建模能力，提升视觉任务的性能。
- Method: 改进Mamba2的结构化掩码为2D折线路径掩码，并将其嵌入ViTs的自注意力机制中。
- Result: 在ADE20K语义分割任务中，PPMA-T/S/B模型分别达到48.7%/51.1%/52.3% mIoU，优于现有方法。
- Conclusion: PPMA通过整合两种架构的优势，显著提升了视觉任务的性能。


### [14] [Heterogeneous-Modal Unsupervised Domain Adaptation via Latent Space Bridging](https://arxiv.org/abs/2506.15971)
*Jiawen Yang,Shuhao Chen,Yucong Duan,Ke Tang,Yu Zhang*

Main category: cs.CV

TL;DR: 本文提出了一种新的异构模态无监督域适应（HMUDA）设置，通过桥接域实现不同模态间的知识迁移，并设计了Latent Space Bridging（LSB）框架，用于语义分割任务，取得了最先进的性能。

- Motivation: 解决传统无监督域适应（UDA）方法在源域和目标域模态完全不同时的局限性。
- Method: 提出HMUDA设置，利用桥接域实现模态间知识迁移；设计LSB框架，采用双分支架构，结合特征一致性损失和域对齐损失。
- Result: 在六个基准数据集上的实验表明，LSB达到了最先进的性能。
- Conclusion: LSB框架在异构模态无监督域适应任务中表现优异，为跨模态知识迁移提供了有效解决方案。


### [15] [LBMamba: Locally Bi-directional Mamba](https://arxiv.org/abs/2506.15976)
*Jingwei Zhang,Xi Han,Hong Qin,Mahdi S. Hosseini,Dimitris Samaras*

Main category: cs.CV

TL;DR: LBMamba通过嵌入轻量级局部反向扫描到前向选择性扫描中，避免了传统双向扫描的计算开销，提高了效率。LBVim作为视觉骨干网络，交替扫描方向以恢复全局感受野，性能优于现有方法。

- Motivation: Mamba的单向性限制了其在计算机视觉中的应用，传统双向扫描方法虽能解决问题但计算成本高。
- Method: 提出LBMamba，将局部反向扫描嵌入前向选择性扫描中，并在寄存器中执行；基于此构建LBVim，交替扫描方向以恢复全局感受野。
- Result: LBVim在多个数据集上表现优异，ImageNet-1K分类、ADE20K分割、COCO检测等任务中均取得性能提升。在病理图像分类任务中，LBMamba集成到MambaMIL后，AUC、F1和准确率均有显著提高。
- Conclusion: LBMamba和LBVim在保持高效的同时，显著提升了性能，为计算机视觉任务提供了新的解决方案。


### [16] [Towards Classifying Histopathological Microscope Images as Time Series Data](https://arxiv.org/abs/2506.15977)
*Sungrae Hong,Hyeongmin Park,Youngsin Ko,Sol Lee,Bryan Wong,Mun Yong Yi*

Main category: cs.CV

TL;DR: 提出一种将显微镜图像作为时间序列数据分类的新方法，利用动态时间规整（DTW）和注意力池化，解决了手动采集和弱标签的挑战，并在性能和稳定性上优于基线方法。

- Motivation: 显微镜病理图像是癌症诊断的关键数据，但深度学习社区对其关注不足。本文旨在解决其手动采集和弱标签带来的独特挑战。
- Method: 将图像序列通过动态时间规整（DTW）拟合为固定长度，并采用注意力池化同时预测类别。
- Result: 方法在性能和稳定性上优于基线，并通过消融实验验证了各组件的贡献。
- Conclusion: 该方法不仅将显微镜图像纳入医学图像分析，还将其性能提升至可信水平。


### [17] [Advanced Sign Language Video Generation with Compressed and Quantized Multi-Condition Tokenization](https://arxiv.org/abs/2506.15980)
*Cong Wang,Zexuan Deng,Zhiwei Jiang,Fei Shen,Yafeng Yin,Shiwei Gan,Zifeng Cheng,Shiping Ge,Qing Gu*

Main category: cs.CV

TL;DR: SignViP是一种新的手语视频生成框架，通过多粒度条件提升生成质量，采用离散标记化和扩散模型实现高效生成。

- Motivation: 现有方法依赖单一粗糙条件（如骨架序列）作为翻译模型和视频生成模型的桥梁，限制了生成视频的自然性和表现力。
- Method: SignViP包含三个核心组件：1）联合训练的视频扩散模型和多条件编码器；2）FSQ自编码器压缩和量化嵌入；3）多条件标记翻译器将文本翻译为离散标记。
- Result: 实验表明，SignViP在视频质量、时间一致性和语义保真度方面达到最先进水平。
- Conclusion: SignViP通过多粒度条件和离散标记化显著提升了手语视频生成的质量和表现力。


### [18] [Adversarial Attacks and Detection in Visual Place Recognition for Safer Robot Navigation](https://arxiv.org/abs/2506.15988)
*Connor Malone,Owen Claxton,Iman Shames,Michael Milford*

Main category: cs.CV

TL;DR: 该论文分析了视觉地点识别（VPR）系统对抗性攻击的脆弱性，提出了一种结合对抗攻击检测器（AAD）的框架，显著提升了导航性能。

- Motivation: VPR系统在对抗性攻击下表现脆弱，可能导致机器人导航灾难性后果，因此需要研究防御方法。
- Method: 分析了四种常见对抗性攻击和四种VPR特有攻击，提出AAD框架，并通过实验验证其性能。
- Result: 实验显示AAD能显著降低定位误差（如沿轨误差减少50%），并探讨了FGSM攻击在VPR中的效果。
- Conclusion: AAD对提升VPR系统安全性至关重要，为实际系统设计提供了量化依据。


### [19] [DIGMAPPER: A Modular System for Automated Geologic Map Digitization](https://arxiv.org/abs/2506.16006)
*Weiwei Duan,Michael P. Gerlek,Steven N. Minton,Craig A. Knoblock,Fandel Lin,Theresa Chen,Leeje Jang,Sofia Kirsanova,Zekun Li,Yijun Lin,Yao-Yi Chiang*

Main category: cs.CV

TL;DR: DIGMAPPER是一个模块化、可扩展的系统，用于自动化地质图的数字化，结合深度学习模型和先进技术，显著提高了效率和准确性。

- Motivation: 地质图包含丰富的地理信息，但数字化过程耗时耗力，DIGMAPPER旨在解决这一问题。
- Method: 系统采用docker化、工作流协调的架构，结合深度学习模型（如布局分析、特征提取和地理配准），并利用上下文学习、合成数据生成和基于Transformer的模型。
- Result: 在100多张标注地图上测试显示，系统在多类特征提取和地理配准方面表现优异。
- Conclusion: DIGMAPPER已在美国地质调查局部署，显著加速了地理空间数据集的生成，支持国家关键矿物评估和更广泛的地学应用。


### [20] [EndoMUST: Monocular Depth Estimation for Robotic Endoscopy via End-to-end Multi-step Self-supervised Training](https://arxiv.org/abs/2506.16017)
*Liangjing Shao,Linxin Bai,Chenkang Du,Xinrong Chen*

Main category: cs.CV

TL;DR: 提出了一种多步微调框架，用于内窥镜场景中的自监督深度估计，解决了光照变化和纹理稀疏问题，并在SCARED和Hamlyn数据集上取得了最优性能。

- Motivation: 内窥镜场景中的光照变化和稀疏纹理对深度估计和自运动估计提出了挑战，现有方法在多模块训练策略上仍有不足。
- Method: 提出了一种多步高效微调框架，包括光流注册、多尺度图像分解和多变换对齐三个步骤，每个步骤仅训练相关网络以避免信息干扰。
- Result: 在SCARED数据集上实现了自监督深度估计的最优性能，在Hamlyn数据集上零样本深度估计误差降低了4%~10%。
- Conclusion: 该方法通过多步微调策略有效解决了内窥镜场景中的深度估计问题，性能显著提升。


### [21] [PAROAttention: Pattern-Aware ReOrdering for Efficient Sparse and Quantized Attention in Visual Generation Models](https://arxiv.org/abs/2506.16054)
*Tianchen Zhao,Ke Hong,Xinhao Yang,Xuefeng Xiao,Huixia Li,Feng Ling,Ruiqi Xie,Siqi Chen,Hongyu Zhu,Yichong Zhang,Yu Wang*

Main category: cs.CV

TL;DR: 提出了一种名为PARO的技术，通过重新组织注意力模式来降低视觉生成中的计算和内存成本，同时保持性能。

- Motivation: 解决视觉生成中注意力机制的二次复杂度问题，尤其是在高分辨率图像或多帧视频生成中，现有技术（如稀疏化和量化）在低密度和低比特宽度下面临挑战。
- Method: 设计了一种名为PARO的令牌重排序技术，将多样化的注意力模式统一为硬件友好的块状模式，从而简化和优化稀疏化与量化。
- Result: PAROAttention在视频和图像生成中实现了无损指标，性能接近全精度基线，同时显著降低了计算密度（20%-30%）和比特宽度（INT8/INT4），端到端延迟加速1.9x至2.7x。
- Conclusion: 通过重新组织注意力模式，PARO技术有效解决了视觉生成中的计算效率问题，为高分辨率内容生成提供了高效解决方案。


### [22] [Stepping Out of Similar Semantic Space for Open-Vocabulary Segmentation](https://arxiv.org/abs/2506.16058)
*Yong Liu,SongLi Wu,Sule Bai,Jiahao Wang,Yitong Wang,Yansong Tang*

Main category: cs.CV

TL;DR: 论文提出新基准OpenBench，评估开放词汇分割模型的真实理解能力，并开发OVSNet方法提升性能。

- Motivation: 现有测试集无法充分衡量模型对开放词汇概念的理解，因其语义空间与训练集相似。
- Method: 提出新基准OpenBench，设计OVSNet方法，通过异构特征融合和训练空间扩展提升性能。
- Result: OVSNet在现有数据集和OpenBench上均取得最优结果。
- Conclusion: OpenBench和OVSNet的有效性得到验证，为开放词汇分割提供新方向。


### [23] [STAR-Pose: Efficient Low-Resolution Video Human Pose Estimation via Spatial-Temporal Adaptive Super-Resolution](https://arxiv.org/abs/2506.16061)
*Yucheng Jin,Jinyan Chen,Ziyue He,Baojun Han,Furan An*

Main category: cs.CV

TL;DR: STAR-Pose是一个针对低分辨率视频中人体姿态估计的时空自适应超分辨率框架，通过改进的Transformer和自适应融合模块提升性能。

- Motivation: 低分辨率视频中的人体姿态估计存在挑战，传统方法要么依赖高质量输入，要么计算成本高，难以在资源受限环境中部署。
- Method: 提出STAR-Pose框架，结合时空Transformer和CNN分支，设计任务导向的损失函数。
- Result: 在多个数据集上表现优异，低分辨率条件下mAP提升5.2%，推理速度比级联方法快2.8-4.4倍。
- Conclusion: STAR-Pose在低分辨率视频姿态估计中高效且性能优越。


### [24] [TD3Net: A Temporal Densely Connected Multi-Dilated Convolutional Network for Lipreading](https://arxiv.org/abs/2506.16073)
*Byung Hoon Lee,Wooseok Shin,Sung Won Han*

Main category: cs.CV

TL;DR: 提出了一种名为TD3Net的新后端架构，结合密集跳跃连接和多扩张时间卷积，用于改进唇读任务中的时间建模。

- Motivation: 现有TCN方法在建模唇部连续运动时存在盲点，导致信息丢失，限制了性能。
- Method: 提出TD3Net，结合密集跳跃连接和多扩张时间卷积，覆盖更广且无盲点的感受野。
- Result: 在两个大型数据集（LRW和LRW-1000）上表现优异，参数和计算量更少。
- Conclusion: TD3Net有效利用了多样时间特征并保持连续性，在唇读系统中具有显著优势。


### [25] [PR-DETR: Injecting Position and Relation Prior for Dense Video Captioning](https://arxiv.org/abs/2506.16082)
*Yizhe Li,Sanping Zhou,Zheng Qin,Le Wang*

Main category: cs.CV

TL;DR: PR-DETR框架通过显式位置和关系先验改进密集视频描述任务，提升事件定位和描述生成性能。

- Motivation: 现有基于Transformer的方法隐式学习事件位置和语义，依赖大量数据且性能受限。
- Method: 提出PR-DETR，引入位置锚定查询和事件关系编码器，显式提供位置和关系先验。
- Result: 在ActivityNet Captions和YouCook2数据集上表现优异，验证了位置和关系先验的有效性。
- Conclusion: 显式位置和关系先验显著提升密集视频描述任务的性能。


### [26] [AutoV: Learning to Retrieve Visual Prompt for Large Vision-Language Models](https://arxiv.org/abs/2506.16112)
*Yuan Zhang,Chun-Kai Fan,Tao Huang,Ming Lu,Sicheng Yu,Junwen Pan,Kuan Cheng,Qi She,Shanghang Zhang*

Main category: cs.CV

TL;DR: AutoV是一种自动选择最优视觉提示的方法，通过训练模型从多个候选提示中选择最佳选项，显著提升了大型视觉语言模型的性能。

- Motivation: 现有手动设计视觉提示的方法效率低且性能不佳，需要一种自动化方法来优化提示选择。
- Method: 提出AutoV，通过自动数据收集和标注流程，训练模型基于文本查询和输入图像选择最佳视觉提示。
- Result: 实验表明，AutoV显著提升了多个LVLM的性能，例如LLaVA-OV和Qwen2.5-VL的准确率分别提高了1.7%和1.9%。
- Conclusion: AutoV是一种高效的视觉提示优化方法，具有广泛的应用潜力。


### [27] [FastInit: Fast Noise Initialization for Temporally Consistent Video Generation](https://arxiv.org/abs/2506.16119)
*Chengyu Bai,Yuming Li,Zhongyu Zhao,Jintao Chen,Peidong Jia,Qi She,Ming Lu,Shanghang Zhang*

Main category: cs.CV

TL;DR: FastInit提出了一种快速噪声初始化方法，通过单次前向传播生成高质量视频噪声，显著提升生成效率和时序一致性。

- Motivation: 现有方法（如FreeInit）通过迭代优化噪声提高视频生成质量，但计算成本高。FastInit旨在解决这一问题。
- Method: FastInit训练了一个视频噪声预测网络（VNPNet），输入随机噪声和文本提示，单次生成优化后的噪声。
- Result: 实验表明，FastInit显著提升了视频生成的质量和时序一致性，且计算效率更高。
- Conclusion: FastInit为视频生成提供了一种高效且实用的解决方案，可直接应用于推理阶段。


### [28] [Neurosymbolic Object-Centric Learning with Distant Supervision](https://arxiv.org/abs/2506.16129)
*Stefano Colamonaco,David Debot,Giuseppe Marra*

Main category: cs.CV

TL;DR: 提出了一种名为DeepObjectLog的神经符号模型，直接从原始非结构化感知数据中学习对象中心表示，仅需远程监督，并在多种泛化场景中优于基线方法。

- Motivation: 现有系统依赖对象级监督或预定义的对象分解，限制了模型的泛化能力。
- Method: 结合感知模块（提取对象表示）和基于概率逻辑编程的符号推理层，通过概率逻辑推理引入新的学习信号。
- Result: 在未见过的对象组合、任务和对象数量等泛化场景中，模型表现优于神经和神经符号基线方法。
- Conclusion: DeepObjectLog通过神经符号方法有效学习对象中心表示，提升了泛化能力。


### [29] [GRPO-CARE: Consistency-Aware Reinforcement Learning for Multimodal Reasoning](https://arxiv.org/abs/2506.16141)
*Yi Chen,Yuying Ge,Rui Wang,Yixiao Ge,Junhao Cheng,Ying Shan,Xihui Liu*

Main category: cs.CV

TL;DR: 论文提出了GRPO-CARE，一种一致性感知的强化学习框架，用于提升多模态大语言模型（MLLMs）的答案正确性和推理连贯性，并通过SEED-Bench-R1基准验证其有效性。

- Motivation: 现有方法（如GRPO）在MLLMs中虽能提升答案准确性，但忽略了推理步骤与答案的逻辑一致性，且缺乏严格的评估基准。
- Method: 提出GRPO-CARE框架，采用双层奖励机制：基础奖励（答案正确性）和自适应一致性奖励（推理连贯性），替代KL惩罚。
- Result: GRPO-CARE在SEED-Bench-R1上表现优于标准GRPO，性能提升6.7%，一致性提高24.5%，并展示出强迁移能力。
- Conclusion: GRPO-CARE为MLLMs提供了一种可泛化的后训练框架，推动了更可解释和鲁棒的MLLMs发展。


### [30] [MBA: Multimodal Bidirectional Attack for Referring Expression Segmentation Models](https://arxiv.org/abs/2506.16157)
*Xingbai Chen,Tingchao Fu,Renyang Liu,Wei Zhou,Chao Yi*

Main category: cs.CV

TL;DR: 提出了一种针对RES模型的多模态双向攻击方法，通过联合优化图像和文本模态，增强对抗样本的跨文本迁移能力。

- Motivation: RES模型在多模态场景下的对抗鲁棒性尚未充分研究，现有攻击方法难以暴露其多模态结构的脆弱性。
- Method: 引入可学习的代理文本嵌入扰动，联合进行视觉对齐优化和文本对抗优化。
- Result: 实验表明，该方法在多个RES模型和数据集上优于现有方法。
- Conclusion: 提出的多模态双向攻击方法有效提升了对抗样本的跨文本迁移能力。


### [31] [Co-Speech Gesture and Facial Expression Generation for Non-Photorealistic 3D Characters](https://arxiv.org/abs/2506.16159)
*Taisei Omine,Naoyuki Kawabata,Fuminori Homma*

Main category: cs.CV

TL;DR: 研究提出了一种为非写实角色（如动漫角色）设计情感表达的方法，包括夸张表情和语义手势，效果显著优于现有研究。

- Motivation: 现有研究多关注写实化虚拟角色，缺乏对非写实角色（如动漫角色）情感表达的支持。
- Method: 利用漫画中的表情数据和对话特定语义手势，设计情感表达方法。
- Result: 用户研究表明，该方法在多个方面显著优于现有研究。
- Conclusion: 该方法为非写实角色的情感表达提供了有效解决方案。


### [32] [Align the GAP: Prior-based Unified Multi-Task Remote Physiological Measurement Framework For Domain Generalization and Personalization](https://arxiv.org/abs/2506.16160)
*Jiyao Wang,Xiao Yang,Hao Lu,Dengbo He,Kaishun Wu*

Main category: cs.CV

TL;DR: 论文提出了一种统一框架GAP，用于多源语义域泛化（MSSDG）和测试时个性化适应（TTPA），通过分解面部视频信息并结合先验知识，实现了多任务远程生理测量的泛化和个性化。

- Motivation: 解决多任务远程生理测量中部分标注和环境噪声对任务特定准确性的干扰，以及泛化与个性化方法之间的融合难题。
- Method: 将面部视频信息分解为不变语义、个体偏差和噪声，结合先验知识设计多模块框架，分别处理泛化和个性化需求。
- Result: 在六个公开数据集和新引入的真实驾驶数据集上验证了框架的有效性。
- Conclusion: GAP框架能够同时处理MSSDG和TTPA，且调整最小，代码和新数据集将公开。


### [33] [Integrating Generative Adversarial Networks and Convolutional Neural Networks for Enhanced Traffic Accidents Detection and Analysis](https://arxiv.org/abs/2506.16186)
*Zhenghao Xi,Xiang Liu,Yaqi Liu,Yitong Cai,Yangyu Zheng*

Main category: cs.CV

TL;DR: 该研究利用深度学习技术（GANs和CNN）解决交通事故检测中的数据不足问题，通过合成数据和模型训练，实现了高精度的实时事故检测。

- Motivation: 全球交通事故数量上升，需要智能、高效的自动化事故检测系统以挽救生命。
- Method: 结合GANs生成合成数据，使用CNN、FTCNN和VIT模型训练，从YouTube视频中收集并处理事故与非事故帧。
- Result: FTCNN和VIT模型分别达到94%和95%的准确率，CNN为88%，证明框架适用于实时交通监控。
- Conclusion: 该框架为未来智能监控系统奠定了基础，可应用于实时交通监控和智慧城市框架。


### [34] [VideoGAN-based Trajectory Proposal for Automated Vehicles](https://arxiv.org/abs/2506.16209)
*Annajoyce Mariani,Kira Maag,Hanno Gottschalk*

Main category: cs.CV

TL;DR: 论文提出了一种基于GAN的方法，通过鸟瞰视角视频生成真实的多模态轨迹，解决了传统方法难以捕捉复杂分布的问题。

- Motivation: 传统方法（如模型驱动、规则基础或经典学习）难以有效捕捉未来轨迹的复杂多模态分布，因此需要更高效的方法。
- Method: 使用低分辨率鸟瞰视角占用网格视频训练GAN，从中提取抽象轨迹数据，并通过单帧检测和帧间匹配实现。
- Result: 在100 GPU小时内完成训练，推理时间低于20毫秒，生成的轨迹在空间和动态参数上与真实数据分布一致。
- Conclusion: GAN方法能高效生成物理真实的轨迹，适用于自动驾驶场景。


### [35] [FOCoOp: Enhancing Out-of-Distribution Robustness in Federated Prompt Learning for Vision-Language Models](https://arxiv.org/abs/2506.16218)
*Xinting Liao,Weiming Liu,Jiaming Qian,Pengyang Zhou,Jiahe Xu,Wenjie Wang,Chaochao Chen,Xiaolin Zheng,Tat-Seng Chua*

Main category: cs.CV

TL;DR: FOCoOp框架通过全局、局部和OOD提示优化联邦提示学习，解决性能与鲁棒性权衡问题。

- Motivation: 现有联邦提示学习方法在OOD偏移下性能与鲁棒性难以平衡，且数据异构性加剧挑战。
- Method: 提出FOCoOp框架，利用三类提示和双层分布鲁棒优化，结合半不平衡最优传输校准提示。
- Result: 实验表明FOCoOp能有效捕捉异构分布并提升OOD鲁棒性。
- Conclusion: FOCoOp为联邦学习中的OOD问题提供了高效解决方案。


### [36] [R3eVision: A Survey on Robust Rendering, Restoration, and Enhancement for 3D Low-Level Vision](https://arxiv.org/abs/2506.16262)
*Weeyoung Kwon,Jeahun Sung,Minkyu Jeon,Chanho Eom,Jihyong Oh*

Main category: cs.CV

TL;DR: 该论文综述了3D低层视觉（3D LLV）领域，探讨了如何将2D低层视觉任务（如超分辨率、去模糊等）扩展到3D空间，以解决神经渲染方法在真实世界退化条件下的局限性。

- Motivation: 现有神经渲染方法（如NeRF和3DGS）通常假设输入为干净高分辨率的多视图图像，但在实际应用中常面临噪声、模糊、低分辨率等问题，限制了其鲁棒性。
- Method: 论文通过形式化退化感知渲染问题，总结了3D LLV的关键挑战（如时空一致性和病态优化），并分类了将低层视觉任务集成到神经渲染框架中的方法。
- Result: 研究展示了这些方法如何在恶劣条件下实现高保真3D重建，并讨论了在自动驾驶、AR/VR等领域的应用。
- Conclusion: 3D LLV是真实环境中鲁棒3D内容生成和场景级重建的重要方向，论文通过综述代表性方法、数据集和评估协议，为该领域提供了全面指导。


### [37] [Dense 3D Displacement Estimation for Landslide Monitoring via Fusion of TLS Point Clouds and Embedded RGB Images](https://arxiv.org/abs/2506.16265)
*Zhaoyi Wang,Jemil Avers Butt,Shengyu Huang,Tomislav Medic,Andreas Wieser*

Main category: cs.CV

TL;DR: 提出了一种融合3D点云和RGB图像的分层分区方法，用于估计密集3D位移矢量场，提高了滑坡监测的空间覆盖率和精度。

- Motivation: 现有方法通常仅依赖几何或辐射信息，导致稀疏或非3D位移估计，无法满足滑坡监测需求。
- Method: 采用分层分区从粗到细的方法，结合3D几何和2D图像特征构建匹配，并通过几何一致性检查和刚性变换估计进行优化。
- Result: 在两个真实滑坡数据集上，方法实现了高空间覆盖率（79%和97%）和高精度（位移偏差分别为0.15m和0.25m）。
- Conclusion: 该方法为基于TLS的滑坡监测提供了实用且适应性强的解决方案，并可扩展至其他点云和监测任务。


### [38] [Fine-grained Image Retrieval via Dual-Vision Adaptation](https://arxiv.org/abs/2506.16273)
*Xin Jiang,Meiqi Cao,Hao Tang,Fei Shen,Zechao Li*

Main category: cs.CV

TL;DR: 提出了一种双视觉适应（DVA）方法，通过样本和特征适应提升细粒度图像检索（FGIR）性能，避免过拟合并保留预训练知识。

- Motivation: 现有FGIR方法容易过拟合训练数据，遗忘预训练知识，导致泛化能力下降。
- Method: 设计了对象感知适应和上下文适应，分别调整输入样本和特征，同时引入判别感知迁移平衡检索效率与性能。
- Result: DVA在三个分布内和三个分布外细粒度数据集上表现优异，且参数较少。
- Conclusion: DVA通过双适应机制有效提升了FGIR的泛化能力和性能。


### [39] [SycnMapV2: Robust and Adaptive Unsupervised Segmentation](https://arxiv.org/abs/2506.16297)
*Heng Zhang,Zikang Wan,Danilo Vasconcellos Vargas*

Main category: cs.CV

TL;DR: SyncMapV2是一种无监督分割算法，具有卓越的鲁棒性，无需重新初始化即可在线适应输入，性能接近人类视觉。

- Motivation: 现有AI算法在噪声增加时性能下降严重，而人类视觉无需显式训练即可分割视觉线索且鲁棒性强。
- Method: 基于自组织动力学方程和随机网络概念的学习范式，无需鲁棒训练、监督或损失函数。
- Result: 在数字噪声、天气和模糊等干扰下，SyncMapV2的mIoU下降极小（0.01%），远超现有方法（下降23.8%）。
- Conclusion: SyncMapV2首次实现了在线适应性，为未来鲁棒自适应智能的发展奠定了基础。


### [40] [Learning Multi-scale Spatial-frequency Features for Image Denoising](https://arxiv.org/abs/2506.16307)
*Xu Zhao,Chen Zhao,Xiantao Hu,Hongliang Zhang,Ying Tai,Jian Yang*

Main category: cs.CV

TL;DR: 提出了一种新型多尺度自适应双域网络（MADNet），用于图像去噪，通过图像金字塔输入和自适应空间频率学习单元（ASFU）实现高频和低频信息的交互，性能优于现有方法。

- Motivation: 现有方法依赖固定单输入单输出的Unet架构，忽略了像素级多尺度表示，且对频域处理过于统一，未区分高频和低频噪声的特性。
- Method: 使用图像金字塔输入，设计ASFU单元通过可学习掩码分离高频和低频信息，并在跳跃连接中设计全局特征融合块增强多尺度特征。
- Result: 在合成和真实噪声图像数据集上的实验验证了MADNet的有效性，性能优于当前最先进的去噪方法。
- Conclusion: MADNet通过多尺度自适应双域设计，显著提升了图像去噪性能。


### [41] [Segment Anything for Satellite Imagery: A Strong Baseline and a Regional Dataset for Automatic Field Delineation](https://arxiv.org/abs/2506.16318)
*Carmelo Scribano,Elena Govi,Paolo bertellini,Simone Parisi,Giorgia Franchini,Marko Bertogna*

Main category: cs.CV

TL;DR: 本文提出了一种基于Segment Anything Model（SAM）的农田边界自动提取方法，通过微调策略适应任务，并补充了一个新的区域数据集ERAS。

- Motivation: 农田边界精确测绘对农业高效运营至关重要，传统地面调查成本高，需通过计算机视觉技术从高分辨率卫星图像中自动提取。
- Method: 基于SAM模型，引入微调策略，并开发了补充区域数据集ERAS。
- Result: 实验验证了分割准确性和泛化能力，为自动化农田边界提取提供了稳健基准。
- Conclusion: 该方法有效，新数据集ERAS已公开。


### [42] [RealDriveSim: A Realistic Multi-Modal Multi-Task Synthetic Dataset for Autonomous Driving](https://arxiv.org/abs/2506.16319)
*Arpit Jadon,Haoran Wang,Phillip Thomas,Michael Stanley,S. Nathaniel Cibik,Rachel Laurat,Omar Maher,Lukas Hoyer,Ozan Unal,Dengxin Dai*

Main category: cs.CV

TL;DR: RealDriveSim是一个多模态合成数据集，用于自动驾驶，支持2D计算机视觉和LiDAR应用，提供64类精细标注，性能优于现有合成基准。

- Motivation: 解决大规模数据标注成本高、现有合成数据集范围有限和真实感不足的问题。
- Method: 开发RealDriveSim数据集，支持多模态应用，并提供精细标注。
- Result: 在多种应用和领域中表现优异，达到最先进水平。
- Conclusion: RealDriveSim为自动驾驶研究提供了高效、低成本的数据解决方案。


### [43] [Reliable Few-shot Learning under Dual Noises](https://arxiv.org/abs/2506.16330)
*Ji Zhang,Jingkuan Song,Lianli Gao,Nicu Sebe,Heng Tao Shen*

Main category: cs.CV

TL;DR: DETA++提出了一种噪声鲁棒的任务适应方法，通过对比相关性聚合和局部最近质心分类器解决少样本学习中的噪声问题。

- Motivation: 现有方法在开放世界中可能因支持样本和查询样本中的分布内外噪声而失效，DETA++旨在解决这一问题。
- Method: 使用对比相关性聚合模块计算支持样本权重，提出干净原型损失和噪声熵最大化损失，并采用内存库和局部最近质心分类器。
- Result: 实验证明DETA++在噪声环境下具有高效性和灵活性。
- Conclusion: DETA++通过噪声鲁棒的任务适应和预测机制，显著提升了少样本学习的可靠性。


### [44] [Transparency Techniques for Neural Networks trained on Writer Identification and Writer Verification](https://arxiv.org/abs/2506.16331)
*Viktoria Pundy,Marco Peer,Florian Kleber*

Main category: cs.CV

TL;DR: 论文研究了神经网络在笔迹识别和验证中的透明度问题，首次应用了两种透明度技术，并评估其效果。

- Motivation: 提高神经网络在笔迹识别和验证中的透明度和可靠性，支持法医专家分析手写文本的相似性。
- Method: 应用两种透明度技术：像素级显著性图和点特异性显著性图，并通过删除和插入评分指标进行评估。
- Result: 像素级显著性图优于点特异性显著性图，适合支持法医专家的工作。
- Conclusion: 像素级显著性图在笔迹识别和验证中具有更高的实用性和透明度。


### [45] [MambaHash: Visual State Space Deep Hashing Model for Large-Scale Image Retrieval](https://arxiv.org/abs/2506.16353)
*Chao He,Hongxi Wei*

Main category: cs.CV

TL;DR: MambaHash是一种基于视觉状态空间的哈希模型，用于大规模图像检索，结合了分组Mamba操作和通道交互注意力模块，显著提升了性能。

- Motivation: 探索Mamba在大规模图像检索任务中的适用性，并提出一种高效的哈希模型。
- Method: 提出分阶段的主干网络，引入分组Mamba操作和多方向扫描，结合通道交互注意力模块和自适应特征增强模块。
- Result: 在CIFAR-10、NUS-WIDE和IMAGENET数据集上表现优于现有深度哈希方法。
- Conclusion: MambaHash在效率和性能上均表现出色，适用于大规模图像检索任务。


### [46] [Prompt-based Dynamic Token Pruning to Guide Transformer Attention in Efficient Segmentation](https://arxiv.org/abs/2506.16369)
*Pallabi Dutta,Anubhab Maity,Sushmita Mitra*

Main category: cs.CV

TL;DR: 提出一种自适应提示引导的剪枝方法，减少ViTs处理医学图像时的计算负担，提升效率。

- Motivation: ViTs处理大量token的高计算需求限制了其在医学图像分析中的实际应用。
- Method: 通过提示引导的空间先验对token进行相关性排序，剪枝低相关性token，保留高相关性token进行后续处理。
- Result: 实验显示token减少35-55%，计算成本降低，同时保持分割精度。
- Conclusion: 该方法提升了计算效率，适用于资源受限环境，促进实时诊断。


### [47] [AGC-Drive: A Large-Scale Dataset for Real-World Aerial-Ground Collaboration in Driving Scenarios](https://arxiv.org/abs/2506.16371)
*Yunhao Hou,Bochao Zou,Min Zhang,Ran Chen,Shangdong Yang,Yanmei Zhang,Junbao Zhuo,Siheng Chen,Jiansheng Chen,Huimin Ma*

Main category: cs.CV

TL;DR: AGC-Drive是首个大规模真实世界数据集，用于空中-地面协作3D感知，填补了无人机视角在协作感知中的空白。

- Motivation: 现有研究多关注车与车或车与基础设施的协作，而无人机提供的动态俯视视角能显著缓解遮挡问题，但缺乏高质量数据集支持。
- Method: 通过两辆装备多摄像头和LiDAR的车辆及一架无人机收集数据，覆盖14种驾驶场景，包含120K LiDAR帧和440K图像。
- Result: 数据集包含400个场景，13类物体的3D标注，并提供了两种协作感知任务的基准测试。
- Conclusion: AGC-Drive填补了空中-地面协作感知数据集的空白，并提供了开源工具支持未来研究。


### [48] [CLIP-MG: Guiding Semantic Attention with Skeletal Pose Features and RGB Data for Micro-Gesture Recognition on the iMiGUE Dataset](https://arxiv.org/abs/2506.16385)
*Santosh Patapati,Trisanth Srinivasan,Amith Adiraju*

Main category: cs.CV

TL;DR: 提出了一种基于CLIP的微手势识别模型CLIP-MG，结合姿态信息和多模态融合，在iMiGUE数据集上达到61.82%的Top-1准确率。

- Motivation: 微手势因动作细微且不自主，识别难度大，需改进现有方法。
- Method: 结合姿态引导的语义查询生成和门控多模态融合机制，改进CLIP模型。
- Result: Top-1准确率为61.82%，显示模型潜力但仍存挑战。
- Conclusion: CLIP-MG展示了改进CLIP用于微手势识别的潜力，但仍有提升空间。


### [49] [HyperPath: Knowledge-Guided Hyperbolic Semantic Hierarchy Modeling for WSI Analysis](https://arxiv.org/abs/2506.16398)
*Peixiang Huang,Yanyan Huang,Weiqin Zhao,Junjun He,Lequan Yu*

Main category: cs.CV

TL;DR: 论文提出HyperPath方法，利用双曲空间建模WSI的语义层次结构，结合视觉和文本特征，提升WSI分类性能。

- Motivation: 现有方法主要依赖欧几里得嵌入，难以充分捕捉WSI的语义层次结构。
- Method: 通过双曲空间整合视觉和文本特征，设计了角度模态对齐损失和语义层次一致性损失，利用测地距离进行分类。
- Result: 实验表明，该方法在多个任务上优于现有方法。
- Conclusion: 双曲嵌入在WSI分析中具有潜力。


### [50] [Robustness Evaluation of OCR-based Visual Document Understanding under Multi-Modal Adversarial Attacks](https://arxiv.org/abs/2506.16407)
*Dong Nguyen Tien,Dung D. Le*

Main category: cs.CV

TL;DR: 该论文提出了首个统一框架，用于生成和评估基于OCR的视觉文档理解（VDU）模型的多模态对抗攻击，覆盖六种梯度布局攻击场景，并通过实验验证了攻击效果。

- Motivation: 探索VDU系统在现实对抗扰动下的鲁棒性，填补了该领域的研究空白。
- Method: 采用梯度布局攻击方法，包括OCR边界框、像素和文本的操纵，约束布局扰动预算以保持合理性。
- Result: 实验表明，行级攻击和复合扰动（BBox + Pixel + Text）对性能影响最大，PGD-based BBox扰动优于随机基线。
- Conclusion: 研究验证了布局预算、文本修改和对抗可迁移性的重要性，为VDU系统的鲁棒性提供了新见解。


### [51] [Efficient Transformations in Deep Learning Convolutional Neural Networks](https://arxiv.org/abs/2506.16418)
*Berk Yilmaz,Daniel Fidel Harvey,Prajit Dhuri*

Main category: cs.CV

TL;DR: 研究探讨了在ResNet50 CNN模型中集成FFT、WHT和DCT信号处理变换对图像分类的影响，发现WHT显著降低能耗并提高准确率。

- Motivation: 评估信号处理变换在CNN中的计算效率、能耗和分类准确率之间的权衡，特别是针对能源受限的应用场景。
- Method: 在ResNet50模型中集成FFT、WHT和DCT，使用CIFAR-100数据集进行实验，比较不同变换的性能。
- Result: WHT在早期卷积层中应用时，准确率提升至74%，能耗降至39 kJ；在更多层应用时，准确率达79%。
- Conclusion: WHT是一种高效且有效的方法，适用于能源受限的CNN应用。


### [52] [Structured Semantic 3D Reconstruction (S23DR) Challenge 2025 -- Winning solution](https://arxiv.org/abs/2506.16421)
*Jan Skvrna,Lukas Neumann*

Main category: cs.CV

TL;DR: 本文介绍了S23DR Challenge 2025的获胜方案，通过3D深度学习方法从稀疏点云和语义分割预测房屋的3D屋顶线框。

- Motivation: 解决从稀疏点云和语义分割中预测房屋3D屋顶线框的挑战。
- Method: 直接在3D空间中操作，首先利用Gestalt分割从COLMAP点云识别顶点候选，然后使用两个PointNet-like模型：一个用于通过分析局部立方体块来细化和分类顶点候选，另一个用于通过处理连接顶点对的圆柱区域来预测边缘。
- Result: 在私有排行榜上获得了0.43的混合结构分数（HSS），赢得了比赛。
- Conclusion: 提出的两阶段3D深度学习方法在预测3D屋顶线框任务中表现优异。


### [53] [How Far Can Off-the-Shelf Multimodal Large Language Models Go in Online Episodic Memory Question Answering?](https://arxiv.org/abs/2506.16450)
*Giuseppe Lando,Rosario Forte,Giovanni Maria Farinella,Antonino Furnari*

Main category: cs.CV

TL;DR: 研究探讨现成的多模态大语言模型（MLLMs）能否无需额外训练即可处理在线情景记忆视频问答（OEM-VQA）。通过将流式自我中心视频转换为轻量级文本记忆，仅需几千字节每分钟，并通过LLM推理模块回答问题。在QAEgo4D-Closed基准上，最佳配置达到56.0%准确率，存储效率比现有专用系统高10^4/10^5倍。

- Motivation: 探索现成MLLMs在OEM-VQA任务中的潜力，避免额外训练成本。
- Method: 将流式视频转换为轻量级文本记忆，结合MLLM描述模块和LLM推理模块回答问题。
- Result: 在QAEgo4D-Closed基准上达到56.0%准确率，存储效率显著提升。
- Conclusion: 现成MLLMs在OEM-VQA任务中表现优异，存储效率高，为未来研究提供改进方向。


### [54] [Spotting tell-tale visual artifacts in face swapping videos: strengths and pitfalls of CNN detectors](https://arxiv.org/abs/2506.16497)
*Riccardo Ziglio,Cecilia Pasquini,Silvio Ranise*

Main category: cs.CV

TL;DR: 论文研究了基于CNN的数据驱动模型在视频流中检测面部交换操作的有效性，发现其在同一数据源下表现优异，但在跨数据集时难以鲁棒地捕捉遮挡相关的视觉线索。

- Motivation: 面部交换操作在视频通信中构成威胁，需要有效检测方法。
- Method: 通过基准测试CNN模型在两个数据集（包括一个新收集的）上，分析其对不同采集源和交换算法的泛化能力。
- Result: CNN模型在同一数据源下表现优异，但在跨数据集时难以捕捉遮挡线索。
- Conclusion: 需要专门策略来检测遮挡相关的视觉线索。


### [55] [Hunyuan3D 2.5: Towards High-Fidelity 3D Assets Generation with Ultimate Details](https://arxiv.org/abs/2506.16504)
*Zeqiang Lai,Yunfei Zhao,Haolin Liu,Zibo Zhao,Qingxiang Lin,Huiwen Shi,Xianghui Yang,Mingxin Yang,Shuhui Yang,Yifei Feng,Sheng Zhang,Xin Huang,Di Luo,Fan Yang,Fang Yang,Lifu Wang,Sicong Liu,Yixuan Tang,Yulin Cai,Zebin He,Tian Liu,Yuhong Liu,Jie Jiang,Linus,Jingwei Huang,Chunchao Guo*

Main category: cs.CV

TL;DR: Hunyuan3D 2.5是一个强大的3D扩散模型套件，用于生成高保真和细节丰富的3D资产。它在形状和纹理生成方面均有显著改进，包括引入新的形状基础模型LATTICE和升级的基于物理的渲染（PBR）技术。

- Motivation: 旨在提升3D资产的生成质量，缩小生成与手工制作3D形状之间的差距。
- Method: 采用两阶段流程，包括形状生成（使用10B参数的LATTICE模型）和纹理生成（基于多视图架构的PBR技术）。
- Result: 在形状和端到端纹理生成方面显著优于之前的方法。
- Conclusion: Hunyuan3D 2.5在3D资产生成领域取得了重要进展，为高质量3D内容生成提供了有效工具。


### [56] [How Hard Is Snow? A Paired Domain Adaptation Dataset for Clear and Snowy Weather: CADC+](https://arxiv.org/abs/2506.16531)
*Mei Qi Tang,Sean Sedwards,Chengjie Huang,Krzysztof Czarnecki*

Main category: cs.CV

TL;DR: CADC+是一个针对自动驾驶的配对天气域适应数据集，用于研究降雪对3D物体检测性能的影响。

- Motivation: 现有数据集在降雪和晴朗天气条件下的标注数据不足，或依赖不真实的合成数据，导致评估不准确。
- Method: 通过扩展CADC数据集，配对降雪和晴朗天气序列，最小化与降雪无关的域偏移。
- Result: 初步结果显示，降雪同时引入了噪声和新的数据域，增加了不确定性。
- Conclusion: CADC+为研究降雪对3D物体检测的影响提供了更真实的数据基础。


### [57] [From Semantic To Instance: A Semi-Self-Supervised Learning Approach](https://arxiv.org/abs/2506.16563)
*Keyhan Najafian,Farhad Maleki,Lingling Jin,Ian Stavness*

Main category: cs.CV

TL;DR: 提出了一种半自监督学习方法GLMask，用于实例分割，减少手动标注需求，在农业和通用数据集上表现优异。

- Motivation: 实例分割在农业等领域需要大量标注数据，但密集遮挡对象增加了标注难度，限制了深度学习应用。
- Method: 设计GLMask图像-掩码表示，减少对颜色特征的依赖，生成语义分割并转为实例分割。
- Result: 在小麦头实例分割上达到98.5% mAP@50，在COCO数据集上提升12.6% mAP@50。
- Conclusion: 该方法不仅适用于农业，还可推广到其他类似数据特征的领域。


### [58] [SafeTriage: Facial Video De-identification for Privacy-Preserving Stroke Triage](https://arxiv.org/abs/2506.16578)
*Tongan Cai,Haomiao Ni,Wenchao Ma,Yuan Xue,Qian Ma,Rachel Leicht,Kelvin Wong,John Volpi,Stephen T. C. Wong,James Z. Wang,Sharon X. Huang*

Main category: cs.CV

TL;DR: SafeTriage是一种新方法，通过去识别化患者面部视频保留关键运动特征，解决AI模型依赖真实患者数据的隐私和伦理问题。

- Motivation: 解决AI模型在卒中分诊中依赖真实患者数据带来的隐私和伦理挑战。
- Method: 利用预训练的视频运动转移模型将患者面部运动特征映射到合成身份上，结合条件生成模型调整输入空间。
- Result: 合成视频有效保留卒中相关面部模式，同时提供强隐私保护，保持诊断准确性。
- Conclusion: SafeTriage为神经疾病数据共享和AI临床分析提供了安全且伦理合规的基础。


### [59] [Spatially-Aware Evaluation of Segmentation Uncertainty](https://arxiv.org/abs/2506.16589)
*Tal Zeevi,Eléonore V. Lieffrig,Lawrence H. Staib,John A. Onofrey*

Main category: cs.CV

TL;DR: 论文提出三种空间感知指标，用于评估医学图像分割中的不确定性，考虑了结构和边界信息，优于传统独立像素评估方法。

- Motivation: 传统不确定性评估指标忽略空间上下文和结构信息，无法区分不同模式的不确定性。
- Method: 提出三种结合结构和边界信息的空间感知指标，并在前列腺分区分割数据上验证。
- Result: 新指标与临床重要因素更一致，能更好区分有意义和虚假的不确定性模式。
- Conclusion: 空间感知指标在医学图像分割中更有效，能提供更可靠的临床信息。


### [60] [MetaQAP -- A Meta-Learning Approach for Quality-Aware Pretraining in Image Quality Assessment](https://arxiv.org/abs/2506.16601)
*Muhammad Azeem Aslam,Muhammad Hamza,Nisar Ahmed,Gulshan Saleem,Zhu Shuangtong,Hu Hongfei,Xu Wei,Saba Aslam,Wang Jun*

Main category: cs.CV

TL;DR: MetaQAP是一种新型无参考图像质量评估模型，通过质量感知预训练和元学习解决IQA挑战，在多个基准数据集上表现优异。

- Motivation: 解决图像质量评估中主观感知和复杂失真的挑战。
- Method: 采用质量感知预训练CNN、质量感知损失函数和元学习集成模型。
- Result: 在LiveCD、KonIQ-10K和BIQ2021数据集上PLCC/SROCC得分优异，泛化能力强。
- Conclusion: MetaQAP为无参考IQA提供了鲁棒且可泛化的框架，推动了该领域的发展。


### [61] [Leveraging CNN and IoT for Effective E-Waste Management](https://arxiv.org/abs/2506.16647)
*Ajesh Thangaraj Nadar,Gabriel Nixon Raj,Soham Chandane,Sushant Bhat*

Main category: cs.CV

TL;DR: 本文提出了一种结合物联网和轻量级CNN分类的电子废物智能分类系统，通过视觉和重量属性自动化分类，提升回收效率。

- Motivation: 电子废物（e-waste）的快速增长及其不当处理对环境与健康构成严重威胁，亟需高效分类与回收方法。
- Method: 采用物联网系统与轻量级CNN分类管道，结合摄像头和电子秤，基于视觉和重量属性自动化分类电子废物。
- Result: 系统能实时检测电路板、传感器和电线等电子废物组件，优化智能回收流程，提高废物处理效率。
- Conclusion: 该物联网与CNN结合的系统为电子废物分类与回收提供了高效解决方案，具有实际应用潜力。


### [62] [A Comparative Analysis of Principal Component Analysis (PCA) and Singular Value Decomposition (SVD) as Dimensionality Reduction Techniques](https://arxiv.org/abs/2506.16663)
*Michael Gyimadu,Gregory Bell*

Main category: cs.CV

TL;DR: 论文比较了PCA和SVD两种线性降维技术，分析其理论、数值稳定性及适用性，并提供了选择指南。

- Motivation: 高维图像数据常需降维处理，但缺乏对PCA和SVD的纯理论比较。
- Method: 从基本原理推导算法，评估其可解释性、数值稳定性及对不同矩阵形状的适用性。
- Result: 提出了无需实验基准的选择指南，并总结了局限性。
- Conclusion: 未来需进一步实验验证，并探索更多应用场景。


### [63] [Extracting Multimodal Learngene in CLIP: Unveiling the Multimodal Generalizable Knowledge](https://arxiv.org/abs/2506.16673)
*Ruiming Chen,Junming Yang,Shiyu Xia,Xu Yang,Jing Wang,Xin Geng*

Main category: cs.CV

TL;DR: MM-LG提出了一种从CLIP中提取多模态通用知识的新框架，通过加权和方式提取多模态和单模态知识，显著提升了性能并降低了计算成本。

- Motivation: 解决现有Learngene方法在多模态场景中通用知识提取的不足，以及CLIP大规模预训练的计算开销问题。
- Method: 使用多模态和单模态块加权和提取通用知识，初始化不同规模和模态的模型。
- Result: 在多个数据集上性能优于现有方法（如Oxford-IIIT PET +3.1%，Flickr30k +4.13%），且参数存储和预训练成本显著降低。
- Conclusion: MM-LG是一种高效的多模态通用知识提取框架，适用于多样化下游任务部署。


### [64] [How to Train your Text-to-Image Model: Evaluating Design Choices for Synthetic Training Captions](https://arxiv.org/abs/2506.16679)
*Manuel Brack,Sudeep Katakol,Felix Friedrich,Patrick Schramowski,Hareesh Ravi,Kristian Kersting,Ajinkya Kale*

Main category: cs.CV

TL;DR: 研究探讨了合成标注策略对文本到图像模型性能的影响，发现密集高质量标注提升文本对齐但可能牺牲美学和多样性，而随机长度标注则能平衡美学与对齐。

- Motivation: 现有文献缺乏对合成标注设计选择的深入分析，本研究填补了这一空白。
- Method: 系统研究不同合成标注策略对模型性能的影响。
- Result: 密集高质量标注提升对齐但影响美学和多样性；随机长度标注平衡美学与对齐；标注分布影响输出偏差。
- Conclusion: 标注设计对模型性能至关重要，研究为文本到图像生成提供了实用的训练数据策略。


### [65] [DepthVanish: Optimizing Adversarial Interval Structures for Stereo-Depth-Invisible Patches](https://arxiv.org/abs/2506.16690)
*Yun Xing,Yue Cao,Nhat Chung,Jie Zhang,Ivor Tsang,Ming-Ming Cheng,Yang Liu,Lei Ma,Qing Guo*

Main category: cs.CV

TL;DR: 研究发现，通过在重复纹理中引入间隔形成条纹结构，显著提升了对抗性补丁在物理世界中的攻击效果，并开发了一种新型立体深度攻击方法。

- Motivation: 立体深度估计在自动驾驶和机器人技术中至关重要，但其易受对抗性攻击。现有方法在物理世界中效果不佳，限制了实际应用。
- Method: 提出一种条纹结构，优化纹理和间隔，开发新型对抗性补丁攻击方法。
- Result: 生成的补丁能有效攻击先进立体深度估计方法（如RAFT-Stereo和STTR）及商用RGB-D相机（如Intel RealSense）。
- Conclusion: 条纹结构显著提升攻击效果，为立体系统的安全评估提供了实用工具。


### [66] [LaVi: Efficient Large Vision-Language Models via Internal Feature Modulation](https://arxiv.org/abs/2506.16691)
*Tongtian Yue,Longteng Guo,Yepeng Tang,Zijia Zhao,Xinxin Zhu,Hua Huang,Jing Liu*

Main category: cs.CV

TL;DR: LaVi提出了一种新型的大视觉语言模型，通过内部特征调制实现高效视觉语言融合，显著提升了计算效率和性能。

- Motivation: 现有的大视觉语言模型在视觉语言融合上效率低下，存在结构破坏或计算负担重的问题。
- Method: LaVi通过轻量级自适应变换，将视觉条件化的delta注入层归一化的仿射参数中，直接调节语言隐藏状态。
- Result: 在15个图像和视频基准测试中，LaVi实现了最先进的多模态性能，计算成本大幅降低（FLOPs减少94%，推理速度提升3.1倍，内存减半）。
- Conclusion: LaVi是一种可扩展且实用的实时多模态推理解决方案。


### [67] [Language-driven Description Generation and Common Sense Reasoning for Video Action Recognition](https://arxiv.org/abs/2506.16701)
*Xiaodan Hu,Chuhang Zou,Suchen Wang,Jaechul Kim,Narendra Ahuja*

Main category: cs.CV

TL;DR: 论文提出了一种结合语言驱动常识先验的视频动作识别框架，通过多模态方法提升对遮挡场景的识别能力。

- Motivation: 现有方法未充分利用语言模型中的常识先验，这些先验能帮助理解复杂场景中的动作。
- Method: 提出三个模块：视频上下文摘要、描述生成和多模态动作识别头，结合视觉与文本线索。
- Result: 在Action Genome和Charades数据集上验证了方法的有效性。
- Conclusion: 语言驱动的常识先验能显著提升视频动作识别的性能。


### [68] [Few-Shot Generalized Category Discovery With Retrieval-Guided Decision Boundary Enhancement](https://arxiv.org/abs/2506.16728)
*Yunhan Ren,Feng Luo,Siyu Huang*

Main category: cs.CV

TL;DR: 论文提出了一种名为FSGCD的任务，旨在在已知信息稀缺的情况下提升广义类别发现（GCD）的性能，并提出了一个基于决策边界增强和亲和力检索的框架。

- Motivation: 现有GCD模型在有限标记样本和少量已知类别下的性能尚未充分探索，因此需要研究如何在信息稀缺条件下提升GCD任务的表现。
- Method: 提出了一个决策边界增强框架，包括决策边界预训练模块和两阶段检索引导的优化策略，利用亲和力检索的伪标记样本优化边界。
- Result: 在六个公共GCD基准测试中，该方法在FSGCD设置下优于现有方法。
- Conclusion: 该方法通过决策边界增强和亲和力检索，有效提升了在已知信息稀缺条件下的GCD性能。


### [69] [TeSG: Textual Semantic Guidance for Infrared and Visible Image Fusion](https://arxiv.org/abs/2506.16730)
*Mingrui Zhu,Xiru Chen,Xin Wei,Nannan Wang,Xinbo Gao*

Main category: cs.CV

TL;DR: 论文提出了一种基于文本语义引导的红外与可见光图像融合方法（TeSG），通过多级语义信息优化融合过程，提升下游任务性能。

- Motivation: 现有文本引导的红外与可见光图像融合方法对文本语义信息的整合和利用研究不足，影响了融合效果和下游任务表现。
- Method: TeSG方法包含三个核心模块：语义信息生成器（SIG）、掩码引导的交叉注意力模块（MGCA）和文本驱动的注意力融合模块（TDAF），分别生成语义信息、初始融合和精细化融合。
- Result: 实验表明，TeSG在性能上优于现有方法，尤其在下游任务中表现突出。
- Conclusion: TeSG通过多级文本语义引导，有效提升了红外与可见光图像融合的质量和实用性。


### [70] [3DeepRep: 3D Deep Low-rank Tensor Representation for Hyperspectral Image Inpainting](https://arxiv.org/abs/2506.16735)
*Yunshan Li,Wenwu Gong,Qianqian Wang,Chao Wang,Lili Yang*

Main category: cs.CV

TL;DR: 提出了一种新的3方向深度低秩张量表示模型（3DeepRep），通过在所有三个HSI张量模式上执行深度非线性变换，显著提升了高光谱图像修复性能。

- Motivation: 现有方法通常仅限制变换在光谱模式上，忽略了其他张量模式的低秩特性，因此需要一种更全面的方法。
- Method: 3DeepRep模型在三个方向上分别最小化核范数，并通过可学习的聚合模块融合结果，采用自监督梯度优化算法。
- Result: 在真实HSI数据集上的实验表明，该方法在定性和定量上均优于现有技术。
- Conclusion: 3DeepRep通过多方向低秩表示和自监督优化，显著提升了高光谱图像修复效果。


### [71] [Cross-modal Offset-guided Dynamic Alignment and Fusion for Weakly Aligned UAV Object Detection](https://arxiv.org/abs/2506.16737)
*Liu Zongzhen,Luo Hui,Wang Zhixing,Wei Yuxing,Zuo Haorui,Zhang Jianlin*

Main category: cs.CV

TL;DR: 提出了一种名为CoDAF的统一框架，用于解决无人机（UAV）多模态目标检测中的空间错位和模态冲突问题，通过动态对齐和融合模块提升性能。

- Motivation: 无人机目标检测在环境监测和城市安全中至关重要，但多模态图像（RGB和红外）的空间错位导致语义不一致和模态冲突，现有方法效果有限。
- Method: CoDAF框架包含两个模块：OSA（基于偏移的语义对齐）和DAFM（动态注意力引导融合模块），分别解决对齐和融合问题。
- Result: 在DroneVehicle数据集上，CoDAF达到了78.6%的mAP。
- Conclusion: CoDAF通过统一设计解决了多模态目标检测中的对齐和融合问题，显著提升了性能。


### [72] [Uncertainty-Aware Variational Information Pursuit for Interpretable Medical Image Analysis](https://arxiv.org/abs/2506.16742)
*Md Nahiduzzaman,Ruwan Tennakoon,Steven Korevaar,Zongyuan Ge,Alireza Bab-Hadiashar*

Main category: cs.CV

TL;DR: 论文提出了一种不确定性感知的V-IP框架（UAV-IP），在医疗影像中提升模型解释性和准确性。

- Motivation: 现有V-IP方法忽略查询-答案生成中的实例级不确定性，影响模型可靠性和临床决策。
- Method: 引入不确定性量化技术，改进V-IP框架，评估于四个医疗影像数据集。
- Result: UAV-IP平均AUC提升3.2%，生成解释更简洁20%，且信息量不减。
- Conclusion: 不确定性感知对设计可解释模型至关重要，提升医疗决策的鲁棒性和可靠性。


### [73] [Noise-Informed Diffusion-Generated Image Detection with Anomaly Attention](https://arxiv.org/abs/2506.16743)
*Weinan Guan,Wei Wang,Bo Peng,Ziwen He,Jing Dong,Haonan Cheng*

Main category: cs.CV

TL;DR: 论文提出了一种基于噪声感知自注意力模块（NASA）的新方法，用于检测扩散模型生成的图像，并通过结合Swin Transformer和跨模态融合嵌入，显著提升了检测性能。

- Motivation: 随着扩散模型生成图像质量的提升，信息安全隐患增加，需要一种能够泛化到未见过的扩散模型的检测方法。
- Method: 通过分析图像噪声模式，提出噪声感知自注意力模块（NASA），并将其集成到Swin Transformer中，形成NASA-Swin架构，同时采用跨模态融合嵌入和通道掩码策略。
- Result: 实验表明，该方法在检测扩散生成图像时表现出色，尤其是在面对未见过的生成方法时，达到了最先进的性能。
- Conclusion: NASA-Swin是一种有效的检测扩散生成图像的方法，具有泛化能力强和性能优越的特点。


### [74] [Class Agnostic Instance-level Descriptor for Visual Instance Search](https://arxiv.org/abs/2506.16745)
*Qi-Ying Sun,Wan-Lei Zhao,Yi-Bo Miao,Chong-Wah Ngo*

Main category: cs.CV

TL;DR: 论文提出了一种基于自监督ViT的分层特征子集检测方法，用于解决视觉实例搜索中的实例级特征表示问题，显著优于现有方法。

- Motivation: 现有深度特征在视觉实例搜索中表现不佳，尤其是对未知类别对象。监督或弱监督方法因性能不足不适用。
- Method: 利用自监督ViT输出的特征集，通过分层方式检测紧凑特征子集，生成层次化特征子集，对应不同语义尺度的实例区域。
- Result: 方法在三个实例搜索基准测试中显著优于现有技术，对已知和未知类别对象均有效。
- Conclusion: 分层分解有效解决了对象嵌入和遮挡问题，提供了一种全面的实例级描述符。


### [75] [Infrared and Visible Image Fusion Based on Implicit Neural Representations](https://arxiv.org/abs/2506.16773)
*Shuchen Sun,Ligen Shi,Chang Liu,Lina Wu,Jun Qiu*

Main category: cs.CV

TL;DR: 提出了一种基于隐式神经表示（INR）的红外与可见光图像融合方法INRFuse，通过神经网络参数化连续函数，自适应融合多模态信息，无需训练数据集即可生成高质量融合图像。

- Motivation: 红外与可见光图像融合旨在结合两种模态的优势，生成信息丰富且满足视觉或计算需求的图像。传统方法依赖离散像素或显式特征，存在局限性。
- Method: 利用归一化空间坐标作为输入，通过多层感知机自适应融合红外与可见光图像特征，设计多损失函数联合优化融合图像与原图像的相似性。
- Result: INRFuse在主观视觉质量和客观评价指标上均优于现有方法，生成的融合图像结构清晰、细节自然、信息丰富，且支持不同分辨率图像的直接融合与超分辨率重建。
- Conclusion: INRFuse通过隐式神经表示突破了传统方法的限制，实现了高质量、分辨率无关的图像融合，为多模态图像处理提供了新思路。


### [76] [PQCAD-DM: Progressive Quantization and Calibration-Assisted Distillation for Extremely Efficient Diffusion Model](https://arxiv.org/abs/2506.16776)
*Beomseok Ko,Hyeryung Jang*

Main category: cs.CV

TL;DR: PQCAD-DM是一种结合渐进量化（PQ）和校准辅助蒸馏（CAD）的混合压缩框架，用于解决扩散模型的计算和资源密集型问题，同时保持生成质量。

- Motivation: 扩散模型在图像生成中表现出色，但其依赖迭代马尔可夫链过程导致计算和资源消耗大，且误差累积限制了压缩技术的有效性。
- Method: PQCAD-DM采用两阶段渐进量化（PQ）和校准辅助蒸馏（CAD）。PQ通过动量机制自适应调整位宽，减少低精度下的权重扰动；CAD利用全精度校准数据集，使量化学生模型匹配全精度性能。
- Result: PQCAD-DM在计算效率和生成质量之间取得平衡，推理时间减半，同时保持竞争力。实验表明其在多种数据集上优于固定位量化方法。
- Conclusion: PQCAD-DM通过混合压缩框架有效解决了扩散模型的高计算成本问题，同时保持了高质量的生成能力。


### [77] [TextBraTS: Text-Guided Volumetric Brain Tumor Segmentation with Innovative Dataset Development and Fusion Module Exploration](https://arxiv.org/abs/2506.16784)
*Xiaoyu Shi,Rahul Kumar Jain,Yinhao Li,Ruibo Hou,Jingliang Cheng,Jie Bai,Guohua Zhao,Lanfen Lin,Rui Xu,Yen-wei Chen*

Main category: cs.CV

TL;DR: 论文介绍了首个公开的多模态数据集TextBraTS，结合MRI图像和文本注释，并提出了一种基于文本引导的医学图像分割方法，显著提高了脑肿瘤分割的准确性。

- Motivation: 现有脑肿瘤分析领域缺乏结合放射图像和文本注释的综合数据集，限制了多模态方法的研究。
- Method: 提出TextBraTS数据集，并开发了一种基于顺序交叉注意力的文本引导体积医学图像分割框架。
- Result: 实验表明，该方法显著提高了脑肿瘤分割的准确性，并提供了有效的多模态集成技术见解。
- Conclusion: TextBraTS数据集和提出的方法为脑肿瘤分析领域的多模态研究提供了重要资源和技术支持。


### [78] [RealSR-R1: Reinforcement Learning for Real-World Image Super-Resolution with Vision-Language Chain-of-Thought](https://arxiv.org/abs/2506.16796)
*Junbo Qiao,Miaomiao Cai,Wei Li,Yutong Liu,Xudong Huang,Gaoqi He,Jiao Xie,Jie Hu,Xinghao Chen,Shaohui Lin*

Main category: cs.CV

TL;DR: RealSR-R1提出了一种结合视觉与语言推理的VLCoT框架，通过GRPO优化方法提升真实世界图像超分辨率任务的性能。

- Motivation: 现有方法在理解退化图像内容时表现不佳，导致重建结果低保真且不自然。
- Method: 提出VLCoT框架，模拟人类处理退化图像的过程，结合GRPO优化方法，设计了四种奖励函数。
- Result: 实验表明，RealSR-R1能生成真实细节并准确理解图像内容，尤其在语义丰富或严重退化的场景中表现突出。
- Conclusion: VLCoT-GRPO框架有效提升了真实世界图像超分辨率的性能，生成结果更自然且准确。


### [79] [Seeing What Matters: Generalizable AI-generated Video Detection with Forensic-Oriented Augmentation](https://arxiv.org/abs/2506.16802)
*Riccardo Corvi,Davide Cozzolino,Ekta Prashnani,Shalini De Mello,Koki Nagano,Luisa Verdoliva*

Main category: cs.CV

TL;DR: 提出了一种基于小波分解的数据增强策略，通过引导检测器关注生成视频的低级伪影而非高级语义缺陷，显著提升了AI生成视频检测器的泛化能力。

- Motivation: 现有视频伪造检测器泛化能力差，无法适应现实场景。通过识别生成架构固有的低级伪影而非模型特定的高级语义缺陷，可以提高检测器的实用性。
- Method: 研究不同生成架构，识别共享的判别性特征；提出基于小波分解的数据增强策略，替换特定频带以引导模型关注更相关的取证线索。
- Result: 在仅使用单一生成模型数据训练的情况下，检测器对其他多种生成模型的视频表现出显著更高的准确率，优于现有技术。
- Conclusion: 该方法通过简单而有效的训练策略，显著提升了检测器的泛化能力，无需复杂算法或大规模数据集。


### [80] [Co-VisiON: Co-Visibility ReasONing on Sparse Image Sets of Indoor Scenes](https://arxiv.org/abs/2506.16805)
*Chao Chen,Nobel Dang,Juexiao Zhang,Wenkai Sun,Pengfei Zheng,Xuhang He,Yimeng Ye,Taarun Srinivas,Chen Feng*

Main category: cs.CV

TL;DR: 该论文提出了Co-VisiON基准，用于评估稀疏图像集中的共视性推理能力，发现现有视觉模型在此任务上表现不佳，尤其是与人类表现相比差距显著。

- Motivation: 研究人类共视性识别能力是否被当前视觉模型达到，并填补这一领域的评估空白。
- Method: 引入Co-VisiON基准，测试稀疏图像条件下的共视性推理，并提出多视图基线模型Covis。
- Result: 专有视觉语言模型表现最佳，但所有模型均远低于人类水平；Covis在纯视觉模型中表现最优。
- Conclusion: 共视性任务需要高层次的多视图推理，未来研究应关注此方向以缩小与人类表现的差距。


### [81] [FOCUS: Unified Vision-Language Modeling for Interactive Editing Driven by Referential Segmentation](https://arxiv.org/abs/2506.16806)
*Fan Yang,Yousong Zhu,Xin Li,Yufei Zhan,Hongyin Zhao,Shurong Zheng,Yaowei Wang,Ming Tang,Jinqiao Wang*

Main category: cs.CV

TL;DR: FOCUS是一个统一的LVLM模型，整合了分割感知和可控对象生成，通过端到端框架实现视觉感知与生成的联合优化。

- Motivation: 当前方法将视觉理解和生成分离，依赖多个独立模型，FOCUS旨在填补这一空白。
- Method: 采用双分支视觉编码器捕获全局语义和空间细节，结合MoVQGAN视觉标记器和多阶段训练策略。
- Result: 在多项任务中表现优异，包括多模态理解、参考分割和可控图像生成。
- Conclusion: FOCUS通过联合优化视觉感知与生成，显著提升了性能。


### [82] [Loupe: A Generalizable and Adaptive Framework for Image Forgery Detection](https://arxiv.org/abs/2506.16819)
*Yuchu Jiang,Jiaming Chu,Jian Zhao,Xin Zhang,Xu Yang,Lei Jin,Chi Zhang,Xuelong Li*

Main category: cs.CV

TL;DR: Loupe是一个轻量级框架，用于联合深度伪造检测和定位，通过整合补丁感知分类器和分割模块，实现了高准确性和泛化能力。

- Motivation: 生成模型的普及引发了视觉内容伪造的严重问题，现有方法在泛化性和架构复杂性上存在局限。
- Method: Loupe结合补丁感知分类器和条件查询的分割模块，引入伪标签引导的测试时适应机制。
- Result: 在DDL数据集上表现优异，IJCAI 2025挑战赛中得分0.846，排名第一。
- Conclusion: Loupe通过补丁级融合和条件查询设计，提升了分类和定位的准确性。


### [83] [Self-supervised Feature Extraction for Enhanced Ball Detection on Soccer Robots](https://arxiv.org/abs/2506.16821)
*Can Lin,Daniele Affinita,Marco E. P. Zimmatore,Daniele Nardi,Domenico D. Bloisi,Vincenzo Suriani*

Main category: cs.CV

TL;DR: 提出了一种自监督学习框架，用于提升足球机器人在动态环境中的球检测性能，无需大量人工标注。

- Motivation: 传统监督学习方法需要大量人工标注，成本高且耗时，因此需要一种更高效的方法。
- Method: 利用预训练模型生成伪标签，通过自监督任务（如着色、边缘检测和三元组损失）学习鲁棒特征，并结合MAML策略快速适应新场景。
- Result: 实验结果表明，该方法在准确性、F1分数和IoU上优于基线模型，且收敛更快。
- Conclusion: 该自监督框架有效提升了球检测性能，适用于动态环境，并开源了新数据集。


### [84] [AnyTraverse: An off-road traversability framework with VLM and human operator in the loop](https://arxiv.org/abs/2506.16826)
*Sattwik Sahu,Agamdeep Singh,Karthik Nambiar,Srikanth Saripalli,P. B. Sujit*

Main category: cs.CV

TL;DR: AnyTraverse是一个结合自然语言提示和人工辅助的框架，用于分割可导航区域，适用于多种机器人车辆，减少人工监督需求。

- Motivation: 当前框架在非结构化环境中表现不佳，且无法适应不同类型的机器人，需要一种更灵活的方法。
- Method: 结合自然语言提示和人工辅助，仅在遇到未知场景时调用操作员，采用零样本学习避免数据收集和重新训练。
- Result: 在多个数据集和机器人平台上验证，性能优于GA-NAV和Off-seg，提供车辆无关的解决方案。
- Conclusion: AnyTraverse在自动化与人工监督之间取得平衡，适用于多变户外场景。


### [85] [Camera Calibration via Circular Patterns: A Comprehensive Framework with Measurement Uncertainty and Unbiased Projection Model](https://arxiv.org/abs/2506.16842)
*Chaehyeon Song,Dongjae Lee,Jongwoo Lim,Ayoung Kim*

Main category: cs.CV

TL;DR: 论文提出了一种无偏的圆形图案投影模型，解决了现有模型在镜头畸变下的偏差问题，并通过引入不确定性提高了校准的鲁棒性和完整性。

- Motivation: 现有圆形图案的投影模型在镜头畸变下存在偏差，导致校准性能不佳。
- Method: 提出无偏的圆形图案投影模型，引入不确定性，并基于马尔可夫随机场建模边界点。
- Result: 新框架显著提高了校准精度和鲁棒性。
- Conclusion: 该方法在圆形图案校准中表现出优越性，并提供了完整的源代码和演示视频。


### [86] [Controllable and Expressive One-Shot Video Head Swapping](https://arxiv.org/abs/2506.16852)
*Chaonan Ji,Jinwei Qi,Peng Zhang,Bang Zhang,Liefeng Bo*

Main category: cs.CV

TL;DR: 提出了一种基于扩散的多条件可控视频头部替换框架，支持静态图像头部无缝移植到动态视频中，并允许调整头部表情和动作。

- Motivation: 现有方法主要关注局部面部替换，忽略了整体头部形态，且在发型多样性和复杂背景处理上表现不佳，且不支持替换后表情修改。
- Method: 采用统一潜在扩散范式，包括身份保留上下文融合和表情感知地标重定向与编辑模块。
- Result: 实验表明，该方法在背景无缝融合和身份保留方面表现优异，同时具备出色的表情迁移能力。
- Conclusion: 该方法在视频头部替换中实现了高精度和灵活性，适用于真实和虚拟角色。


### [87] [ParkFormer: A Transformer-Based Parking Policy with Goal Embedding and Pedestrian-Aware Control](https://arxiv.org/abs/2506.16856)
*Jun Fu,Bin Tian,Haonan Chen,Shi Meng,Tingting Yao*

Main category: cs.CV

TL;DR: 提出了一种基于Transformer的端到端自动驾驶停车框架，通过专家演示学习，结合BEV特征与目标点，并利用GRU预测行人轨迹，在CARLA模拟器中验证了高成功率和低误差。

- Motivation: 传统规则停车系统在动态环境中适应性差，而人类驾驶员能直觉停车，因此提出学习专家演示的框架以提高适应性。
- Method: 输入包括环视摄像头图像、目标点表示、车辆运动和行人轨迹，输出离散控制序列；设计了交叉注意力模块和GRU行人预测器。
- Result: 在CARLA模拟器中，模型成功率达96.57%，位置和方向误差分别为0.21米和0.41度。
- Conclusion: 提出的框架在停车任务中表现优异，关键模块如行人预测和目标点注意力融合效果显著。


### [88] [With Limited Data for Multimodal Alignment, Let the STRUCTURE Guide You](https://arxiv.org/abs/2506.16895)
*Fabian Gröger,Shuo Wen,Huyen Le,Maria Brbić*

Main category: cs.CV

TL;DR: 提出了一种在有限配对数据下构建多模态模型的方法，通过对齐预训练的单模态基础模型，显著减少数据需求。

- Motivation: 现有模型依赖大量配对数据，成本高昂或难以获取，探索在有限数据下实现高质量对齐的可行性。
- Method: 引入STRUCTURE正则化技术，保持单模态编码器潜在空间的邻域几何结构，并优化对齐层选择。
- Result: 在24个零样本分类和检索任务中，平均相对提升51.6%（分类）和91.8%（检索）。
- Conclusion: 该方法在资源受限领域具有广泛适用性，为有限样本多模态学习提供了有效路径。


### [89] [LunarLoc: Segment-Based Global Localization on the Moon](https://arxiv.org/abs/2506.16940)
*Annika Thomas,Robaire Galliath,Aleksander Garbuz,Luke Anger,Cormac O'Neill,Trevor Johst,Dami Thomas,George Lordos,Jonathan P. How*

Main category: cs.CV

TL;DR: 论文提出LunarLoc方法，通过实例分割提取月球表面巨石标志物，实现高精度全局定位，解决视觉惯性里程计长期漂移问题。

- Motivation: 月球表面缺乏GPS等导航基础设施，自主操作需高精度定位，如Artemis计划中的任务。
- Method: 利用立体图像实例分割提取巨石标志物，构建地形图并与参考地图对齐，实现全局定位。
- Result: LunarLoc在多会话实验中达到亚厘米级精度，优于现有技术。
- Conclusion: LunarLoc为月球任务提供无漂移定位方案，公开数据集促进进一步研究。


### [90] [LAION-C: An Out-of-Distribution Benchmark for Web-Scale Vision Models](https://arxiv.org/abs/2506.16950)
*Fanfei Li,Thomas Klein,Wieland Brendel,Robert Geirhos,Roland S. Zimmermann*

Main category: cs.CV

TL;DR: 论文提出LAION-C作为ImageNet-C的替代基准，用于评估模型在web-scale数据集时代的OOD鲁棒性。

- Motivation: 当前OOD基准（如ImageNet-C）已无法有效评估web-scale数据集时代的模型鲁棒性，因为其失真类型已被包含在训练数据中。
- Method: 设计了六种新型失真类型构建LAION-C基准，并评估了包括MLLMs在内的先进模型。
- Result: LAION-C对当代模型（如Gemini和GPT-4o）构成显著挑战，且最佳模型性能已接近或超过人类观察者。
- Conclusion: LAION-C为OOD鲁棒性评估提供了更合适的基准，标志着模型性能已接近人类水平。


### [91] [Visual-Instructed Degradation Diffusion for All-in-One Image Restoration](https://arxiv.org/abs/2506.16960)
*Wenyang Luo,Haina Qin,Zewen Chen,Libin Wang,Dandan Zheng,Yuming Li,Yufan Liu,Bing Li,Weiming Hu*

Main category: cs.CV

TL;DR: Defusion是一种基于视觉指令引导的全能图像修复框架，通过扩散模型在退化空间中直接操作，显著提升了对混合或未知退化的泛化能力。

- Motivation: 现有图像修复方法通常需要针对每种退化类型设计单独模型，限制了其在真实场景中的泛化能力。
- Method: 提出视觉指令引导的退化扩散方法，通过标准化视觉元素构建明确的视觉指令，指导扩散模型在退化空间中直接操作。
- Result: Defusion在多种图像修复任务中表现优于现有方法，包括复杂和真实世界的退化情况。
- Conclusion: Defusion通过视觉指令和扩散模型的结合，实现了更稳定和泛化的图像修复效果。


### [92] [Reversing Flow for Image Restoration](https://arxiv.org/abs/2506.16961)
*Haina Qin,Wenyang Luo,Libin Wang,Dandan Zheng,Jingdong Chen,Ming Yang,Bing Li,Weiming Hu*

Main category: cs.CV

TL;DR: ResFlow是一种新型图像恢复框架，通过确定性路径建模退化过程，显著提升性能和速度。

- Motivation: 现有生成模型将退化过程视为随机变换，导致效率低下和复杂性增加。
- Method: 使用连续归一化流建模确定性退化路径，引入辅助过程消除预测不确定性，采用熵保持流路径匹配速度场。
- Result: 在少于四个采样步骤内完成任务，在多个图像恢复基准上达到最先进水平。
- Conclusion: ResFlow为实际应用提供了一种高效实用的图像恢复解决方案。


### [93] [Enhancing Step-by-Step and Verifiable Medical Reasoning in MLLMs](https://arxiv.org/abs/2506.16962)
*Haoran Sun,Yankai Jiang,Wenjie Lou,Yujie Zhang,Wenjie Li,Lilong Wang,Mianxin Liu,Lei Liu,Xiaosong Wang*

Main category: cs.CV

TL;DR: 提出了一种名为MICS的新方法，用于生成医学领域的链式思维训练数据，并构建了多任务医学推理数据集MMRP和新的医学MLLM模型Chiron-o1，实验证明其性能优越。

- Motivation: 现有方法在医学领域缺乏全面的框架来搜索和评估有效的推理路径，限制了医学MLLM的推理能力。
- Method: 提出MICS方法，通过导师模型初始化推理路径，实习生模型继续扩展，并根据MICS-Score选择最优路径。构建了MMRP数据集和Chiron-o1模型。
- Result: Chiron-o1在多个医学视觉问答和推理基准测试中达到最优性能。
- Conclusion: MICS方法有效提升了医学MLLM的推理能力，Chiron-o1展示了强大的性能。


### [94] [ForestFormer3D: A Unified Framework for End-to-End Segmentation of Forest LiDAR 3D Point Clouds](https://arxiv.org/abs/2506.16991)
*Binbin Xiang,Maciej Wielgosz,Stefano Puliti,Kamil Král,Martin Krůček,Azim Missarov,Rasmus Astrup*

Main category: cs.CV

TL;DR: ForestFormer3D是一种新的端到端框架，用于精确的森林LiDAR点云分割，包括单树和语义分割，性能优于现有方法。

- Motivation: 现有方法难以应对自然森林环境的复杂性和多样性，因此需要一种更有效的分割框架。
- Method: ForestFormer3D结合了ISA引导的查询点选择、基于分数的块合并策略和一对多关联训练机制。
- Result: 模型在FOR-instanceV2数据集上实现了最先进的单树分割性能，并在未见过的测试集上表现出良好的泛化能力。
- Conclusion: ForestFormer3D在多样化的森林环境中表现出鲁棒性，其代码和数据集将公开发布。


### [95] [Prmpt2Adpt: Prompt-Based Zero-Shot Domain Adaptation for Resource-Constrained Environments](https://arxiv.org/abs/2506.16994)
*Yasir Ali Farrukh,Syed Wali,Irfan Khan,Nathaniel D. Bastian*

Main category: cs.CV

TL;DR: Prmpt2Adpt是一种轻量级、高效的零样本域适应框架，通过提示驱动的特征对齐实现快速适应，适用于资源受限环境。

- Motivation: 解决现有无监督域适应方法依赖大型模型和完整源域数据的限制，提升在资源受限环境（如无人机）中的适用性。
- Method: 基于教师-学生范式，使用蒸馏和微调的CLIP模型作为教师模型的冻结骨干，通过提示驱动的实例归一化对齐特征，并生成高质量伪标签指导学生模型适应。
- Result: 在MDS-A数据集上，Prmpt2Adpt性能与最先进方法相当，适应速度快7倍，推理速度快5倍，且仅需少量源图像。
- Conclusion: Prmpt2Adpt是一种实用且可扩展的解决方案，适用于低资源领域的实时适应。


### [96] [A Synthetic Benchmark for Collaborative 3D Semantic Occupancy Prediction in V2X Autonomous Driving](https://arxiv.org/abs/2506.17004)
*Hanlin Wu,Pengfei Lin,Ehsan Javanmardi,Naren Bao,Bo Qian,Hao Si,Manabu Tsukada*

Main category: cs.CV

TL;DR: 论文提出了一种通过协作感知提升3D语义占用预测的方法，填补了数据集空白并建立了基准测试。

- Motivation: 单车的感知能力受限于遮挡、传感器范围和视角狭窄，协作感知可以交换互补信息以提高完整性和准确性。
- Method: 通过CARLA重放现有数据集生成高分辨率语义体素标注，建立不同预测范围的基准，并开发基于空间对齐和注意力聚合的基线模型。
- Result: 基线模型在扩展预测范围时表现优于单代理模型，增益随范围扩大而增加。
- Conclusion: 协作感知能有效提升3D语义占用预测性能，尤其在更大空间范围内效果显著。


### [97] [Unsupervised Image Super-Resolution Reconstruction Based on Real-World Degradation Patterns](https://arxiv.org/abs/2506.17027)
*Yiyang Tie,Hong Zhu,Yunyun Luo,Jing Shi*

Main category: cs.CV

TL;DR: 提出了一种TripleGAN框架，通过两个GAN组件分别处理模糊特性和其他退化模式，第三GAN用于重建真实低分辨率图像，显著提升了超分辨率重建性能。

- Motivation: 真实世界超分辨率重建依赖反映真实退化模式的数据集，但现有方法难以同时捕捉模糊、噪声和隐含退化特征。
- Method: 设计了TripleGAN框架，包括FirstGAN（缩小模糊域差距）、SecondGAN（学习目标域模糊特性和其他退化模式）、ThirdGAN（重建真实低分辨率图像）。
- Result: 在RealSR和DRealSR数据集上，该方法在定量指标上表现优越，重建结果清晰且无过度平滑伪影。
- Conclusion: TripleGAN能有效学习真实退化模式并合成对齐数据集，显著提升超分辨率重建质量。


### [98] [Stretching Beyond the Obvious: A Gradient-Free Framework to Unveil the Hidden Landscape of Visual Invariance](https://arxiv.org/abs/2506.17040)
*Lorenzo Tausani,Paolo Muratore,Morgan B. Talbot,Giacomo Amerio,Gabriel Kreiman,Davide Zoccolan*

Main category: cs.CV

TL;DR: SnS框架通过双目标优化系统表征视觉单元的响应不变性和对抗敏感性，揭示了CNN中不同层级表征对图像变换的影响，并验证了鲁棒网络的更高保真度。

- Motivation: 理解视觉单元如何编码特征组合以支持图像识别，现有方法无法揭示响应不变性的变换流形。
- Method: 提出Stretch-and-Squeeze (SnS)框架，通过双目标优化问题探究不变性和对抗敏感性。
- Result: SnS发现CNN中不同层级表征对图像变换（如亮度、纹理、姿态）的影响不同，鲁棒网络的输出更易被人类识别。
- Conclusion: SnS为视觉系统研究提供了新工具，鲁棒CNN更接近生物视觉系统的表征能力。


### [99] [Relaxed syntax modeling in Transformers for future-proof license plate recognition](https://arxiv.org/abs/2506.17051)
*Florent Meyer,Laurent Guichard,Denis Coquenet,Guillaume Gravier,Yann Soullard,Bertrand Coüasnon*

Main category: cs.CV

TL;DR: 论文提出了一种名为SaLT的语法无关Transformer模型，旨在解决传统Transformer在车牌识别中对历史语法过度依赖的问题，并在实验中证明了其对新语法车牌的鲁棒性。

- Motivation: 传统Transformer在车牌识别中表现优异，但对新语法车牌的性能显著下降，不适合实际生产环境。
- Method: 通过分析Transformer编码器-解码器中位置和上下文信息的流动，识别问题原因，并设计架构改进（如SaLT模型）以实现语法无关的车牌表示建模。
- Result: 实验表明，SaLT在历史语法车牌上表现优异，且对新语法车牌的性能几乎保持不变。
- Conclusion: SaLT通过架构改进有效解决了Transformer对新语法车牌的识别问题，具有实际应用潜力。


### [100] [Assembler: Scalable 3D Part Assembly via Anchor Point Diffusion](https://arxiv.org/abs/2506.17074)
*Wang Zhao,Yan-Pei Cao,Jiale Xu,Yuejiang Dong,Ying Shan*

Main category: cs.CV

TL;DR: Assembler是一个可扩展且通用的3D零件组装框架，通过扩散模型和稀疏锚点云表示，实现了高质量、多样化的3D对象组装。

- Motivation: 解决现有方法在多样化、真实世界对象组装中的局限性，如对称性、重复零件和多有效组装带来的模糊性。
- Method: 将零件组装视为生成问题，使用扩散模型采样合理配置；引入基于稀疏锚点云的形状中心表示；构建大规模数据集。
- Result: 在PartNet上达到最先进性能，首次实现复杂真实世界对象的高质量组装。
- Conclusion: Assembler展示了在交互式和组合式设计中的潜力，并进一步开发了零件感知的3D建模系统。


### [101] [Acquiring and Accumulating Knowledge from Diverse Datasets for Multi-label Driving Scene Classification](https://arxiv.org/abs/2506.17101)
*Ke Li,Chenyu Zhang,Yuxin Ding,Xianbiao Hu,Ruwen Qin*

Main category: cs.CV

TL;DR: 论文提出了一种结合知识获取与积累（KAA）和基于一致性的主动学习（CAL）的新方法，用于解决驾驶场景多标签分类中的数据集不平衡和任务学习平衡问题。

- Motivation: 提升自动驾驶车辆对复杂驾驶环境的理解能力，需解决多标签分类中的数据集不平衡和任务学习平衡问题。
- Method: 结合KAA（从单标签数据集获取知识）和CAL（解决知识分布差异），构建多标签分类模型。
- Result: 在DSI数据集上性能提升56.1%，KAA贡献31.3%，CAL贡献24.8%；在BDD100K和HSD数据集上表现优于SOTA模型，且数据使用量减少85%。
- Conclusion: KAA-CAL方法有效解决了多标签分类中的挑战，显著提升了性能并减少了数据需求。


### [102] [MEXA: Towards General Multimodal Reasoning with Dynamic Multi-Expert Aggregation](https://arxiv.org/abs/2506.17113)
*Shoubin Yu,Yue Zhang,Ziyang Wang,Jaehong Yoon,Mohit Bansal*

Main category: cs.CV

TL;DR: MEXA是一个无需训练的框架，通过动态选择和聚合专家模型实现多模态推理，适用于多样化任务和领域。

- Motivation: 解决多模态输入和任务复杂性增加带来的统一框架构建挑战。
- Method: 动态选择专家模型，生成可解释的文本推理输出，并通过大型推理模型（LRM）聚合结果。
- Result: 在多种多模态基准测试中表现优于基线，验证了其有效性和广泛适用性。
- Conclusion: MEXA通过模块化设计实现了灵活、透明的多模态推理，无需额外训练开销。


### [103] [RGBTrack: Fast, Robust Depth-Free 6D Pose Estimation and Tracking](https://arxiv.org/abs/2506.17119)
*Teng Guo,Jingjin Yu*

Main category: cs.CV

TL;DR: RGBTrack是一个基于RGB数据的实时6D姿态估计与跟踪框架，无需深度输入，通过新颖的二进制搜索和渲染比较机制实现高效深度推断，结合2D跟踪和状态机保持动态场景稳定性。

- Motivation: 解决传统方法依赖深度输入的问题，提供一种更灵活、高效的动态物体姿态跟踪方案。
- Method: 基于FoundationPose架构，结合二进制搜索策略和渲染比较机制，集成XMem 2D跟踪、卡尔曼滤波和状态机，动态调整未知尺度CAD模型。
- Result: 在基准数据集上表现出竞争性精度和实时性能。
- Conclusion: RGBTrack是一种无需深度输入的高效解决方案，适用于机器人、增强现实和计算机视觉领域。


### [104] [Dynamic Watermark Generation for Digital Images using Perimeter Gated SPAD Imager PUFs](https://arxiv.org/abs/2506.17134)
*Md Sakibur Sajal,Marc Dandin*

Main category: cs.CV

TL;DR: 提出了一种基于pgSPAD成像器的数字水印技术，利用制造差异（DSNU）实现源识别和篡改检测。

- Motivation: 探索SPAD成像器在数字水印中的应用，填补现有研究空白。
- Method: 利用三个64x64 pgSPAD芯片的DSNU，分析标准测试图像的水印效果。
- Result: 实现了源识别和篡改检测，并具备可控的灵敏度-鲁棒性权衡。
- Conclusion: pgSPAD成像器可用于动态水印，具有实际应用潜力。


### [105] [Semi-Supervised Multi-Modal Medical Image Segmentation for Complex Situations](https://arxiv.org/abs/2506.17136)
*Dongdong Meng,Sheng Li,Hao Wu,Guoping Wang,Xueqing Yan*

Main category: cs.CV

TL;DR: 提出了一种新的半监督多模态医学图像分割方法，通过多阶段多模态融合和对比互学习提升性能。

- Motivation: 解决半监督条件下多模态融合方法难以有效利用未标记数据的问题。
- Method: 采用多阶段多模态融合和增强策略，结合对比互学习约束跨模态预测一致性。
- Result: 在两个多模态数据集上验证了方法的优越性能和鲁棒性。
- Conclusion: 该方法在复杂场景下具有解决医学图像分割任务的潜力。


### [106] [On the Theory of Conditional Feature Alignment for Unsupervised Domain-Adaptive Counting](https://arxiv.org/abs/2506.17137)
*Zhuonan Liang,Dongnan Liu,Jianan Fan,Yaxuan Song,Qiang Qu,Yu Yao,Peng Fu,Weidong Cai*

Main category: cs.CV

TL;DR: 论文提出了一种条件特征对齐的理论框架，通过分区测量条件差异，证明条件对齐能降低联合误差，并在实验中验证了其优于现有无监督域适应方法。

- Motivation: 目标计数模型在跨域部署时因密度变化而性能下降，标准域适应假设无法解决此问题。
- Method: 提出条件特征对齐框架，分区测量条件差异，推导联合误差边界，并设计实际适应策略。
- Result: 实验表明，该方法在多个计数数据集上优于现有无监督域适应方法。
- Conclusion: 条件特征对齐能有效提升跨域计数的泛化性能。


### [107] [Do We Need Large VLMs for Spotting Soccer Actions?](https://arxiv.org/abs/2506.17144)
*Ritabrata Chakraborty,Rajatsubhra Chakraborty,Avijit Dasgupta,Sandeep Chaurasia*

Main category: cs.CV

TL;DR: 论文提出了一种基于文本的轻量级方法，利用大型语言模型（LLMs）替代传统的视觉语言模型（VLMs）来检测足球比赛中的关键动作，如进球、黄牌和换人。

- Motivation: 传统视频分析方法计算成本高且复杂，而专家评论提供了丰富的上下文信息，足以可靠地识别关键动作。
- Method: 使用SoccerNet Echoes数据集，通过三个专门化的LLMs（分别评估结果、兴奋度和战术）分析时间戳评论，滑动窗口检测动作。
- Result: 实验表明，这种基于语言的方法能有效检测关键比赛事件，且无需训练。
- Conclusion: 该方法为动作检测提供了一种轻量级、无需训练的替代方案，优于传统视频方法。


### [108] [Co-Seg++: Mutual Prompt-Guided Collaborative Learning for Versatile Medical Segmentation](https://arxiv.org/abs/2506.17159)
*Qing Xu,Yuxiang Luo,Wenting Duan,Zhen Chen*

Main category: cs.CV

TL;DR: Co-Seg++框架通过联合语义和实例分割任务，提升医学图像分割性能。

- Motivation: 现有研究通常孤立处理分割任务，忽略了任务间的相互依赖性，导致性能不佳。
- Method: 提出Co-Seg++框架，包含STP-Encoder捕获空间和时间关系，MTC-Decoder通过跨任务指导增强一致性。
- Result: 在多种数据集上表现优于现有方法，适用于解剖结构、组织病理学和细胞核实例的分割。
- Conclusion: Co-Seg++通过任务协同显著提升了医学图像分割的准确性和理解能力。


### [109] [YASMOT: Yet another stereo image multi-object tracker](https://arxiv.org/abs/2506.17186)
*Ketil Malde*

Main category: cs.CV

TL;DR: yasmot是一个轻量级、灵活的对象跟踪器，用于处理来自单目或立体摄像机的图像序列，支持多检测器集成生成共识检测。

- Motivation: 在图像时间序列中，跟踪对象并保持其身份对提升检测性能及下游任务（如行为分类、丰度估计）至关重要。
- Method: yasmot处理流行对象检测器的输出，支持单目或立体摄像机配置，并集成多检测器生成共识检测。
- Result: yasmot实现了轻量级且灵活的对象跟踪功能。
- Conclusion: yasmot为图像序列中的对象跟踪提供了一种高效解决方案。


### [110] [Facial Landmark Visualization and Emotion Recognition Through Neural Networks](https://arxiv.org/abs/2506.17191)
*Israel Juárez-Jiménez,Tiffany Guadalupe Martínez Paredes,Jesús García-Ramírez,Eric Ramos Aguilar*

Main category: cs.CV

TL;DR: 论文提出了一种面部地标箱线图可视化技术，用于识别数据集中的异常值，并比较了两种面部地标特征，结果表明神经网络优于随机森林分类器。

- Motivation: 面部图像情感识别是人机交互中的关键任务，但现有研究缺乏对数据集的深入分析，且面部地标可视化存在挑战。
- Method: 提出面部地标箱线图技术，比较绝对位置与位移两种特征，使用神经网络和随机森林分类器进行实验。
- Result: 神经网络在性能上优于随机森林分类器。
- Conclusion: 面部地标箱线图技术有效，神经网络更适合面部情感识别任务。


### [111] [Hunyuan-GameCraft: High-dynamic Interactive Game Video Generation with Hybrid History Condition](https://arxiv.org/abs/2506.17201)
*Jiaqi Li,Junshu Tang,Zhiyong Xu,Longhuang Wu,Yuan Zhou,Shuai Shao,Tianbao Yu,Zhiguo Cao,Qinglin Lu*

Main category: cs.CV

TL;DR: Hunyuan-GameCraft提出了一种用于游戏环境中高动态交互视频生成的新框架，解决了现有方法在动态性、通用性、长期一致性和效率上的限制。

- Motivation: 当前基于扩散和可控视频生成的方法在动态性、通用性、长期一致性和效率上存在局限，限制了多样化游戏视频的生成能力。
- Method: 通过统一键盘和鼠标输入到共享相机表示空间，提出混合历史条件训练策略，并进行模型蒸馏以提高推理效率。
- Result: 在大规模数据集上训练和微调后，Hunyuan-GameCraft显著优于现有模型，提升了交互游戏视频的真实感和可玩性。
- Conclusion: Hunyuan-GameCraft在交互游戏视频生成中实现了更高的真实感和可玩性，适用于复杂实时环境。


### [112] [UniFork: Exploring Modality Alignment for Unified Multimodal Understanding and Generation](https://arxiv.org/abs/2506.17202)
*Teng Li,Quanfeng Lu,Lirui Zhao,Hao Li,Xizhou Zhu,Yu Qiao,Jun Zhang,Wenqi Shao*

Main category: cs.CV

TL;DR: 论文提出了一种名为UniFork的新型Y形架构，用于解决统一图像理解与生成任务中模态对齐冲突的问题。该架构在浅层共享表示学习，深层采用任务特定分支，显著优于传统全共享Transformer架构。

- Motivation: 统一图像理解与生成任务中，模态对齐模式存在冲突：理解任务需要逐步增强对齐以构建语义信息，而生成任务则需在深层减少对齐以恢复空间细节。这种冲突导致全共享Transformer架构性能受限。
- Method: 提出UniFork架构，浅层共享表示学习，深层采用任务特定分支，避免任务干扰。通过消融实验验证其有效性。
- Result: UniFork在性能上优于传统全共享Transformer架构，并与任务特定模型相当或更好。
- Conclusion: UniFork通过平衡共享学习与任务专业化，解决了统一模型中模态对齐冲突问题，为多模态AI提供了更优的架构设计。


### [113] [Part$^{2}$GS: Part-aware Modeling of Articulated Objects using 3D Gaussian Splatting](https://arxiv.org/abs/2506.17212)
*Tianjiao Yu,Vedant Shah,Muntasir Wahed,Ying Shen,Kiet A. Nguyen,Ismini Lourentzou*

Main category: cs.CV

TL;DR: Part$^{2}$GS是一种新型框架，用于建模多部分物体的高保真几何和物理一致性的铰接数字孪生体，通过部分感知的3D高斯表示和物理约束实现。

- Motivation: 现实世界中的铰接物体建模仍具挑战性，现有方法难以同时实现高保真几何和物理一致性。
- Method: 采用部分感知的3D高斯表示，结合物理约束（如接触强制、速度一致性和矢量场对齐）和排斥点场防止碰撞。
- Result: 在合成和真实数据集上，Part$^{2}$GS在可移动部分的Chamfer距离上比现有方法提升高达10倍。
- Conclusion: Part$^{2}$GS通过结构化表示和物理约束，显著提升了铰接物体建模的性能和一致性。


### [114] [Long-term Traffic Simulation with Interleaved Autoregressive Motion and Scenario Generation](https://arxiv.org/abs/2506.17213)
*Xiuyu Yang,Shuhan Tan,Philipp Krähenbühl*

Main category: cs.CV

TL;DR: InfGen是一种统一的下一令牌预测模型，用于交替执行闭环运动模拟和场景生成，支持长期稳定的交通模拟。

- Motivation: 现有模型和基准主要关注场景中初始代理的闭环运动模拟，无法满足长期模拟的需求，因为代理会随着车辆进入新区域而进出场景。
- Method: InfGen通过交替执行闭环运动模拟和场景生成模式，自动切换以实现长期模拟。
- Result: InfGen在短期（9秒）交通模拟中达到最先进水平，在长期（30秒）模拟中显著优于其他方法。
- Conclusion: InfGen为长期交通模拟提供了一种有效的解决方案，代码和模型将公开发布。


### [115] [Machine Mental Imagery: Empower Multimodal Reasoning with Latent Visual Tokens](https://arxiv.org/abs/2506.17218)
*Zeyuan Yang,Xueyang Yu,Delin Chen,Maohao Shen,Chuang Gan*

Main category: cs.CV

TL;DR: Mirage框架通过隐式视觉标记增强VLM的解码能力，避免显式图像生成，从而提升多模态推理性能。

- Motivation: 现有VLM在需要视觉想象的任务中表现受限，因为其仅能通过文本解码表达视觉推理。
- Method: 提出Mirage框架，通过隐式视觉标记和文本标记交替解码，结合蒸馏和强化学习优化多模态推理。
- Result: 实验证明Mirage在不生成显式图像的情况下显著提升了多模态推理能力。
- Conclusion: Mirage为VLM提供了一种更高效的视觉推理方式，避免了图像生成的计算负担。


### [116] [Emergent Temporal Correspondences from Video Diffusion Transformers](https://arxiv.org/abs/2506.17220)
*Jisu Nam,Soowon Son,Dahyun Chung,Jiyoung Kim,Siyoon Jin,Junhwa Hur,Seungryong Kim*

Main category: cs.CV

TL;DR: DiffTrack是一个定量分析框架，用于研究视频扩散模型（DiTs）如何建立和表示帧间时间对应关系。

- Motivation: 尽管基于DiTs的视频扩散模型在生成时间连贯视频方面取得了显著成功，但其内部如何建立和表示时间对应关系仍不清楚。
- Method: DiffTrack构建了一个带有伪真实跟踪注释的数据集，并提出了新的评估指标，系统分析DiTs的3D注意力机制中各组件（如表示、层和时间步）对时间对应关系的作用。
- Result: 分析发现特定层中的查询-键相似性在时间匹配中起关键作用，且这种匹配在去噪过程中逐渐显著。DiffTrack在零样本点跟踪中表现优异，并可用于改进视频生成的时间一致性。
- Conclusion: DiffTrack为理解视频DiTs的内部机制提供了关键见解，并为未来研究和应用奠定了基础。


### [117] [VLN-R1: Vision-Language Navigation via Reinforcement Fine-Tuning](https://arxiv.org/abs/2506.17221)
*Zhangyang Qi,Zhixiong Zhang,Yizhou Yu,Jiaqi Wang,Hengshuang Zhao*

Main category: cs.CV

TL;DR: VLN-R1是一个端到端框架，利用大型视觉语言模型（LVLM）将第一视角视频流直接转换为连续导航动作，采用GRPO训练方法，并在VLN-CE基准测试中表现优异。

- Motivation: 当前基于语言模型的导航系统局限于离散拓扑图，限制了路径规划能力，因此需要一种能够直接处理连续动作的导航框架。
- Method: VLN-R1采用两阶段训练：监督微调（SFT）对齐专家演示的动作序列文本预测，强化微调（RFT）结合时间衰减奖励（TDR）机制优化多步动作。
- Result: VLN-R1在VLN-CE基准测试中表现优异，证明了LVLM在具身导航中的潜力。
- Conclusion: VLN-R1展示了LVLM通过数据高效、奖励驱动的后训练，能够增强任务特定推理能力。
## cs.GR

### [118] [GratNet: A Photorealistic Neural Shader for Diffractive Surfaces](https://arxiv.org/abs/2506.15815)
*Narayan Kandel,Daljit Singh J. S. Dhillon*

Main category: cs.GR

TL;DR: 提出了一种基于多层感知机（MLP）的数据驱动方法，用于高效、高精度地渲染衍射表面，显著减少数据依赖性和内存占用。

- Motivation: 当前结构着色模型依赖密集的预处理数据，缺乏对隐式神经表示的全面研究，因此需要一种更高效的方法。
- Method: 采用MLP进行数据压缩和建模，避免过拟合，并具有鲁棒的重采样行为。
- Result: 在PSNR、SSIM和FLIP指标下，方法能高质量重建真实数据，内存占用减少两个数量级。
- Conclusion: 该方法在保持主观相似效果的同时，显著提升了性能，适用于衍射表面渲染。


### [119] [VEIGAR: View-consistent Explicit Inpainting and Geometry Alignment for 3D object Removal](https://arxiv.org/abs/2506.15821)
*Pham Khai Nguyen Do,Bao Nguyen Tran,Nam Nguyen,Duc Dung Nguyen*

Main category: cs.GR

TL;DR: VEIGAR是一种高效框架，无需初始3D重建阶段，通过轻量级基础模型和尺度不变深度损失监督策略，显著提升重建质量和跨视图一致性，同时减少训练时间。

- Motivation: 现有方法依赖初始3D重建阶段，计算成本高且效果不佳，需要更高效且高质量的解决方案。
- Method: VEIGAR利用轻量级基础模型在像素空间显式对齐先验，并引入尺度不变深度损失监督策略。
- Result: VEIGAR在重建质量和跨视图一致性上达到新标杆，训练时间减少三倍。
- Conclusion: VEIGAR在效率和效果上均优于现有方法，为NVS和3D生成任务提供了更优解决方案。


### [120] [FlatCAD: Fast Curvature Regularization of Neural SDFs for CAD Models](https://arxiv.org/abs/2506.16627)
*Haotian Yin,Aleksander Plocharski,Michal Jan Wlodarczyk,Mikolaj Kida,Przemyslaw Musialski*

Main category: cs.GR

TL;DR: 提出了一种新的曲率代理方法，通过仅正则化混合二阶项（Weingarten项），避免了完整Hessian计算，显著降低了内存和运行时成本。

- Motivation: 神经符号距离场（SDF）在几何学习中广泛应用，但传统方法依赖高斯曲率惩罚，需要完整Hessian评估和二阶自动微分，成本高昂。
- Method: 提出两种曲率代理实现：(i) 有限差分代理，用四个前向SDF评估和一个一阶梯度替换Hessian条目；(ii) 自动微分代理，通过Hessian-向量积计算混合导数，避免完整Hessian组装。
- Result: 在ABC基准测试中，代理方法在重建保真度上匹配或超越基于Hessian的基线，同时将GPU内存和运行时间减半。
- Conclusion: 该方法为工程级形状重建提供了可扩展、曲率感知的SDF学习路径。


### [121] [Beyond Blur: A Fluid Perspective on Generative Diffusion Models](https://arxiv.org/abs/2506.16827)
*Grzegorz Gruszczynski,Michal Jan Wlodarczyk,Jakub J Meixner,Przemyslaw Musialski*

Main category: cs.GR

TL;DR: 提出了一种基于PDE的图像生成方法，结合了平流-扩散过程，通过GPU加速求解器实现高效计算，并展示了其在生成多样性和质量上的优势。

- Motivation: 现有PDE方法在图像生成中存在局限性，需要更通用的物理驱动模型来提升生成效果。
- Method: 采用平流-扩散PDE，结合随机速度场生成湍流，通过神经网络学习逆操作实现图像生成。
- Result: 该方法能生成更高质量和多样性的图像，同时保持色彩一致性，且兼容现有PDE技术。
- Conclusion: 该工作为基于物理的图像生成提供了新视角，结合流体动力学与深度学习，扩展了PDE在生成模型中的应用。


### [122] [DreamCube: 3D Panorama Generation via Multi-plane Synchronization](https://arxiv.org/abs/2506.17206)
*Yukun Huang,Yanning Zhou,Jianan Wang,Kaiyi Huang,Xihui Liu*

Main category: cs.GR

TL;DR: 论文提出了一种通过多平面同步技术将2D基础模型能力扩展到全景领域的方法，并开发了DreamCube模型，用于生成高质量3D全景内容。

- Motivation: 解决现有方法因3D全景数据稀缺而依赖2D基础模型，但2D单视图与3D全景不兼容的问题。
- Method: 应用多平面同步技术扩展2D基础模型能力，并开发DreamCube模型，利用RGB-D扩散模型生成3D全景。
- Result: 实验证明该方法在全景图像生成、深度估计和3D场景生成中表现优异。
- Conclusion: 通过多平面同步和DreamCube模型，成功实现了高质量3D全景内容的生成。
## astro-ph.EP

### [123] [Exoplanet Classification through Vision Transformers with Temporal Image Analysis](https://arxiv.org/abs/2506.16597)
*Anupma Choudhary,Sohith Bandari,B. S. Kushvah,C. Swastik*

Main category: astro-ph.EP

TL;DR: 该研究提出了一种利用Gramian Angular Fields和Recurrence Plots转换开普勒任务光曲线数据，并通过Vision Transformer模型高效分类系外行星的方法。结果表明Recurrence Plots表现更优，模型在召回率和精确率上表现突出，但数据量减少仍是限制。

- Motivation: 传统系外行星分类方法耗费资源且效率低，需引入先进机器学习技术提升效率。
- Method: 将开普勒任务的光曲线数据转换为Gramian Angular Fields和Recurrence Plots图像，输入Vision Transformer模型进行训练和评估。
- Result: 模型在5折交叉验证中表现优异，Recurrence Plots优于Gramian Angular Fields，召回率89.46%，精确率85.09%。
- Conclusion: 研究强调了优化模型架构的重要性，以提升自动化、性能和泛化能力，但数据量减少仍是挑战。
## physics.ins-det

### [124] [Bias Variation Compensation in Perimeter-Gated SPAD TRNGs](https://arxiv.org/abs/2506.15888)
*Md Sakibur Sajal,Hunter Guthrie,Marc Dandin*

Main category: physics.ins-det

TL;DR: 论文提出了一种基于64x64阵列的pgSPADs的随机数生成器，通过BV补偿技术实现低偏差的随机二进制字符串生成。

- Motivation: 现有硬件友好的去偏算法无法适应广泛的偏差变化（BV），因此需要一种能够有效补偿BV的随机数生成方法。
- Method: 使用64x64阵列的pgSPADs作为熵源，通过调整栅极电压补偿BV，并结合Von Neumann算法去偏。
- Result: 在室温下实现了小于1%的BV，并通过了NIST统计测试套件的全部16项测试。
- Conclusion: 该方法在硬件实现中有效解决了BV问题，并生成了高质量的随机数。
## cs.MM

### [125] [DT-UFC: Universal Large Model Feature Coding via Peaky-to-Balanced Distribution Transformation](https://arxiv.org/abs/2506.16495)
*Changsheng Gao,Zijie Liu,Li Li,Dong Liu,Xiaoyan Sun,Weisi Lin*

Main category: cs.MM

TL;DR: 本文提出了一种通用的特征编码方法，通过数据驱动的分布变换解决不同大模型特征分布不兼容的问题，显著提升了压缩效率和跨模型泛化能力。

- Motivation: 现有特征编码方法多针对特定任务或模型，缺乏通用性，难以应对不同大模型特征分布的多样性。
- Method: 提出一种学习到的峰值到平衡分布变换方法，将异构特征分布对齐到统一目标空间，无需修改下游编码器。
- Result: 在LLaMA3、DINOv2和SD3等模型上验证，压缩效率和跨模型泛化能力显著优于任务专用基线。
- Conclusion: 该方法为通用特征编码提供了有效解决方案，代码将开源以促进未来研究。
## cs.AI

### [126] [The Safety Reminder: A Soft Prompt to Reactivate Delayed Safety Awareness in Vision-Language Models](https://arxiv.org/abs/2506.15734)
*Peiyuan Tang,Haojie Xin,Xiaodong Zhang,Jun Sun,Qin Xia,Zijiang Yang*

Main category: cs.AI

TL;DR: 论文提出了一种名为“安全提醒”的软提示调优方法，用于增强视觉语言模型（VLM）的安全意识，防止生成有害内容。

- Motivation: 随着视觉语言模型（VLM）在代码生成和聊天机器人等实际应用中的能力增强，其安全问题变得至关重要。VLM的多模态特性使其面临独特的漏洞，攻击者可能通过修改视觉或文本输入绕过安全防护，触发有害内容生成。
- Method: 通过系统分析VLM在攻击下的行为，发现了一种称为“延迟安全意识”的现象。基于此，提出了一种软提示调优方法“安全提醒”，通过优化可学习的提示令牌，在文本生成过程中定期注入以增强安全意识。
- Result: 在三个安全基准和一个对抗攻击测试中，该方法显著降低了攻击成功率，同时保持了模型在正常任务中的性能。
- Conclusion: “安全提醒”提供了一种实用的解决方案，能够在实际应用中部署更安全的VLM，同时不影响正常对话和模型性能。


### [127] [IS-Bench: Evaluating Interactive Safety of VLM-Driven Embodied Agents in Daily Household Tasks](https://arxiv.org/abs/2506.16402)
*Xiaoya Lu,Zeren Chen,Xuhao Hu,Yijin Zhou,Weichen Zhang,Dongrui Liu,Lu Sheng,Jing Shao*

Main category: cs.AI

TL;DR: 论文提出了IS-Bench，首个用于评估交互式安全性的多模态基准，揭示了当前VLM驱动的智能体在交互安全性上的不足。

- Motivation: 现有静态评估范式无法动态模拟交互环境中的风险，导致无法充分评估智能体的安全性，亟需新的评估方法。
- Method: 提出IS-Bench，包含161个场景和388种安全风险，支持过程导向的评估，验证风险缓解步骤的顺序。
- Result: 实验显示当前智能体缺乏交互安全意识，安全感知的Chain-of-Thought虽能提升性能，但常影响任务完成。
- Conclusion: IS-Bench为开发更安全的AI系统奠定了基础，揭示了现有方法的局限性。


### [128] [AI's Blind Spots: Geographic Knowledge and Diversity Deficit in Generated Urban Scenario](https://arxiv.org/abs/2506.16898)
*Ciro Beneduce,Massimiliano Luca,Bruno Lepri*

Main category: cs.AI

TL;DR: Error

- Motivation: Error
- Method: Error
- Result: Error
- Conclusion: Error
## cs.LG

### [129] [Global Context-aware Representation Learning for Spatially Resolved Transcriptomics](https://arxiv.org/abs/2506.15698)
*Yunhak Oh,Junseok Lee,Yeongmin Kim,Sangwoo Seo,Namkyeong Lee,Chanyoung Park*

Main category: cs.LG

TL;DR: 论文提出Spotscape框架，通过Similarity Telescope模块和相似性缩放策略改进SRT中的空间域识别，尤其在边界区域表现优异。

- Motivation: 现有基于图的方法在SRT中难以有效识别边界区域的空间域，因其过于依赖相邻点而忽略全局关系。
- Method: 提出Spotscape框架，引入Similarity Telescope模块捕捉全局关系，并设计相似性缩放策略优化多切片整合。
- Result: 实验证明Spotscape在单切片和多切片任务中表现优越。
- Conclusion: Spotscape为SRT中的空间域识别提供了更有效的解决方案。


### [130] [Shadow defense against gradient inversion attack in federated learning](https://arxiv.org/abs/2506.15711)
*Le Jiang,Liyan Ma,Guang Yang*

Main category: cs.LG

TL;DR: 该论文提出了一种针对联邦学习中梯度反转攻击的防御框架，通过影子模型识别敏感区域并针对性注入噪声，显著提升了隐私保护效果，同时最小化对模型性能的影响。

- Motivation: 联邦学习在隐私保护分布式训练中具有重要作用，但梯度反转攻击可能导致隐私泄露。现有防御方法缺乏对梯度或图像信息敏感性的精确理解，导致保护不足或模型性能下降。
- Method: 利用具有可解释性的影子模型识别敏感区域，并针对性地注入噪声，实现更精准的隐私保护。
- Result: 在ChestXRay和EyePACS数据集上，PSNR和SSIM指标显著优于无防御情况，且对模型性能影响极小（F1值下降小于1%）。
- Conclusion: 该框架在多种医疗图像上验证了其泛化能力，为联邦学习提供了稳定且通用的防御策略。


### [131] [Tripartite Weight-Space Ensemble for Few-Shot Class-Incremental Learning](https://arxiv.org/abs/2506.15720)
*Juntae Lee,Munawar Hayat,Sungrack Yun*

Main category: cs.LG

TL;DR: 论文提出了一种新的少样本类增量学习（FSCIL）方法Tri-WE，通过权重空间集成和知识蒸馏解决灾难性遗忘和过拟合问题，并在多个数据集上取得最优结果。

- Motivation: FSCIL中固定特征提取器限制了模型对新类的适应性，导致灾难性遗忘和过拟合。
- Method: 提出Tri-WE方法，在权重空间中集成基础模型、前一个模型和当前模型，并引入基于知识蒸馏的正则化损失。
- Result: 在miniImageNet、CUB200和CIFAR100数据集上取得最优性能。
- Conclusion: Tri-WE方法通过动态更新整个模型和知识蒸馏，有效解决了FSCIL中的核心挑战。


### [132] [Watermarking Autoregressive Image Generation](https://arxiv.org/abs/2506.16349)
*Nikola Jovanović,Ismail Labiad,Tomáš Souček,Martin Vechev,Pierre Fernandez*

Main category: cs.LG

TL;DR: 本文提出了一种在自回归图像生成模型中嵌入水印的方法，解决了重新标记图像令牌时水印丢失的问题，并通过实验验证了其可靠性和鲁棒性。

- Motivation: 随着生成模型的普及，追踪其输出来源的需求日益增加，但目前尚无针对自回归图像生成模型的令牌级水印方法。
- Method: 通过调整语言模型水印技术，引入自定义的标记器-去标记器微调流程和同步层，以应对重新标记带来的水印丢失问题。
- Result: 实验表明，该方法能够可靠且鲁棒地检测水印，并提供理论支持的p值。
- Conclusion: 该方法为自回归图像生成模型的水印嵌入提供了首个令牌级解决方案，具有实用性和理论保障。


### [133] [Subspace-Boosted Model Merging](https://arxiv.org/abs/2506.16506)
*Ronald Skorobogat,Karsten Roth,Mariana-Iuliana Georgescu,Zeynep Akata*

Main category: cs.LG

TL;DR: 论文提出了一种名为Subspace Boosting的方法，用于解决多专家模型合并中的任务向量空间秩崩溃问题，显著提升了合并效果。

- Motivation: 随着合并的专家模型数量增加，性能增益逐渐减少，原因是任务向量空间出现秩崩溃。
- Method: 引入Subspace Boosting方法，通过奇异值分解维护任务向量秩，并使用高阶广义奇异值分解量化任务相似性。
- Result: 在视觉基准测试中，Subspace Boosting将合并效果提升了超过10%，支持多达20个专家模型。
- Conclusion: Subspace Boosting有效解决了模型合并中的秩崩溃问题，并提供了任务相似性的新视角。


### [134] [From Lab to Factory: Pitfalls and Guidelines for Self-/Unsupervised Defect Detection on Low-Quality Industrial Images](https://arxiv.org/abs/2506.16890)
*Sebastian Hönel,Jonas Nordqvist*

Main category: cs.LG

TL;DR: 论文探讨了工业产品表面缺陷检测中机器学习方法的局限性，提出了改进数据质量和模型鲁棒性的框架。

- Motivation: 传统手动检测成本高且易出错，机器学习虽有望替代，但现有方法在低质量数据和实际场景中表现不佳，且常用指标（如AUROC）可能误导实践者。
- Method: 评估了两种先进模型，用于识别和改进生产数据中的质量问题，无需新数据，并提出了问题诊断框架。
- Result: 研究发现基于似然的方法存在常见缺陷，提出了更适合实际场景的经验风险估计框架。
- Conclusion: 为实践者提供了识别模型或数据问题的指导，并改进了现有方法的实用性。
## q-bio.QM

### [135] [Smartphone-integrated RPA-CRISPR-Cas12a Detection System with Microneedle Sampling for Point-of-Care Diagnosis of Potato Late Blight in Early Stage](https://arxiv.org/abs/2506.15728)
*Jiangnan Zhao,Hanbo Xu,Cifu Xu,Wenlong Yin,Laixin Luo,Gang Liu,Yan Wang*

Main category: q-bio.QM

TL;DR: 开发了一种便携式RPA-CRISPR诊断系统，结合智能手机进行荧光图像分析，用于马铃薯晚疫病的早期检测。

- Motivation: 传统PCR和LAMP方法依赖昂贵实验室设备且操作复杂，不适用于田间即时诊断。
- Method: 采用PVA微针贴片快速提取植物叶片样本，建立RPA-CRISPR-Cas12a等温检测系统，特异性靶向P. infestans。
- Result: 检测限为2 pg/uL，灵敏度媲美实验室设备，接种后第3天和第4天检测率分别达80%和100%。
- Conclusion: 该系统摆脱了对专业设备的依赖，为田间植物病害早期检测提供了可行方案。
## cs.CY

### [136] [TrajSceneLLM: A Multimodal Perspective on Semantic GPS Trajectory Analysis](https://arxiv.org/abs/2506.16401)
*Chunhou Ji,Qiumeng Li*

Main category: cs.CY

TL;DR: TrajSceneLLM结合地图图像和LLM生成的文本描述，提升GPS轨迹的语义理解，显著提高了旅行模式识别的性能。

- Motivation: 传统方法难以提取GPS轨迹的深层语义表示和结合地图上下文信息，需要一种新方法增强语义理解。
- Method: 通过整合地图图像和LLM生成的文本描述，生成多模态嵌入，并结合简单MLP分类器。
- Result: 实验表明，该方法在旅行模式识别任务中性能显著提升，减少了对手工特征的依赖。
- Conclusion: TrajSceneLLM在捕捉时空依赖性和语义增强方面具有潜力，适用于地理空间人工智能的多样化应用。
## cs.CG

### [137] [Wavelet-based Global Orientation and Surface Reconstruction for Point Clouds](https://arxiv.org/abs/2506.16299)
*Yueji Ma,Yanzun Meng,Dong Xiao,Zuoqiang Shi,Bin Wang*

Main category: cs.CG

TL;DR: 提出了一种基于小波的方法，用于处理无定向点云的重建问题，通过改进核函数和利用小波基函数的性质，实现了高效且稳定的重建。

- Motivation: 经典小波表面重建方法仅适用于定向点云，而现有改进方法在稀疏点云上表现不佳，因此需要一种更有效的方法。
- Method: 利用小波基函数表示平滑指示函数，通过改进核函数消除表面不连续性，并利用卷积核函数性质加速计算；同时提出构建无散度函数场以增强稳定性和效果。
- Result: 实验表明，该方法在稀疏点云的定向和重建任务上达到最优性能，并在CPU上实现高效运行。
- Conclusion: 该方法解决了无定向点云重建的挑战，具有高效性和稳定性，代码将开源。
## eess.IV

### [138] [Pixel-wise Modulated Dice Loss for Medical Image Segmentation](https://arxiv.org/abs/2506.15744)
*Seyed Mohsen Hosseini*

Main category: eess.IV

TL;DR: 论文提出了一种改进的Dice损失函数（PM Dice损失），通过像素级调制项同时解决医学分割任务中的类别不平衡和难度不平衡问题，计算成本低且效果优于现有方法。

- Motivation: 医学分割任务中存在类别不平衡和难度不平衡问题，导致神经网络训练效果不佳。现有方法计算成本高且效果有限，因此需要一种更简单有效的解决方案。
- Method: 在Dice损失函数中引入像素级调制项，利用Dice损失处理类别不平衡的优势，同时解决难度不平衡问题。
- Result: 在三种常用医学分割任务中，PM Dice损失表现优于其他针对难度不平衡问题设计的方法。
- Conclusion: PM Dice损失是一种计算成本低且有效的解决方案，能够同时处理类别和难度不平衡问题。


### [139] [Diffusion-based Counterfactual Augmentation: Towards Robust and Interpretable Knee Osteoarthritis Grading](https://arxiv.org/abs/2506.15748)
*Zhe Wang,Yuhua Ru,Aladine Chetouani,Tina Shiang,Fang Chen,Fabian Bauer,Liping Zhang,Didier Hans,Rachid Jennane,William Ewing Palmer,Mohamed Jarraya,Yung Hsin Chen*

Main category: eess.IV

TL;DR: 提出了一种基于扩散模型的反事实增强框架（DCA），通过生成针对性反事实样本提升模型鲁棒性和可解释性，显著提高了膝关节骨关节炎（KOA）自动分级的准确性。

- Motivation: 膝关节骨关节炎（KOA）的自动分级存在观察者间差异大和深度学习模型鲁棒性不足的问题，尤其是在关键决策边界附近。
- Method: 使用扩散模型和随机微分方程（SDE）生成反事实样本，结合自校正学习策略优化分类器。
- Result: 在公开数据集上的实验表明，该方法显著提高了分类准确性，且生成的潜在空间拓扑与KOA临床进展知识一致。
- Conclusion: DCA框架将模型不确定性转化为鲁棒训练信号，为开发更准确、可信的自动诊断系统提供了新途径。


### [140] [MoNetV2: Enhanced Motion Network for Freehand 3D Ultrasound Reconstruction](https://arxiv.org/abs/2506.15835)
*Mingyuan Luo,Xin Yang,Zhongnuo Yan,Yan Cao,Yuanji Zhang,Xindi Hu,Jin Wang,Haoxuan Ding,Wei Han,Litao Sun,Dong Ni*

Main category: eess.IV

TL;DR: MoNetV2通过融合图像与运动信息、多级一致性约束和多模态自监督策略，显著提升了自由手3D超声重建的准确性和泛化能力。

- Motivation: 自由手3D超声重建在复杂运动轨迹下存在累积漂移和精度不足的问题，需改进以支持不同扫描速度和策略。
- Method: 提出传感器辅助的时空多分支结构、在线多级一致性约束和多模态自监督策略，结合图像与运动信息优化重建。
- Result: MoNetV2在三个大型数据集上超越现有方法，重建质量和泛化性能显著提升。
- Conclusion: MoNetV2通过多模态融合和一致性约束，有效解决了自由手3D超声重建的挑战，具有广泛临床应用潜力。


### [141] [Cross-Modality Learning for Predicting IHC Biomarkers from H&E-Stained Whole-Slide Images](https://arxiv.org/abs/2506.15853)
*Amit Das,Naofumi Tomita,Kyle J. Syme,Weijie Ma,Paige O'Connor,Kristin N. Corbett,Bing Ren,Xiaoying Liu,Saeed Hassanpour*

Main category: eess.IV

TL;DR: HistoStainAlign是一种深度学习框架，直接从H&E全切片图像预测IHC染色模式，无需标注或组织配准，提高了诊断效率。

- Motivation: IHC染色成本高、耗时长，限制了其在病理分析中的应用。本研究旨在通过计算模型预测IHC染色模式，减少对实际IHC染色的依赖。
- Method: 提出HistoStainAlign框架，通过对比训练策略整合H&E和IHC的联合表征，无需标注或组织配准。
- Result: 在胃肠道和肺组织WSIs上评估，对P53、PD-L1和Ki-67三种IHC染色的加权F1分数分别为0.735、0.830和0.723。
- Conclusion: HistoStainAlign展示了计算模型作为预筛查工具的潜力，可优化IHC染色工作流程。


### [142] [Fast Training-free Perceptual Image Compression](https://arxiv.org/abs/2506.16102)
*Ziran Zhu,Tongda Xu,Minye Huang,Dailan He,Xingtong Ge,Xinjie Zhang,Ling Li,Yan Wang*

Main category: eess.IV

TL;DR: 提出一种无需训练的算法，显著提升现有图像编码器的感知质量，并优化解码时间。

- Motivation: 现有无需训练的感知图像编码器依赖耗时方法（如扩散反转或样本通信），解码时间过长。
- Method: 提出一种理论保证的算法，针对不同解码时间预算（≈0.1s、0.1-10s、≥10s）优化感知质量。
- Result: 将解码时间从1分钟缩短至0.1-10秒，感知质量相当；适用于非可微分编码器（如VTM），并提升现有感知编码器（如MS-ILLM）。
- Conclusion: 该方法在快速解码下显著提升感知质量，FID优于现有条件生成模型编码器（如HiFiC和MS-ILLM）。


### [143] [Enhanced Dermatology Image Quality Assessment via Cross-Domain Training](https://arxiv.org/abs/2506.16116)
*Ignacio Hernández Montilla,Alfonso Medela,Paola Pasquali,Andy Aguilar,Taig Mac Carthy,Gerardo Fernández,Antonio Martorell,Enrique Onieva*

Main category: eess.IV

TL;DR: 论文提出跨域训练图像质量评估（IQA）模型，结合皮肤病学和非皮肤病学数据集，解决皮肤病远程诊疗中图像质量差的问题。

- Motivation: 皮肤病远程诊疗中图像质量差是主要问题，但现有研究未充分利用非皮肤病学IQA的最新进展。
- Method: 创建新的皮肤病IQA数据集，结合跨域训练方法，利用更大规模的图像数据。
- Result: 跨域训练提高了模型性能，解决了皮肤病IQA数据规模小的限制。
- Conclusion: 跨域训练优化了皮肤病远程诊疗中的图像质量管理。


### [144] [From Coarse to Continuous: Progressive Refinement Implicit Neural Representation for Motion-Robust Anisotropic MRI Reconstruction](https://arxiv.org/abs/2506.16210)
*Zhenxuan Zhang,Lipei Zhang,Yanqi Cheng,Zi Wang,Fanwen Wang,Haosen Zhang,Yue Yang,Yinzhe Wu,Jiahao Huang,Angelica I Aviles-Rivero,Zhifan Gao,Guang Yang,Peter J. Lally*

Main category: eess.IV

TL;DR: 提出了一种渐进式细化隐式神经表示（PR-INR）框架，用于解决运动鲁棒MRI中的切片到体积重建问题，显著提升了重建质量和鲁棒性。

- Motivation: 在加速采集或患者运动条件下，MRI的切片到体积重建面临局部细节丢失、全局结构混叠和体积各向异性等挑战。
- Method: PR-INR框架结合运动感知扩散模块、隐式细节恢复模块和体素连续感知表示模块，逐步实现运动校正、结构细化和体积合成。
- Result: 在多种运动条件、欠采样率和切片分辨率下，PR-INR在定量重建指标和视觉质量上均优于现有方法，并展现出跨领域的泛化能力。
- Conclusion: PR-INR为运动鲁棒MRI提供了一种高效且通用的解决方案，显著提升了重建精度和细节恢复能力。


### [145] [CF-Seg: Counterfactuals meet Segmentation](https://arxiv.org/abs/2506.16213)
*Raghav Mehta,Fabio De Sousa Ribeiro,Tian Xia,Melanie Roschewitz,Ainkaran Santhirasekaram,Dominic C. Marshall,Ben Glocker*

Main category: eess.IV

TL;DR: 通过生成反事实图像模拟无疾病状态下的解剖结构，改进医学图像分割，提升临床决策准确性。

- Motivation: 疾病会改变健康组织的表现，增加分割难度，可能导致误诊。因此，需要一种方法在不改变解剖结构的情况下模拟无疾病状态，以改进分割效果。
- Method: 生成反事实图像模拟无疾病状态下的解剖结构，并利用这些图像进行分割，无需修改现有分割模型。
- Result: 在两个真实临床胸部X光数据集上的实验表明，反事实图像的使用提高了解剖结构的分割准确性。
- Conclusion: 反事实图像能有效改进医学图像分割，为临床决策提供更可靠的支持。


### [146] [AGE-US: automated gestational age estimation based on fetal ultrasound images](https://arxiv.org/abs/2506.16256)
*César Díaz-Parga,Marta Nuñez-Garcia,Maria J. Carreira,Gabriel Bernardino,Nicolás Vila-Blanco*

Main category: eess.IV

TL;DR: 本文提出了一种基于深度学习的自动化孕周计算方法，通过新颖的分割架构和距离图解决了数据限制和标注稀缺问题，性能与现有最佳模型相当但复杂度更低。

- Motivation: 准确估计孕周对监测胎儿生长至关重要，但传统方法（如末次月经）在某些情况下难以获取，而超声方法虽可靠但依赖人工测量，存在变异性。
- Method: 采用可解释的深度学习方法，结合新颖的分割架构和距离图，克服数据集限制和标注稀缺问题。
- Result: 该方法性能与现有最佳模型相当，同时降低了复杂度，尤其适用于资源有限和标注数据稀缺的环境。距离图特别适合估计股骨端点。
- Conclusion: 提出的方法在孕周计算中表现出色，尤其适合资源受限环境，且距离图在特定任务中效果显著。


### [147] [VesselSDF: Distance Field Priors for Vascular Network Reconstruction](https://arxiv.org/abs/2506.16556)
*Salvatore Esposito,Daniel Rebain,Arno Onken,Changjian Li,Oisin Mac Aodha*

Main category: eess.IV

TL;DR: VesselSDF利用符号距离场（SDF）改进稀疏CT扫描中血管网络的连续分割，解决了现有方法在结构连续性和几何保真度上的不足。

- Motivation: 稀疏CT扫描中血管网络的准确分割面临挑战，尤其是血管的细长分支结构和扫描平面的稀疏性。现有深度学习方法在结构连续性和几何保真度上表现不佳。
- Method: 提出VesselSDF框架，将血管分割问题转化为连续的SDF回归问题，通过自适应高斯正则化消除SDF伪影，确保平滑性和几何精度。
- Result: 实验表明，VesselSDF显著优于现有方法，保留了血管的几何结构和连通性。
- Conclusion: VesselSDF为临床环境中的血管分析提供了更可靠的工具。


### [148] [DiffO: Single-step Diffusion for Image Compression at Ultra-Low Bitrates](https://arxiv.org/abs/2506.16572)
*Chanung Park,Joo Chan Lee,Jong Hwan Ko*

Main category: eess.IV

TL;DR: DiffO是一种单步扩散模型，用于图像压缩，提供高质量和快速解码，适用于极低比特率。

- Motivation: 现有方法在极低比特率下质量下降严重，且扩散模型解码延迟高。
- Method: 结合VQ残差训练和速率自适应噪声调制，分解结构基码和残差，动态调整去噪强度。
- Result: DiffO在压缩性能和解码速度上超越现有方法，速度提升约50倍。
- Conclusion: DiffO显著提升了生成编解码器的实用性。


### [149] [Hybrid Attention Network for Accurate Breast Tumor Segmentation in Ultrasound Images](https://arxiv.org/abs/2506.16592)
*Muhammad Azeem Aslam,Asim Naveed,Nisar Ahmed*

Main category: eess.IV

TL;DR: 提出了一种基于混合注意力的网络用于乳腺超声图像中的肿瘤分割，结合了DenseNet121编码器和多分支注意力增强解码器，通过全局空间注意力和混合损失函数优化性能。

- Motivation: 乳腺超声图像中的肿瘤分割因噪声、病变尺度变化和模糊边界而具有挑战性，需要更精确的自动化方法。
- Method: 采用预训练的DenseNet121编码器提取特征，结合多分支注意力增强解码器，引入全局空间注意力、位置编码和空间特征增强块，并使用混合损失函数优化。
- Result: 在公开数据集上的实验表明，该方法优于现有方法，能够更精确地分割肿瘤区域。
- Conclusion: 该方法在乳腺超声图像分割中表现出色，有望辅助放射科医生实现早期和准确的乳腺癌诊断。


### [150] [Overfitting in Histopathology Model Training: The Need for Customized Architectures](https://arxiv.org/abs/2506.16631)
*Saghir Alfasly,Ghazal Alabtah,H. R. Tizhoosh*

Main category: eess.IV

TL;DR: 研究发现，在组织病理学图像分析中，直接采用自然图像分析的大规模模型会导致过拟合和性能不佳，需定制专用架构。

- Motivation: 解决深度学习模型在组织病理学图像分析中的过拟合问题，并探索模型容量与性能的关系。
- Method: 通过实验比较不同模型架构（如ResNet和ViT），验证模型容量对性能的影响，并提出定制化架构。
- Result: 实验表明，增加模型容量不一定提升性能，而简单的领域专用架构能减少过拟合并表现更优。
- Conclusion: 组织病理学图像分析需定制化架构，尤其在数据有限时，简单专用模型更有效。


### [151] [A Prior-Guided Joint Diffusion Model in Projection Domain for PET Tracer Conversion](https://arxiv.org/abs/2506.16733)
*Fang Chen,Weifeng Zhang,Xingyu Ai,BingXuan Li,An Li,Qiegen Liu*

Main category: eess.IV

TL;DR: 该研究提出了一种先验引导的联合扩散模型（PJDM），用于在投影域中将18F-FDG PET图像转换为18F-DOPA PET图像，以提高图像质量和合成效果。

- Motivation: 18F-FDG PET在特定肿瘤中效果有限，而18F-DOPA PET具有更高特异性，但其合成复杂且临床应用受限。直接在投影域建模可减少重建过程中的误差累积。
- Method: 研究提出PJDM模型，包括粗估计模型和先验细化模型，通过高阶混合采样器生成初始合成图像，并利用学习到的先验进行迭代细化。
- Result: 实验结果表明，PJDM显著提高了投影域图像质量和合成效果。
- Conclusion: PJDM为18F-DOPA PET图像的生成提供了一种有效方法，代码已开源。


### [152] [Temperature calibration of surface emissivities with an improved thermal image enhancement network](https://arxiv.org/abs/2506.16803)
*Ning Chu,Siya Zheng,Shanqing Zhang,Li Li,Caifang Cai,Ali Mohammad-Djafari,Feng Zhao,Yuanbo Song*

Main category: eess.IV

TL;DR: 本文提出了一种物理引导的神经框架，通过对称跳跃-CNN架构和发射率感知注意力模块，统一温度校正和图像增强，解决了红外热成像中因材料发射率变化导致的温度精度问题。

- Motivation: 红外热成像中材料发射率的变化导致温度精度问题，现有方法常忽略辐射校准和图像退化的联合优化。
- Method: 采用对称跳跃-CNN架构和发射率感知注意力模块，结合双约束损失函数（均值-方差对齐和基于Kullback-Leibler散度的直方图匹配），动态融合热辐射特征和空间背景。
- Result: 在工业鼓风机系统不同条件下的验证中，该方法实现了热辐射特征和空间背景的动态融合，并在各种工业条件下获得准确的校准结果。
- Conclusion: 该方法通过联合优化温度校正和图像增强，有效抑制了发射率伪影并恢复了结构细节，提升了红外热成像的温度精度。


### [153] [PET Tracer Separation Using Conditional Diffusion Transformer with Multi-latent Space Learning](https://arxiv.org/abs/2506.16934)
*Bin Huang,Feihong Xu,Xinchong Shi,Shan Huang,Binxuan Li,Fei Li,Qiegen Liu*

Main category: eess.IV

TL;DR: 提出了一种多潜在空间引导的纹理条件扩散变换模型（MS-CDT），用于PET成像中的示踪剂分离，通过结合扩散和变换架构，利用纹理掩码和多潜在空间先验提升图像细节和分离准确性。

- Motivation: 多示踪剂PET成像能提供更全面的生理和病理信息，但由于不同示踪剂产生的光子对能量相同，信号难以区分。
- Method: 提出MS-CDT模型，整合扩散和变换架构，引入纹理掩码作为条件输入，利用多潜在空间先验捕获多层次特征。
- Result: 在脑部和胸部3D PET数据集上，MS-CDT在图像质量和临床信息保留方面表现优异。
- Conclusion: MS-CDT通过纹理条件和多潜在空间引导，实现了更准确和鲁棒的示踪剂分离，为多示踪剂PET成像提供了新方法。


### [154] [Robust Training with Data Augmentation for Medical Imaging Classification](https://arxiv.org/abs/2506.17133)
*Josué Martínez-Martínez,Olivia Brown,Mostafa Karami,Sheida Nabavi*

Main category: eess.IV

TL;DR: 提出了一种名为RTDA的鲁棒训练算法，用于增强医学图像分类模型对抗对抗性攻击和分布偏移的能力。

- Motivation: 深度神经网络在医学影像诊断中应用广泛，但其易受对抗性攻击和分布偏移影响，降低了诊断可靠性和信任度。
- Method: 采用数据增强的鲁棒训练算法（RTDA），并与六种基线技术（包括对抗训练和数据增强）进行对比。
- Result: RTDA在对抗性攻击和分布偏移下表现出更强的鲁棒性，同时保持高准确率。
- Conclusion: RTDA是一种有效的医学图像分类方法，能够提升模型的鲁棒性和泛化性能。


### [155] [MeDi: Metadata-Guided Diffusion Models for Mitigating Biases in Tumor Classification](https://arxiv.org/abs/2506.17140)
*David Jacob Drexlin,Jonas Dippel,Julius Hense,Niklas Prenißl,Grégoire Montavon,Frederick Klauschen,Klaus-Robert Müller*

Main category: eess.IV

TL;DR: 提出了一种基于元数据的生成扩散模型（MeDi），用于增强代表性不足的亚群数据，以减少下游模型的偏见。

- Motivation: 深度学习模型在组织学预测任务中表现优异，但面对不同条件（如染色、扫描仪、医院和人口统计学）时缺乏鲁棒性，导致偏见预测。
- Method: 提出MeDi框架，通过元数据引导生成合成数据，平衡训练数据并减少偏见。
- Result: MeDi在TCGA中生成了高质量图像，提升了生成图像的保真度，并改善了分类器在亚群偏移数据集上的性能。
- Conclusion: MeDi是减少数据偏见的生成模型的概念验证。


### [156] [Proportional Sensitivity in Generative Adversarial Network (GAN)-Augmented Brain Tumor Classification Using Convolutional Neural Network](https://arxiv.org/abs/2506.17165)
*Mahin Montasir Afif,Abdullah Al Noman,K. M. Tahsin Kabir,Md. Mortuza Ahmmed,Md. Mostafizur Rahman,Mufti Mahmud,Md. Ashraful Babu*

Main category: eess.IV

TL;DR: 研究探讨了GAN生成的脑肿瘤MRI图像与真实图像的不同比例对CNN分类性能的影响，发现少量GAN数据能显著提升模型性能，但过多会降低效果。

- Motivation: 解决医学影像数据稀缺问题，探索GAN生成数据在增强数据集中的有效性。
- Method: 使用DCGAN生成合成图像，与真实图像按不同比例混合训练CNN，并在真实测试集上评估性能。
- Result: 少量GAN数据（如100张）与900张真实数据混合时，模型测试准确率达95.2%，但GAN比例过高时性能下降。
- Conclusion: GAN生成数据可有效扩充有限数据集，但需控制比例以避免影响模型泛化能力。
## cs.RO

### [157] [PRISM-Loc: a Lightweight Long-range LiDAR Localization in Urban Environments with Topological Maps](https://arxiv.org/abs/2506.15849)
*Kirill Muravyev,Vasily Yuryev,Oleg Bulichev,Dmitry Yudin,Konstantin Yakovlev*

Main category: cs.RO

TL;DR: PRISM-Loc是一种基于拓扑地图的定位方法，用于大型环境中的实时定位，结合全局地点识别和局部位姿估计，性能优于现有方法。

- Motivation: 在长距离导航中，使用密集全局激光雷达地图进行实时定位可能困难且内存消耗大，因此需要拓扑地图的解决方案。
- Method: 提出PRISM-Loc方法，采用双重定位流程：全局地点识别和局部位姿估计，后者基于2D特征和点优化。
- Result: 在3公里路线的ITLP-Campus数据集上测试，PRISM-Loc在质量和计算效率上均优于现有方法。
- Conclusion: PRISM-Loc是一种高效且高性能的拓扑地图定位方法，适用于大型环境。


### [158] [Semantic and Feature Guided Uncertainty Quantification of Visual Localization for Autonomous Vehicles](https://arxiv.org/abs/2506.15851)
*Qiyuan Wu,Mark Campbell*

Main category: cs.RO

TL;DR: 本文提出了一种用于自动驾驶视觉定位的不确定性量化方法，通过轻量级传感器误差模型学习测量不确定性，并验证了其准确性。

- Motivation: 传感器测量与深度学习网络的不确定性量化对机器人系统（如自动驾驶汽车）至关重要，尤其是在安全关键应用中。
- Method: 使用轻量级传感器误差模型，将图像特征和语义信息映射到二维误差分布，以学习测量不确定性。
- Result: 在Ithaca365数据集上验证了方法的准确性，结果显示在恶劣天气和光照条件下，测量误差不符合高斯分布，而高斯混合模型能更好预测。
- Conclusion: 提出的方法能有效捕捉上下文相关的测量不确定性，为自动驾驶视觉定位提供了更准确的误差预测。


### [159] [Noise Fusion-based Distillation Learning for Anomaly Detection in Complex Industrial Environments](https://arxiv.org/abs/2506.16050)
*Jiawen Yu,Jieji Ren,Yang Chang,Qiaojun Yu,Xuan Tong,Boyang Wang,Yan Song,You Li,Xinji Mai,Wenqiang Zhang*

Main category: cs.RO

TL;DR: 提出了一种基于异构教师网络（HetNet）的新方法，用于复杂工业环境中的异常检测与定位，显著提升了性能。

- Motivation: 现有方法在复杂、非结构化工业环境中检测工件缺陷时表现不佳，需要更鲁棒的解决方案。
- Method: 采用异构教师网络（HetNet）、自适应局部-全局特征融合模块和局部多元高斯噪声生成模块。
- Result: 在主流基准测试中表现优异，MSC-AD指标提升约10%，并在其他数据集上达到SOTA。
- Conclusion: HetNet能有效应对环境波动，提升工业异常检测系统的可靠性，适用于实时检测。


### [160] [FlowRAM: Grounding Flow Matching Policy with Region-Aware Mamba Framework for Robotic Manipulation](https://arxiv.org/abs/2506.16201)
*Sen Wang,Le Wang,Sanping Zhou,Jingyi Tian,Jiayi Li,Haowen Sun,Wei Tang*

Main category: cs.RO

TL;DR: FlowRAM提出了一种基于生成模型的高效机器人操作框架，通过动态半径调度和多模态信息处理，显著提升了高精度任务的性能。

- Motivation: 当前基于扩散的策略学习方法在推理时计算效率低，且未充分利用生成模型在3D环境中的信息探索潜力。
- Method: FlowRAM结合动态半径调度、状态空间模型和条件流匹配，实现高效的多模态信息处理和动作生成。
- Result: 在RLBench基准测试中，FlowRAM平均成功率提升12%，且推理速度显著提高。
- Conclusion: FlowRAM在高精度机器人操作任务中表现出色，为实际应用提供了高效解决方案。


### [161] [Reimagination with Test-time Observation Interventions: Distractor-Robust World Model Predictions for Visual Model Predictive Control](https://arxiv.org/abs/2506.16565)
*Yuxin Chen,Jianglan Wei,Chenfeng Xu,Boyi Li,Masayoshi Tomizuka,Andrea Bajcsy,Ran Tian*

Main category: cs.RO

TL;DR: 论文提出ReOI方法，通过检测并移除视觉干扰物，提升世界模型在开放环境中的预测可靠性。

- Motivation: 现有世界模型在遇到训练中未见的视觉干扰物时表现脆弱，影响动作预测和下游任务。
- Method: ReOI方法包括检测干扰物、修改观测以移除干扰物、重新预测未来结果并恢复干扰物。
- Result: ReOI在机器人操作任务中显著提升任务成功率，尤其在新型干扰物存在时效果显著。
- Conclusion: ReOI是一种简单有效的测试时策略，能显著提升世界模型在开放环境中的鲁棒性。


### [162] [CodeDiffuser: Attention-Enhanced Diffusion Policy via VLM-Generated Code for Instruction Ambiguity](https://arxiv.org/abs/2506.16652)
*Guang Yin,Yitong Li,Yixuan Wang,Dale McConachie,Paarth Shah,Kunimatsu Hashimoto,Huan Zhang,Katherine Liu,Yunzhu Li*

Main category: cs.RO

TL;DR: 论文提出了一种新型机器人操作框架，通过Vision-Language Model（VLM）解析自然语言指令中的模糊性，生成可执行代码，并结合感知模块解决指令歧义。

- Motivation: 现有语言条件策略因缺乏模块化和可解释性，导致性能不佳，无法有效处理自然语言指令中的模糊性。
- Method: 使用VLM解析自然语言指令，生成任务特定代码，结合感知模块生成3D注意力图以解决指令歧义。
- Result: 实验表明，该方法在语言模糊性、接触密集操作和多物体交互等任务中表现优异。
- Conclusion: 该框架通过模块化和可解释性设计，显著提升了机器人处理模糊自然语言指令的能力。


### [163] [Monocular One-Shot Metric-Depth Alignment for RGB-Based Robot Grasping](https://arxiv.org/abs/2506.17110)
*Teng Guo,Baichuan Huang,Jingjin Yu*

Main category: cs.RO

TL;DR: 提出了一种名为MOMA的新框架，通过单次RGB图像恢复度量深度，解决了透明物体和深度传感器噪声问题，并在实际应用中表现出色。

- Motivation: 当前6D姿态估计依赖昂贵的深度传感器，且对透明物体效果不佳；现有单目深度估计模型（MDEMs）无法泛化。
- Method: 提出MOMA框架，通过单次适应MDEM技术，利用稀疏地面真实深度点进行尺度-旋转-平移对齐。
- Result: MOMA在透明物体上表现良好，并在实际抓取和分拣任务中取得高成功率。
- Conclusion: MOMA是一种高效的单次适应方法，适用于复杂场景和透明物体。


### [164] [Dex1B: Learning with 1B Demonstrations for Dexterous Manipulation](https://arxiv.org/abs/2506.17198)
*Jianglong Ye,Keyi Wang,Chengjing Yuan,Ruihan Yang,Yiquan Li,Jiyue Zhu,Yuzhe Qin,Xueyan Zou,Xiaolong Wang*

Main category: cs.RO

TL;DR: 论文介绍了Dex1B，一个通过生成模型创建的大规模、多样化和高质量的手部操作演示数据集，包含10亿个演示，用于抓取和关节任务。

- Motivation: 生成大规模的手部操作演示具有挑战性，现有方法需要改进。
- Method: 提出了一种结合几何约束和多样性条件的生成模型，用于构建数据集。
- Result: 在仿真和真实机器人实验中，模型显著优于现有方法。
- Conclusion: Dex1B数据集和生成模型为手部操作提供了高效且多样化的解决方案。
## cs.CL

### [165] [LaMP-Cap: Personalized Figure Caption Generation With Multimodal Figure Profiles](https://arxiv.org/abs/2506.06561)
*Ho Yin 'Sam' Ng,Ting-Yao Hsu,Aashish Anantha Ramakrishnan,Branislav Kveton,Nedim Lipka,Franck Dernoncourt,Dongwon Lee,Tong Yu,Sungchul Kim,Ryan A. Rossi,Ting-Hao 'Kenneth' Huang*

Main category: cs.CL

TL;DR: 论文提出LaMP-Cap数据集，用于个性化多模态图表标题生成，通过实验证明多模态信息能提升标题生成质量。

- Motivation: 现有AI生成的图表标题缺乏个性化，难以匹配作者风格和领域需求，需多模态个性化方法。
- Method: 引入LaMP-Cap数据集，结合图表图像、标题及相关段落作为多模态输入，实验验证其效果。
- Result: 实验表明多模态信息（如图像）比纯文本更能提升标题生成质量，接近作者原创标题。
- Conclusion: 多模态个性化方法在图表标题生成中具有优势，LaMP-Cap为未来研究提供新方向。


### [166] [Cross-Modal Obfuscation for Jailbreak Attacks on Large Vision-Language Models](https://arxiv.org/abs/2506.16760)
*Lei Jiang,Zixun Zhang,Zizhou Wang,Xiaobing Sun,Zhen Li,Liangli Zhen,Xiaohua Xu*

Main category: cs.CL

TL;DR: CAMO是一种新型的黑盒越狱攻击框架，通过将恶意提示分解为视觉和文本片段，利用LVLMs的跨模态推理能力绕过安全机制。

- Motivation: 现有黑盒越狱方法容易被检测且效率低，CAMO旨在解决这些问题。
- Method: CAMO将恶意提示分解为良性视觉和文本片段，利用LVLMs的跨模态推理能力重构有害指令。
- Result: CAMO在主流LVLMs上验证有效，具有高效性和跨模型可迁移性。
- Conclusion: 当前安全机制存在显著漏洞，亟需更先进的视觉语言系统安全解决方案。
