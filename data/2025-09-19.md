[[toc]]

## cs.CV

### [1] [Class-invariant Test-Time Augmentation for Domain Generalization](https://arxiv.org/abs/2509.14420)
*Zhicheng Lin,Xiaolin Wu,Xi Zhang*

Main category: cs.CV

TL;DR: 提出了一种轻量级的测试时增强方法CI-TTA，通过弹性变形生成同一类别的多个图像变体，并通过置信度引导的过滤机制聚合预测结果，在领域泛化任务中取得显著效果

- Motivation: 深度模型在分布偏移下性能显著下降，现有方法大多依赖多领域训练或计算密集的测试时适应，需要一种轻量级的补充策略
- Method: Class-Invariant Test-Time Augmentation (CI-TTA)技术，使用弹性和网格变形生成输入图像的多个变体，通过置信度引导的过滤方案去除不可靠输出
- Result: 在PACS和Office-Home数据集上的广泛实验显示，在不同DG算法和骨干网络上均取得一致增益
- Conclusion: 该方法具有有效性和通用性，为领域泛化提供了一种轻量级的测试时增强解决方案


### [2] [AToken: A Unified Tokenizer for Vision](https://arxiv.org/abs/2509.14476)
*Jiasen Lu,Liangchen Song,Mingze Xu,Byeongjoo Ahn,Yanjun Wang,Chen Chen,Afshin Dehghan,Yinfei Yang*

Main category: cs.CV

TL;DR: AToken是首个统一的视觉分词器，能够在图像、视频和3D资产上同时实现高保真重建和语义理解，通过4D潜在空间统一多模态视觉处理。

- Motivation: 现有分词器通常专注于单一模态的重建或理解任务，缺乏统一的跨模态视觉表示方法。AToken旨在解决这一局限，为多模态AI系统提供统一的视觉分词基础。
- Method: 采用纯Transformer架构和4D旋转位置编码，处理任意分辨率和时长的视觉输入。使用无对抗训练目标结合感知和Gram矩阵损失，通过渐进式训练课程从单图像扩展到视频和3D，支持连续和离散潜在标记。
- Result: 图像：0.21 rFID和82.2% ImageNet准确率；视频：3.01 rFVD和32.6% MSRVTT检索率；3D：28.19 PSNR和90.9%分类准确率。在下游任务中表现出竞争力。
- Conclusion: AToken展示了统一视觉分词在构建下一代多模态AI系统中的潜力，为视觉生成和理解任务提供了强大的基础框架。


### [3] [MemEvo: Memory-Evolving Incremental Multi-view Clustering](https://arxiv.org/abs/2509.14544)
*Zisen Kong,Bo Zhong,Pengyuan Li,Dongxia Chang,Yiming Wang*

Main category: cs.CV

TL;DR: 提出MemEvo方法解决增量多视图聚类中的稳定性-可塑性困境，通过模拟海马体-前额叶皮层协作记忆机制，实现新视图适应和历史知识保留的平衡

- Motivation: 解决增量多视图聚类中的稳定性-可塑性困境(SPD)，即模型需要足够可塑性快速适应新数据，同时保持足够稳定性巩固长期知识并防止灾难性遗忘
- Method: 1) 海马体启发的视图对齐模块：通过连续表示中的结构对齐捕获新视图的增益信息；2) 认知遗忘机制：模拟人类记忆衰减模式调节历史知识权重；3) 前额叶皮层启发的知识巩固记忆模块：利用时间张量稳定性逐步巩固历史知识
- Result: 广泛的实验表明，MemEvo在视图数量增长场景中展现出强大的知识保留能力，相比现有最先进方法具有显著优势
- Conclusion: MemEvo通过神经科学启发的记忆机制成功解决了增量多视图聚类中的稳定性-可塑性平衡问题，为处理动态多视图数据提供了有效解决方案


### [4] [Edge-Aware Normalized Attention for Efficient and Detail-Preserving Single Image Super-Resolution](https://arxiv.org/abs/2509.14550)
*Penghao Rao,Tieyong Zeng*

Main category: cs.CV

TL;DR: 提出了一种边缘引导的注意力机制，通过自适应调制图选择性增强结构重要区域，抑制虚假纹理，在轻量级残差设计中实现感知超分辨率的提升

- Motivation: 单图像超分辨率问题高度不适定，现有边缘感知方法存在冗余、优化不稳定或结构增益有限的问题，需要更有效的边缘先验注入方式
- Method: 使用边缘引导注意力机制，从联合编码的边缘特征和中间特征激活中推导自适应调制图，应用于归一化和重加权响应；采用轻量级残差设计，结合像素级、感知和对抗性损失的多目标训练
- Result: 在标准SISR基准测试中，相比SRGAN、ESRGAN和现有边缘注意力基线，在相当模型复杂度下实现了结构清晰度和感知质量的一致改进
- Conclusion: 该公式提供了参数高效的边缘先验注入路径，通过定制多术语损失稳定对抗性细化，无需更深或过度参数化的架构即可增强边缘保真度


### [5] [Adaptive and Iterative Point Cloud Denoising with Score-Based Diffusion Model](https://arxiv.org/abs/2509.14560)
*Zhaonan Wang,Manyi Li,ShiQing Xin,Changhe Tu*

Main category: cs.CV

TL;DR: 提出基于分数扩散模型的自适应迭代点云去噪方法，通过估计噪声变化确定自适应去噪调度，在保持形状边界和细节的同时获得更干净平滑的去噪结果

- Motivation: 现有方法通常需要经验性地重复去噪过程，但如何高效安排迭代去噪过程来处理不同级别或模式的噪声尚不明确
- Method: 基于分数扩散模型，首先估计噪声变化并确定自适应去噪调度，然后迭代调用训练网络更新点云；设计网络架构和两阶段采样策略实现特征融合和梯度融合
- Result: 在合成数据集和真实扫描数据集上均优于现有方法，定性定量结果更好，能更好地保持形状边界和细节
- Conclusion: 提出的自适应迭代点云去噪方法能有效处理不同噪声模式，获得更优的去噪效果


### [6] [DiffVL: Diffusion-Based Visual Localization on 2D Maps via BEV-Conditioned GPS Denoising](https://arxiv.org/abs/2509.14565)
*Li Gao,Hongyang Sun,Liu Liu,Yunhao Li,Yang Cai*

Main category: cs.CV

TL;DR: DiffVL是一个基于扩散模型的视觉定位框架，将视觉定位重新定义为GPS去噪任务，利用SD地图和视觉BEV特征来恢复噪声GPS轨迹中的真实位姿分布，实现亚米级精度而无需HD地图。

- Motivation: 现有视觉定位方法面临困境：HD地图精度高但成本昂贵难以扩展，而基于SD地图的方法主要关注图像与地图的BEV匹配，忽略了普遍存在但噪声严重的GPS信号。GPS在城市场景中容易受到多路径误差影响，需要有效去噪方法。
- Method: 提出DiffVL框架，使用扩散模型将视觉定位重构为GPS去噪任务。核心思想是噪声GPS轨迹在视觉BEV特征和SD地图的条件下隐式编码了真实位姿分布，可以通过迭代扩散细化来恢复。该方法联合建模GPS、SD地图和视觉信号，学习逆转GPS噪声扰动。
- Result: 在多个数据集上的实验表明，该方法相比BEV匹配基线方法达到了最先进的精度水平，实现了亚米级定位精度，且不依赖昂贵的HD地图。
- Conclusion: 这项工作证明了扩散模型可以通过将噪声GPS作为生成先验来实现可扩展的定位，实现了从传统基于匹配方法到生成式方法的范式转变，为大规模视觉定位提供了新思路。


### [7] [DICE: Diffusion Consensus Equilibrium for Sparse-view CT Reconstruction](https://arxiv.org/abs/2509.14566)
*Leon Suarez-Rodriguez,Roman Jacome,Romario Gualdron-Hurtado,Ana Mantilla-Dulcey,Henry Arguello*

Main category: cs.CV

TL;DR: 提出了Diffusion Consensus Equilibrium (DICE)框架，通过整合数据一致性和生成先验两个代理，在稀疏视图CT重建中显著优于现有方法

- Motivation: 稀疏视图CT重建是一个病态逆问题，传统迭代方法难以捕捉医学图像的复杂结构，而扩散模型作为强大的生成先验可以准确建模复杂图像分布
- Method: DICE框架将双代理共识平衡整合到扩散模型的采样过程中，交替执行数据一致性代理（通过近端算子强制测量一致性）和先验代理（通过扩散模型在每个采样步骤进行干净图像估计）
- Result: 实验结果表明，DICE在15、30和60个视图（总共180个）的均匀和非均匀稀疏视图设置下，显著优于最先进的基线方法，重建出高质量的CT图像
- Conclusion: DICE通过平衡互补的数据一致性和生成先验代理，有效结合了强大的生成先验能力和测量一致性，在稀疏视图CT重建中表现出卓越的效果和鲁棒性


### [8] [Domain Adaptation for Ulcerative Colitis Severity Estimation Using Patient-Level Diagnoses](https://arxiv.org/abs/2509.14573)
*Takamasa Yamaguchi,Brian Kenji Iwana,Ryoma Bise,Shota Harada,Takumi Okuo,Kiyohito Tanaka,Kaito Shiku*

Main category: cs.CV

TL;DR: 提出了一种新的弱监督域适应方法，利用患者级诊断结果作为目标域的弱监督，通过共享聚合令牌和最大严重性三元组损失来对齐跨域的类分布，在溃疡性结肠炎严重程度估计中优于现有方法。

- Motivation: 溃疡性结肠炎严重程度估计方法常因不同医院的成像设备和临床设置差异而遭受域偏移问题，现有域适应方法在目标域缺乏监督或标注成本高的情况下表现不佳。
- Method: 使用患者级诊断结果作为弱监督，通过共享聚合令牌和最大严重性三元组损失来对齐跨域的类分布，利用患者级诊断由最严重区域决定的特点。
- Result: 实验结果表明该方法优于比较的域适应方法，在域偏移设置下提高了溃疡性结肠炎严重程度估计的性能。
- Conclusion: 提出的弱监督域适应方法有效解决了域偏移问题，利用常规记录的患者级诊断信息作为弱监督，为医疗图像分析中的域适应提供了实用解决方案。


### [9] [Do Vision-Language Models See Urban Scenes as People Do? An Urban Perception Benchmark](https://arxiv.org/abs/2509.14574)
*Rashid Mushkani*

Main category: cs.CV

TL;DR: 该研究创建了一个包含100张蒙特利尔街道图像的小型基准测试，用于评估视觉语言模型在城市感知任务中的表现，发现模型在客观属性识别上表现优于主观评价

- Motivation: 理解人们如何阅读城市景观可以为设计和规划提供信息，需要测试视觉语言模型在城市感知任务中的能力
- Method: 使用100张街道图像（50张照片+50张合成场景），12名参与者提供230份标注，评估7个VLMs的零样本性能，使用准确率和Jaccard重叠度作为评估指标
- Result: 模型在可见的客观属性上表现更好，最佳系统（claude-sonnet）在多标签项目上达到宏观0.31和平均Jaccard 0.48，人类一致性更高的维度模型得分也更高
- Conclusion: 合成图像略微降低模型表现，发布了可重复的基准测试和工具，用于参与式城市分析中的不确定性感知评估


### [10] [Feature-aligned Motion Transformation for Efficient Dynamic Point Cloud Compression](https://arxiv.org/abs/2509.14591)
*Xuan Deng,Xiandong Meng,Longguang Wang,Tiange Zhang,Xiaopeng Fan,Debin Zhao*

Main category: cs.CV

TL;DR: 提出了一种特征对齐运动变换(FMT)框架用于动态点云压缩，通过隐式建模时间变化和潜在空间条件编码来替代显式运动向量，显著提升了压缩效率和性能。

- Motivation: 动态点云在沉浸式现实、机器人和自动驾驶等领域广泛应用，但现有的显式运动估计方法难以捕捉复杂动态和充分利用时间相关性，导致压缩效率受限。
- Method: 采用特征对齐运动变换框架，用时空对齐策略隐式建模连续时间变化，在潜在空间条件编码框架中使用对齐特征作为时间上下文，并设计了支持双向运动参考和分层编码的随机访问参考策略。
- Result: 实验表明该方法在编码和解码效率上均超越D-DPCC和AdaDPCC，分别实现了20%和9.4%的BD-Rate降低。
- Conclusion: FMT框架通过隐式运动建模和潜在空间条件编码，有效提升了动态点云压缩的效率和性能，为相关应用提供了更优的解决方案。


### [11] [HybridMamba: A Dual-domain Mamba for 3D Medical Image Segmentation](https://arxiv.org/abs/2509.14609)
*Weitong Wu,Zhaohu Xing,Jing Gong,Qin Peng,Lei Zhu*

Main category: cs.CV

TL;DR: HybridMamba是一个用于3D医学图像分割的新架构，通过双互补机制平衡局部和全局特征表示，在MRI和CT数据集上显著优于现有方法。

- Motivation: Mamba在3D生物医学图像分割中表现出色，但过度关注全局上下文建模可能会损害关键的局部结构信息，导致分割结果出现边界模糊和区域失真。
- Method: 提出HybridMamba架构，采用双互补机制：1）特征扫描策略，通过轴向遍历和局部自适应路径逐步整合表示；2）结合空间-频率分析的门控模块，实现全面的上下文建模。
- Result: 在MRI和CT数据集上的实验表明，HybridMamba在3D医学图像分割方面显著优于最先进的方法。
- Conclusion: HybridMamba通过有效平衡局部和全局特征表示，解决了现有方法在3D医学图像分割中的局限性，取得了优异的性能表现。


### [12] [Enhancing Feature Fusion of U-like Networks with Dynamic Skip Connections](https://arxiv.org/abs/2509.14610)
*Yue Cao,Quansong He,Kaishen Wang,Jianlong Xiong,Tao He*

Main category: cs.CV

TL;DR: 提出动态跳跃连接（DSC）模块来解决U型网络中传统跳跃连接的两个关键限制：特征间约束和特征内约束，通过测试时训练和动态多尺度核实现自适应特征融合

- Motivation: 传统跳跃连接存在静态特征融合路径和不足的多尺度特征交互建模问题，限制了全局上下文信息的有效聚合
- Method: DSC模块包含两个组件：测试时训练（TTT）模块解决特征间约束，实现推理时的动态自适应；动态多尺度核（DMSK）模块解决特征内约束，基于全局上下文自适应选择核大小
- Result: DSC模块具有即插即用的有效性，可无缝集成到基于CNN、Transformer、混合CNN-Transformer和Mamba的U型网络中
- Conclusion: 提出的DSC模块通过自适应机制从根本上增强了跨层连接性，解决了传统跳跃连接的关键限制


### [13] [LSTC-MDA: A Unified Framework for Long-Short Term Temporal Convolution and Mixed Data Augmentation in Skeleton-Based Action Recognition](https://arxiv.org/abs/2509.14619)
*Feng Ding,Haisheng Fu,Soroush Oraki,Jie Liang*

Main category: cs.CV

TL;DR: LSTC-MDA框架通过长短期时间卷积模块和联合混合数据增强，解决了骨架动作识别中标注数据稀缺和时空依赖建模难题，在多个基准数据集上达到SOTA性能。

- Motivation: 解决骨架动作识别中的两个长期挑战：标注训练样本稀缺性，以及难以同时建模短程和长程时间依赖关系。
- Method: 提出统一框架LSTC-MDA，包含：1）长短期时间卷积模块（LSTC），并行处理短长期特征分支并通过相似性权重自适应融合；2）扩展的联合混合数据增强（JMDA），在输入层进行加法混合并限制在同一相机视角内操作以避免分布偏移。
- Result: 在多个基准数据集上取得最优结果：NTU 60（X-Sub 94.1%，X-View 97.5%）、NTU 120（X-Sub 90.4%，X-Set 92.0%）、NW-UCLA（97.2%）。消融实验证实各组件均有贡献。
- Conclusion: LSTC-MDA通过改进时间建模和数据多样性，有效解决了骨架动作识别的关键挑战，实现了卓越的性能表现。


### [14] [MultiEdit: Advancing Instruction-based Image Editing on Diverse and Challenging Tasks](https://arxiv.org/abs/2509.14638)
*Mingsong Li,Lin Liu,Hongjun Wang,Haoxing Chen,Xijun Gu,Shizhan Liu,Dong Gong,Junbo Zhao,Zhenzhong Lan,Jianguo Li*

Main category: cs.CV

TL;DR: MultiEdit是一个包含10.7万个高质量图像编辑样本的综合数据集，涵盖6个具有挑战性的编辑任务，包括18种非风格转换编辑类型和38种风格转换操作，通过创新的多模态大语言模型流水线构建。

- Motivation: 当前基于指令的图像编辑方法在处理复杂编辑任务时存在困难，因为现有数据集的编辑类型和样本数量有限，且传统数据集构建方法包含噪声图像-标题对，可能引入偏见并限制模型在复杂编辑场景中的能力。
- Method: 采用创新的数据集构建流水线，利用两个多模态大语言模型（MLLMs）分别生成视觉自适应编辑指令和制作高保真编辑图像，创建了包含多样化编辑类型的高质量数据集。
- Result: 实验表明，使用MultiEdit-Train集微调基础开源模型显著提高了模型在复杂编辑任务上的性能，同时有效保持了在标准编辑基准上的能力。
- Conclusion: MultiEdit为推进更多样化和具有挑战性的基于指令的图像编辑能力研究提供了宝贵资源，该数据集已在HuggingFace上公开可用。


### [15] [Attention Lattice Adapter: Visual Explanation Generation for Visual Foundation Model](https://arxiv.org/abs/2509.14664)
*Shinnosuke Hirano,Yuiga Wada,Tsumugi Iida,Komei Sugiura*

Main category: cs.CV

TL;DR: 提出了一种新的视觉基础模型解释生成方法，通过Attention Lattice Adapter和Alternating Epoch Architect机制，在生成解释的同时部分更新模型参数，显著提升了模型的可解释性和性能。

- Motivation: 现有视觉解释方法缺乏适应性，无法应用于复杂模型，需要一种既能生成解释又能增强模型可解释性的新方法。
- Method: 提出ALA机制自动选择注意力层，无需人工干预；AEA机制每隔一个epoch更新参数，解决注意力区域过小问题。
- Result: 在CUB-200-2011和ImageNet-S数据集上，IoU、插入分数、删除分数等指标均优于基线方法，CUB数据集上平均IoU提升53.2点。
- Conclusion: 该方法有效解决了视觉基础模型解释生成中的适应性问题，显著提升了模型的可解释性和解释质量。


### [16] [DACoN: DINO for Anime Paint Bucket Colorization with Any Number of Reference Images](https://arxiv.org/abs/2509.14685)
*Kazuma Nagata,Naoshi Kaneko*

Main category: cs.CV

TL;DR: DACoN是一个利用基础模型进行线稿自动上色的框架，通过融合基础模型的语义特征和CNN的空间特征，支持任意数量的参考图像，解决了遮挡、姿态变化和视角变化等挑战。

- Motivation: 传统深度学习方法在动漫线稿自动上色中面临遮挡、姿态变化和视角变化的挑战，现有方法通常只能支持1-2张参考图像，限制了上色效果。
- Method: 提出DACoN框架，利用基础模型提取部件级语义特征（即使在线稿中），并将其与CNN提取的高分辨率空间特征融合，实现细粒度且鲁棒的特征提取，同时移除了对参考图像数量的限制。
- Result: 定量和定性评估表明，使用多个参考图像能带来显著优势，实现了优越的上色性能。
- Conclusion: DACoN通过基础模型和特征融合技术，有效解决了动漫线稿自动上色中的关键挑战，支持任意数量参考图像，显著提升了上色质量。


### [17] [FMGS-Avatar: Mesh-Guided 2D Gaussian Splatting with Foundation Model Priors for 3D Monocular Avatar Reconstruction](https://arxiv.org/abs/2509.14739)
*Jinlong Fan,Bingyu Hu,Xingguang Li,Yuxiang Yang,Jing Zhang*

Main category: cs.CV

TL;DR: FMGS-Avatar是一种从单目视频重建高保真可动画人体化身的创新方法，通过网格引导的2D高斯泼溅和基础模型知识蒸馏，解决了单视角几何信息不足和表面细节保持的问题。

- Motivation: 从单目视频重建高质量可动画人体化身面临几何信息不足和表面细节保持的挑战。现有3D高斯泼溅方法由于自由形式的3D高斯基元而难以保持表面细节，需要同时解决表示限制和信息稀缺问题。
- Method: 提出FMGS-Avatar方法，包含两个关键创新：1）网格引导的2D高斯泼溅，将2D高斯基元直接附加到模板网格面上，约束位置、旋转和移动；2）利用Sapiens等基础模型补充单目视频的有限视觉线索，并通过选择性梯度隔离的协调训练策略解决多模态知识蒸馏中的优化目标冲突。
- Result: 实验评估显示，该方法在重建质量上显著优于现有方法，在几何精度和外观保真度方面取得显著提升，同时提供丰富的语义信息。蒸馏的先验知识在共享规范空间中自然支持新颖视角和姿态下时空一致的渲染。
- Conclusion: 通过增强表示和协调信息蒸馏的结合，FMGS-Avatar显著推进了3D单目人体化身重建技术，为解决单视角重建的挑战提供了有效的解决方案。


### [18] [Chain-of-Thought Re-ranking for Image Retrieval Tasks](https://arxiv.org/abs/2509.14746)
*Shangrong Wu,Yanghong Zhou,Yang Chen,Feng Zhang,P. Y. Mok*

Main category: cs.CV

TL;DR: 提出CoTRR方法，利用多模态大语言模型进行链式思维重排序，通过列表排序和查询解构提升图像检索性能

- Motivation: 现有方法仅将MLLMs用于评估而非排序过程，导致其丰富的多模态推理能力未被充分利用，图像检索性能不佳
- Method: 设计列表排序提示使MLLM直接参与候选图像重排序，基于图像评估提示分析候选与查询的匹配度，并通过查询解构提示进行细粒度语义分析
- Result: 在五个数据集上的实验表明，CoTRR在文本到图像检索、组合图像检索和基于聊天的图像检索三个任务中均达到最先进性能
- Conclusion: CoTRR方法有效利用了MLLMs的多模态推理能力，通过链式思维重排序显著提升了图像检索的准确性和可解释性


### [19] [Data Augmentation via Latent Diffusion Models for Detecting Smell-Related Objects in Historical Artworks](https://arxiv.org/abs/2509.14755)
*Ahmed Sheta,Mathias Zinnen,Aline Sindel,Andreas Maier,Vincent Christlein*

Main category: cs.CV

TL;DR: 使用扩散模型生成合成数据来改善历史艺术品中气味相关物体的检测性能，特别是在标注稀缺的细分应用中

- Motivation: 历史艺术品中气味参考物的识别面临标注类别极其详细、标注稀疏和极端类别不平衡等挑战，需要解决标注数据稀缺的问题
- Method: 评估多种基于扩散模型的数据增强策略，将合成数据纳入模型训练
- Result: 合成数据的加入提高了检测性能，该方法在数据量相对较小的情况下也有效，扩大规模有进一步提升的潜力
- Conclusion: 利用扩散模型的大规模预训练为改善检测准确性提供了有前景的方法，特别是在标注稀缺且获取成本高的细分应用中


### [20] [Frame Sampling Strategies Matter: A Benchmark for small vision language models](https://arxiv.org/abs/2509.14769)
*Marija Brkic,Anas Filali Razzouki,Yannis Tevissen,Khalil Guetari,Mounim A. El Yacoubi*

Main category: cs.CV

TL;DR: 首个针对视频问答的小型视觉语言模型的帧精确基准测试，揭示了现有基准测试中的帧采样偏差问题，并提出了标准化的评估协议。

- Motivation: 当前视频基准测试存在显著的帧采样偏差，因为不同模型使用不同的帧选择策略进行评估，导致性能比较不公平且不可靠。
- Method: 提出了第一个帧精确的基准测试，在受控的帧采样策略下评估最先进的小型视觉语言模型，并开源了基准测试代码。
- Result: 结果证实了怀疑的偏差，并揭示了不同帧采样技术下SVLMs的数据特定和任务特定行为。
- Conclusion: 需要为每个基准测试数据集量身定制标准化的帧采样策略，社区需要一个可重现且无偏的协议来评估视频VLM。


### [21] [A Real-Time Multi-Model Parametric Representation of Point Clouds](https://arxiv.org/abs/2509.14773)
*Yuan Gao,Wei Dong*

Main category: cs.CV

TL;DR: 提出了一种多模型参数化表示方法，结合高斯混合模型分割、平面/曲面拟合和边界描述，实现了实时表面检测与拟合，在效率和精度上均优于现有方法。

- Motivation: 现有参数化表示方法存在计算成本高或自由度低的问题，难以同时实现实时性和高精度。需要一种既能实时处理又能用少量基元实现高精度的解决方案。
- Method: 首先使用高斯混合模型分割点云为多个簇，然后选择平坦簇并合并为平面或曲面。平面通过2D体素边界描述方法拟合和界定，曲面使用B样条曲面拟合并采用相同边界描述方法。
- Result: 在多个公开数据集上评估显示，表面检测比最先进方法具有更好的鲁棒性，效率提高3.78倍。相比高斯混合模型精度提升2倍，在低功耗机载计算机上达到36.4 fps。
- Conclusion: 该方法成功解决了实时参数化表示中效率与精度的平衡问题，为内存高效映射和多机器人协作等应用提供了有效的解决方案。


### [22] [Dataset Distillation for Super-Resolution without Class Labels and Pre-trained Models](https://arxiv.org/abs/2509.14777)
*Sunwoo Cho,Yejin Jung,Nam Ik Cho,Jae Woong Soh*

Main category: cs.CV

TL;DR: 提出了一种无需类别标签或预训练SR模型的新型数据蒸馏方法，用于图像超分辨率任务，通过提取高梯度块、CLIP特征分类和扩散模型微调来合成蒸馏训练图像，显著减少训练数据量和计算时间。

- Motivation: 当前基于GAN反转的数据蒸馏方法严重依赖预训练SR网络和类别特定信息，限制了其泛化性和适用性。为了解决这些问题，需要开发一种不依赖这些条件的新方法。
- Method: 首先提取高梯度块，基于CLIP特征对图像进行分类，然后在选定的块上微调扩散模型以学习其分布并合成蒸馏训练图像。
- Result: 仅使用原始数据集的0.68%训练基线Transformer模型时，性能下降仅为0.3 dB。扩散模型微调耗时4小时，SR模型训练在1小时内完成，远少于完整数据集所需的11小时训练时间。
- Conclusion: 该方法在显著减少训练数据量和计算时间的同时，实现了最先进的性能，为数据高效的图像超分辨率训练提供了有效的解决方案。


### [23] [Radiology Report Conditional 3D CT Generation with Multi Encoder Latent diffusion Model](https://arxiv.org/abs/2509.14780)
*Sina Amirrajab,Zohaib Salahuddin,Sheng Kuang,Henry C. Woodruff,Philippe Lambin*

Main category: cs.CV

TL;DR: Report2CT是一个基于放射学报告的3D CT生成框架，使用多文本编码器和潜在扩散模型，直接从完整的放射报告中生成高质量的胸部CT体积，在文本-图像对齐和临床保真度方面达到最先进性能。

- Motivation: 现有的文本到图像生成方法在3D CT合成中主要依赖简化的提示词，忽略了完整放射学报告中的丰富语义细节，导致文本-图像对齐和临床保真度不足。
- Method: 提出Report2CT框架，整合三个预训练的医学文本编码器（BiomedVLP CXR BERT、MedEmbed和ClinicalBERT）来捕捉临床上下文，使用放射学报告和体素间距信息条件化3D潜在扩散模型，在CT RATE数据集的20000个CT体积上进行训练。
- Result: 生成的CT体积具有解剖一致性和优秀视觉质量，多编码器条件化提高了CLIP分数，表明更好地保留了放射报告中的细粒度临床细节。在MICCAI 2025 VLM3D挑战赛中排名第一，在所有评估指标上达到最先进性能。
- Conclusion: 通过利用完整放射学报告和多编码器文本条件化，Report2CT推进了3D CT合成技术，能够生成临床忠实且高质量的合成数据。


### [24] [Fracture interactive geodesic active contours for bone segmentation](https://arxiv.org/abs/2509.14817)
*Liheng Wang,Licheng Zhang,Hailin Xu,Jingxin Zhao,Xiuyun Su,Jiantao Li,Miutian Tang,Weilu Gao,Chong Chen*

Main category: cs.CV

TL;DR: 提出了一种针对骨骼分割的骨折交互式测地线主动轮廓算法，通过结合强度信息和梯度范数的新型边缘检测函数，以及嵌入骨折提示的距离信息自适应步长，有效解决了边缘阻塞、边缘泄漏和骨折现象等问题。

- Motivation: 传统测地线主动轮廓模型在骨骼分割中存在特征提取不区分、难以处理边缘阻塞、边缘泄漏和骨折现象的问题，需要开发更鲁棒的算法来准确捕捉骨骼特征。
- Method: 结合骨科知识构建新型边缘检测函数（强度+梯度范数），引入可嵌入骨折提示的距离信息作为自适应步长来稳定轮廓演化，使轮廓能在骨骼边缘和骨折处准确停止。
- Result: 在骨盆和踝关节分割实验中表现出有效性，能够准确、稳定、一致地解决上述问题，在其他骨骼解剖结构中具有广泛应用前景。
- Conclusion: 该算法成功解决了骨骼分割中的关键挑战，为结合领域知识和深度神经网络提供了新的思路，在医学图像分割领域具有重要应用价值。


### [25] [Template-Based Cortical Surface Reconstruction with Minimal Energy Deformation](https://arxiv.org/abs/2509.14827)
*Patrick Madlindl,Fabian Bongratz,Christian Wachinger*

Main category: cs.CV

TL;DR: 提出了一种最小能量变形损失函数(MED)，作为变形轨迹的正则化器，与广泛使用的Chamfer距离相结合，显著提高了皮层表面重建的训练一致性和可重复性。

- Motivation: 基于学习的皮层表面重建方法虽然大幅加速了处理速度，但确保学习到的变形在变形能量方面最优且在训练运行中保持一致仍然是一个挑战。
- Method: 设计了最小能量变形(MED)损失函数作为正则化器，将其整合到V2C-Flow模型中，与Chamfer距离互补使用。
- Result: 在不损害重建精度和拓扑正确性的前提下，显著改善了之前被忽视的训练一致性和可重复性。
- Conclusion: MED损失函数有效解决了学习式皮层表面重建中的变形能量优化和训练一致性问题，为神经影像分析提供了更可靠的皮层重建工具。


### [26] [ProtoMedX: Towards Explainable Multi-Modal Prototype Learning for Bone Health Classification](https://arxiv.org/abs/2509.14830)
*Alvaro Lopez Pellicer,Andre Mariucci,Plamen Angelov,Marwan Bukhari,Jemma G. Kerns*

Main category: cs.CV

TL;DR: ProtoMedX是一种基于原型的多模态模型，结合DEXA扫描和患者记录进行骨健康分类，在保证高准确率的同时提供可解释性，在4160名NHS患者数据集上达到89.8%的准确率。

- Motivation: 当前骨健康AI研究主要依赖深度学习模型，专注于视觉数据（DEXA/X射线图像）和预测准确性，但缺乏可解释性。医疗应用特别是欧盟AI法案要求模型决策具有可解释性，尤其是对错误决策的分析。
- Method: 提出ProtoMedX多模态模型，结合腰椎DEXA扫描和患者记录。采用基于原型的架构设计，天生具有可解释性，允许对模型决策进行显式分析。
- Result: 在4160名真实NHS患者数据集上，视觉单模态版本达到87.58%准确率，多模态版本达到89.8%准确率，均超过现有已发表方法，同时提供临床医生可视觉理解的可解释性。
- Conclusion: ProtoMedX在骨健康分类任务中实现了最先进的性能，同时提供了医疗应用所需的可解释性，符合欧盟AI法案要求，能够帮助临床医生理解和信任AI决策。


### [27] [MapAnything: Mapping Urban Assets using Single Street-View Images](https://arxiv.org/abs/2509.14839)
*Miriam Louise Carnot,Jonas Kunze,Erik Fastermann,Eric Peukert,André Ludwig,Bogdan Franczyk*

Main category: cs.CV

TL;DR: MapAnything是一个自动从单张图像计算物体地理坐标的模块，利用度量深度估计模型和几何原理，为城市物体和事件映射提供自动化解决方案。

- Motivation: 随着数字化发展，城市管理部门需要维护大量物体（如交通标志、树木）和事件（如涂鸦、道路损坏）的数据库，传统手动方式工作量大且难以保持数据更新。
- Method: 使用先进的度量深度估计模型，基于物体到相机的距离、几何原理和相机规格来自动计算地理坐标。通过LiDAR点云验证距离估计精度，并在不同距离区间和语义区域（如道路、植被）分析性能。
- Result: 模块在城市环境中表现出良好的准确性，通过交通标志和道路损坏等实际用例验证了其有效性。
- Conclusion: MapAnything模块为城市物体和事件映射提供了可行的自动化解决方案，能够显著减少人工工作量并保持数据库的实时更新。


### [28] [Not All Degradations Are Equal: A Targeted Feature Denoising Framework for Generalizable Image Super-Resolution](https://arxiv.org/abs/2509.14841)
*Hongjun Wang,Jiyuan Chen,Zhengwei Yin,Xuan Song,Yinqiang Zheng*

Main category: cs.CV

TL;DR: 本文提出了一种针对图像超分辨率中噪声过拟合问题的特征去噪框架，通过噪声检测和去噪模块来提升模型对未知退化的泛化能力。

- Motivation: 现有方法假设模型对所有退化类型都会过拟合，但研究发现模型主要过拟合噪声，因为噪声的退化模式与其他类型明显不同。
- Method: 提出了包含噪声检测和去噪模块的特征去噪框架，可以与现有超分辨率模型无缝集成，无需修改架构。
- Result: 在五个传统基准测试和数据集上（包括合成和真实场景），该框架相比之前的正则化方法表现出更优越的性能。
- Conclusion: 该研究提供了一个通用的解决方案，专门针对噪声过拟合问题，有效提升了图像超分辨率模型的泛化能力。


### [29] [[Re] Improving Interpretation Faithfulness for Vision Transformers](https://arxiv.org/abs/2509.14846)
*Izabela Kurek,Wojciech Trejter,Stipe Frkovic,Andro Erdelez*

Main category: cs.CV

TL;DR: 该研究复现了Faithful Vision Transformers (FViTs)的结果，验证了Diffusion Denoised Smoothing (DDS)在提高视觉Transformer可解释性鲁棒性方面的效果，并扩展了原始研究的范围。

- Motivation: 验证arXiv:2311.17983论文中关于DDS能够提高视觉Transformer在分割任务和分类任务中对抗攻击鲁棒性的主张，并研究将DDS应用于其他可解释性方法的可行性。
- Method: 复现FViTs方法，使用Diffusion Denoised Smoothing (DDS)技术，在分割任务和分类任务中测试对抗攻击鲁棒性，并扩展到基线方法和新提出的Attribution Rollout方法。同时测量计算成本和环境影响。
- Result: 研究结果与原始研究基本一致，证实DDS确实能提高可解释性方法的鲁棒性，但也发现了一些细微差异并进行了讨论。
- Conclusion: DDS技术能够有效提升视觉Transformer可解释性方法的对抗攻击鲁棒性，但需要考虑其计算成本和环境影响。


### [30] [MARIC: Multi-Agent Reasoning for Image Classification](https://arxiv.org/abs/2509.14860)
*Wonduk Seo,Minhyeong Yu,Hyunjin An,Seunghyun Lee*

Main category: cs.CV

TL;DR: MARIC是一个多智能体框架，将图像分类重构为协作推理过程，通过多个智能体从不同视觉维度分析图像，显著超越基线方法

- Motivation: 传统图像分类方法需要大量参数训练和标注数据，而现有视觉语言模型依赖单次表示，难以捕捉视觉内容的互补方面
- Method: 使用Outliner Agent分析图像全局主题并生成提示，三个Aspect Agent从不同视觉维度提取细粒度描述，Reasoning Agent通过集成反思步骤综合这些输出
- Result: 在4个不同的图像分类基准数据集上，MARIC显著优于基线方法
- Conclusion: 多智能体视觉推理对于鲁棒和可解释的图像分类非常有效


### [31] [Controllable Localized Face Anonymization Via Diffusion Inpainting](https://arxiv.org/abs/2509.14866)
*Ali Salar,Qing Liu,Guoying Zhao*

Main category: cs.CV

TL;DR: 提出基于潜在扩散模型的统一框架，通过自适应属性引导模块实现可控的人像匿名化，支持局部匿名化且无需额外训练

- Motivation: 随着人像图像在计算机视觉中的广泛应用，需要保护个人身份隐私，同时确保匿名化后的图像仍能有效用于下游视觉任务
- Method: 利用潜在扩散模型的修复能力，设计自适应属性引导模块，在反向去噪过程中应用梯度校正，使生成图像的面部属性与合成目标图像对齐
- Result: 在CelebA-HQ和FFHQ数据集上的实验表明，该方法优于现有最先进方法，且不需要额外的模型训练
- Conclusion: 该方法提供了一个有效的人像匿名化解决方案，在保护隐私的同时保持了图像对下游任务的实用性


### [32] [Temporal Representation Learning of Phenotype Trajectories for pCR Prediction in Breast Cancer](https://arxiv.org/abs/2509.14872)
*Ivana Janíčková,Yen Y. Tan,Thomas H. Helbich,Konstantin Miloserdov,Zsuzsanna Bago-Horvath,Ulrike Heber,Georg Langs*

Main category: cs.CV

TL;DR: 该研究提出了一种从乳腺癌患者治疗过程中的MRI影像数据学习早期治疗反应动态表征的方法，用于预测新辅助化疗后的病理完全缓解(pCR)。通过多任务模型在潜在空间中构建治疗反应轨迹，仅使用治疗前数据即可达到0.761的平衡准确率，使用四个时间点数据可提升至0.861。

- Motivation: 个体化治疗决策需要能够预测患者对治疗反应的模型，但由于疾病进展和治疗反应的个体差异很大，这是一个具有挑战性的问题。特别是在乳腺癌新辅助化疗中，准确预测病理完全反应对于治疗决策至关重要。
- Method: 提出多任务学习模型，从纵向MRI数据中学习治疗反应的动态表征。模型在潜在空间中构建治疗轨迹，同时处理外观表示、保持时间连续性，并考虑非响应者群体的高异质性。使用线性分类器在潜在轨迹空间中进行预测。
- Result: 在ISPY-2公开数据集上的实验显示：仅使用治疗前数据(T0)达到0.761平衡准确率，使用早期反应数据(T0+T1)达到0.811，使用四个成像时间点(T0->T3)达到0.861的平衡准确率。
- Conclusion: 该方法通过从影像数据中学习治疗反应的动态表征，能够有效预测乳腺癌患者对新辅助化疗的病理完全反应，为个体化治疗决策提供了有前景的工具。使用更多时间点的数据可以显著提高预测性能。


### [33] [NeRF-based Visualization of 3D Cues Supporting Data-Driven Spacecraft Pose Estimation](https://arxiv.org/abs/2509.14890)
*Antoine Legrand,Renaud Detry,Christophe De Vleeschouwer*

Main category: cs.CV

TL;DR: 提出了一种可视化航天器姿态估计网络依赖的3D视觉线索的方法，通过训练基于NeRF的图像生成器来恢复姿态估计网络利用的主要3D特征

- Motivation: 虽然数据驱动的航天器姿态估计方法已经发展，但由于缺乏对其决策过程的理解，在实际任务中的应用受到阻碍
- Method: 训练基于NeRF的图像生成器，利用通过姿态估计网络反向传播的梯度，强制生成器渲染姿态估计网络利用的主要3D特征
- Result: 实验证明该方法能够恢复相关的3D视觉线索，并提供了关于姿态估计网络监督与其对目标航天器隐式表示之间关系的额外见解
- Conclusion: 该方法成功可视化姿态估计网络依赖的3D视觉特征，有助于理解数据驱动姿态估计方法的决策过程


### [34] [Pseudo-Label Enhanced Cascaded Framework: 2nd Technical Report for LSVOS 2025 VOS Track](https://arxiv.org/abs/2509.14901)
*An Yan,Leilei Cao,Feng Lu,Ran Hong,Youhai Jiang,Fengjie Zhu*

Main category: cs.CV

TL;DR: 基于SAM2框架的视频对象分割解决方案，通过伪标签训练和级联多模型推理，在LSVOS 2025竞赛中获得第二名，J&F分数达到0.8616

- Motivation: 解决复杂视频对象分割中的挑战，包括小目标、频繁遮挡、快速运动和复杂交互等问题
- Method: 采用伪标签策略：使用训练好的SAM2检查点在SAM2Long框架中为MOSE测试集生成伪标签，结合现有数据进行训练。推理时使用SAM2Long和SeC模型并行运行，通过级联决策机制整合两个模型的输出
- Result: 在MOSE测试集上获得0.8616的J&F分数，比SAM2Long基线提高了1.4个百分点，在LSVOS 2025 VOS赛道中获得第二名
- Conclusion: 该方法通过伪标签训练和级联多模型推理，在长复杂视频分割场景中表现出强大的鲁棒性和准确性


### [35] [Trade-offs in Cross-Domain Generalization of Foundation Model Fine-Tuned for Biometric Applications](https://arxiv.org/abs/2509.14921)
*Tahar Chettaoui,Naser Damer,Fadi Boutros*

Main category: cs.CV

TL;DR: CLIP基础模型在专门生物识别任务（人脸识别、形态攻击检测、呈现攻击检测）微调后会出现过度专业化问题，导致跨域泛化能力下降，模型容量越大越能缓解这种遗忘现象

- Motivation: 研究CLIP基础模型在专门生物识别任务微调后是否会出现过度专业化问题，以及这种专业化对模型原有跨域泛化能力的影响
- Method: 系统评估三个CLIP实例（分别针对FR、MAD、PAD任务微调），在14个通用视觉数据集上进行零样本和线性探测测试，同时评估在FR、MAD、PAD基准测试上的表现
- Result: 微调模型确实出现过度专业化，特别是在复杂的人脸识别任务中；FRoundation模型在IJB-C基准上提升58.52%，但在ImageNetV2上性能从69.84%降至51.63%；更大的CLIP架构能更好地保持原始泛化能力
- Conclusion: 任务复杂度和分类头设计（多类vs二分类）与灾难性遗忘程度相关，增加模型容量有助于缓解过度专业化问题，需要在专业化性能和泛化能力之间寻求平衡


### [36] [GenKOL: Modular Generative AI Framework For Scalable Virtual KOL Generation](https://arxiv.org/abs/2509.14927)
*Tan-Hiep To,Duy-Khang Nguyen,Tam V. Nguyen,Minh-Triet Tran,Trung-Nghia Le*

Main category: cs.CV

TL;DR: GenKOL是一个基于生成式AI的交互式系统，帮助营销专业人员高效生成高质量的虚拟KOL图像，通过模块化服务实现服装生成、妆容转移、背景合成和发型编辑等功能。

- Motivation: 解决与真人KOL合作的高成本和物流挑战，通过虚拟KOL技术降低营销成本并加速工作流程。
- Method: 采用模块化架构，集成多种AI能力（服装生成、妆容转移、背景合成、发型编辑），提供直观界面让用户动态组合营销视觉内容，支持本地或云端灵活部署。
- Result: 系统能够显著简化品牌内容生产流程，通过可扩展的虚拟KOL创建降低成本和加速营销工作流程。
- Conclusion: GenKOL系统为营销行业提供了高效、低成本且灵活的虚拟KOL生成解决方案，具有广泛的应用前景和适应性。


### [37] [DF-LLaVA: Unlocking MLLM's potential for Synthetic Image Detection via Prompt-Guided Knowledge Injection](https://arxiv.org/abs/2509.14957)
*Zhuokang Shen,Kaisen Zhang,Bohan Jia,Yuan Fang,Zhou Yu,Shaohui Lin*

Main category: cs.CV

TL;DR: DF-LLaVA是一个新颖的框架，通过从MLLMs提取潜在知识并注入到训练中，实现了在合成图像检测中同时获得高准确性和可解释性，超越了专家模型的表现。

- Motivation: 现有检测模型主要关注简单的真实性分类，只能提供伪造概率或二元判断，缺乏对图像真实性的解释性洞察。MLLM-based方法虽然可提供更可解释的结果，但在纯真实性分类准确性上仍落后于专家模型。
- Method: 提出DF-LLaVA框架，首先从MLLMs提取潜在知识，然后通过提示注入到训练中，释放MLLMs的内在判别潜力。
- Result: 实验证明DF-LLaVA在合成图像检测方面具有优越性，实现了超过专家模型的检测准确性，同时保持了MLLMs提供的可解释性。
- Conclusion: DF-LLaVA是一个简单而有效的框架，成功解决了合成图像检测中准确性与可解释性之间的权衡问题，为图像真实性评估提供了新的解决方案。


### [38] [Seeing 3D Through 2D Lenses: 3D Few-Shot Class-Incremental Learning via Cross-Modal Geometric Rectification](https://arxiv.org/abs/2509.14958)
*Xiang Tuo,Xu Xuemiao,Liu Bangzhen,Li Jinyi,Li Yong,He Shengfeng*

Main category: cs.CV

TL;DR: 提出了Cross-Modal Geometric Rectification (CMGR)框架，通过利用CLIP的分层空间语义来增强3D几何保真度，解决3D类增量学习在极端数据稀缺下的几何错位和纹理偏差问题。

- Motivation: 现有3D类增量学习方法在极端数据稀缺下表现不佳，存在几何错位和纹理偏差问题。虽然最近方法整合了3D数据和2D基础模型，但存在语义模糊、纹理偏差投影以及几何-纹理线索无差别融合等问题，导致决策原型不稳定和灾难性遗忘。
- Method: 提出CMGR框架，包含结构感知几何校正模块（分层对齐3D部件结构与CLIP中间空间先验）、纹理放大模块（合成最小但具有区分性的纹理）和基础-新颖判别器（隔离几何变化）。
- Result: 大量实验表明，该方法显著改善了3D少样本类增量学习，在跨域和域内设置下实现了优越的几何一致性和对纹理偏差的鲁棒性。
- Conclusion: CMGR框架通过增强3D几何保真度和抑制纹理噪声，有效解决了3D类增量学习中的关键挑战，为开放世界场景的可扩展识别系统提供了有效解决方案。


### [39] [Brain-HGCN: A Hyperbolic Graph Convolutional Network for Brain Functional Network Analysis](https://arxiv.org/abs/2509.14965)
*Junhao Jia,Yunyou Liu,Cheng Yang,Yifei Sun,Feiwei Qin,Changmiao Wang,Yong Peng*

Main category: cs.CV

TL;DR: 提出了基于双曲几何的Brain-HGCN框架，用于更准确地建模脑功能网络的层次结构，在精神疾病分类任务上显著优于欧几里得基线方法

- Motivation: 标准欧几里得GNN难以准确表示脑功能网络的层次拓扑结构，限制了在临床诊断中的性能表现
- Method: 基于Lorentz模型的双曲几何深度学习框架，采用新颖的双曲图注意力层和带符号聚合机制，通过几何合理的Fréchet均值进行图级表示学习
- Result: 在两个大规模fMRI数据集的精神疾病分类实验中，该方法显著优于多种最先进的欧几里得基线方法
- Conclusion: 这项工作开创了fMRI分析的新几何深度学习范式，展示了双曲GNN在计算精神病学领域的巨大潜力


### [40] [RoboEye: Enhancing 2D Robotic Object Identification with Selective 3D Geometric Keypoint Matching](https://arxiv.org/abs/2509.14966)
*Xingwu Zhang,Guanxuan Li,Zhuocheng Zhang,Zijun Long*

Main category: cs.CV

TL;DR: RoboEye是一个两阶段目标识别框架，通过结合2D语义特征和领域适应的3D推理来解决电商仓库自动化包装中的物品识别难题，在仅使用RGB图像的情况下显著提升了识别准确率。

- Motivation: 随着电商产品类别的快速增长，仓库自动化包装中的目标识别变得愈发困难。类内变异性、长尾稀有物品、视觉相似物品、多样化包装、杂乱容器、频繁遮挡和大视角变化等因素导致查询图像和参考图像之间的差异增大，仅依赖2D外观特征的方法性能急剧下降。
- Method: 提出两阶段识别框架：第一阶段训练大型视觉模型提取2D特征生成候选排名；第二阶段通过轻量级3D特征感知模块评估3D特征质量并预测是否需要3D重排序，避免不必要的计算。当需要时，使用机器人3D检索变换器，包括生成几何感知密集特征的3D特征提取器和基于关键点的匹配器。
- Result: 实验表明，RoboEye在Recall@1指标上比之前的最先进方法（RoboLLM）提高了7.1%。该方法仅使用RGB图像，避免了对显式3D输入的依赖，降低了部署成本。
- Conclusion: RoboEye通过动态结合2D语义特征和领域适应的3D推理，有效解决了大规模电商环境下的目标识别挑战，在保持计算效率的同时显著提升了识别性能，为仓库自动化提供了实用的解决方案。


### [41] [Beyond Random Masking: A Dual-Stream Approach for Rotation-Invariant Point Cloud Masked Autoencoders](https://arxiv.org/abs/2509.14975)
*Xuanhua Yin,Dingxin Zhang,Yu Feng,Shunqi Mao,Jianhui Yu,Weidong Cai*

Main category: cs.CV

TL;DR: 提出了一种双流掩码策略（3D空间网格掩码和渐进语义掩码）来解决旋转不变点云MAE中随机掩码忽略几何结构和语义连贯性的问题，在多个数据集上取得了显著性能提升

- Motivation: 现有的旋转不变点云掩码自编码器使用随机掩码策略，忽略了几何结构和语义连贯性。随机掩码将补丁独立处理，无法捕捉跨方向一致的空间关系，也忽略了无论旋转如何都能保持身份的语义对象部分
- Method: 提出双流掩码方法：3D空间网格掩码通过坐标排序创建结构化模式来捕捉跨不同方向保持的几何关系；语义掩码使用注意力驱动聚类来发现语义有意义的部件并在掩码过程中保持其连贯性。通过课程学习和动态权重协调这两个互补的流
- Result: 在ModelNet40、ScanObjectNN和OmniObject3D上的综合实验表明，在各种旋转场景下都取得了持续改进，相比基线旋转不变方法显示出显著的性能提升
- Conclusion: 所提出的双流掩码策略作为即插即用组件，无需架构更改即可集成到现有的旋转不变框架中，确保了跨不同方法的广泛兼容性，有效解决了随机掩码的局限性


### [42] [EchoVLM: Dynamic Mixture-of-Experts Vision-Language Model for Universal Ultrasound Intelligence](https://arxiv.org/abs/2509.14977)
*Chaoyin She,Ruifang Lu,Lida Chen,Wei Wang,Qinghua Huang*

Main category: cs.CV

TL;DR: EchoVLM是一个专门为超声医学影像设计的视觉语言模型，采用混合专家架构，在7个解剖区域数据上训练，能够执行超声报告生成、诊断和视觉问答等多任务，相比通用模型在超声报告生成任务上有显著提升。

- Motivation: 传统超声诊断高度依赖医生经验，存在主观性强和诊断效率低的问题。现有通用视觉语言模型在超声医学任务中知识有限，在多器官病变识别方面泛化能力差，多任务诊断效率低。
- Method: 提出EchoVLM模型，采用混合专家(MoE)架构，在涵盖7个解剖区域的数据集上进行训练，支持超声报告生成、诊断和视觉问答等多任务处理。
- Result: 在超声报告生成任务上，EchoVLM相比Qwen2-VL在BLEU-1和ROUGE-1分数上分别提升了10.15和4.77个点，表现出显著优势。
- Conclusion: EchoVLM在提升超声影像诊断准确性方面具有巨大潜力，为未来临床应用提供了可行的技术解决方案，模型代码和权重已开源。


### [43] [SPATIALGEN: Layout-guided 3D Indoor Scene Generation](https://arxiv.org/abs/2509.14981)
*Chuan Fang,Heng Li,Yixun Liang,Jia Zheng,Yongsen Mao,Yuan Liu,Rui Tang,Zihan Zhou,Ping Tan*

Main category: cs.CV

TL;DR: 提出了SpatialGen多视图多模态扩散模型，使用大规模合成数据集生成高质量、语义一致的3D室内场景

- Motivation: 解决现有方法在视觉质量、多样性、语义一致性和用户控制方面的平衡问题，填补缺乏大规模高质量数据集的技术空白
- Method: 构建包含12,328个结构化标注场景的大规模合成数据集，开发多视图多模态扩散模型，基于3D布局和参考图像生成外观、几何和语义信息
- Result: SpatialGen在实验中始终优于先前方法，能够从任意视角生成保持空间一致性的多模态输出
- Conclusion: 通过开源数据和模型推动室内场景理解和生成领域的发展，为设计、虚拟现实和机器人应用提供高效解决方案


### [44] [PRISM: Product Retrieval In Shopping Carts using Hybrid Matching](https://arxiv.org/abs/2509.14985)
*Arda Kabadayi,Senem Velipasalar,Jiajing Chen*

Main category: cs.CV

TL;DR: PRISM是一种用于零售产品检索的三阶段混合方法，结合了视觉语言模型和像素级匹配的优势，在保持实时处理的同时显著提升了检索精度

- Motivation: 传统产品检索面临挑战：不同品牌的同类产品外观高度相似，查询图像角度与目录图像差异大。基础模型难以区分细微局部差异，而像素级匹配方法计算成本过高
- Method: 三阶段框架：1) 使用SigLIP视觉语言模型检索前35个语义相似产品；2) 应用YOLO-E分割模型去除背景干扰；3) 对筛选后的候选产品使用LightGlue进行细粒度像素级匹配
- Result: 在ABV数据集上的实验表明，PRISM在top-1准确率上比现有最先进的图像检索方法提高了4.21%，同时仍保持实时处理能力
- Conclusion: PRISM通过结合语义检索和细粒度匹配的优势，有效解决了零售产品检索中的高类间相似性问题，为实际零售部署提供了既准确又高效的解决方案


### [45] [UCorr: Wire Detection and Depth Estimation for Autonomous Drones](https://arxiv.org/abs/2509.14989)
*Benedikt Kolbeinsson,Krystian Mikolajczyk*

Main category: cs.CV

TL;DR: 提出了一种用于电线分割和深度估计的单目端到端模型，通过时间相关层和合成数据训练，在电线检测和深度估计联合任务上优于现有方法

- Motivation: 在完全自主的无人机中，准确检测障碍物对安全导航至关重要，其中电线检测因其细长轮廓而成为独特且复杂的问题
- Method: 使用单目端到端模型，结合时间相关层并在合成数据上进行训练，处理电线分割和深度估计的联合任务
- Result: 在电线检测和深度估计联合任务上表现出优于现有竞争方法的性能
- Conclusion: 该模型有潜力提高自主无人机的安全性和精确性，在现实场景中具有广阔的应用前景


### [46] [Sea-ing Through Scattered Rays: Revisiting the Image Formation Model for Realistic Underwater Image Generation](https://arxiv.org/abs/2509.15011)
*Vasiliki Ismiroglou,Malte Pedersen,Stefan H. Bengtson,Andreas Aakerberg,Thomas B. Moeslund*

Main category: cs.CV

TL;DR: 本文提出了一种改进的水下合成数据生成管道，包含常被忽略的前向散射项和非均匀介质，并收集了BUCKET数据集验证效果。

- Motivation: 现有的水下图像生成模型主要关注变色问题，但忽略了高浑浊环境中距离相关的能见度损失，需要更全面的合成数据生成方法。
- Method: 提出改进的合成数据生成管道，包含前向散射项和非均匀介质处理；收集BUCKET数据集（受控浑浊条件下的真实浑浊影像和对应参考图像）。
- Result: 在增加的浑浊度条件下显示出比参考模型更好的定性改进效果，调查参与者选择率达到82.5%。
- Conclusion: 包含前向散射和非均匀介质的改进合成数据生成方法能更好地模拟高浑浊水下环境，为水下视觉研究提供更真实的数据支持。


### [47] [No Modality Left Behind: Adapting to Missing Modalities via Knowledge Distillation for Brain Tumor Segmentation](https://arxiv.org/abs/2509.15017)
*Shenghao Zhu,Yifei Chen,Weihong Chen,Shuo Jiang,Guanyu Zhou,Yuanhan Wang,Feiwei Qin,Changmiao Wang,Qiyuan Tian*

Main category: cs.CV

TL;DR: AdaMM是一个针对多模态MRI脑肿瘤分割中缺失模态问题的框架，通过知识蒸馏和三个协同模块提升在不完整输入下的分割准确性和鲁棒性

- Motivation: 临床实践中多模态MRI经常存在缺失模态，限制了现有深度学习方法对完整输入的依赖，特别是在非主导模态组合下表现不佳
- Method: 提出包含三个模块的框架：图引导自适应精炼模块建模特征关联、双瓶颈蒸馏模块通过全局风格匹配和对抗特征对齐传递知识、病变存在引导可靠性模块通过辅助分类任务预测病变类型先验概率
- Result: 在BraTS 2018和2024数据集上的实验表明，AdaMM在单模态和弱模态配置下始终优于现有方法，展现出优异的分割准确性和鲁棒性
- Conclusion: 该方法有效解决了多模态脑肿瘤分割中的缺失模态问题，知识蒸馏策略被证明具有优越性，为方法选择和未来研究提供了实用指导


### [48] [AutoEdit: Automatic Hyperparameter Tuning for Image Editing](https://arxiv.org/abs/2509.15031)
*Chau Pham,Quan Dao,Mahesh Bhosale,Yunjie Tian,Dimitris Metaxas,David Doermann*

Main category: cs.CV

TL;DR: 本文提出基于强化学习的扩散模型超参数优化框架，将图像编辑的超参数搜索问题建模为序列决策任务，通过马尔可夫决策过程动态调整去噪步骤中的超参数，显著减少了传统暴力搜索方法的时间和计算开销。

- Motivation: 现有扩散模型图像编辑方法需要用户暴力调优多个相互依赖的超参数（如反转时间步和注意力修改等），计算成本高昂。巨大的超参数搜索空间限制了实际部署效率。
- Method: 提出强化学习框架，将超参数搜索建模为序列决策任务，建立马尔可夫决策过程来动态调整去噪步骤中的超参数，将编辑目标整合到奖励函数中，使用近端策略优化实现时间效率。
- Result: 实验证明该方法相比现有暴力搜索方法显著减少了搜索时间和计算开销，在保持最优超参数配置的同时提升了效率。
- Conclusion: 该强化学习框架推动了基于扩散模型的图像编辑框架在实际场景中的部署应用，解决了超参数调优的计算效率问题。


### [49] [Synthetic-to-Real Object Detection using YOLOv11 and Domain Randomization Strategies](https://arxiv.org/abs/2509.15045)
*Luisa Torquato Niño,Hamza A. A. Gardi*

Main category: cs.CV

TL;DR: 使用合成数据和域随机化训练YOLOv11检测汤罐，最佳模型在Kaggle竞赛中达到0.910 mAP@50，证明纯合成训练潜力但仍有挑战

- Motivation: 解决目标检测中的合成到真实域差距问题，探索仅使用合成数据和域随机化策略训练目标检测模型的可行性
- Method: 采用YOLOv11模型，通过数据增强、数据集组合和模型缩放等实验，使用合成数据和域随机化策略进行训练
- Result: 最佳配置的YOLOv11l模型在Kaggle竞赛隐藏测试集上达到0.910 mAP@50，合成验证指标高但真实性能预测性差
- Conclusion: 增加合成数据集多样性（多样化视角和复杂背景）结合精心调优的数据增强是缩小域差距的关键，纯合成训练方法具有潜力但仍需改进


### [50] [Transplant-Ready? Evaluating AI Lung Segmentation Models in Candidates with Severe Lung Disease](https://arxiv.org/abs/2509.15083)
*Jisoo Lee,Michael R. Harowicz,Yuwen Chen,Hanxue Gu,Isaac S. Alderete,Lin Li,Maciej A. Mazurowski,Matthew G. Hartwig*

Main category: cs.CV

TL;DR: 本研究评估了三种公开的深度学习肺部分割模型在肺移植患者中的表现，发现Unet-R231在整体性能上优于其他模型，但在中重度病例中所有模型性能均显著下降。

- Motivation: 评估现有深度学习肺部分割模型在肺移植术前规划中的适用性，特别是在不同疾病严重程度和病理类型下的表现差异。
- Method: 回顾性研究32例患者（3645个2D轴位切片），使用三种深度学习模型（Unet-R231、TotalSegmentator、MedSAM）进行肺部分割，通过定量指标（体积相似性、Dice系数、Hausdorff距离）和定性临床可接受性评分进行评估。
- Result: Unet-R231在所有评估维度上表现最佳，但所有模型从中度到重度病例性能显著下降（p<0.05），特别是在体积相似性指标上。肺侧和病理类型间无显著差异。
- Conclusion: Unet-R231是最准确的自动化肺部分割模型，TotalSegmentator次之，但在中重度病理情况下需要专门的模型微调以提高性能。


### [51] [OmniSegmentor: A Flexible Multi-Modal Learning Framework for Semantic Segmentation](https://arxiv.org/abs/2509.15096)
*Bo-Wen Yin,Jiao-Long Cao,Xuying Zhang,Yuming Chen,Ming-Ming Cheng,Qibin Hou*

Main category: cs.CV

TL;DR: OmniSegmentor是一个创新的多模态预训练框架，通过ImageNeXt数据集和高效预训练方法，首次实现了统一的多模态语义分割预训练，在多个数据集上达到SOTA性能。

- Motivation: 当前多模态表示学习虽然证明了多模态线索对语义分割的好处，但缺乏灵活的预训练-微调流程来处理多种视觉模态。
- Method: 1) 基于ImageNet构建包含5种流行视觉模态的大规模多模态预训练数据集ImageNeXt；2) 提出高效预训练方法使模型能够编码不同模态信息
- Result: 在NYU Depthv2、EventScape、MFNet、DeLiVER、SUNRGBD和KITTI-360等多个多模态语义分割数据集上创造了新的最先进记录
- Conclusion: 首次引入了通用的多模态预训练框架，无论涉及模态的任意组合，都能持续增强模型在各种场景下的感知能力


### [52] [RGB-Only Supervised Camera Parameter Optimization in Dynamic Scenes](https://arxiv.org/abs/2509.15123)
*Fang Li,Hao Zhang,Narendra Ahuja*

Main category: cs.CV

TL;DR: 提出了一种仅需单RGB视频即可在动态场景中进行更准确、高效相机参数优化的新方法，无需依赖运动掩码等先验信息

- Motivation: COLMAP在动态场景中需要GT运动掩码且运行时间长，现有方法需要各种难以获取的先验监督信息，而实际拍摄的RGB视频通常缺乏这些信息
- Method: 包含三个关键组件：(1)块状跟踪滤波器建立稀疏铰链关系；(2)异常值感知联合优化自适应降权移动异常值；(3)两阶段优化策略平衡Softplus限制和凸最小值
- Result: 在4个真实数据集和1个合成数据集上验证，证明方法能更高效准确地估计相机参数，仅需单RGB视频作为唯一监督
- Conclusion: 该方法在动态场景相机参数优化方面取得了显著进展，仅需RGB视频即可实现优于现有方法的性能


### [53] [MedFact-R1: Towards Factual Medical Reasoning via Pseudo-Label Augmentation](https://arxiv.org/abs/2509.15154)
*Gengliang Li,Rongyu Chen,Bin Li,Linlin Yang,Guodong Ding*

Main category: cs.CV

TL;DR: MEDFACT-R1是一个两阶段医疗视觉语言模型框架，通过外部知识注入和强化学习提升医学事实推理能力，在三个医疗QA基准上实现了22.5%的绝对准确率提升

- Motivation: 解决医疗视觉语言模型在事实一致性和可靠推理方面的关键挑战，确保医疗AI的可信度
- Method: 两阶段框架：第一阶段使用伪标签监督微调(SFT)注入外部事实知识；第二阶段应用组相对策略优化(GRPO)和四个定制的事实奖励信号来鼓励自一致推理
- Result: 在三个公开医疗QA基准上，相比之前的最先进方法实现了高达22.5%的绝对准确率提升。消融研究验证了伪标签SFT冷启动的必要性和各GRPO奖励的贡献
- Conclusion: 知识注入和强化学习驱动的推理之间的协同作用对于构建可信的医疗AI至关重要


### [54] [Leveraging Geometric Visual Illusions as Perceptual Inductive Biases for Vision Models](https://arxiv.org/abs/2509.15156)
*Haobo Yang,Minghao Guo,Dequan Yang,Wenyu Wang*

Main category: cs.CV

TL;DR: 将几何视觉错觉作为辅助监督任务可以系统性地提升深度学习模型在图像分类中的泛化能力，特别是在处理复杂轮廓和精细纹理的挑战性视觉案例时。

- Motivation: 当前深度学习模型主要依赖大数据集的统计规律，但很少融入来自感知心理学的结构化洞察。研究者希望探索感知驱动的归纳偏置在提升视觉模型性能方面的潜力。
- Method: 创建了一个参数化的合成几何错觉数据集，并评估了三种多源学习策略，将错觉识别任务与ImageNet分类目标相结合。
- Result: 实验表明：(i) 几何错觉作为辅助监督能系统性地改善泛化性能；(ii) 感知驱动的归纳偏置能增强CNN和基于transformer架构的结构敏感性。
- Conclusion: 这项工作展示了感知科学与机器学习的新颖整合，为将感知先验嵌入视觉模型设计提供了新方向。


### [55] [AIP: Subverting Retrieval-Augmented Generation via Adversarial Instructional Prompt](https://arxiv.org/abs/2509.15159)
*Saket S. Chaturvedi,Gaurav Bagwe,Lan Zhang,Xiaoyong Yuan*

Main category: cs.CV

TL;DR: 本文提出了一种针对检索增强生成(RAG)系统的新型攻击方法AIP，通过操纵指令提示来隐秘地改变检索行为，而非直接修改用户查询，揭示了RAG系统中被忽视的安全漏洞。

- Motivation: 现有的RAG攻击主要依赖操纵用户查询，这在实践中往往不可行。指令提示被广泛重用、公开分享且很少审计，其隐含的信任使其成为攻击者操纵RAG行为的理想目标。
- Method: 提出AIP攻击方法，使用多样化查询生成策略模拟真实用户查询的语言变化，并基于遗传算法进行联合优化，在攻击成功率、清洁任务效用和隐蔽性之间取得平衡。
- Result: 实验结果显示AIP攻击成功率高达95.23%，同时保持良性功能，证明了指令提示操纵的有效性和危险性。
- Conclusion: 研究揭示了RAG系统中一个关键且被忽视的漏洞，强调需要重新评估共享指令提示的安全性，提升系统整体安全防护能力。


### [56] [Semi-Supervised 3D Medical Segmentation from 2D Natural Images Pretrained Model](https://arxiv.org/abs/2509.15167)
*Pak-Hei Yeung,Jayroop Ramesh,Pengfei Lyu,Ana Namburete,Jagath Rajapakse*

Main category: cs.CV

TL;DR: 提出M&N框架，通过2D预训练模型向3D分割模型的知识蒸馏，在少量标注的3D医学图像半监督分割中实现最先进性能

- Motivation: 解决3D医学图像分割中标注数据稀缺的问题，利用丰富的2D自然图像预训练模型知识来提升半监督学习效果
- Method: 模型无关的渐进式知识蒸馏框架，通过两个模型相互生成伪掩码进行协同训练，并采用学习率引导的采样策略自适应调整标注和未标注数据比例
- Result: 在多个公开数据集上超越13种现有半监督分割方法，在所有设置下均达到最先进性能，且具有良好的模型适应性
- Conclusion: M&N框架有效实现了2D到3D的知识迁移，为半监督医学图像分割提供了强大且灵活的解决方案


### [57] [A Race Bias Free Face Aging Model for Reliable Kinship Verification](https://arxiv.org/abs/2509.15177)
*Ali Nazari,Bardiya Kariminia,Mohsen Ebrahimi Moghaddam*

Main category: cs.CV

TL;DR: 本文提出了一种名为RA-GAN的无种族偏见人脸老化模型，通过RACEpSp和特征混合器模块生成无偏见图像，用于亲属关系验证，显著提升了跨年龄组的验证准确率。

- Motivation: 解决亲属验证中父母与子女照片存在年龄差距的问题，同时克服现有面部老化模型的种族偏见，提高同年龄照片的相似度和验证准确性。
- Method: 提出RA-GAN模型，包含RACEpSp和特征混合器两个新模块，用于生成无种族偏见的年龄转换图像，并在KinFaceW-I和KinFaceW-II数据集上进行亲属关系验证实验。
- Result: RA-GAN在所有年龄组平均比SAM-GAN提升13.14%的种族准确性，在60+年龄组比CUSP-GAN提升9.1%。在KinFaceW-I数据集上，父子、父女、母子、母女关系的验证准确率分别提升5.22%、5.12%、1.63%和0.41%。
- Conclusion: RA-GAN能有效消除面部老化中的种族偏见，保持身份特征，显著提升跨年龄亲属关系验证的准确性，特别是在父子、父女关系上效果最为明显。


### [58] [Unleashing the Potential of Multimodal LLMs for Zero-Shot Spatio-Temporal Video Grounding](https://arxiv.org/abs/2509.15178)
*Zaiquan Yang,Yuhao Liu,Gerhard Hancke,Rynson W. H. Lau*

Main category: cs.CV

TL;DR: 本文提出了一种基于多模态大语言模型(MLLM)的零样本时空视频定位框架，通过分解时空高亮和时序增强组装策略，显著提升了MLLM在时空视频定位任务上的性能。

- Motivation: 探索多模态大语言模型在零样本时空视频定位任务中的应用，发现MLLM存在动态分配接地令牌的倾向，但往往由于无法充分整合文本查询中的线索而导致次优接地效果。
- Method: 提出DSTH策略将原始查询分解为属性和动作子查询，使用logit引导重注意模块学习空间和时间提示；引入TAS策略通过原始帧和时序增强帧的组装来提升时序一致性。
- Result: 在三个常见STVG基准测试中优于最先进方法，证明了该方法的有效性。
- Conclusion: 该框架成功释放了MLLM的推理能力，为时空视频定位任务提供了有效的零样本解决方案，代码将开源。


### [59] [Maize Seedling Detection Dataset (MSDD): A Curated High-Resolution RGB Dataset for Seedling Maize Detection and Benchmarking with YOLOv9, YOLO11, YOLOv12 and Faster-RCNN](https://arxiv.org/abs/2509.15181)
*Dewi Endah Kharismawati,Toni Kazic*

Main category: cs.CV

TL;DR: MSDD是一个高质量玉米幼苗航空图像数据集，用于植株计数，包含单株、双株和三株三类，在V4-V6生长阶段和天底视角下检测效果最佳，YOLO11速度最快，YOLOv9单株检测精度最高。

- Motivation: 精准农业需要准确的玉米幼苗检测，但现有标注数据集稀缺。传统人工计数方法劳动强度大且容易出错，计算机视觉技术能实现高效准确的检测。
- Method: 构建MSDD航空图像数据集，包含三类玉米植株（单株、双株、三株），涵盖不同生长阶段、种植设置、土壤类型、光照条件和拍摄角度。使用YOLO系列模型进行基准测试。
- Result: 单株检测精度达0.984，召回率0.873；双株和三株检测较困难；YOLO11推理速度最快（35ms/图像）；YOLOv9在单株检测上准确率最高；V4-V6阶段和天底视角下检测最可靠。
- Conclusion: MSDD为开发增强植株计数、优化资源分配和支持实时决策的模型奠定了坚实基础，推动了农业监测自动化和精准农业的发展。


### [60] [Understand Before You Generate: Self-Guided Training for Autoregressive Image Generation](https://arxiv.org/abs/2509.15185)
*Xiaoyu Yue,Zidong Wang,Yuqing Wang,Wenlong Zhang,Xihui Liu,Wanli Ouyang,Lei Bai,Luping Zhou*

Main category: cs.CV

TL;DR: 本文提出了ST-AR训练框架，通过引入自监督目标解决自回归模型在视觉领域的三个关键问题，显著提升了图像理解和生成质量。

- Motivation: 自回归模型作为最初为自然语言设计的生成范式，在视觉领域面临高质量视觉表示学习的挑战，存在局部条件依赖、步间语义不一致和空间不变性不足等问题。
- Method: 提出了ST-AR训练框架，在训练过程中引入自监督目标来有效解决上述三个关键问题，不依赖预训练表示模型。
- Result: ST-AR显著提升了自回归模型的图像理解能力，LlamaGen-L和LlamaGen-XL分别获得约42%和49%的FID改进，同时保持相同的采样策略。
- Conclusion: 自监督目标的引入能够有效解决自回归模型在视觉领域的语义学习问题，显著提升图像生成质量和理解能力。


### [61] [Geometric Image Synchronization with Deep Watermarking](https://arxiv.org/abs/2509.15208)
*Pierre Fernandez,Tomáš Souček,Nikola Jovanović,Hady Elsahar,Sylvestre-Alvise Rebuffi,Valeriu Lacatusu,Tuan Tran,Alexandre Mourachko*

Main category: cs.CV

TL;DR: SyncSeal是一种专门用于图像同步的水印方法，通过在现有水印方法基础上增强对几何变换的鲁棒性，使用嵌入网络和提取网络来预测和校正图像几何变换。

- Motivation: 解决图像水印在面对几何变换（如裁剪、旋转）时容易失效的问题，提升现有水印方法对几何攻击的抵抗能力。
- Method: 采用端到端训练的嵌入网络和提取网络，嵌入网络对图像进行不可察觉的修改，提取网络预测图像所受的几何变换参数，结合判别器保持高感知质量。
- Result: 实验验证表明该方法在多种几何和值度变换下能准确同步图像，有效提升现有水印方法对几何变换的鲁棒性。
- Conclusion: SyncSeal为图像水印提供了有效的同步解决方案，能够显著增强水印系统对几何攻击的抵抗能力。


### [62] [RynnVLA-001: Using Human Demonstrations to Improve Robot Manipulation](https://arxiv.org/abs/2509.15212)
*Yuming Jiang,Siteng Huang,Shengke Xue,Yaxi Zhao,Jun Cen,Sicong Leng,Kehan Li,Jiayan Guo,Kexiang Wang,Mingxiu Chen,Fan Wang,Deli Zhao,Xin Li*

Main category: cs.CV

TL;DR: RynnVLA-001是一个基于大规模视频生成预训练的视觉-语言-动作模型，通过两阶段预训练方法和ActionVAE动作压缩技术，在机器人任务上实现了最先进的性能。

- Motivation: 为了解决视觉-语言-动作模型中动作预测与视觉预测之间的鸿沟，以及降低VLA输出空间的复杂性，需要开发更有效的预训练策略和动作表示方法。
- Method: 提出两阶段预训练方法：第一阶段在1200万自我中心操作视频上进行图像到视频生成预训练；第二阶段联合预测未来关键点轨迹，并引入ActionVAE变分自编码器压缩动作序列为紧凑潜在嵌入。
- Result: 在相同下游机器人数据集上微调后，RynnVLA-001超越了现有最先进的基线模型，证明了所提预训练策略为VLA模型提供了更有效的初始化。
- Conclusion: 该研究证明了大规模视频生成预训练和轨迹感知建模的有效性，ActionVAE成功降低了动作表示的复杂性，为VLA模型的发展提供了新的方向。


### [63] [Out-of-Sight Trajectories: Tracking, Fusion, and Prediction](https://arxiv.org/abs/2509.15219)
*Haichao Zhang,Yi Xu,Yun Fu*

Main category: cs.CV

TL;DR: 提出OST方法，通过视觉-定位映射和去噪模块处理视线外物体的噪声传感器数据，实现无监督轨迹去噪和预测，在Vi-Fi和JRDB数据集上达到SOTA性能

- Motivation: 现有方法依赖完整无噪声观测数据，忽视了视线外物体和传感器噪声的挑战，这些限制在真实场景中带来安全风险并阻碍可靠预测
- Method: 增强的视觉-定位去噪模块利用相机标定建立视觉-定位映射，以无监督方式有效去噪噪声传感器数据，扩展应用到行人和车辆
- Result: 在Vi-Fi和JRDB数据集上实现了轨迹去噪和预测的最先进性能，显著超越先前基线，并与卡尔曼滤波等传统方法进行比较
- Conclusion: 这是首个集成视觉-定位投影来去噪视线外智能体噪声传感器轨迹的工作，为未来进展铺平了道路


### [64] [Lightweight and Accurate Multi-View Stereo with Confidence-Aware Diffusion Model](https://arxiv.org/abs/2509.15220)
*Fangjinhua Wang,Qingshan Xu,Yew-Soon Ong,Marc Pollefeys*

Main category: cs.CV

TL;DR: 提出基于扩散模型的多视角立体视觉框架，将深度图优化建模为条件扩散过程，在保持高效的同时实现SOTA性能

- Motivation: 传统多视角立体视觉方法计算效率低，而扩散模型在生成任务中表现出色，希望将扩散模型的迭代去噪过程应用于深度图优化
- Method: 设计条件编码器指导扩散过程，结合轻量级2D U-Net和卷积GRU的扩散网络，提出基于置信度的自适应采样策略，开发DiffMVS和CasDiffMVS两种方法
- Result: DiffMVS在运行时间和GPU内存方面达到竞争性效率，CasDiffMVS在DTU、Tanks & Temples和ETH3D数据集上实现SOTA性能
- Conclusion: 扩散模型成功应用于多视角立体视觉任务，提出的框架在效率和精度方面都取得了显著提升，为3D几何重建提供了新思路


### [65] [ScaleCUA: Scaling Open-Source Computer Use Agents with Cross-Platform Data](https://arxiv.org/abs/2509.15221)
*Zhaoyang Liu,JingJing Xie,Zichen Ding,Zehao Li,Bowen Yang,Zhenyu Wu,Xuehui Wang,Qiushi Sun,Shi Liu,Weiyun Wang,Shenglong Ye,Qingyun Li,Zeyue Tian,Gen Luo,Xiangyu Yue,Biqing Qi,Kai Chen,Bowen Zhou,Yu Qiao,Qifeng Chen,Wenhai Wang*

Main category: cs.CV

TL;DR: ScaleCUA是一个大规模开源计算机使用代理系统，通过跨6个操作系统和3个任务领域的大规模数据集训练，在多平台GUI操作中实现了最先进的性能。

- Motivation: 当前视觉语言模型虽然能够实现GUI自主操作，但受限于缺乏大规模开源计算机使用数据和基础模型，限制了计算机使用代理的发展。
- Method: 采用闭环流水线结合自动化代理和人类专家构建大规模数据集，涵盖6个操作系统和3个任务领域，并基于此训练跨平台计算机使用代理模型。
- Result: 在多个基准测试中显著超越基线方法（WebArena-Lite-v2 +26.6，ScreenSpot-Pro +10.7），并创下新的SOTA结果（MMBench-GUI L1-Hard 94.4%，OSWorld-G 60.6%，WebArena-Lite-v2 47.4%）。
- Conclusion: 数据驱动的规模化方法对通用计算机使用代理具有强大推动作用，研究团队将发布数据、模型和代码以促进未来研究。


### [66] [Depth AnyEvent: A Cross-Modal Distillation Paradigm for Event-Based Monocular Depth Estimation](https://arxiv.org/abs/2509.15224)
*Luca Bartolomei,Enrico Mannocci,Fabio Tosi,Matteo Poggi,Stefano Mattoccia*

Main category: cs.CV

TL;DR: 提出跨模态蒸馏范式，利用视觉基础模型为事件相机生成密集深度代理标签，无需昂贵深度标注，在合成和真实数据集上达到竞争性性能

- Motivation: 事件相机在高速运动和强光照变化环境下具有优势，但缺乏大规模密集深度标注数据集，限制了基于学习的单目深度估计发展
- Method: 1) 跨模态蒸馏范式：利用空间对齐的RGB帧和事件流，通过视觉基础模型生成密集代理标签；2) 提出两种VFM架构：vanilla Depth Anything v2和新型循环架构
- Result: 在合成和真实数据集上评估显示：i) 跨模态方法达到与全监督方法竞争的性能而不需要深度标注；ii) VFM-based模型实现state-of-the-art性能
- Conclusion: 该方法成功解决了事件相机深度估计中标注数据稀缺的问题，通过跨模态蒸馏和VFM应用实现了优异的性能表现


### [67] [Lost in Translation? Vocabulary Alignment for Source-Free Domain Adaptation in Open-Vocabulary Semantic Segmentation](https://arxiv.org/abs/2509.15225)
*Silvio Mazzucco,Carl Persson,Mattia Segu,Pier Luigi Dovesi,Federico Tombari,Luc Van Gool,Matteo Poggi*

Main category: cs.CV

TL;DR: VocAlign是一个针对开放词汇语义分割的无源域适应框架，采用师生范式增强词汇对齐策略，通过LoRA微调和Top-K类别选择机制，在CityScapes数据集上实现了6.11 mIoU的显著提升。

- Motivation: 针对视觉语言模型在开放词汇语义分割中的无源域适应问题，需要在不访问源数据的情况下有效适应目标域，同时保持计算效率。
- Method: 采用师生范式，结合词汇对齐策略改进伪标签生成；使用LoRA进行高效微调；提出Top-K类别选择机制降低内存需求。
- Result: 在CityScapes数据集上获得6.11 mIoU的显著提升，在零样本分割基准测试中表现出优越性能。
- Conclusion: VocAlign为开放词汇设置下的无源域适应设立了新标准，在保持计算效率的同时显著提升了性能。


### [68] [Calibration-Aware Prompt Learning for Medical Vision-Language Models](https://arxiv.org/abs/2509.15226)
*Abhishek Basu,Fahad Shamshad,Ashshak Sharifdeen,Karthik Nandakumar,Muhammad Haris Khan*

Main category: cs.CV

TL;DR: CalibPrompt是首个在提示调优过程中校准医疗视觉语言模型置信度的框架，通过优化可学习提示和设计校准目标，在稀缺标注数据下提升模型校准性能

- Motivation: 医疗视觉语言模型在医学影像任务中表现出色，但其置信度校准尚未充分探索，错误校准的预测可能导致过度自信的错误，影响临床信任和决策可靠性
- Method: 提出CalibPrompt框架，在提示调优过程中优化少量可学习提示，设计两种校准目标：1）对齐平滑准确率与预测置信度的正则化器；2）最大化文本特征接近度的角度分离损失
- Result: 在4个公开Med-VLMs和5个医学影像数据集上的实验表明，CalibPrompt能一致改善校准性能，同时不明显影响原始准确率
- Conclusion: CalibPrompt是首个有效校准Med-VLMs置信度的框架，通过提示调优和精心设计的校准目标，显著提升了医疗AI系统的可靠性和临床可信度
## cs.AI

### [69] [A Knowledge-driven Adaptive Collaboration of LLMs for Enhancing Medical Decision-making](https://arxiv.org/abs/2509.14998)
*Xiao Wu,Ting-Zhu Huang,Liang-Jian Deng,Yanyuan Qiao,Imran Razzak,Yutong Xie*

Main category: cs.AI

TL;DR: KAMAC是一个知识驱动的自适应多智能体协作框架，通过动态组建专家团队来解决医疗决策中的复杂问题，显著优于传统单智能体和多智能体方法。

- Motivation: 现有基于大语言模型的多智能体协作方法采用静态预分配角色，限制了适应性和动态知识整合能力，无法有效处理复杂临床场景中不断变化的诊断需求。
- Method: KAMAC框架从初始专家智能体开始，通过知识驱动的讨论识别知识缺口，根据需要动态招募额外专家，支持灵活可扩展的协作，最终通过审查更新的智能体评论来做出决策。
- Result: 在两个真实医疗基准测试中，KAMAC显著优于单智能体和先进多智能体方法，特别是在需要动态跨专业知识的复杂临床场景（如癌症预后）中表现突出。
- Conclusion: KAMAC框架通过动态组建专家团队和知识驱动的协作机制，有效解决了医疗决策中多专业知识整合的挑战，为复杂临床场景提供了更灵活和可扩展的解决方案。


### [70] [Generalizable Geometric Image Caption Synthesis](https://arxiv.org/abs/2509.15217)
*Yue Xin,Wenyuan Wang,Rui Pan,Ruida Wang,Howard Meng,Renjie Pi,Shizhe Diao,Tong Zhang*

Main category: cs.AI

TL;DR: 本文提出RLVR方法，通过强化学习和可验证奖励来改进几何图像标注生成，提升多模态大语言模型在几何问题解决和通用推理任务上的性能

- Motivation: 当前多模态大语言模型在处理复杂几何问题时表现不佳，主要原因是缺乏高质量的几何图像-文本对数据集，且传统模板化数据合成方法泛化能力有限
- Method: 采用强化学习与可验证奖励(RLVR)方法，基于50个基本几何关系合成几何图像，并通过数学问题解决任务获得的奖励信号来优化图像标注
- Result: 在MathVista和MathVerse的非几何图像任务上获得2.8%-4.8%的准确率提升，在MMMU的艺术、设计、技术和工程任务上获得2.4%-3.9%的改进
- Conclusion: RLVR方法能够有效捕捉几何问题解决的关键特征，不仅提升了几何任务性能，还增强了模型在分布外场景下的通用推理能力
## cs.LG

### [71] [One-step Multi-view Clustering With Adaptive Low-rank Anchor-graph Learning](https://arxiv.org/abs/2509.14724)
*Zhiyuan Xue,Ben Yang,Xuetao Zhang,Fei Wang,Zhiping Lin*

Main category: cs.LG

TL;DR: 提出了一种名为OMCAL的一步多视图聚类方法，通过自适应低秩锚图学习解决现有锚图多视图聚类方法的信息冗余和噪声干扰问题，并将类别指示符获取与共识锚图学习统一到一个框架中，显著提升了聚类效果和效率。

- Motivation: 现有锚图多视图聚类方法存在两个主要问题：1）直接将多样锚图嵌入到共识锚图中，忽略了冗余信息和噪声，导致聚类效果下降；2）需要独立的后续处理来获取聚类指示符，降低了效率和效果。
- Method: 提出了OMCAL方法，使用基于核范数的自适应共识锚图学习模型来对抗信息冗余和噪声干扰，并将类别指示符获取与共识锚图学习整合到统一框架中，实现一步聚类。
- Result: 在普通和大规模数据集上的大量实验表明，OMCAL在聚类效果和效率方面都优于现有的最先进方法。
- Conclusion: OMCAL方法通过自适应低秩锚图学习和统一框架设计，有效解决了现有方法的局限性，在保持计算效率的同时显著提升了多视图聚类的性能。


### [72] [Communication Efficient Split Learning of ViTs with Attention-based Double Compression](https://arxiv.org/abs/2509.15058)
*Federico Alvetreti,Jary Pomponi,Paolo Di Lorenzo,Simone Scardapane*

Main category: cs.LG

TL;DR: 提出了一种名为ADC的新型通信高效分割学习框架，通过注意力机制双重压缩策略显著减少Vision Transformers中间激活值的传输开销。

- Motivation: 解决分割学习中Vision Transformers中间激活值传输带来的巨大通信开销问题，提高训练效率。
- Method: 采用两种并行压缩策略：1）基于注意力分数合并相似样本的激活值（类无关方式）；2）丢弃最不重要的token。两种策略结合实现前向和反向传播的自然压缩。
- Result: 实验结果表明ADC框架在显著降低通信开销的同时保持了高精度，优于现有最先进的分割学习框架。
- Conclusion: ADC框架通过注意力驱动的双重压缩策略有效解决了分割学习中的通信瓶颈问题，为高效分布式训练提供了新思路。


### [73] [Forecasting and Visualizing Air Quality from Sky Images with Vision-Language Models](https://arxiv.org/abs/2509.15076)
*Mohammad Saleh Vahdatpour,Maryam Eyvazi,Yanqing Zhang*

Main category: cs.LG

TL;DR: 开发了一个AI驱动的空气污染监测系统，通过天空图像预测污染水平并生成可视化污染场景，结合统计纹理分析和生成模型技术

- Motivation: 传统空气污染监测系统空间覆盖有限且可访问性差，需要更直观、透明的环境监测方法来提升公众意识和决策支持
- Method: 结合统计纹理分析和监督学习进行污染分类，利用视觉语言模型引导的图像生成技术创建可解释的空气质量可视化表示
- Result: 在城市场景天空图像数据集上验证有效，能够准确估计污染水平并生成语义一致的视觉合成效果
- Conclusion: 该系统为面向用户的智能应用提供了基础，未来将通过绿色CNN架构和FPGA增量学习实现边缘平台的实时推理和节能部署
## eess.SP

### [74] [Doppler Radiance Field-Guided Antenna Selection for Improved Generalization in Multi-Antenna Wi-Fi-based Human Activity Recognition](https://arxiv.org/abs/2509.15129)
*Navid Hasanzadeh,Shahrokh Valaee*

Main category: eess.SP

TL;DR: 提出基于多普勒辐射场(DoRF)的Wi-Fi感知框架，通过多天线噪声抑制和最优天线选择，提升小规模手势识别的泛化能力

- Motivation: Wi-Fi CSI信号存在AP时钟异步和环境硬件噪声问题，即使经过预处理，DoRF中的多普勒速度投影仍受噪声和异常值影响，限制了人类活动识别性能
- Method: 为多天线AP设计新框架，基于DoRF拟合误差抑制噪声并识别最具信息量的天线，利用多普勒速度投影不一致性来指导选择
- Result: 在具有挑战性的小规模手势识别数据集上实验证明，该方法显著提高了泛化能力
- Conclusion: 该DoRF引导的Wi-Fi HAR方法为鲁棒的实际感知部署铺平了道路
## cs.HC

### [75] [QuizRank: Picking Images by Quizzing VLMs](https://arxiv.org/abs/2509.15059)
*Tenghao Ji,Eytan Adar*

Main category: cs.HC

TL;DR: QuizRank是一种利用大语言模型和视觉语言模型来为维基百科文章选择最佳图像的新方法，通过将文本描述转化为多项选择题来评估图像的教学价值。

- Motivation: 维基百科文章中的图像质量参差不齐，编辑人员缺乏专业训练来选择最有效的教学图像，需要一种自动化方法来评估和排名图像的教学价值。
- Method: 使用LLM将文章主题的文本描述转化为关于概念重要视觉特征的多项选择题，然后用VLM测试图像回答这些问题的能力，回答效果越好的图像排名越高。还引入了对比式QuizRank，利用目标概念和干扰概念的特征差异来生成更具区分度的问题。
- Result: 研究表明VLM作为视觉评估器的有效性，显示出与人类测试者的高度一致性，并能有效区分和排名图像。
- Conclusion: QuizRank方法证明了VLM在评估图像教学价值方面的潜力，为维基百科等平台提供了自动化图像选择的可行方案。
## eess.IV

### [76] [Learning Mechanistic Subtypes of Neurodegeneration with a Physics-Informed Variational Autoencoder Mixture Model](https://arxiv.org/abs/2509.15124)
*Sanduni Pinnawala,Annabelle Hartanto,Ivor J. A. Simpson,Peter A. Wijeratne*

Main category: eess.IV

TL;DR: 提出了一种深度生成模型，用于学习基于物理PDE的混合潜在动态模型，超越传统单一PDE假设，能够从神经影像数据中推断可解释的疾病亚型。

- Motivation: 神经退行性疾病建模需要从稀疏高维神经影像数据中捕捉异质性和空间变化的动态。现有物理集成机器学习方法仅限于单一PDE，无法处理多机制疾病亚型，存在模型错误设定和退化问题。
- Method: 将反应-扩散PDE集成到变分自编码器(VAE)混合模型框架中，支持从神经影像数据推断可解释的潜在变量（如扩散性和反应速率）的亚型。
- Result: 在合成基准测试中评估了该方法，并展示了其在从PET数据中发现阿尔茨海默病进展机制亚型方面的潜力。
- Conclusion: 该方法能够学习物理PDE混合模型，有效解决多机制疾病亚型建模问题，为神经退行性疾病研究提供了新的分析工具。
## cs.CY

### [77] [From Pixels to Urban Policy-Intelligence: Recovering Legacy Effects of Redlining with a Multimodal LLM](https://arxiv.org/abs/2509.15132)
*Anthony Howell,Nancy Wu,Sharmistha Bagchi,Yushim Kim,Chayn Sun*

Main category: cs.CY

TL;DR: 使用GPT-4o多模态大语言模型分析街景图像，通过结构化推理-估计流程评估社区贫困和树木覆盖率，成功验证1930年代红线政策的负面社会环境影响，性能优于传统像素分割方法。

- Motivation: 探索多模态大语言模型在扩展城市测量能力和支持基于地点的政策干预评估方面的潜力，特别是验证历史红线政策的长远影响。
- Method: 采用结构化推理-估计流程处理街景图像，使用GPT-4o推断社区贫困程度和树木覆盖率，并嵌入准实验设计评估1930年代红线政策的遗留影响。
- Result: GPT-4o成功恢复了红线政策预期的负面社会环境影响，估计结果与权威数据源统计无差异，且优于传统像素分割基线方法。
- Conclusion: 多模态大语言模型可作为政策级别的社区测量工具，需要在更广泛的政策评估场景中进行验证。
## cs.RO

### [78] [RLBind: Adversarial-Invariant Cross-Modal Alignment for Unified Robust Embeddings](https://arxiv.org/abs/2509.14383)
*Yuhong Lu*

Main category: cs.RO

TL;DR: RLBind是一个两阶段对抗不变性跨模态对齐框架，通过无监督微调硬化视觉编码器，并利用跨模态对应关系最小化干净/对抗特征与文本锚点之间的差异，同时强制跨模态的类级分布对齐，显著提升了多模态编码器的鲁棒性。

- Motivation: 机器人部署中视觉分支面临对抗性和自然损坏，现有防御方法通常在CLIP风格编码器中对齐干净和对抗特征，但忽视了更广泛的跨模态对应关系，导致增益有限且往往损害零样本迁移能力。
- Method: 两阶段框架：第一阶段对干净-对抗对进行无监督微调以硬化视觉编码器；第二阶段通过最小化干净/对抗特征与文本锚点之间的差异来利用跨模态对应关系，同时强制跨模态的类级分布对齐。
- Result: 在图像、音频、热成像和视频数据上的广泛实验表明，RLBind在干净准确率和范数有界对抗鲁棒性方面均优于LanguageBind主干和标准微调基线。
- Conclusion: RLBind在不牺牲泛化能力的情况下提高了鲁棒性，为具身机器人在导航、操作和其他自主场景中提供了更安全的多传感器感知堆栈的实用路径。


### [79] [Designing Latent Safety Filters using Pre-Trained Vision Models](https://arxiv.org/abs/2509.14758)
*Ihab Tabbara,Yuxuan Yang,Ahmad Hamzeh,Maxwell Astafyev,Hussein Sibai*

Main category: cs.RO

TL;DR: 本文探讨预训练视觉模型在视觉安全滤波器中的应用效果，比较不同训练策略和模型架构的性能表现

- Motivation: 解决视觉控制系统的安全性问题，特别是在关键应用场景中的部署挑战，探索预训练视觉模型作为安全滤波器骨干的有效性
- Method: 使用预训练视觉模型作为分类器骨干定义故障集、基于Hamilton-Jacobi可达性分析的安全滤波器骨干，以及潜在世界模型骨干，比较从头训练、微调和冻结三种策略
- Result: 评估了不同预训练视觉模型在各种任务中的性能表现，比较了学习世界模型和Q函数在安全策略切换决策中的效果
- Conclusion: 预训练视觉模型在视觉安全滤波器设计中具有应用潜力，但需要根据具体任务选择适当的训练策略和模型架构，同时考虑资源受限设备的实际部署需求


### [80] [M4Diffuser: Multi-View Diffusion Policy with Manipulability-Aware Control for Robust Mobile Manipulation](https://arxiv.org/abs/2509.14980)
*Ju Dong,Lei Zhang,Liding Zhang,Yao Ling,Yu Fu,Kaixin Bai,Zoltán-Csaba Márton,Zhenshan Bing,Zhaopeng Chen,Alois Christian Knoll,Jianwei Zhang*

Main category: cs.RO

TL;DR: M4Diffuser是一个用于移动操作的混合框架，结合多视图扩散策略和新型优化控制器，在非结构化环境中显著提高了成功率和安全性

- Motivation: 解决现有单视图方法在非结构化环境中视野有限、探索能力不足的问题，以及传统控制器在奇异点附近效率低下的挑战
- Method: 提出混合框架：多视图扩散策略生成任务相关的末端执行器目标，ReM-QP控制器执行目标（消除松弛变量提高计算效率，加入可操作性感知偏好增强鲁棒性）
- Result: 在仿真和真实环境实验中，相比基线方法成功率提高7-56%，碰撞减少3-31%，展现了强大的泛化能力和平滑的全身协调性能
- Conclusion: M4Diffuser为在非结构化环境中实现可靠的移动操作开辟了新途径，展示了优异的性能和泛化能力
## cs.GR

### [81] [WorldForge: Unlocking Emergent 3D/4D Generation in Video Diffusion Model via Training-Free Guidance](https://arxiv.org/abs/2509.15130)
*Chenxi Song,Yanming Yang,Tong Zhao,Ruibo Li,Chi Zhang*

Main category: cs.GR

TL;DR: WorldForge是一个无需训练的推理时框架，通过三个耦合模块实现精确的运动轨迹控制，解决了视频扩散模型在3D/4D任务中的可控性和几何一致性问题。

- Motivation: 现有视频扩散模型虽然具有丰富的空间先验知识，但存在可控性有限和几何不一致的问题，阻碍了其在3D/4D任务中的实际应用。传统方法需要重新训练或微调，这会破坏预训练知识且计算成本高。
- Method: 提出三个紧密耦合的模块：1) 步内递归细化机制，在每个去噪步骤内重复优化网络预测；2) 流门控潜在融合，利用光流相似性解耦运动和外观；3) 双路径自校正引导，比较引导和非引导路径来校正轨迹漂移。
- Result: 在多个基准测试上的广泛实验验证了该方法在真实性、轨迹一致性和视觉保真度方面的优越性，能够实现精确的运动控制和逼真的内容生成。
- Conclusion: WorldForge引入了一种新颖的即插即用可控视频合成范式，为利用生成先验进行空间智能任务提供了新视角。
## cs.SD

### [82] [Two Web Toolkits for Multimodal Piano Performance Dataset Acquisition and Fingering Annotation](https://arxiv.org/abs/2509.15222)
*Junhyung Park,Yonghyun Kim,Joonhyung Bae,Kirak Kim,Taegyun Kwon,Alexander Lerch,Juhan Nam*

Main category: cs.SD

TL;DR: 开发了一个集成网络工具包，包含PiaRec和ASDF两个GUI，用于简化钢琴表演多模态数据的采集和标注

- Motivation: 钢琴表演是多模态活动，但大规模多模态数据采集过程繁琐，阻碍了该领域的研究进展
- Method: 创建了两个图形用户界面：PiaRec用于同步采集音频、视频、MIDI和表演元数据；ASDF用于从视觉数据中高效标注演奏指法
- Result: 开发了一个完整的系统，能够简化多模态钢琴表演数据集的采集过程
- Conclusion: 该集成工具包可以有效克服钢琴表演多模态数据采集的瓶颈问题
