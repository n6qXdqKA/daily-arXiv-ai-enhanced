[[toc]]

## cs.CV

### [1] [Towards Reliable AR-Guided Surgical Navigation: Interactive Deformation Modeling with Data-Driven Biomechanics and Prompts](https://arxiv.org/abs/2506.08048)
*Zheng Han,Jun Zhou,Jialun Pei,Jing Qin,Yingfang Fan,Qi Dou*

Main category: cs.CV

TL;DR: 提出了一种数据驱动的生物力学算法，结合人机交互机制，提升AR手术导航中变形建模的效率和准确性。

- Motivation: 现有方法在计算效率和应对大解剖变化（如气腹或韧带解剖）时表现不足，导致AR导航不可靠。
- Method: 结合数据驱动的生物力学算法和人机交互机制，允许外科医生动态纠正解剖偏差。
- Result: 在公开数据集上，算法平均目标配准误差为3.42 mm，结合交互提示后降至2.78 mm。
- Conclusion: 该框架实现了高效准确的变形建模，提升了外科医生与算法的协作，为更安全可靠的手术导航铺平道路。


### [2] [ReCogDrive: A Reinforced Cognitive Framework for End-to-End Autonomous Driving](https://arxiv.org/abs/2506.08052)
*Yongkang Li,Kaixin Xiong,Xiangyu Guo,Fang Li,Sixu Yan,Gangwei Xu,Lijun Zhou,Long Chen,Haiyang Sun,Bing Wang,Guang Chen,Hangjun Ye,Wenyu Liu,Xinggang Wang*

Main category: cs.CV

TL;DR: ReCogDrive提出了一种结合视觉语言模型（VLM）和扩散规划器的自动驾驶系统，通过三阶段训练解决领域差距和动作空间不匹配问题，并在NAVSIM基准测试中取得优异表现。

- Motivation: 当前端到端自动驾驶在罕见和长尾场景中表现不佳，且现有基于VLM的方法存在领域差距、动作空间不匹配和模仿学习局限性。
- Method: 采用三阶段训练：1）用驾驶问答数据集训练VLM；2）扩散规划器进行模仿学习；3）强化学习微调。
- Result: 在NAVSIM基准测试中PDMS达到89.6，超越之前最佳视觉方法5.6分。
- Conclusion: ReCogDrive通过结合VLM和扩散规划器，显著提升了自动驾驶在复杂场景中的表现。


### [3] [CuRe: Cultural Gaps in the Long Tail of Text-to-Image Systems](https://arxiv.org/abs/2506.08071)
*Aniket Rege,Zinnia Nie,Mahesh Ramesh,Unmesh Raskar,Zhuoran Yu,Aditya Kusupati,Yong Jae Lee,Ramya Korlakai Vinayak*

Main category: cs.CV

TL;DR: CuRe是一个用于评估文本到图像（T2I）系统文化代表性的新基准和评分套件，通过分析系统对文本条件增加的响应来量化文化偏差。

- Motivation: 现有的T2I系统训练数据以欧美为中心，忽视了全球南部的文化多样性，需要一种方法来评估和改善这种偏差。
- Method: 利用Wikimedia知识图谱构建了一个包含300个文化产物的数据集，分为6个文化轴，通过分析T2I系统对文本条件增加的响应来评估文化代表性。
- Result: CuRe评分器与人类对感知相似性、图像-文本对齐和文化多样性的判断高度相关，适用于多种图像编码器和T2I系统。
- Conclusion: CuRe提供了一种可扩展的方法来量化T2I系统的文化偏差，有助于改善文化多样性表示。


### [4] [IGraSS: Learning to Identify Infrastructure Networks from Satellite Imagery by Iterative Graph-constrained Semantic Segmentation](https://arxiv.org/abs/2506.08137)
*Oishee Bintey Hoque,Abhijin Adiga,Aniruddha Adiga,Siddharth Chaudhary,Madhav V. Marathe,S. S. Ravi,Kirti Rajagopalan,Amanda Wilson,Samarth Swarup*

Main category: cs.CV

TL;DR: IGraSS是一个结合语义分割和图优化的框架，用于改进不完整的地面真实数据，显著提升运河和道路网络的映射准确性。

- Motivation: 现有语义分割模型依赖大量标注数据，但地面真实数据的不完整会影响性能。基础设施网络（如运河和道路）具有图级特性（如可达性或连通性），可用于优化地面真实数据。
- Method: IGraSS结合了多模态（RGB、NDWI、DEM）的语义分割模块和图优化的地面真实数据细化模块，迭代处理卫星图像。
- Result: 实验显示，IGraSS将不可达运河段从18%降至3%，且使用优化后的地面真实数据显著提升了运河识别效果。
- Conclusion: IGraSS是一个通用框架，适用于优化噪声地面真实数据及从遥感图像中映射基础设施网络。


### [5] [Spectral Domain Neural Reconstruction for Passband FMCW Radars](https://arxiv.org/abs/2506.08163)
*Harshvardhan Takawale,Nirupam Roy*

Main category: cs.CV

TL;DR: SpINRv2是一种基于神经网络的框架，用于高保真度体积重建，通过改进频率调制连续波雷达技术，解决了高频下的相位混叠和子区间模糊问题。

- Motivation: 在高频雷达应用中，相位混叠和子区间模糊问题显著，传统方法难以准确建模。SpINRv2旨在通过神经框架解决这些问题，提升重建精度。
- Method: 提出了一种完全可微的频率域前向模型，结合隐式神经表示（INR）进行连续体积场景建模，并引入稀疏性和平滑性正则化以消除子区间模糊。
- Result: 实验表明，SpINRv2在高频条件下显著优于经典和基于学习的方法，为神经雷达3D成像设立了新基准。
- Conclusion: SpINRv2通过频率域建模和正则化技术，有效解决了高频雷达重建中的关键问题，成为该领域的新标杆。


### [6] [Surgeon Style Fingerprinting and Privacy Risk Quantification via Discrete Diffusion Models in a Vision-Language-Action Framework](https://arxiv.org/abs/2506.08185)
*Huixin Zhan,Jason H. Moore*

Main category: cs.CV

TL;DR: 论文提出了一种基于离散扩散框架和视觉-语言-动作（VLA）管道的方法，用于建模外科医生的个性化操作风格，同时关注隐私保护。

- Motivation: 当前AI系统常忽略外科医生的个性化操作风格，而本文旨在通过多模态输入（如内窥镜视频、手术意图语言等）建模这些差异。
- Method: 采用离散扩散框架，结合VLA管道，将手势预测建模为结构化序列去噪任务，并通过自然语言提示编码个性化风格。
- Result: 在JIGSAWS数据集上验证了方法能准确重建手势序列并学习到每位外科医生的独特运动指纹，但个性化嵌入会增加身份泄露风险。
- Conclusion: 个性化嵌入虽提升性能，但也增加隐私风险，需在手术建模中平衡个性化与隐私保护。


### [7] [Open World Scene Graph Generation using Vision Language Models](https://arxiv.org/abs/2506.08189)
*Amartya Dutta,Kazi Sajeed Mehrab,Medha Sawhney,Abhilash Neog,Mridul Khurana,Sepideh Fatemi,Aanish Pradhan,M. Maruf,Ismini Lourentzou,Arka Daw,Anuj Karpatne*

Main category: cs.CV

TL;DR: 论文提出了一种无需训练的开放世界场景图生成（Open-World SGG）框架，利用预训练的视觉语言模型（VLMs）实现零样本推理。

- Motivation: 现有方法依赖数据集特定监督或微调，限制了在开放世界中的适用性。本文旨在利用预训练VLMs的知识，无需额外学习即可生成场景图。
- Method: 将SGG视为零样本结构化推理问题，结合多模态提示、嵌入对齐和轻量级对优化策略，支持对未见对象和关系的推理。
- Result: 在Visual Genome、Open Images V6和PSG数据集上的实验表明，预训练VLMs无需任务级训练即可实现关系理解。
- Conclusion: Open-World SGG框架高效、模型无关，展示了预训练VLMs在开放世界场景图生成中的潜力。


### [8] [Generative Learning of Differentiable Object Models for Compositional Interpretation of Complex Scenes](https://arxiv.org/abs/2506.08191)
*Antoni Nowinowski,Krzysztof Krawiec*

Main category: cs.CV

TL;DR: 扩展了DVP架构，使其能处理多物体场景，并通过潜在空间采样和多种训练模式提升训练效率，优于基线模型。

- Motivation: 解决原始DVP无法处理多物体场景的问题，并利用潜在空间的可解释性优化训练。
- Method: 扩展DVP架构，引入潜在空间采样和多训练模式（图像和潜在空间损失函数），提出新基准数据集。
- Result: 在重建质量和分解重叠物体方面优于MONet和LIVE，训练效率显著提升。
- Conclusion: 扩展的DVP在多物体场景中表现优异，但可微分渲染在自编码器中仍有局限性。


### [9] [GIQ: Benchmarking 3D Geometric Reasoning of Vision Foundation Models with Simulated and Real Polyhedra](https://arxiv.org/abs/2506.08194)
*Mateusz Michalkiewicz,Anekha Sokhal,Tadeusz Michalkiewicz,Piotr Pawlikowski,Mahsa Baktashmotlagh,Varun Jampani,Guha Balakrishnan*

Main category: cs.CV

TL;DR: GIQ是一个评估视觉和视觉语言基础模型几何推理能力的综合基准，揭示了当前模型在几何理解上的显著不足。

- Motivation: 现有方法在标准基准上表现良好，但对几何属性的真实理解尚不明确，因此需要专门评估几何推理能力的工具。
- Method: GIQ包含224种多样多面体的合成和真实图像，通过单目3D重建、3D对称检测、心理旋转测试和零样本形状分类任务进行系统实验。
- Result: 当前模型在基本几何形状重建、对称性检测和复杂几何区分任务中表现不佳，视觉语言助手在复杂多面体上准确率极低。
- Conclusion: GIQ为几何智能研究提供了结构化平台，有助于未来几何感知表示学习的进展。


### [10] [A Comprehensive Study of Decoder-Only LLMs for Text-to-Image Generation](https://arxiv.org/abs/2506.08210)
*Andrew Z. Wang,Songwei Ge,Tero Karras,Ming-Yu Liu,Yogesh Balaji*

Main category: cs.CV

TL;DR: 研究探讨了使用现代仅解码器LLM作为文本编码器在文本到图像扩散模型中的效果，发现层归一化平均嵌入优于传统方法。

- Motivation: 现有文本到图像模型仍使用过时的T5和CLIP作为文本编码器，研究旨在评估现代LLM的潜力。
- Method: 构建标准化训练和评估流程，训练27个模型，分析12种文本编码器的嵌入提取方式、LLM变体和模型大小。
- Result: 层归一化平均嵌入显著提升复杂提示的对齐效果，多数LLM表现优于T5基线。
- Conclusion: 现代LLM作为文本编码器在文本到图像生成中具有优势，尤其是层归一化平均嵌入方法。


### [11] [Using Satellite Images And Self-supervised Machine Learning Networks To Detect Water Hidden Under Vegetation](https://arxiv.org/abs/2506.08214)
*Ioannis Iakovidis,Zahra Kalantari,Amir Hossein Payberah,Fernando Jaramillo,Francisco Pena Escobar*

Main category: cs.CV

TL;DR: 论文提出了一种结合深度聚类和负采样的自监督方法，用于雷达卫星图像的水陆分割，无需人工标注，并通过集成模型提升性能。

- Motivation: 解决传统模型依赖大量人工标注数据的高成本和低效率问题。
- Method: 采用深度聚类和负采样的自监督训练方法，并实现集成模型以减少方差。
- Result: 自监督集成模型在测试集上的IOU指标比全监督单模型提高了0.02。
- Conclusion: 自监督方法在减少标注成本的同时，能够实现接近甚至优于全监督模型的性能。


### [12] [Jamais Vu: Exposing the Generalization Gap in Supervised Semantic Correspondence](https://arxiv.org/abs/2506.08220)
*Octave Mariotti,Zhipeng Du,Yash Bhalgat,Oisin Mac Aodha,Hakan Bilen*

Main category: cs.CV

TL;DR: 论文提出了一种通过单目深度估计将2D关键点提升到3D空间的方法，以学习密集语义对应关系，解决了现有方法在稀疏标注关键点上的泛化问题。

- Motivation: 现有监督语义对应方法局限于稀疏标注关键点的泛化能力，无法有效学习密集对应关系。
- Method: 提出一种新方法，利用单目深度估计将2D关键点映射到3D空间，构建连续规范流形，无需显式3D监督或相机标注。
- Result: 实验表明，该方法在未见关键点上显著优于监督基线，且无监督基线在不同数据集间泛化时表现更优。
- Conclusion: 该方法通过学习密集对应关系，显著提升了语义对应的泛化能力，同时展示了无监督方法的潜力。


### [13] [A Good CREPE needs more than just Sugar: Investigating Biases in Compositional Vision-Language Benchmarks](https://arxiv.org/abs/2506.08227)
*Vishaal Udandarao,Mehdi Cherti,Shyamgopal Karthik,Jenia Jitsev,Samuel Albanie,Matthias Bethge*

Main category: cs.CV

TL;DR: 论文分析了17个用于评估视觉语言模型组合理解能力的基准，发现其设计存在偏见，导致简单启发式方法与CLIP模型表现相当，并提出改进建议。

- Motivation: 研究旨在揭示现有视觉语言组合理解基准的设计缺陷及其导致的评估偏差。
- Method: 通过分析基准的数据来源和构建过程（如负样本生成），识别其中的偏见，并验证简单启发式方法的有效性。
- Result: 发现基准的正负样本分布不对称，导致其无法有效衡量组合理解能力。
- Conclusion: 提出改进基准设计的建议，以减少简单攻击的影响。


### [14] [Highly Compressed Tokenizer Can Generate Without Training](https://arxiv.org/abs/2506.08257)
*L. Lao Beyer,T. Li,X. Chen,S. Karaman,K. He*

Main category: cs.CV

TL;DR: 1D图像标记器通过高度压缩的一维序列实现图像编辑和生成，无需训练生成模型。

- Motivation: 探索1D图像标记器在高度压缩下的图像编辑和生成能力。
- Method: 利用向量量化的1D标记器，通过启发式操作和梯度优化实现图像编辑和生成。
- Result: 展示了在修复和文本引导编辑中的多样性和真实性。
- Conclusion: 1D标记器在图像编辑和生成中具有高效性和灵活性。


### [15] [Seeing Voices: Generating A-Roll Video from Audio with Mirage](https://arxiv.org/abs/2506.08279)
*Aditi Sundararaman,Amogh Adishesha,Andrew Jaegle,Dan Bigioi,Hyoung-Kyu Song,Jon Kyl,Justin Mao,Kevin Lan,Mojtaba Komeili,ShahRukh Athar,Sheila Babayan,Stanislau Beliasau,William Buchwalter*

Main category: cs.CV

TL;DR: Mirage是一个音频到视频的基础模型，能够根据音频输入生成逼真、富有表现力的视频内容，尤其擅长生成与语音同步的人物视频。

- Motivation: 视频的感染力依赖于音频与视觉的和谐结合，但现有方法要么忽略音频专注于无声视频生成，要么局限于特定应用领域（如重新配音）。Mirage旨在填补这一空白。
- Method: Mirage采用基于自注意力的统一训练方法，支持从零开始训练或基于现有权重微调，无需依赖特定于音频的架构或损失组件。
- Result: Mirage生成的视频在主观质量上优于其他方法，能够根据语音音频生成逼真的人物表演视频。
- Conclusion: Mirage为音频到视频生成提供了一种通用且高质量的方法，尤其在语音同步视频生成方面表现出色。


### [16] [SEMA: a Scalable and Efficient Mamba like Attention via Token Localization and Averaging](https://arxiv.org/abs/2506.08297)
*Nhat Thanh Tran,Fanghui Xue,Shuai Zhang,Jiancheng Lyu,Yunling Zheng,Yingyong Qi,Jack Xin*

Main category: cs.CV

TL;DR: 论文提出了一种名为SEMA的新型注意力机制，解决了传统注意力计算复杂度高和线性注意力无法聚焦的问题，并在图像分类任务中表现出色。

- Motivation: 传统注意力机制在计算机视觉任务中存在计算复杂度高（二次复杂度）和线性注意力无法聚焦的问题，需要一种更高效的替代方案。
- Method: 通过数学定义广义注意力，并基于分散特性和Mamba形式注意力设计了SEMA，利用令牌定位避免分散并保持聚焦，同时通过算术平均捕捉全局注意力。
- Result: 在Imagenet-1k分类任务中，SEMA表现优于线性注意力和近期视觉Mamba模型，尤其在更大尺度图像上。
- Conclusion: SEMA是一种可扩展且高效的注意力机制，为计算机视觉任务提供了新的解决方案。


### [17] [OpenRR-1k: A Scalable Dataset for Real-World Reflection Removal](https://arxiv.org/abs/2506.08299)
*Kangning Yang,Ling Ouyang,Huiming Sun,Jie Cai,Lan Fu,Jiaming Ding,Chiu Man Ho,Zibo Meng*

Main category: cs.CV

TL;DR: 提出了一种新颖的反射数据集收集范式，并发布了一个高质量、多样化的OpenRR-1k数据集，用于提升反射去除技术的鲁棒性。

- Motivation: 现有反射去除技术因缺乏高质量的真实场景数据集而受限，需要一种便捷、经济且可扩展的数据收集方法。
- Method: 提出了一种新的数据集收集范式，确保数据高质量、对齐且多样化，并基于此收集了包含1000对图像的OpenRR-1k数据集。
- Result: 通过实验验证，OpenRR-1k数据集显著提升了反射去除方法在复杂真实环境中的鲁棒性。
- Conclusion: OpenRR-1k数据集为反射去除技术提供了有效的基准支持，未来可进一步扩展数据集规模和应用场景。


### [18] [Hyperspectral Image Classification via Transformer-based Spectral-Spatial Attention Decoupling and Adaptive Gating](https://arxiv.org/abs/2506.08324)
*Guandong Li,Mengxia Ye*

Main category: cs.CV

TL;DR: STNet是一种新型网络架构，通过空间-光谱Transformer模块有效解决高光谱图像分类中的过拟合和泛化能力问题。

- Motivation: 高光谱图像分类面临高维数据、地物稀疏分布和光谱冗余等挑战，导致过拟合和泛化能力受限。
- Method: 提出STNet，采用空间-光谱Transformer模块，通过显式解耦空间和光谱注意力及智能门控机制，实现高效特征提取与融合。
- Result: 在IN、UP和KSC数据集上表现优于主流方法，提升了特征提取能力且未增加网络深度或宽度。
- Conclusion: STNet通过创新设计显著提升了高光谱图像分类性能，适用于小样本和高噪声场景。


### [19] [Locating Tennis Ball Impact on the Racket in Real Time Using an Event Camera](https://arxiv.org/abs/2506.08327)
*Yuto Kase,Kai Ishibe,Ryoma Yasuda,Yudai Washida,Sakiko Hashimoto*

Main category: cs.CV

TL;DR: 提出了一种使用事件相机实时定位网球拍击球位置的方法，解决了高速相机内存消耗大和手动数字化耗时的问题。

- Motivation: 在网球等球拍运动中，击球位置的准确定位对分析球员表现和个性化装备设计至关重要，但现有方法存在内存消耗大和人工误差问题。
- Method: 采用事件相机高效捕捉亮度变化，结合三步识别（挥拍时间范围、击球时机、球与球拍轮廓）和原创事件处理技术（PATS）。
- Result: 实验结果表明，该方法在测量网球运动员表现时处于允许范围内，且计算时间满足实时应用需求。
- Conclusion: 事件相机方法能够高效、准确地实时定位击球位置，适用于长时间监控球员表现。


### [20] [How Much To Guide: Revisiting Adaptive Guidance in Classifier-Free Guidance Text-to-Vision Diffusion Models](https://arxiv.org/abs/2506.08351)
*Huixuan Zhang,Junzhe Zhang,Xiaojun Wan*

Main category: cs.CV

TL;DR: 提出了一种通用的自适应引导策略Step AG，通过限制分类器自由引导在前几步去噪中，显著提升了生成效率。

- Motivation: 分类器自由引导方法虽然流行，但计算成本高，现有自适应引导方法缺乏分析和实证支持。
- Method: 提出Step AG策略，仅在去噪的前几步应用分类器自由引导。
- Result: 实验表明，该方法在图像质量和文本对齐上表现良好，平均提速20%-30%。
- Conclusion: Step AG是一种简单通用的策略，适用于多种模型和设置。


### [21] [MedMoE: Modality-Specialized Mixture of Experts for Medical Vision-Language Understanding](https://arxiv.org/abs/2506.08356)
*Shivang Chopra,Lingchao Mao,Gabriela Sanchez-Rodriguez,Andrew J Feola,Jing Li,Zsolt Kira*

Main category: cs.CV

TL;DR: MedMoE提出了一种动态适应不同医学成像模态的视觉语言处理框架，通过Mixture-of-Experts模块和多尺度特征提取，提升模态对齐和检索性能。

- Motivation: 现有医学视觉语言框架采用统一的局部特征提取策略，忽视了不同模态的特定需求。
- Method: MedMoE结合了基于报告类型的MoE模块，通过专家分支处理多尺度图像特征，利用Swin Transformer提取特征金字塔，实现空间自适应注意力。
- Result: 实验表明，MedMoE在多种医学基准测试中提升了模态对齐和检索性能。
- Conclusion: MedMoE证明了模态专用视觉表征在临床视觉语言系统中的价值。


### [22] [Image Demoiréing Using Dual Camera Fusion on Mobile Phones](https://arxiv.org/abs/2506.08361)
*Yanting Mei,Zhilu Zhang,Xiaohe Wu,Wangmeng Zuo*

Main category: cs.CV

TL;DR: 论文提出了一种利用双摄像头融合（DCID）去除图像摩尔纹的方法，通过超广角图像辅助广角图像去摩尔纹，效果优于现有方法。

- Motivation: 现代智能手机通常配备双摄像头，且超广角图像在广角图像出现摩尔纹时能提供正常颜色和纹理。
- Method: 提出轻量级超广角图像编码器，集成到现有去摩尔纹网络中，并采用快速两阶段图像对齐方式。
- Result: 在包含约9,000个样本的真实数据集上，方法表现优于现有技术。
- Conclusion: DCID方法通过双摄像头融合有效去除摩尔纹，且效果显著。


### [23] [SECOND: Mitigating Perceptual Hallucination in Vision-Language Models via Selective and Contrastive Decoding](https://arxiv.org/abs/2506.08391)
*Woohyeon Park,Woojin Kim,Jaeik Kim,Jaeyoung Do*

Main category: cs.CV

TL;DR: SECOND是一种通过选择性对比解码减少视觉语言模型中物体幻觉的新方法，利用多尺度视觉信息提升性能。

- Motivation: 现有视觉语言模型因物体幻觉问题导致性能受限，需更精确的视觉理解方法。
- Method: 提出SECOND方法，通过选择性整合多尺度视觉信息并进行迭代对比，减少幻觉。
- Result: SECOND显著减少幻觉，并在多个基准测试中表现优异。
- Conclusion: 多尺度视觉信息的优先对比在视觉语言模型中有巨大潜力，优于现有方法。


### [24] [RadioDUN: A Physics-Inspired Deep Unfolding Network for Radio Map Estimation](https://arxiv.org/abs/2506.08418)
*Taiqin Chen,Zikun Zhou,Zheng Fang,Wenzhen Zou,Kanjun Liu,Ke Chen,Yongbing Zhang,Yaowei Wang*

Main category: cs.CV

TL;DR: 论文提出了一种基于稀疏信号恢复和物理传播模型的无线电地图估计方法，通过深度学习网络RadioDUN和动态重加权模块（DRM）优化参数，结合障碍物因素提升性能。

- Motivation: 现有方法难以结合无线电地图的物理特性，稀疏样本难以构建密集无线电地图。
- Method: 将无线电地图估计建模为稀疏信号恢复问题，结合物理传播模型分解为多因子优化子问题，提出RadioDUN网络和DRM模块。
- Result: 实验表明，该方法优于现有技术。
- Conclusion: RadioDUN通过物理模型和深度学习结合，显著提升了无线电地图估计的性能。


### [25] [Better Reasoning with Less Data: Enhancing VLMs Through Unified Modality Scoring](https://arxiv.org/abs/2506.08429)
*Mingjie Xu,Andrew Estornell,Hongzheng Yang,Yuzhi Zhao,Zhaowei Zhu,Qi Xuan,Jiaheng Wei*

Main category: cs.CV

TL;DR: 论文提出SCALE方法，通过跨模态评估提升视觉语言模型（VLM）的数据质量，解决图像与文本对齐噪声及文本模糊问题。

- Motivation: 当前视觉语言模型依赖大规模高质量数据集，但存在图像与文本对齐噪声和文本模糊问题，影响模型性能。
- Method: SCALE通过跨模态评估框架，为数据分配任务、生成多类型描述，并评估对齐性、清晰度等指标。
- Result: 发现单模态评估方法低估任务关键样本，而生成图像描述能有效统一多模态任务为文本模态。
- Conclusion: SCALE提升了VLM数据质量，为模型训练提供了更可靠的基准。


### [26] [Enhancing Motion Dynamics of Image-to-Video Models via Adaptive Low-Pass Guidance](https://arxiv.org/abs/2506.08456)
*June Suk Choi,Kyungmin Lee,Sihyun Yu,Yisol Choi,Jinwoo Shin,Kimin Lee*

Main category: cs.CV

TL;DR: 论文提出自适应低通引导（ALG）方法，解决图像到视频（I2V）生成中动态性不足的问题，显著提升视频动态性而不损失图像质量。

- Motivation: 现有I2V方法因过早暴露高频细节导致生成视频动态性不足，需改进以保持动态性和图像质量。
- Method: 提出ALG方法，在去噪早期阶段自适应调制条件图像频率内容，通过低通滤波避免过拟合静态外观。
- Result: ALG在VBench-I2V测试中动态性平均提升36%，同时保持视频质量和图像保真度。
- Conclusion: ALG有效解决了I2V生成中的动态性不足问题，为视频生成提供了简单高效的改进方案。


### [27] [MARMOT: Masked Autoencoder for Modeling Transient Imaging](https://arxiv.org/abs/2506.08470)
*Siyuan Shen,Ziheng Wang,Xingyue Peng,Suan Xia,Ruiqian Li,Shiying Li,Jingyi Yu*

Main category: cs.CV

TL;DR: 提出了一种基于掩码自编码器（MARMOT）的自监督预训练模型，用于处理非视距（NLOS）瞬态成像任务，通过Transformer架构学习特征并预测完整测量。

- Motivation: 现有方法在NLOS场景中主要优化体积密度或表面重建，缺乏从数据集中学习先验知识的能力，因此需要一种能够利用大规模数据预训练的模型。
- Method: 使用Transformer编码器-解码器架构，通过扫描模式掩码（SPM）从部分掩码的瞬态数据中学习特征，并预测完整测量。模型在合成的瞬态数据集TransVerse（500K 3D模型）上预训练。
- Result: 在综合实验中，MARMOT在定量和定性结果上均优于现有方法，证明了其高效性。
- Conclusion: MARMOT通过自监督预训练和Transformer架构，成功提升了NLOS瞬态成像任务的性能，适用于直接特征迁移或解码器微调的下游任务。


### [28] [Context-aware TFL: A Universal Context-aware Contrastive Learning Framework for Temporal Forgery Localization](https://arxiv.org/abs/2506.08493)
*Qilin Yin,Wei Lu,Xiangyang Luo,Xiaochun Cao*

Main category: cs.CV

TL;DR: 论文提出了一种通用上下文感知对比学习框架（UniCaCLF），用于解决视频中部分片段被篡改的时间伪造定位（TFL）问题。

- Motivation: 现有研究多将深度伪造检测视为分类任务，忽略了视频中部分片段被篡改的情况，而TFL更符合实际应用需求。
- Method: 采用监督对比学习，通过异常检测识别伪造片段，并提出上下文感知感知层和自适应上下文更新器，增强伪造与真实片段特征的区分度。
- Result: 在五个公开数据集上的实验表明，UniCaCLF显著优于现有算法。
- Conclusion: UniCaCLF为时间伪造定位提供了一种高效且性能优越的解决方案。


### [29] [MLVTG: Mamba-Based Feature Alignment and LLM-Driven Purification for Multi-Modal Video Temporal Grounding](https://arxiv.org/abs/2506.08512)
*Zhiyi Zhu,Xiaoyu Wu,Zihao Liu,Linlin Yang*

Main category: cs.CV

TL;DR: MLVTG提出了一种新框架，通过MambaAligner和LLMRefiner模块解决现有Transformer方法在视频时间定位中的冗余注意力和模态对齐问题，实现了更精确的定位。

- Motivation: 现有基于Transformer的方法在视频时间定位中存在冗余注意力和模态对齐不佳的问题，需要改进。
- Method: MLVTG结合MambaAligner（使用Vision Mamba块建模时间依赖）和LLMRefiner（利用预训练LLM的冻结层增强语义对齐），实现双对齐策略。
- Result: 在QVHighlights、Charades-STA和TVSum数据集上，MLVTG表现优于现有基线，达到SOTA性能。
- Conclusion: MLVTG通过时间建模和语义净化策略，显著提升了视频时间定位的精度和性能。


### [30] [Robust Visual Localization via Semantic-Guided Multi-Scale Transformer](https://arxiv.org/abs/2506.08526)
*Zhongtao Tian,Wenhao Huang,Zhidong Chen,Xiao Wei Sun*

Main category: cs.CV

TL;DR: 提出了一种结合多尺度特征学习和语义场景理解的框架，用于动态环境中的视觉定位，通过跨尺度注意力融合几何细节和上下文线索，提升定位性能。

- Motivation: 动态环境中光照变化、恶劣天气和移动物体会干扰视觉定位的外观线索，现有绝对姿态回归方法难以保持一致性。
- Method: 采用分层Transformer和跨尺度注意力，结合语义监督和神经场景表示，学习视图不变特征。
- Result: 在TartanAir数据集上，该方法在动态物体、光照变化和遮挡等挑战性场景中优于现有姿态回归方法。
- Conclusion: 多尺度处理与语义指导的结合为动态环境中的鲁棒视觉定位提供了有效策略。


### [31] [LiftVSR: Lifting Image Diffusion to Video Super-Resolution via Hybrid Temporal Modeling with Only 4$\times$RTX 4090s](https://arxiv.org/abs/2506.08529)
*Xijun Wang,Xin Li,Bingchen Li,Zhibo Chen*

Main category: cs.CV

TL;DR: LiftVSR提出了一种高效的视频超分辨率框架，通过结合动态时间注意力和注意力记忆缓存，显著降低了计算成本，同时保持了长期一致性。

- Motivation: 现有方法在视频超分辨率中存在时间一致性不足和计算成本过高的问题，尤其是在长视频中。
- Method: LiftVSR采用混合时间建模机制，包括动态时间注意力（DTA）和注意力记忆缓存（AMC），并通过非对称采样策略优化缓存交互。
- Result: 实验表明，LiftVSR在多个基准测试中表现出色，计算成本显著降低。
- Conclusion: LiftVSR在保持高效的同时，提升了视频超分辨率的时间一致性和性能。


### [32] [TrajFlow: Multi-modal Motion Prediction via Flow Matching](https://arxiv.org/abs/2506.08541)
*Qi Yan,Brian Zhang,Yutong Zhang,Daniel Yang,Joshua White,Di Chen,Jiachao Liu,Langechuan Liu,Binnan Zhuang,Shaoshuai Shi,Renjie Liao*

Main category: cs.CV

TL;DR: TrajFlow是一种基于流匹配的运动预测框架，通过单次推理预测多模态轨迹，显著降低计算开销，同时提升预测一致性和不确定性估计。

- Motivation: 自动驾驶中高效准确的运动预测对安全和决策至关重要，现有生成方法在多模态预测和计算效率上存在不足。
- Method: 提出TrajFlow框架，采用流匹配技术单次预测多轨迹，引入Plackett-Luce分布排序损失优化不确定性估计，并设计自条件训练技术加速推理。
- Result: 在Waymo Open Motion Dataset上，TrajFlow在多项关键指标上达到最优性能。
- Conclusion: TrajFlow为安全关键型自动驾驶应用提供了高效且准确的运动预测解决方案。


### [33] [Convergence of Spectral Principal Paths: How Deep Networks Distill Linear Representations from Noisy Inputs](https://arxiv.org/abs/2506.08543)
*Bowei Tian,Xuntao Lyu,Meng Liu,Hongyi Wang,Ang Li*

Main category: cs.CV

TL;DR: 论文提出Input-Space Linearity Hypothesis（ISLH），认为概念对齐方向源于输入空间，并通过深度选择性放大。引入Spectral Principal Path（SPP）框架，展示深度网络如何沿主导谱方向逐步提取线性表示，并在Vision-Language Models（VLMs）中验证其多模态鲁棒性。

- Motivation: 提升AI的透明性和控制性，从神经元或电路转向结构化语义方向，与人类可解释概念对齐。
- Method: 提出ISLH假设，引入SPP框架，分析深度网络如何沿谱方向提取线性表示，并在VLMs中验证。
- Result: 证明了深度网络逐步提取线性表示的多模态鲁棒性。
- Conclusion: 为深度网络中表示形成的结构化理论奠定基础，有助于提升AI的鲁棒性、公平性和透明性。


### [34] [From Pixels to Graphs: using Scene and Knowledge Graphs for HD-EPIC VQA Challenge](https://arxiv.org/abs/2506.08553)
*Agnese Taluzzi,Davide Gesualdi,Riccardo Santambrogio,Chiara Plizzari,Francesca Palermo,Simone Mentasti,Matteo Matteucci*

Main category: cs.CV

TL;DR: SceneNet和KnowledgeNet是用于HD-EPIC VQA挑战赛的两种方法，分别利用场景图和外部常识知识，结合后达到44.21%的准确率。

- Motivation: 解决复杂的第一人称视觉问答任务，通过细粒度对象交互和外部知识增强推理能力。
- Method: SceneNet使用多模态大语言模型生成场景图；KnowledgeNet引入ConceptNet的常识知识。
- Result: 在HD-EPIC基准测试中，组合方法达到44.21%的准确率。
- Conclusion: 结合场景图和外部知识的方法在复杂VQA任务中表现有效。


### [35] [Towards Cross-Subject EMG Pattern Recognition via Dual-Branch Adversarial Feature Disentanglement](https://arxiv.org/abs/2506.08555)
*Xinyue Niu,Akira Furui*

Main category: cs.CV

TL;DR: 提出了一种基于特征解耦的双分支对抗神经网络，用于跨受试者肌电图（EMG）模式识别，无需校准数据。

- Motivation: 跨受试者EMG模式识别因个体差异面临挑战，传统方法依赖校准数据，耗时且不实用。
- Method: 采用端到端双分支对抗神经网络，将EMG特征解耦为模式特定和受试者特定组件。
- Result: 模型在未见用户数据上表现优异，优于基线方法。
- Conclusion: 该方法为无需校准的跨受试者EMG识别提供了新思路，并展示了在生物识别等领域的潜力。


### [36] [Hierarchical Neural Collapse Detection Transformer for Class Incremental Object Detection](https://arxiv.org/abs/2506.08562)
*Duc Thanh Pham,Hong Dang Nguyen,Nhat Minh Nguyen Quoc,Linh Ngo Van,Sang Dinh Viet,Duc Anh Nguyen*

Main category: cs.CV

TL;DR: 提出了一种名为Hier-DETR的新框架，用于增量目标检测（IOD），通过利用神经崩溃和类别标签的层次关系，确保高效性和竞争力。

- Motivation: 现实世界中新物体不断出现，需要检测模型持续学习而不受灾难性遗忘的影响，但现有IOD模型性能有限且推理时间长。
- Method: 利用神经崩溃处理不平衡数据集，并结合类别标签的层次关系，提出Hier-DETR框架。
- Result: Hier-DETR在效率和性能上均具有竞争力。
- Conclusion: Hier-DETR为解决IOD问题提供了一种高效且性能优越的解决方案。


### [37] [Generating Vision-Language Navigation Instructions Incorporated Fine-Grained Alignment Annotations](https://arxiv.org/abs/2506.08566)
*Yibo Cui,Liang Xie,Yu Zhao,Jiawei Sun,Erwei Yin*

Main category: cs.CV

TL;DR: 论文提出FCA-NIG框架，自动生成具有细粒度跨模态标注的导航指令，解决了现有数据集中子指令和实体级对齐不足的问题，显著提升了VLN智能体的性能。

- Motivation: 现有VLN数据集缺乏细粒度的跨模态对齐标注（如子指令和实体级），限制了智能体在导航任务中的准确决策。
- Method: 提出FCA-NIG框架，通过子轨迹划分、地标检测、指令生成和实体选择等步骤，自动生成具有双级细粒度标注的FCA-R2R数据集。
- Result: 实验表明，FCA-R2R显著提升了多个VLN智能体的性能，增强了状态感知和导航准确性。
- Conclusion: FCA-NIG无需人工标注即可生成高质量训练数据，推动了复杂导航任务中细粒度跨模态学习的发展。


### [38] [Diversity-Guided MLP Reduction for Efficient Large Vision Transformers](https://arxiv.org/abs/2506.08591)
*Chengchao Shen,Hourun Zhu,Gongfan Fang,Jianxin Wang,Xinchao Wang*

Main category: cs.CV

TL;DR: 论文提出了一种名为DGMR的方法，通过多样性引导的MLP压缩，显著减少大型视觉Transformer的参数和计算量，同时几乎不损失性能。

- Motivation: 大型Transformer模型参数过多导致计算和内存成本高昂，研究发现MLP模块占用了大部分参数，因此需要一种高效的压缩方法。
- Method: 采用Gram-Schmidt权重剪枝策略，消除MLP隐藏层的冗余神经元，同时保留权重多样性以在蒸馏过程中更好地恢复性能。
- Result: 实验表明，DGMR方法在多个先进的大型视觉Transformer上实现了超过57%的参数和FLOPs减少，且性能几乎无损。对于EVA-CLIP-E（4.4B），参数和FLOPs减少了71.5%，且性能未下降。
- Conclusion: DGMR是一种高效的压缩方法，显著减少了大型视觉Transformer的资源需求，同时保持了性能，适用于实际应用。


### [39] [Transformers Meet Hyperspectral Imaging: A Comprehensive Study of Models, Challenges and Open Problems](https://arxiv.org/abs/2506.08596)
*Guyang Zhang,Waleed Abdulla*

Main category: cs.CV

TL;DR: 本文综述了Transformer在HSI分类中的应用，分析了其设计选择与挑战，并提出了未来研究方向。

- Motivation: Transformer在长距离依赖学习中表现优异，但在HSI领域的应用尚处于起步阶段，需要系统性的综述和指导。
- Method: 通过分析300多篇论文，对HSI分类的典型流程（如预处理、特征提取、自注意力机制等）进行分类和对比。
- Result: 总结了HSI领域的主要挑战（如数据稀缺、计算开销等），并提出了未来研究重点。
- Conclusion: 旨在为研究者提供选择、组合或扩展Transformer组件的指导，以推动下一代HSI应用的发展。


### [40] [Towards Class-wise Fair Adversarial Training via Anti-Bias Soft Label Distillation](https://arxiv.org/abs/2506.08611)
*Shiji Zhao,Chi Chen,Ranjie Duan,Xizhe Wang,Xingxing Wei*

Main category: cs.CV

TL;DR: 本文提出了一种名为ABSLD的方法，通过调整软标签的平滑度来解决对抗训练中的鲁棒公平性问题。

- Motivation: 对抗训练（AT）和对抗鲁棒性蒸馏（ARD）存在鲁棒公平性问题，即模型对不同类别的鲁棒性表现不均。
- Method: 提出ABSLD方法，通过动态调整不同类别的软标签平滑度，减少学生模型在不同类别上的误差风险差距。
- Result: 实验表明ABSLD在鲁棒性和公平性上优于现有方法。
- Conclusion: ABSLD有效提升了对抗训练的鲁棒公平性，且具有高度适应性。


### [41] [Data-Efficient Challenges in Visual Inductive Priors: A Retrospective](https://arxiv.org/abs/2506.08612)
*Robert-Jan Bruintjes,Attila Lengyel,Osman Semih Kayhan,Davide Zambrano,Nergis Tömen,Hadi Jamali-Rad,Jan van Gemert*

Main category: cs.CV

TL;DR: 论文探讨了在数据不足情况下提升深度学习模型性能的方法，通过组织数据受限挑战赛，发现模型集成和数据增强是关键。

- Motivation: 解决数据不足时深度学习模型性能下降的问题，探索如何通过先验知识提升数据效率。
- Method: 组织四届数据受限挑战赛，限制参与者从头训练模型且禁用迁移学习，研究模型集成和数据增强等方法。
- Result: 成功案例显示，结合Transformer和CNN的模型集成及数据增强效果显著，部分方法引入先验知识。
- Conclusion: 在数据不足时，模型集成、数据增强和先验知识能有效提升深度学习性能。


### [42] [SAMSelect: A Spectral Index Search for Marine Debris Visualization using Segment Anything](https://arxiv.org/abs/2506.08613)
*Joost van Dalen,Yuki M. Asano,Marc Russwurm*

Main category: cs.CV

TL;DR: SAMSelect算法通过选择最佳分类准确率的波段组合，为多光谱图像提供显著的三通道可视化，帮助海洋科学家识别漂浮垃圾。

- Motivation: 由于海洋垃圾在中等分辨率图像中的异质性，传统可视化方法效果不佳，专家需依赖经验和启发式方法选择波段。SAMSelect旨在通过自动化选择优化可视化效果。
- Method: SAMSelect利用Segment Anything Model在小标注数据集上选择分类准确率最高的波段或指数组合，生成三通道可视化。
- Result: 在加纳阿克拉和南非德班的Sentinel-2场景中测试，SAMSelect发现新波段组合（如B8、B2的归一化差异指数）优于文献中的传统指数。
- Conclusion: SAMSelect为海洋科学家提供了一种高效的可视化工具，其开源代码有望推动海洋垃圾的视觉解译研究。


### [43] [A Probability-guided Sampler for Neural Implicit Surface Rendering](https://arxiv.org/abs/2506.08619)
*Gonçalo Dias Pais,Valter Piedade,Moitreya Chatterjee,Marcus Greiff,Pedro Miraldo*

Main category: cs.CV

TL;DR: 该论文提出了一种基于NeRF的改进方法，通过目标采样和新的表面重建损失，提升了3D重建和图像渲染的精度。

- Motivation: 现有NeRF方法因可扩展性问题无法对所有输入数据进行训练，导致采样效率低下。
- Method: 利用前景场景的隐式表面表示，在3D图像投影空间中建模概率密度函数，实现目标采样；提出新的表面重建损失。
- Result: 结合新采样策略和损失函数，显著提升了3D重建和图像渲染的精度，尤其是对感兴趣区域。
- Conclusion: 该方法通过优化采样和损失函数，有效提升了NeRF的性能，适用于复杂场景的细节重建。


### [44] [ECMNet:Lightweight Semantic Segmentation with Efficient CNN-Mamba Network](https://arxiv.org/abs/2506.08629)
*Feixiang Du,Shengkun Wu*

Main category: cs.CV

TL;DR: 提出了一种轻量级CNN-Mamba混合网络ECMNet，用于语义分割，结合了CNN和Mamba的优势，通过EDAB、MSAU和FFM模块提升性能。

- Motivation: 尽管CNN和Transformer在语义分割中表现优异，但全局上下文建模仍有不足。Mamba在视觉任务中展现出长距离依赖建模的潜力，因此结合CNN与Mamba以互补弱点。
- Method: 设计了EDAB轻量瓶颈模块、MSAU多尺度注意力单元和Mamba增强的特征融合模块FFM，以提升特征表示和分割精度。
- Result: 在Cityscapes和CamVid数据集上分别达到70.6%和73.6%的mIoU，参数量为0.87M，计算量为8.27G FLOPs。
- Conclusion: ECMNet在精度和效率上取得了平衡，验证了CNN与Mamba结合的有效性。


### [45] [RoboSwap: A GAN-driven Video Diffusion Framework For Unsupervised Robot Arm Swapping](https://arxiv.org/abs/2506.08632)
*Yang Bai,Liudi Yang,George Eskandar,Fengyi Shen,Dong Chen,Mohammad Altillawi,Ziyuan Liu,Gitta Kutyniok*

Main category: cs.CV

TL;DR: RoboSwap提出了一种结合GAN和扩散模型的视频编辑框架，用于机器人学习中的跨平台数据生成，解决了数据稀缺问题。

- Motivation: 视频合成和编辑的生成模型虽有进展，但高质量数据稀缺限制了机器人学习的跨平台泛化能力。
- Method: RoboSwap通过分割机器人手臂、使用GAN进行无配对翻译，并结合扩散模型增强视频连贯性和运动真实性。
- Result: 实验表明，RoboSwap在三个基准测试中优于现有视频和图像编辑模型，结构连贯性和运动一致性表现更优。
- Conclusion: RoboSwap为机器人学习提供了可靠的跨平台数据生成解决方案。


### [46] [SurfR: Surface Reconstruction with Multi-scale Attention](https://arxiv.org/abs/2506.08635)
*Siddhant Ranade,Gonçalo Dias Pais,Ross Tyler Whitaker,Jacinto C. Nascimento,Pedro Miraldo,Srikumar Ramalingam*

Main category: cs.CV

TL;DR: 提出了一种基于隐式表示的快速、准确的无组织点云表面重建算法，通过三项关键贡献实现了最佳精度与速度的权衡。

- Motivation: 现有学习方法要么需要针对单个对象训练的小模型（细节丰富但泛化性差），要么使用大模型（泛化性强但细节不足且推理慢），因此需要一种兼顾速度、精度和泛化性的新方法。
- Method: 1. 延迟查询（lazy query）加速重建；2. 并行多尺度网格表示增强特征鲁棒性；3. 跨尺度注意力机制提升重建效果。
- Result: 新方法在速度上优于所有基线方法，仅略微损失性能，实现了最佳精度与速度的权衡。
- Conclusion: 该算法通过隐式表示和三项创新，显著提升了点云表面重建的速度和精度，同时保持了泛化能力。


### [47] [Orientation Matters: Making 3D Generative Models Orientation-Aligned](https://arxiv.org/abs/2506.08640)
*Yichong Lu,Yuzhuo Tian,Zijin Jiang,Yikun Zhao,Yuanbo Yang,Hao Ouyang,Haoji Hu,Huimin Yu,Yujun Shen,Yiyi Liao*

Main category: cs.CV

TL;DR: 论文提出了一种方向对齐的3D物体生成任务，并构建了Objaverse-OA数据集，通过微调两种3D生成模型，实现了跨类别的一致方向生成。

- Motivation: 现有3D生成模型因训练数据不一致导致结果方向不统一，限制了其在下游任务中的应用。
- Method: 构建Objaverse-OA数据集，微调多视角扩散和3D变分自编码器模型以实现方向对齐生成。
- Result: 实验表明该方法优于后处理对齐方法，并展示了零样本方向估计和高效旋转操作等下游应用。
- Conclusion: 方向对齐的3D生成方法显著提升了模型的一致性和实用性。


### [48] [Enhancing Video Memorability Prediction with Text-Motion Cross-modal Contrastive Loss and Its Application in Video Summarization](https://arxiv.org/abs/2506.08649)
*Zhiyi Zhu,Xiaoyu Wu,Youwei Lu*

Main category: cs.CV

TL;DR: 本文提出了一种新的多模态视频记忆性预测模型TMCCL，通过文本-运动跨模态对比损失增强运动特征表示，并在两个数据集上取得最优性能。同时，提出MWCVS方法，利用视频记忆性预测减少视频摘要标签的主观性。

- Motivation: 现有视频记忆性预测模型未能充分利用运动线索，且运动特征表示在微调阶段因缺乏标注数据而受限。
- Method: 引入TMCCL模型，利用文本描述相似性构建正负运动样本集，提升运动特征表示。
- Result: 在两个视频记忆性预测数据集上取得最优性能，并验证了MWCVS方法在视频摘要任务中的有效性。
- Conclusion: TMCCL和MWCVS展示了视频记忆性预测的潜力，为多模态学习和视频摘要提供了新思路。


### [49] [Beyond Calibration: Physically Informed Learning for Raw-to-Raw Mapping](https://arxiv.org/abs/2506.08650)
*Peter Grönquist,Stepan Tulyakov,Dengxin Dai*

Main category: cs.CV

TL;DR: 论文提出了一种轻量级的神经物理模型（NPM），用于解决多相机间颜色一致性问题，适应性强且计算成本低。

- Motivation: 多相机系统中颜色一致性问题因传感器和光学差异而复杂，现有方法适应性差或计算成本高。
- Method: NPM通过模拟特定光照下的原始图像，估计设备间的转换，支持物理测量初始化和无配对数据训练。
- Result: 在NUS和BeyondRGB数据集上，NPM表现优于现有方法，实现了跨传感器的稳健颜色一致性。
- Conclusion: NPM是一种高效、适应性强的解决方案，适用于多相机系统的颜色一致性需求。


### [50] [LLaVA-c: Continual Improved Visual Instruction Tuning](https://arxiv.org/abs/2506.08666)
*Wenzhuo Liu,Fei Zhu,Haiyang Guo,Longhui Wei,Cheng-Lin Liu*

Main category: cs.CV

TL;DR: 本文提出了一种改进LLaVA-1.5的方法，通过光谱感知巩固和无监督查询正则化，解决了多任务学习中的任务平衡和基础模型退化问题，实现了持续学习与多任务联合学习相当的效果。

- Motivation: 多任务学习面临任务平衡和扩展成本的挑战，而持续学习虽然能增量获取知识，但当前方法忽视了基础模型的通用能力退化。
- Method: 在LLaVA-1.5基础上引入光谱感知巩固和无监督查询正则化，以优化任务平衡并防止基础模型退化。
- Result: 实验表明，LLaVA-c在标准基准测试中表现优异，同时保持了通用能力，首次证明持续学习可媲美多任务联合学习。
- Conclusion: 该方法简单有效，为持续学习在多模态模型中的应用提供了新思路，代码将公开。


### [51] [ATAS: Any-to-Any Self-Distillation for Enhanced Open-Vocabulary Dense Prediction](https://arxiv.org/abs/2506.08678)
*Juan Yeo,Soonwoo Cha,Jiwoo Song,Hyunbin Jin,Taesup Kim*

Main category: cs.CV

TL;DR: 论文提出了一种名为ATAS的自蒸馏方法，通过同时增强语义一致性和细粒度对齐，改进了CLIP在密集预测任务中的表现。

- Motivation: CLIP在细粒度、区域级理解上表现不佳，影响了其在密集预测任务中的效果。论文旨在解决这一问题。
- Method: 提出Any-to-Any Self-Distillation (ATAS)方法，利用模型的自身知识，通过无标签图像和内部自蒸馏过程优化CLIP视觉编码器的表示。
- Result: 在开放词汇对象检测和语义分割任务中，ATAS显著提升了性能，优于基线CLIP模型。
- Conclusion: ATAS验证了同时保持语义一致性和细粒度对齐的重要性，为开放词汇密集预测提供了有效解决方案。


### [52] [CanadaFireSat: Toward high-resolution wildfire forecasting with multiple modalities](https://arxiv.org/abs/2506.08690)
*Hugo Porta,Emanuele Dalsasso,Jessica L. McCarty,Devis Tuia*

Main category: cs.CV

TL;DR: 加拿大2023年经历了严重的野火季，需高分辨率预测模型。本文提出CanadaFireSat数据集和多模态深度学习方法，显著提升预测性能。

- Motivation: 气候变化导致野火季延长和加剧，需高分辨率预测工具支持减灾。
- Method: 利用Sentinel-2、MODIS和ERA5等多模态数据，结合深度学习模型进行高分辨率（100米）野火预测。
- Result: 多模态输入优于单模态，2023年野火季F1分数达60.3%。
- Conclusion: 多模态深度学习模型在高分辨率和大陆尺度野火预测中具有潜力。


### [53] [VReST: Enhancing Reasoning in Large Vision-Language Models through Tree Search and Self-Reward Mechanism](https://arxiv.org/abs/2506.08691)
*Congzhi Zhang,Jiawei Peng,Zhenglin Wang,Yilong Lai,Haowen Sun,Heng Chang,Fei Ma,Weijiang Yu*

Main category: cs.CV

TL;DR: VReST是一种无需训练的新方法，通过蒙特卡洛树搜索和自奖励机制提升大型视觉语言模型的复杂视觉推理能力。

- Motivation: 大型视觉语言模型在多模态任务中表现优异，但在复杂视觉推理中仍受限，尤其是在链式思维提示技术下。
- Method: VReST通过蒙特卡洛树搜索建立推理树，结合自奖励机制评估推理步骤质量，无需额外模型。
- Result: VReST在三个多模态数学推理基准测试中超越现有方法，达到最优性能。
- Conclusion: VReST验证了多模态任务中测试时间缩放定律的有效性，为未来研究提供了方向。


### [54] [MoSiC: Optimal-Transport Motion Trajectory for Dense Self-Supervised Learning](https://arxiv.org/abs/2506.08694)
*Mohammadreza Salehi,Shashanka Venkataramanan,Ioana Simion,Efstratios Gavves,Cees G. M. Snoek,Yuki M Asano*

Main category: cs.CV

TL;DR: 提出了一种基于运动引导的自监督学习框架，通过聚类密集点轨迹学习时空一致的表示，提升了动态场景中的鲁棒性。

- Motivation: 现有方法依赖静态增强，难以处理物体变形、遮挡和相机运动，导致特征学习不一致。
- Method: 利用现有点追踪器提取长程运动轨迹，通过动量编码器的最优传输机制优化特征聚类，并沿轨迹传播聚类分配以确保时间一致性。
- Result: 在六个图像和视频数据集及四个评估基准上，性能提升1%至6%。
- Conclusion: 通过运动作为隐式监督信号，该方法在动态场景和遮挡情况下表现优异，代码已开源。


### [55] [ArrowPose: Segmentation, Detection, and 5 DoF Pose Estimation Network for Colorless Point Clouds](https://arxiv.org/abs/2506.08699)
*Frederik Hagelskjaer*

Main category: cs.CV

TL;DR: 本文提出了一种针对无色点云的快速检测和5自由度姿态估计网络，通过神经网络预测物体的中心和顶部点来计算姿态。

- Motivation: 无色点云的姿态估计在计算机视觉中具有挑战性，现有方法性能有限，需要更高效的解决方案。
- Method: 使用合成数据训练神经网络，预测物体的中心和顶部点，实现5自由度姿态估计。
- Result: 在基准数据集上表现优于所有无色方法，推理时间仅250毫秒，适用于多种场景。
- Conclusion: 该方法在无色点云姿态估计中实现了最先进的性能，且具有高效性。


### [56] [TraGraph-GS: Trajectory Graph-based Gaussian Splatting for Arbitrary Large-Scale Scene Rendering](https://arxiv.org/abs/2506.08704)
*Xiaohan Zhang,Sitong Wang,Yushen Yan,Yi Yang,Mingda Xu,Qi Liu*

Main category: cs.CV

TL;DR: 论文提出TraGraph-GS方法，通过轨迹图解决大规模场景中高质量新视角合成的挑战，显著提升渲染精度和效率。

- Motivation: 现有方法在大规模场景中因刚性空间分区和区域合并导致高斯重叠问题，无法有效泛化。
- Method: 提出基于图的轨迹分区方法，结合正则化约束和渐进渲染策略，减少高斯重叠和纹理失真。
- Result: 在四个空中和四个地面数据集上表现优异，PSNR平均提升1.86 dB（空中）和1.62 dB（地面）。
- Conclusion: TraGraph-GS通过创新分区和渲染策略，显著提升大规模场景的渲染质量和效率。


### [57] [SceneSplat++: A Large Dataset and Comprehensive Benchmark for Language Gaussian Splatting](https://arxiv.org/abs/2506.08710)
*Mengjiao Ma,Qi Ma,Yue Li,Jiahuan Cheng,Runyi Yang,Bin Ren,Nikola Popovic,Mingqiang Wei,Nicu Sebe,Luc Van Gool,Theo Gevers,Martin R. Oswald,Danda Pani Paudel*

Main category: cs.CV

TL;DR: 论文提出首个大规模3D高斯溅射（3DGS）基准测试，评估三种方法在3D空间的表现，并引入新数据集GaussianWorld-49K。

- Motivation: 现有方法主要在2D视图上评估，缺乏对3D场景整体理解的能力和洞察。
- Method: 提出大规模基准测试，评估1060个场景，涵盖三种方法（优化、优化无关、泛化），并引入49K场景数据集。
- Result: 泛化方法表现最优，能快速推理新场景并实现更好的分割性能。
- Conclusion: 泛化方法在3DGS场景理解中具有优势，数据集和基准将公开以推动研究。


### [58] [Geometric deep learning for local growth prediction on abdominal aortic aneurysm surfaces](https://arxiv.org/abs/2506.08729)
*Dieuwertje Alblas,Patryk Rygiel,Julian Suk,Kaj O. Kappe,Marieke Hofman,Christoph Brune,Kak Khee Yeung,Jelmer M. Wolterink*

Main category: cs.CV

TL;DR: 该论文提出了一种基于SE(3)-对称变换器模型的方法，用于预测腹主动脉瘤（AAA）的生长，以提高个性化监测策略的准确性。

- Motivation: 当前临床指南基于AAA最大直径的监测策略未考虑3D形状与生长的复杂关系，可能导致标准化监测间隔不适用。
- Method: 使用SE(3)-对称变换器模型，直接在血管模型表面预测AAA生长，结合局部多物理特征，保留了血管表面的解剖结构和几何保真度。
- Result: 模型预测AAA生长的中位直径误差为1.18 mm，并能以0.93的准确率识别患者是否在两年内需手术修复。外部验证集结果也显示了模型的泛化能力。
- Conclusion: 通过血管表面的局部定向AAA生长预测是可行的，可为个性化监测策略提供支持。


### [59] [InceptionMamba: An Efficient Hybrid Network with Large Band Convolution and Bottleneck Mamba](https://arxiv.org/abs/2506.08735)
*Yuhang Wang,Jun Li,Zhijian Wu,Jianhua Xu*

Main category: cs.CV

TL;DR: InceptionMamba是一种新型的卷积神经网络架构，通过正交带卷积和Mamba模块解决了InceptionNeXt在空间依赖性和全局上下文建模上的不足，实现了更优的分类和下游任务性能。

- Motivation: InceptionNeXt在图像分类和下游任务中表现优异，但其一维条带卷积限制了空间依赖性的捕捉和局部邻域的空间建模能力，且卷积操作的局部性约束不利于全局上下文建模。
- Method: 提出InceptionMamba架构，用正交带卷积替代传统一维条带卷积以实现更紧密的空间建模，并通过瓶颈Mamba模块实现全局上下文建模，增强跨通道信息融合和扩大感受野。
- Result: 在分类和多种下游任务中，InceptionMamba实现了最先进的性能，同时具有优越的参数和计算效率。
- Conclusion: InceptionMamba通过改进空间建模和全局上下文建模能力，显著提升了性能，是一种高效且竞争力强的架构。


### [60] [RS-MTDF: Multi-Teacher Distillation and Fusion for Remote Sensing Semi-Supervised Semantic Segmentation](https://arxiv.org/abs/2506.08772)
*Jiayi Song,Kaiyu Li,Xiangyong Cao,Deyu Meng*

Main category: cs.CV

TL;DR: 论文提出RS-MTDF框架，利用预训练的视觉基础模型（VFMs）作为多教师，通过特征蒸馏提升半监督遥感图像分割性能。

- Motivation: 遥感图像语义分割依赖大量标注数据，但标注成本高。半监督学习（SSS）可缓解数据依赖，但现有方法难以解决标注与未标注数据间的分布差异。
- Method: RS-MTDF框架采用多个冻结的VFMs（如DINOv2和CLIP）作为教师模型，通过特征级蒸馏和对齐学生特征，增强语义理解。
- Result: 在三个遥感数据集（Potsdam、LoveDA、DeepGlobe）上，RS-MTDF表现最优，尤其在LoveDA上超越现有方法，并在多数类别中取得最高IoU。
- Conclusion: 多教师VFM指导显著提升了遥感分割的泛化能力和语义理解，消融实验验证了各模块的有效性。


### [61] [Gaussian2Scene: 3D Scene Representation Learning via Self-supervised Learning with 3D Gaussian Splatting](https://arxiv.org/abs/2506.08777)
*Keyi Liu,Weidong Yang,Ben Fei,Ying He*

Main category: cs.CV

TL;DR: 论文提出Gaussian2Scene，一种基于3D高斯泼溅（3DGS）的自监督学习框架，用于点云预训练，解决了现有方法依赖隐式表示和高内存需求的问题。

- Motivation: 现有自监督学习方法在场景级别依赖RGB-D图像重建信号，但受限于隐式场景表示和高内存需求，且难以捕捉底层3D几何结构。
- Method: 采用3D高斯泼溅（3DGS）进行预训练，分两阶段：第一阶段通过双分支掩码自编码器学习2D和3D场景表示；第二阶段用重建点云初始化训练，并利用高斯基元的几何位置和渲染RGB图像监督学习。
- Result: 在多个下游3D物体检测任务中，Gaussian2Scene表现优于现有预训练方法。
- Conclusion: Gaussian2Scene通过显式3D重建和高效计算，提升了点云预训练的效果，尤其在几何理解和跨模态学习方面表现突出。


### [62] [Landsat-Bench: Datasets and Benchmarks for Landsat Foundation Models](https://arxiv.org/abs/2506.08780)
*Isaac Corley,Lakshay Sharma,Ruth Crasto*

Main category: cs.CV

TL;DR: Landsat-Bench是一套基于Landsat影像的基准测试，包含EuroSAT-L、BigEarthNet-L和LC100-L，用于评估地理空间基础模型（GFM）。研究发现，基于SSL4EO-L预训练的GFM在性能上优于ImageNet。

- Motivation: Landsat数据缺乏基准测试，限制了基于Landsat的地理空间基础模型的发展。
- Method: 引入Landsat-Bench基准测试套件，评估常见架构和基于SSL4EO-L预训练的GFM。
- Result: SSL4EO-L预训练的GFM在下游任务中表现更优，EuroSAT-L和BigEarthNet-L上的性能分别提升4%和5.1%。
- Conclusion: Landsat-Bench为Landsat数据提供了标准化评估方法，验证了SSL4EO-L预训练GFM的优越性。


### [63] [HomographyAD: Deep Anomaly Detection Using Self Homography Learning](https://arxiv.org/abs/2506.08784)
*Jongyub Seok,Chanjin Kang*

Main category: cs.CV

TL;DR: 提出了一种基于ImageNet预训练网络的新型异常检测方法HomographyAD，针对工业数据集的未对齐问题，通过深度单应性估计和自学习优化性能。

- Motivation: 现有异常检测方法仅适用于完全对齐的数据集，而实际工业环境数据往往未对齐，因此需要一种更适应实际场景的方法。
- Method: 1. 使用深度单应性估计对齐输入前景；2. 通过自学习单应性微调模型；3. 基于测试样本特征与正常特征分布的距离进行异常检测。
- Result: 通过实验验证，该方法显著提升了现有异常检测方法的性能。
- Conclusion: HomographyAD为解决工业环境中未对齐数据的异常检测问题提供了有效方案。


### [64] [A PDE-Based Image Dehazing Method via Atmospheric Scattering Theory](https://arxiv.org/abs/2506.08793)
*Zhuoran Zheng*

Main category: cs.CV

TL;DR: 提出了一种基于偏微分方程（PDE）的单图像去雾方法，结合非局部正则化和暗通道先验，改进了PDE框架，并通过实验验证了其有效性。

- Motivation: 解决单图像去雾问题，通过结合大气散射模型和非局部正则化，提出更高效的PDE框架。
- Method: 改进的PDE框架，包含边缘保持扩散系数、高斯卷积算子和自适应正则化参数，使用Lax-Milgram定理证明解的存在唯一性，并通过PyTorch GPU加速实现。
- Result: 实验结果表明该方法是一种有效的去雾解决方案，并可推广至深度学习模型。
- Conclusion: 提出的PDE框架在单图像去雾中表现出色，具有通用性和高效性。


### [65] [Flow Diverse and Efficient: Learning Momentum Flow Matching via Stochastic Velocity Field Sampling](https://arxiv.org/abs/2506.08796)
*Zhiyuan Ma,Ruixun Liu,Sixian Liu,Jianjun Li,Bowen Zhou*

Main category: cs.CV

TL;DR: Discretized-RF是一种新的整流流（RF）模型，通过将直线路径离散化为多个可变速度子路径（动量场），提高了多样性和多尺度噪声建模能力。

- Motivation: 传统的直线路径整流流模型存在多样性受限和多尺度噪声建模不足的问题。
- Method: 提出Discretized-RF，通过在子路径的动量场中引入噪声，改变速度方向，扩展搜索空间。
- Result: 实验表明，该方法能生成多样且高效的轨迹，并产生高质量和多样化的结果。
- Conclusion: Discretized-RF在多样性和噪声建模方面优于传统整流流模型。


### [66] [HunyuanVideo-HOMA: Generic Human-Object Interaction in Multimodal Driven Human Animation](https://arxiv.org/abs/2506.08797)
*Ziyao Huang,Zixiang Zhou,Juan Cao,Yifeng Ma,Yi Chen,Zejing Rao,Zhiyong Xu,Hongmei Wang,Qin Lin,Yuan Zhou,Qinglin Lu,Fan Tang*

Main category: cs.CV

TL;DR: HunyuanVideo-HOMA是一个弱条件多模态驱动框架，用于提升人-物交互视频生成的泛化性和可控性。

- Motivation: 解决人-物交互视频生成中对精选运动数据的依赖、对新对象/场景泛化能力有限以及可访问性受限的问题。
- Method: 通过稀疏解耦的运动引导，将外观和运动信号编码到多模态扩散变换器（MMDiT）的双输入空间中，并在共享上下文空间中融合以生成时间一致且物理合理的交互。
- Result: 在弱监督下实现了交互自然性和泛化性的最先进性能，并在文本条件生成和交互式对象操作中表现出多功能性。
- Conclusion: HunyuanVideo-HOMA通过创新的框架和适配器设计，显著提升了人-物交互视频生成的质量和灵活性。


### [67] [HiSin: Efficient High-Resolution Sinogram Inpainting via Resolution-Guided Progressive Inference](https://arxiv.org/abs/2506.08809)
*Jiaze E,Srutarshi Banerjee,Tekin Bicer,Guannan Wang,Yanfu Zhang,Bin Ren*

Main category: cs.CV

TL;DR: HiSin是一种基于扩散模型的高效正弦图修复框架，通过分辨率引导的渐进推理减少内存和计算需求。

- Motivation: 高分辨率正弦图修复对CT重建至关重要，但现有扩散模型因高内存和计算需求难以应用。
- Method: HiSin采用分辨率引导的渐进推理，先在低分辨率提取全局结构，再在高分辨率处理小补丁，并结合频率感知补丁跳过和结构自适应步长分配。
- Result: 实验显示HiSin降低峰值内存使用31.25%，推理时间18.15%，且修复精度不受影响。
- Conclusion: HiSin为高分辨率正弦图修复提供了一种高效且准确的方法。


### [68] [Video-CoT: A Comprehensive Dataset for Spatiotemporal Understanding of Videos Based on Chain-of-Thought](https://arxiv.org/abs/2506.08817)
*Shuyi Zhang,Xiaoshuai Hao,Yingbo Tang,Lingfeng Zhang,Pengwei Wang,Zhongyuan Wang,Hongxuan Ma,Shanghang Zhang*

Main category: cs.CV

TL;DR: Video-CoT是一个新数据集，用于提升视频内容理解的时空细节分析能力，包含大量标注样本和评估基准。

- Motivation: 现有的大规模视觉语言模型在视频分析中难以捕捉时空细节，需要更精细的数据集和方法。
- Method: 引入Video-CoT数据集，包含192,000个时空问答对和23,000个CoT标注样本，并提供评估基准。
- Result: 实验显示当前模型在时空理解任务上表现不佳，凸显了任务的挑战性。
- Conclusion: Video-CoT为多媒体理解研究开辟了新方向，支持未来智能系统的视频分析需求。


### [69] [CulturalFrames: Assessing Cultural Expectation Alignment in Text-to-Image Models and Evaluation Metrics](https://arxiv.org/abs/2506.08835)
*Shravan Nayak,Mehar Bhatia,Xiaofeng Zhang,Verena Rieser,Lisa Anne Hendricks,Sjoerd van Steenkiste,Yash Goyal,Karolina Stańczak,Aishwarya Agrawal*

Main category: cs.CV

TL;DR: 研究首次系统量化了文本到图像（T2I）模型在文化和显隐期望上的表现，发现模型在文化和显隐期望上的失败率分别为44%和68%，现有评估指标与人类判断相关性低。

- Motivation: 探讨T2I模型在多样化文化背景下的表现，揭示其在文化和显隐期望上的不足。
- Method: 引入CulturalFrames基准，涵盖10个国家、5个社会文化领域，包含983个提示、3637张图像和10k+人工标注。
- Result: T2I模型在文化和显隐期望上的失败率分别为44%和68%，现有评估指标与人类判断相关性低。
- Conclusion: 研究揭示了T2I模型在文化表现上的关键差距，为开发更具文化意识的模型和评估方法提供了方向。


### [70] [Adapting Vision-Language Foundation Model for Next Generation Medical Ultrasound Image Analysis](https://arxiv.org/abs/2506.08849)
*Jingguo Qu,Xinyang Han,Tonghuan Xiao,Jia Ai,Juan Wu,Tong Zhao,Jing Qin,Ann Dorothy King,Winnie Chiu-Wing Chu,Jing Cai,Michael Tin-Cheung Yingınst*

Main category: cs.CV

TL;DR: 该研究通过领域适应方法优化视觉-语言基础模型，提升超声图像分析的性能，在分割和分类任务中表现优于现有方法。

- Motivation: 超声图像手动标注耗时且存在不一致性，视觉-语言基础模型在医学影像领域表现受限，需克服领域差异。
- Method: 利用大语言模型作为文本优化器，结合特殊设计的适应策略和任务驱动头，对视觉-语言基础模型进行微调。
- Result: 在六个超声数据集和两项任务中，方法显著提升了性能，优于现有视觉-语言和纯基础模型。
- Conclusion: 该方法为超声图像分析提供了高效解决方案，代码已开源。


### [71] [Spatial Transcriptomics Expression Prediction from Histopathology Based on Cross-Modal Mask Reconstruction and Contrastive Learning](https://arxiv.org/abs/2506.08854)
*Junzhuo Liu,Markus Eckstein,Zhixiang Wang,Friedrich Feuerhake,Dorit Merhof*

Main category: cs.CV

TL;DR: 本文提出了一种基于对比学习的深度学习方法，用于从全切片图像预测空间分辨的基因表达，显著提高了基因表达预测的准确性。

- Motivation: 空间转录组学数据获取成本高，大规模数据难以获得，因此需要一种高效的方法从现有图像数据中预测基因表达。
- Method: 采用对比学习框架的深度学习方法，从全切片图像预测基因表达，并在六个不同疾病数据集上评估。
- Result: 相比现有方法，预测高表达基因、高变异基因和标记基因的Pearson相关系数分别提高了6.27%、6.11%和11.26%。
- Conclusion: 该方法不仅保留了基因间相关性，还适用于样本有限的数据集，并展示了在癌症组织定位中的潜力。


### [72] [StreamSplat: Towards Online Dynamic 3D Reconstruction from Uncalibrated Video Streams](https://arxiv.org/abs/2506.08862)
*Zike Wu,Qi Yan,Xuanyu Yi,Lele Wang,Renjie Liao*

Main category: cs.CV

TL;DR: StreamSplat是一个实时处理未校准视频流并重建动态3D场景的框架，解决了现有方法在实时性、动态建模和长期稳定性上的不足。

- Motivation: 现有方法难以同时处理未校准输入、动态场景建模和长期稳定性，StreamSplat旨在解决这些问题。
- Method: 提出静态编码器中的概率采样机制和动态解码器中的双向变形场，实现高效的动态3D高斯泼溅表示。
- Result: StreamSplat在重建质量和动态场景建模上优于现有方法，支持任意长度视频流的在线重建。
- Conclusion: StreamSplat为动态3D场景重建提供了一种高效、稳定的解决方案。


### [73] [DiscoVLA: Discrepancy Reduction in Vision, Language, and Alignment for Parameter-Efficient Video-Text Retrieval](https://arxiv.org/abs/2506.08887)
*Leqi Shen,Guoqiang Gong,Tianxiang Hao,Tao He,Yifeng Zhang,Pengzhang Liu,Sicheng Zhao,Jungong Han,Guiguang Ding*

Main category: cs.CV

TL;DR: 本文提出DiscoVLA方法，通过同时解决视觉、语言和对齐三个差异，提升CLIP模型在视频-文本检索中的性能。

- Motivation: 现有方法主要关注视觉差异，而忽略了语言和对齐差异，导致视频-文本检索效果受限。
- Method: DiscoVLA通过图像-视频特征融合、伪图像标题生成和图像到视频对齐蒸馏，解决视觉、语言和对齐差异。
- Result: 在MSRVTT数据集上，DiscoVLA以50.5%的R@1得分优于现有方法1.5%。
- Conclusion: DiscoVLA通过全面解决三个差异，显著提升了视频-文本检索性能。


### [74] [Product of Experts for Visual Generation](https://arxiv.org/abs/2506.08894)
*Yunzhi Zhang,Carson Murtuza-Lanier,Zizhang Li,Yilun Du,Jiajun Wu*

Main category: cs.CV

TL;DR: 提出了一种基于专家乘积（PoE）的框架，用于在推理时整合异构模型的知识，通过退火重要性采样（AIS）实现，提升了图像和视频合成的可控性和灵活性。

- Motivation: 现代神经模型具有丰富的先验知识，但如何整合来自不同来源（如生成模型、语言模型、图形引擎等）的异构知识仍未被充分探索。
- Method: 采用专家乘积（PoE）框架，通过退火重要性采样（AIS）从异构模型的乘积分布中采样，实现训练无关的知识整合。
- Result: 在图像和视频合成任务中表现出色，提供了比单一方法更好的可控性，并为用户提供了灵活的生成目标指定接口。
- Conclusion: 该框架为异构知识的整合提供了有效途径，提升了生成任务的灵活性和可控性。


### [75] [WetCat: Automating Skill Assessment in Wetlab Cataract Surgery Videos](https://arxiv.org/abs/2506.08896)
*Negin Ghamsarian,Raphael Sznitman,Klaus Schoeffmann,Jens Kowal*

Main category: cs.CV

TL;DR: WetCat是首个专为自动化技能评估设计的湿实验室白内障手术视频数据集，旨在解决传统手动评估的低效和主观性问题。

- Motivation: 传统湿实验室训练依赖人工评估，效率低且主观性强，计算机视觉技术为自动化评估提供了可能。
- Method: 构建WetCat数据集，包含高分辨率视频、阶段注释和关键结构语义分割，聚焦囊膜撕开和超声乳化阶段。
- Result: WetCat为开发可解释的AI评估工具奠定了基础，支持标准化临床指标。
- Conclusion: WetCat推动了客观、可扩展的手术教育，为眼科培训中的自动化工作流分析和技能评估设立了新标准。


### [76] [MIRAGE: Multimodal foundation model and benchmark for comprehensive retinal OCT image analysis](https://arxiv.org/abs/2506.08900)
*José Morano,Botond Fazekas,Emese Sükei,Ronald Fecso,Taha Emre,Markus Gumpinger,Georg Faustmann,Marzieh Oghbaie,Ursula Schmidt-Erfurth,Hrvoje Bogunović*

Main category: cs.CV

TL;DR: MIRAGE是一种新型多模态基础模型，用于分析OCT和SLO图像，并在分类和分割任务中表现出优越性。

- Motivation: 现有AI模型在眼科图像分析中需要大量标注数据且泛化能力不足，基础模型（FMs）虽有潜力但缺乏验证。
- Method: 提出MIRAGE多模态基础模型，并设计新的评估基准，用于OCT/SLO分类和分割任务。
- Result: MIRAGE在分类和分割任务中优于通用和专用FMs及分割方法。
- Conclusion: MIRAGE适合作为开发稳健眼科AI系统的基础，模型和评估基准已公开。


### [77] [Hyperbolic Dual Feature Augmentation for Open-Environment](https://arxiv.org/abs/2506.08906)
*Peilin Yu,Yuwei Wu,Zhi Gao,Xiaomeng Fan,Shuo Yang,Yunde Jia*

Main category: cs.CV

TL;DR: 提出一种双曲双特征增强方法，用于开放环境中的特征增强，提升双曲算法的泛化能力。

- Motivation: 现有双曲特征增强方法局限于封闭环境，无法处理开放环境中的未见类别。
- Method: 1. 使用神经ODE模块估计特征分布；2. 引入正则化保持层次结构；3. 推导损失上界以支持无限增强。
- Result: 在五种开放环境任务中显著提升双曲算法性能。
- Conclusion: 该方法有效解决了开放环境中的特征增强问题。


### [78] [SkipVAR: Accelerating Visual Autoregressive Modeling via Adaptive Frequency-Aware Skipping](https://arxiv.org/abs/2506.08908)
*Jiajun Li,Yue Ma,Xinyu Zhang,Qingyan Wei,Songhua Liu,Linfeng Zhang*

Main category: cs.CV

TL;DR: 论文提出SkipVAR框架，通过动态跳过冗余步骤和替换无条件分支，显著加速视觉自回归模型的推理过程。

- Motivation: 现有视觉自回归模型在高频生成步骤中存在计算冗余，导致推理延迟高，但尚未被深入研究。
- Method: 提出自动步骤跳过策略和无条件分支替换技术，并基于频率信息动态选择加速策略。
- Result: SkipVAR在保持模型质量的同时，实现最高1.81倍整体加速和2.62倍GenEval基准速度提升。
- Conclusion: 频率感知的自适应加速方法有效提升了自回归图像生成的可扩展性。


### [79] [Inherently Faithful Attention Maps for Vision Transformers](https://arxiv.org/abs/2506.08915)
*Ananthu Aniraj,Cassio F. Dantas,Dino Ienco,Diego Marcos*

Main category: cs.CV

TL;DR: 提出一种基于注意力的两阶段方法，通过二进制注意力掩码限制预测仅受关注区域影响，提高对虚假相关性和分布外背景的鲁棒性。

- Motivation: 解决上下文对物体感知的强烈影响，避免因分布外背景导致的偏差表示，同时满足需要上下文的物体中心任务。
- Method: 两阶段框架：第一阶段处理完整图像以发现物体部分和任务相关区域；第二阶段利用注意力掩码限制感受野，进行聚焦分析。
- Result: 在多样化基准测试中显著提升对虚假相关性和分布外背景的鲁棒性。
- Conclusion: 提出的方法通过联合训练两阶段框架，有效过滤虚假信息并提升任务性能。


### [80] [Socratic-MCTS: Test-Time Visual Reasoning by Asking the Right Questions](https://arxiv.org/abs/2506.08927)
*David Acuna,Ximing Lu,Jaehun Jung,Hyunwoo Kim,Amlan Kar,Sanja Fidler,Yejin Choi*

Main category: cs.CV

TL;DR: 论文探讨了如何通过蒙特卡洛树搜索（MCTS）算法在非推理视觉语言模型（VLMs）中诱导长推理链，无需额外训练或监督。

- Motivation: 研究动机是探索是否可以通过搜索机制在已部署的非推理模型中激发隐藏知识和长推理链，避免废弃现有模型。
- Method: 采用蒙特卡洛树搜索（MCTS）算法，通过注入子问题-子答案对，将推理视为搜索过程。
- Result: 在三个基准测试中表现一致提升，MMMU-PRO上总体提升2%，其中文科领域显著提升9%。
- Conclusion: 研究表明，通过搜索机制可以在非推理模型中实现长推理链，为现有模型的再利用提供了可能性。


### [81] [What Limits Virtual Agent Application? OmniBench: A Scalable Multi-Dimensional Benchmark for Essential Virtual Agent Capabilities](https://arxiv.org/abs/2506.08933)
*Wendong Bu,Yang Wu,Qifan Yu,Minghe Gao,Bingchen Miao,Zhenkui Zhang,Kaihang Pan,Yunfei Li,Mengze Li,Wei Ji,Juncheng Li,Siliang Tang,Yueting Zhuang*

Main category: cs.CV

TL;DR: OmniBench是一个自生成、跨平台的图基准，通过子任务组合控制任务复杂度，OmniEval是多维评估框架，评估虚拟代理的10种能力。数据集包含36k任务，人工接受率91%。

- Motivation: 现有基准存在任务复杂度不可控、人工标注有限、缺乏多维评估的问题，需要更高效的评估方法。
- Method: 提出OmniBench（图基准）和OmniEval（评估框架），通过自动化管道合成任务，评估虚拟代理的多维能力。
- Result: 数据集包含36k任务，人工接受率91%，训练效率高于人工标注数据。开源和闭源模型在多维评估中表现各异。
- Conclusion: OmniBench和OmniEval为虚拟代理的多维评估提供了高效工具，推动了未来研究。


### [82] [SSS: Semi-Supervised SAM-2 with Efficient Prompting for Medical Imaging Segmentation](https://arxiv.org/abs/2506.08949)
*Hongjie Zhu,Xiwei Liu,Rundong Xue,Zeyu Zhang,Yong Xu,Daji Ergu,Ying Cai,Yang Zhao*

Main category: cs.CV

TL;DR: 论文提出了一种基于SAM-2的半监督学习方法SSS，通过增强特征差异和多尺度数据增强，显著提升了医学图像分割性能。

- Motivation: 在医学影像领域，减少对高质量标注数据的依赖并有效利用大规模未标注数据是一个关键挑战。半监督学习（SSL）通过知识迁移提升模型性能，成为重要研究方向。
- Method: 结合SAM-2的特征提取能力，提出SSS方法，引入判别性特征增强（DFE）机制和多尺度数据增强策略，并开发了提示生成器以满足SAM-2的输入需求。
- Result: 在ACDC和BHSD数据集上的实验表明，SSS在BHSD上的平均Dice分数达到53.15，比现有最优方法提升了3.65。
- Conclusion: SSS通过利用SAM-2的先验知识和多尺度特征优化，显著提升了半监督医学图像分割的性能，为未来研究提供了新思路。


### [83] [Cross-Spectral Body Recognition with Side Information Embedding: Benchmarks on LLCM and Analyzing Range-Induced Occlusions on IJB-MDF](https://arxiv.org/abs/2506.08953)
*Anirudh Nanduri,Siyuan Huang,Rama Chellappa*

Main category: cs.CV

TL;DR: 本文研究了如何将预训练的ViT模型应用于跨光谱人体识别任务，通过引入Side Information Embedding（SIE）提升性能，并探讨了遮挡问题在可见-红外（VI）Re-ID中的影响。

- Motivation: 跨光谱人体识别（如可见光和红外图像匹配）是一个具有挑战性的任务，现有方法在遮挡处理方面研究不足。本文旨在探索ViT模型在此任务中的潜力，并填补遮挡研究的空白。
- Method: 采用预训练的ViT模型，引入Side Information Embedding（SIE）编码相机信息，并在LLCM数据集上验证性能。同时，使用IJB-MDF数据集分析跨距离、跨光谱的遮挡影响。
- Result: 实验表明，仅编码相机信息（不显式包含域信息）即可在LLCM数据集上实现最先进的性能。遮挡分析揭示了VI-Re-ID中遮挡问题的复杂性。
- Conclusion: ViT模型在跨光谱人体识别中表现优异，相机信息的编码是关键。遮挡问题在VI-Re-ID中需进一步研究，IJB-MDF数据集为此提供了新的评估基准。


### [84] [Segment Concealed Objects with Incomplete Supervision](https://arxiv.org/abs/2506.08955)
*Chunming He,Kai Li,Yachao Zhang,Ziyun Yang,Youwei Pang,Longxiang Tang,Chengyu Fang,Yulun Zhang,Linghe Kong,Xiu Li,Sina Farsiu*

Main category: cs.CV

TL;DR: 论文提出了一种统一方法SEE，用于不完全监督的隐蔽物体分割（ISCOS），通过伪标签生成和特征分组模块解决标注不足和物体隐蔽性问题。

- Motivation: 隐蔽物体分割任务面临标注数据不足和物体与背景相似性高的挑战，需要一种能够有效利用不完全标注数据的方法。
- Method: 提出SEE框架，结合Segment Anything Model生成伪标签，并设计伪标签生成、存储和监督策略，以及混合粒度特征分组模块。
- Result: 实验表明，SEE在多个ISCOS任务中达到最先进性能，并能作为即插即用方案提升现有模型。
- Conclusion: SEE通过伪标签和特征分组有效解决了ISCOS任务中的关键问题，具有广泛适用性。


### [85] [Data Augmentation For Small Object using Fast AutoAugment](https://arxiv.org/abs/2506.08956)
*DaeEun Yoon,Semin Kim,SangWook Yoo,Jongha Lee*

Main category: cs.CV

TL;DR: 提出了一种基于Fast AutoAugment的数据增强方法，显著提升了小目标检测性能。

- Motivation: 小目标检测性能显著低于大目标，是计算机视觉中的重要挑战。
- Method: 使用Fast AutoAugment快速找到最优数据增强策略。
- Result: 在DOTA数据集上实现了20%的性能提升。
- Conclusion: 该方法有效解决了小目标检测性能下降的问题。


### [86] [ORIDa: Object-centric Real-world Image Composition Dataset](https://arxiv.org/abs/2506.08964)
*Jinwoo Kim,Sangmin Han,Jinho Jeong,Jiwoo Choi,Dongyoung Kim,Seon Joo Kim*

Main category: cs.CV

TL;DR: ORIDa是一个大规模的真实世界图像合成数据集，包含30,000多张图像和200个独特对象，支持多样化的场景和位置。

- Motivation: 现有数据集缺乏多样性和规模，无法全面探索真实世界场景，因此需要ORIDa填补这一空白。
- Method: ORIDa提供两种数据类型：事实-反事实集（每组5张图像）和事实场景（单张图像），涵盖多样化的环境和对象位置。
- Result: ORIDa是首个公开的具有如此规模和复杂性的真实世界图像合成数据集。
- Conclusion: ORIDa为对象合成研究的进一步推进提供了宝贵的资源。


### [87] [ADAM: Autonomous Discovery and Annotation Model using LLMs for Context-Aware Annotations](https://arxiv.org/abs/2506.08968)
*Amirreza Rouhi,Solmaz Arezoomandan,Knut Peterson,Joseph T. Woods,David K. Han*

Main category: cs.CV

TL;DR: ADAM是一个无需训练的自优化框架，通过结合语言模型和视觉嵌入实现开放世界中的物体标注。

- Motivation: 解决传统物体检测模型依赖预定义类别、无法识别新物体的问题。
- Method: 利用LLM生成候选标签，结合CLIP视觉嵌入构建ELR，通过频率投票和跨模态重排序分配标签，并通过自优化循环提升一致性。
- Result: 在COCO和PASCAL数据集上，ADAM无需微调即可有效标注新类别。
- Conclusion: ADAM为开放世界物体标注提供了一种无需监督的高效解决方案。


### [88] [Rethinking Range-View LiDAR Segmentation in Adverse Weather](https://arxiv.org/abs/2506.08979)
*Longyu Yang,Ping Hu,Lu Zhang,Jun Liu,Yap-Peng Tan,Heng Tao Shen,Xiaofeng Zhu*

Main category: cs.CV

TL;DR: 本文提出了一种轻量级模块化框架，通过改进LiDAR分割网络的初始模块，提升其在恶劣天气下的泛化性能。

- Motivation: 现有基于范围视图的LiDAR分割方法在恶劣天气下的泛化性能不足，限制了其实际应用。
- Method: 提出了一种双分支框架，分别处理几何属性和反射强度，并引入GAS和RDC模块抑制噪声和校准失真。
- Result: 实验表明，该方法显著提升了模型在恶劣天气下的性能，且推理开销极小。
- Conclusion: 该框架为实际应用中的LiDAR分割提供了一种高效且鲁棒的解决方案。


### [89] [Efficient Medical Vision-Language Alignment Through Adapting Masked Vision Models](https://arxiv.org/abs/2506.08990)
*Chenyu Lian,Hong-Yu Zhou,Dongyun Liang,Jing Qin,Liansheng Wang*

Main category: cs.CV

TL;DR: ALTA是一种高效的医学视觉-语言对齐方法，通过适应预训练的视觉模型，显著提升了检索和零样本分类任务的性能。

- Motivation: 传统跨模态对比学习方法在视觉表示能力上表现不佳，而多模态掩码建模方法虽视觉表示能力强，但跨模态匹配效果差。ALTA旨在解决这一矛盾。
- Method: ALTA通过适应预训练的视觉模型（来自掩码记录建模），结合时间多视图放射影像输入，提升视觉-语言对齐效果。
- Result: ALTA在文本到图像和图像到文本检索任务中分别超过最佳对比方法4%和6%的绝对准确率。
- Conclusion: ALTA不仅高效，还提升了视觉和语言理解能力，代码已开源。


### [90] [Do Concept Replacement Techniques Really Erase Unacceptable Concepts?](https://arxiv.org/abs/2506.08991)
*Anudeep Das,Gurjot Singh,Prach Chantasantitam,N. Asokan*

Main category: cs.CV

TL;DR: 本文探讨了生成模型中概念替换技术（CRTs）的局限性，特别是在图像到图像（I2I）场景中的失效问题，并提出了一种新的技术AntiMirror以同时实现有效性和保真度。

- Motivation: 生成模型（如扩散模型）在文本到图像（T2I）任务中表现出色，但在避免生成不可接受内容（如冒犯性或版权内容）方面仍面临挑战。CRTs试图解决这一问题，但在I2I场景中效果不佳，亟需研究其失效原因。
- Method: 作者首先通过I2I模型实证了现有CRTs的局限性，随后提出了一种新的目标图像编辑技术AntiMirror，旨在在替换不可接受概念的同时保持输入的其他概念（保真度）。
- Result: 实验表明，现有CRTs在I2I场景中无法有效擦除不可接受概念，而AntiMirror技术能够同时实现有效替换和高保真度。
- Conclusion: 本文揭示了CRTs在T2I和I2I场景中的性能差异，并提出了AntiMirror技术作为解决方案，强调了保真度在概念替换中的重要性。


### [91] [SDTagNet: Leveraging Text-Annotated Navigation Maps for Online HD Map Construction](https://arxiv.org/abs/2506.08997)
*Fabian Immel,Jan-Hendrik Pauls,Richard Fehler,Frank Bieder,Jonas Merkert,Christoph Stiller*

Main category: cs.CV

TL;DR: SDTagNet利用广泛可用的SD地图（如OpenStreetMap）提升远距离检测精度，通过引入语义信息和点级编码器，显著提高了地图感知性能。

- Motivation: 高维护成本的HD地图限制了自动驾驶车辆的规模化部署，而在线HD地图构建方法受限于车载传感器的短感知范围。利用SD地图作为先验信息可以解决这一问题。
- Method: SDTagNet通过引入SD地图的语义信息（如文本注释）和点级编码器，结合NLP特征，统一集成各类地图元素。
- Result: 在Argoverse 2和nuScenes数据集上，SDTagNet比无先验地图构建方法提升了45%（+5.9 mAP），比已有SD地图先验方法提升了20%（+3.2 mAP）。
- Conclusion: SDTagNet通过充分利用SD地图信息，显著提升了在线HD地图构建的性能，为自动驾驶提供了更高效的解决方案。


### [92] [Do MIL Models Transfer?](https://arxiv.org/abs/2506.09022)
*Daniel Shao,Richard J. Chen,Andrew H. Song,Joel Runevic,Ming Y. Lu,Tong Ding,Faisal Mahmood*

Main category: cs.CV

TL;DR: 本文研究了多实例学习（MIL）模型在计算病理学中的迁移学习能力，发现预训练MIL模型在不同器官和任务上表现优于从头训练的模型，且泛化能力强。

- Motivation: 探索MIL模型在计算病理学中的迁移学习潜力，解决小规模弱监督数据集的问题。
- Method: 系统评估了11个预训练MIL模型在21个预训练任务上的表现，用于形态学和分子亚型预测。
- Result: 预训练MIL模型在不同器官和目标任务上表现优于从头训练模型，且泛化能力强。
- Conclusion: MIL模型具有强大的适应能力，迁移学习可显著提升计算病理学任务性能。


### [93] [DIsoN: Decentralized Isolation Networks for Out-of-Distribution Detection in Medical Imaging](https://arxiv.org/abs/2506.09024)
*Felix Wagner,Pramit Saha,Harry Anthony,J. Alison Noble,Konstantinos Kamnitsas*

Main category: cs.CV

TL;DR: 论文提出了一种名为DIsoN的去中心化OOD检测框架，解决了训练数据无法共享时的OOD检测问题，并在医学影像数据上验证了其有效性。

- Motivation: 在安全关键领域（如医学影像）部署ML模型时，需要检测训练数据中未见的输入（OOD），但现有方法要么丢弃训练数据，要么假设测试数据与训练数据集中存储，这在现实中难以实现。
- Method: 提出了Isolation Network框架，通过解决二元分类任务量化测试样本与训练数据的分离难度，并进一步扩展为DIsoN，支持在数据无法共享时通过交换模型参数进行比较。
- Result: 在四个医学影像数据集上的12个OOD检测任务中，DIsoN表现优于现有方法，同时保护了数据隐私。
- Conclusion: DIsoN为ML开发者提供了一种新的服务模式，即远程、安全地利用训练数据进行OOD检测。


### [94] [Diffuse and Disperse: Image Generation with Representation Regularization](https://arxiv.org/abs/2506.09027)
*Runqian Wang,Kaiming He*

Main category: cs.CV

TL;DR: 提出了一种名为Dispersive Loss的简单正则化方法，用于改进扩散生成模型，无需额外数据或预训练。

- Motivation: 扩散生成模型通常缺乏显式正则化，且与表示学习进展独立发展。本文旨在通过引入正则化方法弥合这一差距。
- Method: 提出Dispersive Loss，鼓励隐藏空间中的表示分散，类似于对比自监督学习，但无需正样本对。
- Result: 在ImageNet数据集上测试，Dispersive Loss在多种模型中均表现优于基线方法。
- Conclusion: Dispersive Loss为生成模型与表示学习的结合提供了简单有效的解决方案。


### [95] [Princeton365: A Diverse Dataset with Accurate Camera Pose](https://arxiv.org/abs/2506.09035)
*Karhan Kayan,Stamatis Alexandropoulos,Rishabh Jain,Yiming Zuo,Erich Liang,Jia Deng*

Main category: cs.CV

TL;DR: Princeton365是一个大规模多样化的数据集，包含365个带精确相机姿态的视频，填补了当前SLAM基准在精度和数据多样性之间的空白。

- Motivation: 解决现有SLAM基准在数据多样性和精度上的不足，并提供更全面的评估指标。
- Method: 通过校准板和360相机收集室内、室外和物体扫描视频，并提出基于光流的场景尺度感知评估指标。
- Result: 数据集包含同步的单目、立体RGB视频和IMU数据，并提出了新的评估指标和挑战性新视角合成基准。
- Conclusion: Princeton365为SLAM研究提供了更全面的数据和评估工具，有助于分析方法的失败模式。


### [96] [Autoregressive Semantic Visual Reconstruction Helps VLMs Understand Better](https://arxiv.org/abs/2506.09040)
*Dianyi Wang,Wei Song,Yikun Wang,Siyuan Wang,Kaicheng Yu,Zhongyu Wei,Jiaqi Wang*

Main category: cs.CV

TL;DR: 论文提出ASVR方法，通过联合学习视觉和文本模态，提升多模态理解能力，显著优于现有方法。

- Motivation: 现有大型视觉语言模型仅关注文本序列，未充分利用视觉模态，导致视觉细节丢失和模态对齐不足。
- Method: 提出ASVR，在统一自回归框架中联合学习视觉和文本模态，通过语义重建而非原始视觉重建提升理解。
- Result: ASVR在多种多模态基准测试中表现优异，LLaVA-1.5平均提升5%。
- Conclusion: ASVR通过语义视觉重建有效提升多模态理解，且适用于不同数据规模和模型。


### [97] [Cosmos-Drive-Dreams: Scalable Synthetic Driving Data Generation with World Foundation Models](https://arxiv.org/abs/2506.09042)
*Xuanchi Ren,Yifan Lu,Tianshi Cao,Ruiyuan Gao,Shengyu Huang,Amirmojtaba Sabour,Tianchang Shen,Tobias Pfaff,Jay Zhangjie Wu,Runjian Chen,Seung Wook Kim,Jun Gao,Laura Leal-Taixe,Mike Chen,Sanja Fidler,Huan Ling*

Main category: cs.CV

TL;DR: 该论文介绍了Cosmos-Drive-Dreams，一种用于生成高保真、多视角且时空一致的驾驶场景的合成数据生成（SDG）管道，旨在解决自动驾驶系统中数据收集和标注的高成本问题，尤其是罕见边缘案例的获取。

- Motivation: 为自动驾驶系统（AV）收集和标注真实数据成本高且耗时，尤其是罕见边缘案例的获取困难，而这些案例对训练和测试至关重要。
- Method: 提出了Cosmos-Drive-Dreams管道，基于NVIDIA Cosmos世界基础模型，生成可控、高保真、多视角且时空一致的驾驶视频。
- Result: 实验表明，生成的数据有助于缓解长尾分布问题，并提升下游任务（如3D车道检测、3D目标检测和驾驶策略学习）的泛化能力。
- Conclusion: 该研究通过开源工具包、数据集和模型权重，为自动驾驶领域提供了高效的数据生成解决方案。


### [98] [MagCache: Fast Video Generation with Magnitude-Aware Cache](https://arxiv.org/abs/2506.09045)
*Zehong Ma,Longhui Wei,Feng Wang,Shiliang Zhang,Qi Tian*

Main category: cs.CV

TL;DR: 论文提出了一种基于统一幅度规律的视频扩散模型加速方法MagCache，通过自适应跳过不重要时间步和缓存策略，显著提升速度并保持视觉质量。

- Motivation: 现有视频扩散模型加速技术依赖统一启发式方法或时间嵌入变体，容易因提示特定过拟合导致输出不一致，且需要大量校准样本。
- Method: 发现不同模型和提示下残差输出幅度比单调递减的统一规律，提出MagCache，利用误差建模机制和自适应缓存策略跳过不重要时间步。
- Result: MagCache在Open-Sora和Wan 2.1上分别实现2.1倍和2.68倍加速，且在LPIPS、SSIM和PSNR指标上显著优于现有方法。
- Conclusion: MagCache是一种高效且鲁棒的加速方法，仅需单一样本校准，显著提升视频扩散模型的性能和效率。
## cs.AI

### [99] [FEDTAIL: Federated Long-Tailed Domain Generalization with Sharpness-Guided Gradient Matching](https://arxiv.org/abs/2506.08518)
*Sunny Gupta,Nikita Jangid,Shounak Das,Amit Sethi*

Main category: cs.AI

TL;DR: FedTAIL是一个联邦领域泛化框架，通过锐度引导的梯度对齐优化解决长尾分布和优化冲突问题，在领域泛化基准测试中表现优异。

- Motivation: 解决领域泛化中长尾类分布和优化目标冲突的问题。
- Method: 引入梯度一致性正则化、类感知锐度最小化和曲率感知动态加权方案，结合锐度感知扰动增强条件分布对齐。
- Result: 在领域泛化基准测试中达到最先进性能，尤其在领域偏移和标签不平衡情况下表现突出。
- Conclusion: FedTAIL在集中式和联邦设置下均有效，验证了其优化协调、类感知正则化和条件对齐的统一框架的优越性。


### [100] [VIKI-R: Coordinating Embodied Multi-Agent Cooperation via Reinforcement Learning](https://arxiv.org/abs/2506.09049)
*Li Kang,Xiufeng Song,Heng Zhou,Yiran Qin,Jie Yang,Xiaohong Liu,Philip Torr,Lei Bai,Zhenfei Yin*

Main category: cs.AI

TL;DR: VIKI-Bench是一个专为多智能体合作设计的层次化基准测试，包含三个结构化层级：智能体激活、任务规划和轨迹感知。VIKI-R是一个两阶段框架，结合了视觉语言模型和强化学习，显著优于基线方法。

- Motivation: 解决多智能体在动态环境中的协调问题，尤其是视觉驱动的合作策略的局限性。
- Method: 提出了VIKI-Bench基准测试和VIKI-R框架，后者通过微调预训练的视觉语言模型并结合强化学习来优化多智能体合作。
- Result: VIKI-R在所有任务层级上显著优于基线方法，并展示了异构智能体之间的组合合作模式。
- Conclusion: VIKI-Bench和VIKI-R为视觉驱动的多智能体合作提供了统一的测试平台和方法，推动了具身AI系统的发展。
## math.NA

### [101] [Normalized Radon Cumulative Distribution Transforms for Invariance and Robustness in Optimal Transport Based Image Classification](https://arxiv.org/abs/2506.08761)
*Matthias Beckmann,Robert Beinert,Jonas Bresch*

Main category: math.NA

TL;DR: 本文研究了max-normalized R-CDT在非仿射图像变形下的鲁棒性，并提出了mean-normalized R-CDT以应对更广泛的变形和噪声。

- Motivation: 解决在一般仿射变换下图像分类的线性可分性问题，并进一步研究非仿射变形下的鲁棒性。
- Method: 引入max-normalized R-CDT和mean-normalized R-CDT，分析其在不同距离度量（Wasserstein-infinity和Wasserstein-2）下的稳定性。
- Result: 理论分析和数值实验表明，新特征提取器在非仿射变形和脉冲噪声下具有鲁棒性。
- Conclusion: max-normalized和mean-normalized R-CDT在多种变形和噪声条件下均有效，扩展了R-CDT的应用范围。
## q-bio.BM

### [102] [Aligning Proteins and Language: A Foundation Model for Protein Retrieval](https://arxiv.org/abs/2506.08023)
*Qifeng Wu,Zhengzhe Liu,Han Zhu,Yizhou Zhao,Daisuke Kihara,Min Xu*

Main category: q-bio.BM

TL;DR: 提出了一种基于CLIP框架的多模态模型，用于从大规模蛋白质数据集中检索结构和语义相似的蛋白质，以辅助功能注释。

- Motivation: 利用视觉语言模型（VLMs）的最新进展，解决蛋白质结构与功能注释对齐的问题。
- Method: 采用对比学习框架，构建了一个包含约20万蛋白质-描述对的数据集，并在PDB和EMDB数据集上评估模型。
- Result: 模型在零样本检索任务中表现优异，展示了多模态基础模型在蛋白质生物学中的潜力。
- Conclusion: 该框架为蛋白质结构功能理解提供了新思路，具有广泛的应用前景。
## q-bio.NC

### [103] [Instruction-Tuned Video-Audio Models Elucidate Functional Specialization in the Brain](https://arxiv.org/abs/2506.08277)
*Subba Reddy Oota,Khushbu Pahwa,Prachi Jindal,Satya Sai Srinath Namburi,Maneesh Singh,Tanmoy Chakraborty,Bapi S. Raju,Manish Gupta*

Main category: q-bio.NC

TL;DR: 研究表明，指令调优的多模态大语言模型（MLLMs）在视频和音频任务中显著优于非指令调优模型，并能更精确地预测大脑活动。

- Motivation: 填补现有研究在评估多模态模型与大脑对齐时的空白，尤其是在指令调优模型和多模态刺激下的表现。
- Method: 利用指令调优的MLLMs生成任务特定表示，测量其与自然电影观看时记录的神经活动的预测性。
- Result: 指令调优的MLLMs在视频任务中表现优于非指令调优模型15%，在单模态任务中优于20%，且能分层与大脑对齐。
- Conclusion: 任务特定指令显著提升MLLMs与大脑活动的对齐，为研究大脑信息处理提供了新途径。
## eess.IV

### [104] [A System for Accurate Tracking and Video Recordings of Rodent Eye Movements using Convolutional Neural Networks for Biomedical Image Segmentation](https://arxiv.org/abs/2506.08183)
*Isha Puri,David Cox*

Main category: eess.IV

TL;DR: 提出了一种针对啮齿类动物眼睛图像的高精度、灵活的瞳孔和角膜反射识别模型，解决了现有技术未考虑啮齿类眼睛独特特性的问题。

- Motivation: 啮齿类动物是神经科学和视觉科学研究的常用对象，但现有眼动追踪技术主要针对人类眼睛，未考虑啮齿类眼睛的特殊性（如参数变异、毛发干扰和小尺寸）。
- Method: 开发了一种基于卷积神经网络的高精度生物医学图像分割架构，可增量训练以适应啮齿类眼睛参数的变异性，并结合自动化红外视频眼动记录系统。
- Result: 该方法首次实现了对啮齿类动物眼睛图像中瞳孔和角膜反射的高精度识别，提供了先进的眼动追踪技术。
- Conclusion: 该模型为神经科学和视觉科学研究提供了灵活、鲁棒且高精度的啮齿类眼动追踪解决方案。


### [105] [Snap-and-tune: combining deep learning and test-time optimization for high-fidelity cardiovascular volumetric meshing](https://arxiv.org/abs/2506.08280)
*Daniel H. Pak,Shubh Thaker,Kyle Baylous,Xiaoran Zhang,Danny Bluestein,James S. Duncan*

Main category: eess.IV

TL;DR: 本文提出了一种结合深度学习和测试时优化的“snap-and-tune”策略，用于从医学图像生成高质量体积网格，解决了现有方法在高曲率区域和部件间距上的局限性。

- Motivation: 医学图像的高质量体积网格生成是个性化医疗中物理模拟的关键瓶颈，现有深度学习方法在高曲率区域和部件间距上存在不足。
- Method: 采用“snap-and-tune”策略，先通过深度学习快速拟合初始形状，再通过测试时优化进行样本特定的网格修正。
- Result: 方法显著提高了空间精度和网格质量，且无需额外训练标签，完全自动化。
- Conclusion: 该方法在两种软件平台上验证了其通用性和实用性，代码已开源。


### [106] [Plug-and-Play Linear Attention for Pre-trained Image and Video Restoration Models](https://arxiv.org/abs/2506.08520)
*Srinivasan Kidambi,Pravin Nair*

Main category: eess.IV

TL;DR: PnP-Nystra是一种基于Nyström的线性自注意力近似方法，作为即插即用模块，可在不重新训练的情况下加速预训练模型，显著提升计算效率。

- Motivation: 多头自注意力（MHSA）的二次复杂度在实时和资源受限环境中成为计算瓶颈，需要一种高效的替代方案。
- Method: 提出PnP-Nystra，基于Nyström方法线性近似自注意力，作为即插即用模块集成到预训练模型中。
- Result: 在图像和视频修复任务中，PnP-Nystra在GPU和CPU上分别实现2-4倍和2-5倍加速，PSNR最大下降仅1.5 dB。
- Conclusion: PnP-Nystra首次展示了线性注意力可作为MHSA的无训练替代方案，显著提升效率且性能损失有限。


### [107] [DCD: A Semantic Segmentation Model for Fetal Ultrasound Four-Chamber View](https://arxiv.org/abs/2506.08534)
*Donglian Li,Hui Guo,Minglang Chen,Huizhen Chen,Jialing Chen,Bocheng Liang,Pengchen Liang,Ying Tan*

Main category: eess.IV

TL;DR: 提出了一种基于深度学习的模型DCD，用于自动分割胎儿心尖四腔心切面中的关键解剖结构，以提高分割精度并减少超声医师的工作量。

- Motivation: 胎儿心尖四腔心切面的精确分割对先天性心脏病的早期诊断至关重要，但由于超声伪影、噪声和解剖变异性等问题，分割仍然具有挑战性。
- Method: DCD模型结合了Dense ASPP模块（用于多尺度特征提取）和CBAM模块（用于增强自适应特征表示），以捕获局部和全局上下文信息。
- Result: DCD实现了精确且鲁棒的分割，有助于改善产前心脏评估。
- Conclusion: DCD模型在胎儿心尖四腔心切面的分割任务中表现出色，为先天性心脏病的早期诊断提供了有效工具。


### [108] [Biologically Inspired Deep Learning Approaches for Fetal Ultrasound Image Classification](https://arxiv.org/abs/2506.08623)
*Rinat Prochii,Elizaveta Dakhova,Pavel Birulin,Maxim Sharaev*

Main category: eess.IV

TL;DR: 提出一种生物启发的深度学习集成框架，用于同时分类16种胎儿超声图像结构，性能优于现有方法。

- Motivation: 解决胎儿超声图像分类中图像质量低、类内差异大和类别不平衡的挑战。
- Method: 采用分层模块化设计，结合浅层路径（粗粒度特征）和详细路径（细粒度特征）的深度学习模型。
- Result: 在5298张临床图像上测试，90%的器官分类准确率>0.75，75%的器官>0.85。
- Conclusion: 生物启发的模块化设计在复杂临床环境中表现优异，具有可扩展性。


### [109] [MAMBO: High-Resolution Generative Approach for Mammography Images](https://arxiv.org/abs/2506.08677)
*Milica Škipina,Nikola Jovišić,Nicola Dall'Asen,Vanja Švenda,Anil Osman Tur,Slobodan Ilić,Elisa Ricci,Dubravko Ćulibrk*

Main category: eess.IV

TL;DR: 论文提出了一种名为MAMBO的基于扩散模型的方法，用于生成高分辨率乳腺X光片，以解决AI训练数据不足的问题。

- Motivation: 乳腺X光片是乳腺癌检测的金标准，但AI训练需要大量多样化数据，隐私和伦理问题限制了数据获取。
- Method: MAMBO采用基于补丁的扩散模型，结合局部和全局上下文信息，生成3840x3840像素的高分辨率图像。
- Result: 实验表明，MAMBO能生成高度真实的乳腺X光片，并可用于分类模型训练和异常检测。
- Conclusion: MAMBO有潜力提升乳腺X光分析的准确性，实现更早的病变检测。


### [110] [Enhancing Synthetic CT from CBCT via Multimodal Fusion: A Study on the Impact of CBCT Quality and Alignment](https://arxiv.org/abs/2506.08716)
*Maximilian Tschuchnig,Lukas Lamminger,Philipp Steininger,Michael Gadermayr*

Main category: eess.IV

TL;DR: 通过多模态学习增强CBCT到CT的合成，显著提升低质量CBCT-CT对齐情况下的图像质量。

- Motivation: CBCT虽快速低辐射，但存在伪影和视觉质量低的问题，需通过合成CT（sCT）改善。
- Method: 结合术中CBCT与术前CT进行多模态学习，生成sCT，并在真实和合成数据集上验证。
- Result: 多模态sCT优于单模态基线，尤其在低质量CBCT-CT对齐情况下提升显著。
- Conclusion: 多模态学习方法在临床数据中具有高度可重复性，有效提升sCT质量。
## cs.HC

### [111] [SakugaFlow: A Stagewise Illustration Framework Emulating the Human Drawing Process and Providing Interactive Tutoring for Novice Drawing Skills](https://arxiv.org/abs/2506.08443)
*Kazuki Kawamura,Jun Rekimoto*

Main category: cs.HC

TL;DR: SakugaFlow是一个四阶段流程，结合扩散模型和大型语言模型，为初学者提供实时反馈，支持非线性修改和多版本探索，将黑盒生成器转化为学习工具。

- Motivation: 当前AI绘图工具虽然能生成高质量图像，但缺乏人类艺术家的分步过程，限制了学习与探索。
- Method: 采用四阶段流程，结合扩散模型生成图像和语言模型提供反馈，支持非线性修改和多版本分支。
- Result: SakugaFlow通过展示中间输出和教学对话，支持创意探索和技能学习。
- Conclusion: SakugaFlow成功将黑盒生成器转化为支持学习和创作的工具。


### [112] [MOSAIC-F: A Framework for Enhancing Students' Oral Presentation Skills through Personalized Feedback](https://arxiv.org/abs/2506.08634)
*Alvaro Becerra,Daniel Andres,Pablo Villegas,Roberto Daza,Ruth Cobos*

Main category: cs.HC

TL;DR: MOSAIC-F是一个多模态反馈框架，结合了人类评估和多模态数据分析，为学生提供个性化的学习反馈。

- Motivation: 通过整合多模态数据和人类评估，提供更准确、个性化的学习反馈，以提升学生的学习效果。
- Method: 框架包括四个步骤：标准化评估、多模态数据收集、AI生成反馈、学生自我评估与可视化。
- Result: 在提升口头表达能力的测试中，框架成功生成了个性化且可操作的反馈。
- Conclusion: MOSAIC-F通过结合人类和多模态数据评估，有效提升了反馈的准确性和个性化。
## cs.GR

### [113] [Neural-Augmented Kelvinlet: Real-Time Soft Tissue Deformation with Multiple Graspers](https://arxiv.org/abs/2506.08043)
*Ashkan Shahbazi,Kyvia Pereira,Jon S. Heiselman,Elaheh Akbari,Annie C. Benson,Sepehr Seifi,Xinyuan Liu,Garrison L. Johnston,Erwin Terpstra,Anne Draaisma,Jan-Jaap Severes,Jie Ying Wu,Nabil Simaan,Michael L. Miga,Soheil Kolouri*

Main category: cs.GR

TL;DR: 本文提出了一种基于物理信息的神经模拟器，利用Kelvinlet先验改进软组织变形的实时模拟，结合FEM仿真提升精度和物理一致性，适用于手术机器人及医学训练。

- Motivation: 快速准确的软组织变形模拟对手术机器人和医学训练至关重要，现有方法在实时性和物理一致性上存在不足。
- Method: 提出一种新型物理信息神经模拟器，整合Kelvinlet先验进行残差学习和正则化，结合大规模FEM仿真改进神经网络预测。
- Result: 实验表明，该方法能高保真模拟腹腔镜组织抓取操作，提升模拟精度和实时性能。
- Conclusion: Kelvinlet增强学习是一种高效策略，适用于手术应用中实时、物理感知的软组织模拟。


### [114] [A Real-time 3D Desktop Display](https://arxiv.org/abs/2506.08064)
*Livio Tenze,Enrique Canessa*

Main category: cs.GR

TL;DR: altiro3D C++库的扩展版本，支持从2D图像或视频流实时生成3D光场，利用AI技术提升性能，并新增多平台GUI。

- Motivation: 为玻璃自由的全息显示提供更灵活的3D体验，支持多种输入源（如2D摄像头、视频文件、桌面应用）。
- Method: 使用MiDaS CNN从单张2D图像提取深度图，结合AI技术优化性能，新增多平台GUI简化操作。
- Result: 实现实时3D光场合成，支持多种输入源，可直接输出至光场3D设备（如Looking Glass）。
- Conclusion: 扩展后的altiro3D库功能更强大，适用于更广泛的应用场景。


### [115] [Generalizable Articulated Object Reconstruction from Casually Captured RGBD Videos](https://arxiv.org/abs/2506.08334)
*Weikun Peng,Jun Lv,Cewu Lu,Manolis Savva*

Main category: cs.GR

TL;DR: 论文提出了一种从手持相机拍摄的RGBD视频中重建铰接物体的方法，解决了现有方法需要精心采集数据的问题。

- Motivation: 铰接物体在日常生活中普遍存在，但其运动学结构的理解和重建在AI和机器人领域面临数据采集困难的问题。
- Method: 采用由粗到细的框架，从动态RGBD视频中推断关节参数并分割可移动部件。
- Result: 实验表明，该方法在合成和真实数据集上均显著优于现有方法。
- Conclusion: 该方法为铰接物体的通用化、可扩展重建提供了新思路。


### [116] [Complex-Valued Holographic Radiance Fields](https://arxiv.org/abs/2506.08350)
*Yicheng Zhan,Dong-Ha Shin,Seung-Hwan Baek,Kaan Akşit*

Main category: cs.GR

TL;DR: 提出了一种基于复值高斯基元的3D全息场景表示方法，显著提升了渲染速度。

- Motivation: 为了在3D表示中完整建模光的振幅和相位特性，以支持物理逼真的渲染（尤其是全息显示）。
- Method: 通过RGBD多视角图像直接优化复值高斯基元，避免了基于强度的中间表示。
- Result: 相比现有方法，速度提升30倍至10,000倍，同时保持图像质量。
- Conclusion: 该方法为几何对齐、物理逼真的全息场景表示提供了初步解决方案。


### [117] [Fine-Grained Spatially Varying Material Selection in Images](https://arxiv.org/abs/2506.09023)
*Julia Guerrero-Viu,Michael Fischer,Iliyan Georgiev,Elena Garces,Diego Gutierrez,Belen Masia,Valentin Deschaintre*

Main category: cs.GR

TL;DR: 提出了一种基于ViT的多分辨率处理方法，用于图像中的材质选择，对光照和反射变化具有鲁棒性。

- Motivation: 图像编辑中的选择是第一步，但现有方法对光照和反射变化的鲁棒性不足。
- Method: 利用ViT模型的特征，提出多分辨率处理策略，并在新数据集DuMaS上进行训练。
- Result: 方法在纹理和子纹理级别上实现了更精细和稳定的选择效果。
- Conclusion: 该方法为下游编辑任务提供了更可靠的材质选择工具。
## cs.CL

### [118] [Re-Thinking the Automatic Evaluation of Image-Text Alignment in Text-to-Image Models](https://arxiv.org/abs/2506.08480)
*Huixuan Zhang,Xiaojun Wan*

Main category: cs.CL

TL;DR: 本文指出当前文本到图像生成评估框架的不足，提出改进建议。

- Motivation: 现有评估主要依赖人类判断，忽略了评估框架的其他关键特性。
- Method: 识别可靠评估的两个关键方面，实证主流框架的不足。
- Result: 当前评估框架未能满足关键特性。
- Conclusion: 提出改进图像-文本对齐评估的建议。


### [119] [ClimateViz: A Benchmark for Statistical Reasoning and Fact Verification on Scientific Charts](https://arxiv.org/abs/2506.08700)
*Ruiran Su,Jiasheng Si,Zhijiang Guo,Janet B. Pierrehumbert*

Main category: cs.CL

TL;DR: ClimateViz是首个针对科学图表的大规模事实核查基准，包含49,862个与2,896个可视化图表关联的声明，标注为支持、反驳或信息不足。评估显示当前多模态模型在图表推理上表现不佳，最佳模型准确率仅76.2-77.8%，远低于人类水平（89.3-92.7%）。

- Motivation: 科学事实核查多集中于文本和表格，忽视了科学图表在定量证据和统计推理中的关键作用。
- Method: 引入ClimateViz基准，包含专家标注的科学图表和结构化知识图谱解释，评估多模态语言模型在零样本和少样本设置下的表现。
- Result: 当前模型在图表推理上表现较差，最佳模型准确率远低于人类水平，但解释增强输出对某些模型有提升。
- Conclusion: 科学图表事实核查具有挑战性，需进一步研究提升模型性能，ClimateViz数据集和代码已公开。
## cs.LG

### [120] [Gridding Forced Displacement using Semi-Supervised Learning](https://arxiv.org/abs/2506.08019)
*Andrew Wells,Geraldine Henningsen,Brice Bolane Tchinde Kengne*

Main category: cs.LG

TL;DR: 提出了一种半监督方法，将难民的统计数据从行政边界分解到0.5度网格单元，覆盖25个撒哈拉以南非洲国家。

- Motivation: 解决传统难民统计数据在区域和国家层面过于笼统的问题，揭示局部流离失所模式。
- Method: 结合UNHCR的ProGres注册数据、Google Open Buildings的卫星建筑足迹和OpenStreetMap Populated Places的位置坐标，使用标签传播算法生成高粒度空间统计数据。
- Result: 方法平均准确率达92.9%，成功将1000多万难民观测数据分配到合适的网格单元。
- Conclusion: 高分辨率数据集为深入理解流离失所的驱动因素提供了基础。


### [121] [Bi-level Unbalanced Optimal Transport for Partial Domain Adaptation](https://arxiv.org/abs/2506.08020)
*Zi-Ying Chen,Chuan-Xian Ren,Hong Yan*

Main category: cs.LG

TL;DR: 提出了一种Bi-level Unbalanced Optimal Transport (BUOT)模型，通过样本级和类级传输的合作机制，解决了部分域适应问题中的异常类识别和知识转移问题。

- Motivation: 部分域适应问题需要对齐跨域样本并识别异常类，现有权重框架仅能表征样本级关系，对聚类结构探索不足且权重易受预测不准确影响。
- Method: 提出BUOT模型，统一表征样本级和类级关系，通过合作机制提供结构信息和判别信息，结合标签感知传输成本确保局部传输结构。
- Result: 在基准数据集上的实验验证了BUOT的竞争力。
- Conclusion: BUOT模型有效解决了部分域适应问题中的异常类识别和知识转移问题，具有高效性和竞争力。


### [122] [Modality-Balancing Preference Optimization of Large Multimodal Models by Adversarial Negative Mining](https://arxiv.org/abs/2506.08022)
*Chenxi Liu,Tianyi Xiong,Ruibo Chen,Yihan Wu,Junfeng Guo,Tianyi Zhou,Heng Huang*

Main category: cs.LG

TL;DR: MBPO提出了一种新的偏好学习框架，通过生成硬负样本和在线验证奖励来解决LMM中的模态不平衡问题，提升性能并减少幻觉。

- Motivation: 现有LMM在推理中存在模态不平衡问题，语言先验偏见过度压制视觉输入，导致下游任务泛化能力差和幻觉现象。现有偏好优化方法未有效抑制LLM内部偏置，且依赖离线数据。
- Method: MBPO通过对抗性扰动生成硬负样本构建离线偏好数据集，并利用闭端任务生成在线验证奖励数据，结合GRPO进行训练。
- Result: 实验表明MBPO能显著提升LMM在视觉语言任务中的性能，并有效减少幻觉。
- Conclusion: MBPO通过平衡模态偏好和混合数据训练，为LMM的模态不平衡问题提供了有效解决方案。


### [123] [UniVarFL: Uniformity and Variance Regularized Federated Learning for Heterogeneous Data](https://arxiv.org/abs/2506.08167)
*Sunny Gupta,Nikita Jangid,Amit Sethi*

Main category: cs.LG

TL;DR: UniVarFL是一种新的联邦学习框架，通过两种正则化策略解决非IID数据下的性能下降问题，无需依赖全局模型。

- Motivation: 非IID数据导致联邦学习性能下降，传统方法计算成本高或适应性差。
- Method: UniVarFL采用分类器方差正则化和超球面均匀正则化，模拟IID训练动态。
- Result: 在多个基准数据集上，UniVarFL在准确性上优于现有方法。
- Conclusion: UniVarFL是一种高效、可扩展的解决方案，适用于资源受限的实际部署。


### [124] [An Adaptive Method Stabilizing Activations for Enhanced Generalization](https://arxiv.org/abs/2506.08353)
*Hyunseok Seung,Jaewoo Lee,Hyunsuk Ko*

Main category: cs.LG

TL;DR: AdaAct是一种新颖的优化算法，通过根据激活方差调整学习率，提升神经元输出的稳定性，从而改善泛化能力。

- Motivation: 传统激活正则化方法存在局限性，AdaAct旨在通过神经元级别的适应性提升训练稳定性。
- Method: AdaAct通过调整学习率以适应激活方差，结合了Adam的快速收敛和SGD的强泛化能力。
- Result: 在CIFAR和ImageNet等标准图像分类基准测试中，AdaAct表现出色，性能优于其他先进方法。
- Conclusion: AdaAct成功平衡了Adam的快速收敛和SGD的泛化能力，同时保持高效执行时间。


### [125] [Boosting Gradient Leakage Attacks: Data Reconstruction in Realistic FL Settings](https://arxiv.org/abs/2506.08435)
*Mingyuan Fan,Fuyi Wang,Cen Chen,Jianying Zhou*

Main category: cs.LG

TL;DR: 本文通过实证研究证明，即使在现实的联邦学习环境中，客户端数据仍可能被有效重构，并提出FedLeak方法以解决梯度匹配问题。

- Motivation: 探讨联邦学习中的隐私风险，尤其是梯度泄漏攻击（GLAs）在实际环境中的有效性。
- Method: 提出FedLeak方法，包括部分梯度匹配和梯度正则化两项新技术，并设计了一个基于文献和行业实践的实际评估协议。
- Result: FedLeak在现实联邦学习环境中仍能实现高保真数据重构，揭示了系统的重大漏洞。
- Conclusion: 联邦学习系统存在显著隐私风险，亟需更有效的防御方法。


### [126] [HSG-12M: A Large-Scale Spatial Multigraph Dataset](https://arxiv.org/abs/2506.08618)
*Xianquan Yan,Hakan Akgün,Kenji Kawaguchi,N. Duane Loh,Ching Hua Lee*

Main category: cs.LG

TL;DR: HSG-12M是首个大规模空间多图数据集，包含静态和动态的哈密顿谱图，为几何感知图学习奠定基础。

- Motivation: 现有图基准假设边是非空间且简单的，忽略了物理上不同的路径。HSG-12M旨在保留几何多样性，支持更复杂的图学习任务。
- Method: 通过Poly2Graph管道，将一维晶体哈密顿量映射为谱图，生成11.6M静态和5.1M动态图。
- Result: HSG-12M展示了多边几何在大规模学习中的新挑战，并证明谱图可作为多项式、向量和矩阵的通用拓扑指纹。
- Conclusion: HSG-12M为几何感知图学习和数据驱动的科学发现提供了新机遇。


### [127] [Time Series Representations for Classification Lie Hidden in Pretrained Vision Transformers](https://arxiv.org/abs/2506.08641)
*Simon Roschmann,Quentin Bouniot,Vasilii Feofanov,Ievgen Redko,Zeynep Akata*

Main category: cs.LG

TL;DR: 提出了一种将时间序列转换为图像以利用预训练视觉Transformer（ViT）的框架TiViT，在时间序列分类任务中取得最优性能。

- Motivation: 时间序列分类在医疗和工业中很重要，但公开时间序列数据稀缺限制了时间序列基础模型（TSFM）的发展。
- Method: 将时间序列转换为图像，利用预训练的ViT模型（如OpenCLIP）的隐藏表示进行分类。
- Result: TiViT在标准时间序列分类基准上达到最优性能，并发现中间层高内在维度的表示最有效。
- Conclusion: TiViT展示了视觉表示在非视觉领域的复用潜力，并与TSFM表示空间互补。
## cs.CY

### [128] [Surgeons Awareness, Expectations, and Involvement with Artificial Intelligence: a Survey Pre and Post the GPT Era](https://arxiv.org/abs/2506.08258)
*Lorenzo Arboit,Dennis N. Schneider,Toby Collins,Daniel A. Hashimoto,Silvana Perretta,Bernard Dallemagne,Jacques Marescaux,EAES Working Group,Nicolas Padoy,Pietro Mascagni*

Main category: cs.CY

TL;DR: 研究通过2021和2024年的全球调查，分析了外科医生对AI的认知、期望和参与情况，发现AI课程意识和参与度上升，但基础知识仍有限，伦理问题受关注，基础设施是主要障碍。

- Motivation: 探讨AI在手术中的应用潜力及其对外科医生认知和期望的影响。
- Method: 通过2021和2024年的两次全球性横断面调查，评估外科医生对AI的认知、期望、参与度和伦理问题。
- Result: AI课程意识和参与度显著提升，但基础知识仍不足；伦理问题受重视；基础设施是主要障碍；外科医生对AI持乐观态度。
- Conclusion: AI在外科领域潜力巨大，但需通过教育、伦理框架和基础设施解决知识差距和挑战。
## cs.RO

### [129] [PhyBlock: A Progressive Benchmark for Physical Understanding and Planning via 3D Block Assembly](https://arxiv.org/abs/2506.08708)
*Liang Ma,Jiajun Wen,Min Lin,Rongtao Xu,Xiwen Liang,Bingqian Lin,Jun Ma,Yongxin Wang,Ziming Wei,Haokun Lin,Mingfei Han,Meng Cao,Bokui Chen,Ivan Laptev,Xiaodan Liang*

Main category: cs.RO

TL;DR: PhyBlock是一个用于评估视觉语言模型（VLMs）在物理理解和规划能力上的渐进式基准测试，通过3D积木组装任务和视觉问答（VQA）任务进行测试。

- Motivation: 现有VLMs在理解物理现象和3D环境中的规划能力有限，需要一种新的评估方法来填补这一空白。
- Method: PhyBench包含2600个任务（400个组装任务和2200个VQA任务），评估模型在部分完成、故障诊断和规划鲁棒性三个维度上的表现。
- Result: 测试21个先进VLMs后发现，它们在高级规划和推理能力上表现有限，任务复杂度增加时性能显著下降。
- Conclusion: PhyBlock可作为统一测试平台，推动视觉语言理解与真实世界物理问题解决的结合。
