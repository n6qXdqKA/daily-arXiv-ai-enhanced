[[toc]]

## cs.CV

### [1] [Lumina-mGPT 2.0: Stand-Alone AutoRegressive Image Modeling](https://arxiv.org/abs/2507.17801)
*Yi Xin,Juncheng Yan,Qi Qin,Zhen Li,Dongyang Liu,Shicheng Li,Victor Shea-Jay Huang,Yupeng Zhou,Renrui Zhang,Le Zhuo,Tiancheng Han,Xiaoqing Sun,Siqi Luo,Mengmeng Wang,Bin Fu,Yuewen Cao,Hongsheng Li,Guangtao Zhai,Xiaohong Liu,Yu Qiao,Peng Gao*

Main category: cs.CV

TL;DR: Lumina-mGPT 2.0是一个独立的、仅解码器的自回归模型，专注于高质量图像生成及其他任务。它从头训练，无需依赖预训练组件，性能媲美扩散模型，并支持多任务处理。

- Motivation: 现有方法依赖预训练组件或混合架构，限制了设计和许可自由度。Lumina-mGPT 2.0旨在通过从头训练实现更高的灵活性和生成质量。
- Method: 采用自回归模型，统一的分词方案支持多任务处理，并引入高效解码策略（如推理时间缩放和推测性Jacobi采样）提升性能。
- Result: 在文本到图像基准测试中表现优异，甚至超越扩散模型；在Graph200K基准测试中展示了多任务能力。
- Conclusion: Lumina-mGPT 2.0是一个强大且灵活的统一多模态生成基础模型，已开源训练细节、代码和模型。


### [2] [SV3.3B: A Sports Video Understanding Model for Action Recognition](https://arxiv.org/abs/2507.17844)
*Sai Varun Kodathala,Yashwanth Reddy Vutukoori,Rakesh Vunnam*

Main category: cs.CV

TL;DR: SV3.3B是一种轻量级视频理解模型，用于自动化体育视频分析，通过创新的时间运动差异采样和自监督学习实现高效设备端部署，显著优于现有模型。

- Motivation: 传统体育视频分析模型计算量大且缺乏对运动细节的理解，无法捕捉关键的运动阶段（如准备、执行和收尾）。
- Method: 结合DWT-VGG16-LDA关键帧提取、V-DWT-JEPA2编码器和LLM解码器，通过自监督学习和掩码去噪目标进行预训练。
- Result: 在NSVA篮球数据集上表现优异，信息密度、动作复杂性和测量精度显著提升，性能超越GPT-4o等大型闭源模型。
- Conclusion: SV3.3B为体育分析提供了高效、技术细节丰富的解决方案，适合设备端部署。


### [3] [Detail++: Training-Free Detail Enhancer for Text-to-Image Diffusion Models](https://arxiv.org/abs/2507.17853)
*Lifeng Chen,Jiner Wang,Zihao Pan,Beier Zhu,Xiaofeng Yang,Chi Zhang*

Main category: cs.CV

TL;DR: Detail++ 是一个无需训练的框架，通过渐进式细节注入策略（PDI）解决复杂提示下多主题生成的挑战。

- Motivation: 现有文本到图像（T2I）生成模型在处理复杂提示（尤其是多主题和属性）时表现不佳，受人类绘画过程启发，提出分阶段生成方法。
- Method: 将复杂提示分解为简化子提示，分阶段生成；利用自注意力控制布局，并通过交叉注意力和质心对齐损失减少绑定噪声。
- Result: 在 T2I-CompBench 和新构建的风格组合基准测试中，Detail++ 显著优于现有方法。
- Conclusion: Detail++ 通过分阶段生成和优化绑定机制，有效提升了复杂提示下的图像生成质量。


### [4] [FishDet-M: A Unified Large-Scale Benchmark for Robust Fish Detection and CLIP-Guided Model Selection in Diverse Aquatic Visual Domains](https://arxiv.org/abs/2507.17859)
*Muayad Abujabal,Lyes Saad Saoud,Irfan Hussain*

Main category: cs.CV

TL;DR: FishDet-M是最大的统一鱼类检测基准，整合了13个公开数据集，评估了28种目标检测模型，并提出了基于CLIP的模型选择框架，以支持自适应部署。

- Motivation: 解决水下鱼类检测中数据集碎片化、成像条件异质性和评估协议不一致的问题。
- Method: 整合13个数据集，使用COCO风格标注，评估28种模型（YOLO系列、R-CNN、DETR等），并引入CLIP-based模型选择框架。
- Result: 模型性能因架构不同而异，CLIP-based选择框架在零样本下表现优异，无需集成计算。
- Conclusion: FishDet-M为复杂水下场景的目标检测提供了标准化平台，支持未来研究。


### [5] [Towards Facilitated Fairness Assessment of AI-based Skin Lesion Classifiers Through GenAI-based Image Synthesis](https://arxiv.org/abs/2507.17860)
*Ko Watanabe. Stanislav Frolov. Adriano Lucieri. Andreas Dengel*

Main category: cs.CV

TL;DR: 利用生成式AI（GenAI）评估皮肤癌分类器的公平性，发现合成数据在公平性评估中具有潜力，但需注意训练数据与合成数据的匹配问题。

- Motivation: 深度学习在皮肤癌筛查中的应用潜力巨大，但存在潜在偏见，评估和改进公平性至关重要。
- Method: 使用先进的生成式AI模型（LightningDiT）评估公开可用的黑色素瘤分类器的公平性。
- Result: 合成数据在公平性评估中表现良好，但若评估模型与合成数据训练数据不匹配，公平性验证会变得困难。
- Conclusion: 合成数据为医学影像GenAI系统的公平性评估和改进提供了新途径。


### [6] [DiNAT-IR: Exploring Dilated Neighborhood Attention for High-Quality Image Restoration](https://arxiv.org/abs/2507.17892)
*Hanzhou Liu,Binghan Li,Chengkai Liu,Mi Lu*

Main category: cs.CV

TL;DR: 论文提出了一种基于Transformer的图像修复方法DiNAT-IR，通过结合局部和全局注意力机制，解决了传统方法在高效性和质量上的平衡问题。

- Motivation: Transformer在图像修复中表现出色，但自注意力机制的高计算成本限制了其在高分辨率图像上的应用。现有方法如Restormer虽然高效，但可能忽略局部细节。
- Method: 提出Dilated Neighborhood Attention (DiNA)结合滑动窗口注意力和混合膨胀因子，并引入通道感知模块以补充全局上下文。
- Result: DiNAT-IR在多个基准测试中取得竞争性结果，为低层计算机视觉问题提供了高质量解决方案。
- Conclusion: DiNAT-IR通过平衡全局和局部注意力，有效提升了图像修复的质量和效率。


### [7] [AFRDA: Attentive Feature Refinement for Domain Adaptive Semantic Segmentation](https://arxiv.org/abs/2507.17957)
*Md. Al-Masrur Khan,Durgakant Pushp,Lantao Liu*

Main category: cs.CV

TL;DR: 论文提出了一种自适应特征细化（AFR）模块，用于无监督域自适应语义分割（UDA-SS），通过结合高低分辨率特征和高频组件，提升分割精度。

- Motivation: 现有UDA-SS方法难以平衡局部细节和全局上下文信息，导致复杂区域的分割错误。
- Method: AFR模块通过语义先验细化高分辨率特征，整合高频组件，并使用不确定性驱动的注意力平衡局部与全局信息。
- Result: 在GTA V→Cityscapes和Synthia→Cityscapes数据集上分别提升了1.05%和1.04%的mIoU。
- Conclusion: AFR模块轻量且高效，显著提升了UDA-SS的分割性能。


### [8] [OPEN: A Benchmark Dataset and Baseline for Older Adult Patient Engagement Recognition in Virtual Rehabilitation Learning Environments](https://arxiv.org/abs/2507.17959)
*Ali Abedi,Sadaf Safa,Tracey J. F. Colella,Shehroz S. Khan*

Main category: cs.CV

TL;DR: 论文介绍了OPEN数据集，用于AI驱动的老年人在虚拟学习中的参与度识别，填补了现有研究的空白。

- Motivation: 虚拟学习中的参与度对满意度和表现至关重要，但现有研究缺乏针对老年人的数据集和方法。
- Method: 收集了11名老年人六周内每周虚拟学习的数据，提取面部、手部和身体关节特征，并训练机器学习模型。
- Result: 模型识别参与度的准确率高达81%，OPEN数据集为个性化建模提供了基础。
- Conclusion: OPEN数据集为老年人群体的参与度识别研究提供了重要资源，并推动了相关领域的发展。


### [9] [Bearded Dragon Activity Recognition Pipeline: An AI-Based Approach to Behavioural Monitoring](https://arxiv.org/abs/2507.17987)
*Arsen Yermukan,Pedro Machado,Feliciano Domingos,Isibor Kennedy Ihianle,Jordan J. Bird,Stefano S. K. Kaburu,Samantha J. Ward*

Main category: cs.CV

TL;DR: 论文提出了一种基于YOLO模型的自动化系统，用于实时监测鬃狮蜥的行为，解决了传统方法耗时且易出错的问题。

- Motivation: 传统监测鬃狮蜥行为的方法效率低且易出错，需要一种自动化解决方案以提高研究效率和准确性。
- Method: 使用五种YOLO模型（v5-v12）在1200张自定义图像数据集上训练，选择YOLOv8s为最优模型，结合时间插值和规则逻辑分类行为。
- Result: 系统在监测鬃狮蜥的“晒太阳”行为上表现可靠，但“捕猎”行为因蟋蟀检测精度低（mAP@0.5=0.392）效果较差。
- Conclusion: 该系统为受控环境下的爬行动物行为监测提供了可扩展方案，未来需优化蟋蟀检测以提高整体性能。


### [10] [AG-VPReID.VIR: Bridging Aerial and Ground Platforms for Video-based Visible-Infrared Person Re-ID](https://arxiv.org/abs/2507.17995)
*Huy Nguyen,Kien Nguyen,Akila Pemasiri,Akmal Jahan,Clinton Fookes,Sridha Sridharan*

Main category: cs.CV

TL;DR: 论文提出了首个空中-地面跨模态视频行人重识别数据集AG-VPReID.VIR，并设计了TCC-VPReID三流架构以解决跨平台和跨模态的挑战。

- Motivation: 现有数据集主要关注地面视角，存在遮挡、覆盖范围有限等问题，空中视角能解决这些问题。
- Method: 提出AG-VPReID.VIR数据集，包含RGB和红外模态数据；设计TCC-VPReID三流架构，结合风格鲁棒特征学习、基于记忆的跨视角适应和中介引导的时间建模。
- Result: 实验表明，AG-VPReID.VIR数据集具有独特挑战性，TCC-VPReID框架在多个评估协议中表现优异。
- Conclusion: AG-VPReID.VIR和TCC-VPReID为跨模态行人重识别提供了新基准和解决方案。


### [11] [Exploring the interplay of label bias with subgroup size and separability: A case study in mammographic density classification](https://arxiv.org/abs/2507.17996)
*Emma A. M. Stanley,Raghav Mehta,Mélanie Roschewitz,Nils D. Forkert,Ben Glocker*

Main category: cs.CV

TL;DR: 研究了医学影像数据中标签偏差对深度学习模型特征学习和性能的影响，发现偏差大小和子群可分性对模型表现有显著影响。

- Motivation: 探讨医学影像数据中特定子群的系统性标签偏差对AI系统公平性的影响。
- Method: 使用EMBED数据集训练深度学习模型，模拟标签偏差对可分离和不可分离子群的影响。
- Result: 标签偏差导致模型特征表示显著偏移，且偏移程度与子群大小和可分性相关；验证集标签质量影响子群性能。
- Conclusion: 标签偏差对医学影像AI子群公平性有重要影响，需关注数据偏差和验证集标签质量。


### [12] [Registration beyond Points: General Affine Subspace Alignment via Geodesic Distance on Grassmann Manifold](https://arxiv.org/abs/2507.17998)
*Jaeho Shin,Hyeonjae Gil,Junwoo Jang,Maani Ghaffari,Ayoung Kim*

Main category: cs.CV

TL;DR: 论文提出了一种可优化的Grassmannian距离函数，用于刚性变换下的特征配准问题，优于现有方法。

- Motivation: 现有方法无法将Grassmannian特征的距离表示为刚性变换的显式函数，限制了其在配准问题中的应用。
- Method: 通过数学证明，利用高维线性子空间的基作为显式表示，提出了一种可优化的成本函数。
- Result: 提出的方法能够找到全局最优解，并在计算机视觉任务中优于现有解决方案。
- Conclusion: 该成本函数及其扩展在配准问题中表现出优越性能，代码已开源。


### [13] [GRR-CoCa: Leveraging LLM Mechanisms in Multimodal Model Architectures](https://arxiv.org/abs/2507.18009)
*Jake R. Patock,Nicole Catherine Lewis,Kevin McCoy,Christina Gomez,Canling Chen,Lorenzo Luzi*

Main category: cs.CV

TL;DR: GRR-CoCa是一种改进的多模态模型，通过引入高斯误差门控线性单元、均方根归一化和旋转位置嵌入，显著提升了CoCa模型的性能。

- Motivation: 当前领先的多模态模型在架构上落后于大型语言模型（LLMs），因此需要改进以提升性能。
- Method: 在CoCa模型中引入高斯误差门控线性单元、均方根归一化和旋转位置嵌入，优化文本解码器和视觉变换器（ViT）编码器。
- Result: GRR-CoCa在预训练和微调任务中显著优于基线模型，对比损失、困惑度和CoCa损失均有显著提升。
- Conclusion: GRR-CoCa的改进架构在多模态任务中表现出更好的性能和泛化能力。


### [14] [Celeb-DF++: A Large-scale Challenging Video DeepFake Benchmark for Generalizable Forensics](https://arxiv.org/abs/2507.18015)
*Yuezun Li,Delong Zhu,Xinjie Cui,Siwei Lyu*

Main category: cs.CV

TL;DR: 论文介绍了Celeb-DF++数据集，旨在解决DeepFake视频检测的泛化性问题，包含多种伪造类型和评估协议。

- Motivation: 现有数据集在伪造类型多样性上不足，难以支持泛化性检测模型的开发。
- Method: 基于Celeb-DF数据集扩展，引入Celeb-DF++，覆盖三种伪造场景（FS、FR、TF），使用22种不同DeepFake方法生成高质量视频。
- Result: 数据集展示了现有检测方法的局限性，并突出了新数据集的挑战性。
- Conclusion: Celeb-DF++为开发泛化性DeepFake检测方法提供了重要资源。


### [15] [High-fidelity 3D Gaussian Inpainting: preserving multi-view consistency and photorealistic details](https://arxiv.org/abs/2507.18023)
*Jun Zhou,Dinghao Li,Nannan Li,Mingjie Wang*

Main category: cs.CV

TL;DR: 提出了一种基于3D高斯泼溅的3D场景修复框架，通过自动掩码优化和不确定性引导的区域优化，显著提升了修复质量和多视角一致性。

- Motivation: 3D场景修复因结构不规则和多视角一致性要求高而具有挑战性，现有方法难以满足需求。
- Method: 结合自动掩码优化（高斯场景过滤和反向投影）和不确定性引导的细粒度优化策略。
- Result: 在多个数据集上实验表明，该方法在视觉质量和视角一致性上优于现有技术。
- Conclusion: 该框架为3D场景修复提供了高效且高质量的解决方案。


### [16] [Emotion Recognition from Skeleton Data: A Comprehensive Survey](https://arxiv.org/abs/2507.18026)
*Haifeng Lu,Jiuyi Chen,Zhen Zhang,Ruida Liu,Runhao Zeng,Xiping Hu*

Main category: cs.CV

TL;DR: 综述了基于骨骼动作的情感识别技术，包括心理模型、数据集、方法分类（姿势和步态）、技术范式（传统方法、Feat2Net、FeatFusionNet、End2EndNet），并探讨了在心理健康评估中的应用和未来挑战。

- Motivation: 情感识别通常依赖面部表情或生理信号，但基于身体动作的方法更具隐私保护性。3D骨骼采集技术的进步推动了这一领域的发展。
- Method: 系统回顾了骨骼情感识别技术，包括心理模型、数据集、方法分类和技术范式分析。
- Result: 总结了代表性工作，并在常用数据集上进行了基准测试。
- Conclusion: 探讨了情感识别在心理健康评估中的应用潜力，并指出了未来研究方向。


### [17] [ViGText: Deepfake Image Detection with Vision-Language Model Explanations and Graph Neural Networks](https://arxiv.org/abs/2507.18031)
*Ahmad ALBarqawi,Mahmoud Nazzal,Issa Khalil,Abdallah Khreishah,NhatHai Phan*

Main category: cs.CV

TL;DR: ViGText是一种结合图像与视觉大语言模型文本解释的图框架方法，显著提升了深度伪造检测的泛化能力和鲁棒性。

- Motivation: 深度伪造技术的快速发展威胁媒体真实性，传统检测方法难以应对定制化深度伪造内容。
- Method: ViGText通过图像分块、构建图像与文本图，并利用图神经网络进行多级特征提取，结合空间与频率域分析。
- Result: 实验显示ViGText在泛化性和鲁棒性上表现优异，F1分数提升至98.32%，召回率提高11.1%。
- Conclusion: ViGText通过视觉与文本的详细分析，为深度伪造检测设定了新标准，保障媒体真实性。


### [18] [Enhancing Scene Transition Awareness in Video Generation via Post-Training](https://arxiv.org/abs/2507.18046)
*Hanwen Shen,Jiajie Lu,Yupeng Cao,Xiaonan Yang*

Main category: cs.CV

TL;DR: 论文提出了一种名为TAV的数据集，用于解决AI生成视频中多场景转换的连贯性问题，通过后训练提升了场景转换理解和生成质量。

- Motivation: 当前AI生成视频模型在长视频多场景转换上表现不佳，主要因为缺乏场景转换意识。
- Method: 提出Transition-Aware Video (TAV)数据集，包含多场景转换的视频片段，并通过后训练提升模型能力。
- Result: 实验表明，TAV数据集能改善场景转换理解，缩小生成与需求场景的差距，并保持图像质量。
- Conclusion: TAV数据集为多场景视频生成提供了有效解决方案，提升了模型的场景转换能力。


### [19] [BokehDiff: Neural Lens Blur with One-Step Diffusion](https://arxiv.org/abs/2507.18060)
*Chengxuan Zhu,Qingnan Fan,Qi Zhang,Jinwei Chen,Huaqi Zhang,Chao Xu,Boxin Shi*

Main category: cs.CV

TL;DR: BokehDiff是一种新的镜头模糊渲染方法，利用生成扩散先验实现物理精确且视觉吸引人的效果。

- Motivation: 现有方法受限于深度估计的准确性，在深度不连续处会产生伪影。
- Method: 采用物理启发的自注意力模块，结合深度相关的模糊圈约束和自遮挡效应，并将扩散模型适配为一步推理方案。
- Result: 实现了高质量和高保真的渲染效果。
- Conclusion: 通过扩散模型合成逼真的前景，解决了可扩展配对数据不足的问题。


### [20] [Adapting Large VLMs with Iterative and Manual Instructions for Generative Low-light Enhancement](https://arxiv.org/abs/2507.18064)
*Xiaoran Sun,Liyan Wang,Cong Wang,Yeying Jin,Kin-man Lam,Zhixun Su,Yang Yang,Jinshan Pan*

Main category: cs.CV

TL;DR: VLM-IMI是一种利用视觉语言模型（VLMs）和迭代手动指令（IMIs）的低光图像增强框架，通过语义指导提升效果。

- Motivation: 现有低光图像增强方法忽视正常光图像的语义指导，限制了复杂光照条件下的效果。
- Method: 结合文本描述和图像特征，通过指令先验融合模块动态对齐和融合跨模态信息，采用迭代手动指令策略优化输出。
- Result: 在多样场景中，VLM-IMI在定量指标和感知质量上均优于现有方法。
- Conclusion: VLM-IMI通过语义指导和迭代优化，显著提升了低光图像增强的效果。


### [21] [TextSAM-EUS: Text Prompt Learning for SAM to Accurately Segment Pancreatic Tumor in Endoscopic Ultrasound](https://arxiv.org/abs/2507.18082)
*Pascal Spiegler,Taha Koleilat,Arash Harirpoush,Corey S. Miller,Hassan Rivaz,Marta Kersten-Oertel,Yiming Xiao*

Main category: cs.CV

TL;DR: TextSAM-EUS是一种基于文本提示的轻量级SAM模型改进方法，用于胰腺肿瘤的自动分割，无需手动几何提示，性能优于现有方法。

- Motivation: 胰腺癌预后差，EUS图像分割因噪声和低对比度问题依赖大量专家标注数据，现有方法效果有限。
- Method: 结合BiomedCLIP文本编码器和LoRA调整SAM架构，仅调整0.86%参数，实现自动胰腺肿瘤分割。
- Result: 在公开数据集上，TextSAM-EUS的Dice和NSD分别达82.69%/85.28%（自动提示）和83.10%/85.70%（手动提示），优于现有方法。
- Conclusion: TextSAM-EUS首次将提示学习引入SAM医学图像分割，为EUS分割提供了高效、鲁棒的解决方案。


### [22] [Comparison of Segmentation Methods in Remote Sensing for Land Use Land Cover](https://arxiv.org/abs/2507.18099)
*Naman Srivastava,Joel D Joy,Yash Dixit,Swarup E,Rakshit Ramesh*

Main category: cs.CV

TL;DR: 该研究评估了基于查找表（LUT）的大气校正技术，结合监督和半监督学习模型（如DeeplabV3+和CPS），用于LULC预测，并通过动态加权优化CPS模型。以印度海得拉巴为例，展示了城市化对土地利用的影响。

- Motivation: LULC制图对城市和资源规划至关重要，尤其是在发展智能和可持续城市中。研究旨在评估先进技术在城市规划中的实用性和准确性。
- Method: 采用LUT大气校正处理Cartosat MX图像，结合监督和半监督学习模型（DeeplabV3+和CPS），并通过动态加权优化CPS模型。
- Result: 案例研究揭示了海得拉巴因快速城市化导致的城市扩张、绿地减少和工业区扩大等土地利用变化。
- Conclusion: 该技术为城市规划者和政策制定者提供了实用工具，展示了其在土地利用变化分析中的有效性。


### [23] [Datasets and Recipes for Video Temporal Grounding via Reinforcement Learning](https://arxiv.org/abs/2507.18100)
*Ruizhe Chen,Zhiting Fan,Tianze Luo,Heqing Zou,Zhaopeng Feng,Guiyang Xie,Hansheng Zhang,Zhuochen Wang,Zuozhu Liu,Huaijian Zhang*

Main category: cs.CV

TL;DR: 提出了一种两阶段训练框架，结合监督微调和强化学习，提升视频时间定位（VTG）模型的准确性和鲁棒性。

- Motivation: 现有方法在时间感知和泛化能力上表现不佳，需要改进。
- Method: 利用高质量冷启动数据进行监督微调初始化，再通过难度控制的强化学习增强时间定位和推理能力。
- Result: 在多个VTG基准测试中表现优于现有模型，尤其在挑战性和开放域场景中。
- Conclusion: 高质量冷启动数据和难度控制强化学习对提升VTG模型性能至关重要，相关资源已开源。


### [24] [A Multimodal Seq2Seq Transformer for Predicting Brain Responses to Naturalistic Stimuli](https://arxiv.org/abs/2507.18104)
*Qianyi He,Yuan Chang Leong*

Main category: cs.CV

TL;DR: 该论文提出了一种基于序列到序列Transformer的模型，用于预测自然多模态电影刺激下的全脑fMRI响应，结合视觉、听觉和语言输入，并利用预训练模型提取特征。

- Motivation: Algonauts 2025挑战赛要求开发能够预测多模态电影刺激下全脑fMRI响应的编码模型，本文旨在通过序列建模和多模态上下文解决这一问题。
- Method: 使用VideoMAE、HuBERT、Qwen和BridgeTower等预训练模型提取特征，通过双交叉注意力机制整合先验脑状态、当前刺激和情节级摘要信息。
- Result: 模型在分布内和分布外数据上均表现优异，验证了时序感知和多模态序列建模在脑活动预测中的有效性。
- Conclusion: 该研究展示了结合多模态上下文和时序建模的Transformer模型在预测脑活动中的潜力，代码已开源。


### [25] [Distributional Uncertainty for Out-of-Distribution Detection](https://arxiv.org/abs/2507.18106)
*JinYoung Kim,DaeUng Jo,Kimin Yun,Jeonghyo Song,Youngjoon Yoo*

Main category: cs.CV

TL;DR: 提出了一种名为Free-Energy Posterior Network的新框架，联合建模分布不确定性和识别OoD样本，通过自由能量实现细粒度不确定性估计。

- Motivation: 传统方法如MC Dropout仅关注模型或数据不确定性，未能与OoD检测的语义目标对齐。
- Method: 结合自由能量密度估计器和后验网络，直接从不需随机采样的学习参数中估计不确定性。
- Result: 在Fishyscapes等真实基准测试中验证了方法的有效性。
- Conclusion: 该方法提供了语义明确且计算高效的解决方案，适用于不确定性感知分割。


### [26] [T2VWorldBench: A Benchmark for Evaluating World Knowledge in Text-to-Video Generation](https://arxiv.org/abs/2507.18107)
*Yubin Chen,Xuyang Guo,Zhenmei Shi,Zhao Song,Jiahao Zhang*

Main category: cs.CV

TL;DR: T2VWorldBench是首个评估文本到视频模型世界知识生成能力的框架，覆盖6大类60子类1200个提示，发现当前模型在理解世界知识方面存在显著不足。

- Motivation: 当前文本到视频模型在语义一致性和事实准确性方面缺乏系统评估，需要填补这一研究空白。
- Method: 提出T2VWorldBench框架，结合人工评估和基于视觉语言模型的自动化评估，对10种先进模型进行测试。
- Result: 大多数模型无法理解世界知识并生成真正正确的视频。
- Conclusion: 当前模型在世界知识利用方面存在关键缺陷，为构建具备常识推理和事实生成能力的模型提供了研究方向。


### [27] [Information Entropy-Based Framework for Quantifying Tortuosity in Meibomian Gland Uneven Atrophy](https://arxiv.org/abs/2507.18135)
*Kesheng Wang,Xiaoyu Chen,Chunlei He,Fenfen Li,Xinxin Yu,Dexing Kong,Shoujun Huang,Qi Dai*

Main category: cs.CV

TL;DR: 提出了一种基于信息熵的曲线曲折度量化框架，通过概率建模和熵理论结合曲线数据域变换，优于传统方法，并在临床应用中验证了其有效性。

- Motivation: 医学图像分析中曲线曲折度的精确量化对辅助诊断和病理评估至关重要，传统方法如曲率或弧弦比存在局限性。
- Method: 提出信息熵框架，通过比较目标曲线与参考曲线评估曲折度，适用于有生物学参考曲线的医学数据。
- Result: 数值模拟验证了方法的稳定性和有效性，应用于睑板腺萎缩均匀性分析，结果显示两组间显著差异（AUC=0.8768）。
- Conclusion: 该框架在曲线曲折度分析中具有临床实用性，可作为医学诊断中定量形态评估的通用工具。


### [28] [Degradation-Consistent Learning via Bidirectional Diffusion for Low-Light Image Enhancement](https://arxiv.org/abs/2507.18144)
*Jinhong He,Minglong Xue,Zhipu Liu,Mingliang Zhou,Aoxiang Ning,Palaiahnakote Shivakumara*

Main category: cs.CV

TL;DR: 提出了一种双向扩散优化机制，通过联合建模低光和正常光图像的退化过程，提升图像增强质量。

- Motivation: 现有扩散方法因单向建模退化过程，难以捕捉真实世界退化的复杂性，导致结构不一致和像素错位。
- Method: 采用双向扩散（低光到正常光、正常光到低光）训练，引入自适应特征交互块（AFI）和反射感知校正模块（RACM）。
- Result: 在多个基准数据集上，方法在定量和定性评估中优于现有技术，并能泛化到多样化退化场景。
- Conclusion: 双向扩散机制和模块设计有效提升图像增强质量，生成结果更符合人类视觉感知。


### [29] [WaveMamba: Wavelet-Driven Mamba Fusion for RGB-Infrared Object Detection](https://arxiv.org/abs/2507.18173)
*Haodong Zhu,Wenhao Dong,Linlin Yang,Hong Li,Yuguang Yang,Yangyang Ren,Qingcheng Zhu,Zichao Feng,Changbai Li,Shaohui Lin,Runqi Wang,Xiaoyan Luo,Baochang Zhang*

Main category: cs.CV

TL;DR: WaveMamba是一种跨模态融合方法，通过离散小波变换（DWT）分解RGB和红外（IR）图像的互补频率特征，并结合改进的检测头（IDWT）减少信息损失，显著提升目标检测性能。

- Motivation: 利用RGB和红外图像的互补特性提升目标检测性能。
- Method: 提出WaveMamba融合方法，包括WaveMamba Fusion Block（WMFB）和低/高频子带融合策略，结合Mamba框架和门控注意力机制。
- Result: 在四个基准测试中平均mAP提升4.5%，超越现有方法。
- Conclusion: WaveMamba通过高效融合RGB和IR的互补特征，显著提升了目标检测性能。


### [30] [Real-Time Object Detection and Classification using YOLO for Edge FPGAs](https://arxiv.org/abs/2507.18174)
*Rashed Al Amin,Roman Obermaisser*

Main category: cs.CV

TL;DR: 本文提出了一种基于YOLOv5的资源高效实时目标检测与分类系统，针对FPGA平台优化，实现了99%的分类准确率、3.5W的功耗和9FPS的处理速度。

- Motivation: 现有YOLO方法在边缘FPGA平台上资源效率不足，限制了实时目标检测与分类的应用。
- Method: 基于YOLOv5优化，在COCO和GTSRD数据集上训练，并在Xilinx Kria KV260 FPGA板上实现。
- Result: 实验结果显示99%的分类准确率、3.5W功耗和9FPS处理速度。
- Conclusion: 该方法有效实现了资源高效的实时目标检测与分类，适用于边缘计算应用。


### [31] [Unsupervised Domain Adaptation for 3D LiDAR Semantic Segmentation Using Contrastive Learning and Multi-Model Pseudo Labeling](https://arxiv.org/abs/2507.18176)
*Abhishek Kaushik,Norbert Haala,Uwe Soergel*

Main category: cs.CV

TL;DR: 提出了一种两阶段无监督域适应框架，通过对比学习和多模型伪标签策略提升3D LiDAR语义分割的域适应性能。

- Motivation: 解决因传感器类型或地理位置变化导致的3D LiDAR语义分割性能下降问题，同时避免手动标注目标数据的高成本。
- Method: 1. 使用无监督对比学习预训练骨干网络；2. 引入多模型伪标签策略，通过硬投票生成高质量伪标签；3. 利用伪标签微调网络。
- Result: 在从SemanticKITTI到SemanticPOSS和SemanticSlamantic的实验中，分割精度显著优于直接迁移和单模型UDA方法。
- Conclusion: 结合对比预训练和集成伪标签策略，无需目标域标注即可有效缩小复杂域差距。


### [32] [Differential-UMamba: Rethinking Tumor Segmentation Under Limited Data Scenarios](https://arxiv.org/abs/2507.18177)
*Dhruv Jain,Romain Modzelewski,Romain Hérault,Clement Chatelain,Eva Torfeh,Sebastien Thureau*

Main category: cs.CV

TL;DR: Diff-UMamba结合UNet和mamba机制，通过噪声抑制模块提升医学图像分割的准确性和鲁棒性，尤其在数据稀缺场景下表现优异。

- Motivation: 解决深度学习模型在数据稀缺场景中因过拟合噪声和无关模式而泛化能力受限的问题。
- Method: 提出Diff-UMamba架构，结合UNet和mamba机制，引入噪声抑制模块（NRM）通过信号差分策略抑制噪声和无关激活。
- Result: 在多个公共数据集上表现优于基线方法1-3%，在低数据条件下（如BraTS-21）和小型内部数据集（NSCLC CBCT）上提升4-5%。
- Conclusion: Diff-UMamba通过噪声抑制和长程依赖建模，显著提升了医学图像分割的准确性和鲁棒性，尤其在数据稀缺场景下具有优势。


### [33] [MatSSL: Robust Self-Supervised Representation Learning for Metallographic Image Segmentation](https://arxiv.org/abs/2507.18184)
*Hoang Hai Nam Nguyen,Phan Nguyen Duc Hieu,Ho Won Lee*

Main category: cs.CV

TL;DR: MatSSL是一种简化的自监督学习架构，通过门控特征融合有效整合多级表示，解决了金属材料显微图像分析中监督方法依赖标注数据的问题。

- Motivation: 当前金属材料显微图像分析依赖监督方法，需对每个新数据集重新训练且在小样本下表现不稳定。自监督学习虽有望解决此问题，但多数方法仍需大规模数据集。
- Method: MatSSL采用门控特征融合整合多级表示，先在小规模无标注数据集上进行自监督预训练，再在多个基准数据集上微调。
- Result: 在MetalDAM上达到69.13% mIoU，优于ImageNet预训练编码器的66.73%；在EBC数据集上平均mIoU提升近40%。
- Conclusion: MatSSL仅需少量无标注数据即可有效适应金相领域，同时保留从自然图像大规模预训练中学到的丰富可迁移特征。


### [34] [TeEFusion: Blending Text Embeddings to Distill Classifier-Free Guidance](https://arxiv.org/abs/2507.18192)
*Minghao Fu,Guo-Hua Wang,Xiaohao Chen,Qing-Guo Chen,Zhao Xu,Weihua Luo,Kaifu Zhang*

Main category: cs.CV

TL;DR: TeEFusion是一种高效的蒸馏方法，通过将指导幅度直接融入文本嵌入中，简化了复杂的采样策略，显著降低了推理成本。

- Motivation: 解决现有文本到图像合成方法中，分类器自由指导（CFG）和复杂采样策略导致的高推理成本问题。
- Method: 提出TeEFusion方法，通过线性操作融合条件和非条件文本嵌入，无需额外参数，同时让学生模型学习教师模型的复杂采样输出。
- Result: 实验表明，学生模型的推理速度比教师模型快6倍，同时保持图像质量接近教师模型的水平。
- Conclusion: TeEFusion是一种高效且性能接近教师模型的蒸馏方法，显著提升了推理效率。


### [35] [LEAF: Latent Diffusion with Efficient Encoder Distillation for Aligned Features in Medical Image Segmentation](https://arxiv.org/abs/2507.18214)
*Qilin Huang,Tianyu Lin,Zhiguang Chen,Fudan Zheng*

Main category: cs.CV

TL;DR: LEAF是一种基于潜在扩散模型的医学图像分割方法，通过直接预测分割图和使用特征蒸馏技术，显著提升了分割性能，同时保持了模型的高效性。

- Motivation: 现有方法在医学图像分割任务中直接迁移扩散模型，未针对任务进行特定调整，且预训练模型在特征提取方面存在不足。
- Method: 提出LEAF模型，在微调过程中用直接预测分割图替代噪声预测模式，并采用特征蒸馏技术对齐卷积层与基于Transformer的视觉编码器的特征。
- Result: 实验表明，LEAF在多种疾病类型的分割数据集上提升了原始扩散模型的性能，且未增加模型参数或推理计算量。
- Conclusion: LEAF通过改进训练策略和特征对齐，实现了高效且性能优越的医学图像分割。


### [36] [3D Test-time Adaptation via Graph Spectral Driven Point Shift](https://arxiv.org/abs/2507.18225)
*Xin Wei,Qin Yang,Yijie Fang,Mingrui Zhu,Nannan Wang*

Main category: cs.CV

TL;DR: 提出了一种基于图谱域的自适应方法GSDTTA，用于3D点云分类，通过图傅里叶变换优化低频分量实现高效适配。

- Motivation: 解决现有3D点云测试时适配方法计算成本高且依赖额外数据的问题。
- Method: 将点云表示为图，通过图傅里叶变换转换到图谱域，优化低频分量，再逆变换重构点云。
- Result: 在基准数据集上表现优于现有方法。
- Conclusion: GSDTTA是一种高效且有效的3D点云测试时适配方法。


### [37] [DATA: Domain-And-Time Alignment for High-Quality Feature Fusion in Collaborative Perception](https://arxiv.org/abs/2507.18237)
*Chengchang Tian,Jianwei Ma,Yan Huang,Zhanye Chen,Honghao Wei,Hui Zhang,Wei Hong*

Main category: cs.CV

TL;DR: 论文提出了一种名为DATA的网络，通过域和时间对齐提升特征融合质量，解决了硬件多样性和传输延迟带来的问题。

- Motivation: 特征级融合在协作感知中表现良好，但受限于硬件多样性和传输延迟导致的特征质量下降。
- Method: 提出DATA网络，包含一致性保持域对齐模块（CDAM）、渐进时间对齐模块（PTAM）和实例聚焦特征聚合模块（IFAM）。
- Result: 在三个典型数据集上达到最优性能，对严重通信延迟和位姿误差保持鲁棒性。
- Conclusion: DATA网络通过系统对齐特征并最大化语义表示，显著提升了协作感知的性能。


### [38] [DepthDark: Robust Monocular Depth Estimation for Low-Light Environments](https://arxiv.org/abs/2507.18243)
*Longjian Zeng,Zunjie Zhu,Rongfeng Lu,Ming Lu,Bolun Zheng,Chenggang Yan,Anke Xue*

Main category: cs.CV

TL;DR: 提出DepthDark模型，解决低光环境下单目深度估计问题，通过模拟夜间成像和高效参数微调策略，在有限数据和计算资源下实现最优性能。

- Motivation: 当前单目深度估计模型在低光环境下性能显著下降，缺乏针对低光场景的鲁棒基础模型和大规模高质量数据集。
- Method: 引入光晕和噪声模拟模块生成高质量低光数据集，提出基于光照引导和多尺度特征融合的参数高效微调策略。
- Result: 在nuScenes-Night和RobotCar-Night数据集上实现最优深度估计性能。
- Conclusion: DepthDark模型在低光环境下表现出色，验证了其高效性和鲁棒性。


### [39] [LONG3R: Long Sequence Streaming 3D Reconstruction](https://arxiv.org/abs/2507.18255)
*Zhuoguang Chen,Minghui Qin,Tianyuan Yuan,Zhe Liu,Hang Zhao*

Main category: cs.CV

TL;DR: LONG3R是一种新型的流式多视角3D场景重建模型，通过递归处理和内存门控机制实现实时处理，适用于长序列输入。

- Motivation: 现有方法在处理流式输入图像时存在局限性，无法实时处理长序列，限制了实际应用。
- Method: 采用内存门控机制过滤相关内存，结合双源细化解码器进行粗到细的交互，并提出3D时空内存动态优化冗余信息。
- Result: 实验表明，LONG3R在长序列处理上优于现有流式方法，同时保持实时推理速度。
- Conclusion: LONG3R为长序列流式3D重建提供了一种高效且实时的解决方案。


### [40] [Exploiting Gaussian Agnostic Representation Learning with Diffusion Priors for Enhanced Infrared Small Target Detection](https://arxiv.org/abs/2507.18260)
*Junyao Li,Yahao Lu,Xingyuan Guo,Xiaoyu Xian,Tiantian Wang,Yukai Shi*

Main category: cs.CV

TL;DR: 论文提出了一种名为高斯不可知表示学习的方法，通过高斯组压缩器和两阶段扩散模型提升红外小目标检测在数据稀缺情况下的鲁棒性。

- Motivation: 现有红外小目标检测方法依赖大量人工标注数据，但在实际应用中表现脆弱。论文旨在解决数据稀缺问题。
- Method: 提出高斯组压缩器进行非均匀量化，并利用两阶段扩散模型进行真实世界重建。
- Result: 在多种数据稀缺场景下，该方法显著提升了检测性能。
- Conclusion: 高斯不可知表示学习有效增强了红外小目标检测的鲁棒性和性能。


### [41] [Dissecting the Dental Lung Cancer Axis via Mendelian Randomization and Mediation Analysis](https://arxiv.org/abs/2507.18287)
*Wenran Zhang,Huihuan Luo,Linda Wei,Ping Nie,Yiqun Wu,Dedong Yu*

Main category: cs.CV

TL;DR: 研究使用孟德尔随机化方法探讨牙周炎和龋齿与肺癌的因果关系，发现龋齿显著增加肺癌风险，部分由肺功能下降介导。

- Motivation: 探索口腔疾病（牙周炎和龋齿）与肺癌之间的因果关系，以填补现有观察性研究的不足。
- Method: 采用两样本孟德尔随机化（MR）方法，利用大规模基因组数据进行分析，并评估肺功能的介导作用。
- Result: 龋齿显著增加肺癌风险（尤其是鳞状细胞肺癌），部分由肺功能下降介导；牙周炎无显著影响。
- Conclusion: 龋齿与肺癌存在因果关系，建议将口腔护理和肺功能监测纳入癌症预防策略。


### [42] [LMM-Det: Make Large Multimodal Models Excel in Object Detection](https://arxiv.org/abs/2507.18300)
*Jincheng Li,Chunyu Xie,Ji Ao,Dawei Leng,Yuhui Yin*

Main category: cs.CV

TL;DR: 论文提出LMM-Det方法，利用大型多模态模型进行目标检测，无需专用检测模块，通过数据分布调整和推理优化提升召回率。

- Motivation: 大型多模态模型（LMMs）在多模态任务中表现优异，但在目标检测能力上与专用检测器存在显著差距，需填补这一差距。
- Method: 提出LMM-Det方法，通过数据分布调整和推理优化提升召回率，并重新组织指令对话以增强检测能力。
- Result: 实验证明LMM-Det有效，大型多模态模型具备无需额外检测模块的检测能力。
- Conclusion: LMM-Det是一种简单有效的方法，展示了大型多模态模型在目标检测中的潜力。


### [43] [Improving Large Vision-Language Models' Understanding for Field Data](https://arxiv.org/abs/2507.18311)
*Xiaomei Zhang,Hanyu Zheng,Xiangyu Zhu,Jinghuan Wei,Junhong Zou,Zhen Lei,Zhaoxiang Zhang*

Main category: cs.CV

TL;DR: FieldLVLM框架通过结合领域感知语言生成和数据压缩多模态模型调优，显著提升了大型视觉语言模型在科学领域数据理解上的表现。

- Motivation: 大型视觉语言模型在科学领域（尤其是复杂现场数据）的应用尚未充分探索，需要一种新方法来提升其理解能力。
- Method: FieldLVLM包含两个主要组件：领域感知语言生成策略（提取关键物理特征并转换为结构化文本）和数据压缩多模态模型调优（简化输入并保留关键信息）。
- Result: 实验结果表明，FieldLVLM在科学领域数据任务中显著优于现有方法。
- Conclusion: FieldLVLM为大型视觉语言模型在科学研究中的应用提供了新可能性，缩小了大模型与领域特定发现之间的差距。


### [44] [A Multi-Dataset Benchmark for Semi-Supervised Semantic Segmentation in ECG Delineation](https://arxiv.org/abs/2507.18323)
*Minje Park,Jeonghwa Lim,Taehyung Yu,Sunghoon Joo*

Main category: cs.CV

TL;DR: 本文提出了首个针对心电图（ECG）半监督语义分割（SemiSeg）的系统性基准，通过整合多源数据集和评估不同算法，发现Transformer架构优于卷积网络。

- Motivation: ECG分割对临床诊断至关重要，但公开标注数据稀缺，半监督学习成为潜在解决方案。
- Method: 整合多源ECG数据集，采用五种半监督分割算法，在卷积网络和Transformer架构上评估，并提出ECG专用训练策略。
- Result: Transformer在半监督ECG分割中表现优于卷积网络。
- Conclusion: 该基准为半监督ECG分割研究奠定了基础，有望推动该领域进一步发展。


### [45] [Beyond Low-rankness: Guaranteed Matrix Recovery via Modified Nuclear Norm](https://arxiv.org/abs/2507.18327)
*Jiangjun Peng,Yisi Luo,Xiangyong Cao,Shuang Xu,Deyu Meng*

Main category: cs.CV

TL;DR: 提出了一种改进的核范数（MNN）框架，用于矩阵恢复问题，无需调参即可同时捕捉局部和全局低秩信息，并提供了理论恢复保证。

- Motivation: 现有方法在结合局部和全局信息时需要调参，且缺乏理论保证，MNN旨在解决这些问题。
- Method: 通过引入合适的变换并在变换后的矩阵上应用核范数，定义了MNN族范数。
- Result: MNN在Robust PCA和矩阵补全任务中表现出色，实验验证了其有效性。
- Conclusion: MNN提供了一种灵活且统一的低秩恢复方法，适用于多种变换，具有理论和实践优势。


### [46] [GVCCS: A Dataset for Contrail Identification and Tracking on Visible Whole Sky Camera Sequences](https://arxiv.org/abs/2507.18330)
*Gabriel Jarry,Ramon Dalmau,Philippe Very,Franck Ballerini,Stephania-Denisa Bocu*

Main category: cs.CV

TL;DR: 论文提出了一种新的地面可见光相机尾迹序列数据集（GVCCS），用于验证和改进尾迹物理模型，并通过深度学习框架进行尾迹分析。

- Motivation: 航空尾迹对气候的影响与CO2排放相当，但现有观测数据缺乏时间追踪和来源标注，限制了模型的准确性。
- Method: 使用地面全天空相机记录尾迹，构建GVCCS数据集，并提出统一的深度学习框架进行尾迹分割和追踪。
- Result: GVCCS包含122个视频序列（24,228帧），每段尾迹均标注并追踪，为模型校准提供高质量数据。
- Conclusion: GVCCS和深度学习框架为尾迹监测和气候影响评估提供了更准确的基础。


### [47] [Boosting Multi-View Indoor 3D Object Detection via Adaptive 3D Volume Construction](https://arxiv.org/abs/2507.18331)
*Runmin Zhang,Zhu Yu,Si-Yuan Cao,Lingyu Zhu,Guangyi Zhang,Xiaokai Bai,Hui-Liang Shen*

Main category: cs.CV

TL;DR: SGCDet是一种基于自适应3D体积构建的多视角室内3D物体检测框架，通过几何和上下文感知模块动态调整不同视角的贡献，并结合稀疏体积构建策略，实现了高效且自适应的检测。

- Motivation: 现有方法将体素的感受野限制在图像的固定位置，缺乏对几何和上下文信息的动态整合，且存在冗余计算问题。
- Method: 引入几何和上下文感知聚合模块动态整合信息，提出稀疏体积构建策略选择高占用概率体素，减少冗余计算。
- Result: 在ScanNet、ScanNet200和ARKitScenes数据集上达到最先进性能。
- Conclusion: SGCDet通过自适应设计和稀疏策略，实现了高效且无需依赖场景几何真值的3D物体检测。


### [48] [Improving Bird Classification with Primary Color Additives](https://arxiv.org/abs/2507.18334)
*Ezhini Rasendiran R,Chandresh Kumar Maurya*

Main category: cs.CV

TL;DR: 通过将频率信息嵌入声谱图颜色化，显著提高了鸟类鸣声分类的准确性。

- Motivation: 解决鸟类鸣声分类中的环境噪声、重叠鸣叫和标签缺失问题，现有模型在低信噪比或多物种录音中表现不佳。
- Method: 提出通过可视化音高模式、速度和重复（称为motifs）分类鸟类，并在声谱图中嵌入频率信息以增强物种区分。
- Result: 实验显示，该方法在F1、ROC-AUC和CMAP指标上分别提升7.3%、6.2%和6.6%，超越BirdCLEF 2024冠军。
- Conclusion: 通过颜色化嵌入频率信息有效提升了鸟类鸣声分类性能。


### [49] [EgoExoBench: A Benchmark for First- and Third-person View Video Understanding in MLLMs](https://arxiv.org/abs/2507.18342)
*Yuping He,Yifei Huang,Guo Chen,Baoqi Pei,Jilan Xu,Tong Lu,Jiangmiao Pang*

Main category: cs.CV

TL;DR: EgoExoBench是首个用于评估多模态大语言模型在自我视角（egocentric）和他人视角（exocentric）间跨视角推理能力的基准测试，包含7,300多个问答对，覆盖11个子任务。研究发现现有模型在单视角任务表现优异，但在跨视角语义对齐、视角关联和时序推理上仍有困难。

- Motivation: 人类能够通过跨视角学习传递知识，但现有MLLMs在此能力上尚未被充分探索，因此需要建立基准测试以评估和推动相关研究。
- Method: 基于公开数据集构建EgoExoBench，包含三大核心挑战（语义对齐、视角关联、时序推理）和11个子任务，评估了13种前沿MLLMs。
- Result: 模型在单视角任务表现良好，但在跨视角任务中表现不佳，尤其在语义对齐、视角关联和时序推理方面。
- Conclusion: EgoExoBench为研究具有跨视角智能的具身代理和智能助手提供了宝贵资源，未来需进一步改进模型跨视角推理能力。


### [50] [VB-Mitigator: An Open-source Framework for Evaluating and Advancing Visual Bias Mitigation](https://arxiv.org/abs/2507.18348)
*Ioannis Sarridis,Christos Koutlis,Symeon Papadopoulos,Christos Diou*

Main category: cs.CV

TL;DR: VB-Mitigator是一个开源框架，旨在简化和统一视觉偏差缓解技术的开发、评估和比较分析。

- Motivation: 计算机视觉模型中的偏差问题导致AI系统不公平、不可靠且难以泛化，现有研究因分散的实现和不一致的评估方法而进展缓慢。
- Method: VB-Mitigator整合了12种缓解方法和7个基准数据集，提供可扩展的统一研究环境。
- Result: VB-Mitigator为研究社区提供了一个基础代码库，支持公平性计算机视觉模型的开发和评估。
- Conclusion: VB-Mitigator通过标准化评估实践和性能比较，加速了公平性计算机视觉模型的研究。


### [51] [Deformable Convolution Module with Globally Learned Relative Offsets for Fundus Vessel Segmentation](https://arxiv.org/abs/2507.18354)
*Lexuan Zhu,Yuxuan Li,Yuning Ren*

Main category: cs.CV

TL;DR: 提出了一种基于注意力和前馈网络的可变形卷积模块，用于学习偏移量以捕捉全局特征，显著提升了眼底血管分割的性能。

- Motivation: 传统的可变形卷积难以处理复杂形状特征，尤其是具有全局自相似性的结构（如眼底血管）。
- Method: 通过注意力机制和前馈网络学习子像素位移场，自适应地扭曲特征图，实现全局特征变形。
- Result: 在公开数据集上，基于该模块的GDCUnet模型达到了最先进的性能。
- Conclusion: 该模块可广泛应用于具有复杂全局自相似特征的机器视觉任务。


### [52] [MVG4D: Image Matrix-Based Multi-View and Motion Generation for 4D Content Creation from a Single Image](https://arxiv.org/abs/2507.18371)
*Xiaotian Chen,DongFu Yin,Fei Richard Yu,Xuanchen Li,Xinhao Zhang*

Main category: cs.CV

TL;DR: MVG4D是一个从单张静态图像生成动态4D内容的新框架，结合多视图合成与4D高斯泼溅技术，提升时间一致性和视觉真实感。

- Motivation: 尽管生成模型在2D到3D/4D内容创作上取得进展，但高保真且时间一致的动态4D内容生成仍具挑战性。
- Method: MVG4D通过图像矩阵模块合成多视图图像，优化3D高斯点云，并通过轻量变形网络扩展到时间域。
- Result: 在Objaverse数据集上，MVG4D在CLIP-I、PSNR、FVD和时间效率上优于现有方法，减少闪烁并增强细节。
- Conclusion: MVG4D为从最小输入高效可控生成4D内容开辟了新方向。


### [53] [Towards Effective Human-in-the-Loop Assistive AI Agents](https://arxiv.org/abs/2507.18374)
*Filippos Bellos,Yayuan Li,Cary Shu,Ruey Day,Jeffrey M. Siskind,Jason J. Corso*

Main category: cs.CV

TL;DR: 论文提出了一种评估框架和多模态数据集，用于研究AI指导如何影响任务完成、减少错误和学习效果，并通过AR增强的AI代理验证了其有效性。

- Motivation: 研究AI与人类在物理任务中的协作潜力，特别是在提供指导时如何提升人类表现。
- Method: 开发了一个评估框架和多模态数据集，并设计了一个配备AR的AI代理，用于实时任务指导。
- Result: 实验证明，AI辅助协作能显著提升任务完成率。
- Conclusion: AI指导在物理任务中具有实际应用价值，能有效提升人类表现。


### [54] [Towards Consistent Long-Term Pose Generation](https://arxiv.org/abs/2507.18382)
*Yayuan Li,Filippos Bellos,Jason Corso*

Main category: cs.CV

TL;DR: 提出一种新颖的一阶段架构，直接从RGB图像和文本描述生成连续坐标空间的姿态，避免了中间表示和基于令牌的生成，显著优于现有方法。

- Motivation: 现有姿态生成方法依赖中间表示或自回归模型，导致性能下降，尤其在长期生成中难以保持时间一致性。
- Method: 通过相对运动预测机制直接操作姿态坐标，并使用统一的占位符令牌实现单次前向生成。
- Result: 在Penn Action和F-PHAB数据集上，该方法显著优于基于量化和自回归的方法，尤其在长期生成场景中。
- Conclusion: 该方法通过消除中间表示和自回归误差，实现了更高效和一致的姿态生成。


### [55] [HumanMaterial: Human Material Estimation from a Single Image via Progressive Training](https://arxiv.org/abs/2507.18385)
*Yu Jiang,Jiahao Xia,Jiongming Qin,Yusen Wang,Tuo Cao,Chunxia Xiao*

Main category: cs.CV

TL;DR: 论文提出了一种基于物理渲染的全人体逆向渲染方法，通过构建高质量数据集和渐进式训练策略，提升材料估计的准确性，尤其是皮肤的真实感。

- Motivation: 全人体逆向渲染任务缺乏对材料图的约束，导致问题不适定。现有方法因简化材料和渲染方程而限制了渲染结果的真实感，尤其是皮肤。
- Method: 构建高质量数据集OpenHumanBRDF，设计渐进式训练模型HumanMaterial，通过先验模型和微调模型优化材料估计，并引入CPR损失函数。
- Result: 在OpenHumanBRDF数据集和真实数据上的实验表明，该方法达到了最先进的性能。
- Conclusion: 提出的方法和数据集显著提升了全人体逆向渲染的真实感，尤其是皮肤的表现。


### [56] [Iwin Transformer: Hierarchical Vision Transformer using Interleaved Windows](https://arxiv.org/abs/2507.18405)
*Simin Huo,Ning Li*

Main category: cs.CV

TL;DR: Iwin Transformer是一种无需位置嵌入的分层视觉Transformer，通过创新的交错窗口注意力和深度可分离卷积实现从低分辨率到高分辨率的直接微调。

- Motivation: 解决Swin Transformer需要连续两个块才能近似全局注意力的限制，实现全局信息交换。
- Method: 结合交错窗口注意力连接远距离标记，深度可分离卷积连接邻近标记。
- Result: 在图像分类（ImageNet-1K上87.4% top-1准确率）、语义分割和视频动作识别任务中表现优异。
- Conclusion: Iwin Transformer的核心组件可作为独立模块替换自注意力模块，为未来研究（如视频生成）提供启发。


### [57] [DCFFSNet: Deep Connectivity Feature Fusion Separation Network for Medical Image Segmentation](https://arxiv.org/abs/2507.18407)
*Xun Ye,Ruixiang Tang,Mingda Zhang,Jianglong Qin*

Main category: cs.CV

TL;DR: DCFFSNet提出了一种新的特征空间解耦策略，动态平衡多尺度特征表达，显著提升了医学图像分割的精度和边缘一致性。

- Motivation: 现有深度网络在整合拓扑连通性时，通常强制将其作为附加特征模块注入，导致特征空间耦合且缺乏量化不同特征强度的标准化机制。
- Method: DCFFSNet引入了特征空间解耦策略，量化连通性特征与其他特征的相对强度，并构建了深度连通性特征融合-分离架构。
- Result: 在ISIC2018、DSB2018和MoNuSeg数据集上，DCFFSNet在Dice和IoU指标上均优于其他主流方法，解决了分割碎片化问题。
- Conclusion: DCFFSNet显著提升了临床实用性，实现了平滑的边缘过渡和更高的分割精度。


### [58] [Self-Supervised Ultrasound-Video Segmentation with Feature Prediction and 3D Localised Loss](https://arxiv.org/abs/2507.18424)
*Edward Ellis,Robert Mendel,Andrew Bulpitt,Nasim Parsa,Michael F Byrne,Sharib Ali*

Main category: cs.CV

TL;DR: 论文提出了一种基于V-JEPA的自监督学习方法，用于超声视频数据的分割任务，并通过引入3D定位辅助任务提升性能。

- Motivation: 超声图像数据获取和标注困难，自监督学习可以利用未标注数据提升分割性能。
- Method: 采用V-JEPA框架，避免像素级重建或负样本，并结合3D定位辅助任务增强ViT的局部性理解。
- Result: 实验表明，该方法显著提升了分割性能，尤其在数据有限的情况下（10%数据提升8.35%）。
- Conclusion: V-JEPA结合3D定位辅助任务是超声视频分割的有效方法，特别适用于小规模医学数据集。


### [59] [NLML-HPE: Head Pose Estimation with Limited Data via Manifold Learning](https://arxiv.org/abs/2507.18429)
*Mahdi Ghafourian,Federico M. Sukno*

Main category: cs.CV

TL;DR: 提出了一种基于非线性流形学习的深度学习方法NLML-HPE，用于有限训练数据下的头部姿态估计，结合张量分解和神经网络，解决了传统分类方法的局限性。

- Motivation: 头部姿态估计在计算机视觉应用中至关重要，但现有数据集标注不准确且训练数据有限，需要一种更高效的方法。
- Method: 通过张量分解将欧拉角分解到不同子空间，并用余弦曲线建模流形，结合神经网络进行回归。生成了精确的2D头部姿态数据集用于训练。
- Result: 方法在有限数据下实现了实时性能，并能准确预测未见数据。
- Conclusion: NLML-HPE在头部姿态估计中表现出色，解决了数据标注和训练数据不足的问题，具有高效性和实用性。


### [60] [DSFormer: A Dual-Scale Cross-Learning Transformer for Visual Place Recognition](https://arxiv.org/abs/2507.18444)
*Haiyang Jiang,Songhao Piao,Chao Gao,Lei Yu,Liguo Chen*

Main category: cs.CV

TL;DR: 提出了一种结合Dual-Scale-Former（DSFormer）和块聚类策略的新框架，用于提升视觉地点识别（VPR）的鲁棒性和计算效率。

- Motivation: 视觉地点识别在移动机器人定位中至关重要，但在环境条件和视角变化下性能不稳定。
- Method: DSFormer通过双向信息传递增强特征表示，块聚类策略优化数据集分区以提升鲁棒性。
- Result: 方法在多个基准数据集上达到最优性能，减少30%训练数据需求，并显著提高计算效率。
- Conclusion: 该框架为VPR提供了鲁棒的全局嵌入解决方案，优于现有方法。


### [61] [PDB-Eval: An Evaluation of Large Multimodal Models for Description and Explanation of Personalized Driving Behavior](https://arxiv.org/abs/2507.18447)
*Junda Wu,Jessica Echterhoff,Kyungtae Han,Amr Abdelraouf,Rohit Gupta,Julian McAuley*

Main category: cs.CV

TL;DR: 论文提出PDB-Eval基准，用于评估多模态大模型（MLLMs）在驾驶行为理解与推理中的表现，包含PDB-X和PDB-QA两部分，显著提升模型在驾驶领域的零样本性能。

- Motivation: 现有数据集在基于外部视觉证据解释驾驶员行为方面有限，需提升驾驶辅助系统的个性化效果。
- Method: 提出PDB-Eval基准，包含PDB-X（评估时间驾驶场景理解）和PDB-QA（视觉解释问答任务），用于MLLM微调。
- Result: 微调后MLLMs在问答任务中零样本性能提升73.2%，在Brain4Cars和AIDE任务中分别提升12.5%和11.0%。
- Conclusion: PDB-Eval能有效缩小MLLMs与驾驶领域的差距，提升模型性能。


### [62] [Revisiting Physically Realizable Adversarial Object Attack against LiDAR-based Detection: Clarifying Problem Formulation and Experimental Protocols](https://arxiv.org/abs/2507.18457)
*Luo Cheng,Hanwei Zhang,Lijun Zhang,Holger Hermanns*

Main category: cs.CV

TL;DR: 提出了一种设备无关的标准化框架，用于物理对抗物体攻击，支持多种方法并提供开源代码与基准测试协议，成功将模拟攻击转移到真实LiDAR系统。

- Motivation: 现有数字攻击缺乏物理可实现性，物理攻击研究不足且重现性差，需标准化框架以推动研究。
- Method: 提出设备无关框架，抽象物理攻击关键要素，支持多种方法，提供开源代码与仿真及真实场景基准测试协议。
- Result: 框架实现公平比较，加速研究，并成功将模拟攻击转移到真实LiDAR系统。
- Conclusion: 框架促进对抗鲁棒性研究，提供攻击成功因素洞察，增进对真实LiDAR感知的理解。


### [63] [CRUISE: Cooperative Reconstruction and Editing in V2X Scenarios using Gaussian Splatting](https://arxiv.org/abs/2507.18473)
*Haoran Xu,Saining Zhang,Peishuo Li,Baijun Ye,Xiaoxue Chen,Huan-ang Gao,Jv Zheng,Xiaowei Song,Ziqiao Peng,Run Miao,Jinrang Jia,Yifeng Shi,Guangqi Yi,Hang Zhao,Hao Tang,Hongyang Li,Kaicheng Yu,Hao Zhao*

Main category: cs.CV

TL;DR: CRUISE是一个用于V2X驾驶环境的综合重建与合成框架，通过分解高斯泼溅技术实现高保真重建和灵活编辑，提升3D检测和跟踪性能，并生成具有挑战性的极端案例。

- Motivation: 探索仿真在V2X场景中数据生成与增强的潜力，填补现有研究的空白。
- Method: 采用分解高斯泼溅技术重建真实场景，支持动态交通参与者的灵活编辑，并从多视角渲染图像以增强数据集。
- Result: CRUISE实现了高保真重建，提升了3D检测和跟踪性能，并能有效生成极端案例。
- Conclusion: CRUISE为V2X场景的数据生成和增强提供了高效解决方案，推动了自动驾驶技术的发展。


### [64] [Q-Former Autoencoder: A Modern Framework for Medical Anomaly Detection](https://arxiv.org/abs/2507.18481)
*Francesco Dalmonte,Emirhan Bayar,Emre Akbas,Mariana-Iuliana Georgescu*

Main category: cs.CV

TL;DR: 提出了一种基于Q-Former Autoencoder的无监督医学异常检测框架，利用预训练视觉基础模型提取特征，无需领域微调，在多个医学异常检测基准上取得最优结果。

- Motivation: 医学图像异常检测因异常多样性和标注数据稀缺而具有挑战性，需开发无需大量标注的无监督方法。
- Method: 使用预训练的视觉基础模型（如DINO、DINOv2）作为特征提取器，结合Q-Former架构控制重建序列长度，并引入感知损失优化重建质量。
- Result: 在BraTS2021、RESC和RSNA等基准测试中达到最优性能，验证了预训练模型在医学图像分析中的泛化能力。
- Conclusion: 预训练视觉基础模型可直接用于医学图像分析，无需微调，为无监督异常检测提供了高效解决方案。


### [65] [A COCO-Formatted Instance-Level Dataset for Plasmodium Falciparum Detection in Giemsa-Stained Blood Smears](https://arxiv.org/abs/2507.18483)
*Frauke Wilm,Luis Carlos Rivera Monroy,Mathias Öttl,Lukas Mürdter,Leonid Mill,Andreas Maier*

Main category: cs.CV

TL;DR: 论文提出了一种改进的疟疾数据集，用于支持深度学习目标检测训练，并通过实验验证了其有效性。

- Motivation: 解决疟疾诊断中因缺乏详细标注数据而限制深度学习应用的问题。
- Method: 增强公开的NIH疟疾数据集，提供详细的COCO格式标注，并训练Faster R-CNN模型进行验证。
- Result: 交叉验证显示，感染细胞检测的F1分数高达0.88。
- Conclusion: 高质量标注数据对提升检测性能至关重要，改进后的数据集已公开。


### [66] [Reinforced Embodied Active Defense: Exploiting Adaptive Interaction for Robust Visual Perception in Adversarial 3D Environments](https://arxiv.org/abs/2507.18484)
*Xiao Yang,Lingxuan Wu,Lizhong Wang,Chengyang Ying,Hang Su,Jun Zhu*

Main category: cs.CV

TL;DR: 提出了Rein-EAD框架，通过主动探索和交互增强3D环境中的感知鲁棒性，显著降低攻击成功率。

- Motivation: 现有防御机制依赖被动策略，难以适应动态3D环境中的对抗攻击。
- Method: 采用多步目标优化和不确定性导向的奖励机制，实现高效策略更新。
- Result: 实验显示攻击成功率显著降低，同时保持标准准确性，并能泛化到未见攻击。
- Conclusion: Rein-EAD适用于复杂任务，如3D分类、人脸识别和自动驾驶。


### [67] [Delving into Mapping Uncertainty for Mapless Trajectory Prediction](https://arxiv.org/abs/2507.18498)
*Zongzheng Zhang,Xuchong Qiu,Boran Zhang,Guantian Zheng,Xunjiang Gu,Guoxuan Chi,Huan-ang Gao,Leichen Wang,Ziming Liu,Xinrun Li,Igor Gilitschenski,Hongyang Li,Hang Zhao,Hao Zhao*

Main category: cs.CV

TL;DR: 论文提出了一种基于车辆运动状态的自适应地图不确定性集成方法，显著提升了无地图轨迹预测性能。

- Motivation: 在线生成的高清地图可靠性不确定，现有方法未能明确不确定性在哪些场景中对轨迹预测有益。
- Method: 提出Proprioceptive Scenario Gating和Covariance-based Map Uncertainty方法，自适应集成地图不确定性。
- Result: 在nuScenes数据集上，性能提升23.6%，优于现有方法。
- Conclusion: 该方法增强了在线地图与轨迹预测的协同性，提供了不确定性优势场景的解释性。


### [68] [Human Scanpath Prediction in Target-Present Visual Search with Semantic-Foveal Bayesian Attention](https://arxiv.org/abs/2507.18503)
*João Luzio,Alexandre Bernardino,Plinio Moreno*

Main category: cs.CV

TL;DR: SemBA-FAST是一个基于语义和贝叶斯概率的注意力模型，用于预测人类视觉搜索任务中的注意力分布，结合深度学习和人工中央凹技术，性能优于基线和其他自上而下方法。

- Motivation: 研究目标是利用深度学习和人类扫描路径数据，开发一种能够模拟人类视觉注意力的模型，以改进目标搜索任务的注意力预测。
- Method: SemBA-FAST结合了深度目标检测和概率语义融合机制，动态生成注意力图，利用预训练检测器和人工中央凹技术更新自上而下的知识。
- Result: 在COCO-Search18数据集上，SemBA-FAST的扫描路径预测与人类真实扫描路径高度匹配，性能优于基线和其他自上而下方法。
- Conclusion: SemBA-FAST展示了语义-中央凹概率框架在模拟人类注意力方面的潜力，对实时认知计算和机器人技术有重要意义。


### [69] [Explaining How Visual, Textual and Multimodal Encoders Share Concepts](https://arxiv.org/abs/2507.18512)
*Clément Cornet,Romaric Besançon,Hervé Le Borgne*

Main category: cs.CV

TL;DR: 提出了一种新的指标，用于跨模态稀疏自编码器（SAE）特征的定量比较，并通过比较视觉、文本和多模态编码器验证其有效性。

- Motivation: 现有研究仅在同一模态内比较SAE特征，缺乏跨模态的定量比较工具。
- Method: 提出新指标和特征共享性量化方法，对21种不同大小和类型的编码器进行比较研究。
- Result: 发现视觉和文本编码器共享某些特征，表明文本预训练对视觉特征的影响。
- Conclusion: 新工具为跨模态模型比较提供了量化支持，揭示了特征共享现象。


### [70] [Towards Large Scale Geostatistical Methane Monitoring with Part-based Object Detection](https://arxiv.org/abs/2507.18513)
*Adhemar de Senneville,Xavier Bou,Thibaud Ehret,Rafael Grompone,Jean Louis Bonne,Nicolas Dumelie,Thomas Lauvaux,Gabriele Facciolo*

Main category: cs.CV

TL;DR: 论文提出了一种基于部件的方法，用于在遥感图像中检测稀有的生物消化器，并构建了甲烷排放的地理统计估计。

- Motivation: 遥感数据量大但稀有目标检测困难，这对评估人类活动的环境影响至关重要。
- Method: 引入新数据集，开发基于部件的方法以增强检测，并应用于新区域构建生物消化器清单。
- Result: 方法成功检测稀有目标，并计算了甲烷排放的地理统计估计。
- Conclusion: 该方法有效解决了遥感数据中稀有目标检测问题，并支持环境影响的量化评估。


### [71] [Object segmentation in the wild with foundation models: application to vision assisted neuro-prostheses for upper limbs](https://arxiv.org/abs/2507.18517)
*Bolutife Atoki,Jenny Benois-Pineau,Renaud Péteri,Fabien Baldacci,Aymar de Rugy*

Main category: cs.CV

TL;DR: 研究利用基础模型进行语义对象分割，提出基于注视点的提示生成方法，改进分割质量。

- Motivation: 探索基础模型在高度杂乱视觉场景中无需微调的分割能力，应用于上肢神经假体的视觉引导。
- Method: 基于注视点生成提示引导Segment Anything Model (SAM)，并在自我中心视觉数据上微调。
- Result: 在真实世界数据上，IoU分割质量指标提升最高达0.51点。
- Conclusion: 提出的方法在复杂场景中有效提升了分割性能，适用于实际应用。


### [72] [GaussianFusionOcc: A Seamless Sensor Fusion Approach for 3D Occupancy Prediction Using 3D Gaussians](https://arxiv.org/abs/2507.18522)
*Tomislav Pavković,Mohammad-Ali Nikouei Mahani,Johannes Niedermayer,Johannes Betz*

Main category: cs.CV

TL;DR: GaussianFusionOcc提出了一种基于3D高斯和传感器融合的语义占用预测方法，提升了精度和效率。

- Motivation: 自动驾驶需要精确的环境理解和导航，传统密集网格方法效率低，多模态传感器融合可提供互补信息。
- Method: 使用3D高斯表示和模态无关的可变形注意力机制，融合相机、LiDAR和雷达数据，优化高斯属性。
- Result: 在多种传感器组合下表现优异，优于现有方法，提升了内存效率和推理速度。
- Conclusion: GaussianFusionOcc通过多模态融合和高斯表示，实现了更高效、精确的语义占用预测。


### [73] [IntentVCNet: Bridging Spatio-Temporal Gaps for Intention-Oriented Controllable Video Captioning](https://arxiv.org/abs/2507.18531)
*Tianheng Qiu,Jingchun Gao,Jingyu Li,Huiyi Leong,Xuan Huang,Xi Wang,Xiaocheng Zhang,Kele Xu,Lan Zhang*

Main category: cs.CV

TL;DR: 论文提出IntentVCNet，通过提示组合策略和参数高效框适配器，增强大型视觉语言模型（LVLM）在视频序列中对空间细节的建模能力，实现意图导向的精细控制视频描述生成。

- Motivation: 现有大型视觉语言模型（LVLM）在时间和空间理解上表现优异，但无法在时间序列中实现精细的空间控制，难以满足用户意图导向的视频描述需求。
- Method: 提出IntentVCNet，结合提示组合策略和参数高效框适配器，前者建模用户意图与视频序列的隐式关系，后者增强全局视觉上下文中的对象语义信息。
- Result: 实验证明该方法显著提升LVLM对视频序列空间细节的建模能力，生成更精准的意图导向描述，并在多个开源LVLM中达到最优效果。
- Conclusion: IntentVCNet通过统一时空理解知识，成功填补了LVLM在意图导向视频描述中的时空鸿沟，为相关任务提供了有效解决方案。


### [74] [COT-AD: Cotton Analysis Dataset](https://arxiv.org/abs/2507.18532)
*Akbar Ali,Mahek Vyas,Soumyaratna Debnath,Chanda Grover Kamra,Jaidev Sanjay Khalane,Reuben Shibu Devanesan,Indra Deep Mastan,Subramanian Sankaranarayanan,Pankaj Khanna,Shanmuganathan Raman*

Main category: cs.CV

TL;DR: COT-AD是一个用于棉花作物分析的计算机视觉数据集，包含25,000多张图像，其中5,000张标注，支持分类、分割、图像恢复等任务。

- Motivation: 解决棉花农业数据集的不足，支持数据驱动的作物管理。
- Method: 通过航空影像和高分辨率DSLR图像收集数据，标注病虫害、植被和杂草。
- Result: COT-AD数据集填补了棉花专用数据集的空白，支持多种计算机视觉任务。
- Conclusion: COT-AD为棉花作物管理提供了全面的数据支持，推动了数据驱动的农业研究。


### [75] [Elucidating the Design Space of Arbitrary-Noise-Based Diffusion Models](https://arxiv.org/abs/2507.18534)
*Xingyu Qiu,Mengying Yang,Xinghua Ma,Dong Liang,Yuzhen Li,Fanding Li,Gongning Luo,Wei Wang,Kuanquan Wang,Shuo Li*

Main category: cs.CV

TL;DR: EDA扩展了扩散模型的噪声模式自由度，解决了EDM中固定高斯噪声的限制，提升了图像恢复性能。

- Motivation: EDM的固定高斯噪声模式限制了图像恢复的进展，强制注入高斯噪声会破坏图像质量并增加恢复复杂性。
- Method: 提出EDA，支持任意噪声模式，保持EDM模块灵活性，且不增加计算开销。
- Result: EDA在MRI偏置场校正、CT金属伪影减少和自然图像阴影去除任务中表现优异，仅需5步采样即可超越多数专用方法。
- Conclusion: EDA通过扩展噪声模式自由度，显著提升了扩散模型在图像恢复任务中的性能。


### [76] [TTS-VAR: A Test-Time Scaling Framework for Visual Auto-Regressive Generation](https://arxiv.org/abs/2507.18537)
*Zhekai Chen,Ruihang Chu,Yukang Chen,Shiwei Zhang,Yujie Wei,Yingya Zhang,Xihui Liu*

Main category: cs.CV

TL;DR: TTS-VAR是一个通用的测试时扩展框架，用于视觉自回归模型，通过动态平衡计算效率和探索能力，显著提升了生成质量。

- Motivation: 解决视觉生成模型在训练和计算资源上的高成本问题，同时提升测试时的性能和效率。
- Method: 将生成过程建模为路径搜索问题，引入自适应批量大小调度，结合聚类多样性搜索和基于重采样的潜力选择。
- Result: 在Infinity模型上实现了8.7%的GenEval分数提升（从0.69到0.75）。
- Conclusion: 早期结构特征对最终质量有显著影响，不同生成阶段的采样策略需灵活调整。


### [77] [Unposed 3DGS Reconstruction with Probabilistic Procrustes Mapping](https://arxiv.org/abs/2507.18541)
*Chong Cheng,Zijian Wang,Sicheng Yu,Yu Hu,Nanjie Yao,Hao Wang*

Main category: cs.CV

TL;DR: 提出了一种新颖的无姿态3D高斯泼溅重建框架，结合预训练MVS先验和概率Procrustes映射策略，解决了现有方法在大规模户外图像重建中的内存和精度问题。

- Motivation: 现有基于MVS的3D高斯泼溅方法在无姿态重建任务中面临内存限制和精度下降的问题，尤其是在大规模户外图像场景下。
- Method: 将输入图像划分为子集，通过概率Procrustes映射将子图对齐到全局空间，并联合优化几何和姿态；使用软垃圾桶机制剔除不确定对应关系，并通过联合优化框架结合3DGS和相机姿态。
- Result: 在Waymo和KITTI数据集上实现了高精度的无姿态重建，成为当前无姿态3DGS重建的最先进方法。
- Conclusion: 提出的方法有效解决了大规模无姿态图像序列的重建问题，为3D高斯泼溅技术提供了新的解决方案。


### [78] [A 3D Cross-modal Keypoint Descriptor for MR-US Matching and Registration](https://arxiv.org/abs/2507.18551)
*Daniil Morozov,Reuben Dorent,Nazim Haouchine*

Main category: cs.CV

TL;DR: 提出了一种新型3D跨模态关键点描述符，用于MRI和实时超声（iUS）的匹配与配准，通过患者特定的合成训练和对比学习，显著提升了配准精度。

- Motivation: 解决MRI和iUS因模态差异导致的配准难题，提升手术中的实时导航精度。
- Method: 采用患者特定的合成iUS数据训练对比学习模型，结合概率关键点检测和动态硬负样本挖掘的三重损失函数。
- Result: 在ReMIND数据集上，关键点匹配平均精度达69.8%，配准误差为2.39 mm，优于现有方法。
- Conclusion: 该方法无需手动初始化，对iUS视野变化鲁棒，代码已开源。


### [79] [VideoMind: An Omni-Modal Video Dataset with Intent Grounding for Deep-Cognitive Video Understanding](https://arxiv.org/abs/2507.18552)
*Baoyao Yang,Wanyun Li,Dixin Chen,Junxiang Chen,Wenbin Yao,Haifeng Lin*

Main category: cs.CV

TL;DR: VideoMind是一个视频为中心的全模态数据集，用于深度视频内容认知和多模态特征表示增强。它包含103K视频样本，每个样本配有音频和分层文本描述（事实、抽象、意图）。数据集通过Chain-of-Thought方法生成意图表达，并支持下游识别任务。

- Motivation: 现有数据集缺乏深度认知表达（如意图），VideoMind填补了这一空白，旨在推动深度视频理解领域的发展。
- Method: 数据集包含103K视频样本，每个样本配有音频和三层文本描述（事实、抽象、意图）。意图表达通过Chain-of-Thought方法生成，并标注了主题、地点、时间等。
- Result: 建立了包含3,000手动验证样本的黄金标准基准，用于评估深度视频理解。实验结果显示模型（如InternVideo）在深度认知任务中的表现。
- Conclusion: VideoMind是一个强大的基准数据集，推动了细粒度跨模态对齐和深度视频理解领域的发展，数据已公开。


### [80] [Synthetic Data Augmentation for Enhanced Chicken Carcass Instance Segmentation](https://arxiv.org/abs/2507.18558)
*Yihong Feng,Chaitanya Pallerla,Xiaomin Lin,Pouya Sohrabipour Sr,Philip Crandall,Wan Shou,Yu She,Dongyi Wang*

Main category: cs.CV

TL;DR: 论文提出了一种生成逼真合成图像并自动标注的流程，用于解决禽类加工行业中鸡胴体实例分割的数据稀缺问题。通过结合合成数据和真实数据，显著提升了分割性能。

- Motivation: 禽类加工行业需要高效的自动化检测系统，但真实数据的获取和标注成本高昂。合成数据和自动标注可以缓解这一问题。
- Method: 提出生成合成图像并自动标注的流程，结合真实数据集，评估不同比例合成数据对实例分割模型的影响。
- Result: 合成数据显著提升了鸡胴体实例分割的性能，证明了其在数据稀缺情况下的有效性。
- Conclusion: 合成数据增强是一种可行且有效的策略，可以减少人工标注需求，推动禽类加工行业的自动化检测系统发展。


### [81] [Deep Learning-Based Age Estimation and Gender Deep Learning-Based Age Estimation and Gender Classification for Targeted Advertisement](https://arxiv.org/abs/2507.18565)
*Muhammad Imran Zaman,Nisar Ahmed*

Main category: cs.CV

TL;DR: 提出一种基于深度学习的联合年龄和性别分类方法，通过共享表征提升性能，实验结果显示性别分类准确率95%，年龄估计平均绝对误差5.77岁。

- Motivation: 提升定向广告效果，利用面部特征中年龄与性别的相关性，改进现有独立处理任务的方法。
- Method: 设计定制CNN架构，联合学习年龄和性别任务，使用大型多样化数据集，并进行预处理以增强鲁棒性。
- Result: 性别分类准确率95%，年龄估计误差5.77岁，发现年轻群体年龄估计的挑战。
- Conclusion: 需针对性数据增强和模型优化以解决偏差，不同CNN架构和超参数对性能的影响为未来研究提供参考。


### [82] [Facial Demorphing from a Single Morph Using a Latent Conditional GAN](https://arxiv.org/abs/2507.18566)
*Nitish Shukla,Arun Ross*

Main category: cs.CV

TL;DR: 提出了一种新的去变形方法，解决了现有方法在变形复制和依赖相同变形技术的问题，能够处理未知变形技术和人脸风格。

- Motivation: 现有去变形方法存在变形复制问题，且假设训练和测试使用相同变形技术，限制了实际应用。
- Method: 在潜在空间分解变形图像，支持处理未知变形技术和人脸风格，训练基于合成人脸，测试基于真实人脸。
- Result: 方法显著优于现有技术，生成高保真去变形人脸图像。
- Conclusion: 该方法为变形攻击检测提供了更可靠的证据，解决了现有方法的局限性。


### [83] [Adversarial Distribution Matching for Diffusion Distillation Towards Efficient Image and Video Synthesis](https://arxiv.org/abs/2507.18569)
*Yanzuo Lu,Yuxi Ren,Xin Xia,Shanchuan Lin,Xing Wang,Xuefeng Xiao,Andy J. Ma,Xiaohua Xie,Jian-Huang Lai*

Main category: cs.CV

TL;DR: DMDX通过对抗性蒸馏预训练和ADM微调，显著提升了一步生成性能，并在图像和视频合成中设定了新基准。

- Motivation: 解决DMD中反向KL散度最小化导致的模式崩溃问题，提出更高效的蒸馏方法。
- Method: 结合对抗性蒸馏预训练（混合判别器）和ADM微调（扩散判别器对齐潜在预测）。
- Result: 在SDXL上优于DMD2，GPU时间更少；在SD3-Medium、SD3.5-Large和CogVideoX上设定了新基准。
- Conclusion: DMDX通过对抗性方法有效解决了模式崩溃问题，提升了蒸馏效率和生成质量。


### [84] [HybridTM: Combining Transformer and Mamba for 3D Semantic Segmentation](https://arxiv.org/abs/2507.18575)
*Xinyu Wang,Jinghua Hou,Zhe Liu,Yingying Zhu*

Main category: cs.CV

TL;DR: HybridTM结合Transformer和Mamba，提出首个混合架构用于3D语义分割，通过Inner Layer Hybrid Strategy同时捕捉长程依赖和局部特征，在多个数据集上达到SOTA性能。

- Motivation: Transformer在3D语义分割中表现优异但计算复杂度高，Mamba计算高效但特征提取能力不足，结合二者优势是当前挑战。
- Method: 提出HybridTM混合架构及Inner Layer Hybrid Strategy，在更细粒度上结合注意力与Mamba。
- Result: 在ScanNet、ScanNet200和nuScenes等数据集上实现SOTA性能。
- Conclusion: HybridTM有效结合Transformer和Mamba的优势，解决了长程依赖和局部特征提取问题，具有广泛适用性。


### [85] [DRWKV: Focusing on Object Edges for Low-Light Image Enhancement](https://arxiv.org/abs/2507.18594)
*Xuecheng Bai,Yuxiang Wang,Boyu Hu,Qinyuan Jie,Chuanzhi Xu,Hongru Xiao,Kechen Li,Vera Chung*

Main category: cs.CV

TL;DR: DRWKV模型通过GER理论、Evolving WKV Attention和Bi-SAB模块，有效提升低光图像增强的边缘保真度和视觉自然性，并在多个基准测试中表现优异。

- Motivation: 解决低光图像增强中边缘连续性和结构细节保留的挑战。
- Method: 结合GER理论、Evolving WKV Attention机制和Bi-SAB模块，设计MS2-Loss。
- Result: 在PSNR、SSIM和NIQE指标上领先，计算复杂度低，且提升下游任务性能。
- Conclusion: DRWKV在低光图像增强中表现出色，具有泛化能力。


### [86] [SynC: Synthetic Image Caption Dataset Refinement with One-to-many Mapping for Zero-shot Image Captioning](https://arxiv.org/abs/2507.18616)
*Si-Woo Kim,MinJu Jeon,Ye-Chan Kim,Soeun Lee,Taewhan Kim,Dong-Jin Kim*

Main category: cs.CV

TL;DR: SynC框架通过重新分配语义对齐的图片-标题对，优化零样本图像描述（ZIC）中的合成数据集，显著提升模型性能。

- Motivation: 解决文本到图像（T2I）模型生成的合成数据中图片与标题语义不对齐的问题，现有方法不适用于此类噪声。
- Method: 提出SynC框架，采用一对多映射策略和循环一致性对齐评分器，重新分配标题到最匹配的图片。
- Result: 在多个标准基准测试（MS-COCO、Flickr30k、NoCaps）上显著提升ZIC模型性能，达到最优结果。
- Conclusion: SynC为优化合成数据提供了一种有效策略，可显著提升零样本图像描述任务的性能。


### [87] [3D Software Synthesis Guided by Constraint-Expressive Intermediate Representation](https://arxiv.org/abs/2507.18625)
*Shuqing Li,Anson Y. Lam,Yun Peng,Wenxuan Wang,Michael R. Lyu*

Main category: cs.CV

TL;DR: Scenethesis是一种新的3D软件合成方法，通过ScenethesisLang语言实现用户需求与生成软件之间的形式化追溯，支持细粒度修改和复杂空间约束表达。

- Motivation: 现有3D软件生成方法无法修改特定元素或处理复杂空间语义约束，Scenethesis旨在解决这些问题。
- Method: 基于ScenethesisLang语言，将3D软件合成分解为多个阶段，支持独立验证、目标修改和系统约束满足。
- Result: Scenethesis准确捕捉80%以上用户需求，满足90%以上硬约束，同时处理100多个约束，视觉评估分数提升42.8%。
- Conclusion: Scenethesis在3D软件生成中表现出色，解决了现有方法的局限性。


### [88] [SIDA: Synthetic Image Driven Zero-shot Domain Adaptation](https://arxiv.org/abs/2507.18632)
*Ye-Chan Kim,SeungJu Cha,Si-Woo Kim,Taewhan Kim,Dong-Jin Kim*

Main category: cs.CV

TL;DR: 论文提出了一种名为SIDA的新方法，利用合成图像实现高效的零样本域适应，解决了现有文本驱动方法在捕捉复杂现实变化和效率上的不足。

- Motivation: 现有基于文本描述的零样本域适应方法难以捕捉复杂现实变化且效率低下，因此探索利用图像数据提供更细粒度的风格线索。
- Method: 通过生成合成图像（源图像经风格转换）作为目标域代理，引入Domain Mix和Patch Style Transfer模块建模现实变化。
- Result: 在多种零样本适应场景中表现优异，尤其在挑战性领域，且显著减少了适应时间。
- Conclusion: SIDA方法通过合成图像和高效模块设计，实现了更优的零样本域适应性能和效率。


### [89] [Identifying Prompted Artist Names from Generated Images](https://arxiv.org/abs/2507.18633)
*Grace Su,Sheng-Yu Wang,Aaron Hertzmann,Eli Shechtman,Jun-Yan Zhu,Richard Zhang*

Main category: cs.CV

TL;DR: 论文提出了一个基准测试，用于通过图像识别被提示的艺术家名称，并评估了多种方法在不同设置下的表现。

- Motivation: 研究文本到图像模型中明确命名艺术家生成图片的争议性使用，并提供一个基准测试以促进负责任的模型调节。
- Method: 构建包含110位艺术家的1.95M图像数据集，评估特征相似性基线、对比风格描述符、数据归因方法、监督分类器和少样本原型网络。
- Result: 监督和少样本模型在已知艺术家和复杂提示上表现优异，风格描述符在艺术家风格明显时表现更好，多艺术家提示最具挑战性。
- Conclusion: 基准测试揭示了改进空间，并提供了公开数据集和测试平台以推动进一步研究。


### [90] [Captain Cinema: Towards Short Movie Generation](https://arxiv.org/abs/2507.18634)
*Junfei Xiao,Ceyuan Yang,Lvmin Zhang,Shengqu Cai,Yang Zhao,Yuwei Guo,Gordon Wetzstein,Maneesh Agrawala,Alan Yuille,Lu Jiang*

Main category: cs.CV

TL;DR: Captain Cinema是一个用于生成短电影的框架，通过关键帧规划和视频合成实现叙事连贯和视觉一致。

- Motivation: 解决长叙事电影生成中的连贯性和视觉一致性问题。
- Method: 采用自上而下的关键帧规划和自下而上的视频合成方法，结合多模态扩散变换器（MM-DiT）进行训练。
- Result: 实验表明，Captain Cinema能够高效生成视觉连贯且叙事一致的短电影。
- Conclusion: 该框架为高质量短电影生成提供了有效解决方案。
## cs.GR

### [91] [Zero-Shot Dynamic Concept Personalization with Grid-Based LoRA](https://arxiv.org/abs/2507.17963)
*Rameen Abdal,Or Patashnik,Ekaterina Deyneka,Hao Chen,Aliaksandr Siarohin,Sergey Tulyakov,Daniel Cohen-Or,Kfir Aberman*

Main category: cs.GR

TL;DR: 提出了一种零样本框架，用于文本到视频模型中的动态概念个性化，无需实例微调，通过结构化视频网格和轻量级适配器实现高效编辑和合成。

- Motivation: 现有方法需要针对每个实例进行微调，限制了可扩展性，因此需要一种零样本的解决方案。
- Method: 利用结构化2x2视频网格组织输入输出对，训练轻量级Grid-LoRA适配器，并通过Grid Fill模块完成部分观察的布局。
- Result: 实验表明，该方法在未见过的动态概念和编辑场景中均能产生高质量且一致的结果。
- Conclusion: 该方法在单次前向传播中完成操作，无需测试时优化，具有广泛适用性。


### [92] [GeoAvatar: Adaptive Geometrical Gaussian Splatting for 3D Head Avatar](https://arxiv.org/abs/2507.18155)
*SeungJun Moon,Hah Min Lew,Seungeun Lee,Ji-Su Kang,Gyeong-Moon Park*

Main category: cs.GR

TL;DR: GeoAvatar提出了一种自适应几何高斯泼溅框架，通过APS分割高斯点、改进嘴部结构和变形策略，提升3D头像生成的质量和动画保真度。

- Motivation: 现有方法在3D头像生成中难以平衡身份重建与新颖姿态和表情的动画效果，导致质量不佳。
- Method: 提出GeoAvatar框架，包括APS分割高斯点、改进嘴部结构和变形策略，以及正则化损失。
- Result: 实验表明GeoAvatar在重建和新动画场景中优于现有方法。
- Conclusion: GeoAvatar通过自适应几何高斯泼溅和嘴部优化，显著提升了3D头像生成的质量和动画效果。


### [93] [PS-GS: Gaussian Splatting for Multi-View Photometric Stereo](https://arxiv.org/abs/2507.18231)
*Yixiao Chen,Bin Liang,Hanzhi Guo,Yongqing Cheng,Jiayi Zhao,Dongdong Weng*

Main category: cs.GR

TL;DR: 提出了一种结合多视角光度立体（MVPS）的高斯溅射方法（PS-GS），用于高效联合估计几何、材质和光照，显著提升了3D重建的精度和效率。

- Motivation: 现有基于固定环境光照的逆渲染方法在多视角光度立体（MVPS）下重建精度不足，且效率较低。
- Method: 首先构建2D高斯溅射模型作为初始几何，随后通过包含光照计算多层感知机的完整渲染方程进行逆渲染，并利用未标定的光度立体法估计法线进行正则化。
- Result: 在合成和真实数据集上的实验表明，该方法在重建精度和计算效率上优于现有方法。
- Conclusion: PS-GS方法有效解决了逆渲染的病态问题，支持新视角合成、重光照及材质形状编辑。
## physics.med-ph

### [94] [Diffusion-Assisted Frequency Attention Model for Whole-body Low-field MRI Reconstruction](https://arxiv.org/abs/2507.17764)
*Xin Xie,Yu Guan,Zhuoxu Cui,Dong Liang,Qiegen Liu*

Main category: physics.med-ph

TL;DR: DFAM结合扩散模型和频域注意力，显著提升低信噪比条件下的重建性能，优于传统和基于学习的方法。

- Motivation: 解决低场MRI重建在资源受限或欠发达临床环境中的挑战。
- Method: 整合扩散模型的生成能力和频域注意力的表示能力。
- Result: 实验显示DFAM在低信噪比条件下优于其他方法。
- Conclusion: DFAM是低场MRI重建的有前景解决方案。
## cs.RO

### [95] [Evaluation of facial landmark localization performance in a surgical setting](https://arxiv.org/abs/2507.18248)
*Ines Frajtag,Marko Švaco,Filip Šuligoj*

Main category: cs.RO

TL;DR: 论文测试了MediaPipe算法在手术灯光下检测面部标志的准确性，发现其在大角度偏转时性能提升，但存在标志检测不精确的问题。

- Motivation: 解决面部检测算法在医学应用中因光线和位置变化导致的挑战。
- Method: 使用机器人手臂自动调整位置，在固定手术灯光和模型下测试MediaPipe算法。
- Result: 手术灯光下检测准确性提高，但大角度时标准偏差增加。
- Conclusion: MediaPipe算法有潜力整合到医疗程序中，但需改进标志检测精度。


### [96] [ReSem3D: Refinable 3D Spatial Constraints via Fine-Grained Semantic Grounding for Generalizable Robotic Manipulation](https://arxiv.org/abs/2507.18262)
*Chenyu Su,Weiwei Shang,Chen Qian,Fei Zhang,Shuang Cong*

Main category: cs.RO

TL;DR: ReSem3D框架通过结合MLLMs和VFMs，实现细粒度视觉定位和动态3D空间约束，解决现有方法在语义多样性环境中的局限性。

- Motivation: 现有方法在语义建模粒度、实时闭环规划和鲁棒性方面存在不足，需改进以适应多样化环境。
- Method: 利用MLLMs和VFMs的协同作用，分阶段（部件级提取和区域级细化）构建3D空间约束，并编码为实时优化目标。
- Result: 在模拟和真实环境中验证，ReSem3D在零样本条件下表现出强适应性和泛化能力。
- Conclusion: ReSem3D为语义多样性环境提供了一种统一的机器人操作框架，具有实际应用潜力。


### [97] [Adaptive Articulated Object Manipulation On The Fly with Foundation Model Reasoning and Part Grounding](https://arxiv.org/abs/2507.18276)
*Xiaojie Zhang,Yuanfei Wang,Ruihai Wu,Kunqi Xu,Yu Li,Liuyu Xiang,Hao Dong,Zhaofeng He*

Main category: cs.RO

TL;DR: AdaRPG框架利用基础模型提取物体部件，增强视觉感知和操作策略的泛化能力，解决了铰接物体操纵中的几何多样性和功能差异问题。

- Motivation: 铰接物体的内部结构不可直接观察，且几何多样性和功能差异导致现有方法难以实现跨类别泛化。
- Method: 提出AdaRPG框架，通过基础模型提取部件级几何信息，构建部件级功能标注数据集，并基于部件功能推理生成高层控制代码。
- Result: 仿真和实际实验表明，AdaRPG在新型铰接物体类别上表现出强大的泛化能力。
- Conclusion: AdaRPG通过部件级感知和功能推理，显著提升了铰接物体操纵的适应性和泛化能力。
## cs.AI

### [98] [On the Performance of Concept Probing: The Influence of the Data (Extended Version)](https://arxiv.org/abs/2507.18550)
*Manuel de Sousa Ribeiro,Afonso Leote,João Leite*

Main category: cs.AI

TL;DR: 本文探讨了概念探测中训练数据对性能的影响，并提供了两个常用数据集的标签。

- Motivation: 概念探测用于解释神经网络，但现有研究忽视了训练数据对探测模型性能的影响。
- Method: 研究聚焦图像分类任务，分析训练数据对概念探测模型的影响。
- Result: 揭示了训练数据对探测模型性能的重要性，并公开了两个数据集的标签。
- Conclusion: 训练数据是概念探测的关键因素，未来研究应更多关注数据选择。


### [99] [SafeWork-R1: Coevolving Safety and Intelligence under the AI-45$^{\circ}$ Law](https://arxiv.org/abs/2507.18576)
*Shanghai AI Lab,:,Yicheng Bao,Guanxu Chen,Mingkang Chen,Yunhao Chen,Chiyu Chen,Lingjie Chen,Sirui Chen,Xinquan Chen,Jie Cheng,Yu Cheng,Dengke Deng,Yizhuo Ding,Dan Ding,Xiaoshan Ding,Yi Ding,Zhichen Dong,Lingxiao Du,Yuyu Fan,Xinshun Feng,Yanwei Fu,Yuxuan Gao,Ruijun Ge,Tianle Gu,Lujun Gui,Jiaxuan Guo,Qianxi He,Yuenan Hou,Xuhao Hu,Hong Huang,Kaichen Huang,Shiyang Huang,Yuxian Jiang,Shanzhe Lei,Jie Li,Lijun Li,Hao Li,Juncheng Li,Xiangtian Li,Yafu Li,Lingyu Li,Xueyan Li,Haotian Liang,Dongrui Liu,Qihua Liu,Zhixuan Liu,Bangwei Liu,Huacan Liu,Yuexiao Liu,Zongkai Liu,Chaochao Lu,Yudong Lu,Xiaoya Lu,Zhenghao Lu,Qitan Lv,Caoyuan Ma,Jiachen Ma,Xiaoya Ma,Zhongtian Ma,Lingyu Meng,Ziqi Miao,Yazhe Niu,Yuezhang Peng,Yuan Pu,Han Qi,Chen Qian,Xingge Qiao,Jingjing Qu,Jiashu Qu,Wanying Qu,Wenwen Qu,Xiaoye Qu,Qihan Ren,Qingnan Ren,Qingyu Ren,Jing Shao,Wenqi Shao,Shuai Shao,Dongxing Shi,Xin Song,Xinhao Song,Yan Teng,Xuan Tong,Yingchun Wang,Xuhong Wang,Shujie Wang,Xin Wang,Yige Wang,Yixu Wang,Yuanfu Wang,Futing Wang,Ruofan Wang,Wenjie Wang,Yajie Wang,Muhao Wei,Xiaoyu Wen,Fenghua Weng,Yuqi Wu,Yingtong Xiong,Xingcheng Xu,Chao Yang,Yue Yang,Yang Yao,Yulei Ye,Zhenyun Yin,Yi Yu,Bo Zhang,Qiaosheng Zhang,Jinxuan Zhang,Yexin Zhang,Yinqiang Zheng,Hefeng Zhou,Zhanhui Zhou,Pengyu Zhu,Qingzi Zhu,Yubo Zhu,Bowen Zhou*

Main category: cs.AI

TL;DR: SafeWork-R1是一种多模态推理模型，通过SafeLadder框架实现能力与安全性的协同进化，显著提升安全性表现。

- Motivation: 解决传统对齐方法（如RLHF）仅学习人类偏好的局限性，开发具有内在安全推理和自我反思能力的模型。
- Method: 采用SafeLadder框架，结合大规模渐进式安全导向的强化学习后训练和多原则验证器。
- Result: 在安全相关基准测试中平均提升46.54%，优于GPT-4.1和Claude Opus 4，同时保持通用能力。
- Conclusion: SafeLadder框架证明安全性与能力可以协同进化，适用于构建稳健、可靠、可信的通用AI。
## cs.DC

### [100] [Caching Techniques for Reducing the Communication Cost of Federated Learning in IoT Environments](https://arxiv.org/abs/2507.17772)
*Ahmad Alhonainy,Praveen Rao*

Main category: cs.DC

TL;DR: 本文提出了一种在联邦学习中通过缓存策略（FIFO、LRU和基于优先级）减少不必要模型更新传输的方法，以降低通信成本，同时保持模型准确性。实验表明，该方法在CIFAR-10和医疗数据集上减少了通信量且精度损失极小。

- Motivation: 联邦学习（FL）在分布式设备上训练共享模型时，通信成本是主要瓶颈，尤其在资源受限环境中。
- Method: 引入缓存策略（FIFO、LRU和基于优先级）选择性转发重要模型更新，以减少带宽使用。
- Result: 实验结果显示通信量减少且精度损失极小，验证了智能缓存在边缘物联网网络中的可扩展性和内存效率。
- Conclusion: 该方法为智能城市、医疗等延迟敏感应用提供了实用的联邦学习部署方案。
## q-bio.NC

### [101] [Multimodal Recurrent Ensembles for Predicting Brain Responses to Naturalistic Movies (Algonauts 2025)](https://arxiv.org/abs/2507.17897)
*Semih Eren,Deniz Kucukahmetler,Nico Scherf*

Main category: q-bio.NC

TL;DR: 论文提出了一种层次化多模态循环集成模型，用于预测大脑皮层对自然刺激的分布式响应，融合了视觉、听觉和语义信息。

- Motivation: 准确预测大脑皮层对自然刺激的响应需要整合多模态信息的模型。
- Method: 使用预训练的视频、音频和语言嵌入，通过双向RNN编码时间动态，融合后传递到第二层循环层，并通过轻量级个体化头部输出响应。
- Result: 模型在Algonauts 2025挑战中排名第三，整体Pearson r=0.2094，部分区域表现最佳（r=0.63）。
- Conclusion: 该方法为未来多模态大脑编码基准提供了简单且可扩展的基线。
## cs.CL

### [102] [GrAInS: Gradient-based Attribution for Inference-Time Steering of LLMs and VLMs](https://arxiv.org/abs/2507.18043)
*Duy Nguyen,Archiki Prasad,Elias Stengel-Eskin,Mohit Bansal*

Main category: cs.CL

TL;DR: GrAInS是一种基于梯度的推理时引导方法，通过识别关键输入标记并构建方向性引导向量，优化语言和视觉语言模型的行为，无需微调。

- Motivation: 现有推理时引导方法依赖固定干预向量，忽视输入标记的因果影响，且未充分利用多模态梯度信息。GrAInS旨在解决这些问题。
- Method: GrAInS利用对比梯度归因识别关键标记，构建方向性引导向量，并在推理时调整隐藏激活，同时归一化以保持表示规模。
- Result: GrAInS在TruthfulQA上提升13.22%准确率，在MMHal-Bench上减少幻觉率，在SPA-VL上提高对齐胜率8.11%。
- Conclusion: GrAInS提供细粒度、可解释的模型行为控制，优于微调和现有引导方法，同时保持模型流畅性和通用能力。
## cs.LG

### [103] [Enhancing Quantization-Aware Training on Edge Devices via Relative Entropy Coreset Selection and Cascaded Layer Correction](https://arxiv.org/abs/2507.17768)
*Yujia Tong,Jingling Yuan,Chuang Hu*

Main category: cs.LG

TL;DR: QuaRC是一种在边缘设备上结合核心集选择和量化感知训练的框架，通过相对熵分数和层间校正策略减少量化误差，显著提升低比特量化模型的性能。

- Motivation: 边缘设备上低比特量化模型的需求增加，但隐私问题限制了数据使用，传统量化感知训练计算成本高，且核心集选择方法在小规模数据上表现不佳。
- Method: 提出QuaRC框架，分两阶段：1) 使用相对熵分数选择核心集；2) 采用层间校正策略对齐量化模型和全精度模型的中间层输出。
- Result: 在ImageNet-1K数据集上，2-bit量化的ResNet-18使用1%数据子集时，Top-1准确率比现有技术提升5.72%。
- Conclusion: QuaRC有效解决了小规模数据下的量化误差问题，显著提升了边缘设备上量化模型的性能。


### [104] [VIBE: Video-Input Brain Encoder for fMRI Response Modeling](https://arxiv.org/abs/2507.17958)
*Daniel Carlstrom Schad,Shrey Dixit,Janis Keck,Viktor Studenyak,Aleksandr Shpilevoi,Andrej Bicanski*

Main category: cs.LG

TL;DR: VIBE是一个两阶段Transformer模型，融合多模态视频、音频和文本特征预测fMRI活动，性能显著提升。

- Motivation: 通过融合多模态特征（视频、音频、文本）来更准确地预测fMRI活动，提升模型在分布内和分布外数据上的表现。
- Method: 使用开源模型提取特征，通过模态融合Transformer合并特征，再通过带有旋转嵌入的预测Transformer进行时序解码。
- Result: 在CNeuroMod数据集上训练，性能显著优于早期版本，在Algonauts 2025挑战赛中表现优异。
- Conclusion: VIBE展示了多模态融合在fMRI预测中的有效性，为未来研究提供了新方向。


### [105] [ChronoSelect: Robust Learning with Noisy Labels via Dynamics Temporal Memory](https://arxiv.org/abs/2507.18183)
*Jianchao Wang,Qingfeng Li,Pengcheng Zheng,Xiaorong Pu,Yazhou Ren*

Main category: cs.LG

TL;DR: ChronoSelect是一个新颖的框架，通过四阶段内存架构和滑动更新机制，动态分析样本的时序轨迹，将样本划分为干净、边界和噪声子集，显著提升了噪声标签下的模型性能。

- Motivation: 现实数据集中噪声标签的存在会损害深度神经网络的泛化性能，现有方法未能充分利用学习演化的时序动态。
- Method: 提出ChronoSelect框架，采用四阶段内存架构和滑动更新机制，压缩预测历史为紧凑的时序分布，并通过双分支一致性进行样本划分。
- Result: 理论证明框架在噪声条件下的收敛性和稳定性，实验验证其在合成和真实数据集上的先进性能。
- Conclusion: ChronoSelect通过动态时序分析有效解决了噪声标签问题，为相关领域提供了新思路。
## eess.IV

### [106] [Improving Multislice Electron Ptychography with a Generative Prior](https://arxiv.org/abs/2507.17800)
*Christian K. Belardi,Chia-Hao Lee,Yingheng Wang,Justin Lovelace,Kilian Q. Weinberger,David A. Muller,Carla P. Gomes*

Main category: eess.IV

TL;DR: MEP-Diffusion是一种基于扩散模型的生成先验方法，用于增强多片电子ptychography（MEP）的重建质量，显著优于现有方法。

- Motivation: 现有MEP重建算法耗时且效果不佳，需要一种更高效且高质量的重建方法。
- Method: 开发了MEP-Diffusion，一种基于扩散模型的生成先验，通过扩散后验采样（DPS）与现有迭代求解器结合。
- Result: 该方法显著提升了3D重建质量，SSIM指标提高了90.50%。
- Conclusion: MEP-Diffusion是一种高效且高质量的重建方法，适用于MEP技术。


### [107] [Towards Robust Foundation Models for Digital Pathology](https://arxiv.org/abs/2507.17845)
*Jonah Kömen,Edwin D. de Jong,Julius Hense,Hannah Marienwald,Jonas Dippel,Philip Naumann,Eric Marcus,Lukas Ruff,Maximilian Alber,Jonas Teuwen,Frederick Klauschen,Klaus-Robert Müller*

Main category: eess.IV

TL;DR: 该论文研究了生物医学基础模型（FMs）对非生物技术特征的鲁棒性，提出了PathoROB基准和框架，以减少临床部署中的风险。

- Motivation: 生物医学FMs在临床应用中可能因学习非生物特征（如手术技术、实验室程序等）而产生风险，需系统评估其鲁棒性。
- Method: 开发了PathoROB基准，包含三个新指标和四个数据集，评估了20种FMs的鲁棒性，并提出鲁棒化框架。
- Result: 实验显示所有FMs均存在鲁棒性缺陷，非鲁棒性可能导致诊断错误；鲁棒化方法显著降低了风险。
- Conclusion: 鲁棒性评估是临床验证FMs的关键，未来开发需将鲁棒性作为核心设计原则，PathoROB为跨领域评估提供了蓝图。


### [108] [Integrating Feature Selection and Machine Learning for Nitrogen Assessment in Grapevine Leaves using In-Field Hyperspectral Imaging](https://arxiv.org/abs/2507.17869)
*Atif Bilal Asad,Achyut Paudel,Safal Kshetri,Chenchen Kang,Salik Ram Khanal,Nataliya Shcherbatyuk,Pierre Davadant,R. Paul Schreiner,Santosh Kalauni,Manoj Karkee,Markus Keller*

Main category: eess.IV

TL;DR: 研究利用高光谱图像和机器学习模型预测葡萄叶和冠层的氮浓度，确定了关键光谱区域，并展示了该方法在葡萄园氮状态监测中的潜力。

- Motivation: 葡萄园中氮的高时空变异性需要精确估计叶和冠层的氮浓度，以优化施肥管理。
- Method: 使用400-1000nm高光谱图像，结合特征选择方法和机器学习模型（Gradient Boosting和XGBoost）预测氮浓度。
- Result: 模型在冠层和叶级数据上的R平方分别为0.49和0.57，确定了500-525nm、650-690nm、750-800nm和900-950nm等关键光谱区域。
- Conclusion: 高光谱成像结合特征选择和机器学习技术可用于葡萄园氮状态监测。


### [109] [Hierarchical Diffusion Framework for Pseudo-Healthy Brain MRI Inpainting with Enhanced 3D Consistency](https://arxiv.org/abs/2507.17911)
*Dou Hoon Kwark,Shirui Luo,Xiyue Zhu,Yudu Li,Zhi-Pei Liang,Volodymyr Kindratenko*

Main category: eess.IV

TL;DR: 提出了一种分层扩散框架，通过两个垂直的2D阶段（轴向和冠状）实现伪健康MRI图像修复，平衡数据效率和体积一致性。

- Motivation: 当前2D模型在MRI修复中存在体积不连续问题，而3D模型需要大量训练数据。
- Method: 采用轴向扩散模型进行粗修复，冠状扩散模型细化细节，结合自适应重采样。
- Result: 在真实感和体积一致性上优于现有方法。
- Conclusion: 该方法为伪健康MRI图像修复提供了高效且一致的解决方案。


### [110] [Benchmarking of Deep Learning Methods for Generic MRI Multi-OrganAbdominal Segmentation](https://arxiv.org/abs/2507.17971)
*Deepa Krishnaswamy,Cosmin Ciausu,Steve Pieper,Ron Kikinis,Benjamin Billot,Andrey Fedorov*

Main category: eess.IV

TL;DR: 论文分析了三种MRI腹部分割工具的性能，并引入了一种基于CT分割训练的模型ABDSynth，评估了其准确性和泛化性。

- Motivation: 由于MRI分割的挑战性和标注数据有限，需要评估现有工具的性能并探索替代方案。
- Method: 对三种开源模型（MRSegmentator、MRISegmentator-Abdomen、TotalSegmentator MRI）和ABDSynth进行了全面基准测试，使用了三个公共数据集。
- Result: MRSegmentator表现最佳且泛化性最强，ABDSynth虽稍逊但适用于标注预算有限的情况。
- Conclusion: MRSegmentator是首选工具，ABDSynth为标注资源有限时提供了可行替代方案。


### [111] [Direct Dual-Energy CT Material Decomposition using Model-based Denoising Diffusion Model](https://arxiv.org/abs/2507.18012)
*Hang Xu,Alexandre Bousse,Alessandro Perelli*

Main category: eess.IV

TL;DR: 提出了一种名为DEcomp-MoD的深度学习方法，直接从DECT投影数据生成材料图像，解决了传统方法中因忽略束硬化效应导致的次优结果问题。

- Motivation: 传统方法在图像域进行材料分解，忽略了束硬化效应，导致结果不理想。
- Method: 结合谱DECT模型知识和基于分数的去噪扩散先验，直接从投影数据生成材料图像。
- Result: 在低剂量AAPM数据集上，DEcomp-MoD表现优于现有无监督和有监督方法。
- Conclusion: DEcomp-MoD具有临床诊断潜力，优于现有技术。


### [112] [Parameter-Efficient Fine-Tuning of 3D DDPM for MRI Image Generation Using Tensor Networks](https://arxiv.org/abs/2507.18112)
*Binghua Li,Ziqing Chang,Tong Liang,Chao Li,Toshihisa Tanaka,Shigeki Aoki,Qibin Zhao,Zhe Sun*

Main category: eess.IV

TL;DR: 提出了一种名为TenVOO的参数高效微调方法，用于3D U-Net基础的DDPM在MRI图像生成中的优化。

- Motivation: 解决3D卷积操作参数高效表示研究的不足，提升MRI图像生成效率。
- Method: 利用张量网络建模，将3D卷积核表示为低维张量，以减少参数需求。
- Result: 在三个脑MRI数据集上表现优异，仅需原模型0.3%的可训练参数。
- Conclusion: TenVOO在捕获空间依赖性和参数效率方面优于现有方法。


### [113] [U-Net Based Healthy 3D Brain Tissue Inpainting](https://arxiv.org/abs/2507.18126)
*Juexin Zhang,Ying Weng,Ke Chen*

Main category: eess.IV

TL;DR: 提出了一种基于U-Net架构的新方法，用于从掩码输入图像合成健康的3D脑组织，并在BraTS-Local-Inpainting数据集中表现优异。

- Motivation: 解决脑MRI扫描中缺失或损坏区域的健康组织重建问题，提升模型的泛化能力和鲁棒性。
- Method: 采用U-Net架构，结合随机掩码健康图像的全面数据增强策略进行训练。
- Result: 在BraTS-Local-Inpainting验证集上，SSIM为0.841，PSNR为23.257，MSE为0.007，且标准差较低，模型表现稳定。
- Conclusion: 该方法在挑战赛中取得第一名，证明了其在健康脑组织合成任务中的高效性和可靠性。


### [114] [Deep Learning for Glioblastoma Morpho-pathological Features Identification: A BraTS-Pathology Challenge Solution](https://arxiv.org/abs/2507.18133)
*Juexin Zhang,Ying Weng,Ke Chen*

Main category: eess.IV

TL;DR: 论文提出了一种基于预训练模型的方法用于胶质母细胞瘤的诊断，但在验证集上表现不佳，仅获得第二名。

- Motivation: 胶质母细胞瘤的异质性使其诊断具有挑战性，传统方法依赖组织样本特征，而深度学习提供了改进诊断的潜力。
- Method: 利用预训练模型并在BraTS-Path训练数据集上进行微调。
- Result: 模型在验证集上表现较差（准确率0.392），但特异性高（0.899），测试阶段获得第二名。
- Conclusion: 尽管模型在验证集上表现不佳，但其高特异性和测试阶段的成绩表明其潜力。


### [115] [TCM-Tongue: A Standardized Tongue Image Dataset with Pathological Annotations for AI-Assisted TCM Diagnosis](https://arxiv.org/abs/2507.18288)
*Xuebo Jin,Longfei Gao,Anshuo Tong,Zhengyang Chen,Jianlei Kong,Ning Sun,Huijun Ma,Qiang Wang,Yuting Bai,Tingli Su*

Main category: eess.IV

TL;DR: 论文提出了首个专为AI驱动的中医舌诊设计的数据集，包含6,719张标准化条件下的高质量图像，标注了20种病理症状类别，并通过多种深度学习模型验证了其效用。

- Motivation: 中医舌诊因主观解释和影像协议不一致而面临标准化挑战，且缺乏大规模标注数据集，阻碍了AI在该领域的发展。
- Method: 构建了一个包含6,719张高质量舌诊图像的数据集，标注了20种病理症状类别，支持多种标注格式，并用九种深度学习模型进行了基准测试。
- Result: 数据集为AI开发提供了标准化、高质量的数据基础，并通过多种模型验证了其实用性。
- Conclusion: 该数据集填补了中医舌诊领域的数据短缺，为AI在研究和临床实践中的应用提供了可靠支持。


### [116] [UniSegDiff: Boosting Unified Lesion Segmentation via a Staged Diffusion Model](https://arxiv.org/abs/2507.18362)
*Yilong Hu,Shijie Chang,Lihe Zhang,Feng Tian,Weibing Sun,Huchuan Lu*

Main category: eess.IV

TL;DR: UniSegDiff是一种新型扩散模型框架，通过分阶段训练和动态调整预测目标，解决了扩散模型在病灶分割中的注意力分布不均问题，显著提升了性能。

- Motivation: 扩散概率模型（DPM）在生成任务中表现优异，但现有训练和推理策略导致注意力分布不均，影响病灶分割效果。
- Method: 提出UniSegDiff框架，采用分阶段训练和动态调整预测目标的方法，并通过预训练特征提取网络实现统一的病灶分割。
- Result: 在多种成像模态和器官上的实验表明，UniSegDiff显著优于现有最佳方法。
- Conclusion: UniSegDiff通过优化注意力分布，实现了高效且统一的病灶分割，为医学图像分析提供了新思路。


### [117] [DiagR1: A Vision-Language Model Trained via Reinforcement Learning for Digestive Pathology Diagnosis](https://arxiv.org/abs/2507.18433)
*Minxi Ouyang,Lianghui Zhu,Yaqing Bao,Qiang Huang,Jingli Ouyang,Tian Guan,Xitong Ling,Jiawen Li,Song Duan,Wenbin Dai,Li Zheng,Xuemei Zhang,Yonghong He*

Main category: eess.IV

TL;DR: 论文提出了一种针对胃肠道病理图像的多模态模型改进方法，通过构建高质量数据集和引入提示论证策略，显著提升了生成文本的临床相关性和结构完整性。

- Motivation: 当前胃肠道病理多模态模型因数据质量差和推理不透明，导致生成文本存在事实性幻觉且难以审核，限制了临床应用的信任度。
- Method: 构建大规模胃肠道病理数据集，结合病变分类和解剖部位信息的提示论证策略，并采用监督微调与GRPO结合的后期训练流程。
- Result: 实验显示，该方法在生成质量、结构完整性和临床相关性上显著优于现有模型，临床相关性提升18.7%，结构完整性提高32.4%，诊断错误减少41.2%。
- Conclusion: 该方法通过改进数据和推理策略，显著提升了胃肠道病理图像分析的准确性和临床实用性。
## cs.CR

### [118] [NWaaS: Nonintrusive Watermarking as a Service for X-to-Image DNN](https://arxiv.org/abs/2507.18036)
*Haonan An,Guang Hua,Yu Guo,Hangcheng Cao,Susanto Rahardja,Yuguang Fang*

Main category: cs.CR

TL;DR: 论文提出了一种非侵入式的DNN水印服务（NWaaS），通过ShadowMark实现，解决了现有水印方法对模型参数或结构的修改问题，实现了绝对保真度。

- Motivation: 现有DNN水印方法具有侵入性，可能改变模型行为或增加调优成本，限制了实际应用。
- Method: 提出NWaaS范式及ShadowMark实现，利用黑盒API建立非侵入式侧信道，通过密钥编码器和水印解码器提取水印。
- Result: 实验证明ShadowMark在多种DNN架构中有效且实用，能抵御攻击并消除保真度与鲁棒性的权衡。
- Conclusion: ShadowMark为非侵入式DNN水印提供了可行的解决方案，适用于实际部署。
