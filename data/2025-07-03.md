[[toc]]

## cs.CV

### [1] [Geometry-aware 4D Video Generation for Robot Manipulation](https://arxiv.org/abs/2507.01099)
*Zeyi Liu,Shuang Li,Eric Cousineau,Siyuan Feng,Benjamin Burchfiel,Shuran Song*

Main category: cs.CV

TL;DR: 提出了一种4D视频生成模型，通过跨视角点图对齐监督，实现多视角3D一致性，提升机器人动态场景预测能力。

- Motivation: 增强机器人在复杂环境中规划和交互的能力，解决视频生成中时间连贯性和几何一致性的挑战。
- Method: 利用RGB-D观测数据，通过跨视角点图对齐监督训练模型，学习共享3D场景表示，无需相机位姿输入。
- Result: 在模拟和真实机器人数据集中，生成更稳定且空间对齐的视频预测，支持机器人轨迹恢复和操作。
- Conclusion: 该方法有效提升了视频生成的多视角一致性，为机器人操作和新视角泛化提供了支持。


### [2] [Landslide Detection and Mapping Using Deep Learning Across Multi-Source Satellite Data and Geographic Regions](https://arxiv.org/abs/2507.01123)
*Rahul A. Burange,Harsh K. Shinde,Omkar Mutyalwar*

Main category: cs.CV

TL;DR: 该研究利用多源卫星影像和深度学习模型，提出了一种综合方法来提高滑坡识别和预测的准确性。

- Motivation: 滑坡对基础设施、经济和人类生命构成严重威胁，需要准确检测和预测。
- Method: 结合Sentinel-2多光谱数据和ALOS PALSAR衍生的坡度及DEM层，采用多种地理空间分析技术和深度学习分割模型（如U-Net、DeepLabV3+和Res-Net）。
- Result: 研究结果为开发可靠的早期预警系统、改进灾害风险管理和可持续土地利用规划提供了支持。
- Conclusion: 深度学习和多源遥感技术在构建稳健、可扩展和可迁移的滑坡预测模型中具有潜力。


### [3] [cp_measure: API-first feature extraction for image-based profiling workflows](https://arxiv.org/abs/2507.01163)
*Alán F. Muñoz,Tim Treis,Alexandr A. Kalinin,Shatavisha Dasgupta,Fabian Theis,Anne E. Carpenter,Shantanu Singh*

Main category: cs.CV

TL;DR: cp_measure是一个Python库，将CellProfiler的核心测量功能模块化，便于程序化特征提取，支持机器学习和可重复分析。

- Motivation: 传统生物图像分析工具如CellProfiler在自动化、可重复性和机器学习集成方面存在障碍。
- Method: 开发cp_measure库，提取CellProfiler的核心测量功能，设计为模块化、API优先的工具。
- Result: cp_measure的特征与CellProfiler高度一致，并能无缝集成到Python生态系统中。
- Conclusion: cp_measure支持可重复、自动化的图像分析流程，适用于计算生物学中的机器学习应用。


### [4] [Rapid Salient Object Detection with Difference Convolutional Neural Networks](https://arxiv.org/abs/2507.01182)
*Zhuo Su,Li Liu,Matthias Müller,Jiehua Zhang,Diana Wofk,Ming-Ming Cheng,Matti Pietikäinen*

Main category: cs.CV

TL;DR: 提出了一种高效网络设计，结合传统显著目标检测（SOD）与现代CNN，通过像素差异卷积（PDCs）和差异卷积重参数化（DCR）策略提升效率，适用于资源受限设备。

- Motivation: 解决现有SOD模型在资源受限设备上计算开销大的问题，实现实时性能。
- Method: 结合传统SOD的对比线索与现代CNN，提出PDCs和DCR策略，并扩展至视频SOD（STDC）。
- Result: 模型SDNet和STDNet在效率和精度上显著提升，在Jetson Orin设备上分别达到46 FPS和150 FPS。
- Conclusion: 提出的方法在资源受限设备上实现了高效的实时SOD，速度和精度均优于现有轻量级模型。


### [5] [Robust Brain Tumor Segmentation with Incomplete MRI Modalities Using Hölder Divergence and Mutual Information-Enhanced Knowledge Transfer](https://arxiv.org/abs/2507.01254)
*Runze Cheng,Xihang Qiu,Ming Li,Ye Zhang,Chun Li,Fei Yu*

Main category: cs.CV

TL;DR: 提出了一种基于单模态并行处理的鲁棒框架，用于处理多模态MRI数据缺失时的脑肿瘤分割问题，通过Holder散度和互信息保持模态特征，并在BraTS数据集上验证了其优越性。

- Motivation: 多模态MRI数据在脑肿瘤分割中至关重要，但实际应用中常因各种原因缺失某些模态，传统方法难以应对。
- Method: 采用单模态并行处理框架，结合Holder散度和互信息，动态调整网络参数以处理缺失模态。
- Result: 在BraTS 2018和2020数据集上表现优于现有方法，尤其在处理缺失模态时。
- Conclusion: 该框架通过量化预测与真实标签的差异，实现了高精度的分割，适用于实际临床场景。


### [6] [AIGVE-MACS: Unified Multi-Aspect Commenting and Scoring Model for AI-Generated Video Evaluation](https://arxiv.org/abs/2507.01255)
*Xiao Liu,Jiawei Zhang*

Main category: cs.CV

TL;DR: 论文提出AIGVE-MACS，一种为AI生成视频提供数值评分和多方面语言反馈的统一评估模型，显著优于现有基线。

- Motivation: 现有AI生成视频评估指标缺乏解释性，难以与人类评价对齐，因此需要更全面的评估框架。
- Method: 利用AIGVE-BENCH 2数据集，结合视觉语言模型、加权损失和动态帧采样策略，开发AIGVE-MACS模型。
- Result: AIGVE-MACS在评分相关性和评论质量上均达到最优，并通过多代理框架提升视频生成质量53.5%。
- Conclusion: AIGVE-MACS为AI生成视频的全面评估设立了新范式，并开源了数据集和模型。


### [7] [Advancements in Weed Mapping: A Systematic Review](https://arxiv.org/abs/2507.01269)
*Mohammad Jahanbakht,Alex Olsen,Ross Marchant,Emilie Fillols,Mostafa Rahimi Azghadi*

Main category: cs.CV

TL;DR: 该论文综述了杂草测绘领域的最新进展，填补了从数据采集到处理技术的全面文献空白，旨在推动高效、可持续的杂草管理系统发展。

- Motivation: 杂草测绘对精准管理和减少环境影响至关重要，但缺乏全面的文献综述和分析，限制了该领域的进展。
- Method: 采用PRISMA指南，系统分析了数据采集（传感器与平台技术）、数据处理（标注与建模）和测绘技术（时空分析与决策支持工具）的最先进方法。
- Result: 综述提供了杂草测绘领域的全面理解，为未来研究和可持续杂草管理系统开发奠定了基础。
- Conclusion: 该论文填补了杂草测绘领域的文献空白，为高效、可扩展的杂草管理提供了重要参考。


### [8] [Frequency Domain-Based Diffusion Model for Unpaired Image Dehazing](https://arxiv.org/abs/2507.01275)
*Chengxu Liu,Lu Qi,Jinshan Pan,Xueming Qian,Ming-Hsuan Yang*

Main category: cs.CV

TL;DR: Error

- Motivation: Error
- Method: Error
- Result: Error
- Conclusion: Error


### [9] [Learning an Ensemble Token from Task-driven Priors in Facial Analysis](https://arxiv.org/abs/2507.01290)
*Sunyong Seo,Semin Kim,Jongha Lee*

Main category: cs.CV

TL;DR: ET-Fuser是一种新颖的方法，通过利用基于预训练模型任务先验的注意力机制，学习集成令牌，以改进面部分析任务中的特征表示。

- Motivation: 现有方法在单任务学习中缺乏统一的特征表示，ET-Fuser旨在解决这一问题。
- Method: 提出了一种基于自注意力机制的集成令牌学习方法，利用预训练编码器的共享信息。
- Result: 在多种面部分析任务中表现出显著的特征表示改进，且计算成本极低。
- Conclusion: ET-Fuser通过集成令牌方法高效地提升了面部分析任务的性能。


### [10] [DiffusionLight-Turbo: Accelerated Light Probes for Free via Single-Pass Chrome Ball Inpainting](https://arxiv.org/abs/2507.01305)
*Worameth Chinchuthakun,Pakkapon Phongthawee,Amit Raj,Varun Jampani,Pramook Khungurn,Supasorn Suwajanakorn*

Main category: cs.CV

TL;DR: 提出了一种通过将任务重新定义为铬球修复问题，从单张低动态范围（LDR）图像估计光照的简单有效方法。利用预训练的扩散模型Stable Diffusion XL，克服了依赖有限HDR全景数据集的方法的泛化问题。通过迭代修复生成稳定的低频光照先验，并结合曝光LoRA生成HDR光探针。进一步优化为DiffusionLight-Turbo，显著提升速度。

- Motivation: 现有方法依赖有限的HDR全景数据集，泛化能力不足，且扩散模型在生成HDR格式的铬球时存在困难。
- Method: 使用Stable Diffusion XL进行铬球修复，通过迭代修复生成稳定的光照先验；结合曝光LoRA生成HDR光探针；优化为DiffusionLight-Turbo，通过LoRA交换技术加速。
- Result: 实验结果表明，该方法能生成高质量的光照估计，并在多样化场景中表现出优越的泛化能力。
- Conclusion: DiffusionLight及其优化版本Turbo提供了一种高效且泛化能力强的光照估计方法，适用于实际场景。


### [11] [Physics-informed Ground Reaction Dynamics from Human Motion Capture](https://arxiv.org/abs/2507.01340)
*Cuong Le,Huy-Phuong Le,Duc Le,Minh-Thien Duong,Van-Binh Nguyen,My-Ha Le*

Main category: cs.CV

TL;DR: 提出了一种基于物理约束的方法，直接从运动捕捉数据估计地面反作用力，优于传统黑盒深度学习模型。

- Motivation: 传统方法依赖实验室专用设备（如力板）获取地面反作用力，限制了动态学习的应用范围。
- Method: 结合欧拉积分方案和PD算法，利用物理定律和计算模拟约束，从运动捕捉数据计算地面反作用力。
- Result: 在GroundLink数据集上测试，地面反作用力估计精度和模拟根轨迹精度均优于基线模型。
- Conclusion: 提出的物理约束方法显著提高了地面反作用力的估计精度，扩展了动态学习的应用场景。


### [12] [Learning Camera-Agnostic White-Balance Preferences](https://arxiv.org/abs/2507.01342)
*Luxi Zhao,Mahmoud Afifi,Michael S. Brown*

Main category: cs.CV

TL;DR: 论文提出了一种轻量级方法，通过学习后光照估计映射，将中性白平衡校正转换为美学偏好的校正，实现跨相机美学一致性。

- Motivation: 商业自动白平衡（AWB）系统通常追求美学偏好而非准确中性校正，且现有学习方法难以泛化到不同相机传感器。本文旨在解决美学一致性问题。
- Method: 提出一种后光照估计映射，将中性白平衡校正转换为美学偏好的校正，适用于任何中性AWB模块，且模型轻量（约500参数）。
- Result: 在771张智能手机图像数据集上，方法达到最优性能，计算速度快（0.024毫秒），兼容现有跨相机AWB技术。
- Conclusion: 该方法首次实现跨相机美学一致性，轻量高效，适用于多种相机传感器。


### [13] [Learning from Random Subspace Exploration: Generalized Test-Time Augmentation with Self-supervised Distillation](https://arxiv.org/abs/2507.01347)
*Andrei Jelea,Ahmed Nabil Belbachir,Marius Leordeanu*

Main category: cs.CV

TL;DR: GTTA是一种通用的测试时间增强方法，适用于多种视觉和非视觉任务，通过扰动PCA子空间投影形成鲁棒集成，并结合自监督学习降低计算成本。

- Motivation: 现有测试时间增强方法缺乏通用性，GTTA旨在提供一种适用于多种任务的通用解决方案，同时减少计算成本。
- Method: GTTA通过随机扰动PCA子空间投影形成集成，并引入自监督学习阶段，利用集成输出训练初始模型。
- Result: GTTA在多种任务和数据集上表现优于现有方法，并在特定任务（如低能见度水下视频中的鲑鱼分割）中验证了其有效性。
- Conclusion: GTTA是一种通用且高效的测试时间增强方法，适用于广泛的任务，同时保持高精度和低计算成本。


### [14] [Long-Tailed Distribution-Aware Router For Mixture-of-Experts in Large Vision-Language Model](https://arxiv.org/abs/2507.01351)
*Chaoxiang Cai,Longrong Yang,Kaibing Chen,Fan Yang,Xi Li*

Main category: cs.CV

TL;DR: 本文提出了一种长尾分布感知路由器（LTDR），用于视觉-语言混合专家（MoE）模型中的令牌到专家路由（TER），解决了模态间分布差异和视觉尾部令牌激活不足的问题。

- Motivation: 现有MoE框架在视觉-语言模型中忽视了视觉和语言模态的分布差异，导致路由策略不匹配。本文旨在通过分布感知路由和增强尾部令牌激活来优化性能。
- Method: 提出LTDR，包括（1）针对语言和视觉模态的不同分布设计路由策略；（2）通过类似过采样的方法增加视觉尾部令牌的激活专家数量。
- Result: 在多个基准测试中验证了LTDR的有效性，表明其优于现有方法。
- Conclusion: LTDR通过模态感知路由和尾部令牌增强，显著提升了视觉-语言MoE模型的性能。


### [15] [3D Gaussian Splatting Driven Multi-View Robust Physical Adversarial Camouflage Generation](https://arxiv.org/abs/2507.01367)
*Tianrui Lou,Xiaojun Jia,Siyuan Liang,Jiawei Liang,Ming Zhang,Yanjun Xiao,Xiaochun Cao*

Main category: cs.CV

TL;DR: 提出了一种基于3D高斯散射的物理攻击框架PGA，通过快速重建和逼真渲染，增强了跨视角鲁棒性和对抗效果。

- Motivation: 现有伪装攻击方法依赖目标对象的网格先验和模拟环境，耗时且与现实存在差异，且缺乏多视角鲁棒性。
- Method: 利用3D高斯散射技术快速重建目标，避免高斯间的遮挡，并通过min-max优化调整背景，过滤非鲁棒特征。
- Result: 实验验证了PGA的有效性和优越性。
- Conclusion: PGA在物理攻击中表现出更强的对抗效果和跨视角鲁棒性。


### [16] [Activation Reward Models for Few-Shot Model Alignment](https://arxiv.org/abs/2507.01368)
*Tianning Chai,Chancharik Mitra,Brandon Huang,Gautam Rajendrakumar Gare,Zhiqiu Lin,Assaf Arbelle,Leonid Karlinsky,Rogerio Feris,Trevor Darrell,Deva Ramanan,Roei Herzig*

Main category: cs.CV

TL;DR: 提出了一种新的少样本奖励建模方法——激活奖励模型（Activation RMs），通过激活导向构建对齐的奖励信号，无需额外微调，优于现有方法，并在奖励黑客行为缓解中表现优异。

- Motivation: 对齐大型语言模型（LLMs）和多模态模型（LMMs）到人类偏好是提升生成输出质量的关键，传统奖励建模难以适应新偏好，需要改进。
- Method: 利用激活导向技术构建奖励信号，仅需少量监督且无需额外模型微调，提出PreferenceHack基准测试奖励黑客行为。
- Result: Activation RMs在标准奖励建模基准上优于现有少样本方法，并在PreferenceHack基准上超越GPT-4o。
- Conclusion: Activation RMs为少样本奖励建模提供了高效且安全的解决方案，适用于安全关键应用。


### [17] [Active Measurement: Efficient Estimation at Scale](https://arxiv.org/abs/2507.01372)
*Max Hamilton,Jinlin Lai,Wenlong Zhao,Subhransu Maji,Daniel Sheldon*

Main category: cs.CV

TL;DR: 提出了一种名为“主动测量”的人机协作AI框架，通过重要性采样和迭代优化模型，提高科学测量的准确性和统计保障。

- Motivation: 当前AI在科学发现中的应用缺乏足够的准确性和统计保障，需要一种更高效且可靠的方法。
- Method: 使用AI模型预测测量值，通过重要性采样选择样本进行人工标注，迭代优化模型并生成无偏估计。
- Result: 主动测量框架在多个测量任务中显著降低了估计误差，且对AI模型的初始精度要求较低。
- Conclusion: 主动测量为科学测量提供了一种高效、可靠的人机协作解决方案。


### [18] [MUG: Pseudo Labeling Augmented Audio-Visual Mamba Network for Audio-Visual Video Parsing](https://arxiv.org/abs/2507.01384)
*Langyu Wang,Bingke Zhu,Yingying Chen,Yiyuan Zhang,Ming Tang,Jinqiao Wang*

Main category: cs.CV

TL;DR: 提出了一种基于伪标签增强的音频-视觉Mamba网络（MUG），用于改进弱监督音频-视觉视频解析任务中的段级和事件级预测。

- Motivation: 现有方法在弱监督和模型架构的限制下，难以同时提升段级和事件级预测性能。
- Method: 通过伪标签增强生成新数据，并采用音频-视觉Mamba网络进行特征处理和交互。
- Result: 在LLP数据集上，MUG在所有指标上均优于现有方法，如视觉段级和音频段级指标分别提升2.1%和1.2%。
- Conclusion: MUG通过伪标签增强和Mamba网络有效提升了弱监督音频-视觉视频解析的性能。


### [19] [FixTalk: Taming Identity Leakage for High-Quality Talking Head Generation in Extreme Cases](https://arxiv.org/abs/2507.01390)
*Shuai Tan,Bill Gong,Bin Ji,Ye Pan*

Main category: cs.CV

TL;DR: FixTalk框架通过解耦身份信息和运动特征，同时解决身份泄漏和渲染伪影问题，提升了说话头生成的质量。

- Motivation: 现有方法在极端情况下存在身份泄漏（IL）和渲染伪影（RA）问题，影响了说话头生成的质量。
- Method: 提出FixTalk框架，包括增强运动指示器（EMI）解耦身份信息，以及增强细节指示器（EDI）利用泄漏信息修复伪影。
- Result: 实验表明FixTalk有效缓解了IL和RA，性能优于现有方法。
- Conclusion: FixTalk通过创新设计解决了身份泄漏和渲染伪影问题，为高质量说话头生成提供了新思路。


### [20] [Coherent Online Road Topology Estimation and Reasoning with Standard-Definition Maps](https://arxiv.org/abs/2507.01397)
*Khanh Son Pham,Christian Witte,Jens Behley,Johannes Betz,Cyrill Stachniss*

Main category: cs.CV

TL;DR: 论文提出了一种利用标准地图（SD）信息预测车道段、拓扑和道路边界的方法，通过混合编码和去噪技术提升性能，实验表明其优于现有方法。

- Motivation: 当前自动驾驶依赖高清地图（HD），但在线构建HD地图仍具挑战性，需统一建模复杂道路拓扑。
- Method: 提出网络架构，利用SD地图先验信息和混合车道段编码，结合去噪技术和历史帧确保时间一致性。
- Result: 实验证明该方法显著优于现有方法。
- Conclusion: 通过先验信息和一致性建模，有效解决了HD地图在线构建的挑战。


### [21] [Medical-Knowledge Driven Multiple Instance Learning for Classifying Severe Abdominal Anomalies on Prenatal Ultrasound](https://arxiv.org/abs/2507.01401)
*Huanwen Liang,Jingxian Xu,Yuanji Zhang,Yuhao Huang,Yuhan Zhang,Xin Yang,Ran Li,Xuedong Deng,Yanjun Liu,Guowei Tao,Yun Wu,Sheng Zhao,Xinru Gao,Dong Ni*

Main category: cs.CV

TL;DR: 提出了一种基于多实例学习的案例级方法，用于胎儿腹部异常的超声分类，无需标准平面定位，性能优于现有技术。

- Motivation: 胎儿腹部畸形是严重的先天性异常，需准确诊断以指导妊娠管理并降低死亡率。现有AI方法多关注图像级分类，案例级诊断较少。
- Method: 采用混合注意力专家模块（MoAE）对不同平面加权，提出医学知识驱动的特征选择模块（MFS）进行自监督图像标记选择，并结合提示原型学习（PPL）增强MFS。
- Result: 在包含2,419个案例、24,748张图像和6个类别的大规模数据集上验证，性能优于现有方法。
- Conclusion: 该方法在胎儿腹部异常超声分类中表现出色，为案例级诊断提供了新思路。


### [22] [CaptionSmiths: Flexibly Controlling Language Pattern in Image Captioning](https://arxiv.org/abs/2507.01409)
*Kuniaki Saito,Donghyun Kim,Kwanyong Park,Atsushi Hashimoto,Yoshitaka Ushiku*

Main category: cs.CV

TL;DR: 论文提出CaptionSmiths方法，通过量化标题属性并插值端点向量，实现单模型灵活控制标题的语言模式。

- Motivation: 现有图像标题模型难以精细控制生成标题的属性，如长度和描述性，且缺乏平滑过渡能力。
- Method: 量化标题长度、描述性和词汇独特性为连续标量，通过插值端点向量实现条件控制。
- Result: 模型能平滑调整标题属性，词汇对齐优于基线，如长度控制误差减少506%。
- Conclusion: CaptionSmiths成功实现单模型灵活控制标题语言模式，提升生成效果。


### [23] [Gradient Short-Circuit: Efficient Out-of-Distribution Detection via Feature Intervention](https://arxiv.org/abs/2507.01417)
*Jiawei Gu,Ziyue Qiao,Zechao Li*

Main category: cs.CV

TL;DR: 论文提出了一种基于梯度方向一致性的OOD检测方法，通过短路虚假梯度提升检测效果，同时保持ID分类性能。

- Motivation: 在开放世界中，OOD检测对安全部署深度学习模型至关重要。研究发现ID样本的梯度方向一致，而OOD样本则混乱，这启发了新方法的提出。
- Method: 提出了一种推理阶段的技术，短路虚假梯度利用的特征坐标，并通过局部一阶近似避免二次前向传播。
- Result: 在标准OOD基准测试中表现显著提升，方法轻量且对标准推理流程改动小。
- Conclusion: 该方法为实际应用中的鲁棒OOD检测提供了实用路径。


### [24] [DocShaDiffusion: Diffusion Model in Latent Space for Document Image Shadow Removal](https://arxiv.org/abs/2507.01422)
*Wenjie Liu,Bingshu Wang,Ze Wang,C. L. Philip Chen*

Main category: cs.CV

TL;DR: 提出了一种基于潜在空间扩散模型的文档图像阴影去除方法DocShaDiffusion，结合阴影软掩模生成模块（SSGM）和阴影掩模引导扩散模块（SMGDM），有效处理彩色阴影问题。

- Motivation: 现有方法通常仅处理恒定颜色背景的阴影，而忽略了彩色阴影，限制了文档图像增强的效果。
- Method: 设计潜在空间扩散模型DocShaDiffusion，结合SSGM生成阴影掩模并注入噪声，SMGDM引导扩散和去噪过程去除阴影，并提出阴影鲁棒感知特征损失保护细节。
- Result: 在三个公开数据集上验证了方法的优越性，并开发了合成文档彩色阴影去除数据集（SDCSRD）支持模型训练。
- Conclusion: DocShaDiffusion在文档阴影去除任务中表现优异，代码和数据集将公开。


### [25] [DiffMark: Diffusion-based Robust Watermark Against Deepfakes](https://arxiv.org/abs/2507.01428)
*Chen Sun,Haiyang Sun,Zhiqing Guo,Yunfeng Diao,Liejun Wang,Dan Ma,Gaobo Yang,Keqin Li*

Main category: cs.CV

TL;DR: DiffMark是一种基于扩散模型的鲁棒水印框架，通过改进训练和采样方案，结合面部图像和水印条件，生成抗Deepfake篡改的水印图像。

- Motivation: Deepfake技术对安全和隐私构成威胁，现有水印方法对抗Deepfake篡改的鲁棒性不足。
- Method: DiffMark通过时间步依赖的面部条件引导、交叉信息融合模块（CIF）和对抗性Deepfake模拟训练，增强水印鲁棒性。
- Result: 实验证明DiffMark在典型Deepfake攻击下表现优异。
- Conclusion: DiffMark为对抗Deepfake提供了一种有效的水印解决方案。


### [26] [TurboReg: TurboClique for Robust and Efficient Point Cloud Registration](https://arxiv.org/abs/2507.01439)
*Shaocheng Yan,Pengcheng Shi,Zhenjun Zhao,Kaixin Wang,Kuang Cao,Ji Wu,Jiayuan Li*

Main category: cs.CV

TL;DR: 提出了一种快速鲁棒的PCR估计器TurboReg，基于轻量级TurboClique和并行PGS算法，显著提高了速度和性能。

- Motivation: 现有基于最大团搜索的方法虽召回率高，但时间复杂度指数级增长，不适用于时间敏感场景。
- Method: 定义TurboClique为高度约束兼容图中的3-团，结合并行PGS算法，线性时间复杂度。
- Result: 在3DMatch+FCGF数据集上，TurboReg速度提升208.22倍且召回率更高。
- Conclusion: TurboReg在速度和性能上均达到SOTA，适用于实时应用。


### [27] [OoDDINO:A Multi-level Framework for Anomaly Segmentation on Complex Road Scenes](https://arxiv.org/abs/2507.01455)
*Yuxing Liu,Ji Zhang,Zhou Xuchuan,Jingzhong Xiao,Huimin Yang,Jiaxin Zhong*

Main category: cs.CV

TL;DR: OoDDINO是一个新颖的多层次异常分割框架，通过粗到细的检测策略解决现有像素级方法的局限性，结合不确定性引导的检测模型和像素级分割模型，显著提升异常分割性能。

- Motivation: 现有像素级异常分割方法忽视像素间的空间相关性，且全局阈值策略导致误检或漏检，OoDDINO旨在解决这些问题。
- Method: 采用两阶段级联架构：1) 正交不确定性感知融合策略（OUAFS）整合多指标；2) 自适应双阈值网络（ADT-Net）动态生成区域特定阈值。
- Result: 在多个基准数据集上验证，OoDDINO优于现有方法，兼容性强。
- Conclusion: OoDDINO通过多层次策略有效提升异常分割精度，为实际应用提供可靠解决方案。


### [28] [NOCTIS: Novel Object Cyclic Threshold based Instance Segmentation](https://arxiv.org/abs/2507.01463)
*Max Gandyra,Alessandro Santonicola,Michael Beetz*

Main category: cs.CV

TL;DR: NOCTIS是一种无需重新训练即可对未见物体进行实例分割的框架，结合了Grounded-SAM 2和DINOv2的优势，在BOP 2023挑战中表现优异。

- Motivation: 解决无需重新训练即可对各类未见物体进行实例分割的难题。
- Method: 利用Grounded-SAM 2生成物体提议和分割掩码，DINOv2生成图像嵌入，通过相似性评分和循环阈值匹配物体。
- Result: 在BOP 2023挑战的7个核心数据集上，NOCTIS表现优于现有RGB和RGB-D方法。
- Conclusion: NOCTIS提供了一种简单而强大的方法，无需额外训练即可高效分割未见物体。


### [29] [Representation Entanglement for Generation:Training Diffusion Transformers Is Much Easier Than You Think](https://arxiv.org/abs/2507.01467)
*Ge Wu,Shen Zhang,Ruijing Shi,Shanghua Gao,Zhenyuan Chen,Lei Wang,Zhaowei Chen,Hongcheng Gao,Yao Tang,Jian Yang,Ming-Ming Cheng,Xiang Li*

Main category: cs.CV

TL;DR: 论文提出了一种称为REG的方法，通过将低层图像潜在表示与预训练模型的高层类别标记纠缠，显著提升了生成质量和训练效率。

- Motivation: 现有方法（如REPA）在训练扩散模型时利用外部视觉表示，但未在去噪推理过程中充分利用判别性表示。
- Method: REG方法将低层图像潜在表示与预训练基础模型的单个高层类别标记纠缠，直接从纯噪声中生成一致的图像-类别对。
- Result: 在ImageNet 256×256上，SiT-XL/2 + REG实现了63倍和23倍的训练加速，且仅需400K次迭代即可超越4M次迭代的SiT-XL/2 + REPA。
- Conclusion: REG通过语义知识主动引导图像生成，显著提升了生成质量和训练效率，且推理开销极小。


### [30] [Optimizing Methane Detection On Board Satellites: Speed, Accuracy, and Low-Power Solutions for Resource-Constrained Hardware](https://arxiv.org/abs/2507.01472)
*Jonáš Herec,Vít Růžička,Rado Pitoňák*

Main category: cs.CV

TL;DR: 论文提出了一种高效、低功耗的甲烷泄漏检测算法（Mag1c-SAS和CEM），结合机器学习模型，显著提升了检测速度（100x-230x），并优化了波段选择策略，适用于星载硬件。

- Motivation: 甲烷是强效温室气体，现有卫星检测方法因计算资源有限和手动任务模式效率低下，亟需快速、低功耗的星载检测方案。
- Method: 测试了快速目标检测方法（ACE、CEM），提出改进算法Mag1c-SAS，并结合机器学习模型（U-Net、LinkNet）评估性能。同时提出三种波段选择策略。
- Result: Mag1c-SAS和CEM在强羽流检测中表现良好，计算效率显著提升（100x-230x）。一种波段选择策略在减少通道的同时优于传统方法。
- Conclusion: 研究为低硬件需求的星载甲烷检测奠定了基础，代码和数据已开源。


### [31] [Active Control Points-based 6DoF Pose Tracking for Industrial Metal Objects](https://arxiv.org/abs/2507.01478)
*Chentao Shen,Ding Pan,Mingyu Mei,Zaixing He,Xinyue Zhao*

Main category: cs.CV

TL;DR: 提出了一种基于主动控制点的6DoF姿态跟踪方法，用于解决工业金属物体在真实环境中的反射问题。

- Motivation: 工业金属物体的姿态跟踪因反射特性而具有挑战性，需要一种更有效的方法。
- Method: 使用图像控制点生成边缘特征进行优化，并引入最优控制点回归方法以提高鲁棒性。
- Result: 在数据集评估和实际任务中表现有效，适用于实时跟踪。
- Conclusion: 该方法为工业金属物体的实时跟踪提供了可行解决方案，代码已开源。


### [32] [What Really Matters for Robust Multi-Sensor HD Map Construction?](https://arxiv.org/abs/2507.01484)
*Xiaoshuai Hao,Yuting Zhao,Yuheng Ji,Luanyuan Dai,Peng Hao,Dingzhe Li,Shuai Cheng,Rong Yin*

Main category: cs.CV

TL;DR: 论文提出了一种增强多模态融合方法鲁棒性的策略，用于高精度高清地图构建，包括数据增强、新型多模态融合模块和模态丢弃训练策略，并在NuScenes数据集上验证了其有效性。

- Motivation: 现有方法主要关注模型精度，而忽略了鲁棒性，这对实际应用至关重要。
- Method: 提出三个关键组件：数据增强、新型多模态融合模块和模态丢弃训练策略。
- Result: 实验表明，方法显著提升了基线模型的鲁棒性，并在NuScenes数据集上达到最优性能。
- Conclusion: 研究为开发更鲁棒可靠的高清地图构建模型提供了重要见解，推动了其在自动驾驶中的实际应用。


### [33] [AVC-DPO: Aligned Video Captioning via Direct Preference Optimization](https://arxiv.org/abs/2507.01492)
*Jiyang Tang,Hengyi Li,Yifan Du,Wayne Xin Zhao*

Main category: cs.CV

TL;DR: AVC-DPO是一种后训练框架，通过偏好对齐增强视频MLLM的标题生成能力，特别关注时空动态和空间信息。

- Motivation: 现有视频MLLM在标题生成任务中难以根据人类偏好调整焦点，需改进以更好地满足需求。
- Method: 设计增强提示，针对时空动态和空间信息，利用基础模型在不同提示条件下的响应进行偏好感知训练和对齐。
- Result: 在LOVE@CVPR'25 Workshop Track 1A中表现优异，VDC基准上排名第一。
- Conclusion: AVC-DPO通过偏好对齐显著提升了视频MLLM的标题生成能力。


### [34] [Crop Pest Classification Using Deep Learning Techniques: A Review](https://arxiv.org/abs/2507.01494)
*Muhammad Hassam Ejaz,Muhammad Bilal,Usman Habib*

Main category: cs.CV

TL;DR: 综述分析了2018-2025年间37项关于AI害虫分类的研究，探讨了模型架构、数据集及技术挑战，指出从CNN转向混合和Transformer模型的趋势，并总结了当前的主要挑战。

- Motivation: 传统害虫监测方法效率低且难以扩展，深度学习技术（如CNN、ViT）为自动化害虫检测提供了高效解决方案。
- Method: 通过分析37项研究，按作物类型、害虫种类、模型架构、数据集和技术挑战进行分类总结。
- Result: 研究发现早期研究多依赖CNN，而最新趋势转向混合和Transformer模型，提高了准确性和上下文理解能力，但仍面临数据集不平衡、小害虫检测难等挑战。
- Conclusion: 综述提供了该领域的结构化概述，指出了关键挑战和未来方向，为AI害虫监测系统的发展提供了参考。


### [35] [ReFlex: Text-Guided Editing of Real Images in Rectified Flow via Mid-Step Feature Extraction and Attention Adaptation](https://arxiv.org/abs/2507.01496)
*Jimyeong Kim,Jungwon Park,Yeji Song,Nojun Kwak,Wonjong Rhee*

Main category: cs.CV

TL;DR: 提出了一种无需训练、无需用户提供掩码的ReFlow真实图像编辑方法，通过分析中间表示和利用中步潜在特征，显著提升了编辑效果和文本对齐。

- Motivation: 尽管ReFlow在文本到图像生成中表现优异，但其在真实图像编辑中的应用仍具挑战性，需要一种无需额外训练或用户干预的方法。
- Method: 通过分析多模态Transformer块的中间表示，提取关键特征，并利用中步潜在特征进行结构保留，同时调整注意力机制以提升编辑性和文本对齐。
- Result: 在两个基准测试中优于九种基线方法，并通过人类评估验证了用户对该方法的强烈偏好。
- Conclusion: 该方法在真实图像编辑中表现出色，具有无需训练、无需掩码的优势，且能显著提升编辑效果和文本对齐。


### [36] [Integrating Traditional and Deep Learning Methods to Detect Tree Crowns in Satellite Images](https://arxiv.org/abs/2507.01502)
*Ozan Durgut,Beril Kallfelz-Sirmacek,Cem Unsalan*

Main category: cs.CV

TL;DR: 论文提出了一种结合传统方法和深度学习的树冠检测新方法，通过规则后处理提升检测精度和鲁棒性。

- Motivation: 全球变暖、生物多样性丧失和空气污染等问题亟需森林监测，但缺乏自动化监测手段。
- Method: 结合传统方法进行特征提取和分割，利用深度学习检测树冠，并通过规则后处理优化结果。
- Result: 新方法提高了树冠检测数量，并分析了其优缺点和改进空间。
- Conclusion: 提出的规则方法有效提升了树冠检测的准确性和鲁棒性，为森林监测提供了新思路。


### [37] [Following the Clues: Experiments on Person Re-ID using Cross-Modal Intelligence](https://arxiv.org/abs/2507.01504)
*Robert Aufschläger,Youssef Shoeb,Azarm Nowzad,Michael Heigl,Fabian Bally,Martin Schramm*

Main category: cs.CV

TL;DR: 提出了一种跨模态框架cRID，结合视觉语言模型和图注意力网络，用于检测行人数据中的PII并提升行人重识别性能。

- Motivation: 街景数据作为开放数据对自动驾驶和AI研究至关重要，但其中包含的个人可识别信息（PII）带来隐私风险。
- Method: 结合大型视觉语言模型、图注意力网络和表征学习，检测文本可描述的PII线索，并增强行人重识别。
- Result: 在Market-1501到CUHK03-np的跨数据集实验中表现出改进性能。
- Conclusion: cRID框架能有效检测语义上有意义的PII，并提升行人重识别的实用性。


### [38] [Mamba Guided Boundary Prior Matters: A New Perspective for Generalized Polyp Segmentation](https://arxiv.org/abs/2507.01509)
*Tapas K. Dutta,Snehashis Majhi,Deepak Ranjan Nayak,Debesh Jha*

Main category: cs.CV

TL;DR: SAM-MaGuP是一种基于Segment Anything Model的创新方法，通过边界蒸馏模块和1D-2D Mamba适配器，显著提升了息肉分割的准确性和鲁棒性。

- Motivation: 息肉分割在结肠镜图像中至关重要，但由于息肉形状、大小和颜色的多样性以及边界模糊等问题，现有方法难以实现稳定分割。
- Method: 提出SAM-MaGuP，结合边界蒸馏模块和1D-2D Mamba适配器，增强全局上下文交互和边界特征学习。
- Result: 在五个数据集上表现优异，超越现有方法，实现了更高的分割准确性和鲁棒性。
- Conclusion: SAM-MaGuP通过创新设计，为息肉分割领域设定了新标准。


### [39] [Exploring Pose-based Sign Language Translation: Ablation Studies and Attention Insights](https://arxiv.org/abs/2507.01532)
*Tomas Zelezny,Jakub Straka,Vaclav Javorek,Ondrej Valach,Marek Hruz,Ivan Gruber*

Main category: cs.CV

TL;DR: 本文探讨了基于姿态的数据预处理技术（归一化、插值和增强）对手语翻译（SLT）性能的影响，使用改进的T5编码器-解码器模型，实验表明这些技术能显著提升模型性能。

- Motivation: 研究如何通过姿态数据预处理技术提升手语翻译系统的性能，特别是在连续、无注释的翻译任务中。
- Method: 采用改进的T5编码器-解码器模型处理姿态表示，并在YouTubeASL和How2Sign数据集上进行消融实验，分析不同预处理策略的效果。
- Result: 适当的归一化、插值和增强技术显著提高了模型的鲁棒性和泛化能力，并发现添加专用寄存器标记可进一步提升性能。
- Conclusion: 姿态数据预处理技术对手语翻译性能至关重要，模型改进和公开数据为未来研究提供了基础。


### [40] [TrackingMiM: Efficient Mamba-in-Mamba Serialization for Real-time UAV Object Tracking](https://arxiv.org/abs/2507.01535)
*Bingxi Liu,Calvin Chen,Junhao Li,Guyang Yu,Haoqian Song,Xuchen Liu,Jinqiang Cui,Hong Zhang*

Main category: cs.CV

TL;DR: 论文提出了一种基于Mamba模型的TrackingMiM架构，解决了ViT在无人机跟踪中的二次复杂度问题，实现了高效的长序列建模和实时处理。

- Motivation: Vision Transformer（ViT）在无人机（UAV）跟踪系统中因二次复杂度问题难以实时处理数据，而现有Mamba方法存在时间连续性不足的问题。
- Method: 提出了TrackingMiM，一种Mamba-in-Mamba架构，通过嵌套扫描独立处理时空一致的图像块，模板帧作为查询令牌用于跟踪。
- Result: 在五个UAV跟踪基准测试中，TrackingMiM实现了最高精度和显著的速度提升。
- Conclusion: TrackingMiM是一种高效且低计算负担的模型，适用于实时无人机跟踪任务。


### [41] [A Multi-Centric Anthropomorphic 3D CT Phantom-Based Benchmark Dataset for Harmonization](https://arxiv.org/abs/2507.01539)
*Mohammadreza Amirian,Michael Bach,Oscar Jimenez-del-Toro,Christoph Aberle,Roger Schaer,Vincent Andrearczyk,Jean-Félix Maestrati,Maria Martin Asiain,Kyriakos Flouris,Markus Obmann,Clarisse Dromain,Benoît Dufour,Pierre-Alexandre Alois Poletti,Hendrik von Tengg-Kobligk,Rolf Hügli,Martin Kretzschmar,Hatem Alkadhi,Ender Konukoglu,Henning Müller,Bram Stieltjes,Adrien Depeursinge*

Main category: cs.CV

TL;DR: 本文介绍了一个开源基准数据集，用于促进AI在CT分析中的泛化能力，通过减少数据分布偏移。

- Motivation: 解决AI在医学CT分析中因数据分布偏移导致的泛化能力差问题。
- Method: 使用包含1378个CT扫描的开源数据集，涵盖不同扫描仪和设置，并提出评估方法。
- Result: 提供了基线结果和开源代码，支持AI谐调技术的发展。
- Conclusion: 该数据集和方法有助于推动AI谐调技术的开发和应用。


### [42] [Interpolation-Based Event Visual Data Filtering Algorithms](https://arxiv.org/abs/2507.01557)
*Marcin Kowlaczyk,Tomasz Kryjak*

Main category: cs.CV

TL;DR: 提出了一种基于无限脉冲响应（IIR）滤波器矩阵的方法，能去除事件相机数据中约99%的噪声，同时保留有效信号，适用于嵌入式设备。

- Motivation: 事件相机数据流中存在显著噪声，影响了其在神经形态视觉领域的应用。
- Method: 提出了四种基于IIR滤波器矩阵的算法，并在多个事件数据集上进行了测试，包括添加人工噪声和动态视觉传感器记录的噪声。
- Result: 方法能去除约99%的噪声，内存占用约30KB，适用于1280x720分辨率的传感器。
- Conclusion: 该方法高效且适用于嵌入式设备，为事件相机的噪声处理提供了可行方案。


### [43] [A Gift from the Integration of Discriminative and Diffusion-based Generative Learning: Boundary Refinement Remote Sensing Semantic Segmentation](https://arxiv.org/abs/2507.01573)
*Hao Wang,Keyan Hu,Xin Guo,Haifeng Li,Chao Tao*

Main category: cs.CV

TL;DR: 论文提出了一种结合判别学习和扩散生成学习的框架（IDGBR），用于改进遥感语义分割中的边界精度。

- Motivation: 现有方法在捕捉高频边界信息方面存在不足，而扩散生成模型擅长生成高频细节，但语义推理能力较弱。因此，需要结合两者的优势。
- Method: 通过判别模型生成粗分割图，结合原始图像输入条件引导网络，再利用扩散去噪过程迭代优化边界。
- Result: 在五个遥感语义分割数据集上的实验表明，IDGBR能显著改进边界精度。
- Conclusion: IDGBR框架有效结合了判别和生成学习的优势，提升了边界分割的精度。


### [44] [SketchColour: Channel Concat Guided DiT-based Sketch-to-Colour Pipeline for 2D Animation](https://arxiv.org/abs/2507.01586)
*Bryan Constantine Sadihin,Michael Hua Wang,Shei Pern Chua,Hang Su*

Main category: cs.CV

TL;DR: SketchColour是一种基于扩散变换器（DiT）的2D动画草图到色彩转换方法，显著减少了参数和GPU内存使用，并在性能上优于现有方法。

- Motivation: 传统2D动画制作需要大量手工绘制和上色，耗时耗力。SketchColour旨在通过自动化技术提高效率。
- Method: 采用扩散变换器（DiT）架构，通过轻量级通道连接适配器和LoRA微调注入草图信息，避免ControlNet的参数膨胀。
- Result: 在SAKUGA数据集上表现优于现有视频上色方法，仅用一半训练数据即可实现更高的时间一致性和更少的伪影。
- Conclusion: SketchColour为2D动画制作提供了一种高效、低资源消耗的自动化解决方案。


### [45] [Towards Controllable Real Image Denoising with Camera Parameters](https://arxiv.org/abs/2507.01587)
*Youngjin Oh,Junhyeong Kwon,Keuntek Lee,Nam Ik Cho*

Main category: cs.CV

TL;DR: 提出了一种基于相机参数的可控去噪框架，通过ISO、快门速度和光圈值调整去噪强度，提升了去噪网络的性能。

- Motivation: 现有深度学习方法在去噪时缺乏根据噪声水平、相机设置和用户偏好调整去噪强度的灵活性。
- Method: 将ISO、快门速度和光圈值转换为向量，用于控制和增强去噪网络的性能。
- Result: 实验表明，该方法为标准的去噪神经网络增加了可控性，并提升了性能。
- Conclusion: 提出的框架成功实现了基于相机参数的自适应去噪，且代码已开源。


### [46] [Autonomous AI Surveillance: Multimodal Deep Learning for Cognitive and Behavioral Monitoring](https://arxiv.org/abs/2507.01590)
*Ameer Hamza,Zuhaib Hussain But,Umar Arif,Samiya,M. Abdullah Asad,Muhammad Naeem*

Main category: cs.CV

TL;DR: 该研究提出了一种多模态课堂监控系统，结合睡意检测、手机使用追踪和人脸识别，以高精度评估学生注意力。系统采用YOLOv8、LResNet Occ FC、YOLO和MTCNN模型，实现实时监测，并在核心PHP应用中部署，使用ESP32-CAM硬件。

- Motivation: 提升课堂监控的精确性和全面性，同时实现自动考勤记录，适用于多样化教育环境。
- Method: 集成YOLOv8检测手机和睡意，LResNet Occ FC和MTCNN实现人脸识别，使用RMFD和Roboflow数据集训练模型。
- Result: 睡意检测mAP@50为97.42%，人脸识别验证准确率86.45%，手机检测mAP@50为85.89%。
- Conclusion: 该系统通过多模态集成显著提升了课堂监控效果，并具备自动考勤功能，适用于广泛教育场景。


### [47] [DepthSync: Diffusion Guidance-Based Depth Synchronization for Scale- and Geometry-Consistent Video Depth Estimation](https://arxiv.org/abs/2507.01603)
*Yue-Jiang Dong,Wang Zhao,Jiale Xu,Ying Shan,Song-Hai Zhang*

Main category: cs.CV

TL;DR: DepthSync提出了一种无需训练的框架，通过扩散引导实现长视频深度估计的尺度和几何一致性。

- Motivation: 现有方法在处理长视频时存在尺度不一致和几何结构忽略的问题。
- Method: 引入尺度引导和几何引导，协同优化去噪过程以实现一致性。
- Result: 实验验证了DepthSync在长视频中提升尺度和几何一致性的有效性。
- Conclusion: DepthSync为长视频深度估计提供了更一致的解决方案。


### [48] [Survivability of Backdoor Attacks on Unconstrained Face Recognition Systems](https://arxiv.org/abs/2507.01607)
*Quentin Le Roux,Yannick Teglia,Teddy Furon,Philippe Loubet-Moundi,Eric Bourbao*

Main category: cs.CV

TL;DR: 本文首次系统研究了深度学习人脸识别系统中的后门攻击，提出了两种针对人脸检测任务的攻击方法，并验证了大规模损失训练的模型同样易受攻击。通过20种管道配置和15种攻击案例，展示了单一后门可绕过系统功能，并提出了应对措施。

- Motivation: 深度学习人脸识别的广泛应用带来了安全隐患，但现有研究对真实无约束系统中的后门攻击关注不足。
- Method: 通过探索DNN后门在人脸识别管道中的可行性，提出了人脸生成和地标偏移两种攻击方法，并验证了大规模损失训练的模型的脆弱性。
- Result: 实验证明单一后门可绕过系统功能，展示了20种管道配置和15种攻击案例的有效性。
- Conclusion: 研究揭示了人脸识别系统的后门风险，并提供了针对性的最佳实践和防御措施。


### [49] [Perception-Oriented Latent Coding for High-Performance Compressed Domain Semantic Inference](https://arxiv.org/abs/2507.01608)
*Xu Zhang,Ming Lu,Yan Chen,Zhan Ma*

Main category: cs.CV

TL;DR: POLC提出了一种感知导向的潜在编码方法，通过丰富潜在特征的语义内容，提升压缩域语义推理性能，同时减少微调参数。

- Motivation: 传统基于MSE优化的图像编码模型潜在空间语义贫乏，且全模型微调计算成本高。
- Method: 提出POLC方法，通过感知导向优化丰富潜在空间语义，仅需轻量级适配器微调。
- Result: POLC在压缩域语义推理中性能接近生成式图像编码方法，同时显著提升视觉任务表现，微调开销极小。
- Conclusion: POLC为压缩域语义推理提供了一种高效且高性能的解决方案。


### [50] [Prompt Guidance and Human Proximal Perception for HOT Prediction with Regional Joint Loss](https://arxiv.org/abs/2507.01630)
*Yuxiao Wang,Yu Lei,Zhenao Wei,Weiying Xue,Xinyu Jiang,Nan Zhuang,Qi Liu*

Main category: cs.CV

TL;DR: P3HOT框架通过结合提示引导和人类近端感知，改进HOT检测任务，解决了现有模型在区域分割和类别一致性上的问题，并在多个指标上取得显著提升。

- Motivation: 现有HOT检测模型局限于单一图像类型，导致过度分割和区域类别不一致，亟需改进。
- Method: 提出P3HOT框架，结合语义驱动的提示机制和人类近端感知机制，动态感知关键深度范围，并引入区域联合损失（RJLoss）和新评估指标AD-Acc。
- Result: 在两个基准数据集上，P3HOT在四个指标上均取得最佳性能，具体提升为0.7↑、2.0↑、1.6↑和11.0↑。
- Conclusion: P3HOT通过多机制融合显著提升了HOT检测的性能，解决了现有方法的局限性。


### [51] [Tile and Slide : A New Framework for Scaling NeRF from Local to Global 3D Earth Observation](https://arxiv.org/abs/2507.01631)
*Camille Billouard,Dawa Derksen,Alexandre Constantin,Bruno Vallet*

Main category: cs.CV

TL;DR: Snake-NeRF是一种扩展到大场景的NeRF框架，通过分块处理和优化策略，解决了内存限制问题。

- Motivation: 现有NeRF方法因内存限制仅适用于小场景，需扩展到大场景。
- Method: 采用分块处理、图像重叠裁剪、2×2 3D瓦片策略和分段采样器。
- Result: 单GPU上线性时间处理大卫星图像，质量无损失。
- Conclusion: Snake-NeRF有效扩展了NeRF的应用范围，适用于大场景。


### [52] [Depth Anything at Any Condition](https://arxiv.org/abs/2507.01634)
*Boyuan Sun,Modi Jin,Bowen Yin,Qibin Hou*

Main category: cs.CV

TL;DR: DepthAnything-AC是一种基础单目深度估计模型，能够在多样环境条件下工作，通过无监督一致性正则化微调和小量未标记数据提升性能。

- Motivation: 现有基础MDE模型在复杂开放环境（如光照变化、恶劣天气和传感器失真）中表现不佳，需解决数据稀缺和伪标签生成问题。
- Method: 提出无监督一致性正则化微调范式和空间距离约束，以学习补丁级相对关系。
- Result: 实验显示DepthAnything-AC在多种基准测试（包括恶劣天气、合成失真和通用场景）中具有零样本能力。
- Conclusion: DepthAnything-AC在复杂环境条件下表现出色，为单目深度估计提供了更鲁棒的解决方案。


### [53] [SAILViT: Towards Robust and Generalizable Visual Backbones for MLLMs via Gradual Feature Refinement](https://arxiv.org/abs/2507.01643)
*Weijie Yin,Dingkang Yang,Hongyuan Dong,Zijian Kang,Jiacong Wang,Xiao Liang,Chao Feng,Jiao Ran*

Main category: cs.CV

TL;DR: SAILViT是一种逐步特征学习增强的Vision Transformer，旨在解决ViT与LLM直接联合训练时的参数冲突和模态语义鸿沟问题，提升MLLM在多模态交互中的性能。

- Motivation: 现有ViT通过图像-文本对比学习或自监督机制表现优异，但难以与LLM直接联合训练，存在参数初始化冲突和模态语义鸿沟问题。
- Method: 提出SAILViT，采用逐步特征细化实现粗到细的特征对齐和世界知识注入，适应目标训练需求。
- Result: SAILViT在不同参数规模、架构、训练策略和数据规模下表现出强大的鲁棒性和泛化性，显著提升MLLM在OpenCompass基准上的性能。
- Conclusion: SAILViT有效解决了ViT与LLM联合训练的挑战，为MLLM在多模态任务中的性能提升提供了新思路。


### [54] [Autoregressive Image Generation with Linear Complexity: A Spatial-Aware Decay Perspective](https://arxiv.org/abs/2507.01652)
*Yuxin Mao,Zhen Qin,Jinxing Zhou,Hui Deng,Xuyang Shen,Bin Fan,Jing Zhang,Yiran Zhong,Yuchao Dai*

Main category: cs.CV

TL;DR: 提出了一种新型注意力机制LASAD，用于解决线性注意力在图像生成中无法捕捉长距离依赖的问题，显著提升了生成质量和计算效率。

- Motivation: 现有自回归模型依赖Transformer架构，计算复杂度和内存开销高，线性注意力机制在图像生成中表现不佳。
- Method: 提出Linear Attention with Spatial-Aware Decay (LASAD)，通过2D空间位置计算衰减因子，保持空间关系。
- Result: 在ImageNet上，LASADGen实现了最先进的生成性能和计算效率。
- Conclusion: LASADGen成功平衡了线性注意力的效率和高质量生成所需的空间理解。


### [55] [RobuSTereo: Robust Zero-Shot Stereo Matching under Adverse Weather](https://arxiv.org/abs/2507.01653)
*Yuran Wang,Yingping Liang,Yutao Hu,Ying Fu*

Main category: cs.CV

TL;DR: RobuSTereo框架通过扩散模拟和数据增强解决恶劣天气下立体匹配模型的泛化问题，结合专用ConvNet和去噪Transformer提升特征提取能力。

- Motivation: 恶劣天气条件下，立体匹配模型因数据稀缺和特征提取困难而泛化能力差。
- Method: 提出扩散模拟管道生成合成数据，设计结合ConvNet和去噪Transformer的特征编码器。
- Result: 显著提升模型在恶劣天气下的鲁棒性和泛化能力。
- Conclusion: RobuSTereo有效解决了恶劣天气下立体匹配的挑战。


### [56] [SPoT: Subpixel Placement of Tokens in Vision Transformers](https://arxiv.org/abs/2507.01654)
*Martine Hjelkrem-Tan,Marius Aasan,Gabriel Y. Arteaga,Adín Ramírez Rivera*

Main category: cs.CV

TL;DR: SPoT是一种新的视觉Transformer标记化策略，通过连续放置标记避免网格限制，显著减少推理所需的标记数量。

- Motivation: 标准标记化方法将特征限制在离散的网格中，阻碍了模型在稀疏场景中的潜力。
- Method: 提出Subpixel Placement of Tokens (SPoT)，通过连续放置标记，并结合oracle-guided搜索优化位置。
- Result: SPoT显著减少了推理所需的标记数量，同时提升了性能。
- Conclusion: SPoT为灵活、高效且可解释的ViT架构提供了新方向，将稀疏性转化为战略优势。


### [57] [What does really matter in image goal navigation?](https://arxiv.org/abs/2507.01667)
*Gianluca Monaci,Philippe Weinzaepfel,Christian Wolf*

Main category: cs.CV

TL;DR: 研究探讨了端到端强化学习在图像目标导航任务中的有效性，分析了架构选择和模拟器设置对性能的影响，并展示了部分能力可迁移到更现实的场景。

- Motivation: 验证端到端强化学习是否能在图像目标导航任务中高效解决核心导航和方向计算问题，避免依赖专用图像匹配或预训练模块。
- Method: 通过大规模研究分析不同架构选择（如延迟融合、通道堆叠等）对相对姿态估计器从导航训练中涌现的影响，并考察模拟器设置的作用。
- Result: 发现模拟器设置会影响性能，但部分能力可迁移到更现实场景；导航性能与涌现的相对姿态估计能力相关。
- Conclusion: 端到端强化学习在图像目标导航中具有潜力，但需注意模拟器设置的局限性，并进一步探索能力迁移和性能相关性。


### [58] [Facial Emotion Learning with Text-Guided Multiview Fusion via Vision-Language Model for 3D/4D Facial Expression Recognition](https://arxiv.org/abs/2507.01673)
*Muzammil Behzad*

Main category: cs.CV

TL;DR: FACET-VLM是一个用于3D/4D面部表情识别的视觉语言框架，通过多视角表示学习和语义引导实现高精度识别。

- Motivation: 3D/4D面部表情识别在情感计算中具有挑战性，但对人类行为理解、医疗监测和人机交互至关重要。
- Method: 提出CVSA、MTGF和多视角一致性损失三个关键组件，整合多视角表示学习和语义引导。
- Result: 在多个基准测试中达到最先进水平，并成功扩展到4D微表情识别。
- Conclusion: FACET-VLM为多模态面部表情识别提供了高效、可扩展的解决方案。


### [59] [Component Adaptive Clustering for Generalized Category Discovery](https://arxiv.org/abs/2507.01711)
*Mingfu Yan,Jiancheng Huang,Yifan Liu,Shifeng Chen*

Main category: cs.CV

TL;DR: AdaGCD是一种基于自适应槽注意力的对比学习框架，用于在部分标记数据集中发现已知和未知类别，无需预定义类别数量。

- Motivation: 传统方法依赖预定义类别数量的假设，无法处理真实数据的复杂性和变异性。
- Method: 提出AdaGCD框架，结合自适应槽注意力（AdaSlot），动态确定槽的数量，实现灵活聚类。
- Result: 在公开和细粒度数据集上验证了有效性，展示了利用空间局部信息在未标记数据中发现类别的优势。
- Conclusion: AdaGCD通过自适应机制和动态槽分配，显著提升了开放世界场景中的类别发现能力。


### [60] [Using Wavelet Domain Fingerprints to Improve Source Camera Identification](https://arxiv.org/abs/2507.01712)
*Xinle Tian,Matthew Nunes,Emiko Dupont,Shaunagh Downing,Freddie Lichtenstein,Matt Burns*

Main category: cs.CV

TL;DR: 提出了一种基于小波域的相机指纹检测方法，避免了传统方法中的反演步骤，提高了检测精度和处理速度。

- Motivation: 传统的小波去噪方法在提取传感器模式噪声（SPN）时需要反演步骤，效率较低。
- Method: 将指纹构造为小波域指纹，直接在频域进行比较，避免反演步骤。
- Result: 实验表明，该方法在真实数据集上不仅检测精度更高，还能显著提升处理速度。
- Conclusion: 小波域指纹方法简化了提取和比较流程，具有更高的效率和准确性。


### [61] [Soft Self-labeling and Potts Relaxations for Weakly-Supervised Segmentation](https://arxiv.org/abs/2507.01721)
*Zhongwen Zhang,Yuri Boykov*

Main category: cs.CV

TL;DR: 论文提出了一种基于软自标记的弱监督分割方法，通过优化CRF/Potts损失的松弛形式，显著提升了基于涂鸦标签的训练效果，甚至优于全像素级监督。

- Motivation: 解决弱监督分割中仅部分像素有标签（涂鸦）的问题，并通过软自标记改进硬伪标签无法表示类别不确定性和错误的缺陷。
- Method: 提出了一种基于软自标记的辅助损失，系统评估了标准和新CRF松弛（凸和非凸）、邻域系统以及网络预测与软伪标签的连接项，并提出了一种通用的连续子问题求解器。
- Result: 软自标记显著提升了基于涂鸦标签的训练效果，优于更复杂的专用WSSS系统，甚至在某些情况下优于全像素级监督。
- Conclusion: 软自标记是一种有效的弱监督分割方法，其通用思想可应用于其他弱监督问题/系统。


### [62] [When Does Pruning Benefit Vision Representations?](https://arxiv.org/abs/2507.01722)
*Enrico Cassano,Riccardo Renzulli,Andrea Bragagnolo,Marco Grangetto*

Main category: cs.CV

TL;DR: 本文研究了剪枝对视觉模型在可解释性、无监督目标发现和人类感知对齐三个维度的影响，发现存在“最佳点”使稀疏模型表现更优。

- Motivation: 探讨剪枝如何影响深度视觉模型的可解释性、表示学习和人类感知对齐，以填补现有研究的空白。
- Method: 分析不同视觉网络架构在不同稀疏度下的特征归因方法，研究剪枝是否促进更简洁的结构化表示，并评估剪枝是否增强模型与人类感知的对齐。
- Result: 发现稀疏模型在特定条件下（“最佳点”）表现出更高的可解释性、下游泛化能力和人类对齐性，但这些条件高度依赖网络架构和参数规模。
- Conclusion: 剪枝与视觉模型表现之间存在复杂关系，需进一步研究剪枝何时及如何优化视觉表示。


### [63] [ECCV 2024 W-CODA: 1st Workshop on Multimodal Perception and Comprehension of Corner Cases in Autonomous Driving](https://arxiv.org/abs/2507.01735)
*Kai Chen,Ruiyuan Gao,Lanqing Hong,Hang Xu,Xu Jia,Holger Caesar,Dengxin Dai,Bingbing Liu,Dzmitry Tsishkou,Songcen Xu,Chunjing Xu,Qiang Xu,Huchuan Lu,Dit-Yan Yeung*

Main category: cs.CV

TL;DR: 介绍了第一届W-CODA研讨会的详情，聚焦于自动驾驶极端场景的下一代解决方案。

- Motivation: 探索前沿多模态感知与理解技术，以解决自动驾驶中的极端场景问题。
- Method: 邀请5位学术界和工业界专家分享最新进展，并举办双轨挑战赛（极端场景理解与生成）。
- Result: 研讨会汇集了研究论文和挑战赛成果，推动自动驾驶技术的进步。
- Conclusion: W-CODA将持续弥合前沿技术与完全智能、可靠的自动驾驶之间的差距。


### [64] [HOI-Dyn: Learning Interaction Dynamics for Human-Object Motion Diffusion](https://arxiv.org/abs/2507.01737)
*Lin Wu,Zhixiang Chen,Jianglin Lan*

Main category: cs.CV

TL;DR: HOI-Dyn框架通过驱动-响应系统生成逼真的3D人-物交互，利用轻量级Transformer模型预测物体对人物动作的反应，并通过残差动力学损失提升一致性。

- Motivation: 现有方法独立处理人物和物体运动，导致交互行为物理上不合理且因果不一致。
- Method: 提出HOI-Dyn框架，将交互建模为驱动-响应系统，使用Transformer预测物体响应，并引入残差动力学损失优化训练。
- Result: 实验表明，HOI-Dyn提升了交互生成质量，并提供了可行的评估指标。
- Conclusion: HOI-Dyn通过显式建模交互动力学，实现了更逼真和一致的人-物交互生成。


### [65] [DeRIS: Decoupling Perception and Cognition for Enhanced Referring Image Segmentation through Loopback Synergy](https://arxiv.org/abs/2507.01738)
*Ming Dai,Wenxuan Cheng,Jiang-jiang Liu,Sen Yang,Wenxiao Cai,Yanpeng Sun,Wankou Yang*

Main category: cs.CV

TL;DR: DeRIS框架将Referring Image Segmentation分解为感知和认知两个模块，提出Loopback Synergy机制增强模块间协同，并引入数据增强解决长尾分布问题。

- Motivation: 现有RIS框架缺乏对性能瓶颈的系统分析，尤其是多模态认知能力的不足。
- Method: DeRIS将RIS分解为感知和认知模块，提出Loopback Synergy机制，并引入非参照样本转换数据增强。
- Result: DeRIS在非和多参照场景中表现出色，无需专门架构修改。
- Conclusion: DeRIS通过模块化分析和协同机制，显著提升了RIS性能，具有广泛适用性。


### [66] [Calibrated Self-supervised Vision Transformers Improve Intracranial Arterial Calcification Segmentation from Clinical CT Head Scans](https://arxiv.org/abs/2507.01744)
*Benjamin Jin,Grant Mair,Joanna M. Wardlaw,Maria del C. Valdés Hernández*

Main category: cs.CV

TL;DR: 本文研究了基于Vision Transformers（ViTs）和掩码自编码器（MAE）框架的3D医学图像分割方法，首次将其应用于颅内动脉钙化（IAC）的自动量化，并在临床数据中验证了其优越性。

- Motivation: 3D ViTs在医学图像分割中表现不佳，但其在MAE框架下的高效自监督训练特性使其适用于无需昂贵标注的大规模医学影像数据。IAC作为神经血管疾病的生物标志物，其自动量化有助于大规模风险评估。
- Method: 采用MAE预训练ViTs，并在IST-3临床试验的异构数据上微调用于IAC分割。研究了低patch大小和插值上采样对ViTs性能的影响。
- Result: 自监督ViT在Dice分数上比监督nnU-Net基线高3.2分；低patch大小和插值上采样对ViTs表现至关重要；ViTs对高切片厚度更具鲁棒性，临床风险分类提升46%。
- Conclusion: MAE预训练的ViTs在IAC分割中表现优异，具有临床实用价值，代码已开源。


### [67] [SSL4SAR: Self-Supervised Learning for Glacier Calving Front Extraction from SAR Imagery](https://arxiv.org/abs/2507.01747)
*Nora Gourmelon,Marcel Dreier,Martin Mayr,Thorsten Seehaus,Dakota Pyles,Matthias Braun,Andreas Maier,Vincent Christlein*

Main category: cs.CV

TL;DR: 论文提出两种自监督多模态预训练技术和一种混合模型架构，用于从合成孔径雷达图像中提取冰川崩解前沿位置，显著提升了监测精度。

- Motivation: 冰川冰量损失加剧，需要更精确的全年监测方法以理解崩解过程。现有基于ImageNet预训练的模型因领域差异表现不佳。
- Method: 提出两种自监督多模态预训练技术，利用新数据集SSL4SAR，并设计混合模型架构（Swin Transformer编码器+残差CNN解码器）。
- Result: 在CaFFe基准数据集上，模型平均距离误差为293米，优于之前最佳模型67米；集成模型误差降至75米，接近人类水平（38米）。
- Conclusion: 该技术显著提升了冰川崩解前沿的季节性变化监测精度。


### [68] [Rethinking Discrete Tokens: Treating Them as Conditions for Continuous Autoregressive Image Synthesis](https://arxiv.org/abs/2507.01756)
*Peng Zheng,Junke Wang,Yi Chang,Yizhou Yu,Rui Ma,Zuxuan Wu*

Main category: cs.CV

TL;DR: DisCon框架通过将离散标记作为条件信号而非生成目标，解决了连续表示建模的优化挑战，同时避免了量化带来的信息损失，显著提升了图像生成质量。

- Motivation: 大型语言模型（LLMs）的进展激发了将图像编码为离散标记的兴趣，但基于自回归（AR）的视觉生成模型因量化过程导致信息损失，降低了图像保真度。
- Method: DisCon框架重新将离散标记解释为条件信号，建模连续表示在离散标记条件下的概率分布，从而避免直接建模连续表示的挑战。
- Result: DisCon在ImageNet 256×256生成任务上取得了1.38的gFID分数，明显优于现有自回归方法。
- Conclusion: DisCon通过结合离散和连续表示的优势，为视觉生成提供了一种高效且高质量的解决方案。


### [69] [Are Vision Transformer Representations Semantically Meaningful? A Case Study in Medical Imaging](https://arxiv.org/abs/2507.01788)
*Montasir Shams,Chashi Mahiul Islam,Shaeke Salman,Phat Tran,Xiuwen Liu*

Main category: cs.CV

TL;DR: 该论文揭示了视觉变换器（ViTs）在医学图像分类中的表示缺乏语义意义，且对微小变化具有脆弱性，导致分类结果不可靠。

- Motivation: 研究ViTs在医学图像任务中的表示是否具有语义意义，以及其对抗微小变化的鲁棒性。
- Method: 使用基于投影梯度的算法分析ViTs的表示。
- Result: ViTs的表示缺乏语义意义，对微小变化敏感，分类准确率可能下降超过60%。
- Conclusion: ViTs在医学图像分类中的表示存在根本性问题，可能影响其在安全关键系统中的部署。


### [70] [Boosting Adversarial Transferability Against Defenses via Multi-Scale Transformation](https://arxiv.org/abs/2507.01791)
*Zihong Guo,Chen Wan,Yayin Zheng,Hailing Kuang,Xiaohai Lu*

Main category: cs.CV

TL;DR: 提出了一种新的分段高斯金字塔（SGP）攻击方法，通过多尺度图像增强对抗样本的迁移性，显著提高了对防御模型的攻击成功率。

- Motivation: 对抗样本的迁移性对深度神经网络构成重大安全威胁，现有方法多关注单尺度图像，限制了攻击效果。
- Method: 采用高斯滤波和三种下采样方法构建多尺度样本，计算各尺度损失函数的梯度并取平均以确定对抗扰动。
- Result: 实验表明，SGP显著提高了对黑盒防御模型的攻击成功率，平均提升2.3%至32.6%。
- Conclusion: SGP是一种高扩展性的输入变换方法，可轻松集成到现有对抗攻击中，有效提升迁移性。


### [71] [FreeLoRA: Enabling Training-Free LoRA Fusion for Autoregressive Multi-Subject Personalization](https://arxiv.org/abs/2507.01792)
*Peng Zheng,Ye Wang,Rui Ma,Zuxuan Wu*

Main category: cs.CV

TL;DR: FreeLoRA是一个无需训练的框架，通过融合多个特定主题的LoRA模块实现多主题个性化图像生成。

- Motivation: 现有方法在多主题个性化生成中存在复杂调整或联合优化的问题，FreeLoRA旨在解决这一挑战。
- Method: 采用Full Token Tuning策略训练特定主题的LoRA模块，并通过Subject-Aware Inference在推理时激活对应模块。
- Result: 实验表明FreeLoRA在主题保真度和提示一致性上表现优异。
- Conclusion: FreeLoRA为多主题个性化图像生成提供了一种简单且通用的解决方案。


### [72] [HCNQA: Enhancing 3D VQA with Hierarchical Concentration Narrowing Supervision](https://arxiv.org/abs/2507.01800)
*Shengli Zhou,Jianuo Zhu,Qilin Huang,Fangjing Wang,Yanfu Zhang,Feng Zheng*

Main category: cs.CV

TL;DR: HCNQA提出了一种分层监督方法，通过模仿人类逐步聚焦的过程，确保3D VQA模型发展出合理的推理路径，避免浅层捷径。

- Motivation: 现有3D VQA模型仅监督最终输出，可能导致推理路径不合理或浅层捷径。
- Method: 采用分层监督，分三个阶段逐步聚焦，监督关键检查点。
- Result: 实验表明，HCNQA能有效确保合理的推理路径，并提升性能。
- Conclusion: HCNQA通过分层监督解决了3D VQA中的推理路径问题，表现优于现有方法。


### [73] [AMD: Adaptive Momentum and Decoupled Contrastive Learning Framework for Robust Long-Tail Trajectory Prediction](https://arxiv.org/abs/2507.01801)
*Bin Rao,Haicheng Liao,Yanchen Guan,Chengyue Wang,Bonan Wang,Jiaxun Zhang,Zhenning Li*

Main category: cs.CV

TL;DR: 提出了一种自适应动量和解耦对比学习框架（AMD），用于提升自动驾驶中长尾轨迹预测的性能。

- Motivation: 现有研究仅依赖基模型的预测误差，未考虑长尾轨迹模式的多样性和不确定性，导致对复杂危险场景的预测能力不足。
- Method: 结合改进的动量对比学习（MoCo-DT）和解耦对比学习（DCL），设计四种轨迹随机增强方法和在线迭代聚类策略。
- Result: 在nuScenes和ETH/UCY数据集上，AMD在长尾轨迹预测和整体预测精度上均表现最优。
- Conclusion: AMD框架有效提升了模型对长尾轨迹的识别能力，同时保持了高预测精度。


### [74] [Modulate and Reconstruct: Learning Hyperspectral Imaging from Misaligned Smartphone Views](https://arxiv.org/abs/2507.01835)
*Daniil Reutsky,Daniil Vladimirov,Yasin Mamedov,Georgy Perevozchikov,Nancy Mehta,Egor Ershov,Radu Timofte*

Main category: cs.CV

TL;DR: 提出了一种基于多图像的超光谱重建框架（MI-HSR），利用配备光谱滤镜的三摄像头智能手机系统，显著提升了重建精度。

- Motivation: 现有方法依赖单RGB图像，导致光谱信息丢失严重，重建精度受限。
- Method: 采用三摄像头智能手机系统，其中两个镜头配备特定光谱滤镜，通过理论和实证分析配置，提供更丰富的频谱观测。
- Result: 在提出的Doomer数据集上，新方法比现有方法提升了30%的光谱估计精度。
- Conclusion: 多视角光谱滤波结合消费级硬件，可实现更准确和实用的超光谱成像解决方案。


### [75] [MobileIE: An Extremely Lightweight and Effective ConvNet for Real-Time Image Enhancement on Mobile Devices](https://arxiv.org/abs/2507.01838)
*Hailong Yan,Ao Li,Xiangtao Zhang,Zhe Liu,Zenglin Shi,Ce Zhu,Le Zhang*

Main category: cs.CV

TL;DR: 提出了一种轻量级CNN框架，仅约4K参数，通过重参数化和增量权重优化策略实现高效实时图像增强，最高达1,100 FPS。

- Motivation: 解决深度学习模型在资源受限平台（如移动设备）上部署的高计算和内存需求问题。
- Method: 结合重参数化和增量权重优化策略，引入特征自变换模块和层次双路径注意力机制，使用局部方差加权损失优化。
- Result: 首次实现高达1,100 FPS的实时图像增强，并在多个任务中达到速度与性能的最佳平衡。
- Conclusion: 该框架在移动设备上实现了高效的实时图像增强，为资源受限平台提供了可行的解决方案。


### [76] [Future Slot Prediction for Unsupervised Object Discovery in Surgical Video](https://arxiv.org/abs/2507.01882)
*Guiqiu Liao,Matjaz Jogan,Marcel Hussing,Edward Zhang,Eric Eaton,Daniel A. Hashimoto*

Main category: cs.CV

TL;DR: 论文提出了一种动态时序槽变换器（DTST）模块，用于解决手术视频中对象中心表示学习的挑战，并在多个手术数据库中实现了最先进的性能。

- Motivation: 现实世界应用（如手术）中的异构场景难以解析为有意义的一组槽，现有方法在手术视频上表现不佳。
- Method: 提出动态时序槽变换器（DTST）模块，结合时序推理和预测未来最优槽初始化。
- Result: 在多个手术数据库中实现了最先进的性能。
- Conclusion: 无监督对象中心方法可应用于现实世界数据，并成为医疗应用中的常见工具。


### [77] [Self-Reinforcing Prototype Evolution with Dual-Knowledge Cooperation for Semi-Supervised Lifelong Person Re-Identification](https://arxiv.org/abs/2507.01884)
*Kunlun Xu,Fan Zhuo,Jiangmeng Li,Xu Zou,Jiahuan Zhou*

Main category: cs.CV

TL;DR: 论文提出了一种名为SPRED的新框架，用于解决半监督终身行人重识别（Semi-LReID）问题，通过动态原型引导的伪标签生成和新旧知识协同净化，提升未标记数据的利用率。

- Motivation: 现实场景中标注资源有限，现有LReID方法在未标记数据利用时性能下降严重，需要一种能有效利用未标记数据的解决方案。
- Method: 引入可学习身份原型动态捕捉身份分布并生成高质量伪标签，通过双知识合作方案整合当前模型和历史模型知识，净化噪声伪标签。
- Result: 在Semi-LReID基准测试中，SPRED实现了最先进的性能。
- Conclusion: SPRED通过自增强循环设计，显著提升了半监督终身行人重识别的性能。


### [78] [Reasoning to Edit: Hypothetical Instruction-Based Image Editing with Visual Reasoning](https://arxiv.org/abs/2507.01908)
*Qingdong He,Xueqin Chen,Chaoyi Wang,Yanjie Pan,Xiaobin Hu,Zhenye Gan,Yabiao Wang,Chengjie Wang,Xiangtai Li,Jiangning Zhang*

Main category: cs.CV

TL;DR: 论文提出了Reason50K数据集和ReasonBrain框架，用于解决基于指令的图像编辑中复杂隐含假设指令的推理问题。

- Motivation: 现有方法难以处理需要深层推理的复杂隐含假设指令，且缺乏相关数据集和架构支持。
- Method: 提出Reason50K数据集和ReasonBrain框架，结合多模态大语言模型和扩散模型，引入细粒度推理线索提取模块和跨模态增强器。
- Result: ReasonBrain在推理场景中表现优于现有方法，并具有零样本泛化能力。
- Conclusion: Reason50K和ReasonBrain为复杂指令推理的图像编辑提供了有效解决方案。


### [79] [Modality Agnostic, patient-specific digital twins modeling temporally varying digestive motion](https://arxiv.org/abs/2507.01909)
*Jorge Tapias Gomez,Nishant Nadkarni,Lando S. Bosma,Jue Jiang,Ergys D. Subashi,William P. Segars,James M. Balter,Mert R Sabuncu,Neelam Tyagi,Harini Veeraraghavan*

Main category: cs.CV

TL;DR: 该论文提出了一种基于患者特异性数字孪生（DT）的管道，用于评估变形图像配准（DIR）方法在胃肠道（GI）器官运动中的准确性。

- Motivation: 临床实施DIR需要基于体素的空间准确性度量，如手动标记点，但对于高度移动的GI器官难以实现。因此，研究旨在通过DT模型解决这一问题。
- Method: 通过半自动化管道，从静态3D患者扫描生成21个模拟GI运动的4D序列，并评估六种DIR方法的准确性。
- Result: 生成的DT模型运动幅度与真实患者胃运动数据相似，且能提取详细的DIR性能指标和剂量映射准确性验证。
- Conclusion: 该管道为动态复杂解剖区域的DIR工具提供了严格的测试方法，支持空间和剂量准确性的详细评估。


### [80] [3D Reconstruction and Information Fusion between Dormant and Canopy Seasons in Commercial Orchards Using Deep Learning and Fast GICP](https://arxiv.org/abs/2507.01912)
*Ranjan Sapkota,Zhichao Meng,Martin Churuvija,Xiaoqiang Du,Zenghong Ma,Manoj Karkee*

Main category: cs.CV

TL;DR: 提出了一种多季节信息融合框架，结合休眠期和生长期的RGB-D图像，通过实例分割、3D重建和模型对齐，实现果园自动化管理。

- Motivation: 果园生长期树冠密集遮挡结构，限制了机器视觉系统的能力，而休眠期树冠开放可见。因此，需要融合多季节数据以支持全年自动化管理。
- Method: 使用YOLOv9-Seg进行实例分割，Kinect Fusion进行3D重建，Fast GICP进行模型对齐，融合休眠期和生长期的RGB-D图像。
- Result: YOLOv9-Seg在休眠期数据集上表现良好（MSE 0.0047，mAP@50 0.78），Kinect Fusion重建精度高（RMSE 5.23 mm），Fast GICP实现跨季节精确对齐（最小适应分数0.00197）。
- Conclusion: 多季节融合框架显著提升了机器人系统对树冠结构的建模能力，提高了修剪和疏果等自动化操作的精度。


### [81] [IC-Custom: Diverse Image Customization via In-Context Learning](https://arxiv.org/abs/2507.01926)
*Yaowei Li,Xiaoyu Li,Zhaoyang Zhang,Yuxuan Bian,Gan Liu,Xinyuan Li,Jiale Xu,Wenbo Hu,Yating Liu,Lingen Li,Jing Cai,Yuexian Zou,Yancheng He,Ying Shan*

Main category: cs.CV

TL;DR: IC-Custom是一个统一的图像定制框架，通过上下文学习整合位置感知和无位置定制，显著优于现有方法。

- Motivation: 当前图像定制方法缺乏通用框架，限制了多样化应用场景。
- Method: 提出IC-Custom框架，结合多模态注意力机制和任务导向的注册令牌，利用高质量数据集进行训练。
- Result: 在多个基准测试中表现优异，人类偏好度提升73%，仅训练0.4%的模型参数。
- Conclusion: IC-Custom为工业应用提供了高效、通用的图像定制解决方案。


### [82] [evMLP: An Efficient Event-Driven MLP Architecture for Vision](https://arxiv.org/abs/2507.01927)
*Zhentan Zheng*

Main category: cs.CV

TL;DR: 本文提出了一种名为evMLP的新型视觉模型，结合事件驱动的局部更新机制，显著提升了视频处理的计算效率。

- Motivation: 探索多层感知机（MLPs）在视觉任务中的应用，并解决传统方法在视频处理中的冗余计算问题。
- Method: 提出evMLP模型，通过事件驱动机制选择性处理图像或特征图中的变化区域（事件），避免冗余计算。
- Result: 在ImageNet分类任务中表现优异，视频数据集实验显示计算成本显著降低且输出一致。
- Conclusion: evMLP通过事件驱动机制在保持性能的同时提升了计算效率，为视觉模型架构提供了新思路。


### [83] [CI-VID: A Coherent Interleaved Text-Video Dataset](https://arxiv.org/abs/2507.01938)
*Yiming Ju,Jijin Hu,Zhengxiong Luo,Haoge Deng,hanyu Zhao,Li Du,Chengwei Wu,Donglin Hao,Xinlong Wang,Tengfei Pan*

Main category: cs.CV

TL;DR: 论文介绍了CI-VID数据集，用于支持连贯多场景视频序列的生成，超越了传统的孤立文本-视频对。

- Motivation: 现有公共数据集主要包含孤立的文本-视频对，无法支持连贯多场景视频序列的建模。
- Method: 提出CI-VID数据集，包含34万样本，每个样本包含连贯视频片段和文本描述，支持文本和视频到视频的生成。
- Result: 实验表明，使用CI-VID训练的模型在生成视频序列时显著提高了准确性和内容一致性。
- Conclusion: CI-VID数据集在生成故事驱动内容时表现出色，具有高质量和实用价值。


### [84] [LongAnimation: Long Animation Generation with Dynamic Global-Local Memory](https://arxiv.org/abs/2507.01945)
*Nan Chen,Mengqi Huang,Yihao Meng,Zhendong Mao*

Main category: cs.CV

TL;DR: 提出LongAnimation框架，通过动态全局-局部范式实现长动画着色的一致性。

- Motivation: 长动画着色成本高，现有方法仅适用于短片段，缺乏全局一致性。
- Method: 结合SketchDiT、动态全局-局部记忆模块（DGLM）和颜色一致性奖励。
- Result: 在短片段（14帧）和长片段（平均500帧）上均表现优异。
- Conclusion: LongAnimation有效解决了长动画着色的全局一致性问题。


### [85] [Kwai Keye-VL Technical Report](https://arxiv.org/abs/2507.01949)
*Kwai Keye Team,Biao Yang,Bin Wen,Changyi Liu,Chenglong Chu,Chengru Song,Chongling Rao,Chuan Yi,Da Li,Dunju Zang,Fan Yang,Guorui Zhou,Hao Peng,Haojie Ding,Jiaming Huang,Jiangxia Cao,Jiankang Chen,Jingyun Hua,Jin Ouyang,Kaibing Chen,Kaiyu Jiang,Kaiyu Tang,Kun Gai,Shengnan Zhang,Siyang Mao,Sui Huang,Tianke Zhang,Tingting Gao,Wei Chen,Wei Yuan,Xiangyu Wu,Xiao Hu,Xingyu Lu,Yang Zhou,Yi-Fan Zhang,Yiping Yang,Yulong Chen,Zhenhua Wu,Zhenyu Li,Zhixin Ling,Ziming Li,Dehua Ma,Di Xu,Haixuan Gao,Hang Li,Jiawei Guo,Jing Wang,Lejian Ren,Muhao Wei,Qianqian Wang,Qigen Hu,Shiyao Wang,Tao Yu,Xinchen Luo,Yan Li,Yiming Liang,Yuhang Hu,Zeyi Lu,Zhuoran Yang,Zixing Zhang*

Main category: cs.CV

TL;DR: Kwai Keye-VL是一个80亿参数的多模态基础模型，专注于短视频理解，同时保持通用视觉语言能力。通过大规模高质量数据集和创新训练方法，模型在视频和图像任务中表现优异。

- Motivation: 现有MLLMs在动态、信息密集的短视频理解上表现不足，Kwai Keye-VL旨在填补这一空白。
- Method: 采用四阶段预训练和两阶段后训练，包括创新的五模式数据混合和强化学习优化。
- Result: Keye-VL在公共视频基准测试中达到领先水平，并在通用图像任务中保持竞争力。
- Conclusion: Kwai Keye-VL成功解决了短视频理解问题，并通过新基准KC-MMBench验证了其优势。


### [86] [FreeMorph: Tuning-Free Generalized Image Morphing with Diffusion Model](https://arxiv.org/abs/2507.01953)
*Yukang Cao,Chenyang Si,Jinghao Wang,Ziwei Liu*

Main category: cs.CV

TL;DR: FreeMorph是一种无需调优的图像变形方法，适用于不同语义或布局的输入，通过创新的插值和注意力模块设计，实现高质量变形，速度提升10~50倍。

- Motivation: 现有方法依赖预训练扩散模型的微调，受限于时间和语义/布局差异，FreeMorph旨在无需实例训练即可实现高保真图像变形。
- Method: 1）提出指导感知的球形插值设计，通过修改自注意力模块解决身份丢失问题；2）引入步骤导向的变分趋势，混合输入图像的自注意力模块以实现可控过渡。
- Result: FreeMorph在图像变形任务中表现优异，速度提升10~50倍，成为新的技术标杆。
- Conclusion: FreeMorph通过创新设计解决了现有方法的局限性，为图像变形提供了高效、高质量的解决方案。


### [87] [How Well Does GPT-4o Understand Vision? Evaluating Multimodal Foundation Models on Standard Computer Vision Tasks](https://arxiv.org/abs/2507.01955)
*Rahul Ramachandran,Ali Garjani,Roman Bachmann,Andrei Atanov,Oğuzhan Fatih Kar,Amir Zamir*

Main category: cs.CV

TL;DR: 论文对多模态基础模型（如GPT-4o）在标准计算机视觉任务上的表现进行了基准测试，发现其虽不及专业模型，但作为通用模型表现尚可，且在语义任务上优于几何任务。

- Motivation: 评估多模态基础模型在视觉理解方面的实际能力，明确其与专业模型的差距。
- Method: 通过提示链将标准视觉任务转化为文本可提示和API兼容的任务，建立标准化基准框架。
- Result: 模型在语义任务上表现优于几何任务，GPT-4o在非推理模型中表现最佳，推理模型在几何任务上有改进。
- Conclusion: 多模态基础模型在视觉任务中表现出一定的通用性，但仍需改进以接近专业模型水平。


### [88] [Locality-aware Parallel Decoding for Efficient Autoregressive Image Generation](https://arxiv.org/abs/2507.01957)
*Zhuoyang Zhang,Luke J. Huang,Chengyue Wu,Shang Yang,Kelly Peng,Yao Lu,Song Han*

Main category: cs.CV

TL;DR: Locality-aware Parallel Decoding (LPD) 通过灵活的自回归建模和局部感知生成顺序，显著加速自回归图像生成，减少生成步骤，同时保持质量。

- Motivation: 传统自回归图像生成依赖顺序预测，导致高延迟；现有并行化方法效果有限。
- Method: 提出灵活并行自回归建模和局部感知生成顺序两种技术，实现高并行化且保持质量。
- Result: 在 ImageNet 上，生成步骤从 256 减少到 20（256×256），1024 减少到 48（512×512），延迟降低至少 3.4 倍。
- Conclusion: LPD 在加速自回归图像生成方面具有显著优势，同时保持生成质量。
## cs.IR

### [89] [Embedding-based Retrieval in Multimodal Content Moderation](https://arxiv.org/abs/2507.01066)
*Hanzhong Liang,Jinghao Shi,Xiang Shen,Zixuan Wang,Vera Wen,Ardalan Mehrani,Zhiqian Chen,Yifan Wu,Zhixin Zhang*

Main category: cs.IR

TL;DR: 论文提出了一种基于嵌入的检索（EBR）方法，用于补充传统的内容审核分类方法，通过监督对比学习框架训练嵌入模型，显著提升了性能并降低了成本。

- Motivation: 解决传统分类方法在快速响应和成本效率方面的不足，特别是在趋势适应和紧急升级等场景中。
- Method: 采用监督对比学习（SCL）框架训练单模态和多模态嵌入模型，并设计了一个嵌入生成与视频检索集成的系统。
- Result: 离线实验中，EBR将ROC-AUC从0.85提升到0.99，PR-AUC从0.35提升到0.95；在线实验中，行动率提高了10.32%，运营成本降低了80%。
- Conclusion: EBR方法在内容审核中表现出高效、低成本和高灵活性，优于传统分类方法。
## eess.IV

### [90] [Prompt Mechanisms in Medical Imaging: A Comprehensive Survey](https://arxiv.org/abs/2507.01055)
*Hao Yang,Xinlong Liang,Zhang Li,Yue Sun,Zheyu Hu,Xinghe Xie,Behdad Dashtbozorg,Jincheng Huang,Shiwei Zhu,Luyi Han,Jiong Zhang,Shanshan Wang,Ritse Mann,Qifeng Yu,Tao Tan*

Main category: eess.IV

TL;DR: 综述探讨了提示工程在医学影像中的应用，分析了其提升模型性能的潜力及面临的挑战。

- Motivation: 深度学习在医学影像中潜力巨大，但面临数据稀缺、分布偏移和任务泛化等挑战，提示方法成为解决这些问题的关键策略。
- Method: 系统回顾了提示工程在医学影像中的多种形式，包括文本指令、视觉提示和可学习嵌入，并分析了其在图像生成、分割和分类任务中的应用。
- Result: 提示机制显著提高了任务的准确性、鲁棒性和数据效率，同时减少了对手工特征工程的依赖，并增强了模型的可解释性。
- Conclusion: 尽管取得进展，提示设计优化、数据异构性和临床部署的可扩展性仍是挑战，未来方向包括多模态提示和临床整合。


### [91] [MID-INFRARED (MIR) OCT-based inspection in industry](https://arxiv.org/abs/2507.01074)
*N. P. García-de-la-Puente,Rocío del Amor,Fernando García-Torres,Niels Møller Israelsen,Coraline Lapre,Christian Rosenberg Petersen,Ole Bang,Dominik Brouczek,Martin Schwentenwein,Kevin Neumann,Niels Benson,Valery Naranjo*

Main category: eess.IV

TL;DR: 评估中红外光学相干断层扫描（MIR-OCT）系统在穿透材料和检测次表面异常的能力，探索其在工业无损检测中的应用。

- Motivation: 为工业生产过程提供无损检测技术，提高材料异常检测的效率和准确性。
- Method: 通过复合材料和陶瓷的多次采集，评估系统性能，并结合预处理和AI增强视觉算法进行异常检测。
- Result: 探讨了系统参数选择的优化标准，并分析了其优势和局限性。
- Conclusion: MIR-OCT系统在工业无损检测中具有潜力，但需进一步优化参数和算法以提高性能。


### [92] [Classification based deep learning models for lung cancer and disease using medical images](https://arxiv.org/abs/2507.01279)
*Ahmad Chaddad,Jihao Peng,Yihang Wu*

Main category: eess.IV

TL;DR: 提出了一种名为ResNet+的新型深度学习模型，用于改进肺癌预测，通过集成ResNet-D模块和注意力机制提升性能，并在多个公开数据集上验证了其优越性。

- Motivation: 解决传统CNN在降采样过程中丢失特征信息的问题，并提升肺癌和肺部疾病的预测准确性。
- Method: 结合ResNet-D模块改进降采样层，并在瓶颈层加入卷积注意力模块，同时使用数据增强解决类别不平衡问题。
- Result: 在多个数据集上表现优异，如LC2500（98.14%准确率/F1）和IQ-OTH/NCCD（99.25%准确率/F1），且计算成本更低。
- Conclusion: ResNet+模型在肺癌预测中显著优于基线模型，具有更高的准确性和效率。


### [93] [PanTS: The Pancreatic Tumor Segmentation Dataset](https://arxiv.org/abs/2507.01291)
*Wenxuan Li,Xinze Zhou,Qi Chen,Tianyu Lin,Pedro R. A. S. Bassi,Szymon Plotka,Jaroslaw B. Cwikla,Xiaoxi Chen,Chen Ye,Zheren Zhu,Kai Ding,Heng Li,Kang Wang,Yang Yang,Yucheng Tang,Daguang Xu,Alan L. Yuille,Zongwei Zhou*

Main category: eess.IV

TL;DR: PanTS是一个大规模、多机构的数据集，用于推动胰腺CT分析研究，包含36,390个CT扫描和993,000多个专家验证的体素级标注，显著提升了AI模型在胰腺肿瘤检测、定位和分割中的性能。

- Motivation: 现有公共数据集在胰腺CT分析中表现有限，PanTS旨在通过更大规模的标注和更全面的解剖结构覆盖，提升AI模型的性能。
- Method: PanTS数据集包含36,390个CT扫描，覆盖胰腺肿瘤及其周围24个解剖结构，每个扫描附带丰富的元数据。
- Result: 在PanTS上训练的AI模型在胰腺肿瘤检测、定位和分割任务中表现显著优于现有数据集，性能提升归因于16倍更大的肿瘤标注规模和额外的解剖结构支持。
- Conclusion: PanTS是目前最大、最全面的胰腺CT分析资源，为AI模型的开发和评估提供了新的基准。


### [94] [SWinMamba: Serpentine Window State Space Model for Vascular Segmentation](https://arxiv.org/abs/2507.01323)
*Rongchang Zhao,Huanchi Liu,Jian Zhang*

Main category: eess.IV

TL;DR: 提出了一种名为SWinMamba的新方法，通过蛇形窗口序列和双向状态空间模型，实现了医学图像中血管的准确分割。

- Motivation: 血管分割在医学图像中至关重要，但传统方法常因血管细长和先验建模不足导致分割不连续。
- Method: 结合蛇形窗口序列和双向状态空间模型，设计了SWToken和BAM模块，并引入双域学习增强特征表示。
- Result: 在三个数据集上表现优异，实现了完整且连续的血管分割。
- Conclusion: SWinMamba通过创新建模血管连续性，显著提升了分割效果。


### [95] [Structure and Smoothness Constrained Dual Networks for MR Bias Field Correction](https://arxiv.org/abs/2507.01326)
*Dong Liang,Xingyu Qiu,Yuzhen Li,Wei Wang,Kuanquan Wang,Suyu Dong,Gongning Luo*

Main category: eess.IV

TL;DR: 提出了一种名为S2DNets的双网络模型，通过结构和平滑性约束自监督校正MR图像的偏置场，显著提升了图像质量和结构细节保留。

- Motivation: MR图像常因设备限制存在强度不均匀性，影响诊断和分析。现有深度学习模型忽视结构约束和平滑性，导致校正结果失真。
- Method: 提出S2DNets，结合分段结构约束和偏置场平滑性，通过双网络自监督校正MR图像。
- Result: 在临床和模拟数据集上优于传统及深度学习模型，下游分割任务验证了其有效性。
- Conclusion: S2DNets能有效去除不均匀性并保留结构细节，提升MR图像分析质量。


### [96] [BronchoGAN: Anatomically consistent and domain-agnostic image-to-image translation for video bronchoscopy](https://arxiv.org/abs/2507.01387)
*Ahmad Soliman,Ron Keuth,Marian Himstedt*

Main category: eess.IV

TL;DR: 论文提出BronchoGAN，通过引入解剖约束和中间深度图像表示，实现跨不同支气管镜图像域的稳健图像翻译，生成逼真的人体气道图像。

- Motivation: 支气管镜图像数据有限，跨域图像翻译对临床应用至关重要。
- Method: 使用条件GAN集成解剖约束，强制支气管孔匹配，并利用基础模型生成的深度图像作为中间表示。
- Result: 实验表明，BronchoGAN能成功翻译不同域图像，保留解剖结构，FID、SSIM和Dice系数显著提升。
- Conclusion: BronchoGAN通过解剖约束和深度表示，填补了公共支气管镜图像数据的空白。


### [97] [Multi Source COVID-19 Detection via Kernel-Density-based Slice Sampling](https://arxiv.org/abs/2507.01564)
*Chia-Ming Lee,Bo-Cheng Qiu,Ting-Yao Chen,Ming-Han Sun,Fang-Ying Lin,Jung-Tse Tsai,I-An Tsai,Yu-Fan Lin,Chih-Chung Hsu*

Main category: eess.IV

TL;DR: 提出了一种基于SSFL和KDS的多源COVID-19检测方法，通过预处理和模型比较，EfficientNet表现优于Swin Transformer。

- Motivation: 解决多源医疗影像数据的变异性问题，提升COVID-19检测的准确性。
- Method: 采用SSFL框架和KDS采样，结合肺部区域提取和质量控制，选择代表性切片，比较EfficientNet和Swin Transformer。
- Result: EfficientNet的F1-score为94.68%，优于Swin Transformer的93.34%。
- Conclusion: KDS预处理流程在多源数据中有效，数据集平衡对多机构医疗影像评估至关重要。


### [98] [Robust brain age estimation from structural MRI with contrastive learning](https://arxiv.org/abs/2507.01794)
*Carlo Alberto Barbano,Benoit Dufumier,Edouard Duchesnay,Marco Grangetto,Pietro Gori*

Main category: eess.IV

TL;DR: Error

- Motivation: Error
- Method: Error
- Result: Error
- Conclusion: Error


### [99] [Autoadaptive Medical Segment Anything Model](https://arxiv.org/abs/2507.01828)
*Tyler Ward,Meredith K. Owen,O'Kira Coleman,Brian Noehren,Abdullah-Al-Zubaer Imran*

Main category: eess.IV

TL;DR: ADA-SAM是一种新型的多任务学习框架，用于医学图像分割，通过辅助分类器的类激活图指导半监督分割分支，并结合梯度反馈机制提升分类预测。

- Motivation: 传统全监督分割模型依赖大量标注数据，成本高且易出错，需要更高效、自动化的方法。
- Method: 基于Segment Anything (SAM)框架，利用辅助分类器的类激活图指导分割分支，并通过梯度反馈机制连接分割与分类分支。
- Result: 在真实临床数据上验证，ADA-SAM在有限标注条件下优于全监督和半监督基线方法，提升幅度达两位数。
- Conclusion: ADA-SAM提供了一种高效、自动化的医学图像分割方法，显著减少了对标注数据的依赖。


### [100] [A computationally frugal open-source foundation model for thoracic disease detection in lung cancer screening programs](https://arxiv.org/abs/2507.01881)
*Niccolò McConnell,Pardeep Vasudev,Daisuke Yamada,Daryl Cheng,Mehran Azimbagirad,John McCabe,Shahab Aslani,Ahmed H. Shahin,Yukun Zhou,The SUMMIT Consortium,Andre Altmann,Yipeng Hu,Paul Taylor,Sam M. Janes,Daniel C. Alexander,Joseph Jacob*

Main category: eess.IV

TL;DR: TANGERINE是一个开源、计算资源需求低的视觉基础模型，用于低剂量CT（LDCT）分析，可快速适应多种疾病检测任务，显著减少训练时间和数据需求。

- Motivation: 解决LDCT扫描分析中放射科医生短缺的问题，提供一种可扩展、资源高效的解决方案。
- Method: 基于自监督学习预训练，使用超过98,000个胸部LDCT扫描数据，通过3D掩码自编码器框架实现。
- Result: 在14种疾病分类任务中达到最先进性能，包括肺癌和多种呼吸系统疾病，且能泛化到不同临床中心。
- Conclusion: TANGERINE为下一代医学影像工具提供了快速集成的基础，有望将肺癌筛查扩展为全面的呼吸系统疾病管理。
## cs.CR

### [101] [SafePTR: Token-Level Jailbreak Defense in Multimodal LLMs via Prune-then-Restore Mechanism](https://arxiv.org/abs/2507.01513)
*Beitao Chen,Xinyu Lyu,Lianli Gao,Jingkuan Song,Heng Tao Shen*

Main category: cs.CR

TL;DR: 论文分析了多模态大语言模型（MLLMs）的漏洞，提出了一种无需训练的防御框架SafePTR，通过选择性剪枝有害令牌来提升安全性。

- Motivation: 多模态大语言模型（MLLMs）在扩展视觉推理能力的同时，引入了新的漏洞，现有防御方法未能有效解决其根本原因。
- Method: 提出SafePTR框架，通过选择性剪枝有害令牌并恢复良性特征，无需额外训练即可提升安全性。
- Result: 实验表明，SafePTR在三种MLLMs和五个基准测试中显著降低了越狱风险，同时保持了模型效率。
- Conclusion: SafePTR是一种高效且无需训练的防御方法，能显著提升MLLMs的安全性。


### [102] [Empowering Manufacturers with Privacy-Preserving AI Tools: A Case Study in Privacy-Preserving Machine Learning to Solve Real-World Problems](https://arxiv.org/abs/2507.01808)
*Xiaoyu Ji,Jessica Shorland,Joshua Shank,Pascal Delpe-Brice,Latanya Sweeney,Jan Allebach,Ali Shakouri*

Main category: cs.CR

TL;DR: 论文提出了一种隐私保护平台，帮助中小型制造商安全共享数据，研究人员基于此开发工具并反馈给制造商。通过食品晶体质量控制的案例展示了该平台的实际应用。

- Motivation: 中小型制造商因竞争和隐私问题不愿共享数据，但需要创新工具解决问题。
- Method: 开发隐私保护平台，制造商通过安全方法共享数据，研究人员开发工具并反馈。
- Result: 成功开发并部署了食品晶体自动分析工具，提高了效率和准确性。
- Conclusion: 隐私保护平台有效解决了数据共享问题，未来可进一步扩展应用。
## cs.IT

### [103] [A Hybrid Ensemble Learning Framework for Image-Based Solar Panel Classification](https://arxiv.org/abs/2507.01778)
*Vivek Tetarwal,Sandeep Kumar*

Main category: cs.IT

TL;DR: 论文提出了一种新型双集成神经网络（DENN），用于基于图像特征分类清洁与脏污的太阳能板，其性能优于现有集成方法，并在Deep Solar Eye数据集上达到最先进水平。

- Motivation: 随着太阳能系统的普及，需要有效的维护技术以保持其性能。自动区分清洁与脏污太阳能板是主要挑战之一。
- Method: 提出双集成神经网络（DENN），整合多种集成模型的优势，以提高分类准确性和鲁棒性。
- Result: DENN在Deep Solar Eye数据集上表现优于现有方法，达到最先进的准确率。
- Conclusion: 混合集成学习技术在自动化太阳能板检测中具有潜力，可扩展解决现实问题。
## cs.MA

### [104] [Automated Vehicles Should be Connected with Natural Language](https://arxiv.org/abs/2507.01059)
*Xiangbo Gao,Keshu Wu,Hao Zhang,Kexin Tian,Yang Zhou,Zhengzhong Tu*

Main category: cs.MA

TL;DR: 论文提出通过自然语言实现多智能体协作驾驶中的意图和推理通信，以解决现有通信方式的局限性。

- Motivation: 现有协作驾驶通信方式（如传感器数据、神经网络特征等）在带宽效率、信息完整性和智能体互操作性方面存在不足，且忽视了决策级融合。
- Method: 采用自然语言作为通信媒介，直接传递意图、推理和决策，实现从感知数据共享到主动协调的转变。
- Result: 自然语言通信提高了协作驾驶的安全性、效率和透明度。
- Conclusion: 自然语言通信是多智能体协作驾驶中解决现有挑战的有效方法。
## cs.RO

### [105] [VLAD: A VLM-Augmented Autonomous Driving Framework with Hierarchical Planning and Interpretable Decision Process](https://arxiv.org/abs/2507.01284)
*Cristian Gariboldi,Hayato Tokida,Ken Kinjo,Yuki Asada,Alexander Carballo*

Main category: cs.RO

TL;DR: VLAD是一个结合视觉语言模型（VLM）与自动驾驶系统（VAD）的模型，通过定制问答数据集微调VLM，提升空间推理能力，生成导航指令并解释驾驶决策，显著降低碰撞率。

- Motivation: 利用开源视觉语言模型（如LLaVA、Qwen-VL）的通用知识，提升自动驾驶的感知、预测和规划能力。
- Method: 提出VLAD模型，将微调的VLM与VAD系统结合，使用定制问答数据集增强空间推理能力，生成导航指令并提供自然语言解释。
- Result: 在nuScenes数据集上测试，碰撞率平均降低31.82%，优于基线方法。
- Conclusion: VLAD为VLM增强的自动驾驶系统设定了新基准，提高了透明度和可信度。


### [106] [LANet: A Lane Boundaries-Aware Approach For Robust Trajectory Prediction](https://arxiv.org/abs/2507.01308)
*Muhammad Atta ur Rahman,Dooseop Choi,KyoungWook Min*

Main category: cs.RO

TL;DR: 提出了一种基于多向量地图元素的运动预测模型，通过融合车道边界和道路边缘等信息，提升自动驾驶中的轨迹预测能力，并通过剪枝机制保持计算效率。

- Motivation: 当前基于车道中心线的运动预测模型无法充分捕捉道路环境和交通规则，限制了预测的准确性。
- Method: 开发了一种特征融合策略和剪枝机制，整合多向量地图元素并筛选相关连接，以优化计算效率和预测性能。
- Result: 在Argoverse 2数据集上验证了方法的竞争力，性能优于现有模型。
- Conclusion: 该方法提供了更丰富且高效的道路环境表示，推动了自动驾驶运动预测的技术进步。
## cs.CL

### [107] [How Do Vision-Language Models Process Conflicting Information Across Modalities?](https://arxiv.org/abs/2507.01790)
*Tianze Hua,Tian Yun,Ellie Pavlick*

Main category: cs.CL

TL;DR: 研究探讨多模态AI模型在输入信息冲突时的行为，发现模型倾向于优先处理某一模态，并揭示内部注意力机制的作用。

- Motivation: 理解多模态模型在输入信息冲突时的行为及其内部机制。
- Method: 通过向视觉-语言模型提供不一致输入（如图片与标题矛盾），观察模型对不同模态的偏好，并分析内部注意力机制。
- Result: 模型倾向于优先处理某一模态，且内部注意力头可调整模态偏好；发现模态无关的“路由头”可提升性能。
- Conclusion: 研究为识别和控制多模态模型在冲突信号中的行为提供了重要基础。
## q-bio.NC

### [108] [Age Sensitive Hippocampal Functional Connectivity: New Insights from 3D CNNs and Saliency Mapping](https://arxiv.org/abs/2507.01411)
*Yifei Sun,Marshall A. Dalton,Robert D. Sanders,Yixuan Yuan,Xiang Li,Sharon L. Naismith,Fernando Calamante,Jinglei Lv*

Main category: q-bio.NC

TL;DR: 本文提出了一种可解释的深度学习框架，通过海马功能连接预测大脑年龄，揭示了与年龄相关的关键海马-皮层连接。

- Motivation: 海马灰质减少是神经生物衰老的标志，但其功能连接的变化尚不明确。
- Method: 使用三维卷积神经网络（3D CNN）结合LayerCAM显著性映射，分析海马功能连接。
- Result: 识别出与年龄高度敏感的海马-皮层连接区域，并区分了前后海马功能连接的差异。
- Conclusion: 研究为海马衰老的功能机制提供了新见解，展示了可解释深度学习在神经影像数据中的潜力。
## cs.LG

### [109] [Escaping Platos Cave: JAM for Aligning Independently Trained Vision and Language Models](https://arxiv.org/abs/2507.01201)
*Hyoseo,Yoon,Yisong Yue,Been Kim*

Main category: cs.LG

TL;DR: 论文提出了一种联合自动编码器调制器（JAM）框架，用于优化视觉和语言模型之间的表示对齐，通过多目标优化实现模态间共享结构。

- Motivation: 探索视觉和语言模型是否能在独立训练后收敛到共享的统计模型，并研究如何显式优化这种对齐。
- Method: 引入JAM框架，联合训练模态特定的自动编码器，通过重构和跨模态目标鼓励对齐。
- Result: JAM框架在多种对齐目标、层深度和基础模型规模下均能有效诱导对齐。
- Conclusion: 该框架为将通用单模态基础模型转化为专用多模态模型提供了理论和实践路径。


### [110] [How Weight Resampling and Optimizers Shape the Dynamics of Continual Learning and Forgetting in Neural Networks](https://arxiv.org/abs/2507.01559)
*Lapo Frati,Neil Traft,Jeff Clune,Nick Cheney*

Main category: cs.LG

TL;DR: 研究探讨了神经网络最后一层权重重采样（“zapping”）在持续学习和少样本迁移学习中的作用，发现其能加速模型适应新领域，并揭示了优化器选择对学习动态的复杂影响。

- Motivation: 尽管实证研究表明“zapping”在持续学习中有效，但其作用机制尚不明确，因此需要深入研究。
- Method: 通过卷积神经网络在持续学习和少样本迁移学习中的实验，分析“zapping”和优化器选择对学习动态的影响。
- Result: “zapping”能帮助模型更快适应新领域，优化器选择会显著影响任务间的学习与遗忘动态。
- Conclusion: “zapping”和优化器选择在持续学习中起关键作用，揭示了任务间复杂的协同/干扰模式。
