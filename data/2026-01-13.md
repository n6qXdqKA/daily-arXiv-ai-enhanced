[[toc]]

## cs.CV

### [1] [HyperTopo-Adapters: Geometry- and Topology-Aware Segmentation of Leaf Lesions on Frozen Encoders](https://arxiv.org/abs/2601.06067)
*Chimdi Walter Ndubuisi,Toni Kazic*

Main category: cs.CV

TL;DR: 提出HyperTopo-Adapters方法，在冻结的视觉编码器上添加轻量级适配器，将特征嵌入到双曲+欧几里得+球面（H+E+S）乘积流形中，结合拓扑先验改进叶片病变分割的拓扑结构保持能力。

- Motivation: 叶片病变分割对拓扑结构敏感，小的合并、分裂或假孔洞可能具有生物学意义，但标准的像素级损失在欧几里得潜在空间中对此惩罚较弱。需要更好地保持拓扑结构。
- Method: 1. 在冻结视觉编码器上训练轻量级HyperTopo-Adapters头，将特征嵌入到H+E+S乘积流形中；2. 引入拓扑先验：持久同调距离用于评估选择，可微替代结合软欧拉特征匹配和总变差正则化；3. 采用双曲对比项和拓扑先验的预热策略；4. 提出基于top-K Dice中最小PD距离的检查点选择规则。
- Result: 在Kaggle叶片病变数据集（N=2,940）上，边界和拓扑指标持续提升（Δβ₁孔洞误差减少9%），Dice/IoU保持竞争力。进行了全面的消融实验分析。
- Conclusion: 贡献了一个开放、可复现的训练/评估套件，能够隔离几何/拓扑先验并揭示失败模式，为构建更强的拓扑保持架构提供指导。该方法在保持拓扑结构方面表现出优势。


### [2] [OptFormer: Optical Flow-Guided Attention and Phase Space Reconstruction for SST Forecasting](https://arxiv.org/abs/2601.06078)
*Yin Wang,Chunlin Gong,Zhuozhen Xu,Lehan Zhang,Xiang Wu*

Main category: cs.CV

TL;DR: OptFormer：一种结合相空间重构与光流引导运动感知注意力机制的海表温度预测模型，在NOAA数据集上表现优异

- Motivation: 海表温度预测对气候建模和灾害预报至关重要，但由于其非线性时空动力学特性和长预测时间跨度，现有方法面临挑战
- Method: 提出OptFormer编码器-解码器模型，整合相空间重构与光流引导的运动感知注意力机制，利用帧间运动线索突出空间场的相对变化，聚焦动态区域并有效捕捉长程时间依赖
- Result: 在NOAA海表温度数据集上的多空间尺度实验表明，OptFormer在1:1训练-预测设置下取得优越性能，在准确性和鲁棒性上显著超越现有基线方法
- Conclusion: OptFormer通过结合相空间重构和运动感知注意力机制，有效解决了海表温度预测中的非线性时空动态和长预测跨度问题，为气候建模和灾害预报提供了更准确的工具


### [3] [Semantic Event Graphs for Long-Form Video Question Answering](https://arxiv.org/abs/2601.06097)
*Aradhya Dixit,Tianxi Liang*

Main category: cs.CV

TL;DR: 提出语义事件图(SEG)作为视频与语言模型间的轻量符号接口，用紧凑的时序交互日志替代原始帧，在长视频问答中实现91.4%的token节省，同时保持65.0%的准确率。

- Motivation: 现有视觉语言模型在处理小时级长视频时面临token和计算预算限制，通常需要降采样帧或输入密集视觉嵌入，需要在时间覆盖范围和成本之间权衡。
- Method: 使用YOLOv11检测和跟踪对象，将邻近模式转换为START/END人-物事件，组织成时序场景图(TSG)。推理时通过查询感知剪枝模块识别锚点实体和词汇相关事件，返回小子图并转换为文本，最后用Gemini 2.5 Flash生成答案。
- Result: 在5个YouTube视频(每个300-500个交互)和120个自动生成长视野问题上，SEG仅使用3.47k token达到65.0%准确率，接近完整日志基线(62.5%使用40.39k token)，token使用减少91.4%。短上下文基线(仅最后30秒)准确率降至2.5%。
- Conclusion: 符号时序图可作为现成视觉语言模型的有效即插即用记忆层，在保持长距离推理能力的同时，使长视频问答在token和成本效率上大幅提升。


### [4] [COVR:Collaborative Optimization of VLMs and RL Agent for Visual-Based Control](https://arxiv.org/abs/2601.06122)
*Canming Xia,Peixi Peng,Guang Tan,Zhan Su,Haoran Xu,Zhenxian Liu,Luntong Li*

Main category: cs.CV

TL;DR: COVR提出视觉强化学习与视觉语言模型协同优化框架，通过RL生成数据增强VLM语义推理能力，再用增强的VLM指导策略学习，提升视觉RL样本效率

- Motivation: 现有工作主要关注从VLM到RL的知识蒸馏，忽视了RL生成的交互数据对增强VLM的潜力。视觉RL在复杂任务中因高维观测导致样本效率低下，需要更有效的协同优化方法
- Method: 提出COVR协同优化框架：1) 用RL生成数据微调VLM以增强任务一致的语义推理能力；2) 用增强的VLM通过动作先验指导策略学习；3) 引入探索驱动的动态过滤模块和回报感知的自适应损失权重模块；4) 设计渐进式微调策略减少资源消耗
- Result: 在多种具有挑战性的视觉控制任务上，COVR表现出强大的性能，验证了框架的有效性
- Conclusion: COVR实现了VLM与RL策略的相互增强，通过协同优化框架显著提升了视觉RL的样本效率，为视觉强化学习与视觉语言模型的结合提供了新思路


### [5] [Low-Back Pain Physical Rehabilitation by Movement Analysis in Clinical Trial](https://arxiv.org/abs/2601.06138)
*Sao Mai Nguyen*

Main category: cs.CV

TL;DR: 提出Keraal数据集，这是一个临床收集的康复运动数据集，用于支持智能辅导系统开发，包含腰痛康复患者的临床运动数据，并评估了先进的人体运动分析算法。

- Motivation: 需要临床康复环境下的真实患者运动数据来开发和评估智能辅导系统，现有数据集缺乏临床环境中的康复运动记录。
- Method: 收集临床患者的腰痛康复运动数据，创建Keraal数据集，并在最先进的人体运动分析算法上进行基准测试。
- Result: 建立了包含临床康复运动的数据集，该数据集可用于解决运动评估、错误识别、空间定位和时间定位四个康复监测挑战。
- Conclusion: Keraal数据集为康复智能辅导系统的开发提供了宝贵的临床资源，能够支持更准确的运动分析和错误检测。


### [6] [Forget-It-All: Multi-Concept Machine Unlearning via Concept-Aware Neuron Masking](https://arxiv.org/abs/2601.06163)
*Kaiyuan Deng,Bo Hui,Gen Li,Jie Ji,Minghai Qin,Geng Yuan,Xiaolong Ma*

Main category: cs.CV

TL;DR: FIA是一个基于模型稀疏性的免训练多概念遗忘框架，通过对比概念显著性识别概念敏感神经元，构建统一掩码来选择性剪枝目标概念，同时保留通用内容生成能力。

- Motivation: 文本到图像扩散模型的广泛应用引发了对生成受版权保护、不当或敏感图像的担忧。现有单概念遗忘方法难以扩展到多概念场景，在遗忘效果、生成质量和超参数敏感性方面存在挑战。
- Method: 提出Forget It All框架：1) 引入对比概念显著性量化权重连接对目标概念的贡献；2) 结合时空信息识别概念敏感神经元；3) 构建统一多概念掩码，保留概念无关神经元（支持通用内容生成），剪枝概念特定神经元以移除目标概念。
- Result: 在三个不同遗忘任务上的广泛实验表明，FIA实现了更可靠的多概念遗忘，提高了遗忘效果，同时保持了语义保真度和图像质量。
- Conclusion: FIA是一个免训练、只需最小超参数调整的即插即用框架，有效解决了多概念遗忘的挑战，在遗忘效果和生成质量之间取得了良好平衡。


### [7] [What Users Leave Unsaid: Under-Specified Queries Limit Vision-Language Models](https://arxiv.org/abs/2601.06165)
*Dasol Choi,Guijin Son,Hanwool Lee,Minhyuk Kim,Hyunwoo Ko,Teabin Lim,Ahn Eungyeol,Jungwhan Kim,Seunghyeok Hong,Youngsook Song*

Main category: cs.CV

TL;DR: HAERAE-Vision基准测试显示，真实世界视觉问题通常不完整且依赖图像上下文，而当前VLM在原始查询上表现不佳（<50%），查询明确化可提升8-22个百分点，表明模型困难主要源于查询不完整而非能力不足。

- Motivation: 当前视觉语言基准测试主要使用结构良好、明确的提示，但真实用户查询往往是非正式且不完整的，用户依赖图像传达上下文，这导致评估与现实部署之间存在差距。
- Method: 构建HAERAE-Vision基准测试，包含653个来自韩国在线社区的真实视觉问题（从86K候选问题中筛选0.76%），每个问题都配有明确的改写版本，共1,306个查询变体。评估39个视觉语言模型，分析原始查询与明确化查询的性能差异。
- Result: 即使最先进的模型（GPT-5、Gemini 2.5 Pro）在原始查询上准确率也低于50%。查询明确化可带来8-22个百分点的提升，较小模型受益最大。即使使用网络搜索，不完整查询的表现仍不如不使用搜索的明确查询。
- Conclusion: VLM困难的主要来源是自然查询的不完整性而非模型能力，这揭示了基准测试评估与现实世界部署之间的关键差距。查询明确化是提升性能的有效方法，特别是对较小模型。


### [8] [B-FIRE: Binning-Free Diffusion Implicit Neural Representation for Hyper-Accelerated Motion-Resolved MRI](https://arxiv.org/abs/2601.06166)
*Di Xu,Hengjie Liu,Yang Yang,Mary Feng,Jin Ning,Xin Miao,Jessica E. Scholey,Alexandra E. Hotca-cho,William C. Chen,Michael Ohliger,Martina Descovich,Huiming Dong,Wensha Yang,Ke Sheng*

Main category: cs.CV

TL;DR: B-FIRE：一种无需分箱的扩散隐式神经表示框架，用于超加速4DMRI重建，能够恢复瞬时3D腹部解剖结构

- Motivation: 现有4DMRI技术会产生平均呼吸相位的伪影，模糊和误表示瞬时动态信息。需要新范式来重建极度欠采样的非笛卡尔k空间数据，以恢复瞬时动态信息。
- Method: 提出B-FIRE框架，采用CNN-INR编码器-解码器骨干网络，通过扩散过程优化，结合全面的损失函数，包括图像域保真度和频率感知约束。使用运动分箱图像对作为训练参考，推理时处理无需分箱的欠采样数据。
- Result: 在T1加权StarVIBE肝脏MRI数据集上测试，加速比从每帧8个径向采样（RV8）到RV1。B-FIRE在重建保真度、运动轨迹一致性和推理延迟方面优于直接NuFFT、GRASP-CS和展开CNN方法。
- Conclusion: B-FIRE能够有效恢复瞬时3D腹部解剖结构，为超加速4DMRI重建提供了新解决方案，在保持高保真度的同时显著减少伪影。


### [9] [Analyzing the Structure of Handwritten Digits: A Comparative Study of PCA, Factor Analysis, and UMAP](https://arxiv.org/abs/2601.06168)
*Jyotiraditya Gupta*

Main category: cs.CV

TL;DR: 使用PCA、FA和UMAP三种降维方法分析MNIST手写数字的内在结构，揭示手写数字存在于低维流形中，不同方法从不同角度揭示其几何和统计特性。

- Motivation: 手写数字图像虽然处于高维像素空间，但具有强烈的几何和统计结构。本研究旨在探索MNIST数据集中手写数字的潜在组织结构，而不是关注分类准确性。
- Method: 采用三种互补的降维技术：主成分分析（PCA）揭示全局方差方向；因子分析（FA）分解为可解释的潜在手写基元；均匀流形近似与投影（UMAP）发现非线性流形结构。
- Result: PCA显示少数主成分即可实现高保真重建；FA识别出对应笔画、循环和对称性的手写基元；UMAP揭示了数字类别间平滑的风格过渡。所有方法都表明手写数字占据结构化的低维流形。
- Conclusion: 手写数字存在于结构化的低维流形中，不同的统计框架从互补的角度揭示了这种结构：PCA关注全局方差，FA提供可解释的基元分解，UMAP展示非线性几何关系。


### [10] [Think Bright, Diffuse Nice: Enhancing T2I-ICL via Inductive-Bias Hint Instruction and Query Contrastive Decoding](https://arxiv.org/abs/2601.06169)
*Zhiyong Ma,Zhenpeng Li,Yuanjie Shi,Zhengping Li,Jiahao Chen,Qingyuan Chuai*

Main category: cs.CV

TL;DR: TBDN是一个无需训练的训练免费框架，通过Hint Instruction和Query Contrastive Decoding解决文本到图像上下文学习中的合规失败和先验主导幻觉问题，在多个基准测试中达到SOTA性能。

- Motivation: 文本到图像上下文学习面临两个相互强化的瓶颈：合规失败（模型不遵循示例）和先验主导幻觉（模型过度依赖预训练先验），形成恶性循环降低生成质量。现有方法依赖定制化训练，限制了灵活性并增加了部署成本。
- Method: 提出TBDN训练免费框架，包含两个互补的闭环机制：1) Hint Instruction：通过轻量级提示工程注入任务感知归纳偏置，锚定模型在上下文映射规则上；2) Query Contrastive Decoding：通过对比完整输入和查询省略的分布来调整语言模型的解码分布，抑制先验主导幻觉。
- Result: 在CoBSAT和Text-to-Image Fast Mini-ImageNet上达到最先进性能，在不同模型骨干、提示设计和超参数上具有鲁棒泛化能力。在Dreambench++上的概念保持和提示遵循方面也保持有希望的性能。
- Conclusion: 通过打破两个瓶颈，TBDN建立了一个简单而有效的框架，用于高效可靠的文本到图像上下文学习，无需训练即可实现高质量图像合成。


### [11] [TIR-Flow: Active Video Search and Reasoning with Frozen VLMs](https://arxiv.org/abs/2601.06176)
*Hongbo Jin,Siyi Xie,Jiayu Ding,Kuanwei Lin,Ge Li*

Main category: cs.CV

TL;DR: TIR-Flow是一个无需额外数据或参数更新的视频推理框架，通过主动视觉搜索和推理，显著提升大型视频语言模型的推理能力。

- Motivation: 现有大型视频语言模型虽然感知能力显著，但推理能力仍是瓶颈。传统方法依赖大规模思维链数据集合成和监督微调，主要优化概率采样效率和对齐输出分布，但未能激活动态视觉探索所需的内在智能。
- Method: 提出TIR-Flow框架，包含三个协同模块：HDD将复杂查询分解为可验证的子任务；HAP主动引导视觉注意力收集高分辨率证据进行假设验证；EBA维护持久工作空间来积累和更新发现的线索进行逻辑推理。
- Result: 在七个基准测试上的广泛实验表明，TIR-Flow显著优于最近的强基线方法，平均性能提升5.9%，在Egoschema上增益达到10.5%。
- Conclusion: 为冻结的视觉语言模型赋予类似System-2的主动感知能力，是解决长时域视频推理问题的可扩展路径。


### [12] [A Unified Attention U-Net Framework for Cross-Modality Tumor Segmentation in MRI and CT](https://arxiv.org/abs/2601.06187)
*Nishan Rai,Pushpa R. Dahal*

Main category: cs.CV

TL;DR: 提出统一的Attention U-Net架构，同时在MRI和CT数据集上训练，研究单一模型在不同成像模态和解剖部位的泛化能力。

- Motivation: 探索单一模型能否在不同医学成像模态（MRI和CT）和解剖部位之间实现泛化，避免使用模态特定编码器或域适应方法，为跨模态肿瘤分割建立基线。
- Method: 使用统一的Attention U-Net架构，结合模态协调预处理、注意力门控跳跃连接和模态感知Focal Tversky损失函数，同时在BraTS 2021（MRI）和LIDC-IDRI（CT）数据集上训练。
- Result: 统一模型在Dice系数、IoU和AUC指标上在两个模态上都表现出竞争力，验证了单一模型跨模态分割的可行性。
- Conclusion: 该研究成功证明了单一Attention U-Net模型可以同时在MRI和CT肿瘤分割任务上取得良好性能，为未来跨模态医学图像分割研究提供了可复现的基线。


### [13] [How Does India Cook Biryani?](https://arxiv.org/abs/2601.06198)
*Shubham Goel,Farzana S,C V Rishi,Aditya Arun,C V Jawahar*

Main category: cs.CV

TL;DR: 该研究创建了首个大规模印度香饭制作视频数据集，并提出多阶段框架利用视觉语言模型分析不同地区烹饪程序的差异，建立了评估模型结构化多模态推理能力的新基准。

- Motivation: 在线烹饪视频的普及为系统研究印度香饭的地区多样性提供了机会，但现有视频理解方法无法捕捉烹饪视频中细粒度、多模态和文化背景的差异。
- Method: 收集12种地区风格的120个高质量YouTube视频，提出多阶段框架：利用视觉语言模型将视频分割为细粒度程序单元，对齐音频转录和标准食谱文本，建立视频比较管道识别地区变体差异，创建多推理层次问答基准。
- Result: 构建了首个大规模印度香饭制作视频数据集，开发了视频比较方法，建立了多推理层次问答基准，评估了多种最先进模型在零样本和微调设置下的表现。
- Conclusion: 该研究为评估视觉语言模型在结构化多模态推理任务上的表现提供了新测试平台，为通过烹饪视频进行文化遗产计算分析开辟了新方向。


### [14] [QwenStyle: Content-Preserving Style Transfer with Qwen-Image-Edit](https://arxiv.org/abs/2601.06202)
*Shiwen Zhang,Haibin Huang,Chi Zhang,Xuelong Li*

Main category: cs.CV

TL;DR: 首个基于Qwen-Image-Edit的内容保持风格迁移模型，通过课程持续学习框架处理干净和噪声三元组数据，在风格相似度、内容一致性和美学质量上达到SOTA性能

- Motivation: 扩散变换器(DiTs)在内容保持风格迁移中存在挑战，因为其内部内容和风格特征纠缠。需要开发能够保持内容完整性的风格迁移方法
- Method: 提出QwenStyle模型：1)收集过滤高质量特定风格数据，合成数千类野外风格图像的三元组；2)引入课程持续学习框架，混合处理干净和噪声三元组数据；3)激活Qwen-Image-Edit的内容保持和风格定制能力
- Result: QwenStyle V1在三个核心指标上达到最先进性能：风格相似度、内容一致性和美学质量，能够泛化到未见过的风格而不降低内容保持能力
- Conclusion: 成功开发了首个基于Qwen-Image-Edit的内容保持风格迁移模型，通过课程持续学习框架有效解决了扩散变换器中内容和风格特征纠缠的问题


### [15] [Cascading multi-agent anomaly detection in surveillance systems via vision-language models and embedding-based classification](https://arxiv.org/abs/2601.06204)
*Tayyab Rehman,Giovanni De Gasperis,Aly Shmahell*

Main category: cs.CV

TL;DR: 提出一个级联多智能体框架，将重建模型、目标检测和视觉语言系统统一起来，实现实时、可解释的异常检测，在保持高感知质量的同时将延迟降低三倍。

- Motivation: 动态视觉环境中的智能异常检测需要平衡实时性能与语义可解释性。现有方法各自存在局限：重建模型缺乏上下文推理，目标检测器速度快但语义有限，视觉语言系统可解释性好但计算成本过高。
- Method: 采用级联多智能体框架，早期模块执行重建门控过滤和目标级评估，高层推理智能体选择性调用以解释语义模糊事件。使用自适应升级阈值和发布-订阅通信骨干，支持异步协调和异构硬件上的可扩展部署。
- Result: 在大规模监控数据上的评估显示，相比直接视觉语言推理，级联框架将延迟降低三倍，同时保持高感知保真度（PSNR = 38.3 dB, SSIM = 0.965）和一致的语义标注。
- Conclusion: 该框架通过结合早期退出效率、自适应多智能体推理和可解释的异常归因，超越了传统检测流水线，为可扩展的智能视觉监控建立了可重复且节能的基础。


### [16] [When Imbalance Comes Twice: Active Learning under Simulated Class Imbalance and Label Shift in Binary Semantic Segmentation](https://arxiv.org/abs/2601.06209)
*Julien Combes,Alexandre Derville,Jean-François Coeurjolly*

Main category: cs.CV

TL;DR: 该研究通过模拟实验分析类别不平衡和标签偏移对主动学习算法的影响，发现熵选择和核心集选择在高度不平衡数据集上仍保持高效，但强标签偏移会导致效率损失。

- Motivation: 在机器视觉和医学影像等应用中，数据量大且标注成本高，同时存在两个特殊问题：1）大多数图像无缺陷导致类别不平衡；2）图像数量过大无法全部存储导致潜在标签偏移。需要理解这两种不平衡如何影响主动学习算法。
- Method: 基于两个开源数据集进行模拟研究，人工创建可控制类别不平衡和标签偏移水平的数据集。比较三种标准主动学习选择策略：随机采样、基于熵的选择和核心集选择。
- Result: 主动学习策略（特别是熵选择和核心集选择）即使在高度不平衡的数据集上仍然保持有趣且高效。同时量化了强标签偏移情况下发生的效率损失。
- Conclusion: 主动学习算法在类别不平衡场景下仍然有效，但标签偏移会显著影响其性能。这为实际应用中处理不平衡数据和存储限制提供了重要见解。


### [17] [Akasha 2: Hamiltonian State Space Duality and Visual-Language Joint Embedding Predictive Architectur](https://arxiv.org/abs/2601.06212)
*Yani Meziani*

Main category: cs.CV

TL;DR: Akasha 2是一个先进的多模态架构，结合了哈密顿状态空间对偶性和视觉-语言联合嵌入预测架构，通过物理启发的归纳偏置实现了卓越的时空一致性和高效推理。

- Motivation: 该研究的动机是将物理启发的归纳偏置融入神经网络架构，以提升多模态系统的时空一致性和推理效率。传统方法在处理长时间序列和复杂物理场景时存在局限性，需要更符合物理规律的模型设计。
- Method: 方法整合了哈密顿状态空间对偶性(H-SSD)和视觉-语言联合嵌入预测架构(VL-JEPA)，采用Mamba-3选择性状态空间模型(SSM)增强稀疏哈密顿专家混合(SMoE-HE)，通过辛积分强制执行潜在物理守恒定律。视觉合成方面引入了哈密顿流匹配(HFM)和持久3D高斯泼溅(3DGS)。
- Result: 实现了最先进的视频预测(FVD: 287)，视觉合成速度比扩散模型快4倍，推理速度比Transformer基线快3-18倍，在移动硬件上实现超低延迟(<50ms)，并在长时间范围内保持能量守恒。
- Conclusion: 研究表明，将物理启发的归纳偏置融入神经架构能显著提升性能，建立了潜在世界模型的新范式，通过全息记忆架构实现了前所未有的时空一致性。


### [18] [Two-step Authentication: Multi-biometric System Using Voice and Facial Recognition](https://arxiv.org/abs/2601.06218)
*Kuan Wei Chen,Ting Yi Lin,Wen Ren Yang,Aryan Kesarwani,Riya Singh*

Main category: cs.CV

TL;DR: 提出一个经济高效的两步身份验证系统，结合人脸识别和声纹验证，仅使用普通设备的摄像头和麦克风。首先通过人脸识别从已注册的小群体中识别候选用户，然后仅针对匹配身份进行声纹验证，以减少计算量并提高鲁棒性。

- Motivation: 开发一个成本效益高的多生物特征认证系统，利用普通设备已有的摄像头和麦克风，通过两步验证流程提高安全性和鲁棒性，同时减少计算开销。
- Method: 采用两步验证流程：1) 使用基于MTCNN人脸定位和剪枝VGG-16分类器的人脸识别系统，在5个受试者的924张增强图像数据集上训练；2) 使用基于CNN的声纹验证模型，在LibriSpeech train-other-360数据集上训练，仅对匹配身份进行验证。
- Result: 人脸识别系统达到95.1%准确率；声纹验证模型达到98.9%准确率和3.456%等错误率(EER)。整个系统在减少计算量的同时保持了高识别性能。
- Conclusion: 提出的两步多生物特征认证系统有效结合人脸和声纹识别，在普通设备上实现高精度身份验证，同时通过顺序验证策略降低了计算复杂度，为经济高效的安全系统提供了可行方案。


### [19] [SAPL: Semantic-Agnostic Prompt Learning in CLIP for Weakly Supervised Image Manipulation Localization](https://arxiv.org/abs/2601.06222)
*Xinghao Wang,Changtao Miao,Dianmo Sheng,Tao Gong,Qi Chu,Nenghai Yu,Quanchen Zou,Deyue Zhang,Xiangzheng Zhang*

Main category: cs.CV

TL;DR: SAPL：基于CLIP的语义无关提示学习方法，通过边界感知提示学习和分层边界对比学习，利用边界线索实现无需像素级标注的图像篡改定位

- Motivation: 现有图像篡改定位方法依赖昂贵的像素级标注，而弱监督方法仅使用图像级标签且关注全局分类，忽略了关键的局部边界线索。观察到篡改边界的特征变化远大于内部区域，需要一种能有效利用边界信息的方法。
- Method: 提出语义无关提示学习(SAPL)框架，包含两个互补模块：1)边界感知上下文提示学习(ECPL)：利用边界增强图像特征通过注意力机制生成可学习文本提示，将语义无关信息嵌入文本特征；2)分层边界对比学习(HECL)：提取真实和篡改边界块，通过对比学习增强两者的区分度。最终从相似度图中预测篡改区域。
- Result: 在多个公开基准测试上的实验表明，SAPL显著优于现有方法，实现了最先进的定位性能。
- Conclusion: SAPL通过将CLIP的关注点从高级语义转向边界线索，有效解决了弱监督图像篡改定位问题，无需像素级标注即可实现精确的篡改区域定位。


### [20] [Ground What You See: Hallucination-Resistant MLLMs via Caption Feedback, Diversity-Aware Sampling, and Conflict Regularization](https://arxiv.org/abs/2601.06224)
*Miao Pan,Wangjie Gan,Jintao Chen,Wenqi Zhang,Bing Sun,Jianwei Yin,Xuhong Zhang*

Main category: cs.CV

TL;DR: 该论文针对MLLMs在RL训练中的幻觉问题，提出包含视觉定位增强、探索多样性提升和样本干扰缓解的三模块框架，显著降低幻觉率并提高推理准确性。

- Motivation: MLLMs在实际部署中面临严重的幻觉问题，特别是在RL优化过程中尤为突出，这严重阻碍了其实际应用。论文旨在系统分析RL训练中MLLMs产生幻觉的根本原因，并提出解决方案。
- Method: 提出包含三个核心模块的框架：1) 增强视觉定位，在推理前引入专门的规划和描述阶段，使用基于质量的描述奖励确保准确初始锚定；2) 提升探索多样性，基于奖励分布的均值和方差对样本分类，优先处理高方差样本；3) 缓解样本干扰，通过分组样本对并应用InfoNCE损失来调节NTK相似性。
- Result: 实验结果表明，所提方法显著降低了幻觉率，并有效提高了MLLMs的推理准确性。
- Conclusion: 该研究系统识别了MLLMs在RL训练中产生幻觉的三个关键因素，并提出了相应的解决方案框架，为减少MLLMs幻觉问题提供了有效途径。


### [21] [Synthetic FMCW Radar Range Azimuth Maps Augmentation with Generative Diffusion Model](https://arxiv.org/abs/2601.06228)
*Zhaoze Wang,Changxu Zhang,Tai Fei,Christopher Grimm,Yi Jin,Claas Tebruegge,Ernst Warsitz,Markus Gardill*

Main category: cs.CV

TL;DR: 提出条件生成框架合成真实FMCW雷达距离-方位图，通过扩散模型生成多类别雷达数据，提升下游任务性能

- Motivation: 汽车雷达数据集稀缺且多样性低，限制了基于深度学习的环境感知性能，需要解决数据不足问题
- Method: 使用条件生成扩散模型，通过置信度图进行条件控制，结合几何感知条件和时间一致性正则化处理雷达特性
- Result: 在ROD2021数据集上，信号重建质量比基线方法提高3.6dB PSNR，结合真实和合成数据训练使平均精度提升4.15%
- Conclusion: 生成框架不仅能产生物理合理且多样化的雷达频谱，还能显著提升下游任务的模型泛化能力


### [22] [A survey of facial recognition techniques](https://arxiv.org/abs/2601.06239)
*Aya Kaysan Bahjat*

Main category: cs.CV

TL;DR: 这篇论文是一篇关于人脸识别技术的综述性文章，系统回顾了该领域的主要方法、挑战和数据库，并提供了实验结果分析。

- Motivation: 随着多媒体内容的快速增长，人脸识别已成为重要的研究领域。人脸作为具有众多独特特征的复杂对象，在图像处理和计算机视觉中面临诸多挑战，如光照变化、年龄变化、姿态变化、部分遮挡和表情变化等，需要有效的方法来解决这些问题。
- Method: 论文采用文献综述方法，系统分析了多种人脸识别技术，包括隐马尔可夫模型、主成分分析（PCA）、弹性簇图匹配、支持向量机（SVM）、Gabor小波、人工神经网络（ANN）、特征脸、独立成分分析（ICA）和3D可变形模型。同时分析了多个面部数据库（JAFEE、FEI、Yale、LFW、AT&T/ORL、AR）的图像数据。
- Result: 论文提供了对人脸识别领域的全面回顾，包括各种方法的分析比较，以及在多个标准数据库上的实验结果。通过详细讨论，展示了不同方法在处理光照、年龄、姿态、遮挡和表情等挑战时的表现。
- Conclusion: 这篇综述为人脸识别领域提供了系统的文献回顾，总结了现有方法的特点和局限性，并强调了处理各种挑战因素对于开发有效人脸识别系统的重要性。论文最后提供了实验结果，为该领域的进一步研究提供了参考。


### [23] [EyeTheia: A Lightweight and Accessible Eye-Tracking Toolbox](https://arxiv.org/abs/2601.06279)
*Stevenson Pather,Niels Martignène,Arnaud Bugnet,Fouad Boutaleb,Fabien D'Hondt,Deise Santana Maia*

Main category: cs.CV

TL;DR: EyeTheia是一个轻量级、开源的深度学习管道，用于基于网络摄像头的视线估计，适用于浏览器实验平台和现实世界的认知与临床研究。

- Motivation: 为浏览器实验平台和现实世界的认知与临床研究提供低成本、可扩展的视线跟踪解决方案，解决商业解决方案昂贵且不透明的问题。
- Method: 结合MediaPipe地标提取和受iTracker启发的卷积神经网络，采用两种策略：在移动数据上预训练模型并适应桌面环境，或在桌面数据集上从头训练相同架构，支持轻量级用户特定微调。
- Result: 在MPIIFaceGaze验证中，两种方法在标定前表现相当，用户特定微调能持续减少视线预测误差；在Dot-Probe任务中与SeeSo SDK比较，刺激呈现期间左右视线分配有强一致性，但时间变异性较高。
- Conclusion: EyeTheia为低成本视线跟踪提供了透明且可扩展的解决方案，适合可扩展和可重复的实验与临床研究，代码、训练模型和实验材料已公开。


### [24] [NAS-GS: Noise-Aware Sonar Gaussian Splatting](https://arxiv.org/abs/2601.06285)
*Shida Xu,Jingqi Jiang,Jonatan Scharff Willners,Sen Wang*

Main category: cs.CV

TL;DR: NAS-GS：一种针对水下声纳图像的噪声感知高斯溅射框架，通过双向溅射技术和GMM噪声模型解决声纳图像3D重建和新视角合成的挑战。

- Motivation: 水下声纳图像在自主导航、海洋考古和环境监测中至关重要，但声纳图像特有的复杂噪声模式和缺乏高程信息给3D重建和新视角合成带来了重大挑战。
- Method: 提出NAS-GS框架，包含：1）双向溅射技术，准确建模声纳成像中强度累积和透射率计算的双向过程；2）基于高斯混合模型的噪声模型，捕捉侧瓣、散斑和多径噪声等复杂声纳噪声模式。
- Result: 在模拟和真实世界大规模离岸声纳场景中实现了最先进的性能，在新视角合成和3D重建方面取得了优越结果，提高了渲染速度而不牺牲质量。
- Conclusion: NAS-GS框架有效解决了声纳图像3D重建的挑战，通过创新的双向溅射和噪声建模技术，显著提升了水下声纳场景的渲染质量和重建精度。


### [25] [Perception Test 2025: Challenge Summary and a Unified VQA Extension](https://arxiv.org/abs/2601.06287)
*Joseph Heyward,Nikhil Pathasarathy,Tyler Zhu,Aravindh Mahendran,João Carreira,Dima Damen,Andrew Zisserman,Viorica Pătrăucean*

Main category: cs.CV

TL;DR: Perception Test 2025挑战赛在ICCV 2025举办，旨在评估最先进视频模型和多模态感知进展，强调任务统一化，包含五个统一赛道，显示现有模型在统一接口处理多样化感知任务时面临显著困难。

- Motivation: 该挑战赛的主要动机是评估最先进的视频模型，衡量多模态感知领域的进展，并通过任务统一化来测试当前最先进的多模态模型，因为统一化对现有模型提出了更严峻的挑战。
- Method: 挑战赛采用任务统一化方法，将五个赛道整合：统一视频问答、统一对象和点跟踪、统一动作和声音定位、基础视频问答、小时级视频问答。特别将传统感知任务重新表述为多项选择视频问答问题，要求参赛者使用统一方法而非特定任务的工程化流程。
- Result: 挑战赛结果显示，现有模型在通过统一接口处理多样化感知任务时面临显著困难。报告总结了主要挑战赛的结果，包括现有任务和新增加的基准测试。
- Conclusion: Perception Test 2025通过提出统一化挑战，突显了现有模型在通过统一接口处理多样化感知任务时面临的重大困难，强调了多模态感知领域需要进一步发展的方向。


### [26] [VideoWeave: A Data-Centric Approach for Efficient Video Understanding](https://arxiv.org/abs/2601.06309)
*Zane Durante,Silky Singh,Arpandeep Khatua,Shobhit Agarwal,Reuben Tan,Yong Jae Lee,Jianfeng Gao,Ehsan Adeli,Li Fei-Fei*

Main category: cs.CV

TL;DR: VideoWeave通过拼接现有短视频构建合成长期训练样本，提高视频语言模型的数据效率，无需修改模型架构

- Motivation: 训练视频语言模型成本高昂，因为处理长帧序列费用高且长视频标注数据有限，需要提高数据效率
- Method: 通过拼接现有短视频数据集中的短视频构建合成长期训练样本，研究不同数据组合策略（随机拼接、视觉聚类拼接、字幕丰富化）
- Result: 在相同计算约束下，使用VideoWeave训练的模型在视频问答任务上比传统视频微调获得更高准确率
- Conclusion: 重组训练数据而非修改架构，为训练视频语言模型提供了简单可扩展的路径


### [27] [Object-WIPER : Training-Free Object and Associated Effect Removal in Videos](https://arxiv.org/abs/2601.06391)
*Saksham Singh Kushwaha,Sayan Nag,Yapeng Tian,Kuldeep Kulkarni*

Main category: cs.CV

TL;DR: Object-WIPER：无需训练的框架，可从视频中移除动态物体及其视觉特效，并用语义一致、时序连贯的内容进行修复

- Motivation: 现有视频物体移除方法通常需要训练，且难以处理动态物体及其关联的视觉特效（如阴影、反射）。缺乏合适的评估指标来衡量移除效果的质量
- Method: 基于预训练文本到视频扩散变换器(DiT)，通过视觉-文本交叉注意力和视觉自注意力定位相关视觉标记，生成效果掩码并与用户掩码融合。先对视频进行反演获取结构化噪声，然后重新初始化掩码标记为高斯噪声，在去噪过程中保留背景标记以维持场景保真度
- Result: 在DAVIS和新构建的真实世界关联特效基准(WIPER-Bench)上，Object-WIPER在提出的新评估指标上超越了基于训练和无训练基线，实现了干净的移除和时序稳定的重建，无需任何重新训练
- Conclusion: Object-WIPER是一个无需训练的有效框架，能够从视频中移除动态物体及其视觉特效，并保持语义一致性和时序连贯性。提出的新评估指标能更好地衡量物体移除质量


### [28] [Context Matters: Peer-Aware Student Behavioral Engagement Measurement via VLM Action Parsing and LLM Sequence Classification](https://arxiv.org/abs/2601.06394)
*Ahmed Abdelkawy,Ahmed Elsayed,Asem Ali,Aly Farag,Thomas Tretter,Michael McIntyre*

Main category: cs.CV

TL;DR: 提出一個三階段框架，利用視覺語言模型和大語言模型，僅需少量標註數據即可從影片中預測學生參與度，並考慮課堂情境。

- Motivation: 現有學生參與度預測方法需要大量標註數據，且受隱私限制只能使用自有數據集，同時忽略課堂同儕行為的上下文情境。
- Method: 1. 使用少量樣本微調視覺語言模型進行學生動作識別
2. 用滑動時間窗口將2分鐘影片分段，用微調後的VLM模型為每段分配動作類別
3. 利用大語言模型結合動作序列和課堂情境，分類學生為參與或未參與
- Result: 實驗結果顯示該方法在識別學生參與度方面具有有效性。
- Conclusion: 提出的三階段框架能有效解決數據稀缺和情境忽略問題，為學生參與度測量提供新方法。


### [29] [GlobalPaint: Spatiotemporal Coherent Video Outpainting with Global Feature Guidance](https://arxiv.org/abs/2601.06413)
*Yueming Pan,Ruoyu Feng,Jianmin Bao,Chong Luo,Nanning Zheng*

Main category: cs.CV

TL;DR: GlobalPaint是一个基于扩散模型的视频外绘框架，通过分层处理（关键帧外绘+中间帧插值）和增强的时空模块（3D窗口注意力+全局特征引导）实现时空一致的高质量视频扩展。

- Motivation: 视频外绘需要在扩展视频边界时保持空间合理性和长时间跨度的时序一致性，特别是在相机或物体运动导致外绘内容随时间可见的情况下，这比图像外绘更具挑战性。
- Method: 采用分层处理流程：先外绘关键帧，再通过以完成边界为条件的插值模型完成中间帧，减少顺序处理的误差累积。模型层面，在预训练图像修复主干上增强：(1) 增强时空模块，采用3D窗口注意力加强时空交互；(2) 全局特征引导，使用专用提取器从所有帧的观察区域提取OpenCLIP特征到紧凑的全局token中。
- Result: 在基准数据集上的综合评估表明，相比现有方法，GlobalPaint在重建质量和运动自然度方面均有提升。
- Conclusion: GlobalPaint通过分层处理和增强的时空建模，实现了时空一致的高质量视频外绘，解决了传统方法中的误差累积和时序不一致问题。


### [30] [WHU-PCPR: A cross-platform heterogeneous point cloud dataset for place recognition in complex urban scenes](https://arxiv.org/abs/2601.06442)
*Xianghong Zou,Jianping Li,Yandi Yang,Weitong Wu,Yuan Wang,Qiegen Liu,Zhen Dong*

Main category: cs.CV

TL;DR: 提出了WHU-PCPR数据集，这是一个用于点云地点识别的跨平台异构点云数据集，包含移动激光扫描和便携式头盔激光扫描系统采集的数据，覆盖城市和校园场景，轨迹长达82.3公里。

- Motivation: 现有点云地点识别数据集在场景、平台和传感器多样性方面不足，限制了相关研究的有效发展。实际应用中，点云通常来自不同平台和激光雷达在不同场景下采集，需要更全面的数据集来支持研究。
- Method: 建立WHU-PCPR数据集，包含：1）跨平台异构点云：来自测量级车载移动激光扫描系统和低成本便携式头盔激光扫描系统，配备不同的机械和固态激光雷达传感器；2）复杂定位场景：涵盖城市和校园道路场景的实时和长期变化；3）大规模空间覆盖：82.3公里轨迹，60个月时间跨度，约30公里不重复路线。
- Result: 基于WHU-PCPR数据集对几种代表性点云地点识别方法进行了广泛评估和深入分析，提供了关键挑战和未来研究方向的简要讨论。数据集和基准代码已开源。
- Conclusion: WHU-PCPR数据集填补了点云地点识别领域在数据集多样性方面的空白，为相关研究提供了更全面的基准测试平台，有助于推动点云地点识别技术的发展。


### [31] [How to Build Robust, Scalable Models for GSV-Based Indicators in Neighborhood Research](https://arxiv.org/abs/2601.06443)
*Xiaoya Tang,Xiaohe Yue,Heran Mane,Dapeng Li,Quynh Nguyen,Tolga Tasdizen*

Main category: cs.CV

TL;DR: 该研究通过实证分析探讨了计算机视觉模型在跨领域泛化（如从ImageNet到街景图像）中的关键问题，为有限标注数据下的模型选择和适应提供实用指导。

- Motivation: 健康研究表明社区环境与健康结果密切相关，计算机视觉可用于大规模社区环境特征化。但模型在不同领域间的泛化能力不确定（如从ImageNet到街景图像），且在实际应用中面临模型选择、无监督训练策略、计算约束和下游性能等关键问题，这些决策成本高且需要专业知识。
- Method: 通过实证分析比较模型性能，研究如何为有限规模和标注的数据集选择和适应基础模型，同时利用更大的无标注数据集进行无监督训练。包括全面的定量和视觉分析，比较无监督适应前后的模型表现。
- Result: 论文提供了关于模型选择和适应的实用见解，通过无监督训练策略在有限标注数据下提升模型性能，具体结果需要查看完整论文的定量分析数据。
- Conclusion: 该研究为健康研究等应用领域提供了计算机视觉模型跨领域适应的实用指南，帮助研究人员在有限资源和标注数据下做出更明智的模型选择和训练策略决策。


### [32] [Tone Matters: The Impact of Linguistic Tone on Hallucination in VLMs](https://arxiv.org/abs/2601.06460)
*Weihao Hong,Zhiyuan Jiang,Bingyu Shen,Xinlei Guan,Yangyi Feng,Meng Xu,Boyang Li*

Main category: cs.CV

TL;DR: 研究发现视觉语言模型在安全关键应用中存在幻觉问题，Ghost-100数据集通过控制视觉细节缺失和5级提示强度框架，揭示了模型对结构性约束的脆弱性，而非语义敌对性。

- Motivation: 视觉语言模型在安全关键应用中需要可靠的视觉基础，但经常产生图像中不存在的幻觉细节。现有研究主要关注对象存在与否，缺乏对提示措辞和结构约束如何系统性诱导幻觉的深入理解。
- Method: 引入Ghost-100程序生成数据集，其中关键视觉细节被故意移除；使用5级提示强度框架，从中性查询到有毒需求和刚性格式约束；评估三个代表性开源VLM模型：MiniCPM-V 2.6-8B、Qwen2-VL-7B和Qwen3-VL-8B。
- Result: 所有模型的幻觉率并不随提示强度单调增加，在较高强度级别都出现减少，但并非所有模型在最大胁迫下都持续减少。这表明当前的安全对齐更擅长检测语义敌对性而非结构性胁迫。
- Conclusion: 当前视觉语言模型的安全对齐机制在处理结构性胁迫方面存在局限性，需要改进模型对格式约束和合规压力的鲁棒性，以提升在安全关键应用中的可靠性。


### [33] [On the Adversarial Robustness of 3D Large Vision-Language Models](https://arxiv.org/abs/2601.06464)
*Chao Liu,Ngai-Man Cheung*

Main category: cs.CV

TL;DR: 本文首次系统研究基于点云的3D视觉语言模型的对抗鲁棒性，提出视觉攻击和字幕攻击两种策略，发现3D VLMs在无目标攻击下存在显著漏洞，但在有目标攻击中比2D VLMs更具韧性。

- Motivation: 虽然3D视觉语言模型在3D理解任务中表现出强大的推理和泛化能力，但其对抗鲁棒性尚未得到充分研究。2D VLMs的研究表明视觉输入的整合显著增加了对抗攻击的脆弱性，本文旨在探究3D视觉是否同样会损害3D VLMs的鲁棒性。
- Method: 提出两种互补的攻击策略：1）视觉攻击：扰动3D编码器和投影器产生的视觉令牌特征，评估视觉-语言对齐的鲁棒性；2）字幕攻击：直接操纵输出令牌序列，评估端到端系统鲁棒性。每种攻击都包括无目标和有目标变体。
- Result: 实验表明，3D VLMs在无目标攻击下表现出显著的对抗脆弱性，但在旨在强制产生特定有害输出的有目标攻击中，相比2D对应模型展现出更强的韧性。
- Conclusion: 3D VLMs存在对抗脆弱性问题，特别是在无目标攻击下。随着这些模型在安全关键应用中的部署，提高其对抗鲁棒性至关重要。研究结果为未来增强3D VLMs的安全性提供了重要见解。


### [34] [SparseOccVLA: Bridging Occupancy and Vision-Language Models via Sparse Queries for Unified 4D Scene Understanding and Planning](https://arxiv.org/abs/2601.06474)
*Chenxu Dang,Jie Wang,Guang Li,Zhiwen Hou,Zihan You,Hangjun Ye,Jie Ma,Long Chen,Yan Wang*

Main category: cs.CV

TL;DR: SparseOccVLA是一个新颖的视觉-语言-动作模型，通过稀疏占用查询统一了场景理解、占用预测和轨迹规划，解决了传统VLM的令牌爆炸和时空推理限制问题。

- Motivation: 自动驾驶中，视觉语言模型擅长高层推理但存在令牌爆炸和时空推理限制，而语义占用提供细粒度空间表示但过于密集难以与VLM高效集成。目前缺乏有效整合两种范式的方法。
- Method: 提出SparseOccVLA模型：1) 轻量级稀疏占用编码器生成紧凑的稀疏占用查询作为视觉和语言的桥梁；2) 将查询对齐到语言空间由LLM进行统一场景理解和未来占用预测；3) LLM引导的锚点扩散规划器，包含解耦的锚点评分和去噪以及跨模态轨迹条件融合。
- Result: 在OmniDrive-nuScenes上CIDEr相对提升7%，在Occ3D-nuScenes上mIoU提升0.5分，在nuScenes基准测试中创下开环规划指标的最先进水平，展示了强大的整体能力。
- Conclusion: SparseOccVLA通过稀疏占用查询有效桥接了视觉语言模型和语义占用，实现了统一的场景理解、占用预测和轨迹规划，为自动驾驶提供了更全面的感知和决策能力。


### [35] [VVTRec: Radio Interferometric Reconstruction through Visual and Textual Modality Enrichment](https://arxiv.org/abs/2601.06475)
*Kai Cheng,Ruoqi Wang,Qiong Luo*

Main category: cs.CV

TL;DR: VVTRec：一种多模态射电干涉数据重建方法，通过可见度引导的视觉和文本模态增强，利用预训练的视觉语言模型提升图像重建质量

- Motivation: 现有射电干涉测量方法仅考虑稀疏可见度数据的单一模态，导致重建图像存在残留伪影且相关性建模不足。需要增强可见度信息提取并提升图像域输出质量
- Method: 提出VVTRec多模态重建方法：将稀疏可见度转换为图像形式和文本形式的特征，获得空间和语义信息增强；利用预训练视觉语言模型实现无需额外训练的性能提升
- Result: 实验表明VVTRec能有效利用多模态信息增强成像结果，且不引入过多计算开销
- Conclusion: 通过可见度引导的多模态增强和预训练知识提取，VVTRec改善了射电干涉图像的结构完整性和准确性


### [36] [SRFlow: A Dataset and Regularization Model for High-Resolution Facial Optical Flow via Splatting Rasterization](https://arxiv.org/abs/2601.06479)
*JiaLin Zhang,Dong Li*

Main category: cs.CV

TL;DR: 提出了高分辨率面部光流数据集SRFlow和专用模型SRFlowNet，通过高斯溅射光栅化引导的面部皮肤运动捕捉，显著提升了面部光流估计和微表情识别性能。

- Motivation: 当前缺乏高分辨率面部光流数据集，这限制了面部运动分析领域的发展。特别是在纹理较少或重复图案区域，传统方法容易产生高频噪声和大尺度误差。
- Method: 1) 创建高分辨率面部光流数据集SRFlow；2) 提出SRFlowNet模型，使用掩码和梯度计算的定制正则化损失（差分或Sobel算子），在无纹理或重复图案区域抑制噪声和误差；3) 利用高斯溅射光栅化引导高分辨率皮肤运动捕捉。
- Result: 1) SRFlow数据集训练使各种光流模型的端点误差(EPE)降低达42%(从0.5081到0.2953)；2) SRFlowNet结合SRFlow数据集在三个微表情数据集上F1分数提升达48%(从0.4733到0.6947)；3) 首次实现高斯溅射光栅化引导的高分辨率皮肤运动捕捉。
- Conclusion: SRFlow数据集和SRFlowNet模型共同推动了面部光流估计和微表情识别的发展，通过高质量数据集和专门的正则化方法解决了纹理区域的光流估计难题，为面部运动分析提供了有力工具。


### [37] [Learning Domain Agnostic Latent Embeddings of 3D Faces for Zero-shot Animal Expression Transfer](https://arxiv.org/abs/2601.06484)
*Yue Wang,Lawrence Amadi,Xiang Gao,Yazheng Chen,Yuanpeng Liu,Ning Lu,Xianfeng Gu*

Main category: cs.CV

TL;DR: 提出一个零样本框架，将人类面部表情迁移到3D动物面部网格，无需动物表情数据，通过解耦身份和表情的潜在空间实现跨物种表情迁移。

- Motivation: 现有的表情迁移方法通常需要大量配对数据，但获取动物表情数据困难。本文旨在开发一个无需动物表情数据的跨物种表情迁移框架，解决人类与动物面部几何差异大的挑战。
- Method: 结合内在几何描述符（HKS/WKS）和网格无关的潜在嵌入，解耦面部身份和表情。身份潜在空间捕捉物种无关的面部结构，表情潜在空间编码跨人类和动物的变形模式。仅使用人类表情对训练，学习嵌入、解耦和重耦合。使用雅可比损失、顶点位置损失和拉普拉斯损失确保几何一致性。
- Result: 实验表明该方法实现了合理的跨物种表情迁移，有效缩小了人类与动物面部形状之间的几何差距，无需动物表情数据即可完成表情迁移。
- Conclusion: 提出了一个零样本框架，成功将人类面部表情迁移到3D动物面部，通过解耦身份和表情的潜在表示，实现了无需动物训练数据的跨物种表情迁移，为计算机图形学和动画提供了新工具。


### [38] [3D CoCa v2: Contrastive Learners with Test-Time Search for Generalizable Spatial Intelligence](https://arxiv.org/abs/2601.06496)
*Hao Tang,Ting Huang,Zeyu Zhang*

Main category: cs.CV

TL;DR: 3D CoCa v2：通过对比学习与测试时搜索的统一框架，提升3D场景描述任务的泛化能力，在室内外场景中均取得显著改进。

- Motivation: 现有3D场景描述方法面临点云数据稀疏不规则、弱语义关联以及跨域泛化能力不足的问题，特别是在室内外不同环境间的迁移性能较差。
- Method: 提出统一框架：1）基于冻结CLIP的语义先验；2）空间感知的3D场景几何编码器；3）多模态解码器联合优化对比学习和描述生成目标；4）测试时搜索生成多样候选描述并进行奖励引导选择。
- Result: 在ScanRefer上CIDEr@0.5IoU提升+1.50，Nr3D上提升+1.61，在TOD3Cap的零样本跨域评估中CIDEr@0.25提升+3.8，显著优于前代方法。
- Conclusion: 3D CoCa v2通过统一对比学习与描述生成，结合测试时搜索策略，有效提升了3D场景描述的泛化能力和跨域性能，为空间智能提供了更鲁棒的解决方案。


### [39] [Bridging Robustness and Efficiency: Real-Time Low-Light Enhancement via Attention U-Net GAN](https://arxiv.org/abs/2601.06518)
*Yash Thesia,Meera Suthar*

Main category: cs.CV

TL;DR: 提出混合注意力U-Net GAN，在保持生成模型纹理恢复能力的同时实现40倍加速，填补低光图像增强中速度与质量之间的空白。

- Motivation: 当前低光图像增强存在明显权衡：扩散模型质量高但计算延迟大（2-4秒/图像），CNN模型速度快但纹理恢复差（过度平滑）。缺乏既能提供生成级纹理恢复又能边缘部署的模型。
- Method: 提出混合注意力U-Net GAN：将注意力门集成到轻量级U-Net骨干网络中，在条件对抗框架下训练，单次前向传播即可近似生成模型的高频保真度。
- Result: 在SID数据集上取得最佳LPIPS分数0.112（高效模型中），显著优于SID、EnlightenGAN等基线，推理延迟仅0.06秒，比潜在扩散模型快40倍。
- Conclusion: 扩散模型的迭代采样对纹理恢复并非必需，通过注意力U-Net GAN可在单次前向传播中实现近实时的高质量低光增强，填补了速度与质量之间的实践空白。


### [40] [BabyVision: Visual Reasoning Beyond Language](https://arxiv.org/abs/2601.06521)
*Liang Chen,Weichu Xie,Yiyan Liang,Hongfeng He,Hans Zhao,Zhibo Yang,Zhiqi Huang,Haoning Wu,Haoyu Lu,Y. charles,Yiping Bao,Yuantao Fan,Guopeng Li,Haiyang Shen,Xuanzhong Chen,Wendong Xu,Shuzheng Si,Zefan Cai,Wenhao Chai,Ziqi Huang,Fangfu Liu,Tianyu Liu,Baobao Chang,Xiaobo Hu,Kaiyuan Chen,Yixin Ren,Yang Liu,Yuan Gong,Kuan Li*

Main category: cs.CV

TL;DR: BabyVision是一个评估多模态大语言模型核心视觉能力的基准测试，发现当前最先进的MLLMs在基本视觉任务上表现远低于人类水平，甚至不如3岁儿童。

- Motivation: 人类在获得语言能力之前就已发展出核心视觉技能，而当前的多模态大语言模型(MLLMs)过度依赖语言先验来弥补其脆弱的视觉理解能力。研究发现最先进的MLLMs在人类（甚至3岁儿童）能轻松解决的基本视觉任务上持续失败。
- Method: 引入BabyVision基准测试，包含388个项目，分为22个子类，涵盖四个关键类别，旨在评估MLLMs独立于语言知识的核心视觉能力。同时提出BabyVision-Gen和自动评估工具包。
- Result: 主要MLLMs表现显著低于人类基线。Gemini3-Pro-Preview得分为49.7，落后于6岁儿童，远低于成人平均分94.1。这表明尽管在知识密集型评估中表现出色，当前MLLMs仍缺乏基本的视觉原语。
- Conclusion: BabyVision的进展代表了向人类水平视觉感知和推理能力迈出的一步。代码和基准数据已开源，供复现研究使用。


### [41] [Toward Generalizable Deblurring: Leveraging Massive Blur Priors with Linear Attention for Real-World Scenarios](https://arxiv.org/abs/2601.06525)
*Yuanting Gao,Shuo Cao,Xiaohui Li,Yuandong Pu,Yihao Liu,Kai Zhang*

Main category: cs.CV

TL;DR: 提出GLOWDeblur模型，通过模糊模式预训练(BPP)和运动语义引导(MoSeG)提升去模糊模型的泛化能力，在多个基准测试中验证了有效性。

- Motivation: 现有深度学习去模糊方法泛化能力差，主要原因是数据集在真实性和模糊模式多样性之间存在权衡，以及算法设计限制（像素级损失只关注局部细节而忽略结构语义一致性）。扩散模型虽然感知质量好，但在窄数据集上训练时仍无法泛化。
- Method: 1. 模糊模式预训练(BPP)：从仿真数据集学习模糊先验，通过联合微调迁移到真实数据；2. 运动语义引导(MoSeG)：在严重退化情况下增强模糊先验；3. GLOWDeblur架构：结合基于卷积的预重建和域对齐模块与轻量级扩散主干。
- Result: 在六个广泛使用的基准测试和两个真实世界数据集上的大量实验验证了方法的有效性，确认了模糊先验对鲁棒泛化的重要性，GLOWDeblur的轻量设计确保了实际应用可行性。
- Conclusion: 模糊模式多样性是鲁棒泛化的关键因素，提出的BPP和MoSeG方法能有效提升去模糊模型的泛化能力，GLOWDeblur模型在保持轻量化的同时实现了优异的性能。


### [42] [Towards Egocentric 3D Hand Pose Estimation in Unseen Domains](https://arxiv.org/abs/2601.06537)
*Wiktor Mucha,Michael Wray,Martin Kampel*

Main category: cs.CV

TL;DR: V-HPOT是一种改进3D手部姿态估计跨域性能的新方法，通过虚拟相机空间估计关键点深度实现相机无关预测，并采用自监督测试时优化策略，显著减少跨域姿态误差。

- Motivation: 现有3D手部姿态估计方法在相同域内表现良好，但在新环境中泛化能力差，主要受限于训练数据不足和深度感知问题，容易过拟合到特定相机内参。
- Method: 1) 在虚拟相机空间中估计关键点z坐标，通过焦距和图像尺寸归一化实现相机无关深度预测；2) 提出自监督测试时优化策略，应用3D一致性损失在预测和空间尺度变换的手部姿态之间，无需真实标注即可适应目标域特征。
- Result: 在跨域场景中显著提升3D手部姿态估计性能：H2O数据集上平均姿态误差减少71%，AssemblyHands数据集上减少41%。相比现有方法，在所有数据集上优于所有单阶段方法，与两阶段方法表现相当，但所需数据量少3.5到14倍。
- Conclusion: V-HPOT通过虚拟相机空间归一化和自监督测试时优化，有效解决了3D手部姿态估计的跨域泛化问题，在减少数据需求的同时实现了显著的性能提升。


### [43] [LLMTrack: Semantic Multi-Object Tracking with Multi-modal Large Language Models](https://arxiv.org/abs/2601.06550)
*Pan Liao,Feng Yang,Di Wu,Jinwen Yu,Yuhua Zhu,Wenhui Zhao*

Main category: cs.CV

TL;DR: LLMTrack是一个用于语义多目标跟踪的端到端框架，通过解耦强定位与深度理解，使用Grounding DINO作为"眼睛"、LLaVA-OneVision作为"大脑"，结合时空融合模块和三阶段训练策略，在BenSMOT基准上实现SOTA性能。

- Motivation: 传统MOT系统虽然能精确定位和关联目标（回答"在哪里"和"是谁"），但缺乏对目标行为语义的理解（"是什么"和"为什么"），无法理解行为背后的语义含义。需要弥合几何感知与认知推理之间的鸿沟。
- Method: 采用仿生设计哲学：1) Grounding DINO作为"眼睛"负责强定位；2) LLaVA-OneVision多模态大模型作为"大脑"负责深度理解；3) 时空融合模块聚合实例级交互特征和视频级上下文；4) 渐进式三阶段训练策略：视觉对齐、时序微调、通过LoRA进行语义注入。
- Result: 在BenSMOT基准测试中，LLMTrack实现了最先进的性能，在实例描述、交互识别和视频摘要方面显著优于现有方法，同时保持稳健的跟踪稳定性。
- Conclusion: LLMTrack成功地将几何感知与认知推理相结合，为语义多目标跟踪提供了有效的解决方案，通过大语言模型理解复杂轨迹，实现了从"自闭观察者"到"语义理解者"的转变。


### [44] [ArrowGEV: Grounding Events in Video via Learning the Arrow of Time](https://arxiv.org/abs/2601.06559)
*Fangxu Yu,Ziyao Lu,Liqiang Niu,Fandong Meng,Jie Zhou*

Main category: cs.CV

TL;DR: ArrowGEV：基于强化学习的视频事件定位框架，通过建模时间方向性（前向/后向视频）提升视觉语言模型的事件定位能力和时间方向理解

- Motivation: 现有视觉语言模型主要训练在前向视频中关联事件与时间戳，忽略了事件固有的时间结构和方向性，限制了模型的鲁棒性和泛化能力。受物理学中"时间箭头"概念启发，需要显式建模时间方向性来改进事件定位
- Method: 提出ArrowGEV强化学习框架：1）将事件分为时间敏感型（如放下包）和时间不敏感型（如左手拿毛巾）；2）对时间敏感事件，设计奖励机制鼓励模型区分前向和后向视频；3）对时间不敏感事件，强制模型在两个方向保持一致的定位结果
- Result: 大量实验表明ArrowGEV不仅提高了事件定位精度和时间方向性识别能力，还增强了通用视频理解和推理能力
- Conclusion: 通过显式建模时间方向性，ArrowGEV框架有效提升了视觉语言模型在视频事件定位任务中的性能，证明了考虑时间方向性对视频理解的重要性


### [45] [QCaption: Video Captioning and Q&A through Fusion of Large Multimodal Models](https://arxiv.org/abs/2601.06566)
*Jiale Wang,Gee Wah Ng,Lee Onn Mak,Randall Cher,Ng Ding Hei Ryan,Davis Wang*

Main category: cs.CV

TL;DR: QCaption是一个融合关键帧提取、大型多模态模型和大型语言模型的视频描述与问答管道，相比现有方法在视频描述任务上提升44.2%，在问答任务上提升48.9%，适合本地部署。

- Motivation: 现有视频分析方法在处理文本、图像和视频的集成分析方面存在局限，需要一种能够融合多模态信息且适合本地部署的解决方案来提升视频分析性能。
- Method: 提出QCaption管道，融合三个模型：1) 关键帧提取模型；2) 大型多模态模型用于图像-文本分析；3) 大型语言模型用于文本分析。通过这种融合实现文本、图像和视频的集成分析。
- Result: 实验结果显示，QCaption在视频描述任务上相比现有方法提升44.2%，在问答任务上提升48.9%。消融研究评估了LLM在融合中的作用，并与其他视频描述方法进行了基准测试。
- Conclusion: QCaption展示了模型融合方法在推进视频分析方面的潜力，提供了一种完全自包含、适合本地部署的高性能视频分析解决方案。


### [46] [APEX: Learning Adaptive Priorities for Multi-Objective Alignment in Vision-Language Generation](https://arxiv.org/abs/2601.06574)
*Dongliang Chen,Xinlin Zhuang,Junjie Xu,Luojian Xie,Zehui Wang,Jiaxi Zhuang,Haolin Yang,Liang Dou,Xiao He,Xingjiao Wu,Ying Qian*

Main category: cs.CV

TL;DR: APEX提出自适应多目标对齐方法，解决文本到图像生成中静态线性加权导致的优化不平衡问题，通过双阶段自适应归一化和P^3自适应优先级调度实现更平衡的Pareto权衡。

- Motivation: 当前文本到图像生成的多目标对齐通常使用静态线性加权，但在异质奖励下固定权重往往失效，导致优化不平衡：模型过度拟合高方差、高响应性目标（如OCR），而低估感知目标。作者识别出两个机制原因：方差劫持和梯度冲突。
- Method: 提出APEX方法：1) 双阶段自适应归一化稳定异质奖励；2) P^3自适应优先级调度，结合学习潜力、冲突惩罚和进度需求动态安排目标优先级。
- Result: 在Stable Diffusion 3.5上，APEX在四个异质目标上实现了改进的Pareto权衡：PickScore +1.31，DeQA +0.35，Aesthetics +0.53，同时保持竞争力的OCR准确性，缓解了多目标对齐的不稳定性。
- Conclusion: APEX通过自适应机制有效解决了多目标对齐中的优化不平衡问题，为异质奖励下的文本到图像生成提供了更稳定和平衡的优化框架。


### [47] [Sissi: Zero-shot Style-guided Image Synthesis via Semantic-style Integration](https://arxiv.org/abs/2601.06605)
*Yingying Deng,Xiangyu He,Fan Tang,Weiming Dong,Xucheng Yin*

Main category: cs.CV

TL;DR: 提出无需训练的框架，将风格引导合成重新定义为上下文学习任务，通过预训练ReFlow修复模型和多模态注意力融合实现高质量风格化

- Motivation: 现有文本引导图像生成方法在精确风格化方面存在困难，通常需要任务特定重训练或昂贵的反演过程，会损害内容完整性、降低风格保真度，并在语义提示遵循和风格对齐之间产生不理想的权衡
- Method: 训练免费框架，将参考风格图像与掩码目标图像拼接，利用预训练ReFlow修复模型通过多模态注意力融合无缝集成语义内容和所需风格；提出动态语义-风格集成(DSSI)机制重新加权文本语义和风格视觉标记之间的注意力
- Result: 实验表明该方法实现了高保真风格化，具有优越的语义-风格平衡和视觉质量，为复杂、易产生伪影的现有方法提供了简单而强大的替代方案
- Conclusion: 提出的训练免费框架通过重新定义风格引导合成为上下文学习任务，解决了现有方法在精确风格化方面的局限性，实现了高质量的风格化结果


### [48] [Boosting Overlapping Organoid Instance Segmentation Using Pseudo-Label Unmixing and Synthesis-Assisted Learning](https://arxiv.org/abs/2601.06642)
*Gui Huang,Kangyuan Zheng,Xuan Cai,Jiaqi Wang,Jianjia Zhang,Kaida Ning,Wenbo Wei,Yujuan Zhu,Jiong Zhang,Mengting Liu*

Main category: cs.CV

TL;DR: 提出PLU方法解决器官类器官重叠分割问题，结合伪标签解混和轮廓合成，仅用10%标注数据达到全监督性能

- Motivation: 器官类器官实例分割对医学研究至关重要，但面临高质量标注数据稀缺和显微镜成像中普遍重叠的问题。现有半监督学习框架在重叠区域容易产生噪声伪标签偏差，合成辅助的半监督学习也难以解耦交织的类器官
- Method: 提出伪标签解混(PLU)方法：1)识别重叠实例的错误伪标签；2)通过实例分解重新生成类器官标签。采用轮廓合成方法高效合成类器官实例，特别是重叠情况。在图像合成前对伪标签进行实例级增强，提升合成数据效果
- Result: 在两个类器官数据集上的实验表明，仅使用10%标注数据就能达到全监督模型的性能，并取得最先进的结果。消融研究验证了PLU、轮廓合成和增强感知训练的有效性
- Conclusion: 通过在伪标签和合成两个层面解决重叠问题，本研究推动了可扩展、标注高效的类器官分析，为精准医学中的高通量应用开辟了新潜力


### [49] [eSkiTB: A Synthetic Event-based Dataset for Tracking Skiers](https://arxiv.org/abs/2601.06647)
*Krishna Vinod,Joseph Raj Vishal,Kaustav Chanda,Prithvi Jai Ramesh,Yezhou Yang,Bharatesh Chakravarthi*

Main category: cs.CV

TL;DR: 论文提出首个基于事件相机的滑雪追踪数据集eSkiTB，通过对比实验证明事件相机在广播视频中静态覆盖物干扰下比RGB追踪更鲁棒，SDTrack方法在静态覆盖主导场景中IoU达到0.685，比RGB方法高20个百分点。

- Motivation: RGB广播视频中的滑雪追踪面临运动模糊、静态覆盖物和杂乱背景等挑战，而事件相机具有异步对比度感知特性，天然对这些干扰具有鲁棒性，但缺乏冬季运动追踪的受控基准数据集。
- Method: 1. 从SkiTB数据集通过直接视频到事件转换生成合成事件数据集eSkiTB，避免神经插值；2. 使用SDTrack（脉冲变压器）与STARK（RGB变压器）进行基准测试；3. 在静态覆盖物主导的场景中评估追踪性能。
- Result: 1. 在静态覆盖物主导场景中，事件追踪IoU达到0.685，比RGB追踪高出20.0个百分点；2. 在整个数据集上，SDTrack平均IoU为0.711；3. 证明时间对比度是视觉拥挤环境中追踪弹道运动的可靠线索。
- Conclusion: eSkiTB建立了冬季运动中事件追踪的首个受控设置，突显了事件相机在滑雪追踪中的潜力，时间对比度是处理广播视频中静态覆盖物干扰的有效线索。


### [50] [Quantification and Classification of Carbon Nanotubes in Electron Micrographs using Vision Foundation Models](https://arxiv.org/abs/2601.06673)
*Sanjay Pradeep,Chen Wang,Matthew M. Dahm,Jeff D. Eldredge,Candace S. J. Tsai*

Main category: cs.CV

TL;DR: 提出基于视觉基础模型的统一框架，用于自动化电子显微镜图像中碳纳米管的定量分析和形态分类，显著提高准确性和效率。

- Motivation: 当前碳纳米管形态表征依赖缓慢、主观的手动分割，需要自动化解决方案来支持暴露评估和毒理学研究的高通量分析。
- Method: 1) 基于Segment Anything Model (SAM)的交互式量化工具，用最少用户输入实现高精度分割；2) 利用分割掩码空间约束DINOv2视觉变换器，从粒子区域提取特征并抑制背景噪声的分类流程。
- Result: 在1,800张TEM图像数据集上，该架构在区分四种不同CNT形态方面达到95.5%的准确率，显著优于当前基线，且仅使用少量训练数据。能够处理混合样本，正确分类同一视野中共存的不同粒子类型。
- Conclusion: 零样本分割与自监督特征学习的结合实现了高通量、可重复的纳米材料分析，将劳动密集型瓶颈转变为可扩展的数据驱动过程。


### [51] [When Humans Judge Irises: Pupil Size Normalization as an Aid and Synthetic Irises as a Challenge](https://arxiv.org/abs/2601.06725)
*Mahsa Mitcheff,Adam Czajka*

Main category: cs.CV

TL;DR: 人类在虹膜验证中的表现研究：瞳孔大小对齐和合成虹膜图像对准确性的影响

- Motivation: 尽管虹膜识别技术已经很成熟，但在法医应用中，人类专家仍需要审查和确认匹配结果，特别是在样本质量较差或需要判断样本真伪的情况下。本研究旨在评估人类在虹膜验证任务中的表现，特别是在瞳孔大小变化和合成图像场景下的能力。
- Method: 研究设计了两种控制场景：(1) 在不同瞳孔大小条件下，比较有无瞳孔大小对齐（使用基于自编码器的身份保持图像转换模型）对人类验证准确性的影响；(2) 使用合成生成的虹膜图像对（包括真实对和冒名顶替对），评估人类区分真伪虹膜的能力。
- Result: 瞳孔大小归一化显著提高了人类验证准确性。参与者能够区分真实虹膜对和合成虹膜对是否来自同一眼睛，但当比较真实虹膜与高质量合成虹膜时，准确性下降。人类更倾向于将同一眼睛的真实-合成图像对判断为不同眼睛的图像对。
- Conclusion: 瞳孔大小对齐对人类参与的虹膜匹配任务至关重要；尽管现代生成模型能产生高保真度图像，但人类对同一眼睛的真实-合成图像对的判断准确性低于真实图像对，这表明合成虹膜图像在人类验证中存在挑战。


### [52] [Benchmarking Egocentric Clinical Intent Understanding Capability for Medical Multimodal Large Language Models](https://arxiv.org/abs/2601.06750)
*Shaonan Liu,Guo Yu,Xiaoling Luo,Shiyi Zheng,Wenting Chen,Jie Liu,Linlin Shen*

Main category: cs.CV

TL;DR: MedGaze-Bench：首个利用临床医生注视作为认知指针评估医学多模态大模型在手术、急诊模拟和诊断解读中意图理解能力的基准测试

- Motivation: 现有基准测试无法评估医学多模态大模型在真实世界部署所需的关键能力——以自我为中心的临床意图理解，这限制了模型的实际应用价值
- Method: 提出MedGaze-Bench基准，利用临床医生注视作为认知指针，构建三维临床意图框架：空间意图（区分视觉噪声中的精确目标）、时间意图（通过回顾性和前瞻性推理推断因果逻辑）、标准意图（通过安全检查验证协议合规性）
- Result: 实验显示当前MLLMs在自我中心意图理解方面表现不佳，过度依赖全局特征，导致虚构观察结果和不加批判地接受无效指令
- Conclusion: 需要开发更可靠的医学多模态大模型，能够准确理解临床意图，避免幻觉和认知顺从，MedGaze-Bench为此提供了有效的评估框架


### [53] [The Normalized Difference Layer: A Differentiable Spectral Index Formulation for Deep Learning](https://arxiv.org/abs/2601.06777)
*Ali Lotfi,Adam Carter,Mohammad Meysami,Thuan Ha,Kwabena Nketia,Steve Shirtliffe*

Main category: cs.CV

TL;DR: 提出可微分的归一化差分层，将传统遥感归一化差分指数中的波段系数从固定值改为可学习参数，保持光照不变性和有界输出优势的同时，让模型能自适应学习任务特定的波段权重。

- Motivation: 传统归一化差分指数在遥感中应用广泛，具有光照不变性、输出有界等优点，但其系数通常固定为1，限制了其对特定学习任务的适应能力。需要一种既能保持传统优势又能自适应学习波段权重的方法。
- Method: 提出可微分的归一化差分层作为神经网络模块，使用softplus重参数化确保系数为正且分母有界，设计前向和反向传播算法支持端到端训练，可处理有符号输入并堆叠在深层架构中。
- Result: 使用该层的模型在达到与标准多层感知器相似分类精度的同时，参数数量减少约75%；在10%乘性噪声下，精度仅下降0.17%，而基线MLP下降3.03%；学习到的系数模式在不同深度下保持一致性。
- Conclusion: 归一化差分层成功将传统遥感指数转化为可学习的神经网络模块，在保持光照不变性和输出有界等优点的同时，显著提升了参数效率和噪声鲁棒性，为遥感深度学习提供了新的可解释模块。


### [54] [CliffordNet: All You Need is Geometric Algebra](https://arxiv.org/abs/2601.06793)
*Zhongping Ji*

Main category: cs.CV

TL;DR: CliffordNet提出基于几何代数的视觉骨干网络，用Clifford几何积统一特征交互，无需传统FFN模块，在极小参数量下达到SOTA性能

- Motivation: 挑战现有视觉架构堆叠启发式模块（空间混合器+通道混合器）的范式，回归数学第一性原理，探索基于几何代数的统一交互机制
- Method: 提出Clifford代数网络（CAN/CliffordNet），基于Clifford几何积（uv = u·v + u∧v）统一特征交互，通过高效稀疏滚动机制实现严格线性复杂度O(N)
- Result: Nano变体在CIFAR-100上达到76.41%准确率（仅1.4M参数），匹配ResNet-18（11.2M参数）但参数量减少8倍；Base变体在微小模型上创下78.05%的新SOTA
- Conclusion: 几何交互的表征密度极高，使标准FFN变得冗余，全局理解可从严格的代数完备局部交互中涌现，暗示"几何即所需"的范式转变


### [55] [SpatialNav: Leveraging Spatial Scene Graphs for Zero-Shot Vision-and-Language Navigation](https://arxiv.org/abs/2601.06806)
*Jiwen Zhang,Zejun Li,Siyuan Wang,Xiangyu Shi,Zhongyu Wei,Qi Wu*

Main category: cs.CV

TL;DR: SpatialNav：一种基于空间场景图的零样本视觉语言导航代理，通过探索环境构建全局空间表示，显著提升导航性能

- Motivation: 零样本VLN代理缺乏从大规模训练数据中隐式学习空间知识的过程，主要依赖局部观察进行导航，导致探索效率低下和性能差距显著。为解决这一问题，研究者考虑让代理在执行任务前充分探索环境。
- Method: 构建空间场景图（SSG）来显式捕捉探索环境中的全局空间结构和语义，基于SSG开发SpatialNav代理，整合了以代理为中心的空间地图、罗盘对齐的视觉表示和远程物体定位策略。
- Result: 在离散和连续环境中的综合实验表明，SpatialNav显著优于现有零样本代理，并明显缩小了与最先进学习方法的差距。
- Conclusion: 全局空间表示对于可泛化导航至关重要，SpatialNav通过显式构建空间场景图有效提升了零样本视觉语言导航的性能。


### [56] [SARA: Scene-Aware Reconstruction Accelerator](https://arxiv.org/abs/2601.06831)
*Jee Won Lee,Hansol Lim,Minhyeok Im,Dohyeon Lee,Jongseong Brad Choi*

Main category: cs.CV

TL;DR: SARA通过几何驱动的图像对选择方法，在SfM中显著减少匹配对数量（98%减少），同时保持重建精度，实现46.5%旋转误差降低和50倍加速。

- Motivation: 传统SfM流水线仅基于视觉相似性选择图像对，导致大量冗余匹配和计算开销。需要一种更智能的方法来优先选择对重建最有信息量的图像对。
- Method: SARA采用几何优先的图像对选择策略，通过轻量级预匹配阶段估计重叠度和视差，计算重建信息量得分。构建信息加权生成树，并添加针对性的边用于闭环、长基线锚点和弱视图增强。
- Result: 相比穷举匹配，SARA将旋转误差降低46.5±5.5%，平移误差降低12.5±6.5%，实现最多50倍加速（匹配对从30,848减少到580对，减少98%）。重建指标保持在基线±3%范围内。
- Conclusion: SARA通过几何驱动的图像对选择，将SfM的匹配复杂度从二次降低到准线性，在保持重建质量的同时显著提升效率，为大规模场景重建提供了实用解决方案。


### [57] [Enhancing Low-resolution Image Representation Through Normalizing Flows](https://arxiv.org/abs/2601.06834)
*Chenglong Bao,Tongyao Pang,Zuowei Shen,Dihan Zheng,Yihang Zou*

Main category: cs.CV

TL;DR: LR2Flow：一种在紧框架小波域中结合可逆神经网络学习低分辨率图像表示的非线性框架，在图像缩放、压缩和去噪等任务中表现优异。

- Motivation: 低分辨率图像表示能降低存储和传输成本，但关键挑战在于如何在保留重要视觉内容的同时准确重建原始图像。现有方法需要更有效的表示学习框架。
- Method: 提出LR2Flow非线性框架，将紧框架小波块与归一化流相结合，在紧框架小波域中设计可逆神经网络来学习低分辨率图像表示。
- Result: 通过重建误差分析证明了在紧框架小波域设计可逆神经网络的必要性。在图像缩放、压缩和去噪等任务上的实验结果表明，学习到的表示有效且框架鲁棒。
- Conclusion: LR2Flow成功解决了低分辨率图像表示中的关键挑战，为图像处理任务提供了有效的表示学习框架，在多个应用场景中展现出优越性能。


### [58] [OSCAR: Optical-aware Semantic Control for Aleatoric Refinement in Sar-to-Optical Translation](https://arxiv.org/abs/2601.06835)
*Hyunseo Lee,Sang Min Kim,Ho Kyung Shin,Taeheon Kim,Woo-Jeoung Nam*

Main category: cs.CV

TL;DR: 提出了一种新颖的SAR到光学图像转换框架，通过跨模态语义对齐、语义引导生成指导和不确定性感知目标来解决SAR图像中的斑点噪声和几何失真问题，实现了卓越的感知质量和语义一致性。

- Motivation: 合成孔径雷达（SAR）具有全天候成像能力，但将SAR观测转换为逼真的光学图像是一个病态问题。现有方法受限于SAR数据固有的斑点噪声和几何失真，导致语义误解、纹理合成模糊和结构幻觉。
- Method: 提出三核心技术创新：1）跨模态语义对齐：通过从光学教师模型向SAR学生模型蒸馏鲁棒语义先验，建立光学感知SAR编码器；2）语义引导生成指导：通过语义基础ControlNet集成类感知文本提示（全局上下文）和分层视觉提示（局部空间指导）；3）不确定性感知目标：显式建模偶然不确定性以动态调整重建焦点，有效减轻斑点噪声引起的伪影。
- Result: 大量实验表明，该方法在感知质量和语义一致性方面优于现有最先进方法。
- Conclusion: 该框架通过解决SAR图像转换中的核心挑战（斑点噪声、几何失真、语义模糊），实现了高质量的SAR到光学图像转换，为跨模态遥感图像分析提供了有效解决方案。


### [59] [PRISM: Color-Stratified Point Cloud Sampling](https://arxiv.org/abs/2601.06839)
*Hansol Lim,Minhyeok Im,Jongseong Brad Choi*

Main category: cs.CV

TL;DR: PRISM是一种基于颜色引导的分层采样方法，用于RGB-LiDAR点云，通过按颜色变化分配采样密度来保留纹理丰富区域，减少视觉同质区域。

- Motivation: 传统点云下采样方法（随机采样、体素网格、法向空间采样）强制空间均匀性，但忽略了场景的彩色内容。观察到独特场景特征通常表现出色彩多样性，而重复冗余特征在颜色上是同质的。
- Method: 将RGB颜色空间作为分层域，对每个颜色箱施加最大容量k，采样密度与色彩多样性成正比。通过颜色引导的分层采样，保留高颜色变化的纹理丰富区域，大幅减少视觉同质表面。
- Result: 该方法将采样空间从空间覆盖转向视觉复杂性，产生更稀疏的点云，同时保留3D重建任务所需的基本特征。
- Conclusion: PRISM通过颜色引导的分层采样，有效平衡了点云稀疏性和特征保留，特别适用于需要保留纹理丰富区域的3D重建应用。


### [60] [Speak While Watching: Unleashing TRUE Real-Time Video Understanding Capability of Multimodal Large Language Models](https://arxiv.org/abs/2601.06843)
*Junyan Lin,Junlong Tong,Hao Wu,Jialiang Zhang,Jinming Liu,Xin Jin,Xiaoyu Shen*

Main category: cs.CV

TL;DR: 提出并行流式框架，通过三种设计（重叠、组解耦、间隙隔离）放松位置连续性约束，实现同时感知与生成，显著降低实时视频理解延迟。

- Motivation: 现有MLLM大多限于离线推理，需要完整输入才能生成输出。虽然流式方法通过交错感知和生成降低了延迟，但仍强制顺序的感知-生成循环，限制了实时交互。主要瓶颈是标准位置编码方案施加的全局位置连续性约束，这紧密耦合了感知和生成，阻碍了有效的输入输出并行化。
- Method: 提出并行流式框架，通过三种设计放松位置连续性约束：1) 重叠设计：允许感知和生成部分重叠；2) 组解耦设计：将输入分组并解耦处理；3) 间隙隔离设计：在感知和生成之间引入间隙隔离。这些设计使模型能够同时处理输入和实时生成响应。
- Result: 实验表明组解耦设计在效率和性能之间达到最佳平衡，保持高流畅性和准确性的同时显著降低延迟。在平衡的感知-生成工作负载下，该框架可实现高达2倍的加速。
- Conclusion: 提出的并行流式框架通过放松位置连续性约束，实现了同时感知和生成，为"边看边说"的实时系统建立了原则性路径，显著提升了MLLM在实时视频理解中的性能。


### [61] [MedGround: Bridging the Evidence Gap in Medical Vision-Language Models with Verified Grounding Data](https://arxiv.org/abs/2601.06847)
*Mengmeng Zhang,Xiaoping Wu,Hao Luo,Fan Wang,Yisheng Lv*

Main category: cs.CV

TL;DR: MedGround是一个自动化流程，将分割资源转化为高质量医学指代定位数据，创建了MedGround-35K数据集，显著提升视觉语言模型在医学领域的指代定位能力。

- Motivation: 当前视觉语言模型在生成临床叙述时经常难以将其陈述与视觉证据有效关联，这主要是由于缺乏高质量、大规模的临床指代定位数据对。
- Method: 提出MedGround自动化流程：利用专家分割掩码作为空间锚点，精确推导定位目标，提取形状和空间线索，指导VLMs合成自然的、临床基础的查询。采用多阶段验证系统，包括格式检查、几何和医学先验规则、基于图像的视觉判断，过滤模糊或视觉不支持样本。
- Result: 创建了MedGround-35K新型多模态医学数据集。实验表明，使用该数据集训练的VLMs在指代定位性能上持续提升，增强了多对象语义消歧能力，并在未见过的定位场景中表现出强大的泛化能力。
- Conclusion: MedGround提供了一个可扩展的数据驱动方法，将医学语言锚定到可验证的视觉证据上，为医学视觉语言模型的指代定位能力提供了有效解决方案。


### [62] [MVGGT: Multimodal Visual Geometry Grounded Transformer for Multiview 3D Referring Expression Segmentation](https://arxiv.org/abs/2601.06874)
*Changli Wu,Haodong Wang,Jiayi Ji,Yutian Yao,Chunsai Du,Jihua Kang,Yanwei Fu,Liujuan Cao*

Main category: cs.CV

TL;DR: MV-3DRES：从稀疏多视角图像直接进行3D指代表达分割，提出MVGGT端到端框架解决传统两阶段方法的质量和速度问题，引入PVSO优化策略解决前景梯度稀释问题，并建立MVRefer基准。

- Motivation: 现有3D指代表达分割方法依赖高质量稠密点云，而实际应用（如机器人、手机）只有稀疏RGB视图和严格延迟要求。传统两阶段方法（先重建点云再分割）存在几何质量低、目标区域粗糙、运行慢的问题。
- Method: 提出MVGGT（多模态视觉几何基础Transformer）端到端框架，通过双分支设计将语言信息集成到稀疏视角几何推理中。为解决训练中的前景梯度稀释问题，引入PVSO（每视角无目标抑制优化）提供更强更平衡的梯度。
- Result: MVGGT建立了首个强基线，在MVRefer基准上实现高精度和快速推理，优于现有替代方法。代码和模型已公开。
- Conclusion: MV-3DRES解决了从稀疏多视角图像直接进行3D指代表达分割的实际需求，MVGGT框架通过端到端设计和PVSO优化策略，在精度和效率上均取得显著提升，为实际应用提供了可行方案。


### [63] [Unsupervised Domain Adaptation with SAM-RefiSeR for Enhanced Brain Tumor Segmentation](https://arxiv.org/abs/2601.06882)
*Dillan Imans,Phuoc-Nguyen Bui,Duc-Tai Le,Hyunseung Choo*

Main category: cs.CV

TL;DR: 提出SAM-RefiSeR方法，通过无监督域适应增强脑肿瘤分割性能

- Motivation: 脑肿瘤分割在不同医疗中心数据分布差异大，需要适应新领域数据而无需额外标注
- Method: 结合SAM（Segment Anything Model）和RefiSeR（Refinement and Selection with Regularization）框架，通过伪标签生成和正则化实现无监督域适应
- Result: 在多个脑肿瘤数据集上验证，相比基线方法显著提升分割精度，特别是在目标域数据上
- Conclusion: SAM-RefiSeR有效解决了跨域脑肿瘤分割问题，为临床应用中适应不同医疗中心数据提供了实用解决方案


### [64] [MixRI: Mixing Features of Reference Images for Novel Object Pose Estimation](https://arxiv.org/abs/2601.06883)
*Xinhang Liu,Jiawei Shi,Zheng Dang,Yuchao Dai*

Main category: cs.CV

TL;DR: MixRI是一个轻量级网络，用于解决RGB图像中基于CAD模型的新物体姿态估计问题，无需微调即可直接应用于新物体，强调低内存需求和快速推理。

- Motivation: 现有方法通常需要大量参考图像和大规模网络参数，这在实际应用中导致高内存需求和慢推理速度。需要一种轻量级解决方案，能在减少参考图像数量的同时保持性能。
- Method: 设计轻量级网络，通过多视图信息直接在查询图像和参考图像之间匹配点。采用参考图像融合策略，显著减少所需参考图像数量，从而降低处理时间和存储需求。
- Result: 在BOP挑战赛的七个核心数据集上，MixRI使用更少的参考图像和更小的网络参数，取得了与其他需要更多参考图像和更大网络参数的方法相当的结果。
- Conclusion: MixRI证明了通过轻量级网络设计和参考图像融合策略，可以在保持姿态估计性能的同时，显著降低内存需求和推理时间，满足实际应用需求。


### [65] [CLIMP: Contrastive Language-Image Mamba Pretraining](https://arxiv.org/abs/2601.06891)
*Nimrod Shabtay,Itamar Zimerman,Eli Schwartz,Raja Giryes*

Main category: cs.CV

TL;DR: CLIMP：首个完全基于Mamba的对比视觉语言模型，用Mamba替换了视觉和文本编码器，在跨模态检索、OOD鲁棒性和可变分辨率支持方面优于CLIP-ViT-B

- Motivation: CLIP依赖的Vision Transformer存在两个主要问题：注意力机制容易受到虚假相关性的影响，以及计算复杂度随分辨率呈二次方增长。需要一种更高效、更鲁棒的架构来替代Transformer。
- Method: 提出CLIMP模型，用Mamba架构完全替换CLIP中的视觉和文本编码器。视觉部分使用VMamba捕捉视觉空间归纳偏置，文本部分使用自回归Mamba编码器。该架构天然支持可变输入分辨率，无需位置编码插值或专门训练。
- Result: 在ImageNet-O上超越OpenAI CLIP-ViT-B 7.5%；在16倍训练分辨率下检索准确率提升6.6%，同时内存使用减少5倍，FLOPs减少1.8倍；支持密集字幕检索，克服了CLIP的固定上下文限制。
- Conclusion: Mamba在视觉语言学习方面展现出优势特性，是Transformer-based CLIP的有力替代方案，特别是在处理虚假相关性、计算效率和可变分辨率支持方面表现优异。


### [66] [UDPNet: Unleashing Depth-based Priors for Robust Image Dehazing](https://arxiv.org/abs/2601.06909)
*Zengyuan Zuo,Junjun Jiang,Gang Wu,Xianming Liu*

Main category: cs.CV

TL;DR: UDPNet利用DepthAnything V2的深度先验增强现有去雾模型，通过深度引导注意力和深度先验融合模块，在多个数据集上实现SOTA性能。

- Motivation: 现有去雾方法大多只关注RGB特征，忽略了场景深度与雾霾分布的相关性。即使联合优化深度估计和去雾的方法，也因深度信息利用不足而性能欠佳。
- Method: 提出UDPNet框架，利用DepthAnything V2的深度先验增强现有去雾模型。包含深度引导注意力模块（DGAM）通过轻量级深度引导通道注意力自适应调制特征，以及深度先验融合模块（DPFM）通过双滑动窗口多头交叉注意力机制实现多尺度深度图特征分层融合。
- Result: 在多个去雾数据集上超越SOTA方法：SOTS数据集PSNR提升0.85dB，Haze4K数据集提升1.19dB，NHR数据集提升1.79dB。深度先验的鲁棒性使网络能动态适应不同雾霾密度、光照条件和域差异。
- Conclusion: UDPNet为深度感知去雾建立了新基准，证明了利用大规模预训练深度估计模型的深度先验能显著提升去雾性能，代码和预训练模型已开源。


### [67] [RenderFlow: Single-Step Neural Rendering via Flow Matching](https://arxiv.org/abs/2601.06928)
*Shenghao Zhang,Runtao Liu,Christopher Schroers,Yang Zhang*

Main category: cs.CV

TL;DR: RenderFlow：基于流匹配的单步确定性神经渲染框架，通过稀疏关键帧引导实现近实时物理准确渲染，并支持逆渲染任务

- Motivation: 传统物理渲染计算成本高，而现有基于扩散模型的深度学习方法存在延迟高、随机性强、物理准确性差和时间一致性不足的问题
- Method: 提出基于流匹配的端到端确定性单步神经渲染框架RenderFlow，结合稀疏关键帧引导模块增强渲染质量和泛化能力
- Result: 实现近实时性能的逼真渲染，在渲染质量和物理准确性方面显著提升，并可通过轻量适配器模块扩展到逆渲染任务
- Conclusion: RenderFlow成功弥合了现代生成模型效率与传统物理渲染精度之间的差距，为实时高质量渲染提供了有效解决方案


### [68] [Measuring Social Bias in Vision-Language Models with Face-Only Counterfactuals from Real Photos](https://arxiv.org/abs/2601.06931)
*Haodong Chen,Qiang Huang,Jiaqi Zhao,Qiuping Jiang,Xiaojun Chang,Jun Yu*

Main category: cs.CV

TL;DR: 提出了一种基于面部反事实评估的视觉语言模型社会偏见测量方法，通过仅编辑面部属性来隔离人口统计效应，构建了FOCUS数据集和REFLECT基准测试。

- Motivation: 视觉语言模型在重要社会场景中部署时存在社会偏见问题，但现有评估方法难以区分人口统计特征与其他视觉混杂因素（如背景、服装）的影响，导致归因困难。
- Method: 提出"仅面部反事实评估范式"：从真实照片出发，仅编辑与种族和性别相关的面部属性，保持其他视觉因素不变。基于此构建FOCUS数据集（480张场景匹配的反事实图像）和REFLECT基准测试（包含三种决策导向任务）。
- Result: 对五个最先进视觉语言模型的实验表明，在严格视觉控制下，人口统计差异仍然存在，并且在不同任务形式中差异显著。
- Conclusion: 需要采用受控的反事实审计来准确评估多模态模型的社会偏见，任务设计是评估过程中的关键因素。


### [69] [Watching, Reasoning, and Searching: A Video Deep Research Benchmark on Open Web for Agentic Video Reasoning](https://arxiv.org/abs/2601.06943)
*Chengwen Liu,Xiaomin Yu,Zhuoyue Chang,Zhe Huang,Shuo Zhang,Heng Lian,Kunyi Wang,Rui Xu,Sen Hu,Jianheng Hou,Hao Peng,Chengwei Qin,Xiaobin Hu,Hong Peng,Ronghao Chen,Huacan Wang*

Main category: cs.CV

TL;DR: VideoDR是首个视频深度研究基准，专注于视频条件开放域问答，需要跨帧视觉锚点提取、交互式网络检索和多跳推理验证。研究发现Agentic范式并不总是优于Workflow范式，其优势取决于模型在长检索链中保持初始视频锚点的能力。

- Motivation: 现实世界视频问答场景中，视频通常只提供局部视觉线索，而可验证答案分布在开放网络上。现有模型需要同时执行跨帧线索提取、迭代检索和多跳推理验证，但缺乏系统基准来评估这些能力。
- Method: 构建VideoDR基准，包含视频条件开放域问答任务，要求跨帧视觉锚点提取、交互式网络检索和多跳推理。通过严格人工标注和质量控制，获得涵盖六个语义领域的高质量样本。评估了闭源和开源多模态大语言模型在Workflow和Agentic两种范式下的表现。
- Result: 评估结果显示Agentic范式并不总是优于Workflow范式，其优势取决于模型在长检索链中保持初始视频锚点的能力。目标漂移和长时一致性是核心瓶颈。
- Conclusion: VideoDR为研究开放网络环境下的视频智能体提供了系统基准，揭示了下一代视频深度研究智能体的关键挑战，特别是目标漂移和长时一致性问题。


### [70] [SketchJudge: A Diagnostic Benchmark for Grading Hand-drawn Diagrams with Multimodal Large Language Models](https://arxiv.org/abs/2601.06944)
*Yuhang Su,Mei Wang,Yaoyao Zhong,Guozhang Li,Shixing Li,Yihan Feng,Hua Huang*

Main category: cs.CV

TL;DR: SketchJudge是一个评估多模态大语言模型在手绘STEM图表评分任务中表现的新基准，包含1,015个手绘学生回答，涵盖几何、物理、图表和流程图四个领域，揭示了当前MLLMs在符号和噪声环境下的视觉语言对齐脆弱性。

- Motivation: 多模态大语言模型在视觉理解方面取得了显著进展，但在处理人类手绘草图的无结构和模糊性时表现不佳，特别是在视觉评分任务中。模型不仅需要解决问题，还需要诊断手绘图表中的错误，这需要复杂的结构、语义和元认知推理能力。
- Method: 研究者引入了SketchJudge基准，包含1,015个手绘学生回答，涵盖四个STEM领域：几何、物理、图表和流程图。这些数据具有多样化的风格变化和不同的错误类型，专门用于评估MLLMs作为手绘图表评分者的能力。
- Result: 评估结果显示，即使是先进的多模态大语言模型也显著落后于人类表现，验证了该基准在暴露当前视觉语言对齐在符号和噪声环境下的脆弱性方面的有效性。
- Conclusion: SketchJudge基准成功揭示了当前MLLMs在处理手绘STEM图表评分任务时的局限性，为未来研究提供了重要的评估工具，所有数据、代码和评估脚本都已公开。


### [71] [Unified Personalized Understanding, Generating and Editing](https://arxiv.org/abs/2601.06965)
*Yu Zhong,Tianwei Lin,Ruike Zhu,Yuqian Yuan,Haoyu Zheng,Liang Liang,Wenqiao Zhang,Feifei Shao,Haoyuan Li,Wanggui He,Hao Jiang,Yueting Zhuang*

Main category: cs.CV

TL;DR: OmniPersona：首个端到端统一多模态模型个性化框架，集成个性化理解、生成和编辑于单一架构，通过结构解耦概念令牌和显式知识回放实现一致个性化行为。

- Motivation: 现有统一多模态模型采用"一刀切"范式，难以建模用户特定概念（如<maeve>），现有个性化方法依赖外部检索效率低，或使用可学习软提示导致跨任务干扰和知识错位。
- Method: 提出结构解耦的概念令牌，为不同任务分配专用子空间以减少干扰；引入显式知识回放机制，在任务间传播个性化属性知识；建立OmniPBench评估基准，扩展UnifyBench概念集并集成理解、生成和编辑的跨任务评估协议。
- Result: 实验结果表明OmniPersona在多样化个性化任务中提供竞争性和鲁棒的性能，成为统一个性化研究的强基线。
- Conclusion: OmniPersona首次在统一多模态模型中集成个性化理解、生成和编辑，通过结构解耦和知识回放实现一致可控的个性化，为可控统一个性化研究提供新方向。


### [72] [Can Textual Reasoning Improve the Performance of MLLMs on Fine-grained Visual Classification?](https://arxiv.org/abs/2601.06993)
*Jie Zhu,Yiyang Su,Xiaoming Liu*

Main category: cs.CV

TL;DR: 研究发现CoT推理在细粒度视觉分类任务中会降低性能，这种"思考成本"现象主要由推理长度导致，提出了ReFine-RFT框架来约束推理长度并提升性能。

- Motivation: 多模态大语言模型在细粒度视觉分类任务上表现不佳，而CoT推理虽然能提升数学和编程任务性能，但在视觉感知任务中反而会损害性能，需要系统研究其原因。
- Method: 通过零样本评估和多种训练范式系统研究CoT在FGVC中的作用，发现推理长度是性能下降的关键因素，提出ReFine-RFT框架结合alg归一化方法平衡异质奖励信号。
- Result: 实验表明推理长度越长分类准确率越低，提出的ReFine-RFT框架在多个FGVC基准测试中达到最先进性能。
- Conclusion: 揭示了CoT在视觉任务中的"思考成本"现象，提出的ReFine-RFT框架能有效约束推理长度并提供密集的准确性反馈，显著提升FGVC性能。


### [73] [Spatial Multi-Task Learning for Breast Cancer Molecular Subtype Prediction from Single-Phase DCE-MRI](https://arxiv.org/abs/2601.07001)
*Sen Zeng,Hong Zhou,Zheng Zhu,Yang Liu*

Main category: cs.CV

TL;DR: 提出基于单相DCE-MRI的乳腺癌分子亚型预测空间多任务学习框架，通过多尺度空间注意力和ROI加权模块，同时预测ER、PR、HER2状态和Ki-67指数，在临床实用成像协议下实现准确非侵入性分类。

- Motivation: 传统免疫组化分析需要侵入性活检且存在采样偏差，而临床DCE-MRI通常只采集单相后对比图像以减少扫描时间和造影剂剂量，需要开发从临床实用单相DCE-MRI预测分子亚型的非侵入性方法。
- Method: 提出空间多任务学习框架，整合深度特征提取网络与多尺度空间注意力机制，捕捉肿瘤内和瘤周特征；包含ROI加权模块强调肿瘤核心、边缘和周围组织；通过共享表示和任务特定分支利用生物标志物间的相关性。
- Result: 在960例数据集上，ER、PR、HER2分类的AUC分别为0.893、0.824、0.857，Ki-67回归的MAE为8.2%，显著优于放射组学和单任务深度学习基线，证明使用标准成像协议进行准确非侵入性分子亚型预测的可行性。
- Conclusion: 该空间多任务学习框架能够从临床实用的单相DCE-MRI准确预测乳腺癌分子亚型，为个性化治疗提供非侵入性替代方案，有望改善临床工作流程并减少对侵入性活检的依赖。


### [74] [Adversarial Attacks on Medical Hyperspectral Imaging Exploiting Spectral-Spatial Dependencies and Multiscale Features](https://arxiv.org/abs/2601.07056)
*Yunrui Gu,Zhenzhe Gao,Cong Kong,Zhaoxia Yin*

Main category: cs.CV

TL;DR: 本文提出了一种针对医学高光谱成像的针对性对抗攻击框架，包含局部像素依赖攻击和多尺度信息攻击，揭示了医学HSI模型的独特脆弱性。

- Motivation: 医学高光谱成像（HSI）能够通过捕获丰富的光谱-空间组织信息实现准确疾病诊断，但深度学习的最新进展暴露了其对对抗攻击的脆弱性。本文旨在识别这种脆弱性的根本原因，并提出针对性攻击框架。
- Method: 提出了一个针对性对抗攻击框架，包含两个核心组件：1）局部像素依赖攻击：利用相邻像素间的空间相关性；2）多尺度信息攻击：扰动跨层次光谱-空间尺度的特征。
- Result: 在Brain和MDC数据集上的实验表明，所提出的攻击显著降低了分类性能（特别是在肿瘤区域），同时保持视觉不可感知性。与现有方法相比，该方法揭示了医学HSI模型的独特脆弱性。
- Conclusion: 本文揭示了医学高光谱成像模型的两个根本脆弱性来源，并提出了有效的针对性攻击框架。这强调了在临床应用中需要开发鲁棒的、结构感知的防御机制。


### [75] [Billboard in Focus: Estimating Driver Gaze Duration from a Single Image](https://arxiv.org/abs/2601.07073)
*Carlos Pizarroso,Zuzana Berger Haladová,Zuzana Černeková,Viktor Kocur*

Main category: cs.CV

TL;DR: 提出全自动广告牌检测与驾驶员注视时长估计流程，无需人工标注或眼动仪，准确率达68.1%

- Motivation: 路边广告牌是户外广告核心元素，但可能分散驾驶员注意力增加事故风险，需要评估其相关性但缺乏自动化方法
- Method: 两阶段流程：1) 基于YOLO的目标检测模型，在Mapillary Vistas训练并在BillboardLamac微调；2) 基于检测框位置和DINOv2特征的分类器
- Result: 广告牌检测任务达到94% mAP@50，在BillboardLamac数据集上单帧准确率68.1%，并在Google街景图像上验证
- Conclusion: 提出的全自动流程能有效估计驾驶员对广告牌的注视时长，为评估广告牌相关性提供实用工具


### [76] [Efficient Visual Question Answering Pipeline for Autonomous Driving via Scene Region Compression](https://arxiv.org/abs/2601.07092)
*Yuliang Cai,Dongqiangzi Ye,Zitian Chen,Chongruo Wu*

Main category: cs.CV

TL;DR: 提出SRC-Pipeline框架，通过压缩早期帧token并保留近期帧完整token，在自动驾驶VQA任务中减少66%计算量同时保持性能

- Motivation: 自动驾驶中的视觉问答需要低延迟实时处理，但当前VLM模型计算成本高，处理密集patch token导致延迟，限制了在安全关键场景的实际部署
- Method: 提出SRC-Pipeline框架，学习将早期帧token压缩为少量高级token，同时保留近期帧的完整patch token，实现计算效率提升
- Result: 在自动驾驶视频问答任务中，实现了66%的FLOPs减少，同时保持可比性能，使VLM能在实时安全关键场景更有效运行
- Conclusion: SRC-Pipeline通过智能token压缩策略，在保持性能的同时显著降低计算成本，为自动驾驶VQA的实际部署提供了可行的解决方案


### [77] [3D Wavelet-Based Structural Priors for Controlled Diffusion in Whole-Body Low-Dose PET Denoising](https://arxiv.org/abs/2601.07093)
*Peiyuan Jing,Yue Tang,Chun-Wun Cheng,Zhenxuan Zhang,Liutao Yang,Thiago V. Lima,Klaus Strobel,Antoine Leimgruber,Angelica Aviles-Rivero,Guang Yang,Javier Montoya*

Main category: cs.CV

TL;DR: 提出WCC-Net，一种基于3D扩散模型的PET图像去噪方法，通过小波表示引入频域结构先验，在保持生成表达能力的同时改善解剖结构一致性。

- Motivation: 低剂量PET成像减少患者辐射暴露但噪声增加，影响图像质量和诊断可靠性。现有扩散模型具有随机性，难以在低信噪比和全身体积成像中保持解剖结构一致性。
- Method: 提出Wavelet-Conditioned ControlNet (WCC-Net)，完全3D扩散框架，通过小波表示引入频域结构先验。使用轻量控制分支将小波结构指导注入冻结的预训练扩散主干，解耦解剖结构和噪声，保持生成表达能力和3D结构连续性。
- Result: 在内部1/20剂量测试集上，WCC-Net比强扩散基线PSNR提高+1.21 dB，SSIM提高+0.008，同时减少结构失真(GMSD)和强度误差(NMAE)。在未见剂量水平(1/50和1/4)上表现出强大泛化能力，实现优越定量性能和改善的体积解剖一致性。
- Conclusion: WCC-Net通过小波条件控制有效解决了扩散模型在低剂量PET去噪中的结构一致性问题，在保持生成质量的同时显著改善解剖结构保真度，展现出强大的泛化能力。


### [78] [MEDVISTAGYM: A Scalable Training Environment for Thinking with Medical Images via Tool-Integrated Reinforcement Learning](https://arxiv.org/abs/2601.07107)
*Meng Lu,Yuxing Lu,Yuchen Zhuang,Megan Mullins,Yang Xie,Guanghua Xiao,Charles Fleming,Wenqi Shi,Xuan Wang*

Main category: cs.CV

TL;DR: MedVistaGym是一个用于医疗视觉语言模型（VLMs）的交互式训练环境，通过强化学习训练模型进行工具集成的视觉推理，在医疗图像分析中显著提升性能。

- Motivation: 当前医疗VLMs在医疗图像理解方面存在局限，特别是多步推理和迭代视觉交互能力不足。模型通常依赖静态视觉嵌入和单次推理，无法重新检查、验证或细化视觉证据。虽然工具集成推理是很有前景的方向，但开源VLMs缺乏训练基础设施来学习有效的工具选择、调用和协调。
- Method: 提出MedVistaGym训练环境，为VLMs提供统一的、可执行的接口进行智能体训练。模型学习决定何时调用哪些工具、定位任务相关的图像区域、整合单个或多个子图像证据到交错的多模态推理中。通过轨迹采样和端到端强化学习训练MedVistaGym-R1模型。
- Result: 在六个医疗VQA基准测试中，MedVistaGym-R1-8B模型超过了同等规模工具增强基线的19.10%到24.21%，表明结构化的智能体训练（而不仅仅是工具访问）能够有效解锁医疗图像分析中的工具集成推理能力。
- Conclusion: MedVistaGym通过提供交互式训练环境，使医疗VLMs能够学习有效的工具集成推理策略，显著提升了医疗图像分析的性能，证明了结构化智能体训练对于解锁工具集成推理能力的重要性。


### [79] [Few-shot Class-Incremental Learning via Generative Co-Memory Regularization](https://arxiv.org/abs/2601.07117)
*Kexin Bao,Yong Li,Dan Zeng,Shiming Ge*

Main category: cs.CV

TL;DR: 提出一种生成式协同记忆正则化方法用于少样本类增量学习，通过生成域适应微调、构建表示记忆和权重记忆，以及协同记忆正则化来提升模型性能

- Motivation: 少样本类增量学习需要模型具备强大的表示和适应能力，以避免对旧类的灾难性遗忘和对新类的过拟合。现有方法在这两方面存在挑战，需要一种更有效的解决方案。
- Method: 1. 基础学习阶段：使用生成域适应微调预训练的生成编码器，结合掩码自编码器解码器进行特征重建和全连接分类器进行特征分类
2. 构建两类记忆：表示记忆（存储各类平均特征）和权重记忆（存储分类器权重）
3. 增量学习阶段：通过同时优化特征分类和协同记忆正则化，在少样本类上动态训练分类器
4. 以类增量方式更新记忆，协同正则化增量学习
- Result: 在流行基准测试上的广泛实验表明，该方法明显优于现有最先进方法，提高了识别准确率，同时缓解了对旧类的灾难性遗忘和对新类的过拟合。
- Conclusion: 提出的生成式协同记忆正则化方法有效解决了少样本类增量学习中的关键挑战，通过记忆机制协同正则化学习过程，实现了更好的性能平衡。


### [80] [Motion Focus Recognition in Fast-Moving Egocentric Video](https://arxiv.org/abs/2601.07154)
*Daniel Hong,James Tribble,Hao Wang,Chaoyi Zhou,Ashish Bastola,Siyu Huang,Abolfazl Razi*

Main category: cs.CV

TL;DR: 提出一种实时运动焦点识别方法，可从任意第一人称视频估计主体的运动意图，特别针对体育和快速运动场景

- Motivation: 现有第一人称数据集主要关注动作识别任务，而忽视了体育和快速运动场景中运动分析的内在作用，需要填补这一空白
- Method: 利用基础模型进行相机姿态估计，引入系统级优化以实现高效可扩展推理，采用滑动批量推理策略
- Result: 在收集的第一人称动作数据集上评估，方法实现了实时性能，内存消耗可控
- Conclusion: 使以运动为中心的分析在实际边缘部署中变得可行，为现有体育和快速运动活动的第一人称研究提供了补充视角


### [81] [Test-time Adaptive Hierarchical Co-enhanced Denoising Network for Reliable Multimodal Classification](https://arxiv.org/abs/2601.07163)
*Shu Shen,C. L. Philip Chen,Tong Zhang*

Main category: cs.CV

TL;DR: TAHCD是一种测试时自适应层次协同增强去噪网络，用于处理低质量多模态数据中的异构噪声，通过全局和实例级噪声去除以及测试时协同增强，提高分类性能、鲁棒性和泛化能力。

- Motivation: 安全关键应用中低质量多模态数据的可靠学习是一个重要问题。现有方法面临两个主要限制：1) 难以可靠去除异构数据噪声，阻碍鲁棒的多模态表示学习；2) 遇到未见噪声时适应性和泛化能力有限。
- Method: 提出测试时自适应层次协同增强去噪网络(TAHCD)。包含：1) 自适应稳定子空间对齐和样本自适应置信对齐，在全局和实例层面去除异构噪声；2) 测试时协同增强，以无标签方式根据输入噪声自适应更新模型，通过全局和实例层面协同增强模态特定和跨模态噪声的联合去除过程。
- Result: 在多个基准测试上的实验表明，该方法相比最先进的可靠多模态学习方法，实现了更优的分类性能、鲁棒性和泛化能力。
- Conclusion: TAHCD通过层次化噪声去除和测试时自适应增强，有效解决了多模态噪声问题，为低质量多模态数据的可靠学习提供了有效解决方案。


### [82] [DIVER: Dynamic Iterative Visual Evidence Reasoning for Multimodal Fake News Detection](https://arxiv.org/abs/2601.07178)
*Weilin Zhou,Zonghao Ying,Chunlei Meng,Jiahui Liu,Hengyang Zhou,Quanchen Zou,Deyue Zhang,Dongdong Yang,Xiangzheng Zhang*

Main category: cs.CV

TL;DR: DIVER是一个动态迭代视觉证据推理框架，用于多模态假新闻检测。它通过渐进式证据驱动推理，首先建立文本基线，仅在文本证据不足时引入视觉信息，并选择性调用细粒度视觉工具，通过不确定性感知融合优化推理效率和准确性。

- Motivation: 现有多模态假新闻检测方法存在两个主要问题：1）依赖静态融合或大型语言模型，导致计算冗余；2）视觉基础薄弱，存在幻觉风险。需要一种更高效、可靠的框架来应对对抗性虚假信息。
- Method: DIVER采用渐进式证据驱动推理范式：1）首先通过语言分析建立强文本基线，利用模态内一致性过滤不可靠或幻觉声明；2）仅在文本证据不足时引入视觉信息，通过模态间对齐验证自适应决定是否需要深度视觉检查；3）对于跨模态语义差异显著的样本，选择性调用OCR和密集字幕等细粒度视觉工具提取任务相关证据；4）通过不确定性感知融合迭代聚合证据，优化多模态推理。
- Result: 在Weibo、Weibo21和GossipCop数据集上的实验表明，DIVER平均优于最先进基线方法2.72%，同时将推理延迟减少4.12秒，优化了推理效率。
- Conclusion: DIVER通过动态迭代视觉证据推理，有效解决了现有多模态假新闻检测方法的计算冗余和幻觉风险问题，在保持高准确性的同时显著提升了推理效率，为对抗性虚假信息检测提供了更可靠的解决方案。


### [83] [ShowUI-Aloha: Human-Taught GUI Agent](https://arxiv.org/abs/2601.07181)
*Yichun Zhang,Xiangwu Guo,Yauhong Goh,Jessica Hu,Zhiheng Chen,Xin Wang,Difei Gao,Mike Zheng Shou*

Main category: cs.CV

TL;DR: ShowUI-Aloha是一个将人类桌面录屏转换为结构化可执行任务的完整框架，包含录制、学习、规划和执行四个组件，旨在解决GUI自动化训练数据稀缺问题。

- Motivation: GUI自动化面临的主要挑战是缺乏可扩展的高质量训练数据。人类演示录屏虽然丰富，但通常冗长、非结构化且缺乏标注，难以供智能体学习。
- Method: 提出包含四个关键组件的完整流水线：1) 录制器捕获屏幕视频和精确交互；2) 学习器语义解析原始交互和视觉上下文，生成自然语言描述；3) 规划器读取解析后的演示，维护任务状态，基于上下文推理动态制定高层动作计划；4) 执行器在操作系统层面忠实执行动作计划，包含安全检查与实时反馈。
- Result: 该框架为收集和解析真实世界人类数据提供了可扩展的解决方案，展示了通过观察人类行为构建通用GUI智能体的可行路径。
- Conclusion: ShowUI-Aloha能够将非结构化的人类桌面录屏转换为结构化、可执行的任务，为解决GUI自动化训练数据问题提供了有效方法，推动了通用GUI智能体的发展。


### [84] [SIRR-LMM: Single-image Reflection Removal via Large Multimodal Model](https://arxiv.org/abs/2601.07209)
*Yu Guo,Zhiqiang Lao,Xiyun Song,Yubin Zhou,Heather Yu*

Main category: cs.CV

TL;DR: 提出基于物理渲染的合成数据集生成框架和基于大型多模态模型的反射去除方法，在单图像反射去除任务上取得优于现有方法的性能。

- Motivation: 玻璃表面会产生复杂的反射和透射光相互作用，使得单图像反射去除（SIRR）具有挑战性。现有数据集要么合成数据的物理真实性有限，要么真实捕获的数据规模不足。
- Method: 1）提出合成数据集生成框架：通过路径追踪3D玻璃模型在真实背景图像上，创建具有不同玻璃属性、相机设置和后处理效果的物理准确反射场景；2）利用大型多模态模型（LMM）：将图像层拼接为单个复合输入，应用联合标注，使用任务特定的LoRA进行微调而非全参数训练。
- Result: 相比最先进的方法，该方法在反射去除和分离性能上取得了改进。
- Conclusion: 通过物理准确的合成数据集生成和基于大型多模态模型的有效微调策略，能够更好地解决单图像反射去除问题。


### [85] [SceneNAT: Masked Generative Modeling for Language-Guided Indoor Scene Synthesis](https://arxiv.org/abs/2601.07218)
*Jeongjun Choi,Yeonsoo Park,H. Jin Kim*

Main category: cs.CV

TL;DR: SceneNAT：单阶段掩码非自回归Transformer，通过少量并行解码从自然语言指令生成完整3D室内场景，相比现有方法在性能和效率上均有提升。

- Motivation: 现有3D场景生成方法通常采用自回归或扩散模型，计算成本高且效率低。需要一种能同时保证语义合规性和空间布局准确性，同时降低计算成本的高效方法。
- Method: 1. 单阶段掩码非自回归Transformer架构；2. 对语义和空间属性的完全离散化表示进行掩码建模；3. 在属性和实例级别应用掩码策略以捕获对象内外结构；4. 使用专门的三元组预测器进行关系推理，将可学习关系查询映射到稀疏的符号三元组（主语、谓语、宾语）。
- Result: 在3D-FRONT数据集上的实验表明，SceneNAT在语义合规性和空间布局准确性方面优于最先进的自回归和扩散基线方法，同时计算成本显著降低。
- Conclusion: SceneNAT通过掩码非自回归Transformer和关系推理机制，实现了高效且高质量的3D室内场景生成，为自然语言驱动的3D场景合成提供了新的解决方案。


### [86] [VENUS: Visual Editing with Noise Inversion Using Scene Graphs](https://arxiv.org/abs/2601.07219)
*Thanh-Nhan Vo,Trong-Thuan Nguyen,Tam V. Nguyen,Minh-Triet Tran*

Main category: cs.CV

TL;DR: VENUS是一个无需训练的框架，通过场景图引导进行图像编辑，在保持背景的同时实现语义一致性，大幅提升编辑质量和效率。

- Motivation: 现有文本图像编辑模型难以平衡背景保持和语义一致性，而场景图编辑方法虽然提供更好可控性，但依赖模型微调导致计算成本高、可扩展性差。
- Method: VENUS采用分割提示条件策略，将编辑目标对象与背景上下文分离，同时利用噪声反演保持未编辑区域的保真度，并整合多模态大语言模型提取的场景图与扩散模型，无需额外训练。
- Result: 在PIE-Bench上，PSNR从22.45提升至24.80，SSIM从0.79提升至0.84，LPIPS从0.100降低至0.070；CLIP相似度从24.19提升至24.97；EditVal上DINO得分0.87；运行时间从6-10分钟缩短至20-30秒。
- Conclusion: VENUS在无需训练的情况下，显著提升了场景图引导图像编辑的质量和效率，同时在背景保持和语义一致性方面优于现有文本编辑方法，为可控图像编辑提供了高效解决方案。


### [87] [Language-Grounded Multi-Domain Image Translation via Semantic Difference Guidance](https://arxiv.org/abs/2601.07221)
*Jongwon Ryu,Joonhyung Park,Jaeho Han,Yeong-Seok Kim,Hye-rin Kim,Sunjae Yoon,Junyeong Kim*

Main category: cs.CV

TL;DR: LACE是一个基于语言的多属性可控图像翻译框架，通过GLIP-Adapter融合全局语义与局部结构特征，结合多域控制引导机制，实现细粒度的多域图像翻译控制。

- Motivation: 现有方法在多域图像翻译中难以保持结构完整性并提供细粒度的属性控制，特别是在涉及多个领域时。需要一种能够将自然语言提示中的语义差异精确地映射到视觉变换的方法。
- Method: 提出LACE框架，包含两个核心组件：1) GLIP-Adapter融合全局语义与局部结构特征以保持一致性；2) 多域控制引导机制将源提示与目标提示之间的语义差异显式地映射到每个属性的翻译向量中。
- Result: 在CelebA(Dialog)和BDD100K数据集上的实验表明，LACE在视觉保真度、结构保持和可解释的域特定控制方面优于现有基线方法。
- Conclusion: LACE作为一个跨模态内容生成框架，成功地将语言语义与可控视觉翻译连接起来，实现了组合式的多域控制，每个属性都可以独立调节强度。


### [88] [Universal Adversarial Purification with DDIM Metric Loss for Stable Diffusion](https://arxiv.org/abs/2601.07253)
*Li Zheng,Liangbin Xie,Jiantao Zhou,He YiMin*

Main category: cs.CV

TL;DR: 提出UDAP框架，专门针对Stable Diffusion模型的对抗攻击进行净化，利用DDIM逆过程中干净与对抗图像的不同重建行为来优化净化过程，并引入动态epoch调整策略提高效率。

- Motivation: 现有对抗净化方法主要针对分类任务设计，无法有效应对针对Stable Diffusion特定组件的对抗攻击（如VAE编码器、UNet去噪器或两者的混合攻击），存在SD安全防护的空白。
- Method: 提出Universal Diffusion Adversarial Purification (UDAP)框架，利用干净图像和对抗图像在DDIM逆过程中的不同重建行为，通过最小化DDIM度量损失来去除对抗噪声，并引入动态epoch调整策略根据重建误差自适应优化迭代次数。
- Result: 实验表明UDAP对多种对抗攻击方法（包括PID、Anti-DreamBooth、MIST等）具有鲁棒性，能有效防御VAE-targeted、UNet-targeted和混合攻击，且在不同SD版本和文本提示下具有良好的泛化能力。
- Conclusion: UDAP填补了Stable Diffusion安全防护的空白，提供了一种高效、通用的对抗净化框架，在实际应用场景中具有实用价值。


### [89] [From Landslide Conditioning Factors to Satellite Embeddings: Evaluating the Utilisation of Google AlphaEarth for Landslide Susceptibility Mapping using Deep Learning](https://arxiv.org/abs/2601.07268)
*Yusen Cheng,Qinfeng Zhu,Lei Fan*

Main category: cs.CV

TL;DR: 本研究评估Google AlphaEarth嵌入作为滑坡敏感性制图的替代预测因子，发现AE嵌入模型在所有研究区域和深度学习模型中均优于传统滑坡条件因子，性能提升显著。

- Motivation: 传统滑坡敏感性制图依赖滑坡条件因子，但其可用性、异质性和预处理不确定性限制了制图可靠性。AE嵌入作为地球表面条件的统一表示，可能提供更好的预测能力。
- Method: 使用两种AE表示（保留主成分和完整64波段）与传统LCF在三个研究区域（台湾南投、香港、意大利艾米利亚-罗马涅）进行比较，采用三种深度学习模型（CNN1D、CNN2D、Vision Transformer），通过多种评估指标进行性能评估。
- Result: AE模型在所有区域和模型中均优于传统LCF，F1分数提升约4%-15%，AUC增加0.04-0.11。完整64波段AE表示效果最佳，制图结果与观测滑坡空间对应更清晰，对局部滑坡易发条件更敏感。
- Conclusion: AE嵌入作为标准化、信息丰富的替代方案，在滑坡敏感性制图中具有强大潜力，特别是当AE嵌入与滑坡清单时间对齐更紧密时效果更佳。


### [90] [PALUM: Part-based Attention Learning for Unified Motion Retargeting](https://arxiv.org/abs/2601.07272)
*Siqi Liu,Maoyu Wang,Bo Dai,Cewu Lu*

Main category: cs.CV

TL;DR: PALUM：通过语义身体部位划分和注意力机制学习跨不同骨骼拓扑的通用运动表示，实现不同骨架结构间的运动重定向

- Motivation: 当源角色和目标角色骨骼结构差异巨大时，保持原始运动的语义和质量变得非常困难。现有方法在处理不同骨骼排列时面临挑战。
- Method: 将关节划分为语义身体部位，应用注意力机制捕捉时空关系，学习跨骨骼拓扑的通用运动表示。引入循环一致性机制确保语义连贯性。
- Result: 在处理多样化骨骼结构时表现出优越性能，能保持运动真实感和语义保真度，即使推广到未见过的骨骼-运动组合也能良好工作。
- Conclusion: PALUM通过骨架无关的表示学习和目标特定结构信息，成功解决了不同骨架结构间的运动重定向问题，为未来研究提供了有效工具。


### [91] [GenDet: Painting Colored Bounding Boxes on Images via Diffusion Model for Object Detection](https://arxiv.org/abs/2601.07273)
*Chen Min,Chengyang Li,Fanjie Kong,Qi Zhu,Dawei Zhao,Liang Xiao*

Main category: cs.CV

TL;DR: GenDet将目标检测重新定义为图像生成任务，通过条件生成架构直接生成带语义标注的边界框

- Motivation: 传统目标检测方法与生成模型之间存在差距，需要一种新框架来弥合生成模型与判别任务之间的鸿沟，为构建统一的视觉理解系统提供新视角
- Method: 基于预训练的Stable Diffusion模型构建条件生成架构，将检测任务转化为潜在空间中的语义约束，直接生成带有语义标注的边界框
- Result: GenDet在保持生成方法灵活性的同时，达到了与判别式检测器相当的竞争性准确度
- Conclusion: GenDet成功弥合了生成模型与判别任务之间的差距，为目标检测提供了全新的生成式视角，展示了构建统一视觉理解系统的潜力


### [92] [Focal Guidance: Unlocking Controllability from Semantic-Weak Layers in Video Diffusion Models](https://arxiv.org/abs/2601.07287)
*Yuanyang Yin,Yufan Deng,Shenghai Yuan,Kaipeng Zhang,Xiao Yang,Feng Zhao*

Main category: cs.CV

TL;DR: 本文提出Focal Guidance方法，通过识别语义弱层并注入细粒度语义指导和注意力缓存，解决图像到视频生成中文本指导与视觉约束耦合不足的问题。

- Motivation: 现有图像到视频生成模型虽然注重视觉一致性，但在有效耦合高频视觉约束和低频文本指导方面存在不足，导致对文本提示的遵循程度不够。研究发现基于DiT的I2V模型中存在语义弱层现象，这是由于条件隔离导致的视觉特征注意力与文本指导部分脱节。
- Method: 提出Focal Guidance方法，包含两个机制：1) 细粒度语义指导(FSG)：利用CLIP识别参考帧关键区域作为锚点指导语义弱层；2) 注意力缓存：将语义响应层的注意力图转移到语义弱层，注入显式语义信号，减轻对学习视觉先验的过度依赖。
- Result: 在提出的I2V指令遵循评估基准上，Focal Guidance显著提升性能：在Wan2.1-I2V上总分提升至0.7250(+3.97%)，在MMDiT-based HunyuanVideo-I2V上提升至0.5571(+7.44%)，证明了方法的有效性和泛化能力。
- Conclusion: Focal Guidance通过针对性地增强语义弱层的可控性，有效解决了图像到视频生成中文本指导与视觉约束的耦合问题，显著提升了模型对文本指令的遵循能力。


### [93] [VideoLoom: A Video Large Language Model for Joint Spatial-Temporal Understanding](https://arxiv.org/abs/2601.07290)
*Jiapeng Shi,Junke Wang,Zuyao You,Bo He,Zuxuan Wu*

Main category: cs.CV

TL;DR: VideoLoom是一个统一的视频大语言模型，专注于联合时空理解，通过构建LoomData-8.7k数据集和LoomBench基准测试，在时空定位任务上取得SOTA性能。

- Motivation: 现有视频理解模型通常在空间或时间维度上表现有限，缺乏联合时空理解能力。需要开发能够同时处理细粒度空间定位和时间定位的统一模型。
- Method: 1. 构建LoomData-8.7k数据集：包含以人为中心的视频，带有时间基础和空间定位的标注；2. 开发VideoLoom模型：统一的视频大语言模型，用于联合时空理解；3. 创建LoomBench基准测试：包含时间、空间和组合视频-问题对，用于全面评估。
- Result: 在多个时空基准测试中取得SOTA或高度竞争力性能：ReVOS上的63.1 J&F（指代视频对象分割），Charades-STA上的48.3 R1@0.7（时间定位）。LoomBench提供了全面的评估框架。
- Conclusion: VideoLoom为联合时空视频理解提供了一个通用有效的解决方案，通过数据集、模型和基准测试的完整套件，为多模态智能设立了新标准。


### [94] [A Visual Semantic Adaptive Watermark grounded by Prefix-Tuning for Large Vision-Language Model](https://arxiv.org/abs/2601.07291)
*Qi Zheng,Shuliang Liu,Yu Huang,Sihang Jia,Jungang Li,Lyuhao Chen,Junhao Chen,Hanqian Li,Aiwei Liu,Yibo Yan,Xuming Hu*

Main category: cs.CV

TL;DR: VISA-Mark是一种视觉语义自适应水印框架，通过视觉证据权重引导词汇分区和logits扰动，在保持视觉保真度的同时嵌入可检测信号，解决了传统水印方法破坏视觉基础或推理延迟高的问题。

- Motivation: 现有水印方法存在两个主要问题：1）视觉无关水印引入无关标记并破坏视觉基础；2）语义感知方法因拒绝采样导致推理延迟过高。需要一种既能保护视觉保真度又能高效推理的水印方案。
- Method: 使用轻量级前缀调谐器提取动态视觉证据权重，量化候选标记的视觉支持程度。基于这些权重进行自适应词汇分区和logits扰动，将水印强度集中在视觉支持的标记上，实现视觉对齐。
- Result: VISA-Mark在视觉一致性（Chair-I）上比传统方法提升7.8%，保持高检测准确率（96.88% AUC）和强攻击鲁棒性（99.3%），同时不牺牲推理效率。
- Conclusion: VISA-Mark通过视觉语义自适应水印机制，在保持视觉保真度的同时实现高效可靠的水印嵌入，为多模态水印建立了新的可靠性保护标准。


### [95] [Inference-Time Scaling for Visual AutoRegressive modeling by Searching Representative Samples](https://arxiv.org/abs/2601.07293)
*Weidong Tang,Xinyan Wan,Siyu Li,Xiumei Wang*

Main category: cs.CV

TL;DR: 首次提出VAR-Scaling框架，通过核密度估计将离散潜在空间映射到准连续特征空间，采用密度自适应混合采样策略，在向量量化视觉自回归模型中实现推理时间缩放，显著提升生成质量。

- Motivation: 虽然推理时间缩放在大语言模型和扩散模型中显著提升了生成质量，但在向量量化视觉自回归模型中尚未探索。主要挑战在于离散潜在空间阻碍了连续路径搜索，需要解决这一关键问题。
- Method: 1) 发现VAR缩放存在两种模式：通用模式和特定模式，后者有条件地优化前者；2) 通过核密度估计将离散采样空间映射到准连续特征空间；3) 提出密度自适应混合采样策略：Top-k采样聚焦高密度区域保持质量，Random-k采样探索低密度区域保持多样性。
- Result: 在类条件生成和文本到图像评估实验中，VAR-Scaling在推理过程中表现出显著改进，证明了该框架在提升向量量化视觉自回归模型生成质量方面的有效性。
- Conclusion: VAR-Scaling是首个在向量量化视觉自回归模型中实现推理时间缩放的通用框架，通过克服离散潜在空间的限制，优化关键尺度的样本保真度，从而显著提升输出质量。


### [96] [Mimic Human Cognition, Master Multi-Image Reasoning: A Meta-Action Framework for Enhanced Visual Understanding](https://arxiv.org/abs/2601.07298)
*Jianghao Yin,Qingbin Li,Kun Sun,Cheng Ding,Jie Wang,Qin Chen,Jie Zhou,Nan Wang,Changqing Li,Pei Wu,Jian Xu,Zheming Yang,Liang He*

Main category: cs.CV

TL;DR: CINEMA框架通过模拟人类认知过程，将多图像推理分解为五个结构化元动作，结合检索树采样和两阶段强化学习，在多模态推理任务上取得SOTA性能。

- Motivation: 当前多模态大语言模型在单图像理解上表现优异，但在多图像推理场景中性能显著下降。多图像推理面临图像间复杂关系和关键信息分散等根本性挑战。
- Method: 提出CINEMA框架，将多图像推理分解为五个结构化元动作：全局、聚焦、提示、思考和回答。采用检索树采样策略生成高质量元动作轨迹进行冷启动训练，然后使用两阶段强化学习：探索阶段采用多样性保持策略，利用阶段采用DAPO逐步加强利用。
- Result: 在多个基准测试中取得竞争性SOTA性能：在MUIR和MVMath基准上超越GPT-4o，在视频理解基准上显著优于专用视频推理模型。构建了包含57k冷启动和58k强化学习实例的数据集。
- Conclusion: CINEMA框架通过模拟人类认知过程，有效解决了多图像推理的挑战，展示了该方法的有效性和泛化能力，为多模态推理提供了新的解决方案。


### [97] [Revisiting the Ordering of Channel and Spatial Attention: A Comprehensive Study on Sequential and Parallel Designs](https://arxiv.org/abs/2601.07310)
*Zhongming Liu,Bingbing Jiang*

Main category: cs.CV

TL;DR: 系统研究通道与空间注意力融合策略，发现数据规模与注意力架构性能的耦合规律，提出基于场景的注意力模块构建指南。

- Motivation: 当前通道注意力和空间注意力的融合策略选择主要依赖经验，缺乏系统分析和统一原则，需要建立科学的指导框架。
- Method: 在统一框架下系统比较通道-空间注意力组合，构建包含顺序、并行、多尺度和残差四类共18种拓扑结构的评估套件，在2个视觉和9个医疗数据集上进行实验。
- Result: 发现"数据规模-方法-性能"耦合规律：小样本任务中"通道-多尺度空间"级联结构最优；中等规模任务中并行可学习融合架构表现最佳；大规模任务中带动态门控的并行结构性能最好。此外，"空间-通道"顺序在细粒度分类中更稳定有效，残差连接能缓解梯度消失问题。
- Conclusion: 提出了基于场景的注意力模块构建指南，为未来注意力模块设计提供科学依据，代码已开源。


### [98] [OSCAR: Open-Set CAD Retrieval from a Language Prompt and a Single Image](https://arxiv.org/abs/2601.07333)
*Tessa Pulli,Jean-Baptiste Weibel,Peter Hönig,Matthias Hirschmanner,Markus Vincze,Andreas Holzinger*

Main category: cs.CV

TL;DR: OSCAR是一种无需训练的方法，通过语言提示和单张图像从无标签3D数据库中检索匹配的物体模型，用于6D姿态估计中的物体模型获取。

- Motivation: 在机器人、AR等应用中，物体集合不断变化，现有零样本姿态估计器需要CAD模型，但部署后难以获取，且持续变化的物体集合使得准确识别目标实例模型更加困难。
- Method: OSCAR采用两阶段检索：1) 使用CLIP进行基于文本的过滤识别候选模型；2) 使用DINOv2进行基于图像的细化选择最相似的物体。在入库阶段，生成数据库模型的多视角渲染图并用图像描述模型标注描述性标题。
- Result: 在跨域3D模型检索基准MI3DOR上优于所有SOTA方法；在YCB-V物体数据集上检索精度达90.48%；使用最相似物体模型进行姿态估计比基于重建的方法效果更好。
- Conclusion: OSCAR提供了一种有效的训练免费方法，用于从无标签3D数据库中检索物体模型，支持6D姿态估计中的物体模型自动化获取，特别是在精确实例不可用时使用最相似模型进行姿态估计。


### [99] [Reconstruction Guided Few-shot Network For Remote Sensing Image Classification](https://arxiv.org/abs/2601.07335)
*Mohit Jaiswal,Naman Jain,Shivani Pathak,Mainak Singha,Nikunja Bihari Kar,Ankit Jha,Biplab Banerjee*

Main category: cs.CV

TL;DR: 提出RGFS-Net，通过掩码图像重建任务增强少样本遥感图像分类的泛化能力，在EuroSAT和PatternNet数据集上优于现有基线方法。

- Motivation: 少样本遥感图像分类面临标记样本有限和地物类型变化大的挑战，需要提升模型对未见类别的泛化能力。
- Method: 提出重建引导的少样本网络(RGFS-Net)，引入掩码图像重建任务：遮挡输入图像部分区域并重建，促进语义丰富的特征学习，增强空间理解和类间区分能力。
- Result: 在EuroSAT和PatternNet数据集上，使用1-shot和5-shot协议评估，RGFS-Net始终优于现有基线方法。
- Conclusion: 该方法简单有效，兼容标准骨干网络，为少样本遥感分类提供了鲁棒解决方案。


### [100] [PulseMind: A Multi-Modal Medical Model for Real-World Clinical Diagnosis](https://arxiv.org/abs/2601.07344)
*Jiao Xu,Junwei Liu,Jiangwei Lao,Qi Zhu,Yunpeng Zhao,Congyun Jin,Shinan Liu,Zhihong Lu,Lihe Zhang,Xin Chen,Jian Wang,Ping Wang*

Main category: cs.CV

TL;DR: PulseMind是一个多模态诊断模型家族，包含MediScope数据集、PulseMind评测基准和CRPO训练框架，专注于真实世界多轮临床诊断对话。

- Motivation: 现有医学多模态模型主要专注于皮肤病学、病理学或放射学等专业图像分析，未能充分捕捉真实世界临床诊断的复杂性。真实诊断涉及异构输入，需要在医患互动中进行持续的上下文理解。
- Method: 1. 构建MediScope诊断数据集：包含98,000个真实世界多轮咨询和601,500张医学图像，涵盖10个主要临床科室和200多个亚专科。2. 开发PulseMind Benchmark：多轮诊断咨询基准，采用主动性、准确性、有用性和语言质量四维评估协议。3. 设计基于比较的强化策略优化（CRPO）训练框架：使用相对偏好信号而非绝对分数奖励，提供稳定且符合人类偏好的训练指导。
- Result: PulseMind在诊断咨询基准和公共医学基准上都取得了有竞争力的性能表现。
- Conclusion: PulseMind通过整合系统性策划的数据集、全面评估基准和定制训练框架，成功构建了一个能够处理真实世界多轮临床诊断复杂性的多模态诊断模型家族。


### [101] [Seeing Right but Saying Wrong: Inter- and Intra-Layer Refinement in MLLMs without Training](https://arxiv.org/abs/2601.07359)
*Shezheng Song,Shasha Li,Jie Yu*

Main category: cs.CV

TL;DR: DualPD：一种无需训练的双视角解码优化策略，通过层间注意力引导对比和头级信息过滤，解决MLLMs中"看对说错"的问题，提升多模态理解准确性。

- Motivation: 多模态大语言模型在视觉语言任务中表现出色，但其内部推理存在关键不一致性：深层可能关注正确视觉区域，但最终预测常被早期层的噪声注意力误导，导致"看对说错"现象。
- Method: 提出DualPD双视角解码优化策略：1）层间注意力引导对比logits模块，通过对比注意力最大偏移层间的输出logits来捕捉正确答案信念演变；2）头级信息过滤模块，抑制关注无关区域的低贡献注意力头，提升每层注意力质量。
- Result: 在LLaVA和Qwen-VL模型家族及多个多模态基准测试上的实验表明，DualPD无需训练即可持续提升准确性，验证了其有效性和泛化能力。
- Conclusion: DualPD通过解码时优化有效解决了MLLMs中"看对说错"的问题，无需额外训练即可提升模型性能，为多模态理解提供了实用的优化方案。


### [102] [HiVid-Narrator: Hierarchical Video Narrative Generation with Scene-Primed ASR-anchored Compression](https://arxiv.org/abs/2601.07366)
*Haoxuan Li,Mengyan Li,Junjun Zheng*

Main category: cs.CV

TL;DR: 提出了E-HVC数据集和HiVid-Narrator框架，用于生成电商视频的结构化叙事，通过分层压缩和分阶段构建解决现有方法难以统一细粒度感知与高层故事组织的问题。

- Motivation: 现有方法难以同时处理电商视频的细粒度视觉细节感知和将其组织成连贯高层故事的能力，需要新的数据集和方法来解决这一挑战。
- Method: 1) 构建E-HVC数据集，包含双粒度时间标注：时间思维链和章节摘要；2) 采用分阶段构建方法，先收集ASR和帧级描述作为证据，再基于时间思维链精炼章节边界和标题；3) 提出SPA-Compressor压缩多模态token为分层场景和事件表示；4) 建立HiVid-Narrator框架。
- Result: HiVid-Narrator框架相比现有方法，在减少输入token的同时实现了更优的叙事质量。
- Conclusion: 通过E-HVC数据集和HiVid-Narrator框架，成功解决了电商视频结构化叙事生成中的细粒度感知与高层故事组织的统一问题，实现了高效且高质量的叙事生成。


### [103] [Learning Dynamic Collaborative Network for Semi-supervised 3D Vessel Segmentation](https://arxiv.org/abs/2601.07377)
*Jiao Xu,Xin Chen,Lihe Zhang*

Main category: cs.CV

TL;DR: 提出DiCo动态协作网络用于半监督3D血管分割，通过动态切换师生角色、多视角整合和对抗监督提升性能

- Motivation: 传统均值教师方法中师生角色固定，但由于3D血管数据的复杂性，教师模型不一定总是优于学生模型，导致认知偏差限制性能
- Method: 1) 动态协作网络允许两个模型动态切换师生角色；2) 多视角整合模块捕捉输入的不同视角；3) 对抗监督约束未标记数据中分割血管的形状；4) 将3D体积投影到2D视图以减少标签不一致的影响
- Result: 在三个3D血管分割基准测试中取得了新的最先进性能
- Conclusion: DiCo方法通过动态师生角色切换、多视角整合和对抗监督，有效解决了传统均值教师方法在复杂3D血管分割中的局限性


### [104] [Forecast the Principal, Stabilize the Residual: Subspace-Aware Feature Caching for Efficient Diffusion Transformers](https://arxiv.org/abs/2601.07396)
*Guantao Chen,Shikang Zheng,Yuqi Lin,Linfeng Zhang*

Main category: cs.CV

TL;DR: SVD-Cache：通过SVD分解DiT特征空间，对主成分子空间使用EMA预测，直接重用残差子空间，实现近无损的推理加速

- Motivation: DiT模型在图像和视频生成中取得了突破性质量，但其迭代采样过程计算成本高昂。现有的特征缓存方法对所有特征组件统一处理，未能充分利用特征空间的不同时间行为特性。
- Method: 提出SVD-Cache框架：1）通过奇异值分解（SVD）将扩散特征分解为不同子空间；2）发现主成分子空间随时间平滑演化，残差子空间呈现低能量振荡；3）对主成分子空间应用指数移动平均（EMA）预测；4）直接重用残差子空间。
- Result: 在FLUX和HunyuanVideo等模型上实现5.55倍加速，保持近无损质量，兼容蒸馏、量化和稀疏注意力等模型加速技术。
- Conclusion: SVD-Cache通过识别和利用DiT特征空间的不同时间行为特性，实现了高效的特征缓存策略，为扩散模型的推理加速提供了新思路。


### [105] [SDHSI-Net: Learning Better Representations for Hyperspectral Images via Self-Distillation](https://arxiv.org/abs/2601.07416)
*Prachet Dev Singh,Shyamsundar Paramasivam,Sneha Barman,Mainak Singha,Ankit Jha,Girish Mishra,Biplab Banerjee*

Main category: cs.CV

TL;DR: 该论文提出将自蒸馏技术应用于高光谱图像分类，通过将网络早期输出作为软目标来增强模型性能，无需外部教师网络。

- Motivation: 高光谱图像分类面临高光谱维度和有限标注数据的挑战，传统深度学习方法容易过拟合且计算成本高。自蒸馏技术作为一种无需外部教师网络的知识蒸馏变体，有望提升模型性能。
- Method: 将自蒸馏应用于高光谱图像分类，将网络早期输出作为软目标，强制中间预测与最终预测之间的一致性，从而改善特征空间中的类内紧凑性和类间可分性。
- Result: 在两个基准高光谱数据集上验证了方法的有效性，显示出分类准确性和鲁棒性的显著提升。
- Conclusion: 自蒸馏技术对于光谱-空间学习是有效的，能够改善高光谱图像分类性能，代码已开源。


### [106] [PanoSAMic: Panoramic Image Segmentation from SAM Feature Encoding and Dual View Fusion](https://arxiv.org/abs/2601.07447)
*Mahdi Chamseddine,Didier Stricker,Jason Rambach*

Main category: cs.CV

TL;DR: PanoSAMic是一个用于全景图像语义分割的新模型，它通过集成SAM编码器、多模态融合和球形注意力机制，在多个数据集上取得了SotA结果。

- Motivation: 现有的图像基础模型主要针对透视图像训练，不适用于球形全景图像。全景图像存在畸变和边缘不连续问题，需要专门的处理方法。
- Method: 1) 修改SAM编码器输出多阶段特征；2) 引入空间-模态融合模块选择相关模态和最佳特征；3) 语义解码器使用球形注意力和双视图融合处理畸变和边缘不连续问题。
- Result: 在Stanford2D3DS数据集上，RGB、RGB-D和RGB-D-N模态均取得SotA结果；在Matterport3D数据集上，RGB和RGB-D模态取得SotA结果。
- Conclusion: PanoSAMic成功将预训练的SAM编码器集成到全景图像语义分割中，通过创新的多模态融合和球形处理机制，有效解决了全景图像的特殊挑战。


### [107] [Improving Video Question Answering through query-based frame selection](https://arxiv.org/abs/2601.07459)
*Himanshu Patil,Geo Jolly,Ramana Raja Buddala,Ganesh Ramakrishnan,Rohit Saluja*

Main category: cs.CV

TL;DR: 提出基于子模互信息函数的查询驱动帧选择方法，替代均匀采样，在VideoQA任务中提升准确率4%

- Motivation: 现有VideoQA模型通常采用均匀采样固定数量帧，这种方法无法捕捉视频重要帧和上下文信息，影响问答准确性
- Method: 基于子模互信息函数进行查询驱动的帧选择，根据问题选择相关且互补的视觉信息帧
- Result: 在MVBench数据集上，使用Video-LLaVA和LLaVA-NeXT模型，查询驱动帧选择比均匀采样提升准确率最高达4%
- Conclusion: 查询驱动的帧选择方法能有效提升VideoQA准确性，适用于依赖视频帧子集的各种任务


### [108] [From Sketch to Fresco: Efficient Diffusion Transformer with Progressive Resolution](https://arxiv.org/abs/2601.07462)
*Shikang Zheng,Guantao Chen,Lixuan He,Jiacheng Liu,Yuqi Lin,Chang Zou,Linfeng Zhang*

Main category: cs.CV

TL;DR: Fresco是一个动态分辨率框架，通过渐进上采样统一跨阶段的重噪声和全局结构，在保持低分辨率草稿效率和高分辨率精修保真度的同时，实现近无损加速。

- Motivation: 现有动态分辨率采样方法存在两个主要问题：1) 依赖启发式重噪声注入，破坏跨阶段一致性，迫使模型重新学习全局结构；2) 不加区分地上采样整个潜在空间，导致累积误差和可见伪影。
- Method: 提出Fresco框架，统一跨阶段的重噪声和全局结构，采用渐进上采样策略，只对未收敛区域进行上采样，保持所有阶段对齐到同一最终目标。
- Result: 在FLUX上实现10倍加速，在HunyuanVideo上实现5倍加速，与蒸馏、量化和特征缓存正交，结合蒸馏模型可达22倍加速，实现近无损加速。
- Conclusion: Fresco通过渐进上采样和跨阶段一致性保持，在保持生成质量的同时显著加速扩散变换器采样，为动态分辨率采样提供了更有效的解决方案。


### [109] [FocalOrder: Focal Preference Optimization for Reading Order Detection](https://arxiv.org/abs/2601.07483)
*Fuyuan Liu,Dianyu Yu,He Ren,Nayu Liu,Xiaomian Kang,Delai Qiu,Fa Zhang,Genpeng Zhen,Shengping Liu,Jiaen Liang,Wei Huang,Yining Wang,Junnan Zhu*

Main category: cs.CV

TL;DR: FocalOrder框架通过Focal Preference Optimization解决文档阅读顺序检测中的位置差异问题，在复杂中间区域表现优异，在多个基准测试中达到SOTA。

- Motivation: 现有方法假设文档布局区域难度分布均匀，但实际存在"位置差异"问题：模型在确定性的起始和结束区域表现良好，但在复杂的中间区域性能崩溃。这是因为标准训练中大量简单模式淹没了困难布局的学习信号。
- Method: 提出FocalOrder框架，采用Focal Preference Optimization (FPO)。具体包括：1) 使用指数移动平均机制的自适应难度发现，动态识别难以学习的转换；2) 引入难度校准的成对排序目标，强制全局逻辑一致性。
- Result: 在OmniDocBench v1.0和Comp-HRDoc上建立了新的SOTA结果。紧凑模型不仅优于竞争的专业基线，还显著超越大规模通用视觉语言模型。
- Conclusion: 将优化与文档内在结构模糊性对齐对于掌握复杂文档结构至关重要。FocalOrder通过解决位置差异问题，有效提升了文档阅读顺序检测的性能。


### [110] [Anatomy Aware Cascade Network: Bridging Epistemic Uncertainty and Geometric Manifold for 3D Tooth Segmentation](https://arxiv.org/abs/2601.07499)
*Bing Yu,Liu Shi,Haitao Wang,Deran Qi,Xiang Cai,Wei Zhong,Qiegen Liu*

Main category: cs.CV

TL;DR: 提出AACNet用于CBCT三维牙齿分割，通过粗到细框架解决边界模糊问题，在125个CBCT数据集上达到90.17% Dice系数和3.63mm HD95，优于现有方法。

- Motivation: CBCT三维牙齿分割是数字牙科工作流程的前提，但由于低对比度和不清晰的牙弓边界导致的粘连伪影，实现高保真分割仍然具有挑战性。
- Method: 提出解剖感知级联网络(AACNet)，包含两个机制：模糊门控边界细化器(AGBR)和符号距离图引导的解剖注意力(SDMAA)。AGBR使用基于熵的门控机制在不确定过渡区进行特征校正，SDMAA通过符号距离图集成隐式几何约束以保持拓扑一致性。
- Result: 在125个CBCT数据集上，AACNet达到90.17% Dice相似系数和3.63mm 95% Hausdorff距离，显著优于现有方法。在外部数据集上HD95为2.19mm，显示出良好的泛化能力。
- Conclusion: AACNet通过解决边界模糊和保持全局结构一致性，实现了准确的CBCT牙齿分割，验证了其在手术规划等下游临床应用中的可靠性。


### [111] [Mon3tr: Monocular 3D Telepresence with Pre-built Gaussian Avatars as Amortization](https://arxiv.org/abs/2601.07518)
*Fangyu Lin,Yingdong Hu,Zhening Liu,Yufan Zhuang,Zehong Lin,Jun Zhang*

Main category: cs.CV

TL;DR: Mon3tr：首个基于3D高斯泼溅的单目3D远程呈现框架，通过离线重建和在线推理实现低带宽、高帧率的全身全息交互

- Motivation: 现有沉浸式远程呈现系统依赖多摄像头硬件和高带宽体积流，难以在移动设备上实现实时性能。需要降低系统复杂性和成本，同时保持高质量的全息呈现效果。
- Method: 采用分期计算策略：1）离线多视角重建阶段构建用户特定虚拟化身；2）在线单目推理阶段使用单目RGB摄像头实时捕捉动作和表情驱动3DGS参数化人体模型。通过WebRTC数据通道传输<0.2Mbps的运动和外观特征，接收端使用轻量级3DGS属性变形网络动态生成校正调整。
- Result: 在新型姿态下PSNR>28dB，端到端延迟约80ms，相比点云流带宽降低>1000倍，在Meta Quest 3等设备上实现约60FPS的实时运行，支持多样化场景的单目输入。
- Conclusion: Mon3tr首次将3D高斯泼溅参数化人体建模集成到远程呈现中，显著降低了系统复杂性和成本，实现了高质量、低带宽、实时的沉浸式远程协作，为AR/VR应用提供了可行的解决方案。


### [112] [ViewMorpher3D: A 3D-aware Diffusion Framework for Multi-Camera Novel View Synthesis in Autonomous Driving](https://arxiv.org/abs/2601.07540)
*Farhad G. Zanjani,Hong Cai,Amirhossein Habibian*

Main category: cs.CV

TL;DR: ViewMorpher3D：基于图像扩散模型的多视角图像增强框架，用于提升自动驾驶场景中的照片真实感和多视角一致性，减少3D重建渲染中的伪影。

- Motivation: 自动驾驶系统依赖多视角图像进行感知和决策，需要逼真的闭环模拟器。现有3D重建技术（如高斯泼溅）在渲染新视角时会产生伪影，特别是在外推视角或观测稀疏的情况下。
- Method: 基于图像扩散模型的多视角图像增强框架，联合处理一组渲染视图，条件包括相机姿态、3D几何先验、时间相邻或空间重叠的参考视图。框架支持可变数量的相机和灵活的参考/目标视图配置。
- Result: 在真实世界驾驶数据集上的实验显示，图像质量指标显著提升，有效减少伪影同时保持几何保真度。
- Conclusion: ViewMorpher3D能够提升自动驾驶模拟器的视觉质量，增强多视角一致性，为感知和规划算法的开发评估提供更真实的模拟环境。


### [113] [BenchSeg: A Large-Scale Dataset and Benchmark for Multi-View Food Video Segmentation](https://arxiv.org/abs/2601.07581)
*Ahmad AlMughrabi,Guillermo Rivo,Carlos Jiménez-Farfán,Umair Haroon,Farid Al-Areqi,Hyunjun Jung,Benjamin Busam,Ricardo Marques,Petia Radeva*

Main category: cs.CV

TL;DR: 提出了BenchSeg数据集和基准，用于多视角食物视频分割，包含55个菜肴场景和25,284个标注帧，评估了20个SOTA分割模型，发现记忆增强方法能保持时间一致性。

- Motivation: 当前食物图像分割方法存在多视角数据有限和对新视角泛化能力差的问题，需要更好的数据集和基准来推动饮食分析领域的发展。
- Method: 整合了4个现有数据集（Nutrition5k、Vegetables & Fruits、MetaFood3D、FoodKit）创建BenchSeg数据集，包含55个菜肴场景和25,284个标注帧，在360°自由相机运动下捕获。评估了20个SOTA分割模型（包括SAM-based、transformer、CNN和大型多模态模型），并在现有FoodSeg103数据集和BenchSeg上进行测试，结合视频记忆模块。
- Result: 标准图像分割器在新视角下性能急剧下降，而记忆增强方法能保持跨帧的时间一致性。基于SeTR-MLA+XMem2的最佳模型优于先前工作（比FoodMem提升约2.63% mAP）。
- Conclusion: BenchSeg数据集为食物分割和跟踪提供了新的研究基准，记忆增强方法在保持时间一致性方面表现优异，有助于推动饮食分析技术的发展。数据集和模型已公开发布。


### [114] [Robust Multicentre Detection and Classification of Colorectal Liver Metastases on CT: Application of Foundation Models](https://arxiv.org/abs/2601.07585)
*Shruti Atul Mali,Zohaib Salahuddin,Yumeng Zhang,Andre Aichert,Xian Zhong,Henry C. Woodruff,Maciej Bobowicz,Katrine Riklund,Juozas Kupčinskas,Lorenzo Faggioni,Roberto Francischello,Razvan L Miclea,Philippe Lambin*

Main category: cs.CV

TL;DR: 开发了一个基于基础模型的AI管道，用于结直肠肝转移瘤（CRLM）的患者级分类和病灶级检测，在CT上实现了高精度和可解释性。

- Motivation: 结直肠肝转移瘤是癌症相关死亡的主要原因，在多中心环境中CT检测仍然具有挑战性，需要开发可靠、可解释的AI检测系统。
- Method: 使用EuCanImage联盟（n=2437）和外部TCIA队列（n=197）的CT数据，基于预训练模型UMedPT进行微调，采用MLP头进行分类和FCOS-based头进行病灶检测，集成不确定性量化和可解释性分析。
- Result: 分类模型在组合测试集上AUC为0.90，敏感性0.82；外部队列敏感性0.85。排除最不确定的20%病例后，AUC提升至0.91，平衡准确率0.86。检测模型整体识别69.1%的病灶，按病灶大小四分位数从30%提升至98%。
- Conclusion: 基于基础模型的管道能够在异质CT数据上实现稳健、可解释的CRLM检测和分类，具有临床实用性。


### [115] [Diffusion in SPAD Signals](https://arxiv.org/abs/2601.07599)
*Lior Dvir,Nadav Torem,Yoav Y. Schechner*

Main category: cs.CV

TL;DR: 该论文推导了单光子雪崩二极管(SPAD)原始信号的似然函数和评分函数，并基于扩散模型解决SPAD信号的逆问题，分析了光子计数和检测时间的影响。

- Motivation: SPAD信号（检测事件的时间）与光子通量呈非线性关系且具有随机性，需要建立准确的概率模型来解决基于SPAD信号的逆问题。
- Method: 推导SPAD原始信号的似然函数和评分函数，结合扩散模型表达图像先验，分析不同光子计数水平和检测时间信息利用的影响。
- Result: 建立了SPAD信号的完整概率模型，为基于SPAD的逆问题提供了关键工具，展示了在低/高光子计数条件下以及利用检测时间信息的效果。
- Conclusion: 该研究为SPAD信号处理提供了理论基础，评分函数是解决SPAD逆问题的关键，扩散模型能有效表达图像先验，检测时间信息对信号重建有重要影响。


### [116] [UIKA: Fast Universal Head Avatar from Pose-Free Images](https://arxiv.org/abs/2601.07603)
*Zijian Wu,Boyao Zhou,Liangxiao Hu,Hongyu Liu,Yuan Sun,Xuan Wang,Xun Cao,Yujun Shen,Hao Zhu*

Main category: cs.CV

TL;DR: UIKA是一种基于前馈网络的动画化高斯头部模型，可从任意数量的未摆姿输入（单张图像、多视角捕捉、手机视频）生成3D头像，无需传统工作室级多视角系统和长时间优化。

- Motivation: 传统头像方法需要工作室级多视角捕捉系统和长时间优化过程，限制了实际应用。UIKA旨在重新思考这一任务，通过改进模型表示、网络设计和数据准备，实现从更便捷的输入（包括单张图像）生成高质量动画化3D头部模型。
- Method: 1. 引入UV引导的头像建模策略，通过像素级面部对应估计将输入图像重投影到UV空间；2. 设计可学习的UV token，在屏幕和UV级别应用注意力机制；3. 使用合成的身份丰富的大规模训练数据集。
- Result: 在单目和多视角设置下，UIKA显著优于现有方法，能够从各种便捷输入生成高质量的动画化3D头部模型。
- Conclusion: UIKA通过创新的UV引导建模策略、可学习UV token设计和高质量合成数据集，实现了从便捷输入生成高质量动画化3D头部模型，为头像创建提供了更实用的解决方案。


### [117] [PARL: Position-Aware Relation Learning Network for Document Layout Analysis](https://arxiv.org/abs/2601.07620)
*Fuyuan Liu,Dianyu Yu,He Ren,Nayu Liu,Xiaomian Kang,Delai Qiu,Fa Zhang,Genpeng Zhen,Shengping Liu,Jiaen Liang,Wei Huang,Yining Wang,Junnan Zhu*

Main category: cs.CV

TL;DR: 提出PARL，一个无需OCR的纯视觉文档布局分析框架，通过位置感知和关系学习实现高效准确的布局分析，超越多模态方法。

- Motivation: 现有方法依赖高质量OCR融合视觉和文本特征，存在文本识别错误传播和计算开销大的问题。作者认为有效的布局分析应基于文档内在视觉结构而非文本-视觉融合。
- Method: 提出PARL框架：1) 双向空间位置引导可变形注意力模块，将布局元素的位置依赖直接嵌入视觉特征；2) 图细化分类器，通过动态构建的布局图建模上下文关系来优化预测。
- Result: 在DocLayNet上为纯视觉方法建立新基准，在M6Doc上甚至超越强大多模态模型。PARL（65M参数）比大型多模态模型（256M参数）效率高约4倍。
- Conclusion: 精密的视觉结构建模比多模态融合更高效且鲁棒，证明了纯视觉方法在文档布局分析中的优越性。


### [118] [GeoMotionGPT: Geometry-Aligned Motion Understanding with Large Language Models](https://arxiv.org/abs/2601.07632)
*Zhankai Ye,Bofan Li,Yukai Jin,Shuoqiu Li,Wei Wang,Yanfu Zhang,Shangqian Gao,Xin Liu*

Main category: cs.CV

TL;DR: 提出一种新框架，通过正交化运动码本和LLM嵌入空间，统一两者的几何基础，从而提升LLM对细微运动推理的能力，在HumanML3D上性能提升20%。

- Motivation: 现有方法将运动量化与语义嵌入学习解耦，仅通过token ID连接，未能有效对齐运动空间的内在几何结构与嵌入空间，限制了LLM进行细微运动推理的能力。
- Method: 1) 使用带Gumbel-Softmax的解码器量化器进行可微分训练和平衡码本使用；2) 通过稀疏投影将运动码映射到LLM嵌入空间并保持正交性；3) 采用两阶段正交正则化计划，在tokenizer训练和LLM微调中施加软约束以保持几何对齐。
- Result: 在HumanML3D数据集上的大量实验表明，该框架相比当前最先进方法实现了20%的性能提升，验证了统一几何基础能有效增强LLM的细微运动推理能力。
- Conclusion: 通过强制运动码本和LLM嵌入空间的正交性，使两者的关系结构自然相互映射，为运动理解和运动-语言推理提供了更有效的几何对齐基础。


### [119] [StdGEN++: A Comprehensive System for Semantic-Decomposed 3D Character Generation](https://arxiv.org/abs/2601.07660)
*Yuze He,Yanning Zhou,Wang Zhao,Jingwen Ye,Zhongkai Wu,Ran Yi,Yong-Jin Liu*

Main category: cs.CV

TL;DR: StdGEN++是一个生成高质量、语义分解3D角色的系统，通过双分支语义感知大重建模型实现几何、颜色和组件语义的联合重建，支持生产级编辑和动画应用。

- Motivation: 现有3D生成方法通常产生单一网格，缺乏游戏和动画工业流水线所需的结构灵活性，无法支持组件级编辑和高级下游应用。
- Method: 1. 双分支语义感知大重建模型(Dual-Branch S-LRM)联合重建几何、颜色和组件语义；2. 兼容混合隐式场的语义表面提取机制；3. 粗到细的提议方案减少内存占用；4. 基于视频扩散的纹理分解模块分离外观为可编辑层。
- Result: StdGEN++在几何精度和语义解缠方面达到最先进水平，显著优于现有方法，生成的结构独立性支持非破坏性编辑、物理合规动画和视线跟踪等高级功能。
- Conclusion: StdGEN++为自动化角色资产生产提供了强大解决方案，通过语义分解的3D角色生成解锁了高级下游应用能力，满足工业流水线需求。


### [120] [Variational Contrastive Learning for Skeleton-based Action Recognition](https://arxiv.org/abs/2601.07666)
*Dang Dinh Nguyen,Decky Aspandi Latif,Titus Zaharia*

Main category: cs.CV

TL;DR: 提出了一种结合变分推理和对比学习的自监督骨架动作识别方法，在低标签场景下表现优异

- Motivation: 现有的对比学习方法主要是判别式的，难以捕捉人体运动固有的变化性和不确定性，需要一种能学习结构化、语义丰富表示的方法
- Method: 提出变分对比学习框架，将概率潜在建模与对比自监督学习相结合，学习具有结构化和语义意义的表示
- Result: 在三个广泛使用的骨架动作识别基准测试中，该方法始终优于现有方法，特别是在低标签场景下；定性分析显示特征更关注重要骨骼关节
- Conclusion: 变分对比学习框架能有效学习结构化表示，在骨架动作识别任务中，特别是在监督信号有限的情况下，表现出优越性能


### [121] [Advancing Multinational License Plate Recognition Through Synthetic and Real Data Fusion: A Comprehensive Evaluation](https://arxiv.org/abs/2601.07671)
*Rayson Laroca,Valter Estevam,Gladston J. P. Moreira,Rodrigo Minetto,David Menotti*

Main category: cs.CV

TL;DR: 该研究通过综合使用真实和合成数据来提升车牌识别性能，测试了16个OCR模型在12个公开数据集上的表现，发现大量合成数据能显著提升模型性能，并探索了三种合成数据生成方法的最佳组合。

- Motivation: 尽管现有研究使用合成图像来改进车牌识别，但这些方法存在局限性。本研究旨在通过全面探索真实和合成数据的整合来克服这些限制，提升车牌识别性能。
- Method: 对16个OCR模型在12个不同地区的公开数据集上进行基准测试，探索了三种合成数据生成方法：基于模板的生成、字符排列和使用GAN模型，并研究这些方法的组合效果。
- Result: 大量合成数据的整合显著提升了模型在数据集内和跨数据集场景下的性能；三种合成方法的组合产生了显著的协同效应，端到端结果超越了最先进方法和商业系统；合成数据有效缓解了训练数据不足的问题；识别了不同模型在准确性和速度之间的最佳平衡点。
- Conclusion: 综合使用真实和合成数据能显著提升车牌识别性能，特别是多种合成方法的组合能产生协同效应，为有限训练数据场景提供了有效解决方案，并找到了准确性与速度的最佳平衡模型。


### [122] [Leveraging 3D Representation Alignment and RGB Pretrained Priors for LiDAR Scene Generation](https://arxiv.org/abs/2601.07692)
*Nicolas Sereyjol-Garros,Ellington Kirby,Victor Besnier,Nermin Samet*

Main category: cs.CV

TL;DR: R3DPA是首个利用图像预训练先验进行LiDAR场景生成的方法，通过自监督3D表征和图像预训练知识迁移，在有限LiDAR数据下实现SOTA性能，并支持点云控制。

- Motivation: LiDAR场景合成是解决自动驾驶等机器人任务中3D数据稀缺的新兴方案。现有方法使用扩散或流匹配模型生成场景，但3D数据相比数百万样本的RGB数据集仍然有限。
- Method: 1) 将生成模型的中间特征与自监督3D特征对齐，显著提升生成质量；2) 从大规模图像预训练生成模型迁移知识到LiDAR生成，缓解LiDAR数据集限制；3) 仅使用无条件模型即可在推理时实现点云控制，包括物体修复和场景混合。
- Result: 在KITTI-360基准测试中，R3DPA实现了最先进的性能。
- Conclusion: R3DPA通过利用图像预训练先验和自监督3D表征，成功解决了LiDAR数据稀缺问题，实现了高质量的LiDAR场景生成和控制能力。


### [123] [Smooth Operator: Smooth Verifiable Reward Activates Spatial Reasoning Ability of Vision-Language Model](https://arxiv.org/abs/2601.07695)
*Siwen Jiao,Tianxiong Lv,Kangan Qian,Chenxu Zhao,Xiuyuan Zhu,Tianlun Li,Xiaolong Cheng,Jinyu Li,Zhihao Liao,Yang Cai*

Main category: cs.CV

TL;DR: 提出SNRA算子和AP-GRPO框架，解决VLMs在3D场景理解中数值预测精度不足的问题，通过密集连续奖励激活和绝对标量梯度保留，提升数据利用效率。

- Motivation: 传统基于相对排序的强化学习方法在3D场景理解中存在严重奖励稀疏性和梯度不稳定问题，无法有效利用3D物理约束提供的可验证信号。在标准GRPO框架中，相对归一化导致"接近命中"样本遭受优势崩溃，造成有价值边界样本在优化中被丢弃的数据利用瓶颈。
- Method: 1. 提出Smooth Numerical Reward Activation (SNRA)算子：使用动态参数化Sigmoid函数将原始反馈转换为密集连续的奖励连续体；2. 提出Absolute-Preserving GRPO (AP-GRPO)框架：整合绝对标量梯度以缓解传统相对排序机制中的数值信息损失；3. 构建Numerical3D-50k数据集：包含50,000个可验证的3D子任务。
- Result: AP-GRPO在保持更高数据效率的同时，实现了与大规模监督方法相当的性能，有效激活了VLMs中的潜在3D推理能力，无需架构修改。构建了包含50,000个可验证3D子任务的Numerical3D-50k数据集。
- Conclusion: 通过SNRA算子和AP-GRPO框架，成功解决了VLMs在3D场景理解中的数值预测瓶颈问题，实现了更高效的数据利用和更精确的数值推理，为视觉语言模型在3D理解任务中的应用提供了有效解决方案。


### [124] [Hidden Monotonicity: Explaining Deep Neural Networks via their DC Decomposition](https://arxiv.org/abs/2601.07700)
*Jakob Paul Zimmermann,Georg Loho*

Main category: cs.CV

TL;DR: 论文提出两种利用单调性提升神经网络可解释性的方法：1）将训练好的ReLU网络分解为两个单调凸部分，改进现有显著性方法；2）训练两个单调神经网络的差值模型，获得自解释性系统。

- Motivation: 虽然单调性已被证明能提升神经网络的可解释性，但并非所有函数都能用单调神经网络良好近似。本文旨在探索如何在不完全依赖单调网络的情况下，仍能利用单调性来增强模型的可解释性。
- Method: 提出两种方法：1）改进ReLU网络分解为两个单调凸部分的算法，克服权重爆炸的数值障碍，开发SplitCAM和SplitLRP显著性方法；2）训练两个单调神经网络的差值模型，构建具有自解释性的系统。
- Result: SplitCAM和SplitLRP在VGG16和Resnet18网络上，在ImageNet-S数据集的所有Quantus显著性指标类别中均优于现有最佳方法。差值模型方法也展现出强大的自解释性特性。
- Conclusion: 即使不能直接使用单调神经网络，仍可通过网络分解和差值模型两种方式有效利用单调性来显著提升神经网络的可解释性，为模型解释提供了新的实用方法。


### [125] [FMAC: a Fair Fiducial Marker Accuracy Comparison Software](https://arxiv.org/abs/2601.07723)
*Guillaume J. Laurent,Patrick Sandoz*

Main category: cs.CV

TL;DR: 提出了一种基于高保真合成图像的基准方法，用于公平比较不同标记系统的位姿估计精度，通过低差异采样探索6自由度空间，并开源了相关代码。

- Motivation: 当前缺乏公平比较不同标记系统位姿估计精度的方法，需要一种能够系统评估各种标记在不同6自由度配置下性能的基准测试框架。
- Method: 开发了基于物理的射线追踪渲染算法，能够直接使用相机标定参数，生成包含畸变、散焦和衍射模糊的高保真合成图像；采用低差异采样方法系统探索6自由度空间，通过36对组合图分析各自由度与位姿误差的相关性。
- Result: 该方法成功应用于评估多种知名标记系统的位姿估计精度，揭示了它们在不同条件下的优势和局限性，为标记选择提供了科学依据。
- Conclusion: 提出的基准测试框架能够公平比较不同标记系统的位姿估计性能，开源代码促进了该领域的研究和应用，为标记系统的评估和选择提供了可靠工具。


### [126] [Evaluating the encoding competence of visual language models using uncommon actions](https://arxiv.org/abs/2601.07737)
*Chen Ling,Nai Ding*

Main category: cs.CV

TL;DR: 作者提出UAIT数据集，专门评估视觉语言模型在不常见常识动作场景中的语义理解能力，通过反常识图像-文本对测试模型超越表面模式识别的深度推理能力。

- Motivation: 现有数据集主要关注统计频率优势的常见视觉场景，缺乏对模型深度语义理解能力的测试。需要评估模型是否能理解语法合理但语义违反常识的图像-文本对，特别是代理-患者关系和物理可行性等深层语义。
- Method: 采用半自动化流程构建UAIT数据集：使用大语言模型、少样本提示工程和文本到图像生成技术合成高质量反常识图像-文本样本，每个样本配有精心设计的多选题来测试细粒度推理能力。
- Result: 评估多个最先进的视觉语言模型和对比学习模型，发现所有模型在语义判断上都显著差于人类表现，特别是在区分语法正确性和语义合理性方面。轻量级模型经过微调后准确率可提升，显示定向适应的潜力。
- Conclusion: 该研究不仅揭示了视觉语言模型的关键弱点，还为开发具有真正视觉语义推理能力的鲁棒模型提供了诊断工具和研究方向，展示了定向适应的巨大潜力。


### [127] [On the application of the Wasserstein metric to 2D curves classification](https://arxiv.org/abs/2601.07749)
*Agnieszka Kaliszewska,Monika Syga*

Main category: cs.CV

TL;DR: 提出基于Wasserstein距离的变体方法，通过离散概率度量聚焦2D曲线特定片段进行分类，应用于考古学数据聚类分析

- Motivation: 在2D曲线分类中，传统方法通常对整个曲线进行处理，但实际应用中往往需要重点关注曲线的特定部分（片段），例如考古学中的特定特征区域
- Method: 开发Wasserstein距离的多种变体，通过离散概率度量来反映曲线不同片段的重要性，从而在分类时能够聚焦于指定的曲线片段
- Result: 通过一系列实验验证了该方法在考古学2D曲线聚类分析中的性能表现
- Conclusion: 提出的Wasserstein距离变体方法能够有效聚焦于2D曲线的指定片段进行分类，在考古学数据分析中展现出实用价值


### [128] [Video Evidence to Reasoning Efficient Video Understanding via Explicit Evidence Grounding](https://arxiv.org/abs/2601.07761)
*Yanxiang Huang,Guohua Gao,Zhaoyang Wei,Jianyuan Ni*

Main category: cs.CV

TL;DR: CoE框架通过解耦感知与推理，使用轻量级证据提取模块和强化学习锚定协议，在视频理解中实现高效且可靠的推理，显著减少幻觉并提升准确性。

- Motivation: 大型视觉语言模型在视频推理中面临两难困境：要么计算成本过高（冗长推理），要么存在幻觉风险（高效但无依据的方法）。需要解决感知基础与推理效率之间的平衡问题。
- Method: 提出Chain of Evidence (CoE)框架，包含两个核心创新：1) 轻量级证据基础模块(EGM)，作为查询引导的过滤器动态提取高保真视觉证据；2) 通过强化学习优化的证据锚定协议，使用复合奖励机制强制模型在推理过程中严格引用时间锚点。
- Result: 在五个基准测试（包括Video-MME、MVBench和VSI-Bench）上，CoE增强模型建立了新的最先进水平，在准确性上显著优于现有方法。
- Conclusion: CoE是一个强大且实用的可靠视频理解范式，通过架构解耦和协同优化感知基础与推理效率，有效解决了LVLMs在视频推理中的基本困境。


### [129] [Beyond External Guidance: Unleashing the Semantic Richness Inside Diffusion Transformers for Improved Training](https://arxiv.org/abs/2601.07773)
*Lingchen Sun,Rongyuan Wu,Zhengqiang Zhang,Ruibin Li,Yujing Sun,Shuaizheng Liu,Lei Zhang*

Main category: cs.CV

TL;DR: 提出Self-Transcendence方法，仅使用内部特征监督实现DiT快速收敛，无需外部预训练模型

- Motivation: 现有方法如REPA需要依赖外部预训练网络（如DINO）来加速DiT训练，这引入了额外依赖并降低了灵活性。作者认为DiT自身有能力指导自己的训练。
- Method: 1. 先短期训练DiT，对齐其浅层特征与预训练VAE的潜在表示（约40轮）；2. 对中间特征应用classifier-free guidance，增强其判别能力和语义表达能力；3. 使用这些丰富的内部特征作为监督信号指导新的DiT训练。
- Result: 相比现有自包含方法，性能显著提升；在生成质量和收敛速度上甚至能超越REPA，且无需任何外部预训练模型；方法对不同骨干网络更灵活，有潜力应用于更广泛的基于扩散的生成任务。
- Conclusion: Self-Transcendence是一种简单有效的方法，仅通过内部特征监督实现DiT快速收敛，消除了对外部预训练模型的依赖，提高了灵活性和应用范围。


### [130] [Vision-Language Model for Accurate Crater Detection](https://arxiv.org/abs/2601.07795)
*Patrick Bauer,Marius Schwinning,Florian Renk,Andreas Weinmann,Hichem Snoussi*

Main category: cs.CV

TL;DR: 基于OWLv2视觉Transformer模型，采用LoRA参数高效微调和CIoU+对比损失组合，实现月球陨石坑高精度检测，最大召回率94.0%，精度73.1%

- Motivation: 欧洲航天局计划使用Argonaut着陆器执行月球任务，陨石坑对安全着陆构成风险，需要可靠的自动检测算法。现有挑战包括陨石坑尺寸形状多样、光照变化和复杂地形。
- Method: 采用OWLv2视觉Transformer模型，使用IMPACT项目手动标注的高分辨率月球图像数据集进行微调。通过LoRA参数高效微调策略插入可训练参数，优化CIoU定位损失和对比分类损失的组合损失函数。
- Result: 在IMPACT测试数据集上取得最大召回率94.0%和最大精度73.1%，视觉结果令人满意。方法在挑战性月球成像条件下实现可靠的陨石坑检测。
- Conclusion: 提出的深度学习方法能够有效检测月球陨石坑，为未来月球探索中的稳健陨石坑分析铺平道路，支持ESA的Argonaut着陆器安全着陆任务。


### [131] [Exchange Is All You Need for Remote Sensing Change Detection](https://arxiv.org/abs/2601.07805)
*Sijun Dong,Siming Fu,Kaiyu Li,Xiangyong Cao,Xiaoliang Meng,Bo Du*

Main category: cs.CV

TL;DR: SEED提出了一种简化的遥感变化检测范式，用参数免费的特征交换替代传统的显式差分计算，在保持性能的同时大幅简化模型结构。

- Motivation: 传统遥感变化检测方法通常使用孪生编码器并通过减法或拼接等显式差分计算模块来识别变化，这种设计较为复杂。本文挑战这种复杂性，探索更简洁有效的特征融合方式。
- Method: 提出SEED（Siamese Encoder-Exchange-Decoder）范式，通过参数免费的特征交换机制替代显式差分计算。在孪生编码器和解码器之间共享权重，使模型实际上只使用单一参数集。特征交换被形式化为正交置换算子，理论上证明在像素一致性条件下能保持互信息和贝叶斯最优风险。
- Result: 在SYSU-CD、LEVIR-CD、PX-CLCD、WaterCD和CDD五个基准数据集上，使用SwinT、EfficientNet和ResNet三种骨干网络进行实验，SEED的性能达到或超越了当前最先进方法。此外，通过插入特征交换机制，标准语义分割模型也能转变为有竞争力的变化检测器（SEG2CD）。
- Conclusion: 简单的特征交换机制足以实现高性能的信息融合，为变化检测提供了一个鲁棒、统一且可解释的框架。该范式展示了简洁设计的有效性，并提供了将语义分割模型转化为变化检测器的通用方法。


### [132] [More Images, More Problems? A Controlled Analysis of VLM Failure Modes](https://arxiv.org/abs/2601.07812)
*Anurag Das,Adrian Bulat,Alberto Baldrati,Ioannis Maniadis Metaxas,Bernt Schiele,Georgios Tzimiropoulos,Brais Martinez*

Main category: cs.CV

TL;DR: 提出了MIMIC基准来评估大视觉语言模型的多图像能力，发现了模型在多图像信息聚合和概念跟踪上的普遍问题，并提出数据生成和注意力优化的解决方案。

- Motivation: 现有的大视觉语言模型在多图像理解和推理方面的能力尚未得到充分探索，现有基准缺乏对模型核心弱点的深入分析，需要系统评估多图像能力。
- Method: 1) 提出MIMIC基准来严格评估LVLMs的多图像能力；2) 通过诊断实验揭示模型在多图像信息聚合和概念跟踪上的问题；3) 提出两种解决方案：基于数据的过程化数据生成策略和基于优化的注意力掩码方案。
- Result: 实验显示提出的方法显著改善了跨图像信息聚合能力，并在现有多图像基准测试中超越了先前的最先进方法。
- Conclusion: MIMIC基准揭示了LVLMs在多图像理解方面的核心挑战，提出的数据生成和注意力优化方法有效提升了模型的多图像能力，为未来研究提供了重要基础。


### [133] [MHLA: Restoring Expressivity of Linear Attention via Token-Level Multi-Head](https://arxiv.org/abs/2601.07832)
*Kewei Zhang,Ye Huang,Yufan Deng,Jincheng Yu,Junsong Chen,Huan Ling,Enze Xie,Daquan Zhou*

Main category: cs.CV

TL;DR: 提出多头线性注意力(MHLA)解决线性注意力中的全局上下文坍缩问题，通过沿token维度分头计算注意力，在保持线性复杂度的同时恢复softmax注意力的表达能力。

- Motivation: Transformer的自注意力机制具有二次复杂度，阻碍其在大规模应用中的使用。线性注意力虽然高效，但直接应用会导致性能下降，现有修复方法通常通过额外模块重新引入计算开销，违背了原始目的。
- Method: 提出多头线性注意力(MHLA)，通过沿token维度将注意力计算分配到多个头中，避免全局上下文坍缩，保持表示多样性。该方法在保持线性复杂度的同时恢复softmax注意力的表达能力。
- Result: 在多个领域验证了MHLA的有效性：ImageNet分类提升3.6%，NLP任务提升6.3%，图像生成提升12.6%，视频生成在相同时间复杂度下提升41%。
- Conclusion: MHLA成功解决了线性注意力中的全局上下文坍缩问题，在保持线性复杂度的同时显著提升了各种任务的性能，为高效Transformer模型提供了有效解决方案。


### [134] [Tuning-free Visual Effect Transfer across Videos](https://arxiv.org/abs/2601.07833)
*Maxwell Jones,Rameen Abdal,Or Patashnik,Ruslan Salakhutdinov,Sergey Tulyakov,Jun-Yan Zhu,Kuan-Chieh Jackson Wang*

Main category: cs.CV

TL;DR: RefVFX是一个前馈框架，能够将参考视频中的复杂时间特效转移到目标视频或图像上，解决了现有方法难以处理动态光照变化、角色变换等难以用文本描述的时间特效的问题。

- Motivation: 现有方法擅长基于提示或关键帧条件的编辑，但难以处理动态时间特效（如动态光照变化、角色变换），这些特效难以用文本或静态条件描述。视频特效转移具有挑战性，因为模型需要将新的时间动态与输入视频的现有运动和外观相整合。
- Method: 1) 构建大规模三元组数据集（参考特效视频、输入图像/视频、输出视频）；2) 提出可扩展的自动化流水线生成高质量配对视频，保持输入的运动和结构，同时基于固定、可重复的特效进行转换；3) 使用LoRA适配器增强图像到视频特效，通过程序化组合生成基于代码的时间特效；4) 基于新数据集，使用最近的文本到视频骨干网络训练参考条件模型。
- Result: 实验结果表明，RefVFX产生视觉一致且时间连贯的编辑效果，能够泛化到未见过的特效类别，在定量指标和人类偏好评估中都优于仅使用提示的基线方法。
- Conclusion: RefVFX框架成功解决了视频特效转移的挑战，通过构建大规模数据集和自动化流水线，实现了高质量、可泛化的时间特效转移，为视频编辑提供了新的有效工具。
## cs.HC

### [135] [AutoTour: Automatic Photo Tour Guide with Smartphones and LLMs](https://arxiv.org/abs/2601.06781)
*Huatao Xu,Zihe Liu,Zilin Zeng,Baichuan Li,Mo Li*

Main category: cs.HC

TL;DR: AutoTour是一个通过融合照片视觉特征与附近地理空间特征，自动生成细粒度地标标注和描述性叙述的系统，为用户提供交互式、上下文感知的探索体验。

- Motivation: 现有旅游应用依赖预定义内容或专有数据集，无法提供可扩展和上下文感知的照片引导。AutoTour旨在利用开放可扩展数据源，增强用户探索体验。
- Method: 设计免训练流程：1) 从用户GPS位置提取过滤相关地理空间特征；2) 通过VLM检测照片中主要地标并投影到水平空间平面；3) 几何匹配算法基于估计距离和方向对齐照片特征与地理空间实体；4) 匹配特征直接标注在原照片上，并配以LLM生成的文本和音频描述。
- Result: AutoTour能够为标志性和鲜为人知的地标提供丰富、可解释的标注，实现交互式、上下文感知的探索，连接视觉感知和地理空间理解。
- Conclusion: AutoTour通过融合视觉特征与开放地理空间数据，实现了可扩展的细粒度地标标注和叙述生成，为用户提供了新型的交互式探索体验。


### [136] [A Multimodal Dataset of Student Oral Presentations with Sensors and Evaluation Data](https://arxiv.org/abs/2601.07576)
*Alvaro Becerra,Ruth Cobos,Roberto Daza*

Main category: cs.HC

TL;DR: SOPHIAS是一个12小时的多模态数据集，包含50个学生口头报告，整合了8种同步传感器数据，用于研究口头报告表现与多模态行为、生理信号之间的关系。

- Motivation: 高等教育中口头报告技能至关重要，但缺乏捕捉真实学生表现的多模态综合数据集。现有数据集不足以全面分析学生在真实课堂环境中的行为、互动和生理反应。
- Method: 收集了65名本科生和硕士生在真实课堂环境中进行的50个口头报告（10-15分钟报告加5-15分钟问答）。整合了8种同步传感器数据：高清网络摄像头、环境音频和摄像头音频、眼动追踪眼镜、智能手表生理传感器、以及点击器、键盘和鼠标交互。还包括幻灯片、基于量规的教师、同伴和自我评估，以及带时间戳的情境标注。
- Result: 创建了SOPHIAS数据集，包含12小时的多模态记录，捕捉了真实课堂环境中学生的真实行为、互动和生理反应。数据集公开可用，支持研究多模态行为生理信号与报告表现的关系、同伴评估研究，并为开发自动化反馈和多模态学习分析工具提供基准。
- Conclusion: SOPHIAS填补了口头报告技能评估中多模态数据集的空白，为研究学生表现与多模态信号之间的关系提供了宝贵资源，支持开发更有效的学习分析工具和自动化反馈系统。
## cs.LG

### [137] [Judge Model for Large-scale Multimodality Benchmarks](https://arxiv.org/abs/2601.06106)
*Min-Han Shih,Yu-Hsin Wu,Yu-Wei Chen*

Main category: cs.LG

TL;DR: 提出一个专门的多模态评判模型，用于在多样化任务上提供可靠、可解释的评估，通过聚合多模态判断、分析输出质量和推理一致性，并与人类评估结果高度一致。

- Motivation: 当前多模态大语言模型评估缺乏可靠、可解释且可扩展的评估方法，需要一种能够提供诊断反馈的评判框架来支持多模态AI研究的发展。
- Method: 设计专门的多模态评判模型，构建涵盖文本、音频、图像、视频的多模态基准，从公开数据集中精心采样以确保可重复性，采用聚合多模态判断、分析输出质量和推理一致性的框架，而非简单评分。
- Result: 评估了包括Gemini 2.5、Phi 4和Qwen 2.5在内的多个MLLM，在280个多模态样本上，评判模型评估结果与人类标注者评分高度一致，显示出良好的对齐性。
- Conclusion: 该评判模型作为可扩展、可解释的评估管道，对未来多模态AI研究具有重要潜力，能够提供可靠的自动化评估和诊断反馈。


### [138] [Attention in Geometry: Scalable Spatial Modeling via Adaptive Density Fields and FAISS-Accelerated Kernels](https://arxiv.org/abs/2601.06135)
*Zhaowen Fan*

Main category: cs.LG

TL;DR: ADF是一个几何注意力框架，将空间聚合重新定义为连续空间中的查询条件化、度量诱导的注意力算子，通过FAISS加速实现可扩展性，并在成都地区飞机轨迹分析中应用。

- Motivation: 该研究旨在弥合自适应核方法与注意力机制之间的概念鸿沟，通过将空间影响重新解释为基于物理距离的几何保持注意力，为连续空间中的空间分析提供更自然的框架。
- Method: 提出自适应密度场（ADF）框架，将空间聚合公式化为查询条件化、度量诱导的注意力算子；使用FAISS加速的倒排文件索引实现可扩展性，将近似最近邻搜索作为注意力机制的内在组成部分。
- Result: 在成都地区飞机轨迹分析的案例研究中，成功提取了轨迹条件化的影响区域（ZOI），揭示了循环空域结构和局部偏差。
- Conclusion: ADF框架成功地将几何注意力概念应用于连续空间分析，为空间数据建模提供了新的视角，并在实际航空轨迹分析中展示了其有效性。


### [139] [Forget Many, Forget Right: Scalable and Precise Concept Unlearning in Diffusion Models](https://arxiv.org/abs/2601.06162)
*Kaiyuan Deng,Gen Li,Yang Xiao,Bo Hui,Xiaolong Ma*

Main category: cs.LG

TL;DR: 提出ScaPre框架，解决大规模多概念遗忘中的冲突更新、不精确机制和可扩展性瓶颈问题，实现高效精确的概念遗忘

- Motivation: 文本到图像扩散模型虽取得显著进展，但存在版权和滥用问题，需要机器遗忘技术。然而，将多概念遗忘扩展到大规模场景面临三个挑战：冲突权重更新阻碍遗忘或降低生成质量；不精确机制导致相似内容受损；依赖额外数据或模块造成可扩展性瓶颈
- Method: 提出ScaPre框架，包含冲突感知稳定设计（集成谱迹正则化和几何对齐以稳定优化、抑制冲突、保持全局结构）和Informax Decoupler（识别概念相关参数并自适应重加权更新，将遗忘严格限制在目标子空间）。该方法提供高效闭式解，无需辅助数据或子模型
- Result: 在对象、风格和显式内容上的综合实验表明，ScaPre能有效移除目标概念同时保持生成质量。在可接受质量限制内，遗忘概念数量比最佳基线多5倍，实现了大规模遗忘的最先进精度和效率
- Conclusion: ScaPre框架成功解决了大规模概念遗忘的关键挑战，通过冲突感知稳定设计和Informax Decoupler实现了精确、高效的概念移除，为扩散模型的安全应用提供了有效解决方案


### [140] [Monkey Jump : MoE-Style PEFT for Efficient Multi-Task Learning](https://arxiv.org/abs/2601.06356)
*Nusrat Jahan Prottasha,Md Kowsher,Chun-Nam Yu,Chen Chen,Ozlem Garibay*

Main category: cs.LG

TL;DR: Monkey Jump是一种无需额外可训练参数的混合专家风格参数高效微调方法，通过将现有适配器作为隐式专家并使用无梯度k-means聚类进行路由，显著减少参数和内存消耗。

- Motivation: 传统的混合专家参数高效微调方法虽然能实现每令牌专业化，但引入了额外的可训练路由器和专家参数，增加了内存使用和训练成本，这与参数高效微调的核心目标相矛盾。
- Method: Monkey Jump将Transformer块中已有的适配器（如查询、键、值、上、下投影）作为隐式专家，使用指数移动平均的k-means聚类进行令牌路由，无需梯度和学习参数。
- Result: 在14个文本、14个图像和19个视频基准测试中，Monkey Jump与基于混合专家的参数高效微调方法性能相当，但可训练参数减少7-29倍，内存消耗降低48%，训练速度提高1.5-2倍。
- Conclusion: Monkey Jump实现了混合专家风格的专业化而无需额外参数，是架构无关的通用方法，可在保持性能的同时显著提升参数效率和训练速度。


### [141] [Beyond Perfect Scores: Proof-by-Contradiction for Trustworthy Machine Learning](https://arxiv.org/abs/2601.06704)
*Dushan N. Wadduwage,Dineth Jayakody,Leonidas Zimianitis*

Main category: cs.LG

TL;DR: 该论文提出了一种基于随机反证法的机器学习模型可信度测试方法，通过精心设计的标签置换来检测模型是否依赖真实临床线索而非虚假相关性。

- Motivation: 机器学习模型在生物医学预测任务中表现出强大潜力，但由于可信度问题阻碍了其临床采用。主要担忧在于难以判断模型是否依赖真实临床线索还是数据中的虚假层次相关性。
- Method: 基于随机反证法，提出简单但广泛适用的可信度测试方法。该方法在基于潜在结果框架精心置换的虚假标签上训练和测试模型。真正可信的模型应在标签置换下失效，而在真实和置换标签上表现相当的准确性则表明过拟合、捷径学习或数据泄漏。通过可解释的Fisher式p值量化这种行为。
- Result: 该方法在多个新的细菌诊断任务上进行了评估，成功区分了学习真实因果关系的任务和模型与那些由数据集伪影或统计巧合驱动的任务和模型。
- Conclusion: 该工作为在机器学习和生命科学研究社区之间建立严谨性和信任奠定了基础，使机器学习模型向临床采用迈进了一步。


### [142] [Explainable Deep Radiogenomic Molecular Imaging for MGMT Methylation Prediction in Glioblastoma](https://arxiv.org/abs/2601.07035)
*Hasan M Jamil*

Main category: cs.LG

TL;DR: 基于多参数MRI的AI放射基因组学框架，用于无创预测胶质母细胞瘤MGMT启动子甲基化状态

- Motivation: 胶质母细胞瘤预后差，传统MGMT状态检测依赖侵入性活检，存在肿瘤异质性和手术风险，需要无创预测方法
- Method: 整合放射组学、深度学习和可解释AI，从多序列MRI提取特征，使用3D卷积神经网络学习深度表示，采用早期融合和注意力机制融合特征，应用Grad-CAM和SHAP进行可解释性分析
- Result: 在RSNA-MICCAI数据集上训练，在BraTS 2021数据集上进行外部验证，展示了AI驱动的放射基因组学在精准肿瘤学中的潜力
- Conclusion: 该框架推进了分子影像学领域，支持胶质母细胞瘤临床可操作分子生物标志物的无创、准确和可解释预测


### [143] [OceanSAR-2: A Universal Feature Extractor for SAR Ocean Observation](https://arxiv.org/abs/2601.07392)
*Alexandre Tuel,Thomas Kerdreux,Quentin Febvre,Alexis Mouche,Antoine Grouazel,Jean-Renaud Miadana,Antoine Audras,Chen Wang,Bertrand Chapron*

Main category: cs.LG

TL;DR: OceanSAR-2是第二代SAR海洋观测基础模型，通过改进的自监督学习和动态数据筛选策略，在降低训练成本的同时提升了性能，并在多个下游任务中表现出色。

- Motivation: 开发更高效、性能更强的SAR海洋观测基础模型，为海洋应用提供系统化的评估基准，推动SAR模型在海洋领域的进步。
- Method: 基于改进的自监督学习（SSL）训练方法和动态数据筛选策略，在Sentinel-1 Wave Mode数据上进行训练，降低了训练成本。
- Result: 模型在多个下游任务中表现出强大的迁移性能，包括地球物理模式分类、海面风矢量估计、有效波高估计和冰山检测。
- Conclusion: OceanSAR-2作为第二代SAR海洋观测基础模型，通过改进的训练策略实现了性能提升和成本降低，同时发布了标准化基准数据集，为SAR海洋应用模型的系统评估和发展奠定了基础。


### [144] [Task Prototype-Based Knowledge Retrieval for Multi-Task Learning from Partially Annotated Data](https://arxiv.org/abs/2601.07474)
*Youngmin Oh,Hyung-Il Kim,Jung Uk Kim*

Main category: cs.LG

TL;DR: 提出基于原型知识检索的框架，解决部分标注多任务学习中的负迁移问题，通过任务原型和知识检索transformer实现鲁棒的多任务学习。

- Motivation: 现实应用中多任务学习很重要，但获取所有任务的完整标注数据成本高昂。现有部分标注MTL方法依赖未标注任务的预测，难以建立可靠的任务关联，可能导致负迁移和性能下降。
- Method: 提出原型知识检索框架：1) 任务原型嵌入任务特定特征并量化任务关联；2) 知识检索transformer基于这些关联自适应优化特征表示。引入关联知识生成(AKG)损失确保任务原型持续捕获任务特定特征。
- Result: 大量实验证明该框架的有效性，即使在只有部分任务被标注的情况下，也能实现鲁棒的多任务学习。
- Conclusion: 提出的原型知识检索框架解决了部分标注多任务学习中的关键问题，通过建立可靠的任务关联避免了负迁移，为实际应用中的多任务学习提供了有效解决方案。
## cs.IR

### [145] [PixRec: Leveraging Visual Context for Next-Item Prediction in Sequential Recommendation](https://arxiv.org/abs/2601.06458)
*Sayak Chakrabarty,Souradip Pal*

Main category: cs.IR

TL;DR: PixRec是一个视觉语言推荐框架，通过结合文本属性和产品图像，在顺序推荐任务中显著超越纯文本推荐器。

- Motivation: 当前基于大语言模型的顺序推荐方法主要依赖文本信息，忽视了现实推荐场景（特别是电子商务）中丰富的视觉信息。许多商品具有相似的文本描述但视觉特征不同，需要多模态方法来提升推荐准确性。
- Method: 提出PixRec框架，采用视觉语言模型作为骨干，联合处理图像-文本序列。保持双塔结构和混合训练目标，同时对物品-物品和用户-物品交互的多模态特征投影进行对齐。使用亚马逊评论数据集并增强产品图像。
- Result: 在亚马逊评论数据集上的实验显示，相比纯文本推荐器，在top-rank准确率上提升3倍，在top-10准确率上提升40%。这表明视觉特征有助于区分文本描述相似的物品。
- Conclusion: 视觉信息在顺序推荐中具有重要价值，PixRec框架为构建利用视觉信息的软件系统迈出了一步。未来方向包括扩展多模态推荐器训练、增强视觉-文本特征融合以及评估推理时性能。


### [146] [ReinPool: Reinforcement Learning Pooling Multi-Vector Embeddings for Retrieval System](https://arxiv.org/abs/2601.07125)
*Sungguk Cha,DongWook Kim,Mintae Kim,Youngsub Han,Byoung-Ki Jeon,Sangyeob Lee*

Main category: cs.IR

TL;DR: ReinPool使用强化学习动态筛选和池化多向量嵌入，将存储压缩746-1249倍，同时恢复76-81%的检索性能，显著优于静态平均池化方法。

- Motivation: 多向量嵌入模型虽然能保留细粒度的视觉和文本细节，但存储每个token的嵌入会使索引大小膨胀1000倍以上，严重限制了可扩展性。需要一种方法在保持检索性能的同时大幅压缩表示。
- Method: 提出ReinPool强化学习框架，通过逆检索目标和基于NDCG的奖励，学习动态筛选和池化多向量嵌入为紧凑的检索优化表示，无需手动重要性标注。
- Result: 在Vidore V2基准测试中，ReinPool将多向量表示压缩746-1249倍为单向量，恢复76-81%的全多向量检索性能，相比静态平均池化基线获得22-33%的绝对NDCG@3提升。
- Conclusion: 学习的选择机制显著优于启发式聚合方法，ReinPool能够在保持检索性能的同时大幅压缩多向量嵌入，解决了多向量模型的可扩展性问题。
## cs.CY

### [147] [Using street view images and visual LLMs to predict heritage values for governance support: Risks, ethics, and policy implications](https://arxiv.org/abs/2601.06056)
*Tim Johansson,Mikael Mangold,Kristina Dabrock,Anna Donarelli,Ingrid Campo-Ruiz*

Main category: cs.CY

TL;DR: 使用多模态大语言模型分析瑞典街景图像，识别具有遗产价值的建筑，为瑞典建筑改造计划提供数据支持

- Motivation: 欧盟能源绩效建筑指令要求成员国制定国家建筑改造计划，但瑞典缺乏建筑遗产价值国家登记册，这成为制定改造计划的障碍
- Method: 使用多模态大语言模型对瑞典全国154,710张街景图像进行零样本预测，识别具有潜在遗产价值的建筑
- Result: 识别出500万平方米供暖建筑面积的潜在遗产价值建筑，为瑞典建筑改造计划提供数据基础
- Conclusion: LLM方法可为建筑改造计划提供支持，但需关注透明度、错误检测和迎合性等风险问题
## cs.AI

### [148] [Circuit Mechanisms for Spatial Relation Generation in Diffusion Transformers](https://arxiv.org/abs/2601.06338)
*Binxu Wang,Jingxuan Fan,Xu Pan*

Main category: cs.AI

TL;DR: 研究通过机制可解释性方法分析DiT如何生成正确的物体空间关系，发现不同文本编码器导致不同的电路机制，影响模型鲁棒性。

- Motivation: 尽管DiT在文本到图像生成方面取得进展，但模型在生成文本提示中指定的物体间正确空间关系方面仍有困难。本研究旨在通过机制可解释性方法探究DiT如何生成正确的空间关系。
- Method: 采用机制可解释性方法，从头训练不同大小的DiT模型，使用不同文本编码器（随机文本嵌入和预训练的T5编码器），学习生成包含两个物体及其属性和空间关系的图像。
- Result: 所有模型都能近乎完美地学习该任务，但底层机制因文本编码器选择而显著不同：使用随机文本嵌入时，空间关系信息通过两阶段电路传递；使用T5编码器时，DiT使用不同的电路，利用文本令牌中的信息融合。
- Conclusion: 虽然两种设置下的域内性能相似，但它们对域外扰动的鲁棒性不同，这可能表明在真实场景中生成正确关系的困难性。
## eess.IV

### [149] [Deep Joint Source-Channel Coding for Wireless Video Transmission with Asymmetric Context](https://arxiv.org/abs/2601.06170)
*Xuechen Chen,Junting Li,Chuang Chen,Hairong Lin,Yishen Li*

Main category: eess.IV

TL;DR: 提出基于条件编码和非对称上下文的高效深度联合信源信道编码方法，用于视频传输，通过特征传播和内容自适应编码提升性能并减少误差累积。

- Motivation: 传统条件编码的神经视频压缩需要从相同上下文预测编码和解码条件，但在JSCC方案中，即使编码器构建了模拟传输管道，也无法推断与解码器相同的重建帧，这限制了性能。
- Method: 1) 设计神经网络从非对称上下文学习编码和解码条件；2) 引入特征传播，允许中间特征在编码器和解码器独立传播以生成条件；3) 实现内容自适应编码，使用熵模型和掩码机制实现可变带宽传输。
- Result: 实验结果表明，该方法在性能上优于现有深度视频传输框架，有效缓解了误差累积问题。通过减少误差累积，可以降低插入帧内编码模式的频率，进一步提升性能。
- Conclusion: 提出的基于条件编码和非对称上下文的高效深度JSCC方法通过特征传播和内容自适应编码，显著提升了视频传输性能，有效解决了误差累积问题，为视频传输提供了更优的解决方案。


### [150] [Real-Time Image Processing Algorithms for Embedded Systems](https://arxiv.org/abs/2601.06243)
*Soundes Oumaima Boufaida,Abdemadjid Benmachiche,Majda Maatallah*

Main category: eess.IV

TL;DR: 该研究针对嵌入式视觉系统，优化了边缘检测、角点检测和斑点检测算法，通过算法架构优化、量化技术、帧间冗余消除和自适应帧平均等方法，在DSP和FPGA上实现了速度更快、能效更高的图像处理。

- Motivation: 嵌入式视觉系统需要在资源受限的硬件上实现实时图像处理，但现有算法在延迟、精度和功耗方面存在挑战，需要优化算法和硬件协同设计以满足汽车、监控和机器人等领域的实际应用需求。
- Method: 采用优化的算法架构和量化技术，结合帧间冗余消除和自适应帧平均方法，在DSP和FPGA等嵌入式处理器上实现边缘检测、角点检测和斑点检测算法。
- Result: 仿真和硬件试验表明，相比传统实现方法，所提出的方法在速度和能效方面都有显著提升，为嵌入式成像系统提供了可扩展且经济的解决方案。
- Conclusion: 该研究强调了算法与硬件架构协同设计的重要性，为汽车、监控和机器人等领域的实时嵌入式视觉应用提供了可行的技术路径，证明了优化方法在嵌入式图像处理中的有效性。


### [151] [Performance Analysis of DCT, Hadamard, and PCA in Block-Based Image Compression](https://arxiv.org/abs/2601.06273)
*Yashika Ahlawat*

Main category: eess.IV

TL;DR: 论文通过实验比较DCT、Hadamard和PCA在不同块大小和压缩率下的性能，发现PCA仅在块维度足够大时才优于固定变换，而DCT在标准8×8块大小和低比特率下接近最优。

- Motivation: 研究数据驱动的PCA变换与固定变换（如DCT）在图像压缩中的性能差异，解释为什么DCT在实际编解码器中如此鲁棒，并探索基于块的学得变换的局限性。
- Method: 使用率失真分析和能量压缩分析，对DCT、Hadamard和PCA在多种块大小和压缩率下进行实验比较。
- Result: PCA仅在块维度足够大时才优于固定变换，而DCT在标准8×8块大小和低比特率下接近最优，这解释了DCT在实际编解码器中的鲁棒性。
- Conclusion: DCT在标准块大小下仍然是最优或接近最优的选择，而基于块的学得变换在实际应用中存在局限性，这支持了传统编解码器中继续使用DCT的合理性。


### [152] [R$^3$D: Regional-guided Residual Radar Diffusion](https://arxiv.org/abs/2601.06465)
*Hao Li,Xinqi Liu,Yaoqing Jin*

Main category: eess.IV

TL;DR: R3D是一个区域引导的残差雷达扩散框架，通过残差扩散建模和sigma自适应区域引导，提升毫米波雷达点云质量，在低噪声阶段对关键区域进行轻量级引导，优于现有方法。

- Motivation: 毫米波雷达在恶劣条件下能实现鲁棒的环境感知，但存在点云稀疏、噪声大、角分辨率低的问题。现有基于扩散的雷达增强方法要么需要建模完整的LiDAR分布导致学习复杂度高，要么由于均匀区域处理而未能优先处理关键结构。
- Method: 提出R3D框架：1）残差扩散建模，专注于LiDAR-雷达残差编码，捕捉互补的高频细节以降低学习难度；2）sigma自适应区域引导，利用雷达特定信号特性生成注意力图，仅在低噪声阶段应用轻量级引导，避免梯度不平衡同时细化关键区域。
- Result: 在ColoRadar数据集上的大量实验表明，R3D优于最先进的方法，为雷达感知增强提供了实用解决方案。
- Conclusion: R3D通过残差扩散建模和自适应区域引导，有效解决了现有雷达增强方法的学习复杂度和关键区域处理问题，为毫米波雷达感知提供了高质量的增强方案。


### [153] [USFetal: Tools for Fetal Brain Ultrasound Compounding](https://arxiv.org/abs/2601.06726)
*Mohammad Khateri,Morteza Ghahremani,Sergio Valencia,Camilo Jaimes,Alejandra Sierra,Jussi Tohka,P. Ellen Grant,Davood Karimi*

Main category: eess.IV

TL;DR: 该论文系统综述了胎儿脑部超声复合技术，提出了首个分类体系，实现了四种代表性方法比较，引入了两种新的深度学习策略，并在10个数据集上进行了全面评估，发布了公开工具包。

- Motivation: 超声是胎儿脑部成像的安全、经济、易获取技术，但存在视角依赖伪影、操作者变异性、视野有限等问题，使得解释和定量评估困难。超声复合技术旨在通过整合多个3D采集的互补信息来克服这些限制。
- Method: 1) 首次系统分类胎儿脑部超声复合的计算策略；2) 实现并比较四种关键类别方法：多尺度、基于变换、变分和深度学习；3) 针对缺乏完整视角无伪影标注数据的问题，专注于无监督和自监督策略，引入两种新深度学习方法：自监督复合框架和基于无监督深度即插即用先验的复合方法；4) 在10个多视角胎儿脑部超声数据集上进行综合评估。
- Result: 1) 建立了首个胎儿脑部超声复合技术分类体系；2) 实现了四种代表性方法的比较分析；3) 提出了两种新的深度学习复合方法；4) 在10个数据集上进行了专家评分和定量图像质量指标评估；5) 发布了公开的USFetal Compounding Toolbox工具包。
- Conclusion: 该研究为胎儿脑部超声复合提供了系统框架和工具，特别针对缺乏标注数据的问题提出了无监督和自监督解决方案，发布的工具包将支持基准测试和未来研究，推动超声复合技术的发展。


### [154] [Fast Multi-Stack Slice-to-Volume Reconstruction via Multi-Scale Unrolled Optimization](https://arxiv.org/abs/2601.07519)
*Margherita Firenze,Sean I. Young,Clinton J. Wang,Hyuk Jin Yun,Elfar Adalsteinsson,Kiho Im,P. Ellen Grant,Polina Golland*

Main category: eess.IV

TL;DR: 提出快速卷积框架，通过融合多个正交2D切片堆栈来重建3D结构，并利用轻量级优化细化切片对齐，应用于胎儿脑MRI，在10秒内完成高质量3D重建，速度远超现有方法。

- Motivation: 虽然全卷积网络在现代医学影像中已成为主流，但其在切片到体积重建（SVR）任务中的潜力尚未充分探索。SVR需要从错位的2D采集数据中联合估计3D解剖结构和切片姿态，现有方法效率较低。
- Method: 提出快速卷积框架，融合多个正交2D切片堆栈来恢复连贯的3D结构，使用非刚性位移场表示变换，并通过轻量级模型优化细化切片对齐。该方法可泛化到其他SVR问题如胎儿身体和胎盘MRI。
- Result: 应用于胎儿脑MRI时，该方法在10秒内重建出高质量3D体积，其中切片配准仅需1秒，精度与最先进的迭代SVR流程相当，但速度大幅提升。快速推理时间为MRI采集期间的实时体积反馈提供了可能。
- Conclusion: 该框架展示了卷积网络在SVR任务中的强大潜力，实现了快速、高质量的3D重建，为实时、扫描仪侧的体积反馈开辟了新途径，具有广泛的临床应用前景。
## cs.DC

### [155] [SC-MII: Infrastructure LiDAR-based 3D Object Detection on Edge Devices for Split Computing with Multiple Intermediate Outputs Integration](https://arxiv.org/abs/2601.07119)
*Taisuke Noguchi,Takayuki Nishio,Takuya Azumi*

Main category: cs.DC

TL;DR: 提出SC-MII方法，通过边缘设备处理初始DNN层并将中间输出发送到边缘服务器，实现多基础设施LiDAR的3D物体检测，降低延迟和设备负载

- Motivation: 当前基于LiDAR的3D物体检测模型在边缘设备部署面临计算需求高、能耗大的挑战，且单LiDAR设置存在盲点问题
- Method: SC-MII（Split Computing with Multiple Intermediate outputs Integration）：边缘设备处理本地点云的初始DNN层，将中间输出发送到边缘服务器，服务器集成这些特征并完成推理
- Result: 在真实数据集上实现2.19倍加速，边缘设备处理时间减少71.6%，精度最多下降1.09%
- Conclusion: SC-MII方法有效降低了边缘设备的计算负载和延迟，同时保护隐私，为自动驾驶中的多基础设施LiDAR3D检测提供了实用解决方案
## cs.RO

### [156] [Semantic Enrichment of CAD-Based Industrial Environments via Scene Graphs for Simulation and Reasoning](https://arxiv.org/abs/2601.06415)
*Nathan Pascal Walus,Ranulfo Bezerra,Shotaro Kojima,Tsige Tadesse Alemayoh,Satoshi Tadokoro,Kazunori Ohno*

Main category: cs.RO

TL;DR: 提出一种离线方法，从CAD环境创建详细的3D场景图，通过大型视觉语言模型增强语义、空间和功能信息，用于机器人训练和动态仿真

- Motivation: 工业环境中的功能元素（如显示屏和交互阀门）对机器人训练很重要，但CAD文件通常缺乏语义、关系和功能信息，限制了仿真和训练的可能性
- Method: 使用离线方法从CAD环境创建3D场景图，通过大型视觉语言模型（LVLM）增强环境的语义、空间和功能信息，特别关注管道结构和功能关系识别
- Result: 提供了生成语义标签的定量结果和场景图的定性结果，特别在管道结构和识别的功能关系方面，所有代码、结果和环境都将公开
- Conclusion: 提出的3D场景图方法能够有效组织CAD环境的语义、空间和功能信息，为动态仿真和推理提供基础，特别适用于工业环境中的机器人训练


### [157] [CulinaryCut-VLAP: A Vision-Language-Action-Physics Framework for Food Cutting via a Force-Aware Material Point Method](https://arxiv.org/abs/2601.06451)
*Hyunseo Koh,Chang-Yong Song,Youngjae Choi,Misa Viveiros,David Hyde,Heewon Kim*

Main category: cs.RO

TL;DR: 提出一个结合视觉-语言-动作数据集与基于物质点法的物理切割模拟器的统一框架，用于解决食品切割这一具有挑战性的机器人操作任务。

- Motivation: 食品切割是视觉与机器人操作交叉领域的重要应用，但由于刀具与可变形材料之间的高度非线性交互、大变形、频繁接触和拓扑变化，导致数据收集困难且危险。
- Method: 1. 基于MLS-MPM的物质点法模拟器，减少数值耗散和能量漂移，保持旋转和剪切响应；2. 通过粒子与网格间的脉冲交换估计力和应力分布；3. 提供包含多样化切割轨迹、多视角视觉观察、细粒度语言指令以及力-扭矩和工具姿态标签的基准数据集。
- Result: 建立了一个尊重切割核心物理原理的学习-评估循环，为在可变形物体操作中推进视觉-语言-动作模型提供了安全、可重复和可扩展的基础。
- Conclusion: 该框架通过结合物理精确的模拟器和丰富的多模态数据集，为解决食品切割等复杂机器人操作任务提供了系统性的解决方案，促进了视觉-语言-动作模型在可变形物体操作领域的发展。


### [158] [Precision Meets Art: Autonomous Multi-UAV System for Large Scale Mural Drawing](https://arxiv.org/abs/2601.06508)
*Andrei A. Korigodskii,Artem E. Vasiunik,Georgii A. Varin,Adilia M. Zukhurova,Matvei V. Urvantsev,Semen A. Osipenkov,Igor S. Efremov,Georgii E. Bondar*

Main category: cs.RO

TL;DR: 开发了一个用于户外自动壁画绘制的多无人机系统，结合了2D定位和LiDAR的复杂定位系统，以及新型飞行控制算法，成功绘制了100平方米的壁画，相比单无人机方法显著提升了可扩展性和操作速度。

- Motivation: 将自主无人机集成到大规模艺术项目中是机器人学的新应用领域，需要解决多无人机协调、精确定位和稳定飞行控制等技术挑战，以实现高效、高质量的户外壁画创作。
- Method: 设计了新型多无人机系统，采用状态机算法协调多无人机同时工作；开发了结合单运动跟踪相机2D定位和机载LiDAR的复杂定位系统；提出了沿轨迹方向和垂直方向工作方式不同的新型飞行控制算法，确保绘图平滑性和高精度。
- Result: 成功使用开发的多无人机系统绘制了100平方米的壁画，验证了系统有效性；相比单无人机方法，显著提高了可扩展性和操作速度，同时在恶劣天气条件下保持高稳定性。
- Conclusion: 自主机器人群体在创意应用中具有巨大潜力，该多无人机系统为大规模机器人艺术的发展铺平了道路，展示了自主无人机在艺术创作中的实际应用价值。


### [159] [ObjSplat: Geometry-Aware Gaussian Surfels for Active Object Reconstruction](https://arxiv.org/abs/2601.06997)
*Yuetao Li,Zhizhou Jia,Yu Zhang,Qun Hao,Shaohui Zhang*

Main category: cs.RO

TL;DR: ObjSplat：基于高斯面元的主动重建框架，通过几何感知视点评估和多步前瞻规划，高效重建具有真实感外观和精确几何的未知物体

- Motivation: 自主高保真物体重建是创建数字资产和弥合机器人仿真与现实差距的基础。传统方法在复杂几何物体上存在局限性，需要更智能的主动重建方法。
- Method: 使用高斯面元作为统一表示；引入几何感知视点评估管道，显式建模背面可见性和遮挡感知多视角共视性；采用基于动态构建空间图的多步前瞻规划器（NBP），联合优化信息增益和移动成本。
- Result: 在仿真和真实世界文化遗产上的实验表明，ObjSplat能在几分钟内生成物理一致的模型，相比现有方法在重建保真度、表面完整性和扫描时间/路径长度方面均有显著提升。
- Conclusion: ObjSplat通过创新的视点评估和规划策略，实现了高效、高质量的主动物体重建，为数字资产创建和机器人应用提供了实用解决方案。


### [160] [HERE: Hierarchical Active Exploration of Radiance Field with Epistemic Uncertainty Minimization](https://arxiv.org/abs/2601.07242)
*Taekbeom Lee,Dabin Kim,Youngseok Jang,H. Jin Kim*

Main category: cs.RO

TL;DR: HERE：基于神经辐射场的主动3D场景重建框架，通过认知不确定性量化识别未探索区域，采用分层探索策略实现高效数据采集和精确重建

- Motivation: 现有主动3D重建方法难以可靠识别未探索或重建质量差的区域，导致数据采集效率低和重建不完整。需要一种能直接捕捉数据不足并指导针对性探索的方法。
- Method: 1. 基于证据深度学习的认知不确定性量化，直接关联重建误差；2. 分层探索策略：局部规划从高不确定性体素提取目标视点，全局规划指导大规模覆盖；3. 主动学习驱动的相机轨迹生成。
- Result: 在多种尺度的逼真模拟场景中，相比现有方法实现了更高的重建完整性。硬件演示进一步验证了其实际应用可行性。
- Conclusion: HERE框架通过认知不确定性量化和分层探索策略，有效解决了主动3D重建中的未探索区域识别问题，实现了高效数据采集和高质量场景重建。
## q-bio.NC

### [161] [Gamma2Patterns: Deep Cognitive Attention Region Identification and Gamma-Alpha Pattern Analysis](https://arxiv.org/abs/2601.06257)
*Sobhana Jahan,Saydul Akbar Murad,Nick Rahimi,Noorbakhsh Amiri Golilarz*

Main category: q-bio.NC

TL;DR: Gamma2Patterns：一个结合Gamma/Alpha脑电与眼动追踪的多模态框架，用于表征深度认知注意，识别前额、颞叶等关键脑区在深度专注中的主导作用。

- Motivation: 尽管深度认知注意以增强的Gamma振荡和协调的视觉行为为特征，但计算研究很少综合这些模态或识别维持专注的关键神经区域。现有研究缺乏对这些生理机制的综合分析。
- Method: 提出Gamma2Patterns多模态框架，结合Gamma和Alpha频段EEG活动与眼动追踪测量。使用SEED-IV数据集，从62个通道提取频谱功率、爆发式时域动态以及注视-扫视-瞳孔信号，分析高专注（Gamma主导）和低专注（Alpha主导）状态下的神经激活差异。
- Result: 发现前额极、颞叶、前额叶和顶枕区域表现出最强的Gamma功率和爆发率，表明这些区域在深度注意参与中起主导作用。眼动信号确认了额叶、前额极和额颞区域的补充贡献。Gamma功率和爆发持续时间比Alpha功率单独提供更具区分度的深度专注标记。
- Conclusion: 研究建立了深度专注的皮层区域和振荡特征的多模态证据图谱，为未来AI系统中脑启发的注意机制提供了神经生理学基础。
## cs.CL

### [162] [TeleMem: Building Long-Term and Multimodal Memory for Agentic AI](https://arxiv.org/abs/2601.06037)
*Chunliang Chen,Ming Guan,Xiao Lin,Jiaxu Li,Qiyi Wang,Xiangyu Chen,Jixiang Luo,Changzhi Sun,Dell Zhang,Xuelong Li*

Main category: cs.CL

TL;DR: TeleMem是一个统一的长时多模态记忆系统，通过叙事动态提取维护连贯用户画像，采用结构化写入管道提升存储效率，结合ReAct推理实现视频内容理解，在长时角色扮演任务上显著优于现有方法。

- Motivation: 大型语言模型在长时对话中因注意力限制而表现不佳，现有检索增强生成方法缺乏可靠的记忆更新机制，存在模式驱动的幻觉、写入效率低、多模态推理支持不足等问题。
- Method: 1) 叙事动态提取确保只保存对话基础信息；2) 结构化写入管道批量处理、检索、聚类和整合记忆条目；3) 多模态记忆模块结合ReAct推理，实现观察-思考-行动的闭环过程。
- Result: 在ZH-4O长时角色扮演游戏基准测试中，TeleMem比最先进的Mem0基线准确率高19%，token使用减少43%，速度提升2.1倍。
- Conclusion: TeleMem通过统一的长时多模态记忆系统有效解决了现有方法的局限性，在保持准确性的同时显著提升了效率和速度，为长时交互系统提供了有力支持。


### [163] [Forest Before Trees: Latent Superposition for Efficient Visual Reasoning](https://arxiv.org/abs/2601.06803)
*Yubo Wang,Juntian Zhang,Yichen Wu,Yankai Lin,Nils Lukas,Yuhan Liu*

Main category: cs.CL

TL;DR: Laser提出了一种新的视觉推理范式，通过动态窗口对齐学习实现"先森林后树木"的认知层次，在保持可解释性的同时显著减少推理token并提升性能。

- Motivation: 现有视觉语言模型的思维链方法存在信息带宽瓶颈，视觉细节在离散化过程中丢失；而潜在推理方法又容易因刚性自回归目标导致过早的语义崩溃。
- Method: 提出Laser范式，采用动态窗口对齐学习：将潜在状态与未来语义的动态有效窗口对齐，实现"先森林后树木"的认知层次；通过自精化叠加稳定无约束学习，同时保持可解码轨迹的可解释性。
- Result: 在6个基准测试中达到潜在推理方法的最先进性能，平均超越强基线Monet 5.03%；推理token减少97%以上，且在分布外领域展现出鲁棒泛化能力。
- Conclusion: Laser通过动态窗口对齐学习有效解决了视觉推理中的信息瓶颈和语义崩溃问题，在保持可解释性的同时实现了高效且鲁棒的视觉推理。
## cs.CR

### [164] [Leveraging Membership Inference Attacks for Privacy Measurement in Federated Learning for Remote Sensing Images](https://arxiv.org/abs/2601.06200)
*Anh-Kiet Duong,Petra Gomez-Krämer,Hoàng-Ân Lê,Minh-Tan Pham*

Main category: cs.CR

TL;DR: 本文利用成员推理攻击作为联邦学习在遥感图像分类中的隐私评估框架，发现通信高效的FL策略能降低攻击成功率同时保持性能。

- Motivation: 尽管联邦学习将训练数据本地化以保护隐私，但研究表明FL模型仍可能通过输出泄露敏感信息，因此需要严格的隐私评估方法。
- Method: 采用成员推理攻击作为量化隐私测量框架，评估多种黑盒MIA技术（包括基于熵的攻击、改进熵攻击和似然比攻击），在不同FL算法和通信策略上进行测试。
- Result: 在两个公开场景分类数据集上的实验表明，MIA能有效揭示仅靠准确性无法捕捉的隐私泄露。通信高效的FL策略能降低MIA成功率，同时保持有竞争力的性能。
- Conclusion: MIA可作为实用的隐私评估指标，强调了将隐私测量集成到遥感应用FL系统设计中的重要性。


### [165] [From Easy to Hard++: Promoting Differentially Private Image Synthesis Through Spatial-Frequency Curriculum](https://arxiv.org/abs/2601.06368)
*Chen Gong,Kecen Li,Zinan Lin,Tianhao Wang*

Main category: cs.CR

TL;DR: FETA-Pro：一种结合空间特征和频率特征的差分隐私合成图像生成方法，通过辅助生成器处理频率特征，再结合空间特征和DP-SGD训练，在隐私预算ε=1时比基线方法平均提高25.7%的保真度和4.1%的效用。

- Motivation: 现有DP-FETA方法主要适用于图像相似度高的数据集，但对于图像差异较大的场景效果有限。本文旨在探索除DP-SGD外还能结合使用的其他工具，特别是针对图像变化显著的情况。
- Method: 提出FETA-Pro方法：1）引入频率特征作为"训练捷径"，其复杂度介于空间特征和完整图像之间；2）利用生成模型的流水线特性，设计辅助生成器生成与噪声频率特征对齐的图像；3）另一个模型使用这些图像，结合空间特征和DP-SGD进行训练。
- Result: 在五个敏感图像数据集上评估，在隐私预算ε=1时，FETA-Pro比最佳基线方法平均提高25.7%的保真度和4.1%的效用。
- Conclusion: FETA-Pro通过结合空间和频率特征，并利用生成模型流水线特性，有效解决了图像差异显著场景下的差分隐私合成图像质量问题，显著提升了生成效果。


### [166] [VIPER Strike: Defeating Visual Reasoning CAPTCHAs via Structured Vision-Language Inference](https://arxiv.org/abs/2601.06461)
*Minfeng Qi,Dongyang He,Qin Wang,Lefeng Zhang*

Main category: cs.CR

TL;DR: ViPer是一个统一的视觉推理CAPTCHA攻击框架，结合结构化视觉感知和自适应LLM推理，在六个主流VRC提供商上达到93.2%成功率，接近人类水平。

- Motivation: 现有视觉推理CAPTCHA（VRC）攻击方法存在局限性：视觉中心方法依赖特定模板检测器，无法处理新布局；推理中心方法使用LLM但细粒度视觉感知能力不足。两者都缺乏处理异构VRC部署的通用性。
- Method: ViPer框架整合结构化多对象视觉感知与自适应LLM推理，通过模块化流程解析视觉布局、将属性与问题语义对齐，并推断目标坐标。还提出模板空间随机化（TSR）防御策略，通过扰动语言模板而不改变任务语义来降低攻击成功率。
- Result: 在六个主流VRC提供商（VTT、Geetest、NetEase、Dingxiang、Shumei、Xiaodun）上达到93.2%成功率，接近人类水平。相比现有方法（GraphNet 83.2%、Oedipus 65.8%、Holistic 89.5%）表现更优。在不同LLM骨干（GPT、Grok、DeepSeek、Kimi）上保持90%以上准确率。
- Conclusion: ViPer展示了结合视觉感知和语言推理的统一攻击框架的有效性，同时提出的TSR防御策略为设计人类可解但机器难解的CAPTCHA提供了方向。


### [167] [qAttCNN - Self Attention Mechanism for Video QoE Prediction in Encrypted Traffic](https://arxiv.org/abs/2601.06862)
*Michael Sidorov,Ofer Hadar*

Main category: cs.CR

TL;DR: 提出qAttCNN模型，利用流量包大小参数从加密视频通话中推断无参考QoE指标（BRISQUE和FPS），解决ISP无法访问原始媒体流的问题。

- Motivation: 随着视频会议和即时通讯应用的普及，WebRTC协议被广泛使用，但网络条件恶化会降低流媒体质量和用户体验。由于端到端加密，互联网服务提供商无法访问原始媒体流，只能获取QoS和路由信息，难以准确评估QoE。
- Method: 提出QoE注意力卷积神经网络（qAttCNN），利用流量包大小参数来推断两个无参考QoE指标：BRISQUE（图像质量评估）和帧率（FPS）。在自定义的WhatsApp视频通话数据集上进行评估。
- Result: 使用平均绝对误差百分比（MAEP）评估，qAttCNN在BRISQUE预测上达到2.14%误差，在FPS预测上达到7.39%误差，优于现有QoE模型。
- Conclusion: qAttCNN能够有效从加密视频通话流量中准确推断QoE指标，为ISP在无法访问原始媒体内容的情况下监控和改善用户体验提供了可行方案。


### [168] [Proof of Reasoning for Privacy Enhanced Federated Blockchain Learning at the Edge](https://arxiv.org/abs/2601.07134)
*James Calo,Benny Lo*

Main category: cs.CR

TL;DR: 提出Proof of Reasoning (PoR)共识机制，专门为区块链上的联邦学习设计，通过掩码自编码器保护数据隐私，实现高效可验证的聚合，降低计算复杂度并保持高精度。

- Motivation: 现有区块链共识机制大多不直接针对联邦学习，也不支持聚合步骤。需要一种专门为联邦学习设计的共识机制来保护数据隐私、防御恶意攻击，并增强参与网络的验证能力。
- Method: PoR包含三个定制化过程：1) 训练掩码自编码器(MAE)生成编码器作为特征映射，混淆输入数据以抵抗重建和模型反转攻击；2) 在边缘训练下游分类器，接收编码器输出；3) 将网络权重、编码数据点、网络输出和真实标签加入区块进行联邦聚合，支持更复杂可验证的聚合方法。
- Result: PoR产生更鲁棒的网络，显著降低计算复杂度，通过仅在边缘训练下游分类器保持高精度。能够扩展到大型物联网网络，具有低延迟和存储增长，并能适应数据、法规和网络条件的变化。
- Conclusion: PoR是一种专门为联邦学习设计的创新共识机制，有效解决了数据隐私保护、恶意攻击防御和网络验证问题，为大规模物联网环境下的联邦学习提供了高效可扩展的解决方案。


### [169] [BlindU: Blind Machine Unlearning without Revealing Erasing Data](https://arxiv.org/abs/2601.07214)
*Weiqi Wang,Zhiyi Tian,Chenhan Zhang,Shui Yu*

Main category: cs.CR

TL;DR: BlindU：一种在联邦学习中实现隐私保护机器遗忘的方法，用户本地生成压缩表示，服务器仅基于这些表示进行遗忘，无需访问原始数据

- Motivation: 现有机器遗忘方法要求用户先将数据上传到服务器作为遗忘前提，这在联邦学习等隐私保护场景中不可行。需要探索在不向服务器暴露待遗忘数据的情况下实现遗忘的方法。
- Method: 1) 使用信息瓶颈机制训练FL模型，编码器学习压缩表示；2) 用户本地生成隐私保护的压缩表示；3) 服务器基于这些表示和标签进行遗忘；4) 引入两个专用遗忘模块；5) 使用多梯度下降算法平衡遗忘和效用保留；6) 采用无噪声差分隐私掩码增强隐私保护
- Result: 理论分析和大量实验结果表明，BlindU在隐私保护和遗忘效果方面优于现有最佳隐私保护遗忘基准方法
- Conclusion: BlindU成功解决了在联邦学习等隐私保护场景中实现机器遗忘的挑战，通过压缩表示和差分隐私掩码实现了有效的隐私保护遗忘


### [170] [SecureCAI: Injection-Resilient LLM Assistants for Cybersecurity Operations](https://arxiv.org/abs/2601.07835)
*Mohammed Himayath Ali,Mohammed Aqib Abdullah,Mohammed Mudassir Uddin,Shahnawaz Alam*

Main category: cs.CR

TL;DR: SecureCAI是一个针对网络安全环境中LLM的防御框架，通过扩展宪法AI原则、安全护栏、自适应宪法演进和DPO来防御提示注入攻击，在保持良性任务准确性的同时显著降低攻击成功率。

- Motivation: 大型语言模型在安全运营中心的应用面临提示注入攻击的严重威胁，恶意指令嵌入安全工件会操纵模型行为。传统安全机制在对抗性网络安全环境中不足以应对复杂的对抗性操纵，需要专门针对高风险安全场景的防御方案。
- Method: SecureCAI框架扩展宪法AI原则，结合安全感知的护栏机制、自适应宪法演进和直接偏好优化（DPO）来消除不安全响应模式。框架包含持续红队反馈循环，实现动态适应新兴攻击策略。
- Result: 实验评估显示，SecureCAI相比基线模型将攻击成功率降低了94.7%，同时在良性安全分析任务上保持95.1%的准确性。在持续对抗压力下，宪法遵循分数超过0.92。
- Conclusion: SecureCAI为语言模型能力在操作网络安全工作流程中的可信集成奠定了基础，解决了对抗性领域中当前AI安全方法的关键缺口，能够动态适应新兴攻击策略。
## cs.GR

### [171] [Investigating Anthropometric Fidelity in SAM 3D Body](https://arxiv.org/abs/2601.06035)
*Aizierjiang Aiersilan,Ruting Cheng,James Hahn*

Main category: cs.GR

TL;DR: SAM 3D Body在人体网格恢复方面表现出色，但在特殊身体形态（如老年肌肉萎缩、脊柱侧弯、怀孕）的细节重建上存在局限，这是由于感知-失真权衡导致的"回归均值"效应。

- Motivation: SAM 3D Body在单图像人体网格恢复方面取得了最先进的性能，但研究发现该模型在重建特殊身体形态的详细人体测量学偏差方面存在系统性局限，特别是在老年肌肉萎缩、脊柱侧弯、怀孕等特殊人群上。
- Method: 通过分析SAM 3D Body的架构机制，研究其依赖的低维参数化MHR表示、语义不变条件（DINOv3）和基于注释的对齐如何共同导致"回归均值"效应，从而平滑掉个体生物学细节。
- Result: 研究发现SAM 3D Body的局限性不是模型能力不足，而是感知-失真权衡的副产品。模型架构倾向于生成"平均"身体形态，即使输入图像中特殊身体特征很明显，也无法准确重建这些细节。
- Conclusion: 虽然SAM 3D Body在一般人体网格恢复方面表现出色，但在医学领域应用时需要解决特殊身体形态的细节重建问题。研究提出了具体的建设性路径，以扩展该模型在医学领域的应用潜力。
## cs.MA

### [172] [OS-Symphony: A Holistic Framework for Robust and Generalist Computer-Using Agent](https://arxiv.org/abs/2601.07779)
*Bowen Yang,Kaiming Jin,Zhenyu Wu,Zhaoyang Liu,Qiushi Sun,Zehao Li,JingJing Xie,Zhoumianze Liu,Fangzhi Xu,Kanzhi Cheng,Qingyun Li,Yian Wang,Yu Qiao,Zun Wang,Zichen Ding*

Main category: cs.MA

TL;DR: OS-Symphony是一个用于计算机使用代理的全面框架，通过反射记忆代理和多功能工具代理解决长时程工作流中的视觉上下文丢失和新领域泛化问题。

- Motivation: 当前视觉语言模型在计算机使用代理中存在局限性：长时程工作流中缺乏对历史视觉上下文的细粒度控制，以及在新领域中缺乏视觉感知的教程检索能力，导致鲁棒性和泛化性不足。
- Method: OS-Symphony框架包含一个协调器，整合两个关键创新：1) 反射记忆代理，利用里程碑驱动的长期记忆实现轨迹级自校正；2) 多功能工具代理，包含采用SeeAct范式的多模态搜索器，在浏览器沙盒中合成实时视觉对齐的教程。
- Result: 实验结果显示OS-Symphony在不同模型规模上均取得显著性能提升，在三个在线基准测试中创下新的最先进结果，特别是在OSWorld上达到65.84%的准确率。
- Conclusion: OS-Symphony通过创新的反射记忆和视觉感知教程检索机制，有效解决了计算机使用代理在长时程任务和新领域中的鲁棒性和泛化性问题，为自动化系统提供了更强大的能力。
## cs.IT

### [173] [Hard Thresholding Pursuit Algorithms for Least Absolute Deviations Problem](https://arxiv.org/abs/2601.06558)
*Jiao Xu,Peng Li,Bing Zheng*

Main category: cs.IT

TL;DR: GFHTP₁算法在LAD准则下对异常值具有鲁棒性，无需信号稀疏度先验信息且无参数设计，在计算效率和鲁棒性方面优于现有算法。

- Motivation: 在部分测量值被任意幅度异常值污染的场景中，需要研究自适应迭代硬阈值算法对异常值的鲁棒性。现有算法大多需要信号稀疏度先验信息且参数复杂，需要简化实现过程。
- Method: 提出graded fast hard thresholding pursuit (GFHTP₁)算法，基于最小绝对偏差(LAD)准则，采用自适应迭代硬阈值方法，无需信号稀疏度先验信息，且为无参数设计。
- Result: 数值实验表明GFHTP₁算法在鲁棒性和计算效率方面持续优于竞争算法，特别是在存在异常值的情况下表现优异。
- Conclusion: GFHTP₁算法通过无参数设计和无需稀疏度先验的特性，在异常值污染场景中提供了优越的鲁棒性和计算效率，简化了实现过程。
