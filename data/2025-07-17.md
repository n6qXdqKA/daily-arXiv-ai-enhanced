[[toc]]

## cs.CV

### [1] [An Memory-Efficient Framework for Deformable Transformer with Neural Architecture Search](https://arxiv.org/abs/2507.11549)
*Wendong Mao,Mingfan Zhao,Jianfeng Guan,Qiwei Dong,Zhongfeng Wang*

Main category: cs.CV

TL;DR: 本文提出了一种硬件友好的优化框架，用于解决可变形注意力变换器（DAT）在硬件部署中的内存访问问题，通过神经架构搜索和FPGA验证系统，实现了高效且低精度损失的部署。

- Motivation: 可变形注意力变换器（DAT）在计算机视觉任务中表现出色，但其数据依赖的采样机制导致不规则的内存访问模式，增加了硬件部署的难度。现有方法要么硬件开销高，要么牺牲模型精度。
- Method: 提出了一种基于神经架构搜索（NAS）的方法，通过新的切片策略自动划分输入特征为均匀块，避免内存冲突；同时设计了FPGA验证系统进行性能测试。
- Result: 在ImageNet-1K数据集上的实验表明，该框架仅导致0.2%的精度损失；在Xilinx FPGA上的硬件实验显示，DRAM访问次数减少至现有方法的18%。
- Conclusion: 该硬件友好的优化框架在保持模型精度的同时，显著提升了DAT在边缘硬件上的部署效率。


### [2] [Deformable Dynamic Convolution for Accurate yet Efficient Spatio-Temporal Traffic Prediction](https://arxiv.org/abs/2507.11550)
*Hyeonseok Jin,Geonmin Kim,Kyungbaek Kim*

Main category: cs.CV

TL;DR: 提出了一种名为DDCN的模型，通过动态可变形卷积网络解决交通预测中的异质性和可扩展性问题，实现了高效且准确的预测。

- Motivation: 传统方法在捕捉交通数据的时空异质性和可扩展性方面存在不足，尤其是GNN需要预定义邻接矩阵且难以处理大规模数据。
- Method: DDCN采用动态可变形卷积网络，分解为编码器-解码器结构，利用空间和时空注意力块突出重要特征。
- Result: 在四个真实数据集上的实验表明，DDCN性能优越，验证了CNN方法在时空交通预测中的潜力。
- Conclusion: DDCN通过动态可变形卷积和注意力机制，实现了高效且准确的交通预测，为CNN在时空预测中的应用提供了新思路。


### [3] [Inversion-DPO: Precise and Efficient Post-Training for Diffusion Models](https://arxiv.org/abs/2507.11554)
*Zejian Li,Yize Li,Chenye Meng,Zhongni Liu,Yang Ling,Shengyuan Zhang,Guang Yang,Changyuan Yang,Zhiyuan Yang,Lingyun Sun*

Main category: cs.CV

TL;DR: 提出了一种名为Inversion-DPO的新对齐框架，通过DDIM反转优化扩散模型，无需奖励模型，显著提升训练效率和精度。

- Motivation: 现有对齐方法计算开销大且可能影响模型精度，Inversion-DPO旨在解决这些问题。
- Method: 利用DDIM反转将Direct Preference Optimization (DPO)应用于扩散模型，避免奖励建模。
- Result: 在文本到图像生成和组合图像生成任务中表现优异，生成高保真且组合一致的图像。
- Conclusion: Inversion-DPO为扩散模型提供了一种高效、高精度的对齐方法，适用于复杂生成任务。


### [4] [Reprogramming Vision Foundation Models for Spatio-Temporal Forecasting](https://arxiv.org/abs/2507.11558)
*Changlu Chen,Yanbin Liu,Chaoxi Niu,Ling Chen,Tianqing Zhu*

Main category: cs.CV

TL;DR: ST-VFM是一个新颖的框架，通过重新编程视觉基础模型（VFMs）来解决时空预测任务中的挑战，包括缺乏时间建模能力和视觉与时空数据的模态差异。

- Motivation: 尽管基础模型在自然语言处理和计算机视觉中表现出色，但在时空预测中，大型语言模型（LLMs）难以捕捉丰富的时空相关性。因此，需要一种方法将视觉基础模型（VFMs）重新编程以适用于时空预测。
- Method: ST-VFM采用双分支架构，结合原始时空输入和辅助时空流输入，并通过两个重新编程阶段（前VFM和后VFM）处理这些输入，以增强时间建模和模态对齐。
- Result: 在十个时空数据集上的实验表明，ST-VFM优于现有基线，展示了其在不同VFM主干（如DINO、CLIP、DEIT）上的有效性和鲁棒性。
- Conclusion: ST-VFM是一个强大的通用框架，能够有效解决时空预测任务中的挑战，并为未来的研究提供了新的方向。


### [5] [Expert Operational GANS: Towards Real-Color Underwater Image Restoration](https://arxiv.org/abs/2507.11562)
*Ozer Can Devecioglu,Serkan Kiranyaz,Mehmet Yamac,Moncef Gabbouj*

Main category: cs.CV

TL;DR: xOp-GAN提出了一种多生成器的GAN模型，用于解决水下图像恢复中的异质性问题，通过多个专家生成器分别处理不同质量范围的图像，并通过判别器选择最佳恢复结果。

- Motivation: 水下图像恢复因复杂的光传播、散射和深度相关衰减而具有挑战性，传统单生成器GAN难以处理异质性退化问题。
- Method: 提出xOp-GAN，包含多个专家生成器，每个生成器专注于特定质量范围的图像恢复，判别器在推理阶段选择最佳恢复结果。
- Result: 在LSUI数据集上，xOp-GAN的PSNR达到25.16 dB，显著优于单回归器模型且复杂度更低。
- Conclusion: xOp-GAN通过多生成器和判别器的协同工作，显著提升了水下图像恢复的性能。


### [6] [Data-Driven Meta-Analysis and Public-Dataset Evaluation for Sensor-Based Gait Age Estimation](https://arxiv.org/abs/2507.11571)
*Varun Velankar*

Main category: cs.CV

TL;DR: 本文通过元分析和大规模实验，评估了步态年龄估计的多种方法，并提出了降低误差的实用指南。

- Motivation: 步态年龄估计在医疗、安全和人机交互中有重要应用，但现有方法在实验室和现实数据中存在差异。
- Method: 结合元分析、大规模数据集实验和可解释性技术（如Grad-CAM），评估了多种模型（如CNN、SVM、决策树等）。
- Result: CNN平均误差4.2年，多传感器融合误差3.4年；步态指标与年龄相关性显著；深度网络准确率达96%。
- Conclusion: 通过综合方法，步态年龄估计误差可降至3年以下，为实际应用提供了性能基准和指南。


### [7] [What cat is that? A re-id model for feral cats](https://arxiv.org/abs/2507.11575)
*Victor Caquilpan*

Main category: cs.CV

TL;DR: 论文提出了一种改进的PPGNet模型（PPGNet-Cat），用于通过相机陷阱图像识别野生野猫个体，取得了高精度结果。

- Motivation: 野猫对澳大利亚野生动物造成严重威胁，需要高效监控以减少其影响。
- Method: 改进PPGNet模型（原用于阿穆尔虎识别），适应野猫图像特征，并探索对比学习方法如ArcFace损失。
- Result: PPGNet-Cat表现优异，mAP达0.86，rank-1准确率为0.95。
- Conclusion: PPGNet-Cat在野猫重识别领域具有竞争力。


### [8] [SketchDNN: Joint Continuous-Discrete Diffusion for CAD Sketch Generation](https://arxiv.org/abs/2507.11579)
*Sathvik Chereddy,John Femiani*

Main category: cs.CV

TL;DR: SketchDNN提出了一种生成CAD草图的模型，通过统一的连续-离散扩散过程联合建模连续参数和离散类别标签。其核心创新是高斯-Softmax扩散，显著提升了生成质量。

- Motivation: 解决CAD草图中原始参数化的异质性和原始元素的排列不变性问题。
- Method: 采用高斯-Softmax扩散，通过高斯噪声扰动logits并通过softmax变换投影到概率单纯形上。
- Result: FID从16.04降至7.80，NLL从84.8降至81.33，在SketchGraphs数据集上达到新SOTA。
- Conclusion: SketchDNN在CAD草图生成中表现出色，解决了关键挑战并显著提升了性能。


### [9] [Interpretable Prediction of Lymph Node Metastasis in Rectal Cancer MRI Using Variational Autoencoders](https://arxiv.org/abs/2507.11638)
*Benjamin Keel,Aaron Quyn,David Jayne,Maryam Mohsin,Samuel D. Relton*

Main category: cs.CV

TL;DR: 使用变分自编码器（VAE）替代传统卷积神经网络（CNN）进行直肠癌淋巴结转移（LNM）分期，取得了更高的诊断准确性。

- Motivation: 传统基于淋巴结大小、形状和纹理的放射学标准诊断准确性有限，VAE因其生成模型特性能够直接编码视觉特征和有意义的数据模式，提供更可解释的潜在空间。
- Method: 提出'VAE-MLP'模型，应用于168名未接受新辅助治疗的患者的内部MRI数据集，以术后病理N分期为真实标签评估模型性能。
- Result: 模型在MRI数据集上表现优异，交叉验证指标为AUC 0.86 +/- 0.05，敏感性0.79 +/- 0.06，特异性0.85 +/- 0.05。
- Conclusion: VAE-MLP模型在直肠癌LNM分期中实现了最先进的性能，为临床诊断提供了更准确的工具。


### [10] [Posture-Driven Action Intent Inference for Playing style and Fatigue Assessment](https://arxiv.org/abs/2507.11642)
*Abhishek Jaiswal,Nisheeth Srivastava*

Main category: cs.CV

TL;DR: 论文提出了一种基于姿势的心理状态推断方法，通过板球比赛验证其有效性，F1分数超过75%，AUC-ROC超过80%。

- Motivation: 姿势推断在疲劳诊断、伤害预防和性能提升方面潜力巨大，但面临数据敏感性挑战。体育场景成为替代方案。
- Method: 利用板球比赛视频，通过运动分析区分攻击性和防守性击球意图。
- Result: 方法在区分意图上表现优异，F1分数75%，AUC-ROC 80%。姿势信号强，数据噪声下仍有效。
- Conclusion: 研究为体育分析提供了通用技术，并拓展了人类行为分析的应用领域。


### [11] [VISTA: Monocular Segmentation-Based Mapping for Appearance and View-Invariant Global Localization](https://arxiv.org/abs/2507.11653)
*Hannah Shafferman,Annika Thomas,Jouko Kinnari,Michael Ricard,Jose Nino,Jonathan How*

Main category: cs.CV

TL;DR: VISTA是一种新颖的全局定位框架，通过对象分割和跟踪结合几何一致性，解决了视角变化和季节变化带来的定位挑战，显著提升了召回率并节省了存储空间。

- Motivation: 在无结构环境中，传统定位方法因视角变化、季节变化等问题表现不佳，需要一种无需特定领域训练、适应性强的方法。
- Method: VISTA结合前端对象分割与跟踪管道和后端子图对应搜索，利用几何一致性对齐参考帧。
- Result: 在季节和倾斜角度数据集上，召回率提升69%，地图大小仅为基线方法的0.6%。
- Conclusion: VISTA在多样环境下实现了高效、轻量化的全局定位，适用于资源受限平台。


### [12] [Seeing the Signs: A Survey of Edge-Deployable OCR Models for Billboard Visibility Analysis](https://arxiv.org/abs/2507.11730)
*Maciej Szankin,Vidhyananth Venkatasamy,Lihang Ying*

Main category: cs.CV

TL;DR: 本文比较了多模态视觉语言模型（VLMs）与传统CNN-based OCR在户外广告文本识别中的表现，发现VLMs在场景理解上更优，但轻量级CNN在裁剪文本识别上仍具竞争力且计算成本更低。

- Motivation: 户外广告文本识别在复杂场景中仍具挑战性，传统OCR方法在真实条件下表现不佳，而新兴VLMs可能提供更优解决方案。
- Method: 系统性地比较了Qwen 2.5 VL 3B、InternVL3和SmolVLM2等VLMs与轻量级CNN-based OCR（PaddleOCRv4）在公开数据集（ICDAR 2015和SVT）上的表现，并加入合成天气干扰模拟真实场景。
- Result: 部分VLMs在整体场景推理上表现优异，但轻量级CNN在裁剪文本识别上仍具竞争力且计算成本更低。
- Conclusion: VLMs在场景理解上有优势，但轻量级CNN更适合边缘部署。研究公开了天气增强的基准和评估代码以促进未来研究。


### [13] [Beyond Task-Specific Reasoning: A Unified Conditional Generative Framework for Abstract Visual Reasoning](https://arxiv.org/abs/2507.11761)
*Fan Shi,Bin Li,Xiangyang Xue*

Main category: cs.CV

TL;DR: 论文提出了一种统一的条件生成求解器（UCGS），旨在通过单一框架解决多种抽象视觉推理（AVR）任务，避免了任务特定设计或参数调整的需求。

- Motivation: 解决现有深度AVR求解器在不同任务中需要任务特定设计或参数调整的问题，降低解决AVR问题的成本。
- Method: 将一些著名的AVR任务重新表述为目标图像在问题面板中的可预测性估计问题，并通过训练一个条件生成模型来解决多种AVR任务。
- Result: 实验表明，UCGS通过多任务训练展示了跨多种AVR任务的抽象推理能力，并具备零样本推理能力。
- Conclusion: UCGS提供了一种统一的解决方案，能够高效解决多种AVR任务，并具备对新任务的泛化能力。


### [14] [CorrMoE: Mixture of Experts with De-stylization Learning for Cross-Scene and Cross-Domain Correspondence Pruning](https://arxiv.org/abs/2507.11834)
*Peiwen Xia,Tangfei Liao,Wei Zhu,Danhuai Zhao,Jianjun Ke,Kaihao Zhang,Tong Lu,Tao Wang*

Main category: cs.CV

TL;DR: CorrMoE提出了一种新的对应关系剪枝框架，通过去风格化双分支和双融合专家混合模块，提升了跨域和跨场景的鲁棒性。

- Motivation: 解决现有方法在跨域和跨场景变化下对应关系剪枝的不足。
- Method: 采用去风格化双分支处理域偏移，双融合专家混合模块应对场景多样性。
- Result: 在基准数据集上表现出更高的准确性和泛化能力。
- Conclusion: CorrMoE在跨域和跨场景任务中优于现有方法。


### [15] [ProtoConNet: Prototypical Augmentation and Alignment for Open-Set Few-Shot Image Classification](https://arxiv.org/abs/2507.11845)
*Kexuan Shi,Zhuang Qi,Jingjing Zhu,Lei Meng,Yaochen Zhang,Haibei Huang,Xiangxu Meng*

Main category: cs.CV

TL;DR: ProtoConNet通过整合背景信息增强特征空间多样性，解决了小样本开放集图像分类中上下文信息利用不足的问题。

- Motivation: 现有方法仅依赖单张图像的视觉信息，忽略了上下文信息的整合潜力。
- Method: 提出ProtoConNet，包含聚类数据选择（CDS）、上下文增强语义细化（CSR）和原型对齐（PA）三个模块。
- Result: 在两个数据集上的实验表明，ProtoConNet在表示学习和开放集样本识别上优于现有方法。
- Conclusion: ProtoConNet通过上下文信息整合和原型对齐，显著提升了小样本开放集分类的性能。


### [16] [From Coarse to Nuanced: Cross-Modal Alignment of Fine-Grained Linguistic Cues and Visual Salient Regions for Dynamic Emotion Recognition](https://arxiv.org/abs/2507.11892)
*Yu Liu,Leyuan Qu,Hanlei Shi,Di Gao,Yuhua Zheng,Taihao Li*

Main category: cs.CV

TL;DR: 论文提出GRACE方法，通过动态运动建模、语义文本细化和跨模态对齐，提升动态面部表情识别的性能。

- Motivation: 现有方法未能充分利用文本中的情感线索，且缺乏过滤无关面部动态的有效机制。
- Method: GRACE结合动态运动建模、语义文本细化和跨模态对齐，通过CATE模块生成情感感知文本，并利用运动差异加权机制突出表情相关运动。
- Result: 在三个基准数据集上，GRACE显著提升识别性能，尤其在模糊或不平衡情感类别场景中，达到SOTA结果。
- Conclusion: GRACE通过跨模态对齐和情感感知文本优化，有效解决了现有方法的局限性，提升了动态面部表情识别的准确性。


### [17] [Spatial Frequency Modulation for Semantic Segmentation](https://arxiv.org/abs/2507.11893)
*Linwei Chen,Ying Fu,Lin Gu,Dezhi Zheng,Jifeng Dai*

Main category: cs.CV

TL;DR: 论文提出了一种空间频率调制（SFM）方法，通过调制高频特征到低频再解调回高频，有效减少下采样中的混叠问题，并保留细节。

- Motivation: 高频信息对语义分割精度很重要，但下采样层会导致高频信息混叠或失真。
- Method: 提出SFM，通过自适应重采样（ARS）调制高频特征，再通过多尺度自适应上采样（MSAU）解调。
- Result: SFM有效减少混叠并保留细节，适用于多种任务和架构。
- Conclusion: SFM在多种视觉任务中表现出广泛的适用性和有效性。


### [18] [SEPose: A Synthetic Event-based Human Pose Estimation Dataset for Pedestrian Monitoring](https://arxiv.org/abs/2507.11910)
*Kaustav Chanda,Aayush Atul Verma,Arpitsinh Vaghela,Yezhou Yang,Bharatesh Chakravarthi*

Main category: cs.CV

TL;DR: SEPose是一个合成的基于事件的人体姿态估计数据集，用于固定行人感知，填补了相关数据不足的空白。

- Motivation: 解决事件传感器在行人监控系统中数据不足的问题，特别是在复杂条件下。
- Method: 使用CARLA模拟器和动态视觉传感器生成SEPose数据集，包含近350K标注行人姿态关键点。
- Result: 在真实事件数据上评估RVT和YOLOv8模型，展示了数据集的模拟到现实的泛化能力。
- Conclusion: SEPose数据集为事件传感器在行人监控中的应用提供了重要支持。


### [19] [Dark-EvGS: Event Camera as an Eye for Radiance Field in the Dark](https://arxiv.org/abs/2507.11931)
*Jingqian Wu,Peiqi Duan,Zongqiang Wang,Changwei Wang,Boxin Shi,Edmund Y. Lam*

Main category: cs.CV

TL;DR: Dark-EvGS框架通过事件辅助3D高斯泼溅技术，在低光环境下从任意视角重建明亮帧，解决了事件噪声、帧质量差和色调不一致的问题。

- Motivation: 传统相机在低光环境下因动态范围限制和长曝光导致的运动模糊难以捕捉清晰多视角图像，事件相机的高动态范围和高速度特性有望解决这些问题。
- Method: 提出Dark-EvGS框架，采用三重监督学习获取整体知识和细节，引入色调匹配模块保证渲染帧的色调一致性，并创建首个真实数据集。
- Result: 实验表明，该方法在低光条件下优于现有方法，成功实现了辐射场重建。
- Conclusion: Dark-EvGS为低光环境下的多视角图像重建提供了有效解决方案，代码和数据已公开。


### [20] [Hyperphantasia: A Benchmark for Evaluating the Mental Visualization Capabilities of Multimodal LLMs](https://arxiv.org/abs/2507.11932)
*Mohammad Shahab Sepehri,Berk Tinaz,Zalan Fabian,Mahdi Soltanolkotabi*

Main category: cs.CV

TL;DR: 论文介绍了Hyperphantasia基准，用于评估多模态大语言模型（MLLMs）的心理可视化能力，发现其与人类表现存在显著差距。

- Motivation: 当前基准主要评估被动视觉感知，缺乏对主动构建视觉模式以支持问题解决能力的评估，而心理可视化是人类认知的核心能力。
- Method: 通过四个程序生成的谜题任务，分三个难度级别评估MLLMs的表现，并探索强化学习提升视觉模拟能力的潜力。
- Result: 评估显示MLLMs与人类表现存在显著差距，部分模型能识别视觉模式，但稳健的心理可视化仍是挑战。
- Conclusion: 心理可视化是当前MLLMs的开放挑战，未来需进一步研究提升其能力。


### [21] [RaDL: Relation-aware Disentangled Learning for Multi-Instance Text-to-Image Generation](https://arxiv.org/abs/2507.11947)
*Geon Park,Seon Bin Kim,Gunho Jung,Seong-Whan Lee*

Main category: cs.CV

TL;DR: 本文提出了一种关系感知解耦学习（RaDL）框架，用于解决文本到图像（T2I）模型中多实例生成的关系和属性问题。

- Motivation: 现有方法在生成多实例图像时，难以处理实例间的关系差异和多重属性泄漏问题。
- Method: RaDL通过可学习参数增强实例特定属性，并利用关系注意力机制生成关系感知的图像特征。
- Result: 在COCO-Position、COCO-MIG和DrawBench等基准测试中，RaDL在位置准确性、多重属性考虑和实例关系方面显著优于现有方法。
- Conclusion: RaDL是生成考虑多实例关系和属性的图像的有效解决方案。


### [22] [Prototypical Progressive Alignment and Reweighting for Generalizable Semantic Segmentation](https://arxiv.org/abs/2507.11955)
*Yuhang Zhang,Zhengyu Zhang,Muxin Liao,Shishun Tian,Wenbin Zou,Lu Zhang,Chen Xu*

Main category: cs.CV

TL;DR: PPAR框架通过渐进式对齐和原型重加权，利用CLIP模型提升语义分割的泛化能力，解决现有方法的不足。

- Motivation: 解决通用语义分割中现有原型方法的三个挑战：粗对齐策略、原型过拟合及忽略特征适应性差异。
- Method: 定义OTP和VTP原型，采用渐进式对齐策略和原型重加权机制，结合CLIP模型。
- Result: 在多个基准测试中达到最先进性能。
- Conclusion: PPAR通过渐进对齐和重加权有效提升泛化能力，理论分析与实验结果一致。


### [23] [Language-Guided Contrastive Audio-Visual Masked Autoencoder with Automatically Generated Audio-Visual-Text Triplets from Videos](https://arxiv.org/abs/2507.11967)
*Yuchi Ishikawa,Shota Nakada,Hokuto Munakata,Kazuhiro Saito,Tatsuya Komatsu,Yoshimitsu Aoki*

Main category: cs.CV

TL;DR: LG-CAV-MAE通过结合预训练文本编码器和对比音频-视觉掩码自编码器，提升跨模态表示学习，自动生成高质量音频-视觉-文本三元组，显著优于现有方法。

- Motivation: 提升音频-视觉表示学习，通过引入文本模态增强跨模态学习能力。
- Method: 结合预训练文本编码器和对比音频-视觉掩码自编码器，自动生成音频-视觉-文本三元组，使用CLAP过滤确保对齐。
- Result: 在音频-视觉检索任务中recall@10提升5.6%，分类任务提升3.2%。
- Conclusion: LG-CAV-MAE通过自动生成高质量三元组和跨模态学习，显著提升了音频-视觉任务的性能。


### [24] [Watch, Listen, Understand, Mislead: Tri-modal Adversarial Attacks on Short Videos for Content Appropriateness Evaluation](https://arxiv.org/abs/2507.11968)
*Sahid Hossain Mustakim,S M Jishanul Islam,Ummay Maria Muna,Montasir Chowdhury,Mohammed Jawwadul Islam,Sadia Ahmmed,Tashfia Sikder,Syed Tasdid Azam Dhrubo,Swakkhar Shatabda*

Main category: cs.CV

TL;DR: 论文提出了一个评估多模态大语言模型（MLLMs）在短视频内容审核中安全性的框架，包括SVMA数据集和ChimeraBreak攻击策略，揭示了模型的高脆弱性和偏见。

- Motivation: 当前的安全评估多依赖单模态攻击，未能全面评估多模态攻击的脆弱性，尤其在短视频场景下。
- Method: 提出SVMA数据集和ChimeraBreak三模态攻击策略，同时挑战视觉、听觉和语义推理路径。
- Result: 实验显示MLLMs存在显著脆弱性，攻击成功率（ASR）高，并揭示了模型对良性或违规内容的误分类偏见。
- Conclusion: 研究为开发更鲁棒和安全的MLLMs提供了关键见解。


### [25] [GS-Bias: Global-Spatial Bias Learner for Single-Image Test-Time Adaptation of Vision-Language Models](https://arxiv.org/abs/2507.11969)
*Zhaohong Huang,Yuxin Zhang,Jingjing Xie,Fei Chao,Rongrong Ji*

Main category: cs.CV

TL;DR: GS-Bias是一种高效的测试时适应方法，通过全局和空间偏置学习提升视觉语言模型的性能，同时显著减少计算开销。

- Motivation: 现有方法在性能和效率之间难以平衡，要么调优文本提示开销大，要么手工视觉特征增强效果不稳定。
- Method: 引入全局偏置和空间偏置，直接添加到预训练模型的输出logits中，避免全反向传播。
- Result: 在15个基准数据集上达到最优性能，例如在跨数据集和领域泛化中分别提升2.23%和2.72%，内存使用仅为TPT的6.5%。
- Conclusion: GS-Bias在高效性和性能上均优于现有方法，为测试时适应提供了新思路。


### [26] [EC-Diff: Fast and High-Quality Edge-Cloud Collaborative Inference for Diffusion Models](https://arxiv.org/abs/2507.11980)
*Jiajian Xie,Shengyu Zhang,Zhou Zhao,Fan Wu,Fei Wu*

Main category: cs.CV

TL;DR: EC-Diff 是一种混合边缘-云协作框架，通过梯度噪声估计加速云推理，并优化云-边缘切换点以保持生成质量。

- Motivation: 解决云推理时间过长和边缘模型输出不一致的问题。
- Method: 采用 K 步噪声近似策略减少云推理频率，并使用两阶段贪婪搜索算法优化参数。
- Result: 实验表明，EC-Diff 显著提升生成质量，推理速度平均提升 2 倍。
- Conclusion: EC-Diff 在保持高质量生成的同时，显著加速了推理过程。


### [27] [Unsupervised Part Discovery via Descriptor-Based Masked Image Restoration with Optimized Constraints](https://arxiv.org/abs/2507.11985)
*Jiahao Xia,Yike Wu,Wenjian Huang,Jianguo Zhang,Jian Zhang*

Main category: cs.CV

TL;DR: 提出了一种名为Masked Part Autoencoder (MPAE)的无监督部件发现方法，通过掩码和局部特征对齐，实现了跨类别和场景的鲁棒性部件发现。

- Motivation: 现有无监督部件发现方法因缺乏鲁棒性而应用受限，MPAE旨在解决这一问题。
- Method: MPAE通过掩码图像学习部件描述符和特征图，利用局部特征相似性填充掩码区域，从而对齐部件形状。
- Result: MPAE在复杂场景中能鲁棒地发现与实际物体形状匹配的部件，并通过实验验证了其有效性。
- Conclusion: MPAE为无监督部件发现提供了新范式，支持跨类别和场景的应用，并解决了遮挡和部件相似性等挑战。


### [28] [Style Composition within Distinct LoRA modules for Traditional Art](https://arxiv.org/abs/2507.11986)
*Jaehyun Lee,Wonhark Park,Wonsik Shin,Hyunho Lee,Hyoung Min Na,Nojun Kwak*

Main category: cs.CV

TL;DR: 提出一种零样本扩散管道，通过融合不同风格模型的去噪潜在空间，实现区域化风格混合。

- Motivation: 现有扩散模型难以在区域层面控制多种绘画风格的混合，常导致单一风格主导。
- Method: 在去噪过程中，利用低噪声潜在空间携带的强风格信息，通过空间掩码融合不同风格模型的潜在空间，并结合ControlNet的深度图条件。
- Result: 定性和定量实验表明，该方法能根据掩码成功实现区域化风格混合。
- Conclusion: 该方法实现了精确的区域化风格控制，同时保持各风格的真实性。


### [29] [ID-EA: Identity-driven Text Enhancement and Adaptation with Textual Inversion for Personalized Text-to-Image Generation](https://arxiv.org/abs/2507.11990)
*Hyun-Jun Jin,Young-Eun Kim,Seong-Whan Lee*

Main category: cs.CV

TL;DR: ID-EA是一种新框架，通过ID驱动的增强器和适配器改进文本到图像扩散模型中的身份一致性。

- Motivation: 现有Textual Inversion方法在保持面部身份一致性上存在语义对齐问题。
- Method: ID-EA包含ID-Enhancer和ID-Adapter，分别优化身份嵌入和调整文本条件。
- Result: ID-EA在身份保持指标上显著优于现有方法，且计算效率高。
- Conclusion: ID-EA有效解决了身份一致性问题，并提升了生成速度。


### [30] [SAMST: A Transformer framework based on SAM pseudo label filtering for remote sensing semi-supervised semantic segmentation](https://arxiv.org/abs/2507.11994)
*Jun Yin,Fei Wu,Yupeng Ren,Jisheng Huang,Qiankun Li,Heng jin,Jianhai Fu,Chanjie Cui*

Main category: cs.CV

TL;DR: SAMST是一种半监督语义分割方法，利用Segment Anything Model（SAM）的零样本泛化和边界检测能力，通过迭代优化伪标签，提升遥感语义分割的性能。

- Motivation: 公共遥感数据集因分辨率差异和地物类别定义不一致而缺乏普适性，需要利用大量未标记数据提升模型性能。
- Method: SAMST结合监督模型自训练和基于SAM的伪标签优化器，通过阈值过滤、提示生成和标签细化模块迭代优化伪标签。
- Result: 在Potsdam数据集上的实验验证了SAMST的有效性和可行性，解决了标记数据有限的挑战。
- Conclusion: SAMST通过结合大模型的泛化能力与小模型的训练效率，显著提升了伪标签精度和模型性能。


### [31] [AU-Blendshape for Fine-grained Stylized 3D Facial Expression Manipulation](https://arxiv.org/abs/2507.12001)
*Hao Li,Ju Dai,Feng Zhou,Kaida Ning,Lei Li,Junjun Pan*

Main category: cs.CV

TL;DR: AUBlendSet是一个基于AU-Blendshape表示的3D面部数据集，用于跨身份的细粒度面部表情操控。AUBlendNet通过学习不同风格的AU-Blendshape基向量，实现了风格化的3D情感面部操控。

- Motivation: 现有数据集不足以支持细粒度的风格化3D面部表情操控，因此需要构建新的数据集和方法。
- Method: 提出了AUBlendSet数据集和AUBlendNet网络，前者基于32个标准面部动作单元（AUs）和500个身份，后者通过学习AU-Blendshape基向量实现风格化操控。
- Result: 通过定性定量实验验证了AUBlendSet和AUBlendNet在风格化表情操控、语音驱动动画和情感识别数据增强中的有效性。
- Conclusion: AUBlendSet和AUBlendNet填补了3D面部动画任务中的空白，展示了其在多任务中的潜力。


### [32] [Frequency-Dynamic Attention Modulation for Dense Prediction](https://arxiv.org/abs/2507.12006)
*Linwei Chen,Lin Gu,Ying Fu*

Main category: cs.CV

TL;DR: 提出了一种基于电路理论的频率动态注意力调制（FDAM）方法，通过注意力反转和频率动态缩放技术，解决了ViTs中频率消失的问题，提升了模型性能。

- Motivation: ViTs的注意力机制导致频率消失，丢失关键细节和纹理，需要一种方法来动态调整频率响应。
- Method: 提出FDAM，包含注意力反转（AttInv）和频率动态缩放（FreqScale）两种技术，动态调制ViTs的频率响应。
- Result: 在多种模型（如SegFormer、DeiT、MaskDINO）和任务（语义分割、目标检测等）中表现提升，并在遥感检测中达到SOTA。
- Conclusion: FDAM有效解决了ViTs的频率消失问题，显著提升了模型性能，具有广泛适用性。


### [33] [Dual form Complementary Masking for Domain-Adaptive Image Segmentation](https://arxiv.org/abs/2507.12008)
*Jiawen Wang,Yinda Chen,Xiaoyu Liu,Che Liu,Dong Liu,Jianqing Gao,Zhiwei Xiong*

Main category: cs.CV

TL;DR: 论文将掩码图像建模（MIM）重新定义为稀疏信号重建问题，提出MaskTwins框架，通过互补掩码增强特征提取，无需预训练即可实现跨域分割。

- Motivation: 现有方法仅将掩码视为输入图像的变形，缺乏理论分析，未能充分利用掩码重建在特征提取中的潜力。
- Method: 将掩码重建视为稀疏信号重建问题，提出MaskTwins框架，通过互补掩码一致性增强特征学习。
- Result: 实验证明MaskTwins在自然和生物图像分割中优于基线方法，提取域不变特征效果显著。
- Conclusion: MaskTwins为域自适应分割提供了新范式，无需预训练即可实现跨域特征提取。


### [34] [Deep Neural Encoder-Decoder Model to Relate fMRI Brain Activity with Naturalistic Stimuli](https://arxiv.org/abs/2507.12009)
*Florian David,Michael Chan,Elenor Morgenroth,Patrik Vuilleumier,Dimitri Van De Ville*

Main category: cs.CV

TL;DR: 提出了一种端到端的深度神经编码-解码模型，用于编码和解码自然刺激下的大脑活动，通过fMRI数据预测视觉皮层的活动并重建视觉输入。

- Motivation: 探索如何利用深度学习模型填补自然电影刺激与fMRI采集之间的时间分辨率差距，并研究视觉处理的神经机制。
- Method: 采用时间卷积层的编码-解码架构，利用连续电影帧的时间相关性，预测视觉皮层及其周围体素的活动，并通过显著性图分析贡献区域。
- Result: 模型成功重建了边缘、面孔和对比等视觉特征，显著性图显示中枕区、梭状区和距状区是主要贡献区域。
- Conclusion: 研究表明深度学习模型可以作为研究视觉处理的工具，揭示了视觉处理中关键脑区的功能。


### [35] [SS-DC: Spatial-Spectral Decoupling and Coupling Across Visible-Infrared Gap for Domain Adaptive Object Detection](https://arxiv.org/abs/2507.12017)
*Xiwei Zhang,Chunjin Yang,Yiming Xiao,Runtong Zhang,Fanman Meng*

Main category: cs.CV

TL;DR: 提出了一种基于解耦-耦合策略的SS-DC框架，用于RGB-IR域自适应目标检测，通过光谱分解和空间-光谱耦合提升性能。

- Motivation: 现有方法将RGB域视为统一域，忽略了其多子域（如白天、夜晚、雾天），解耦域不变和域特定特征有助于RGB-IR域适应。
- Method: 设计了光谱自适应幂等解耦模块（SAID）和滤波器组光谱处理范式，结合自蒸馏解耦损失和空间-光谱耦合方法。
- Result: 在多个RGB-IR数据集上显著提升基线性能，优于现有UDAOD方法。
- Conclusion: 解耦-耦合策略有效提升RGB-IR域自适应目标检测性能。


### [36] [Dataset Ownership Verification for Pre-trained Masked Models](https://arxiv.org/abs/2507.12022)
*Yuechen Xie,Jie Song,Yicheng Shan,Xiaoyan Zhang,Yuanyu Wan,Shengxuming Zhang,Jiarui Duan,Mingli Song*

Main category: cs.CV

TL;DR: 提出了一种针对掩码模型的数据集所有权验证方法DOV4MM，填补了现有技术空白，并通过实验验证其有效性。

- Motivation: 高质量开源数据集面临被滥用的风险，现有验证技术不适用于掩码模型，需解决这一关键问题。
- Method: 基于掩码信息重建难度差异，设计DOV4MM方法验证黑盒模型是否在目标数据集上预训练。
- Result: 在多个掩码模型上验证，DOV4MM显著优于现有方法，p值远低于0.05。
- Conclusion: DOV4MM为掩码模型的数据集所有权验证提供了有效解决方案，保护了数据集所有者权益。


### [37] [MVAR: MultiVariate AutoRegressive Air Pollutants Forecasting Model](https://arxiv.org/abs/2507.12023)
*Xu Fan,Zhihao Wang,Yuetan Lin,Yan Zhang,Yang Xiang,Hao Li*

Main category: cs.CV

TL;DR: 提出了一种多变量自回归空气污染物预测模型（MVAR），解决了现有研究忽视污染物间相互作用和空间响应的问题，并构建了标准化数据集。

- Motivation: 空气污染物对环境和健康构成威胁，现有研究多关注单一污染物预测，忽视了污染物间的相互作用和空间响应。
- Method: 设计了多变量自回归训练范式，开发了气象耦合空间变换模块，结合AI气象预报，提升数据利用效率。
- Result: 实验结果表明，MVAR模型优于现有方法，支持120小时长期预测。
- Conclusion: MVAR模型有效解决了多变量污染物预测问题，并验证了其架构的优越性。


### [38] [3D-MoRe: Unified Modal-Contextual Reasoning for Embodied Question Answering](https://arxiv.org/abs/2507.12026)
*Rongtao Xu,Han Gao,Mingming Yu,Dong An,Shunpeng Chen,Changwei Wang,Li Guo,Xiaodan Liang,Shibiao Xu*

Main category: cs.CV

TL;DR: 3D-MoRe是一种新范式，通过结合多模态嵌入、跨模态交互和语言模型解码器，生成大规模3D-语言数据集，显著提升了3D场景任务的表现。

- Motivation: 解决室内场景任务（如问答和密集标注）对多样化、可扩展数据的需求。
- Method: 整合多模态嵌入、跨模态交互和语言模型解码器，利用ScanNet数据集和文本标注生成QA对和对象描述。
- Result: 在ScanQA和ScanRefer任务中，CIDEr分数分别提升2.15%和1.84%。
- Conclusion: 3D-MoRe有效提升了3D场景任务的表现，代码和数据集将公开以促进社区发展。


### [39] [SGLoc: Semantic Localization System for Camera Pose Estimation from 3D Gaussian Splatting Representation](https://arxiv.org/abs/2507.12027)
*Beining Xu,Siting Zhu,Hesheng Wang*

Main category: cs.CV

TL;DR: SGLoc是一种新颖的定位系统，通过利用3D高斯泼溅（3DGS）表示和语义信息直接回归相机姿态，无需先验姿态信息。

- Motivation: 解决在没有初始姿态先验的情况下，实现高精度的全局定位问题。
- Method: 采用多级姿态回归策略和基于语义的全局检索算法，逐步估计和优化查询图像的姿态。
- Result: 在12scenes和7scenes数据集上表现出优于基线的性能。
- Conclusion: SGLoc展示了无需初始姿态先验的全局定位能力，具有优越性能。


### [40] [Intra-view and Inter-view Correlation Guided Multi-view Novel Class Discovery](https://arxiv.org/abs/2507.12029)
*Xinhang Wan,Jiyuan Liu,Qian Qu,Suyuan Liu,Chuyu Zhang,Fangdi Wang,Xinwang Liu,En Zhu,Kunlun He*

Main category: cs.CV

TL;DR: 本文提出了一种名为IICMVNCD的新框架，首次在多视图数据中探索新类发现（NCD），解决了现有方法在单视图数据和伪标签依赖上的局限性。

- Motivation: 现有NCD方法主要针对单视图数据且依赖伪标签，导致性能不稳定。本文旨在解决多视图数据中的新类发现问题。
- Method: 通过矩阵分解在视图内捕获分布一致性，在视图间利用已知类关系指导新类聚类，动态调整视图权重。
- Result: 实验验证了IICMVNCD框架的有效性。
- Conclusion: IICMVNCD在多视图数据中实现了更稳定的新类发现性能。


### [41] [MoViAD: Modular Visual Anomaly Detection](https://arxiv.org/abs/2507.12049)
*Manuel Barusco,Francesco Borsatti,Arianna Stropeni,Davide Dalle Pezze,Gian Antonio Susto*

Main category: cs.CV

TL;DR: MoViAD是一个模块化库，旨在加速视觉异常检测（VAD）的研究与部署，提供最先进的模型、数据集和工具，支持多种场景和实际部署需求。

- Motivation: 解决VAD领域因异常数据稀缺和无监督训练需求带来的挑战，同时加速研究和实际应用。
- Method: 开发了一个高度模块化的库MoViAD，集成多种模型、数据集、评估指标和优化工具，支持灵活部署和扩展。
- Result: MoViAD提供了全面的VAD解决方案，支持多种场景和高效部署，适用于研究和工程需求。
- Conclusion: MoViAD为VAD领域的研究和部署提供了高效、灵活的工具，推动了该领域的发展。


### [42] [InstructFLIP: Exploring Unified Vision-Language Model for Face Anti-spoofing](https://arxiv.org/abs/2507.12060)
*Kun-Hsiang Lin,Yu-Wen Tseng,Kang-Yang Huang,Jhih-Ciang Wu,Wen-Huang Cheng*

Main category: cs.CV

TL;DR: InstructFLIP是一种基于视觉语言模型（VLM）的指令调优框架，通过文本指导增强跨域泛化能力，显著提升人脸反欺骗（FAS）的准确性和训练效率。

- Motivation: 解决人脸反欺骗中攻击类型语义理解不足和跨域训练冗余的两大挑战。
- Method: 集成视觉语言模型（VLM）增强视觉输入感知，采用元域策略学习统一模型，并设计内容与风格分离的指令调优框架InstructFLIP。
- Result: 在多个域上超越现有最优模型（SOTA），显著减少训练冗余。
- Conclusion: InstructFLIP通过文本指导和元域策略，有效提升了FAS的泛化能力和效率。


### [43] [MS-DETR: Towards Effective Video Moment Retrieval and Highlight Detection by Joint Motion-Semantic Learning](https://arxiv.org/abs/2507.12062)
*Hongxu Ma,Guanshuo Wang,Fufu Yu,Qiong Jia,Shouhong Ding*

Main category: cs.CV

TL;DR: MS-DETR框架通过统一学习运动与语义特征，提升了视频时刻检索和高光检测任务的表现。

- Motivation: 现有DETR框架未充分利用视频内容中时间运动与空间语义的复杂关系，MS-DETR旨在挖掘这一潜力。
- Method: 提出MS-DETR，编码器显式建模运动与语义的模态内相关性，解码器利用跨模态任务相关性进行精确定位。通过生成策略和对比去噪学习解决数据稀疏问题。
- Result: 在四个基准测试中，MS-DETR显著优于现有最优模型。
- Conclusion: MS-DETR通过运动与语义的统一学习及数据增强策略，有效提升了任务性能。


### [44] [Foresight in Motion: Reinforcing Trajectory Prediction with Reward Heuristics](https://arxiv.org/abs/2507.12083)
*Muleilan Pei,Shaoshuai Shi,Xuesong Chen,Xu Liu,Shaojie Shen*

Main category: cs.CV

TL;DR: 论文提出了一种基于规划视角的运动预测方法，通过先推理行为意图再预测轨迹，结合逆向强化学习（IRL）和分层解码器，显著提升了预测性能。

- Motivation: 现有数据驱动方法直接预测未来轨迹，缺乏对行为意图的显式建模，而意图推理对自动驾驶安全性至关重要。
- Method: 1. 使用向量化表示编码交通代理和场景元素；2. 通过查询中心范式聚合上下文特征；3. 基于IRL推导奖励分布；4. 利用分层DETR-like解码器生成轨迹。
- Result: 在Argoverse和nuScenes数据集上表现优异，显著提升了预测置信度和性能。
- Conclusion: 结合意图推理和轨迹预测的方法在运动预测任务中具有显著优势，为自动驾驶安全提供了新思路。


### [45] [YOLOv8-SMOT: An Efficient and Robust Framework for Real-Time Small Object Tracking via Slice-Assisted Training and Adaptive Association](https://arxiv.org/abs/2507.12087)
*Xiang Yu,Xinyao Liu,Guang Liang*

Main category: cs.CV

TL;DR: 该论文提出了一种针对无人机视角下小型敏捷多目标（如鸟类）跟踪的解决方案，结合了检测和跟踪的创新方法，并在MVA 2025挑战赛中取得冠军。

- Motivation: 解决无人机视角下小型多目标跟踪的三大挑战：目标外观特征稀缺、相机与目标动态复杂、频繁遮挡和身份模糊。
- Method: 采用跟踪-检测范式，提出检测端的SliceTrain训练增强框架和跟踪端的独立于外观信息的鲁棒跟踪器，结合运动方向维护和自适应相似度度量。
- Result: 在SMOT4SB测试集上达到SO-HOTA分数55.205，表现最优。
- Conclusion: 该框架有效解决了复杂现实中的小型多目标跟踪问题，具有先进性和实用性。


### [46] [BRUM: Robust 3D Vehicle Reconstruction from 360 Sparse Images](https://arxiv.org/abs/2507.12095)
*Davide Di Nucci,Matteo Tomei,Guido Borghi,Luca Ciuffreda,Roberto Vezzani,Rita Cucchiara*

Main category: cs.CV

TL;DR: 提出了一种基于稀疏视图输入的车辆3D重建方法，结合深度图和改进的姿态估计架构，显著提升了重建质量。

- Motivation: 现有方法（如NeRF和Gaussian Splatting）依赖密集输入视图，限制了实际应用。本文旨在解决稀疏视图下的车辆重建问题。
- Method: 改进Gaussian Splatting，引入选择性光度损失和高置信度像素处理，采用DUSt3R架构优化姿态估计，并构建新数据集。
- Result: 实验表明，该方法在多个基准测试中达到最先进性能，即使在输入受限条件下也能实现高质量重建。
- Conclusion: 该方法显著提升了稀疏视图下的车辆3D重建效果，具有实际应用潜力。


### [47] [DeepShade: Enable Shade Simulation by Text-conditioned Image Generation](https://arxiv.org/abs/2507.12103)
*Longchao Da,Xiangrui Liu,Mithun Shivakoti,Thirulogasankar Pranav Kutralingam,Yezhou Yang,Hua Wei*

Main category: cs.CV

TL;DR: 论文提出了一种名为DeepShade的扩散模型，用于生成随时间变化的阴影图像，并结合对比学习优化阴影预测，以改进极端高温天气下的路径规划和城市规划。

- Motivation: 全球变暖加剧热浪对公共健康的威胁，但现有路径规划系统因难以从卫星图像中准确估计阴影而无法提供遮荫信息。
- Method: 1. 构建包含多样地理区域和城市布局的阴影数据集；2. 提出DeepShade模型，结合RGB和边缘特征，利用对比学习捕捉阴影时间变化规律。
- Result: 通过文本条件生成阴影图像，提高了阴影预测性能，并在亚利桑那州坦佩的实际路径规划中验证了其效用。
- Conclusion: 该研究为极端高温天气下的城市规划提供了参考，并展示了潜在的实际应用价值。


### [48] [Out-of-distribution data supervision towards biomedical semantic segmentation](https://arxiv.org/abs/2507.12105)
*Yiquan Gao,Duohui Xu*

Main category: cs.CV

TL;DR: Med-OoD框架通过引入OoD数据监督，解决了医学图像分割中前景与背景误分类的问题，无需外部数据或额外标注，显著提升了性能。

- Motivation: 医学图像分割网络在有限和不完美数据集上容易误分类前景与背景，OoD数据在其他视觉任务中的强大表现启发了这一研究。
- Method: 提出Med-OoD框架，利用OoD数据监督完全监督的医学分割，无需外部数据、特征正则化目标或额外标注。
- Result: 在Lizard数据集上显著减少误分类并提升性能，甚至仅用OoD数据训练的网络达到76.1% mIoU。
- Conclusion: Med-OoD展示了OoD数据在医学分割中的潜力，为重新思考OoD数据的作用提供了新视角。


### [49] [Non-Adaptive Adversarial Face Generation](https://arxiv.org/abs/2507.12107)
*Sunpill Kim,Seunghun Paik,Chanwoo Hwang,Minsu Kim,Jae Hong Seo*

Main category: cs.CV

TL;DR: 提出一种新方法生成对抗性人脸，利用FRS特征空间的结构特性，通过属性子空间实现高成功率，仅需单次非自适应查询。

- Motivation: 对抗攻击对FRS构成严重安全威胁，现有方法依赖迭代优化或迁移性，效率低且不适用于商业FRS。
- Method: 利用FRS特征空间中的属性子空间（如性别或种族），生成对抗性人脸，无需迭代优化或迁移性。
- Result: 在AWS CompareFaces API上，仅需100张人脸图像的单次查询，成功率超过93%。
- Conclusion: 该方法高效且灵活，能生成具有特定属性的对抗性人脸，适用于商业FRS。


### [50] [LidarPainter: One-Step Away From Any Lidar View To Novel Guidance](https://arxiv.org/abs/2507.12114)
*Yuzhou Ji,Ke Ma,Hong Cai,Anchun Zhang,Lizhuang Ma,Xin Tan*

Main category: cs.CV

TL;DR: LidarPainter是一种基于扩散模型的实时方法，通过稀疏LiDAR数据和损坏渲染恢复一致的驾驶场景视图，显著提升重建质量和效率。

- Motivation: 动态驾驶场景重建在数字孪生和自动驾驶模拟中至关重要，但现有方法在偏离输入轨迹时存在背景和车辆模型退化问题，且受限于不一致性、变形和耗时。
- Method: 提出LidarPainter，一种一步扩散模型，利用稀疏LiDAR条件和损坏渲染实时恢复一致的驾驶视图，支持高保真车道变换。
- Result: 实验表明，LidarPainter在速度、质量和资源效率上优于现有方法，比StreetCrafter快7倍且仅需五分之一GPU内存，还支持文本提示的风格化生成。
- Conclusion: LidarPainter为驾驶场景重建提供了高效、高质量的解决方案，并支持多样化的风格扩展。


### [51] [Open-Vocabulary Indoor Object Grounding with 3D Hierarchical Scene Graph](https://arxiv.org/abs/2507.12123)
*Sergey Linok,Gleb Naumov*

Main category: cs.CV

TL;DR: OVIGo-3DHSG是一种基于3D分层场景图的开放词汇室内物体定位方法，结合了大型语言模型进行多步推理，提高了空间上下文理解能力。

- Motivation: 解决复杂查询中涉及的空间参考问题，提升室内环境的空间推理和理解能力。
- Method: 利用RGB-D帧序列构建分层场景图，结合开放词汇基础模型和传感器数据处理，整合大型语言模型进行多步推理。
- Result: 在Habitat Matterport 3D多楼层语义场景中表现出高效的场景理解和鲁棒的物体定位能力。
- Conclusion: OVIGo-3DHSG在需要空间推理和室内环境理解的应用中展现出强大潜力。


### [52] [Block-based Symmetric Pruning and Fusion for Efficient Vision Transformers](https://arxiv.org/abs/2507.12125)
*Yi-Kuan Hsieh,Jun-Wei Hsieh,Xin Li,Yu-Ming Chang,Yu-Chee Tseng*

Main category: cs.CV

TL;DR: BSPF-ViT通过联合修剪Q/K令牌并考虑令牌交互，显著降低了ViT的计算成本，同时提升了性能。

- Motivation: ViT的高计算成本限制了其实际应用，现有方法因独立修剪Q/K令牌而牺牲了准确性。
- Method: 提出Block-based Symmetric Pruning and Fusion (BSPF-ViT)，联合优化Q/K令牌修剪，并通过相似性融合保留关键信息。
- Result: 在DeiT-T和DeiT-S上分别提升1.3%和2.0%的准确率，计算开销减少50%，速度提升40%。
- Conclusion: BSPF-ViT在降低计算成本的同时显著提升了ViT的性能，适用于各种ViT变体。


### [53] [Learning Pixel-adaptive Multi-layer Perceptrons for Real-time Image Enhancement](https://arxiv.org/abs/2507.12135)
*Junyu Lou,Xiaorui Zhao,Kexuan Shi,Shuhang Gu*

Main category: cs.CV

TL;DR: 提出了一种结合双边网格和MLP的BPAM框架，用于图像增强，解决了现有方法的线性变换限制和全局参数共享问题。

- Motivation: 现有双边网格方法仅支持线性变换，而传统MLP方法难以处理局部变化，因此需要一种结合两者优势的解决方案。
- Method: 通过生成包含MLP参数的双边网格，每个像素动态获取独特的变换参数，并提出网格分解策略和指导图优化参数生成。
- Result: 在公开数据集上，BPAM框架性能优于现有方法，且保持实时处理能力。
- Conclusion: BPAM框架成功结合了双边网格的空间建模能力和MLP的非线性映射能力，为图像增强提供了高效解决方案。


### [54] [AD-GS: Object-Aware B-Spline Gaussian Splatting for Self-Supervised Autonomous Driving](https://arxiv.org/abs/2507.12137)
*Jiawei Xu,Kai Deng,Zexin Fan,Shenlong Wang,Jin Xie,Jian Yang*

Main category: cs.CV

TL;DR: AD-GS是一种自监督框架，用于从单一日志中实现高质量的自由视角驾驶场景渲染，无需手动标注。

- Motivation: 当前高质量方法依赖昂贵的手动标注，而自监督方法无法准确捕捉动态物体运动或正确分解场景，导致渲染伪影。
- Method: AD-GS结合局部感知B样条曲线和全局感知三角函数，通过动态高斯和双向时间可见性掩模表示物体，并引入可见性推理和物理刚性正则化。
- Result: AD-GS在无标注方法中表现显著优于现有技术，且与依赖标注的方法竞争。
- Conclusion: AD-GS为驾驶场景的高质量渲染提供了一种高效且无需标注的解决方案。


### [55] [Neural Human Pose Prior](https://arxiv.org/abs/2507.12138)
*Michal Heker,Sefy Kararlitsky,David Tolpin*

Main category: cs.CV

TL;DR: 提出了一种基于归一化流的神经先验模型，用于人体姿态建模，通过RealNVP学习6D旋转格式的姿态分布，解决了6D旋转流形上的分布建模问题。

- Motivation: 现有方法多为启发式或表达能力有限，无法有效建模6D旋转格式的姿态分布。
- Method: 利用RealNVP学习6D旋转格式的姿态分布，通过反转Gram-Schmidt过程解决流形上的分布建模问题。
- Result: 通过定性和定量评估验证了方法的有效性，消融实验分析了其影响。
- Conclusion: 为人体动作捕捉和重建提供了概率基础。


### [56] [Fine-Grained Image Recognition from Scratch with Teacher-Guided Data Augmentation](https://arxiv.org/abs/2507.12157)
*Edwin Arkel Rios,Fernando Mikael,Oswin Gosal,Femiloye Oyerinde,Hao-Chun Liang,Bo-Cheng Lai,Min-Chun Hu*

Main category: cs.CV

TL;DR: 论文提出了一种无需依赖预训练模型的高性能细粒度图像识别（FGIR）方法TGDA，通过数据增强和知识蒸馏实现任务特定架构设计，在低分辨率和高分辨率输入下均优于现有方法。

- Motivation: 现有FGIR方法依赖预训练模型，限制了在资源受限环境中的适应性和任务特定架构的发展。
- Method: 引入TGDA框架，结合数据感知增强和细粒度感知教师模型的弱监督，通过知识蒸馏训练任务特定架构（如LRNets和ViTFS）。
- Result: 在多个FGIR基准测试中，TGDA方法性能优于或匹配现有预训练模型，尤其在低分辨率设置下，LRNets提升精度23%，参数减少20.6倍。
- Conclusion: TGDA展示了作为预训练替代方案的潜力，为高效细粒度视觉系统开辟了新途径。


### [57] [Hybrid Ensemble Approaches: Optimal Deep Feature Fusion and Hyperparameter-Tuned Classifier Ensembling for Enhanced Brain Tumor Classification](https://arxiv.org/abs/2507.12177)
*Zahid Ullah,Dragan Pamucar,Jihie Kim*

Main category: cs.CV

TL;DR: 提出了一种双集成框架，结合预训练深度学习模型和超参数优化的机器学习模型，以提高脑肿瘤MRI分类的准确性。

- Motivation: MRI诊断脑肿瘤时，人为因素（如疲劳、经验不足）可能导致误诊，因此需要自动化方法提高精度。
- Method: 采用预处理、数据增强、预训练深度学习模型提取特征，并结合超参数优化的机器学习模型进行分类。
- Result: 实验表明，特征融合和分类器融合优于现有方法，超参数优化显著提升性能。
- Conclusion: 双集成框架有效提高了脑肿瘤分类的准确性，为自动化诊断提供了新思路。


### [58] [Wavelet-based Decoupling Framework for low-light Stereo Image Enhancement](https://arxiv.org/abs/2507.12188)
*Shuangli Du,Siming Yan,Zhenghao Shi,Zhenzhen You,Lu Sun*

Main category: cs.CV

TL;DR: 提出了一种基于小波变换的低光立体图像增强方法，通过特征空间解耦解决现有方法中特征纠缠和黑盒特性的问题。

- Motivation: 低光图像存在复杂的退化问题，现有方法将所有退化因素编码在单一潜在空间中，导致特征高度纠缠和黑盒特性，容易引发捷径学习。
- Method: 利用小波变换将特征空间分解为低频分支（用于光照调整）和多个高频分支（用于纹理增强），并设计了高频引导的跨视角交互模块（HF-CIM）和基于交叉注意力的细节纹理增强模块（DTEM）。
- Result: 实验结果表明，该算法在光照调整和高频信息恢复方面具有显著优势。
- Conclusion: 通过小波变换和特征空间解耦，有效解决了低光图像增强中的特征纠缠问题，提升了图像质量。


### [59] [Revealing the Ancient Beauty: Digital Reconstruction of Temple Tiles using Computer Vision](https://arxiv.org/abs/2507.12195)
*Arkaprabha Basu*

Main category: cs.CV

TL;DR: 论文提出了三种先进技术（分形卷积、自敏感瓷砖填充和超分辨率方法），用于印度古迹的保护与修复，结合计算机视觉和机器学习，实现了高效且美观的解决方案。

- Motivation: 现代数字化方法为文化遗产保护带来了革命性变化，但印度古迹因其独特的建筑风格和美学价值需要专门的技术支持。
- Method: 1. 分形卷积方法用于图像分割；2. 自敏感瓷砖填充（SSTF）方法专为Bankura陶土寺庙设计；3. 结合MosaicSlice数据增强的超分辨率技术。
- Result: 这些方法实现了高细节的区域填充和图像升级，同时保持了真实性和低成本自动化。
- Conclusion: 研究在传统与创新之间找到平衡，为文化遗产保护提供了高效且美观的解决方案。


### [60] [RODS: Robust Optimization Inspired Diffusion Sampling for Detecting and Reducing Hallucination in Generative Models](https://arxiv.org/abs/2507.12201)
*Yiqi Tian,Pengfei Jin,Mingze Yuan,Na Li,Bo Zeng,Quanzheng Li*

Main category: cs.CV

TL;DR: RODS是一种基于优化的扩散采样方法，通过几何线索检测和纠正高风险步骤，减少幻觉现象，提升采样保真度和鲁棒性。

- Motivation: 扩散模型的采样过程容易因分数近似不准确而产生幻觉，需要一种无需重新训练且计算成本低的方法来改善。
- Method: 提出RODS，利用损失景观的几何线索检测和纠正高风险采样步骤，优化采样轨迹并自适应调整扰动。
- Result: 在多个数据集上，RODS能检测70%以上的幻觉样本并纠正25%以上，同时避免引入新伪影。
- Conclusion: RODS通过优化视角改进扩散采样，显著减少幻觉现象，且计算成本低，具有实际应用潜力。


### [61] [MGFFD-VLM: Multi-Granularity Prompt Learning for Face Forgery Detection with VLM](https://arxiv.org/abs/2507.12232)
*Tao Chen,Jingyi Zhang,Decheng Liu,Chunlei Peng*

Main category: cs.CV

TL;DR: 论文提出了一种新的伪造检测框架MGFFD-VLM，通过扩展数据集和改进训练策略，提升了视觉大语言模型在伪造检测和解释性方面的性能。

- Motivation: 现有方法未充分利用面部质量相关属性，且缺乏有效的训练策略，限制了伪造检测和解释能力。
- Method: 扩展了VQA数据集为DD-VQA+，引入属性驱动的混合LoRA策略、多粒度提示学习和伪造感知训练策略。
- Result: 实验表明，该方法在文本伪造判断和分析方面优于现有方法，准确率更高。
- Conclusion: MGFFD-VLM框架通过多策略集成显著提升了伪造检测的性能和解释性。


### [62] [Generate to Ground: Multimodal Text Conditioning Boosts Phrase Grounding in Medical Vision-Language Models](https://arxiv.org/abs/2507.12236)
*Felix Nützel,Mischa Dombrowski,Bernhard Kainz*

Main category: cs.CV

TL;DR: 生成式文本到图像扩散模型在医学影像中实现零样本短语定位，性能优于现有判别方法。

- Motivation: 探索生成式模型在医学影像短语定位中的潜力，提升疾病定位的准确性和可解释性。
- Method: 使用跨注意力图的生成式扩散模型，结合领域特定语言模型（如CXR-BERT），并引入Bimodal Bias Merging（BBM）后处理技术。
- Result: mIoU分数翻倍，显著优于现有判别方法，定位准确性进一步提升。
- Conclusion: 生成式模型为医学影像短语定位提供了更有效的范式，具有临床应用潜力。


### [63] [Calisthenics Skills Temporal Video Segmentation](https://arxiv.org/abs/2507.12245)
*Antonio Finocchiaro,Giovanni Maria Farinella,Antonino Furnari*

Main category: cs.CV

TL;DR: 该论文提出了一种自动化工具，用于从视频中识别和分割静态体操技能，以辅助运动员训练和比赛评分。

- Motivation: 体操技能的评估依赖于难度和持续时间，但目前缺乏专门的视频分割工具。
- Method: 研究提出了一个标注了静态体操技能时间分割的数据集，并测试了基线方法。
- Result: 结果表明该问题是可行的，但仍有改进空间。
- Conclusion: 本研究为体操领域的自动化工具开发提供了初步探索。


### [64] [Comparative Analysis of CNN Performance in Keras, PyTorch and JAX on PathMNIST](https://arxiv.org/abs/2507.12248)
*Anida Nezović,Jalal Romano,Nada Marić,Medina Kapo,Amila Akagić*

Main category: cs.CV

TL;DR: 该研究比较了Keras、PyTorch和JAX在医学图像分类任务中的性能，使用PathMNIST数据集评估训练效率、分类准确性和推理速度。

- Motivation: 尽管深度学习框架在医学图像分类中广泛应用，但不同框架的性能比较尚未充分研究。
- Method: 通过CNN实现，使用PathMNIST数据集评估训练效率、分类准确性和推理速度。
- Result: 研究揭示了计算速度与模型准确性之间的权衡。
- Conclusion: 结果为医学图像分析的研究者和从业者提供了有价值的参考。


### [65] [Site-Level Fine-Tuning with Progressive Layer Freezing: Towards Robust Prediction of Bronchopulmonary Dysplasia from Day-1 Chest Radiographs in Extremely Preterm Infants](https://arxiv.org/abs/2507.12269)
*Sybelle Goedicke-Fritz,Michelle Bous,Annika Engel,Matthias Flotho,Pascal Hirsch,Hannah Wittig,Dino Milanovic,Dominik Mohr,Mathias Kaspar,Sogand Nemat,Dorothea Kerner,Arno Bücker,Andreas Keller,Sascha Meyer,Michael Zemlin,Philipp Flotho*

Main category: cs.CV

TL;DR: 该研究开发了一种基于深度学习的模型，利用出生24小时内的胸部X光片预测极低出生体重婴儿的中/重度支气管肺发育不良（BPD）结局，AUROC为0.78。

- Motivation: BPD是一种慢性肺病，预防干预措施可能带来严重风险，因此早期预测至关重要。常规的胸部X光片可作为非侵入性预测工具。
- Method: 研究使用163名极低出生体重婴儿的胸部X光片，微调了预训练的ResNet-50模型，采用渐进层冻结和CutMix增强技术。
- Result: 最佳模型在预测中/重度BPD时表现良好（AUROC 0.78），且域内预训练显著优于ImageNet初始化。
- Conclusion: 研究表明，域特异性预训练结合渐进冻结和线性探测技术，能够从常规X光片中准确预测BPD，且计算效率高。


### [66] [FADE: Adversarial Concept Erasure in Flow Models](https://arxiv.org/abs/2507.12283)
*Zixuan Fu,Yan Ren,Finn Carter,Chenyue Wang,Ze Niu,Dacheng Yu,Emily Davis,Bo Zhang*

Main category: cs.CV

TL;DR: 提出了一种名为FADE的新方法，用于从文本到图像扩散模型中删除指定概念，确保隐私和公平性。

- Motivation: 扩散模型在图像生成方面表现出色，但也存在隐私泄露和偏见传播的风险，需要一种有效的方法移除敏感概念。
- Method: FADE结合轨迹感知的微调策略和对抗性目标，确保概念被可靠移除同时保持模型保真度。
- Result: FADE在概念移除和图像质量方面表现优异，优于现有基线方法，提升了5-10%的综合性能。
- Conclusion: FADE为安全公平的生成建模设定了新标准，无需从头训练即可移除指定概念。


### [67] [Efficient Calisthenics Skills Classification through Foreground Instance Selection and Depth Estimation](https://arxiv.org/abs/2507.12292)
*Antonio Finocchiaro,Giovanni Maria Farinella,Antonino Furnari*

Main category: cs.CV

TL;DR: 提出了一种基于深度估计和运动员区域检索的徒手技能分类方法，避免了传统姿态估计的高计算成本，显著提升了效率和分类精度。

- Motivation: 传统基于姿态估计的方法计算成本高、推理时间长，限制了实时应用和移动设备的适用性。
- Method: 利用Depth Anything V2进行深度估计，YOLOv10进行运动员定位，通过分割运动员区域而非姿态估计实现分类。
- Result: 方法在推理速度上比骨架方法快38.3倍，分类精度提升（0.837 vs. 0.815）。
- Conclusion: 该方法高效且模块化设计灵活，适用于实时应用和未来改进。


### [68] [Compositional Discrete Latent Code for High Fidelity, Productive Diffusion Models](https://arxiv.org/abs/2507.12318)
*Samuel Lavoie,Michael Noukhovitch,Aaron Courville*

Main category: cs.CV

TL;DR: 本文提出了一种名为离散潜在码（DLC）的图像表示方法，用于改进扩散模型的生成能力。DLC通过自监督学习训练，具有易生成性和组合性，显著提升了图像生成质量，并在ImageNet上实现了新的SOTA。

- Motivation: 扩散模型在复杂分布建模中的成功主要依赖于输入条件。本文旨在研究理想的表示方法，以提高样本保真度、易生成性和组合性，从而支持训练分布外的样本生成。
- Method: 引入离散潜在码（DLC），一种基于自监督学习的图像表示方法，生成离散令牌序列。通过扩散模型结合DLC，实现了高质量的图像生成和组合性。
- Result: DLC显著提升了生成保真度，在ImageNet上达到新的SOTA。组合DLC还能生成训练分布外的样本，并展示了文本到图像生成的能力。
- Conclusion: DLC是一种高效的图像表示方法，通过其组合性和易生成性，为扩散模型提供了更强的生成能力和灵活性。


### [69] [Unsupervised Monocular 3D Keypoint Discovery from Multi-View Diffusion Priors](https://arxiv.org/abs/2507.12336)
*Subin Jeon,In Cho,Junyoung Hong,Seon Joo Kim*

Main category: cs.CV

TL;DR: KeyDiff3D是一个无监督的单目3D关键点估计框架，利用预训练的多视角扩散模型生成几何先验，无需手动标注或多视角图像。

- Motivation: 现有方法依赖昂贵的手动标注或多视角图像，KeyDiff3D旨在仅用单视角图像实现准确的3D关键点估计。
- Method: 通过扩散模型生成多视角图像作为监督信号，并提取其2D多视角特征构建3D特征体积，将隐式3D先验转化为显式特征。
- Result: 在Human3.6M、Stanford Dogs等数据集上验证了方法的准确性、泛化能力及对生成3D对象的操控能力。
- Conclusion: KeyDiff3D提供了一种高效的无监督3D关键点估计方法，并扩展了扩散模型在3D对象操控中的应用。


### [70] [Improving Lightweight Weed Detection via Knowledge Distillation](https://arxiv.org/abs/2507.12344)
*Ahmet Oğuz Saltık,Max Voigt,Sourav Modak,Mike Beckworth,Anthony Stein*

Main category: cs.CV

TL;DR: 论文研究了通过通道知识蒸馏（CWD）和掩码生成蒸馏（MGD）提升轻量级模型在杂草检测中的性能，验证了在嵌入式设备上的实时部署可行性。

- Motivation: 精准农业中杂草检测对减少环境影响至关重要，但资源有限平台上的模型部署仍具挑战性，尤其是区分视觉相似的杂草种类。
- Method: 使用YOLO11x作为教师模型，YOLO11n作为学生模型，通过CWD和MGD进行知识蒸馏，并在真实数据集（甜菜作物和四种杂草）上实验。
- Result: CWD和MGD均显著提升模型性能，CWD学生模型的mAP50提高了2.5%，MGD提高了1.9%，且未增加模型复杂度。
- Conclusion: CWD和MGD是提升深度学习杂草检测准确性的有效、高效且实用的方法，适用于精准农业和植物表型分析。


### [71] [Cluster Contrast for Unsupervised Visual Representation Learning](https://arxiv.org/abs/2507.12359)
*Nikolaos Giakoumoglou,Tania Stathaki*

Main category: cs.CV

TL;DR: Cluster Contrast (CueCo) 是一种结合对比学习和聚类方法的新型无监督视觉表示学习方法，通过同时分散和对齐特征表示，显著提升了分类准确率。

- Motivation: 近年来，对比学习和聚类方法在无监督视觉表示学习中取得了显著进展，但如何结合两者的优势仍是一个挑战。CueCo旨在通过同时优化对比损失和聚类目标，提升特征表示的质量。
- Method: CueCo采用两个神经网络（查询网络和键网络），键网络通过查询输出的慢移动平均更新。方法结合对比损失（增强类间分离）和聚类目标（增强类内紧凑性）。
- Result: 在CIFAR-10、CIFAR-100和ImageNet-100上，CueCo分别达到91.40%、68.56%和78.65%的top-1分类准确率（使用ResNet-18骨干网络）。
- Conclusion: CueCo通过整合对比学习和聚类方法，为无监督视觉表示学习开辟了新方向。


### [72] [Text-driven Multiplanar Visual Interaction for Semi-supervised Medical Image Segmentation](https://arxiv.org/abs/2507.12382)
*Kaiwen Huang,Yi Zhou,Huazhu Fu,Yizhe Zhang,Chen Gong,Tao Zhou*

Main category: cs.CV

TL;DR: 提出了一种名为Text-SemiSeg的文本驱动多平面视觉交互框架，用于半监督医学图像分割，通过文本增强视觉语义嵌入，提升模型性能。

- Motivation: 医学图像标注成本高，文本信息可提供额外上下文以增强视觉语义理解，但目前研究较少。
- Method: 框架包含三个模块：文本增强多平面表示（TMR）、类别感知语义对齐（CSA）和动态认知增强（DCA）。
- Result: 在三个公开数据集上的实验表明，模型能有效利用文本信息增强视觉特征，性能优于其他方法。
- Conclusion: Text-SemiSeg通过文本与视觉交互，显著提升了半监督医学图像分割的效果。


### [73] [OD-VIRAT: A Large-Scale Benchmark for Object Detection in Realistic Surveillance Environments](https://arxiv.org/abs/2507.12396)
*Hayat Ullah,Abbas Khan,Arslan Munir,Hari Kalva*

Main category: cs.CV

TL;DR: 提出了两个视觉目标检测基准OD-VIRAT Large和OD-VIRAT Tiny，用于评估复杂环境下的人体监测算法，并测试了多种先进目标检测模型的性能。

- Motivation: 开发可靠的公共安全监测系统需要多样且具有挑战性的数据集，以全面评估模型性能。
- Method: 创建了两个数据集（OD-VIRAT Large和OD-VIRAT Tiny），包含丰富的标注信息，并对RETMDET、YOLOX等先进模型进行了性能测试。
- Result: OD-VIRAT Large包含8.7百万标注实例，OD-VIRAT Tiny包含288,901标注实例，测试了多种模型在复杂条件下的表现。
- Conclusion: 该研究为开发更高效、鲁棒的目标检测架构提供了基准和实验设置，填补了现有研究的空白。


### [74] [AutoVDC: Automated Vision Data Cleaning Using Vision-Language Models](https://arxiv.org/abs/2507.12414)
*Santosh Vasa,Aditi Ramadwar,Jnana Rama Krishna Darabattula,Md Zafar Anwar,Stanislaw Antol,Andrei Vatavu,Thomas Monninger,Sihao Ding*

Main category: cs.CV

TL;DR: AutoVDC框架利用视觉语言模型自动检测视觉数据集中的错误标注，提升数据质量，验证显示其高效性。

- Motivation: 人工标注存在缺陷且成本高，需自动化工具提升数据集质量。
- Method: 使用Vision-Language Models (VLMs)自动识别错误标注，并在KITTI和nuImages数据集上验证。
- Result: AutoVDC在错误检测和数据清理实验中表现优异。
- Conclusion: AutoVDC能显著提升自动驾驶大规模数据集的可靠性和准确性。


### [75] [QuRe: Query-Relevant Retrieval through Hard Negative Sampling in Composed Image Retrieval](https://arxiv.org/abs/2507.12416)
*Jaehyun Kwak,Ramahdani Muhammad Izaaz Inhar,Se-Young Yun,Sung-Ju Lee*

Main category: cs.CV

TL;DR: 论文提出了一种名为QuRe的方法，通过硬负采样减少假阴性，优化了组合图像检索（CIR）的性能，并创建了HP-FashionIQ数据集以更好地评估用户满意度。

- Motivation: 现有CIR方法仅关注目标图像检索，忽略了其他图像的相关性，导致假阴性问题，影响用户满意度。
- Method: 提出QuRe方法，通过奖励模型目标和硬负采样策略减少假阴性，并创建HP-FashionIQ数据集评估用户偏好。
- Result: QuRe在FashionIQ和CIRR数据集上达到最优性能，并在HP-FashionIQ数据集上表现出与人类偏好最强的对齐。
- Conclusion: QuRe通过减少假阴性提升了CIR性能，并展示了与人类偏好的一致性。


### [76] [InterpIoU: Rethinking Bounding Box Regression with Interpolation-Based IoU Optimization](https://arxiv.org/abs/2507.12420)
*Haoyuan Liu,Hiroshi Watanabe*

Main category: cs.CV

TL;DR: 提出InterpIoU和Dynamic InterpIoU损失函数，通过插值框解决IoU不可微问题，提升小物体检测性能。

- Motivation: 现有IoU损失函数依赖手工几何惩罚项，对小物体检测效果不佳且易导致边界框扩大。
- Method: 提出基于插值框的InterpIoU损失函数，并进一步引入动态调整插值系数的Dynamic InterpIoU。
- Result: 在COCO、VisDrone和PASCAL VOC数据集上表现优于现有方法，小物体检测效果显著提升。
- Conclusion: InterpIoU和Dynamic InterpIoU有效解决了现有IoU损失函数的局限性，提升了检测性能。


### [77] [DVFL-Net: A Lightweight Distilled Video Focal Modulation Network for Spatio-Temporal Action Recognition](https://arxiv.org/abs/2507.12426)
*Hayat Ullah,Muhammad Ali Shafique,Abbas Khan,Arslan Munir*

Main category: cs.CV

TL;DR: 提出了一种轻量级视频识别网络DVFL-Net，通过知识蒸馏和时空特征调制，在保持高性能的同时降低计算成本，适用于实时应用。

- Motivation: Transformer模型在视频识别中性能优越但计算成本高，需要一种轻量级解决方案。
- Method: 采用知识蒸馏和时空焦点调制技术，将大模型的时空知识迁移到小模型中。
- Result: DVFL-Net在多个基准测试中表现优异，计算成本低且内存占用少。
- Conclusion: DVFL-Net在性能和效率之间取得了平衡，适合实时视频识别任务。


### [78] [Traffic-Aware Pedestrian Intention Prediction](https://arxiv.org/abs/2507.12433)
*Fahimeh Orvati Nia,Hai Lin*

Main category: cs.CV

TL;DR: 提出了一种基于动态交通信号和场景信息的行人意图预测模型TA-STGCN，显著提升了预测准确率。

- Motivation: 现有模型在行人意图预测中未充分考虑动态交通信号和场景信息，影响了实际应用效果。
- Method: 采用TA-STGCN模型，整合交通信号状态（红、黄、绿）和边界框尺寸作为关键特征，捕捉时空依赖关系。
- Result: 在PIE数据集上，TA-STGCN比基线模型准确率提升4.75%。
- Conclusion: TA-STGCN通过动态交通信号和场景信息的整合，显著提升了行人意图预测的准确性。


### [79] [Describe Anything Model for Visual Question Answering on Text-rich Images](https://arxiv.org/abs/2507.12441)
*Yen-Linh Vu,Dinh-Thang Duong,Truong-Binh Duong,Anh-Khoi Nguyen,Thanh-Huy Nguyen,Le Thien Phuc Nguyen,Jianhua Xing,Xingjian Li,Tianyang Wang,Ulas Bagci,Min Xu*

Main category: cs.CV

TL;DR: DAM-QA利用区域感知的视觉语言模型DAM，通过多区域视图聚合答案，显著提升文本密集图像的VQA任务性能。

- Motivation: 针对文本密集图像的VQA任务，需要细粒度提取文本信息，DAM的区域级描述能力可能对此有益。
- Method: 提出DAM-QA框架，整合DAM的区域感知能力，通过多区域视图聚合答案。
- Result: 在六个VQA基准测试中表现优于基线DAM，DocVQA上提升7+分，参数更少且性能接近通用VLMs。
- Conclusion: DAM类模型结合高效使用策略，在文本密集和更广泛的VQA任务中具有潜力。


### [80] [Vision-based Perception for Autonomous Vehicles in Obstacle Avoidance Scenarios](https://arxiv.org/abs/2507.12449)
*Van-Hoang-Anh Phan,Chi-Tam Nguyen,Doan-Trung Au,Thanh-Danh Phan,Minh-Thien Duong,My-Ha Le*

Main category: cs.CV

TL;DR: 提出了一种基于摄像头感知和Frenet-Pure Pursuit规划的障碍物避障系统，结合YOLOv11和Depth Anything V2模型，并在校园场景中验证了其有效性。

- Motivation: 确保自动驾驶车辆的安全，需解决复杂环境中的障碍物避障问题。
- Method: 采用摄像头感知模块（YOLOv11和Depth Anything V2）和Frenet-Pure Pursuit规划策略。
- Result: 系统在多样化校园场景中有效避障，验证了模型的准确性和鲁棒性。
- Conclusion: 提出的方法在自动驾驶障碍物避障中表现高效，具备实际应用潜力。


### [81] [Mitigating Object Hallucinations via Sentence-Level Early Intervention](https://arxiv.org/abs/2507.12455)
*Shangpin Peng,Senqiao Yang,Li Jiang,Zhuotao Tian*

Main category: cs.CV

TL;DR: SENTINEL框架通过句子级早期干预和领域内偏好学习，显著减少多模态大语言模型中的幻觉问题，性能优于现有方法。

- Motivation: 多模态大语言模型在跨模态理解中存在幻觉问题，现有方法成本高或存在数据分布不匹配问题。
- Method: 通过迭代采样模型输出、验证对象存在性并分类句子，构建上下文感知偏好数据，使用C-DPO损失训练模型。
- Result: SENTINEL将幻觉减少90%以上，在幻觉和通用能力基准测试中优于现有方法。
- Conclusion: SENTINEL通过早期干预和偏好学习有效减少幻觉，具有优越性和泛化能力。


### [82] [Interpreting Radiologist's Intention from Eye Movements in Chest X-ray Diagnosis](https://arxiv.org/abs/2507.12461)
*Trong-Thang Pham,Anh Nguyen,Zhigang Deng,Carol C. Wu,Hien Van Nguyen,Ngan Le*

Main category: cs.CV

TL;DR: 论文提出了一种名为RadGazeIntent的深度学习方法，通过建模放射科医生的意图驱动行为，预测其在医学图像中的诊断意图。

- Motivation: 现有模型未能捕捉放射科医生凝视背后的意图，而理解这种意图对提高医学图像分析的准确性至关重要。
- Method: 采用基于Transformer的架构，处理凝视数据的时空维度，将细粒度注视特征转化为粗粒度的诊断意图表示。
- Result: RadGazeIntent在三个意图标记数据集（RadSeq、RadExplore、RadHybrid）上均优于基线方法。
- Conclusion: RadGazeIntent能够有效预测放射科医生的诊断意图，为医学图像分析提供了新思路。


### [83] [SpatialTrackerV2: 3D Point Tracking Made Easy](https://arxiv.org/abs/2507.12462)
*Yuxi Xiao,Jianyuan Wang,Nan Xue,Nikita Karaev,Yuri Makarov,Bingyi Kang,Xing Zhu,Hujun Bao,Yujun Shen,Xiaowei Zhou*

Main category: cs.CV

TL;DR: SpatialTrackerV2是一种单目视频中的前馈3D点跟踪方法，通过统一几何、相机运动和物体运动，实现了高性能的端到端跟踪。

- Motivation: 超越基于现成组件的模块化3D跟踪方法，探索几何、相机运动和物体运动的内在联系。
- Method: 将世界空间3D运动分解为场景几何、相机自运动和像素级物体运动，采用完全可微分和端到端的架构。
- Result: 在多种数据集上训练后，性能优于现有3D跟踪方法30%，且运行速度快50倍。
- Conclusion: SpatialTrackerV2通过联合学习几何和运动，实现了高效且高精度的3D点跟踪。


### [84] [MMHU: A Massive-Scale Multimodal Benchmark for Human Behavior Understanding](https://arxiv.org/abs/2507.12463)
*Renjie Li,Ruijie Ye,Mingyang Wu,Hao Frank Yang,Zhiwen Fan,Hezhen Hu,Zhengzhong Tu*

Main category: cs.CV

TL;DR: 提出MMHU，一个大规模的人类行为分析基准数据集，包含丰富的注释和多样化的数据来源，用于评估自动驾驶中的人类行为理解。

- Motivation: 人类行为理解对安全驾驶系统至关重要，但目前缺乏全面的评估基准。
- Method: 开发了MMHU数据集，包含57k人类运动片段和1.73M帧，涵盖多种数据来源，并采用人机协作标注流程生成行为描述。
- Result: 提供了数据集分析和多任务基准测试，包括运动预测、运动生成和行为问答。
- Conclusion: MMHU为自动驾驶中的人类行为研究提供了全面的评估工具。


### [85] [CytoSAE: Interpretable Cell Embeddings for Hematology](https://arxiv.org/abs/2507.12464)
*Muhammed Furkan Dasdelen,Hyesu Lim,Michele Buck,Katharina S. Götze,Carsten Marr,Steffen Schneider*

Main category: cs.CV

TL;DR: CytoSAE是一种稀疏自编码器，用于医学图像中的机制解释，特别是在血液学领域，能够识别形态学相关概念并验证其有效性。

- Motivation: 医学影像领域缺乏解释基础模型推理的工具，稀疏自编码器（SAEs）在视觉领域已显示出潜力，但在医学影像中的应用尚未充分探索。
- Method: 提出CytoSAE，一种在超过40,000张外周血单细胞图像上训练的稀疏自编码器，能够泛化到不同数据集，并识别形态学相关概念。
- Result: CytoSAE在患者和疾病特定概念生成、病理细胞检测以及AML亚型分类任务中表现优异，性能接近最先进水平。
- Conclusion: CytoSAE为医学影像提供了可解释的工具，尤其在血液学领域，具有广泛的应用潜力。


### [86] [PhysX: Physical-Grounded 3D Asset Generation](https://arxiv.org/abs/2507.12465)
*Ziang Cao,Zhaoxi Chen,Linag Pan,Ziwei Liu*

Main category: cs.CV

TL;DR: 论文提出PhysX，一种物理基础的3D资产生成范式，包括数据集PhysXNet和生成框架PhysXGen，填补了物理属性标注的空白。

- Motivation: 现有3D生成模型忽视物理属性，限制了在仿真和具身AI等领域的应用。
- Method: 1) 构建PhysXNet数据集，标注五个物理维度；2) 提出PhysXGen框架，通过双分支架构注入物理知识。
- Result: 实验验证了框架的优越性能和泛化能力。
- Conclusion: PhysX为生成物理AI提供了新方向，代码和数据将开源。
## cs.SD

### [87] [Stereo Sound Event Localization and Detection with Onscreen/offscreen Classification](https://arxiv.org/abs/2507.12042)
*Kazuki Shimada,Archontis Politis,Iran R. Roman,Parthasaarathy Sudarsanam,David Diaz-Guerra,Ruchi Pandey,Kengo Uchida,Yuichiro Koyama,Naoya Takahashi,Takashi Shibuya,Shusuke Takahashi,Tuomas Virtanen,Yuki Mitsufuji*

Main category: cs.SD

TL;DR: 本文介绍了DCASE2025挑战赛任务3的目标、数据集、基线和指标，重点研究了立体声音频数据的声事件定位与检测（SELD）。

- Motivation: 从传统的多通道音频转向更常见的立体声音频，以解决有限视野（FOV）场景下的声事件定位问题。
- Method: 使用立体声音频和视频数据，结合方向估计和距离估计，并引入新的子任务——屏幕内外事件分类。
- Result: 基线系统在立体声音频数据上表现良好。
- Conclusion: 立体声音频SELD在有限视野场景中具有潜力，并提出了新的评估指标。
## physics.ins-det

### [88] [A Spatial-Physics Informed Model for 3D Spiral Sample Scanned by SQUID Microscopy](https://arxiv.org/abs/2507.11853)
*J. Senthilnath,Jayasanker Jayabalan,Zhuoyi Lin,Aye Phyu Phyu Aung,Chen Hao,Kaixin Xu,Yeow Kheng Lim,F. C. Wellstood*

Main category: physics.ins-det

TL;DR: 论文提出了一种空间物理信息模型（SPIM），用于改进半导体先进封装中的非破坏性测试（NDT），通过磁成像（MFI）和电流密度转换，解决了现有方法忽略的涡流效应和图像错位问题。

- Motivation: 先进封装的非破坏性测试因层深和复杂性而变得困难，现有方法仅依赖快速傅里叶变换（FFT）进行磁场反转，未考虑涡流效应和测试设置中的图像错位。
- Method: SPIM包含三个关键部分：1）通过对齐“锐利”导线信号增强磁图像以减轻涡流效应；2）纠正扫描SQUID显微镜的错位导致的倾斜效应；3）结合毕奥-萨伐尔定律和FFT将磁场转换为电流密度。
- Result: SPIM将I通道锐度提高了0.3%，Q通道锐度降低了25%，并成功消除了实际图像中0.30的旋转和倾斜错位。
- Conclusion: SPIM展示了空间分析与物理驱动模型结合在实际应用中的潜力。
## q-bio.NC

### [89] [Spontaneous Spatial Cognition Emerges during Egocentric Video Viewing through Non-invasive BCI](https://arxiv.org/abs/2507.12417)
*Weichen Dai,Yuxuan Huang,Li Zhu,Dongjun Liu,Yu Zhang,Qibin Zhao,Andrzej Cichocki,Fabio Babiloni,Ke Li,Jianyu Qiu,Gangyong Jia,Wanzeng Kong,Qing Wu*

Main category: q-bio.NC

TL;DR: 非侵入性脑机接口（BCI）通过EEG解码被动观看视频时的6D空间姿态，揭示大脑空间系统的自发性和连续性运作。

- Motivation: 研究旨在理解自然被动体验下大脑如何支持空间表征，填补现有对大规模神经动力学认识的空白。
- Method: 使用基于EEG的BCI解码被动观看视频时的6D姿态，分析视觉输入对空间表征的影响。
- Result: EEG能可靠解码空间表征，解码性能在100毫秒/帧的视觉输入下最佳，揭示了分布式神经编码机制。
- Conclusion: 大脑空间系统在被动条件下仍自发运作，挑战了主动与被动空间认知的传统区分，为非侵入性研究提供了新视角。
## cs.SC

### [90] [FactorHD: A Hyperdimensional Computing Model for Multi-Object Multi-Class Representation and Factorization](https://arxiv.org/abs/2507.12366)
*Yifei Zhou,Xuchu Huang,Chenyu Ni,Min Zhou,Zheyu Yan,Xunzhao Yin,Cheng Zhuo*

Main category: cs.SC

TL;DR: FactorHD是一种新型的超维计算模型，能够高效表示和分解复杂的类-子类关系，显著提升计算效率和准确性。

- Motivation: 现有超维计算模型在表示复杂的类-子类关系时面临挑战，如分解困难和信息冗余问题。
- Method: FactorHD采用符号编码方法嵌入额外记忆子句，并设计高效分解算法选择性消除冗余类。
- Result: FactorHD在表示规模为10^9时速度提升约5667倍，与ResNet-18结合在Cifar-10数据集上达到92.48%的分解准确率。
- Conclusion: FactorHD克服了现有模型的局限性，为神经符号AI系统提供了更高效的类-子类关系表示和分解方法。
## cs.CR

### [91] [Effective Fine-Tuning of Vision Transformers with Low-Rank Adaptation for Privacy-Preserving Image Classification](https://arxiv.org/abs/2507.11943)
*Haiwei Lin,Shoko Imaizumi,Hitoshi Kiya*

Main category: cs.CR

TL;DR: 提出一种低秩适应方法，用于训练隐私保护的视觉Transformer模型，冻结预训练权重并减少可训练参数。

- Motivation: 传统低秩适应方法冻结补丁嵌入层，限制了模型性能。本文旨在改进这一点，同时保持高准确性和隐私保护。
- Method: 在ViT的每一层注入可训练的低秩分解矩阵，且不冻结补丁嵌入层。
- Result: 减少可训练参数的同时，保持与全参数微调几乎相同的准确性。
- Conclusion: 该方法在隐私保护和模型性能之间取得了良好平衡。


### [92] [IDFace: Face Template Protection for Efficient and Secure Identification](https://arxiv.org/abs/2507.12050)
*Sunpill Kim,Seunghun Paik,Chanwoo Hwang,Dongsoo Kim,Junbum Shin,Jae Hong Seo*

Main category: cs.CR

TL;DR: IDFace是一种基于同态加密的高效安全人脸识别方法，显著提升了加密模板匹配的效率。

- Motivation: 随着人脸识别系统的广泛应用，用户隐私保护变得尤为重要，尤其是防止从模板中恢复人脸图像特征。现有同态加密方法效率低下，亟需改进。
- Method: 提出IDFace，采用两种新技术：模板表示变换降低匹配成本，空间高效编码减少加密算法的空间浪费。
- Result: 实验表明，IDFace能在126ms内从100万个加密模板中识别出人脸模板，仅比明文识别慢2倍。
- Conclusion: IDFace在保护隐私的同时显著提升了效率，为人脸识别系统的安全应用提供了可行方案。
## astro-ph.IM

### [93] [Image-Based Multi-Survey Classification of Light Curves with a Pre-Trained Vision Transformer](https://arxiv.org/abs/2507.11711)
*Daniel Moreno-Cartagena,Guillermo Cabrera-Vives,Alejandra M. Muñoz Arancibia,Pavlos Protopapas,Francisco Förster,Márcio Catelan,A. Bayo,Pablo A. Estévez,P. Sánchez-Sáez,Franz E. Bauer,M. Pavez-Herrera,L. Hernández-García,Gonzalo Rojas*

Main category: astro-ph.IM

TL;DR: Swin Transformer V2用于多巡天数据的光度分类，联合处理ZTF和ATLAS数据效果最佳。

- Motivation: 研究如何利用预训练的视觉Transformer（Swin Transformer V2）在多巡天设置中进行光度分类，以提升分类性能。
- Method: 采用Swin Transformer V2，评估不同数据整合策略，发现联合处理ZTF和ATLAS数据的多巡天架构效果最好。
- Result: 多巡天架构能有效建模巡天特性和跨巡天交互，性能最佳。
- Conclusion: 研究为未来时域天文学的可扩展分类器构建提供了指导。
## eess.IV

### [94] [CompressedVQA-HDR: Generalized Full-reference and No-reference Quality Assessment Models for Compressed High Dynamic Range Videos](https://arxiv.org/abs/2507.11900)
*Wei Sun,Linhan Cao,Kang Fu,Dandan Zhu,Jun Jia,Menghan Hu,Xiongkuo Min,Guangtao Zhai*

Main category: eess.IV

TL;DR: 论文提出了一种名为CompressedVQA-HDR的视频质量评估框架，针对高动态范围（HDR）视频压缩质量评估问题，采用Swin Transformer和SigLip 2作为骨干网络，分别构建了全参考（FR）和无参考（NR）模型，并在实验中取得了最优性能。

- Motivation: 当前视频压缩质量评估方法在HDR视频多样性增加时缺乏泛化能力，因此需要一种更有效的评估框架。
- Method: 采用Swin Transformer和SigLip 2作为骨干网络，分别构建FR和NR模型，并通过预训练和微调策略解决HDR训练数据不足的问题。
- Result: 模型在实验中表现优于现有方法，CompressedVQA-HDR-FR在IEEE ICME 2025的挑战赛中获得了第一名。
- Conclusion: CompressedVQA-HDR框架有效解决了HDR视频质量评估的挑战，并在性能上达到了领先水平。


### [95] [Identifying Signatures of Image Phenotypes to Track Treatment Response in Liver Disease](https://arxiv.org/abs/2507.12012)
*Matthias Perkonigg,Nina Bastati,Ahmed Ba-Ssalamah,Peter Mesenbrink,Alexander Goehler,Miljen Martic,Xiaofei Zhou,Michael Trauner,Georg Langs*

Main category: eess.IV

TL;DR: 无监督机器学习通过深度聚类网络识别肝脏MRI图像中的组织模式，量化弥漫性肝病的治疗反应，并在临床试验中验证其有效性。

- Motivation: 量化疾病进展和治疗反应的图像模式对个体化治疗和新疗法开发至关重要。
- Method: 使用深度聚类网络对医学图像块进行编码和聚类，建立组织词汇表，量化治疗反应。
- Result: 方法能识别与治疗相关的特定肝脏组织变化路径，并优于现有非成像指标。还能从非侵入性影像预测活检特征。
- Conclusion: 该方法在独立验证队列中表现出适用性，为肝病治疗提供了新工具。


### [96] [Benchmarking and Explaining Deep Learning Cortical Lesion MRI Segmentation in Multiple Sclerosis](https://arxiv.org/abs/2507.12092)
*Nataliia Molchanova,Alessandro Cagol,Mario Ocampo-Pineda,Po-Jui Lu,Matthias Weigel,Xinjie Chen,Erin Beck,Charidimos Tsagkas,Daniel Reich,Colin Vanden Bulcke,Anna Stolting,Serena Borrelli,Pietro Maggi,Adrien Depeursinge,Cristina Granziera,Henning Mueller,Pedro M. Gordaliza,Meritxell Bach Cuadra*

Main category: eess.IV

TL;DR: 该论文提出了一种基于nnU-Net框架的多中心MRI皮质病变检测与分割方法，通过优化模型和评估泛化能力，展示了较高的检测性能，并公开了代码和模型以促进临床应用。

- Motivation: 皮质病变（CLs）是多发性硬化症（MS）的重要生物标志物，但由于MRI表现不明显、专家标注困难以及缺乏标准化自动化方法，其临床应用受限。
- Method: 研究使用656份3T和7T MRI扫描数据，采用MP2RAGE和MPRAGE序列，结合专家共识标注，利用nnU-Net框架进行优化，并评估模型的泛化能力。
- Result: 模型在域内和域外的F1分数分别为0.64和0.5，展示了较强的病变检测能力，并分析了数据变异性、病变模糊性和协议差异对性能的影响。
- Conclusion: 研究为临床应用中数据变异性等问题提供了解决方案，并公开了代码和模型以促进可重复性和进一步研究。


### [97] [Landmark Detection for Medical Images using a General-purpose Segmentation Model](https://arxiv.org/abs/2507.11551)
*Ekaterina Stansfield,Jennifer A. Mitterer,Abdulrahman Altahhan*

Main category: eess.IV

TL;DR: 论文提出了一种结合YOLO和SAM的混合模型，用于在骨科骨盆X光片中精确分割解剖标志和复杂轮廓。

- Motivation: 现有的通用分割模型（如SAM）和医学适应模型（如MedSAM）无法直接用于骨科骨盆标志的精细分割，需要特定提示。
- Method: 利用YOLO进行目标检测生成边界框，作为SAM的输入提示，结合两者优势构建混合模型。
- Result: 混合模型在分割8个解剖标志的基础上，扩展到72个标志和16个复杂区域（如股骨皮质和骨盆入口），表现优异。
- Conclusion: YOLO和SAM的结合在骨科骨盆X光片的分割任务中表现出色，解决了现有模型的局限性。


### [98] [3D Wavelet Latent Diffusion Model for Whole-Body MR-to-CT Modality Translation](https://arxiv.org/abs/2507.11557)
*Jiaxu Zheng,Meiman He,Xuhui Tang,Xiong Wang,Tuoyu Cao,Tianyi Zeng,Lichi Zhang,Chenyu You*

Main category: eess.IV

TL;DR: 提出了一种新型3D小波潜在扩散模型（3D-WLDM），用于从MR图像合成高质量的CT图像，解决了现有方法在空间对齐和图像质量上的不足。

- Motivation: MR成像在临床诊断中至关重要，但现有的MR-to-CT合成方法在全身成像中存在空间对齐差和图像质量不足的问题，影响下游临床任务的可靠性。
- Method: 采用3D小波潜在扩散模型，结合小波残差模块增强特征捕获与重建，通过解耦结构和模态特性保持解剖完整性，并引入双跳跃连接注意力机制提升高分辨率CT生成。
- Result: 生成的CT图像在骨结构和软组织对比度上表现更优，空间对齐和图像质量显著提升。
- Conclusion: 3D-WLDM为MR-to-CT合成提供了一种高效解决方案，有望改善临床工作流程的准确性和可靠性。


### [99] [Predicting Pulmonary Hypertension in Newborns: A Multi-view VAE Approach](https://arxiv.org/abs/2507.11561)
*Lucas Erlacher,Samuel Ruipérez-Campillo,Holger Michel,Sven Wellmann,Thomas M. Sutter,Ece Ozkan,Julia E. Vogt*

Main category: eess.IV

TL;DR: 该论文提出了一种基于多视角变分自编码器（VAE）的方法，用于新生儿肺动脉高压（PH）的预测，通过多视角超声心动图视频提高特征提取和鲁棒性。

- Motivation: 新生儿肺动脉高压（PH）的诊断依赖于超声心动图，但其准确性受操作者影响且现有自动化方法多针对成人，限制了在新生儿中的应用。多视角超声心动图虽有望提升诊断效果，但现有模型泛化能力不足。
- Method: 采用多视角变分自编码器（VAE）框架，从超声心动图视频中提取复杂潜在表征，并与单视角和监督学习方法进行对比。
- Result: 结果表明，多视角学习方法在泛化能力和分类准确性上优于单视角和监督学习方法。
- Conclusion: 多视角学习为新生儿PH的稳健评估提供了有效方法。


### [100] [Are Vision Foundation Models Ready for Out-of-the-Box Medical Image Registration?](https://arxiv.org/abs/2507.11569)
*Hanxue Gu,Yaqian Chen,Nicholas Konz,Qihang Li,Maciej A. Mazurowski*

Main category: eess.IV

TL;DR: 该研究评估了基于基础模型的图像配准算法在乳腺MRI中的应用，发现某些模型（如SAM）在整体配准上优于传统方法，但在细节处理上仍有不足。

- Motivation: 探索基础模型在复杂、可变形解剖结构（如乳腺）中的配准能力，解决乳腺MRI配准的挑战。
- Method: 评估了五种预训练编码器（DINO-v2、SAM、MedSAM、SSLSAM、MedCLIP）在四种乳腺配准任务中的表现。
- Result: SAM在整体配准上表现优异，但对纤维腺体组织的细节配准效果不佳；医学或乳腺特定图像的额外预训练未提升性能。
- Conclusion: 需进一步研究领域特定训练对配准的影响，并开发提升全局配准和细节准确性的策略。


### [101] [Unit-Based Histopathology Tissue Segmentation via Multi-Level Feature Representation](https://arxiv.org/abs/2507.12427)
*Ashkan Shakarami,Azade Farshad,Yousef Yeganeh,Lorenzo Nicole,Peter Schuffler,Stefano Ghidoni,Nassir Navab*

Main category: eess.IV

TL;DR: UTS是一种基于单元的组织分割框架，通过分类固定大小的32*32瓦片而非像素，减少标注工作量并提高计算效率，同时保持准确性。

- Motivation: 解决组织病理学中像素级分割的高标注成本和计算效率低的问题。
- Method: 提出多级视觉变换器（L-ViT），利用多级特征表示捕捉细粒度形态和全局组织上下文。
- Result: 在459个H&E染色区域的386,371个瓦片上评估，性能优于U-Net变体和基于变换器的基线。
- Conclusion: UTS在减少标注和计算成本的同时，保持了分割准确性，适用于临床任务如肿瘤-间质定量和手术边缘评估。
## eess.SP

### [102] [DoRF: Doppler Radiance Fields for Robust Human Activity Recognition Using Wi-Fi](https://arxiv.org/abs/2507.12132)
*Navid Hasanzadeh,Shahrokh Valaee*

Main category: eess.SP

TL;DR: 提出了一种基于Wi-Fi CSI的多普勒速度投影重建3D潜在运动表示的方法，通过构建多普勒辐射场（DoRF）提升人类活动识别的泛化能力。

- Motivation: 尽管Wi-Fi CSI在多普勒速度投影方面已用于人类活动识别（HAR），但其泛化能力仍不足以实际应用。受NeRF启发，希望通过3D潜在运动表示提升鲁棒性。
- Method: 从Wi-Fi CSI中提取一维多普勒速度投影，重建3D潜在运动表示，并构建多普勒辐射场（DoRF）以全面描述活动。
- Result: 该方法显著提高了Wi-Fi HAR的泛化准确性，展示了DoRF在实际传感应用中的潜力。
- Conclusion: DoRF为Wi-Fi CSI在HAR中的实际部署提供了更鲁棒和通用的解决方案。
## cs.CL

### [103] [MapIQ: Benchmarking Multimodal Large Language Models for Map Question Answering](https://arxiv.org/abs/2507.11625)
*Varun Srivastava,Fan Lei,Srija Mukhopadhyay,Vivek Gupta,Ross Maciejewski*

Main category: cs.CL

TL;DR: 论文介绍了MapIQ基准数据集，用于评估多模态大语言模型（MLLMs）在地图视觉问答（Map-VQA）中的表现，填补了现有研究对地图类型和主题覆盖的不足。

- Motivation: 现有Map-VQA研究主要关注等值区域图，限制了主题类别和视觉分析任务的多样性。
- Method: 构建包含14,706个问答对的MapIQ数据集，涵盖三种地图类型和六个主题，评估多个MLLMs在六项视觉分析任务中的表现，并与人类基准对比。
- Result: 实验揭示了MLLMs的鲁棒性、敏感性及其对内部地理知识的依赖，为提升Map-VQA性能提供了潜在方向。
- Conclusion: MapIQ为Map-VQA研究提供了更全面的基准，揭示了MLLMs的局限性及改进空间。


### [104] [A Survey of Deep Learning for Geometry Problem Solving](https://arxiv.org/abs/2507.11936)
*Jianzhe Ma,Wenxuan Wang,Qin Jin*

Main category: cs.CL

TL;DR: 本文综述了深度学习在几何问题求解中的应用，包括任务总结、方法回顾、评估指标分析及未来挑战讨论。

- Motivation: 几何问题求解是数学推理的关键领域，涉及教育、人工智能数学能力评估等多领域，深度学习的发展推动了相关研究。
- Method: 综合总结了几何问题求解的相关任务，回顾了深度学习方法，分析了评估指标，并讨论了当前挑战与未来方向。
- Result: 提供了深度学习在几何问题求解中的全面参考，旨在推动该领域的进一步发展。
- Conclusion: 本文为几何问题求解中的深度学习研究提供了实用指南，并指出了未来探索方向。


### [105] [POLYCHARTQA: Benchmarking Large Vision-Language Models with Multilingual Chart Question Answering](https://arxiv.org/abs/2507.11939)
*Yichen Xu,Liangyu Chen,Liang Zhang,Wenxuan Wang,Qin Jin*

Main category: cs.CL

TL;DR: PolyChartQA是一个多语言图表问答基准，覆盖10种语言的22,606张图表和26,151个问答对，旨在解决现有图表理解基准的英语中心问题。

- Motivation: 现有图表理解基准主要基于英语，限制了其全球适用性。PolyChartQA旨在通过多语言支持提升图表理解的包容性。
- Method: 采用解耦的生成流程，分离图表数据和渲染代码，利用先进的LLM翻译和严格质量控制生成多语言图表。
- Result: 实验显示，英语与其他语言（尤其是非拉丁文字的低资源语言）之间存在显著的性能差距。
- Conclusion: PolyChartQA为推进全球包容性视觉语言模型奠定了基础。
## cs.RO

### [106] [Towards Autonomous Riding: A Review of Perception, Planning, and Control in Intelligent Two-Wheelers](https://arxiv.org/abs/2507.11852)
*Mohammed Hassanin,Mohammad Abu Alsheikh,Carlos C. N. Kuhn,Damith Herath,Dinh Thai Hoang,Ibrahim Radwan*

Main category: cs.RO

TL;DR: 综述分析了自动驾驶技术在两轮微型交通工具（如电动滑板车和电动自行车）中的应用，指出当前研究的不足并提出未来方向。

- Motivation: 两轮微型交通工具的快速普及需要可靠的自主骑行技术，但其独特挑战（如不稳定性和有限资源）尚未得到充分解决。
- Method: 通过系统分析自主骑行系统的核心组件（感知、规划、控制），借鉴自动驾驶技术的研究成果，识别当前研究的不足。
- Result: 发现当前研究在感知系统、行业支持和研究关注度方面存在显著不足，并提出多模态传感器和边缘深度学习等方向。
- Conclusion: 结合自动驾驶技术和自主骑行的需求，推动安全、高效、可扩展的自主骑行系统发展。


### [107] [A Multi-Level Similarity Approach for Single-View Object Grasping: Matching, Planning, and Fine-Tuning](https://arxiv.org/abs/2507.11938)
*Hao Chen,Takuya Kiyokawa,Zhengtao Hu,Weiwei Wan,Kensuke Harada*

Main category: cs.RO

TL;DR: 论文提出了一种基于相似性匹配的新方法，通过利用已知物体的相似性来指导未知物体的抓取，解决了单视角下抓取不确定性的问题。

- Motivation: 传统学习框架对感知噪声和环境变化敏感，性能鲁棒性不足，因此需要一种更通用的抓取方法。
- Method: 通过视觉特征匹配数据库中的物体模型，利用候选模型的抓取知识规划模仿抓取，并通过局部微调优化抓取质量。
- Result: 提出了一种多级相似性匹配框架和C-FPFH描述符，结合语义、几何和尺寸特征，提高了匹配准确性。
- Conclusion: 新方法在单视角下实现了对未知物体的鲁棒抓取，克服了传统学习框架的局限性。


### [108] [EgoVLA: Learning Vision-Language-Action Models from Egocentric Human Videos](https://arxiv.org/abs/2507.12440)
*Ruihan Yang,Qinxi Yu,Yecheng Wu,Rui Yan,Borui Li,An-Chieh Cheng,Xueyan Zou,Yunhao Fang,Hongxu Yin,Sifei Liu,Song Han,Yao Lu,Xiaolong Wang*

Main category: cs.RO

TL;DR: 论文提出了一种利用人类视频训练视觉-语言-动作（VLA）模型的方法，通过逆运动学和动作重定向将人类动作转化为机器人动作，并展示了其优越性能。

- Motivation: 传统机器人模仿学习依赖机器人硬件数据收集，限制了数据规模和多样性。人类视频提供了更丰富的场景和任务。
- Method: 使用人类视频训练VLA模型，预测人类手腕和手部动作，通过逆运动学和重定向转化为机器人动作，并用少量机器人演示微调模型。
- Result: 在Isaac Humanoid Manipulation Benchmark上评估，EgoVLA显著优于基线，验证了人类数据的重要性。
- Conclusion: 利用人类视频训练VLA模型是一种高效的方法，能够显著提升机器人模仿学习的性能。
## cs.LG

### [109] [The Impact of Coreset Selection on Spurious Correlations and Group Robustness](https://arxiv.org/abs/2507.11690)
*Amaya Dharmasiri,William Yang,Polina Kirichenko,Lydia Liu,Olga Russakovsky*

Main category: cs.LG

TL;DR: 本文分析了数据选择方法对核心集偏差水平及下游模型鲁棒性的影响，揭示了样本难度与偏差对齐之间的复杂关系。

- Motivation: 研究数据选择方法是否会延续、放大或减轻数据集中的偏差，以提升数据高效机器学习的公平性和鲁棒性。
- Method: 在十个不同的虚假相关性基准上，结合五种评分指标和五种数据选择策略，全面分析核心集选择对偏差和模型鲁棒性的影响。
- Result: 发现基于嵌入的样本评分方法比基于学习动态的方法更不易加剧偏差，但优先选择困难样本的方法虽能降低偏差，却无法保证下游鲁棒性。
- Conclusion: 核心集选择方法需谨慎设计，以避免加剧偏差并确保模型鲁棒性。


### [110] [MNIST-Gen: A Modular MNIST-Style Dataset Generation Using Hierarchical Semantics, Reinforcement Learning, and Category Theory](https://arxiv.org/abs/2507.11821)
*Pouya Shaeri,Arash Karimi,Ariane Middel*

Main category: cs.LG

TL;DR: MNIST-Gen是一个自动化、模块化的框架，用于生成针对特定领域的MNIST风格数据集，结合了CLIP语义理解和强化学习，显著提高了效率和准确性。

- Motivation: 标准数据集（如MNIST）对领域特定任务不适用，而创建自定义数据集又耗时且复杂。
- Method: 结合CLIP语义理解、强化学习和人类反馈，采用分层语义分类和可组合的形态模型。
- Result: 生成两个新数据集（Tree-MNIST和Food-MNIST），自动分类准确率达85%，节省80%时间。
- Conclusion: MNIST-Gen为领域特定任务提供了高效、灵活的数据集生成解决方案。


### [111] [PRISM: Distributed Inference for Foundation Models at Edge](https://arxiv.org/abs/2507.12145)
*Muhammad Azlan Qazi,Alexandros Iosifidis,Qi Zhang*

Main category: cs.LG

TL;DR: PRISM是一种通信高效且计算感知的策略，用于在边缘设备上部署分布式Transformer推理，显著减少通信和计算开销。

- Motivation: 基础模型（FMs）在边缘部署时面临通信和计算挑战，需要高效策略。
- Method: 采用Segment Means表示近似中间输出特征，优化自注意力机制以减少冗余计算，并设计分区感知的因果掩码。
- Result: 在ViT、BERT和GPT-2上测试，通信开销减少99.2%，计算减少51.24%，精度损失小。
- Conclusion: PRISM为资源受限的边缘环境提供了一种可扩展且实用的基础模型部署方案。


### [112] [RegCL: Continual Adaptation of Segment Anything Model via Model Merging](https://arxiv.org/abs/2507.12297)
*Yuan-Chen Shu,Zhiwei Lin,Yongtao Wang*

Main category: cs.LG

TL;DR: 本文提出RegCL框架，通过模型合并实现多领域知识的高效整合，解决了SAM模型在特定领域性能受限的问题。

- Motivation: 现有基于适配器的一步适应方法在跨领域使用时可能导致性能下降，限制了模型的扩展性。
- Method: RegCL将模型合并算法引入持续学习范式，通过优化权重合并不同领域的适配模块（如LoRA模块）。
- Result: 实验表明，RegCL在多领域数据集上表现优异，验证了其在动态场景中的有效性。
- Conclusion: RegCL通过参数高效的多领域知识整合，解决了持续学习中的灾难性遗忘问题。


### [113] [PROL : Rehearsal Free Continual Learning in Streaming Data via Prompt Online Learning](https://arxiv.org/abs/2507.12305)
*M. Anwar Ma'sum,Mahardhika Pratama,Savitha Ramasamy,Lin Liu,Habibullah Habibullah,Ryszard Kowalczyk*

Main category: cs.LG

TL;DR: 提出了一种基于提示的在线持续学习方法，解决了数据隐私和参数增长问题，性能优于现有方法。

- Motivation: 在线持续学习中数据隐私限制和参数增长问题影响了性能，需要一种高效且实用的解决方案。
- Method: 包括轻量级提示生成器、可训练的缩放-移位器、预训练模型泛化保持和硬软更新机制。
- Result: 在多个数据集上性能显著优于现有方法，参数较少且训练/推理时间适中。
- Conclusion: 该方法在性能和效率上均表现优异，代码已开源。
## cs.GR

### [114] [MOSPA: Human Motion Generation Driven by Spatial Audio](https://arxiv.org/abs/2507.11949)
*Shuyang Xu,Zhiyang Dou,Mingyi Shi,Liang Pan,Leo Ho,Jingbo Wang,Yuan Liu,Cheng Lin,Yuexin Ma,Wenping Wang,Taku Komura*

Main category: cs.GR

TL;DR: 该论文提出了一个基于空间音频驱动的人体运动生成框架（MOSPA），并发布了首个全面的空间音频驱动人体运动数据集（SAM），填补了现有研究中对空间音频特征影响人体运动的忽视。

- Motivation: 虚拟人类如何动态且真实地响应多样化的听觉刺激是角色动画中的关键挑战，但目前相关研究较少，且现有模型通常忽略了空间音频信号中的空间特征对人体运动的影响。
- Method: 作者开发了一个简单而有效的扩散生成框架（MOSPA），通过有效的融合机制捕捉身体运动与空间音频之间的关系，并基于新发布的数据集（SAM）进行训练和测试。
- Result: MOSPA能够根据不同的空间音频输入生成多样且真实的人体运动，并在实验中达到了最先进的性能。
- Conclusion: 该研究填补了空间音频驱动人体运动领域的空白，并通过开源模型和数据集推动了相关研究的发展。


### [115] [HPR3D: Hierarchical Proxy Representation for High-Fidelity 3D Reconstruction and Controllable Editing](https://arxiv.org/abs/2507.11971)
*Tielong Wang,Yuxuan Xiong,Jinfan Liu,Zhifan Zhang,Ye Chen,Yue Shi,Bingbing Ni*

Main category: cs.GR

TL;DR: 提出了一种新型的3D分层代理节点表示方法，解决了现有3D表示（如网格、体素、点云和NeRF）在通用性、编辑性和复杂性之间的权衡问题。

- Motivation: 现有3D表示方法（如网格、NeRF）在通用性、编辑性和复杂性之间存在显著局限性，无法同时满足重建、生成、编辑和驱动等任务的需求。
- Method: 通过稀疏的分层组织（树状结构）代理节点表示物体的形状和纹理，每个节点存储局部信息，并通过神经插值和轻量解码实现高效查询。
- Result: 实验表明，该方法在3D重建和编辑中表现出高效的表达能力、高保真渲染质量和卓越的可编辑性。
- Conclusion: 提出的3D分层代理节点表示方法在通用性、编辑性和复杂性之间取得了平衡，为3D表示提供了新的解决方案。
