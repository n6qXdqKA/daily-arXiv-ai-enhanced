[[toc]]

## cs.CV

### [1] [Mechanistic Interpretability of Diffusion Models: Circuit-Level Analysis and Causal Validation](https://arxiv.org/abs/2506.17237)
*Dip Roy*

Main category: cs.CV

TL;DR: 该论文通过定量电路分析揭示了扩散模型在图像生成中的计算路径和机制原理，发现自然数据与合成数据的处理存在算法差异，并识别了八种功能不同的注意力机制。

- Motivation: 研究扩散模型在图像生成中的计算机制，以理解其行为并为生成模型的控制提供定量基础。
- Method: 通过对2,000张合成图像和2,000张CelebA人脸图像进行系统性干预实验，分析计算复杂性和注意力模式。
- Result: 发现自然图像处理需要更高计算复杂度，识别了八种功能不同的注意力机制，干预实验显示性能下降25.6%至128.3%。
- Conclusion: 研究为生成模型行为的算法理解和控制提供了定量基础，支持通过机制干预策略优化模型性能。


### [2] [SRKD: Towards Efficient 3D Point Cloud Segmentation via Structure- and Relation-aware Knowledge Distillation](https://arxiv.org/abs/2506.17290)
*Yuqi Li,Junhao Dong,Zeyu Dong,Chuanguang Yang,Zhulin An,Yongjun Xu*

Main category: cs.CV

TL;DR: 提出了一种名为SRKD的结构和关系感知知识蒸馏框架，用于将大型教师模型的知识转移到轻量级学生模型，以解决3D点云分割的计算复杂性和部署限制问题。

- Motivation: 解决3D点云分割中大规模基于Transformer的模型的计算复杂性和部署限制问题。
- Method: 提出亲和矩阵关系对齐模块和跨样本小批量构建策略，结合KL散度对齐语义分布和真实监督。
- Result: 方法在显著降低模型复杂度的同时实现了最先进的性能。
- Conclusion: SRKD在现实部署场景中表现出高效性和有效性。


### [3] [Fine-Scale Soil Mapping in Alaska with Multimodal Machine Learning](https://arxiv.org/abs/2506.17302)
*Yijun Lin,Theresa Chen,Colby Brungard,Grunwald Sabine,Sue Ives,Matt Macander,Timm Nawrocki,Yao-Yi Chiang,Nic Jelinski*

Main category: cs.CV

TL;DR: MISO是一种基于视觉的机器学习模型，用于生成阿拉斯加高分辨率土壤地图，优于传统随机森林方法，适用于永久冻土监测和生态保护。

- Motivation: 阿拉斯加土壤测绘对生态保护和基础设施稳定至关重要，但传统方法依赖实地工作且分辨率不足。气候变暖加速冻土融化，亟需高精度地图支持决策。
- Method: MISO结合地理空间基础模型、隐式神经表示和对比学习，实现连续空间预测和多模态对齐。与随机森林（RF）对比验证其性能。
- Result: MISO在空间交叉验证中表现优于RF，泛化能力更强，召回率更高，适用于偏远地区冻土监测。
- Conclusion: MISO展示了先进机器学习在土壤测绘中的潜力，为冻土区采样和规划提供实用指导。


### [4] [RadarSeq: A Temporal Vision Framework for User Churn Prediction via Radar Chart Sequences](https://arxiv.org/abs/2506.17325)
*Sina Najafi,M. Hadi Sepanj,Fahimeh Jafari*

Main category: cs.CV

TL;DR: 提出了一种基于时间感知的计算机视觉框架，通过雷达图序列建模用户行为，结合CNN和双向LSTM提升用户流失预测性能。

- Motivation: 非订阅制零工平台中用户流失预测因缺乏显式标签和动态行为而具有挑战性，现有方法难以捕捉关键时间线索。
- Method: 将用户行为模式建模为雷达图序列，结合预训练CNN编码器和双向LSTM捕捉时空模式。
- Result: 在真实数据集上表现优于经典模型和ViT基线，F1分数提升17.7，精度提升29.4，AUC提升16.1。
- Conclusion: 框架模块化设计、可解释性工具和高效部署特性适用于动态零工经济平台的大规模流失建模。


### [5] [P2MFDS: A Privacy-Preserving Multimodal Fall Detection System for Elderly People in Bathroom Environments](https://arxiv.org/abs/2506.17332)
*Haitian Wang,Yiren Wang,Xinyu Wang,Yumeng Miao,Yuliang Zhang,Yu Zhang,Atif Mansoor*

Main category: cs.CV

TL;DR: 本文提出了一种隐私保护的多模态跌倒检测系统（P2MFDS），结合毫米波雷达和3D振动传感，用于老年人浴室环境中的跌倒检测，显著提高了准确率和召回率。

- Motivation: 随着老龄化加剧，浴室环境中的跌倒风险增加，现有单模态系统在复杂环境中准确性不足，亟需一种隐私保护的多模态解决方案。
- Method: 开发传感器评估框架，融合毫米波雷达和3D振动传感，构建大规模隐私保护数据集；提出双流网络P2MFDS，结合CNN-BiLSTM-Attention和多尺度CNN-SEBlock-Self-Attention分支。
- Result: P2MFDS在准确率和召回率上显著优于现有方法。
- Conclusion: 该系统为老年人浴室跌倒检测提供了高效、隐私保护的解决方案，代码和模型将开源。


### [6] [A Novel Multi-layer Task-centric and Data Quality Framework for Autonomous Driving](https://arxiv.org/abs/2506.17346)
*Yuhan Zhou,Haihua Chen,Kewei Sha*

Main category: cs.CV

TL;DR: 本文提出了一种面向任务的、基于数据质量的五层框架，用于下一代自动驾驶车辆（AVs），旨在通过数据质量（DQ）与任务需求和性能目标的映射，提升AV的功能性、效率和可信度。

- Motivation: 当前AV领域的研究和实践过于关注模型/算法，而忽视了数据质量（DQ）的重要性。本文旨在填补这一空白，为AV提供更可靠的数据支持。
- Method: 提出一个五层框架（数据层、DQ层、任务层、应用层和目标层），并通过nuScenes数据集上的案例研究验证了部分冗余去除对YOLOv8目标检测任务的性能提升。
- Result: 案例研究表明，多源图像数据的部分冗余去除可以提升目标检测性能，同时揭示了图像和LiDAR数据中的冗余DQ问题。
- Conclusion: 本文为AV领域在DQ、任务编排和性能导向系统开发方面提出了新的挑战，并有望推动构建更具适应性、可解释性和鲁棒性的AV系统。


### [7] [Efficient Feedback Gate Network for Hyperspectral Image Super-Resolution](https://arxiv.org/abs/2506.17361)
*Xufei Wang,Mingjian Zhang,Fei Ge,Jinchen Zhu,Wen Sha,Jifen Ren,Zhimeng Hou,Shouguo Zheng,ling Zheng,Shizhuang Weng*

Main category: cs.CV

TL;DR: 提出了一种基于分组的高效反馈门网络（EFGN），通过反馈和门操作提升单幅高光谱图像超分辨率（SHSR）性能，利用空间-光谱增强模块（SSRGM）和渐进扩张融合模块（SPDFM）优化特征提取。

- Motivation: 现有SHSR方法未能充分利用波段间和空间-光谱信息的关联性，导致性能受限。
- Method: 设计了反馈门网络，结合大核卷积和光谱交互，通过SPDFM模块学习波段和空间信息，并利用SSRGM模块增强特征表示。
- Result: 在三个高光谱数据集上验证了方法的优越性，光谱保真度和空间重建效果优于现有技术。
- Conclusion: EFGN通过高效的特征提取和增强模块，显著提升了SHSR的性能。


### [8] [From Drawings to Decisions: A Hybrid Vision-Language Framework for Parsing 2D Engineering Drawings into Structured Manufacturing Knowledge](https://arxiv.org/abs/2506.17374)
*Muhammad Tayyab Khan,Lequn Chen,Zane Yong,Jun Ming Tan,Wenhe Feng,Seung Ki Moon*

Main category: cs.CV

TL;DR: 提出了一种结合旋转感知目标检测模型和视觉语言解析器的混合框架，用于高效提取2D工程图中的关键信息，并在实验中验证了其优越性能。

- Motivation: 手动提取2D工程图中的关键信息效率低下，通用OCR模型因复杂布局和工程符号表现不佳，需要更可靠的自动化解决方案。
- Method: 采用YOLOv11-OBB检测旋转边界框，结合轻量级视觉语言模型（Donut和Florence-2）解析结构化输出。
- Result: Donut模型表现优于Florence-2，精确率达88.5%，召回率99.2%，F1分数93.5%。
- Conclusion: 该框架在数字化制造中具有实际应用价值，支持下游任务如工艺和工具选择。


### [9] [Spatial-Temporal Pre-Training for Embryo Viability Prediction Using Time-Lapse Videos](https://arxiv.org/abs/2506.17403)
*Zhiyi Shi,Junsik Kim,Helen Y. Yang,Yonghyun Song,Hyun-Jic Oh,Dalit Ben-Yosef,Daniel Needleman,Hanspeter Pfister*

Main category: cs.CV

TL;DR: 提出了一种名为STPT的自监督学习方法，用于解决胚胎发育视频中的内存和语义对齐问题，显著提高了IVF胚胎存活率预测的准确性。

- Motivation: 由于标记数据有限且传统自监督学习方法难以处理胚胎发育视频的长序列和变长问题，需要一种更高效的方法。
- Method: STPT分为空间和时间两阶段训练，分别处理视频帧内和帧间关系，避免传统对齐方法的内存和语义问题。
- Result: 在23,027个视频（3,286个标记）上，STPT的AUC达到0.635，优于基线方法。
- Conclusion: STPT能高效处理长视频和变长问题，为IVF胚胎存活率预测提供了新思路。


### [10] [VMRA-MaR: An Asymmetry-Aware Temporal Framework for Longitudinal Breast Cancer Risk Prediction](https://arxiv.org/abs/2506.17412)
*Zijun Sun,Solveig Thrun,Michael Kampffmeyer*

Main category: cs.CV

TL;DR: 论文提出了一种基于Vision Mamba RNN（VMRNN）和状态空间模型（SSM）的方法，结合LSTM机制和不对称模块，用于捕捉乳腺组织的动态变化，提升乳腺癌风险预测的准确性。

- Motivation: 乳腺癌是全球主要死因之一，现有筛查方法多依赖静态数据。利用时间动态信息捕捉乳腺组织演变趋势，可提升高风险群体的筛查效果。
- Method: 采用VMRNN结合SSM和LSTM机制，引入不对称模块（SAD和LAT）检测双侧乳腺差异，优化时间动态建模。
- Result: 方法在预测癌症发病方面表现优异，尤其对高密度乳腺和远期时间点（第4、5年）效果显著。
- Conclusion: 该方法有望推动乳腺癌早期识别和个性化筛查策略的发展。


### [11] [Trans${^2}$-CBCT: A Dual-Transformer Framework for Sparse-View CBCT Reconstruction](https://arxiv.org/abs/2506.17425)
*Minmin Yang,Huantao Ren,Senem Velipasalar*

Main category: cs.CV

TL;DR: 论文提出了一种结合CNN-Transformer的Trans-CBCT模型，用于稀疏视图CBCT重建，并通过引入点Transformer进一步提升性能。

- Motivation: 稀疏视图CBCT扫描速度快且辐射剂量低，但会导致严重的伪影和空间覆盖不足。
- Method: 采用TransUNet结合CNN和Transformer，增强局部细节和全局上下文；引入邻居感知的点Transformer以提升空间一致性。
- Result: 在LUNA16数据集上，Trans-CBCT比基线提升1.17 dB PSNR和0.0163 SSIM；Trans$^2$-CBCT进一步提升了0.63 dB PSNR和0.0117 SSIM。
- Conclusion: 结合CNN-Transformer特征与点几何推理的方法在稀疏视图CBCT重建中表现优异。


### [12] [Enhancing Wireless Device Identification through RF Fingerprinting: Leveraging Transient Energy Spectrum Analysis](https://arxiv.org/abs/2506.17439)
*Nisar Ahmed,Gulshan Saleem,Hafiz Muhammad Shahzad Asif,Muhammad Usman Younus,Kalsoom Safdar*

Main category: cs.CV

TL;DR: 该论文提出了一种基于瞬态能量谱分析和CNN-Bi-GRU混合深度学习模型的射频设备识别方法，实现了高精度的分类性能。

- Motivation: 随着物联网技术和5G网络的快速发展，复杂电磁环境中的辐射设备数量激增，准确识别和分类这些设备成为关键挑战。
- Method: 利用通用线性调频小波变换提取射频设备的瞬态特征，构建包含1080个样本的数据集，并采用CNN-Bi-GRU混合模型进行分类。
- Result: 10折交叉验证结果显示，分类精度达99.17%，精确率99.33%，召回率99.53%，F1分数99.43%。
- Conclusion: CNN-Bi-GRU模型在射频设备识别中表现出色，适用于复杂无线环境中的设备分类。


### [13] [AQUA20: A Benchmark Dataset for Underwater Species Classification under Challenging Conditions](https://arxiv.org/abs/2506.17455)
*Taufikur Rahman Fuad,Sabbir Ahmed,Shahriar Ivan*

Main category: cs.CV

TL;DR: 论文介绍了AQUA20数据集，评估了13种深度学习模型在复杂水下环境中的海洋物种分类性能，ConvNeXt表现最佳，并提供了可解释性分析。

- Motivation: 水下视觉识别因浑浊、低光照和遮挡等复杂失真问题而极具挑战性，需要新的数据集和方法来提升性能。
- Method: 使用AQUA20数据集（8,171张水下图像，20种海洋物种），评估了13种深度学习模型（包括轻量级CNN和Transformer架构）。
- Result: ConvNeXt表现最佳，Top-3准确率98.82%，Top-1准确率90.69%，F1-score 88.92%。其他模型在复杂性和性能之间存在权衡。
- Conclusion: AQUA20为水下物种识别研究提供了基础，展示了模型性能提升的空间，并公开了数据集。


### [14] [When Every Millisecond Counts: Real-Time Anomaly Detection via the Multimodal Asynchronous Hybrid Network](https://arxiv.org/abs/2506.17457)
*Dong Xiao,Guangyao Chen,Peixi Peng,Yangru Huang,Yifan Zhao,Yongxing Dai,Yonghong Tian*

Main category: cs.CV

TL;DR: 提出了一种实时异常检测方法，结合事件相机和RGB相机数据，通过异步图神经网络和CNN实现高精度和快速响应。

- Motivation: 现有方法注重检测精度但忽略响应时间，而自动驾驶场景对实时性要求高。
- Method: 提出多模态异步混合网络，结合事件相机的事件流和RGB相机的图像数据，利用异步GNN和CNN提取时空特征。
- Result: 在基准数据集上表现优于现有方法，实现毫秒级实时性能和高精度。
- Conclusion: 该方法在自动驾驶中实现了快速且精确的异常检测，满足实时性需求。


### [15] [Photogranulometry -- Dataset of soil images with corresponding particle size distributions](https://arxiv.org/abs/2506.17469)
*Thomas Plante St-Cyr,François Duhaime,Jean-Sébastien Dubé,Simon Grenier*

Main category: cs.CV

TL;DR: 论文提出了一种基于光学粒度分析的方法，通过高分辨率图像数据集训练卷积神经网络（CNN），以解决传统粒度分布分析的高成本和低效率问题。

- Motivation: 传统粒度分布分析成本高、效率低，光学粒度分析可以集成到常规实验室工作流程中，减少停机时间和维护成本。
- Method: 使用标准化的顶视图拍摄321种土壤样本的12,714张高分辨率图像（45 MP），并采用定制测试台和锥四分法处理大样本。
- Result: 提供了高质量的数据集，为CNN在岩土工程中的应用提供了训练基础。
- Conclusion: 光学粒度分析结合CNN是一种高效、低成本的替代方案，适用于岩土工程实验室。


### [16] [Few-Shot, Now for Real: Medical VLMs Adaptation without Balanced Sets or Validation](https://arxiv.org/abs/2506.17500)
*Julio Silva-Rodríguez,Fereshteh Shakeri,Houda Bahig,Jose Dolz,Ismail Ben Ayed*

Main category: cs.CV

TL;DR: 本文探讨了视觉语言模型（VLMs）在医学图像分析中的应用，指出现有方法对数据分布的假设不切实际，并提出了一种无需验证集的线性探针方法，以应对数据不平衡的挑战。

- Motivation: 现有VLMs在医学领域的应用假设了平衡的支持集和额外的验证集，这与现实中的疾病流行不平衡和数据效率问题不符。
- Method: 提出了一种无需训练的自适应线性探针方法，结合视觉和文本监督，以在数据不平衡和无验证集的条件下实现鲁棒适应。
- Result: 实验表明，现有方法在现实条件下性能显著下降，甚至可能不如零样本推理；而提出的方法在多种模态和任务中表现稳健。
- Conclusion: 本文揭示了现有VLMs在医学领域的局限性，并提出了一种高效、鲁棒的适应方法，为实际应用提供了可行的解决方案。


### [17] [Trustworthy Few-Shot Transfer of Medical VLMs through Split Conformal Prediction](https://arxiv.org/abs/2506.17503)
*Julio Silva-Rodríguez,Ismail Ben Ayed,Jose Dolz*

Main category: cs.CV

TL;DR: 该论文探讨了医学视觉语言模型（VLM）在数据高效图像分类中的可靠性问题，提出了一种新的转导式分割共形适应（SCA-T）方法，以提高效率和条件覆盖。

- Motivation: 尽管医学视觉语言模型在数据高效图像分类中表现出色，但其可靠性尚未充分研究。本文旨在通过分割共形预测（SCP）框架提供可信度保证。
- Method: 提出转导式分割共形适应（SCA-T），一种在共形场景中进行无监督转导适应的新方法，联合校准和测试数据。
- Result: 实验表明，SCA-T在效率和条件覆盖方面优于传统SPC方法，同时保持相同的经验保证。
- Conclusion: SCA-T为医学VLM的可靠性提供了有效解决方案，适用于多种图像模态和任务。


### [18] [Learning golf swing signatures from a single wrist-worn inertial sensor](https://arxiv.org/abs/2506.17505)
*Jessy Lauer*

Main category: cs.CV

TL;DR: 提出了一种基于手腕传感器的个性化高尔夫挥杆分析框架，通过合成数据和神经网络重建全身运动，识别技术缺陷并提供反馈。

- Motivation: 解决高尔夫挥杆分析中孤立指标、专业运动员数据不足及缺乏丰富运动表示的问题。
- Method: 利用公开视频构建专业挥杆数据集，通过生物准确的人体网格恢复重建3D运动，训练神经网络从手腕数据推断运动和分段挥杆阶段。
- Result: 系统能准确估计全身运动和挥杆事件，识别技术缺陷，预测球员身份、球杆类型等，并提供个性化反馈。
- Conclusion: 挑战了挥杆一致性和单一理想挥杆的假设，为研究、教练和运动损伤预防提供了可扩展的高保真运动分析。


### [19] [Scene-R1: Video-Grounded Large Language Models for 3D Scene Reasoning without 3D Annotations](https://arxiv.org/abs/2506.17545)
*Zhihao Yuan,Shuyi Jiang,Chun-Mei Feng,Yaolun Zhang,Shuguang Cui,Zhen Li,Na Zhao*

Main category: cs.CV

TL;DR: Scene-R1是一个无需3D实例监督的视频驱动框架，通过强化学习和两阶段接地管道实现3D场景理解。

- Motivation: 现有3D感知大语言模型依赖预训练3D检测器且决策不透明，需改进。
- Method: 结合强化学习驱动的推理和两阶段接地管道（时间接地和图像接地），利用SAM2生成像素级掩码并投影到3D。
- Result: 在多个数据集上超越现有基线，提供透明推理步骤。
- Conclusion: 强化学习与RGB-D视频结合为3D场景理解提供高效且可信的路径。


### [20] [SynDaCaTE: A Synthetic Dataset For Evaluating Part-Whole Hierarchical Inference](https://arxiv.org/abs/2506.17558)
*Jake Levi,Mark van der Wilk*

Main category: cs.CV

TL;DR: 论文提出了一种合成数据集SynDaCaTE，用于评估胶囊网络是否真正学习到部分-整体层次结构，并展示了现有模型的瓶颈及自注意力机制的有效性。

- Motivation: 现有胶囊网络在监督任务中难以验证是否真正学习到部分-整体层次结构，因此需要一种新的评估方法。
- Method: 提出合成数据集SynDaCaTE，并通过实验分析现有胶囊模型的瓶颈，验证自注意力机制在部分-整体推理中的有效性。
- Result: 发现现有胶囊模型的瓶颈，并证明自注意力机制在部分-整体推理中表现优异。
- Conclusion: SynDaCaTE为胶囊网络评估提供了新工具，自注意力机制为未来计算机视觉的归纳偏置设计提供了方向。


### [21] [VLA-OS: Structuring and Dissecting Planning Representations and Paradigms in Vision-Language-Action Models](https://arxiv.org/abs/2506.17561)
*Chongkai Gao,Zixuan Liu,Zhenghao Chi,Junshan Huang,Xin Fei,Yiwen Hou,Yuxuan Zhang,Yudi Lin,Zhirui Fang,Zeyu Jiang,Lin Shao*

Main category: cs.CV

TL;DR: 论文研究了Vision-Language-Action（VLA）模型中的任务规划和动作生成范式，提出统一的VLA-OS架构，并通过实验验证视觉基础规划表示和分层VLA范式的优势。

- Motivation: 现有VLA模型在任务规划和动作生成范式上差异显著，难以确定性能提升的具体来源和改进方向。
- Method: 提出VLA-OS统一架构，设计多维度实验（对象类别、视觉模态、环境、末端执行器）对比不同规划范式。
- Result: 视觉基础规划表示优于语言表示；分层VLA范式在任务性能、泛化能力等方面表现更优，但训练和推理速度较慢。
- Conclusion: 分层VLA范式是更优选择，但需权衡速度与性能；视觉基础规划表示值得进一步研究。


### [22] [LLM-driven Medical Report Generation via Communication-efficient Heterogeneous Federated Learning](https://arxiv.org/abs/2506.17562)
*Haoxuan Che,Haibo Jin,Zhengrui Guo,Yi Lin,Cheng Jin,Hao Chen*

Main category: cs.CV

TL;DR: FedMRG是一个基于联邦学习的框架，用于隐私保护的多中心LLM驱动的医学报告生成，解决了通信效率和数据异质性挑战。

- Motivation: 医学图像-报告数据分散且隐私受限，阻碍了LLM驱动的医学报告生成模型的开发。
- Method: 采用低秩分解减少通信开销，结合客户端感知对比学习和双适配器机制处理数据异质性。
- Result: FedMRG在多中心数据上表现出良好的泛化能力和临床准确性，同时保持通信效率。
- Conclusion: FedMRG为隐私保护的医学报告生成提供了可行方案，具有广泛的应用潜力。


### [23] [HalluRNN: Mitigating Hallucinations via Recurrent Cross-Layer Reasoning in Large Vision-Language Models](https://arxiv.org/abs/2506.17587)
*Le Yu,Kaishen Wang,Jianlong Xiong,Yue Cao,Tao He*

Main category: cs.CV

TL;DR: HalluRNN通过架构级解决方案（DG-DPU模块）减少大型视觉语言模型的幻觉问题，无需大量资源或任务特定配置。

- Motivation: 解决LVLMs生成的文本与视觉内容不一致的幻觉问题，避免资源密集型方法。
- Method: 提出Dual-Gated Depth Propagation Unit (DG-DPU)模块，通过跨层循环推理增强模型稳定性。
- Result: 仅微调DG-DPU模块，HalluRNN在多个基准测试中表现优异且稳健。
- Conclusion: HalluRNN提供了一种高效且通用的方法，显著减少了LVLMs的幻觉问题。


### [24] [DRAMA-X: A Fine-grained Intent Prediction and Risk Reasoning Benchmark For Driving](https://arxiv.org/abs/2506.17590)
*Mihir Godbole,Xiangbo Gao,Zhengzhong Tu*

Main category: cs.CV

TL;DR: 论文介绍了DRAMA-X基准，用于评估自动驾驶中的意图预测、风险评估和行动建议任务，并提出了SGG-Intent框架作为基线方法。

- Motivation: 理解行人等弱势道路使用者的短期运动对自动驾驶安全至关重要，但目前缺乏多类意图预测的基准。
- Method: 通过自动化标注流程构建DRAMA-X基准，并提出SGG-Intent框架，结合视觉语言模型和大型语言模型进行推理。
- Result: 实验表明，基于场景图的推理能提升意图预测和风险评估性能，尤其是显式建模上下文线索时。
- Conclusion: DRAMA-X填补了多类意图预测的空白，SGG-Intent框架为自动驾驶决策提供了有效参考。


### [25] [SELFI: Selective Fusion of Identity for Generalizable Deepfake Detection](https://arxiv.org/abs/2506.17592)
*Younghun Kim,Minsuk Jang,Myung-Joon Kwon,Wonjun Lee,Changick Kim*

Main category: cs.CV

TL;DR: SELFI框架通过动态调节身份特征的使用，提升了深度伪造检测的泛化能力，平均AUC提升3.1%。

- Motivation: 解决身份特征在深度伪造检测中的矛盾使用（抑制或依赖），提出需根据样本相关性动态控制。
- Method: 提出SELFI框架，包含FAIA（提取并投影身份特征）和IAFM（选择性融合身份与视觉特征）。
- Result: 在四个基准测试中，SELFI平均AUC提升3.1%，在DFDC数据集上提升6%。
- Conclusion: 身份特征应动态控制而非盲目抑制或依赖，SELFI框架显著提升了检测性能。


### [26] [A Multimodal In Vitro Diagnostic Method for Parkinson's Disease Combining Facial Expressions and Behavioral Gait Data](https://arxiv.org/abs/2506.17596)
*Wei Huang,Yinxuan Xu,Yintao Zhou,Zhengyu Li,Jing Huang,Meng Pang*

Main category: cs.CV

TL;DR: 提出了一种基于面部表情和步态的多模态体外诊断方法，用于帕金森病的早期检测，解决了现有方法的局限性。

- Motivation: 帕金森病的不可治愈性和快速进展对患者及其家庭造成严重影响，早期检测需求增加，但现有方法存在数据不足、设备要求高和单模态风险等问题。
- Method: 采用轻量级深度学习模型进行特征提取和融合，结合面部表情和步态数据，提高诊断准确性并便于移动设备部署。
- Result: 建立了最大的多模态帕金森病数据集，并通过实验验证了方法的有效性。
- Conclusion: 提出的多模态方法在帕金森病早期检测中表现出更高的准确性和实用性。


### [27] [OpenMAP-BrainAge: Generalizable and Interpretable Brain Age Predictor](https://arxiv.org/abs/2506.17597)
*Pengyu Kan,Craig Jones,Kenichi Oishi*

Main category: cs.CV

TL;DR: 提出了一种基于Transformer的模型，用于预测大脑MRI扫描的年龄，具有可解释性和对人口统计学及技术差异的鲁棒性。

- Motivation: 开发一个可解释且对大脑MRI扫描中的人口统计学和技术差异具有鲁棒性的年龄预测模型。
- Method: 采用Transformer架构，结合自监督预训练和伪3D T1加权MRI扫描的三视图处理，引入茎架构降低计算复杂度。
- Result: 在ADNI2 & 3和OASIS3测试集上MAE为3.65年，AIBL数据集上MAE为3.54年，BAG与认知评分显著负相关。
- Conclusion: 模型融合多视图和体积信息，实现了高精度、强泛化性和可解释性，并与神经退行性疾病相关。


### [28] [HIRE: Lightweight High-Resolution Image Feature Enrichment for Multimodal LLMs](https://arxiv.org/abs/2506.17608)
*Nikitha SR,Aradhya Neeraj Mathur,Tarun Ram Menta,Rishabh Jain,Mausoom Sarkar*

Main category: cs.CV

TL;DR: 论文提出了一种浅层特征增强器，通过特征上采样实现高效的高分辨率特征生成，显著降低了计算成本。

- Motivation: 高分辨率图像特征在多模态大语言模型中表现优异，但计算成本高昂，需多次调用大型图像编码器。
- Method: 提出浅层特征增强器，通过特征上采样生成高分辨率特征，减少计算开销。
- Result: 实验表明，该方法在训练和推理时间上大幅降低，计算成本节省高达1.5倍FLOPs。
- Conclusion: 浅层特征增强器在保持性能的同时显著提升了效率，为高分辨率特征生成提供了实用解决方案。


### [29] [JarvisArt: Liberating Human Artistic Creativity via an Intelligent Photo Retouching Agent](https://arxiv.org/abs/2506.17612)
*Yunlong Lin,Zixu Lin,Kunjie Lin,Jinbin Bai,Panwang Pan,Chenxin Li,Haoyu Chen,Zhongdao Wang,Xinghao Ding,Wenbo Li,Shuicheng Yan*

Main category: cs.CV

TL;DR: JarvisArt是一个基于多模态大语言模型的智能修图代理，通过理解用户意图和模仿专业艺术家的推理过程，协调200多种Lightroom工具，提供个性化修图服务。

- Motivation: 解决现有AI修图工具调整性差、泛化能力不足的问题，满足用户多样化和个性化的编辑需求。
- Method: 采用两阶段训练：Chain-of-Thought监督微调建立基础推理能力，GRPO-R优化决策和工具使用；提出Agent-to-Lightroom协议实现无缝集成。
- Result: 在MMArt-Bench上，JarvisArt在内容保真度上比GPT-4o提升60%，同时保持指令跟随能力。
- Conclusion: JarvisArt为用户提供了友好交互、强大泛化和精细控制，为智能修图开辟了新途径。


### [30] [CLiViS: Unleashing Cognitive Map through Linguistic-Visual Synergy for Embodied Visual Reasoning](https://arxiv.org/abs/2506.17629)
*Kailing Li,Qi'ao Xu,Tianwen Qian,Yuqian Fu,Yang Jiao,Xiaoling Wang*

Main category: cs.CV

TL;DR: CLiViS是一个无需训练的新框架，结合LLMs和VLMs的优势，通过动态认知地图实现视觉推理。

- Motivation: 解决EVR中复杂指令和长时序视频的挑战，弥补LLMs和VLMs的不足。
- Method: 利用LLMs进行高层任务规划，VLMs进行开放世界视觉感知，动态更新场景上下文。
- Result: 在多个基准测试中表现优异，尤其在长时序视觉依赖任务中。
- Conclusion: CLiViS通过动态认知地图有效结合感知与推理，提升EVR性能。


### [31] [Optimization-Free Patch Attack on Stereo Depth Estimation](https://arxiv.org/abs/2506.17632)
*Hangcheng Liu,Xu Kuang,Xingshuo Han,Xingwan Wu,Haoran Ou,Shangwei Guo,Xingyi Huang,Tao Xiang,Tianwei Zhang*

Main category: cs.CV

TL;DR: 论文提出了PatchHunter，一种无需优化的对抗性补丁攻击方法，针对立体深度估计（SDE）模型，解决了现有攻击方法在现实场景中适用性差的问题。

- Motivation: 现有SDE模型的对抗攻击方法多局限于不现实的设置（如静态场景的数字扰动），缺乏实际应用价值。研究旨在设计物理可实现、场景自适应且可迁移的攻击方法。
- Method: 提出统一攻击框架，覆盖立体匹配的四个核心阶段；进一步提出PatchHunter，利用强化学习在视觉模式空间中搜索对抗补丁。
- Result: PatchHunter在KITTI数据集、CARLA模拟器和真实车辆部署中表现优异，攻击成功率高且具有更好的黑盒可迁移性。
- Conclusion: PatchHunter为SDE模型提供了更有效的对抗攻击方法，尤其在现实物理条件下表现突出。


### [32] [Adaptive Multi-prompt Contrastive Network for Few-shot Out-of-distribution Detection](https://arxiv.org/abs/2506.17633)
*Xiang Fang,Arvind Easwaran,Blaise Genest*

Main category: cs.CV

TL;DR: 论文提出了一种名为AMCN的新网络，用于解决少样本OOD检测问题，通过自适应多提示对比网络和文本-图像结合的方法，显著提升了性能。

- Motivation: 传统OOD检测方法需要大量训练样本，限制了实际应用。少样本OOD检测更具挑战性，且现有方法忽略了类间多样性。
- Method: 提出AMCN网络，利用CLIP连接文本与图像，生成自适应提示（可学习ID提示、固定标签OOD提示和自适应标签OOD提示），并通过类间阈值和提示引导的ID-OOD分离模块优化边界。
- Result: 实验表明AMCN优于其他最先进方法。
- Conclusion: AMCN通过自适应多提示和文本-图像结合，有效解决了少样本OOD检测问题。


### [33] [Histopathology Image Report Generation by Vision Language Model with Multimodal In-Context Learning](https://arxiv.org/abs/2506.17645)
*Shih-Wen Liu,Hsuan-Yu Fan,Wei-Ta Chu,Fu-En Yang,Yu-Chiang Frank Wang*

Main category: cs.CV

TL;DR: PathGenIC框架通过多模态上下文学习机制，结合训练集中的上下文信息，动态检索相似的WSI-报告对，提升医学报告生成质量。

- Motivation: 自动化生成病理学图像的医学报告是一个关键挑战，需要有效的视觉表示和领域知识。
- Method: 提出PathGenIC框架，利用多模态上下文学习机制，动态检索相似WSI-报告对，并引入自适应反馈。
- Result: 在HistGen基准测试中取得最佳性能，BLEU、METEOR和ROUGE-L指标显著提升，且对不同报告长度和疾病类别具有鲁棒性。
- Conclusion: PathGenIC为AI驱动的病理学报告生成提供了解决方案，为未来多模态临床应用奠定了基础。


### [34] [MDSAM:Memory-Driven Sparse Attention Matrix for LVLMs Hallucination Mitigation](https://arxiv.org/abs/2506.17664)
*Shuaiye Lu,Linjiang Zhou,Xiaochuan Shi*

Main category: cs.CV

TL;DR: 提出了一种无需训练的注意力矩阵方法MDSAM，通过动态调整图像令牌的注意力来减少大型视觉语言模型中的幻觉现象。

- Motivation: 大型视觉语言模型在解码时对图像令牌的敏感性导致幻觉现象，表现为注意力峰值。
- Method: 提出Memory-Driven Sparse Attention Matrix (MDSAM)，动态捕获并优化每层对图像令牌的注意力分配。
- Result: 在图像描述和视觉问答等任务中，MDSAM能持续减少幻觉并提高可靠性。
- Conclusion: MDSAM无需额外训练或外部工具，适用于多种LVLM架构，有效减少幻觉。


### [35] [CSDN: A Context-Gated Self-Adaptive Detection Network for Real-Time Object Detection](https://arxiv.org/abs/2506.17679)
*Wei Haolin*

Main category: cs.CV

TL;DR: 论文提出了一种基于Transformer的检测头CSDN，通过门控机制替代传统自注意力和交叉注意力层，以更高效地利用CNN主干网络的特征，提升目标检测的全局上下文建模能力。

- Motivation: 传统CNN在目标检测中受限于有限的感受野，难以捕捉全局上下文信息。同时，DETR等Transformer架构中存在信息冗余问题。
- Method: 设计了Context-Gated Scale-Adaptive Detection Network (CSDN)，采用门控机制动态选择和组合多注意力模式的特征维度和尺度信息。
- Result: CSDN显著提升了检测精度，且只需少量微调即可适配多种CNN检测器。
- Conclusion: CSDN通过高效的特征利用和全局上下文建模，为目标检测提供了更优的解决方案。


### [36] [Domain Generalization using Action Sequences for Egocentric Action Recognition](https://arxiv.org/abs/2506.17685)
*Amirshayan Nasirimajd,Chiara Plizzari,Simone Alberto Peirone,Marco Ciccone,Giuseppe Averta,Barbara Caputo*

Main category: cs.CV

TL;DR: 论文提出了一种名为SeqDG的领域泛化方法，通过利用动作序列的一致性提升模型在未见环境中的泛化能力，并在两个数据集上验证了其有效性。

- Motivation: 解决Egocentric Action Recognition模型在未见环境中性能下降的问题，利用动作序列的一致性提升泛化能力。
- Method: 提出SeqDG方法，包括视觉-文本序列重建目标（SeqRec）和跨领域动作序列混合训练（SeqMix）。
- Result: 在EPIC-KITCHENS-100上，跨领域动作识别相对提升2.4%；在EGTEA上，模型在领域内动作识别中超过SOTA 0.6% Top-1准确率。
- Conclusion: SeqDG通过动作序列和跨领域训练显著提升了模型在未见环境中的泛化能力。


### [37] [SSAVSV: Towards Unified Model for Self-Supervised Audio-Visual Speaker Verification](https://arxiv.org/abs/2506.17694)
*Gnana Praveen Rajasekhar,Jahangir Alam*

Main category: cs.CV

TL;DR: 提出了一种基于对比学习和掩码数据建模的自监督学习框架，用于音频-视觉说话人验证，减少了计算成本并提高了鲁棒性。

- Motivation: 传统音频-视觉方法依赖大量标记数据和独立模态架构，计算成本高且扩展性差。
- Method: 使用不对称掩码和掩码数据建模的自监督学习框架，采用共享视觉Transformer骨干网络处理多模态输入。
- Result: 实验表明，该方法在无标记数据下表现优异，计算成本低于传统方法。
- Conclusion: 提出的统一框架在计算效率和鲁棒性上优于传统方法，适用于多模态输入。


### [38] [DreamJourney: Perpetual View Generation with Video Diffusion Models](https://arxiv.org/abs/2506.17705)
*Bo Pan,Yang Chen,Yingwei Pan,Ting Yao,Wei Chen,Tao Mei*

Main category: cs.CV

TL;DR: DreamJourney提出了一种两阶段框架，利用视频扩散模型生成动态场景的长期视频，解决了现有方法在3D感知和动态对象运动方面的不足。

- Motivation: 现有方法基于2D扩散模型，缺乏3D感知能力，且无法捕捉动态4D世界中的对象运动。DreamJourney旨在解决这些问题。
- Method: 第一阶段将输入图像提升为3D点云并渲染部分图像序列，利用视频扩散模型补全缺失区域；第二阶段通过多模态大语言模型生成对象运动描述，并用视频扩散模型动画化当前视图。
- Result: 实验表明，DreamJourney在定量和定性上均优于现有方法。
- Conclusion: DreamJourney通过结合3D感知和动态对象运动，实现了更高质量的长期动态场景生成。


### [39] [Programmable-Room: Interactive Textured 3D Room Meshes Generation Empowered by Large Language Models](https://arxiv.org/abs/2506.17707)
*Jihyun Kim,Junho Park,Kyeongbo Kong,Suk-Ju Kang*

Main category: cs.CV

TL;DR: Programmable-Room是一个通过自然语言指令交互式生成和编辑3D房间网格的框架，利用视觉编程（VP）和大型语言模型（LLM）分解任务并统一处理。

- Motivation: 为了实现对房间属性的精确控制，将复杂的3D房间生成任务分解为多个简单步骤，并通过统一的框架支持这些任务。
- Method: 采用视觉编程（VP）方法，利用LLM生成类似Python的程序模块，整合3D坐标生成、全景图像纹理生成、3D网格构建和家具布置等模块。纹理生成模块使用预训练的大规模扩散模型，并通过双向LSTM优化训练目标。
- Result: 展示了框架在生成和编辑3D房间网格方面的灵活性，并在定量和定性上优于现有模型。
- Conclusion: Programmable-Room通过分解任务和视觉编程方法，实现了高效且高质量的3D房间生成与编辑。


### [40] [PDC-Net: Pattern Divide-and-Conquer Network for Pelvic Radiation Injury Segmentation](https://arxiv.org/abs/2506.17712)
*Xinyu Xiong,Wuteng Cao,Zihuang Wu,Lei Zhang,Chong Gao,Guanbin Li,Qiyuan Qin*

Main category: cs.CV

TL;DR: 提出了一种名为PDC-Net的新网络，用于MRI中盆腔放射损伤（PRI）的自动分割，通过多方向聚合模块和记忆引导上下文模块提升分割精度。

- Motivation: 盆腔放射损伤（PRI）的精确分割对预后评估和个性化治疗计划至关重要，但现有方法因器官形态复杂和上下文混淆而面临挑战。
- Method: 提出PDC-Net，包含多方向聚合模块（MDA）增强形状拟合，记忆引导上下文模块（MGC）提升全局模式区分，以及自适应融合解码器（AFD）动态选择特征。
- Result: 在首个大规模盆腔放射损伤数据集上验证，PDC-Net优于现有方法。
- Conclusion: PDC-Net通过分而治之的策略有效解决了PRI分割中的挑战，为临床提供了更精确的工具。


### [41] [YOLOv13: Real-Time Object Detection with Hypergraph-Enhanced Adaptive Visual Perception](https://arxiv.org/abs/2506.17733)
*Mengqi Lei,Siqi Li,Yihong Wu,Han Hu,You Zhou,Xinhu Zheng,Guiguang Ding,Shaoyi Du,Zongze Wu,Yue Gao*

Main category: cs.CV

TL;DR: YOLOv13提出了一种基于超图的自适应相关性增强机制（HyperACE）和全流程聚合与分配范式（FullPAD），显著提升了复杂场景下的目标检测性能，同时减少了参数和计算量。

- Motivation: 现有YOLO系列模型在全局多对多高阶相关性建模方面存在不足，限制了复杂场景下的检测性能。
- Method: 提出HyperACE机制和FullPAD范式，利用超图计算实现全局特征融合，并采用深度可分离卷积降低计算复杂度。
- Result: 在MS COCO基准测试中，YOLOv13-N的mAP比YOLO11-N提升3.0%，比YOLOv12-N提升1.5%。
- Conclusion: YOLOv13通过创新机制和范式，实现了高效且高性能的实时目标检测。


### [42] [PhysID: Physics-based Interactive Dynamics from a Single-view Image](https://arxiv.org/abs/2506.17746)
*Sourabh Vasant Gothe,Ayon Chattopadhyay,Gunturi Venkata Sai Phani Kiran,Pratik,Vibhav Agarwal,Jayesh Rajkumar Vachhani,Sourav Ghosh,Parameswaranath VM,Barath Raj KR*

Main category: cs.CV

TL;DR: PhysID利用生成模型从单视角图像创建物理交互动态，简化3D建模和物理属性校准，实现实时交互和个性化体验。

- Motivation: 将静态图像转化为交互式体验是计算机视觉中的挑战，PhysID旨在通过简化流程提升移动用户体验。
- Method: 利用大型生成模型进行3D网格生成和物理属性预测，结合设备端物理引擎实现实时渲染。
- Result: 实验验证了多模态大语言模型的零样本能力和3D重建模型的性能，展示了端到端框架的有效性。
- Conclusion: PhysID在移动设备上实现了实时、非确定性交互和个性化体验，显著降低了技术门槛。


### [43] [LoLA-SpecViT: Local Attention SwiGLU Vision Transformer with LoRA for Hyperspectral Imaging](https://arxiv.org/abs/2506.17759)
*Fadi Abdeladhim Zidi,Djamel Eddine Boukhari,Abdellah Zakaria Sellam,Abdelkrim Ouafi,Cosimo Distante,Salah Eddine Bekhouche,Abdelmalik Taleb-Ahmed*

Main category: cs.CV

TL;DR: 提出了一种轻量级光谱视觉变换器（LoLA-SpecViT），通过参数高效架构解决高光谱图像分类中的高维度和标签稀缺问题，结合3D卷积和局部自注意力，显著提升性能。

- Motivation: 高光谱图像分类面临高维数据、频带冗余和标注样本稀缺的挑战，现有变换器模型在标签稀缺条件下的可扩展性和适应性不足。
- Method: 结合3D卷积前端和局部窗口自注意力，引入低秩适应（LoRA）减少可训练参数，使用循环学习率调度器优化训练。
- Result: 在三个基准数据集上表现优异，最高达99.91%准确率，参数更少且低标签条件下鲁棒性更强。
- Conclusion: LoLA-SpecViT为高光谱图像应用提供了可扩展且通用的解决方案，适用于农业、环境监测等领域。


### [44] [Incorporating Rather Than Eliminating: Achieving Fairness for Skin Disease Diagnosis Through Group-Specific Expert](https://arxiv.org/abs/2506.17787)
*Gelei Xu,Yuying Duan,Zheyuan Liu,Xueyang Li,Meng Jiang,Michael Lemmon,Wei Jin,Yiyu Shi*

Main category: cs.CV

TL;DR: FairMoE框架通过动态路由数据到最合适的专家模块，解决了AI在皮肤病诊断中的偏见问题，同时保持高准确性和公平性。

- Motivation: 现有偏见缓解方法常因消除敏感属性与诊断预测的关联而丢失临床相关线索，导致性能下降。FairMoE旨在通过利用敏感属性实现公平性。
- Method: 提出FairMoE框架，采用分层混合专家模块作为群体特定学习器，动态路由数据而非硬性分组。
- Result: 实验显示FairMoE在保持公平性指标的同时显著提升了准确性，优于传统方法。
- Conclusion: FairMoE为AI诊断中的公平性问题提供了一种有效且性能优越的解决方案。


### [45] [Time-Contrastive Pretraining for In-Context Image and Video Segmentation](https://arxiv.org/abs/2506.17837)
*Assefa Wahd,Jacob Jaremko,Abhilash Hareendranathan*

Main category: cs.CV

TL;DR: 提出了一种名为Temporal的自监督目标，用于视觉上下文学习（ICL），通过重新定义ICL为视频对象分割（VOS）任务，解决了传统网格方法的限制。

- Motivation: 主流ICL方法依赖网格策略，缺乏视觉应用所需的灵活性，限制了上下文图像的数量和分辨率。
- Method: 引入Temporal自监督目标预训练提示检索器，将ICL重新定义为VOS任务，支持可变数量的上下文图像并保持其完整分辨率。
- Result: 在MICCAI FLARE 2022上，图像分割Dice得分提升10.64%（90.95%），视频分割提升14.88%（92.45%）。
- Conclusion: Temporal方法显著提升了视觉ICL的性能，解决了网格方法的局限性。


### [46] [Robust Foreground-Background Separation for Severely-Degraded Videos Using Convolutional Sparse Representation Modeling](https://arxiv.org/abs/2506.17838)
*Kazuki Naganuma,Shunsuke Ono*

Main category: cs.CV

TL;DR: 提出了一种基于卷积稀疏表示（CSR）的前景-背景分离方法，用于处理低帧率和噪声视频。

- Motivation: 现有方法无法准确分离前景和背景，且缺乏对多种噪声的显式建模。
- Method: 结合CSR、通用特征捕获函数和显式噪声表征函数，构建多凸优化问题，并通过交替求解子问题实现。
- Result: 实验表明，该方法在红外和显微镜视频中优于现有方法。
- Conclusion: 提出的方法能有效分离前景和背景，并处理多种噪声和低帧率问题。


### [47] [Fetuses Made Simple: Modeling and Tracking of Fetal Shape and Pose](https://arxiv.org/abs/2506.17858)
*Yingcheng Liu,Peiqi Wang,Sebastian Diaz,Esra Abaci Turk,Benjamin Billot,Patricia Ellen Grant,Polina Golland*

Main category: cs.CV

TL;DR: 提出了一种基于SMPL的3D胎儿统计身体模型，用于改进胎儿MRI分析中的形状和运动捕捉，解决了现有方法在细节丢失或时间分析复杂的问题。

- Motivation: 现有胎儿MRI分析方法依赖解剖关键点或体积分割，前者简化结构但忽略细节，后者完整但难以处理时间序列。
- Method: 构建3D统计胎儿身体模型，迭代估计图像空间中的姿态和标准姿态空间中的形状，提高对MRI伪影和失真鲁棒性。
- Result: 模型在未见过的胎儿形状上达到3.2 mm表面对齐误差（3 mm体素大小），并支持自动人体测量。
- Conclusion: 该方法首次实现3D胎儿统计身体模型，为产前诊断中的运动和形状分析提供了新工具。


### [48] [Cross-modal State Space Modeling for Real-time RGB-thermal Wild Scene Semantic Segmentation](https://arxiv.org/abs/2506.17869)
*Xiaodong Guo,Zi'ang Lin,Luwen Hu,Zhihong Deng,Tong Liu,Wujie Zhou*

Main category: cs.CV

TL;DR: CM-SSM是一种高效的RGB-热语义分割架构，通过跨模态状态空间建模（SSM）方法，解决了多源数据处理的计算开销问题。

- Motivation: 在野外环境中，RGB和热数据的融合可以显著提升语义分割性能，但现有方法（如基于Transformer的方法）计算开销大，难以在资源受限的系统上运行。
- Method: CM-SSM包含两个关键模块：跨模态2D选择性扫描（CM-SS2D）用于建立模态间的状态空间模型，以及跨模态状态空间关联（CM-SSA）用于整合全局关联和局部空间特征。
- Result: 实验表明，CM-SSM在CART数据集上实现了最先进的性能，且参数和计算成本更低；在PST900数据集上也表现出良好的泛化能力。
- Conclusion: CM-SSM通过线性计算复杂度解决了多源数据处理的效率问题，同时保持了高性能。


### [49] [SurgVidLM: Towards Multi-grained Surgical Video Understanding with Large Language Model](https://arxiv.org/abs/2506.17873)
*Guankun Wang,Wenjin Mo,Junyi Wang,Long Bai,Kun Yuan,Ming Hu,Jinlin Wu,Junjun He,Yiming Huang,Nicolas Padoy,Zhen Lei,Hongbin Liu,Nassir Navab,Hongliang Ren*

Main category: cs.CV

TL;DR: SurgVidLM是首个专为精细手术视频理解设计的视频语言模型，通过SVU-31K数据集和StageFocus机制，显著优于现有Vid-LLMs。

- Motivation: 现有视频语言模型缺乏对手术视频精细任务的支持，而手术视频的复杂序列信息需要专门模型。
- Method: 提出SurgVidLM，使用SVU-31K数据集训练，引入StageFocus机制和Multi-frequency Fusion Attention。
- Result: SurgVidLM在全面和精细视频理解任务中表现优异。
- Conclusion: SurgVidLM填补了手术视频精细理解领域的空白，展示了复杂场景下的优越性能。


### [50] [StainPIDR: A Pathological Image Decouplingand Reconstruction Method for StainNormalization Based on Color VectorQuantization and Structure Restaining](https://arxiv.org/abs/2506.17879)
*Zheng Chen*

Main category: cs.CV

TL;DR: 提出了一种名为StainPIDR的染色归一化方法，通过解耦图像的结构特征和颜色特征，并利用目标颜色特征重新染色，以解决病理图像颜色差异问题。

- Motivation: 病理图像的颜色差异可能影响计算机辅助诊断系统的性能，因此需要一种有效的方法来归一化染色。
- Method: 通过解耦图像的结构和颜色特征，训练固定的颜色向量码本，并利用交叉注意力机制重新染色结构特征。还设计了模板图像选择算法。
- Result: 实验验证了StainPIDR和模板选择算法的有效性，表明该方法在染色归一化任务中表现良好。
- Conclusion: StainPIDR能有效解决病理图像颜色差异问题，代码将公开。


### [51] [Cloud-Aware SAR Fusion for Enhanced Optical Sensing in Space Missions](https://arxiv.org/abs/2506.17885)
*Trong-An Bui,Thanh-Thoai Le*

Main category: cs.CV

TL;DR: 提出了一种结合SAR-光学特征融合和深度学习的云注意力重建框架，用于生成无云光学图像，显著提升了重建质量。

- Motivation: 云污染严重影响光学卫星图像的可用性，阻碍环境监测、灾害响应和土地利用分析等关键应用。
- Method: 采用注意力驱动的特征融合机制，结合SAR的结构信息和光学数据的光谱特征，并引入云感知模型更新策略，自适应加权损失以优化云遮挡区域的重建。
- Result: 实验结果表明，该方法在PSNR（31.01 dB）、SSIM（0.918）和MAE（0.017）上优于现有方法。
- Conclusion: 该框架能有效生成高保真、空间和光谱一致的无云光学图像。


### [52] [Relation3D: Enhancing Relation Modeling for Point Cloud Instance Segmentation](https://arxiv.org/abs/2506.17891)
*Jiahao Lu,Jiacheng Deng*

Main category: cs.CV

TL;DR: Relation3D通过自适应超点聚合模块和对比学习引导的超点细化模块改进3D实例分割，增强场景特征和查询特征之间的关系建模。

- Motivation: 现有基于Transformer的方法主要关注场景特征与查询特征的外部关系，缺乏对场景特征内部及查询特征之间关系的有效建模。
- Method: 提出自适应超点聚合模块和对比学习引导的超点细化模块，改进超点特征表示；引入关系感知自注意力机制，结合位置和几何关系增强查询特征间的关系建模。
- Result: 在ScanNetV2、ScanNet++、ScanNet200和S3DIS数据集上表现出优越性能。
- Conclusion: Relation3D通过改进关系建模，显著提升了3D实例分割的效果。


### [53] [BeltCrack: the First Sequential-image Industrial Conveyor Belt Crack Detection Dataset and Its Baseline with Triple-domain Feature Learning](https://arxiv.org/abs/2506.17892)
*Jianghong Huang,Luping Ji,Xin Ma,Mao Ye*

Main category: cs.CV

TL;DR: 本文构建了首个真实工业场景的传送带裂缝数据集（BeltCrack14ks和BeltCrack9kd），并提出了一种基于时空频三域特征分层融合的基线方法，验证了数据集的有效性和方法的优越性。

- Motivation: 传送带裂缝是影响工业安全的重要因素，但现有数据集多为路面或合成数据，缺乏真实工业场景的数据集，阻碍了机器学习在该领域的应用。
- Method: 构建了真实工业场景的传送带裂缝数据集，并提出了一种基于时空频三域特征分层融合的基线方法。
- Result: 实验结果表明数据集有效，且基线方法明显优于其他类似检测方法。
- Conclusion: 本文填补了真实工业传送带裂缝数据集的空白，并验证了基线方法的有效性，为后续研究提供了基础。


### [54] [EgoWorld: Translating Exocentric View to Egocentric View using Rich Exocentric Observations](https://arxiv.org/abs/2506.17896)
*Junho Park,Andrew Sangwoo Ye,Taein Kwon*

Main category: cs.CV

TL;DR: EgoWorld是一个两阶段框架，通过外中心观测重建自我中心视角，解决了现有方法的局限性，并在多个数据集上表现优异。

- Motivation: 自我中心视觉对AR、VR和机器人应用至关重要，但现有方法依赖2D线索和多视角同步设置，存在局限性。
- Method: EgoWorld通过外中心深度图重建点云，重投影到自我中心视角，并利用扩散修复生成密集图像。
- Result: 在H2O和TACO数据集上达到最优性能，并能泛化到新对象、动作和场景。
- Conclusion: EgoWorld在无标签真实场景中也表现良好，展示了其实际应用潜力。


### [55] [PostAlign: Multimodal Grounding as a Corrective Lens for MLLMs](https://arxiv.org/abs/2506.17901)
*Yixuan Wu,Yang Zhang,Jian Wu,Philip Torr,Jindong Gu*

Main category: cs.CV

TL;DR: MMGrounded-PostAlign框架通过多模态对齐提升MLLMs的视觉理解能力，减少幻觉。

- Motivation: 解决MLLMs在视觉语言任务中过度依赖虚假相关性和语言先验的问题。
- Method: 引入多模态接地模块（视觉和文本接地）和负拒绝机制，选择性推理机制。
- Result: 在多个基准测试中显著提升细粒度视觉理解和幻觉抑制。
- Conclusion: MMGrounded-PostAlign有效提升MLLMs的视觉理解能力并减少幻觉。


### [56] [Cause-Effect Driven Optimization for Robust Medical Visual Question Answering with Language Biases](https://arxiv.org/abs/2506.17903)
*Huanjia Zhu,Yishu Liu,Xiaozhao Fang,Guangming Lu,Bingzhi Chen*

Main category: cs.CV

TL;DR: 提出了一种名为CEDO的新框架，通过三种机制（MHO、GMS、DLR）从因果和效应角度全面缓解医学视觉问答模型中的语言偏见。

- Motivation: 现有医学视觉问答模型存在语言偏见问题，即问题类型与答案类别之间建立了虚假关联。
- Method: CEDO框架包含三种机制：MHO（模态驱动的异构优化）、GMS（梯度引导的模态协同）和DLR（分布适应的损失重新缩放），分别从不同角度缓解偏见。
- Result: 在多个传统和偏见敏感基准测试中，CEDO表现出优于现有方法的鲁棒性。
- Conclusion: CEDO通过综合优化机制有效缓解了语言偏见，提升了模型的鲁棒性。


### [57] [Feedback Driven Multi Stereo Vision System for Real-Time Event Analysis](https://arxiv.org/abs/2506.17910)
*Mohamed Benkedadra,Matei Mancas,Sidi Ahmed Mahmoudi*

Main category: cs.CV

TL;DR: 提出了一种基于3D立体视觉的交互系统管道，通过融合多个3D相机实现全场景重建，适用于普通和敏感应用，支持事件识别、目标跟踪等功能。

- Motivation: 现有2D和3D相机在复杂环境中不可靠，需要更稳健的场景理解方法。
- Method: 融合多个3D相机进行全场景重建，结合反馈机制优化决策。
- Result: 初步实验展示了管道的可行性和功能多样性。
- Conclusion: 提出了下一步研究计划以推动管道进入生产阶段。


### [58] [PlanMoGPT: Flow-Enhanced Progressive Planning for Text to Motion Synthesis](https://arxiv.org/abs/2506.17912)
*Chuhao Jin,Haosen Li,Bingzi Zhang,Che Liu,Xiting Wang,Ruihua Song,Wenbing Huang,Ying Qin,Fuzheng Zhang,Di Zhang*

Main category: cs.CV

TL;DR: PlanMoGPT通过渐进式规划和流增强的细粒度运动标记化，解决了LLM在文本到运动生成中的性能瓶颈，显著提升了生成质量和多样性。

- Motivation: 当前基于LLM的文本到运动生成方法在性能上落后于非LLM方法，主要问题在于运动标记化的粒度选择：细粒度标记化导致局部依赖问题，而粗粒度标记化牺牲了运动细节。
- Method: 提出PlanMoGPT框架，结合渐进式规划和流增强的细粒度运动标记化。渐进式规划利用LLM的自回归能力分层生成运动标记，流增强标记化通过提高下采样分辨率和扩大码本规模减少细节损失。
- Result: 在文本到运动基准测试中，PlanMoGPT实现了最先进的性能，长序列生成的FID分数提升了63.8%，运动多样性提高了49.9%。
- Conclusion: PlanMoGPT成功解决了当前非LLM方法中多样性-质量的权衡问题，为文本到运动生成设定了新标准。


### [59] [IDAL: Improved Domain Adaptive Learning for Natural Images Dataset](https://arxiv.org/abs/2506.17931)
*Ravi Kant Gupta,Shounak Das,Amit Sethi*

Main category: cs.CV

TL;DR: 提出了一种新的无监督域适应方法，通过结合ResNet和FPN的架构以及创新的损失函数，显著提升了域适应性能。

- Motivation: 解决现有对抗域适应方法在多模态分布对齐上的不足，特别是在自然图像中存在的尺度、噪声和风格变化问题。
- Method: 结合ResNet和FPN的深度架构，设计新的损失函数组合，以处理多模态分布和自然图像的挑战。
- Result: 在Office-Home、Office-31和VisDA-2017数据集上优于现有方法，在DomainNet上表现相当。
- Conclusion: 该方法在域适应任务中表现出更高的准确性和鲁棒性，同时加速了训练收敛。


### [60] [GEMeX-ThinkVG: Towards Thinking with Visual Grounding in Medical VQA via Reinforcement Learning](https://arxiv.org/abs/2506.17939)
*Bo Liu,Xiangyu Zhao,Along He,Yidi Chen,Huazhu Fu,Xiao-Ming Wu*

Main category: cs.CV

TL;DR: 论文提出了一种名为ThinkVG的数据集和可验证奖励机制，以提高医学视觉问答的可靠性和可解释性。

- Motivation: 当前医学视觉问答模型的答案可靠性和可解释性不足，影响了临床决策的信任度。
- Method: 通过分解答案生成过程为中间推理步骤，并引入可验证奖励机制进行强化学习后训练。
- Result: 方法仅用八分之一的数据即达到可比性能，验证了其高效性和有效性。
- Conclusion: 提出的数据集和方法显著提升了医学视觉问答的可解释性和可靠性。


### [61] [SegChange-R1:Augmented Reasoning for Remote Sensing Change Detection via Large Language Models](https://arxiv.org/abs/2506.17944)
*Fei Zhou*

Main category: cs.CV

TL;DR: 提出了一种基于大语言模型（LLM）的增强推理方法（SegChange-R1），通过整合文本描述信息提升变化检测能力，并设计了基于线性注意力的空间变换模块（BEV）解决模态对齐问题。

- Motivation: 提升遥感变化检测的精度和效率，特别是在建筑物变化检测中，通过引入文本描述和统一特征空间来优化模型性能。
- Method: 结合LLM增强推理方法（SegChange-R1）和线性注意力空间变换模块（BEV），构建了首个无人机视角建筑物变化检测数据集（DVCD）。
- Result: 在四个广泛使用的变化检测数据集上实验表明，该方法显著优于现有方法。
- Conclusion: SegChange-R1通过文本描述和BEV模块有效提升了变化检测性能，为相关领域提供了新的解决方案。


### [62] [Classification of Tents in Street Bazaars Using CNN](https://arxiv.org/abs/2506.17946)
*Azamat Ibragimov,Ruslan Isaev,Remudin Reshid Mekuria,Gulnaz Gimaletdinova,Dim Shaiakhmetov*

Main category: cs.CV

TL;DR: 论文提出了一种改进的深度学习模型，用于分类街头市集中的帐篷，比较了自定义CNN和EfficientNetB0的性能。结果显示EfficientNetB0在分类准确率上表现更优。

- Motivation: 街头市集是许多地区的重要经济中心，但其非结构化特性使得帐篷等基础设施的自动分类具有挑战性。传统手动方法效率低下，因此需要更高效的自动化解决方案。
- Method: 研究使用自定义CNN和EfficientNetB0模型，基于126张原始照片及其增强数据集进行训练，并通过多种性能指标（如准确率、精确率、召回率等）评估模型。
- Result: 自定义CNN达到92.8%的准确率，而EfficientNetB0达到98.4%，表明迁移学习在分类任务中效果显著。
- Conclusion: 预训练模型（如EfficientNetB0）能显著提升分类准确率和泛化能力，适用于市集图像分类任务。


### [63] [Mobile Image Analysis Application for Mantoux Skin Test](https://arxiv.org/abs/2506.17954)
*Liong Gele,Tan Chye Cheah*

Main category: cs.CV

TL;DR: 本文介绍了一款新开发的移动应用，用于通过Mantoux皮肤试验（TST）诊断潜伏性结核感染（LTBI），解决了传统方法的低随访率、患者不适和主观测量问题。

- Motivation: 传统TST方法存在随访率低、患者不适和主观测量误差的问题，导致误诊和治疗延迟。
- Method: 应用采用带比例尺的贴纸作为参考物，结合ARCore和DeepLabv3等图像处理与机器学习技术，实现皮肤硬结的精确测量。
- Result: 与标准临床实践相比，该应用显著提高了准确性和可靠性。
- Conclusion: 该创新为结核病管理提供了高效工具，未来将优化算法和扩展功能。


### [64] [ELMAR: Enhancing LiDAR Detection with 4D Radar Motion Awareness and Cross-modal Uncertainty](https://arxiv.org/abs/2506.17958)
*Xiangyuan Peng,Miao Tang,Huawei Sun,Bierzynski Kay,Lorenzo Servadei,Robert Wille*

Main category: cs.CV

TL;DR: 论文提出了一种结合4D雷达运动状态和跨模态不确定性的LiDAR检测框架，以解决LiDAR和4D雷达融合中的未对齐问题，并在VoD数据集上取得了优异性能。

- Motivation: LiDAR和4D雷达在自动驾驶中各有优势，但融合时存在模态未对齐问题，需要一种方法充分利用两者的优势。
- Method: 通过动态运动感知编码模块提取4D雷达的运动信息，并估计边界框的实例级不确定性以减少跨模态未对齐，优化LiDAR预测。
- Result: 在VoD数据集上，整个区域的mAP达到74.89%，驾驶走廊内达到88.70%，实时推理速度为30.02 FPS。
- Conclusion: 该方法有效解决了跨模态未对齐问题，结合了LiDAR和4D雷达的优势，实现了高性能的实时检测。


### [65] [BPCLIP: A Bottom-up Image Quality Assessment from Distortion to Semantics Based on CLIP](https://arxiv.org/abs/2506.17969)
*Chenyue Song,Chen Hui,Wei Zhang,Haiqi Zhu,Shaohui Liu,Hong Huang,Feng Jiang*

Main category: cs.CV

TL;DR: 提出了一种基于CLIP的自底向上图像质量评估方法BPCLIP，通过多尺度交叉注意力模块和文本编码器增强图像质量与人类语言的关联，在多个基准测试中表现优异。

- Motivation: 现有方法多采用线性融合多尺度特征，未能充分捕捉失真对语义内容的影响，需改进。
- Method: 利用CLIP模型，设计自底向上的多尺度交叉注意力模块，结合40个图像质量形容词，增强图像质量与语言的关联。
- Result: 在多数公共FR和NR IQA基准测试中表现优异，且更具鲁棒性。
- Conclusion: BPCLIP通过结合CLIP和自底向上方法，有效提升了图像质量评估的性能和鲁棒性。


### [66] [Enabling PSO-Secure Synthetic Data Sharing Using Diversity-Aware Diffusion Models](https://arxiv.org/abs/2506.17975)
*Mischa Dombrowski,Bernhard Kainz*

Main category: cs.CV

TL;DR: 论文提出了一种通过最大化多样性来保护隐私的合成数据生成框架，性能接近真实数据。

- Motivation: 合成数据在医学影像中具有隐私保护潜力，但现有方法在合法性和性能上存在不足。
- Method: 提出了一种通用的扩散模型训练框架，生成非个人化的合成数据。
- Result: 合成数据性能接近真实数据，显著优于不保护隐私的现有方法。
- Conclusion: 最大化多样性不仅能提升性能，还能保护隐私，为合成数据应用提供了新思路。


### [67] [Fast Neural Inverse Kinematics on Human Body Motions](https://arxiv.org/abs/2506.17996)
*David Tolpin,Sefy Kagarlitsky*

Main category: cs.CV

TL;DR: 提出了一种快速可靠的神经逆向运动学框架，用于从3D关键点实时捕捉人体运动。

- Motivation: 无标记运动捕捉具有灵活性和低成本优势，但计算需求高且推理速度慢，限制了实时应用。
- Method: 详细描述了网络架构、训练方法和推理流程，并通过消融研究验证设计决策。
- Result: 框架在定性和定量评估中表现良好。
- Conclusion: 该框架为实时人体运动捕捉提供了一种高效解决方案。


### [68] [OSDMamba: Enhancing Oil Spill Detection from Remote Sensing Images Using Selective State Space Model](https://arxiv.org/abs/2506.18006)
*Shuaiyu Chen,Fu Wang,Peng Ren,Chunbo Luo,Zeyu Fu*

Main category: cs.CV

TL;DR: OSDMamba，一种基于Mamba的架构，用于油污检测，通过选择性扫描机制和多尺度特征融合，显著提升了检测精度。

- Motivation: 现有方法在油污检测中面临样本不足、类别不平衡和小区域检测困难的问题，需要更有效的解决方案。
- Method: 提出OSDMamba，结合Mamba的选择性扫描机制和不对称解码器，增强多尺度特征融合和细节保留。
- Result: 在两个公开数据集上，OSDMamba的性能提升了8.9%和11.8%。
- Conclusion: OSDMamba在油污检测中表现出色，为小区域检测和类别不平衡问题提供了有效解决方案。


### [69] [On the Robustness of Human-Object Interaction Detection against Distribution Shift](https://arxiv.org/abs/2506.18021)
*Chi Xie,Shuang Liang,Jie Li,Feng Zhu,Rui Zhao,Yichen Wei,Shengjie Zhao*

Main category: cs.CV

TL;DR: 论文提出了一种评估HOI检测模型鲁棒性的新方法，并通过数据增强和特征融合策略显著提升了模型的性能。

- Motivation: 现有HOI检测模型在理想图像和自然分布下表现良好，但在实际场景中分布偏移时性能不足，限制了其实际应用。
- Method: 提出自动化方法创建鲁棒性评估基准，评估40多个现有模型，并通过跨域数据增强和特征融合策略改进模型。
- Result: 实验表明，提出的方法显著提升了多种模型的鲁棒性，并在标准基准测试中也有益处。
- Conclusion: 该研究为HOI检测模型的鲁棒性提供了新思路，并展示了简单有效的方法提升性能。


### [70] [PP-DocBee2: Improved Baselines with Efficient Data for Multimodal Document Understanding](https://arxiv.org/abs/2506.18023)
*Kui Huang,Xinrong Chen,Wenyu Lv,Jincheng Liao,Guanzhong Wang,Yi Liu*

Main category: cs.CV

TL;DR: PP-DocBee2是PP-DocBee的升级版，通过提升合成数据质量、改进视觉特征融合策略和优化推理方法，显著提升了中文商业文档的理解性能。

- Motivation: 解决PP-DocBee在多模态文档理解中的局限性，提升性能与效率。
- Method: 采用大规模多模态预训练模型评估数据质量，优化训练数据；分解ViT层并应用新特征融合策略增强推理能力。
- Result: 性能提升11.4%，推理延迟降低73%。
- Conclusion: PP-DocBee2通过技术创新显著提升了多模态文档理解任务的效率和效果。


### [71] [MiCo: Multiple Instance Learning with Context-Aware Clustering for Whole Slide Image Analysis](https://arxiv.org/abs/2506.18028)
*Junjian Li,Hulin Kuang,Jin Liu,Hailin Yue,Mengshen He,Jianxin Wang*

Main category: cs.CV

TL;DR: 提出了一种名为MiCo的多实例学习框架，通过上下文感知聚类增强WSI中跨区域的组织相关性。

- Motivation: 解决WSI中组织分布分散和跨区域空间交互难以建模的问题。
- Method: MiCo通过聚类提取形态模式，使用Cluster Route模块动态链接相同组织类型，Cluster Reducer模块整合冗余锚点。
- Result: 在九个大型癌症数据集上表现优于现有方法。
- Conclusion: MiCo有效增强了WSI中组织的语义关联和相关性。


### [72] [Pre-Trained LLM is a Semantic-Aware and Generalizable Segmentation Booster](https://arxiv.org/abs/2506.18034)
*Fenghe Tang,Wenxin Ma,Zhiyang He,Xiaodong Tao,Zihang Jiang,S. Kevin Zhou*

Main category: cs.CV

TL;DR: 本文提出了一种结合预训练冻结LLM层的混合结构（LLM4Seg），用于医学图像分割任务，显著提升了性能。

- Motivation: 探索预训练大型语言模型（LLM）在视觉任务中的潜力，尤其是医学图像分割。
- Method: 设计了一个简单的混合结构，将冻结的预训练LLM层集成到CNN编码器-解码器分割框架中。
- Result: 该设计在多种医学图像模态中提升了分割性能，且仅需少量可训练参数。
- Conclusion: LLM的语义感知能力可有效迁移至视觉任务，增强全局理解和局部建模能力。


### [73] [CmFNet: Cross-modal Fusion Network for Weakly-supervised Segmentation of Medical Images](https://arxiv.org/abs/2506.18042)
*Dongdong Meng,Sheng Li,Hao Wu,Suqing Tian,Wenjun Ma,Guoping Wang,Xueqing Yan*

Main category: cs.CV

TL;DR: 提出了一种名为CmFNet的3D弱监督跨模态医学图像分割方法，通过多模态特征学习和混合监督策略解决稀疏标注导致的性能下降和过拟合问题。

- Motivation: 高精度医学图像分割需要密集标注，成本高且耗时。弱监督学习利用稀疏标注更高效，但存在性能下降和过拟合问题。
- Method: CmFNet包含三个组件：模态特定特征学习网络、跨模态特征学习网络和混合监督学习策略，结合多模态信息和多种监督方式。
- Result: 在临床和公开数据集上表现优于现有弱监督方法，甚至优于全监督方法。
- Conclusion: CmFNet有效提升分割性能，适用于临床治疗和多种医学专家。


### [74] [CLGRPO: Reasoning Ability Enhancement for Small VLMs](https://arxiv.org/abs/2506.18048)
*Fanyi Wang,Binzhi Dong,Haotian Hu,Jinjin Xu,Zhiwang Zhang*

Main category: cs.CV

TL;DR: 本文提出了一种增量训练策略（Incremental Training Strategy），通过自监督构建COT数据和多阶段训练，显著提升了小视觉语言模型（SVLMs）的推理能力。

- Motivation: SVLMs因参数规模小（≤2B）而成本低，但推理能力受限。本文旨在通过优化训练策略提升其性能。
- Method: 1. 自监督构建COT数据；2. 四阶段增量训练（SFT、格式对齐GRPO、推理增强GRPO、CLGRPO约束）。
- Result: 在EMOSet-118K数据集上，1B SVLM的准确率提升2.77，召回率提升0.69，性能接近8B模型。
- Conclusion: 增量训练策略有效提升了SVLMs的推理能力，使其在低成本下达到接近大模型的性能。


### [75] [Deep Supervised LSTM for 3D morphology estimation from Multi-View RGB Images of Wheat Spikes](https://arxiv.org/abs/2506.18060)
*Olivia Zumsteg,Nico Graf,Aaron Haeusler,Norbert Kirchgessner,Nicola Storni,Lukas Roth,Andreas Hund*

Main category: cs.CV

TL;DR: 该论文提出了一种基于深度学习的非破坏性小麦穗体积估计方法，通过结合DINOv2和LSTM网络，显著提高了从2D图像估计3D形态特征的准确性。

- Motivation: 由于2D图像在深度信息丢失、投影失真和遮挡等问题，准确估计小麦穗的体积具有挑战性。
- Method: 采用DINOv2（自监督视觉Transformer）和单向LSTM网络结合的迁移学习管道，并通过深度监督学习增强模型的泛化能力。
- Result: 在六视角室内图像上，模型的平均绝对百分比误差（MAPE）为6.46%，优于传统方法（9.36%和13.98%）。在单图像野外数据上微调后，MAPE为10.82%。
- Conclusion: 深度学习模型在复杂几何形状（如小麦穗）的体积估计中表现优于传统几何方法，形状对预测精度有显著影响。


### [76] [Training-free Test-time Improvement for Explainable Medical Image Classification](https://arxiv.org/abs/2506.18070)
*Hangzhou He,Jiachen Tang,Lei Zhu,Kaiwen Li,Yanye Lu*

Main category: cs.CV

TL;DR: 论文提出了一种无需训练的策略，通过最小新数据和图像级标签提升概念瓶颈模型（CBM）在新环境中的性能，同时保持源域准确性。

- Motivation: 解决CBM在部署到新环境时因概念级偏移和缺乏专家标注概念标签而面临的挑战。
- Method: 采用训练无关的混淆概念识别策略，通过屏蔽误导概念和增强判别性概念来优化模型。
- Result: 方法在皮肤和白细胞图像上验证有效，提升了跨域性能。
- Conclusion: 提出的策略为可解释医学图像分类提供了高效且低成本的解决方案。


### [77] [MUPA: Towards Multi-Path Agentic Reasoning for Grounded Video Question Answering](https://arxiv.org/abs/2506.18071)
*Jisheng Dang,Huilin Song,Junbin Xiao,Bimei Wang,Han Peng,Haoxuan Li,Xun Yang,Meng Wang,Tat-Seng Chua*

Main category: cs.CV

TL;DR: MUPA是一种多路径协作方法，用于解决Grounded VideoQA问题，通过结合视频定位、问答、答案反思和聚合，显著提高了定位准确性，同时保持答案准确性。

- Motivation: 现代多模态模型依赖语言先验和虚假相关性，导致预测缺乏视觉证据支持。MUPA旨在解决这一问题。
- Method: MUPA采用多路径协作设计，包括视频定位、问答、答案反思和聚合三个推理路径，通过反思代理整合多路径结果。
- Result: MUPA在2B参数规模下超越7B规模的竞争对手，7B参数时在NExT-GQA和DeVE-QA上分别达到30.3%和47.4%的Acc@GQA。
- Conclusion: MUPA通过多路径协作设计，显著提升了视频语言理解的可靠性和准确性。


### [78] [TEM^3-Learning: Time-Efficient Multimodal Multi-Task Learning for Advanced Assistive Driving](https://arxiv.org/abs/2506.18084)
*Wenzhuo Liu,Yicheng Qiao,Zhen Wang,Qiannan Guo,Zilong Chen,Meihua Zhou,Xinran Li,Letian Wang,Zhiwei Li,Huaping Liu,Wenshuo Wang*

Main category: cs.CV

TL;DR: TEM^3-Learning是一个高效的多模态多任务学习框架，通过两阶段架构优化驾驶辅助任务，实现了高精度和实时性能。

- Motivation: 现有方法在单模态限制和低效架构方面存在不足，无法全面理解场景或实时部署。
- Method: 提出MTS-Mamba子网络提取时空特征，MGMI模块自适应整合多模态特征。
- Result: 在AIDE数据集上实现SOTA精度，轻量级架构（<6M参数）和142.32 FPS推理速度。
- Conclusion: TEM^3-Learning有效解决了多任务学习的负迁移问题，提升了驾驶辅助系统的性能。


### [79] [ShareGPT-4o-Image: Aligning Multimodal Models with GPT-4o-Level Image Generation](https://arxiv.org/abs/2506.18095)
*Junying Chen,Zhenyang Cai,Pengcheng Chen,Shunian Chen,Ke Ji,Xidong Wang,Yunjin Yang,Benyou Wang*

Main category: cs.CV

TL;DR: ShareGPT-4o-Image数据集和Janus-4o模型旨在开源多模态生成能力，提升文本到图像及文本和图像到图像的生成性能。

- Motivation: 当前领先的多模态生成模型（如GPT-4o-Image）是专有的，限制了开放研究。本研究旨在通过开源数据集和模型推动这一领域的发展。
- Method: 使用GPT-4o生成合成数据集ShareGPT-4o-Image（45K文本到图像和46K文本和图像到图像数据），并基于此训练Janus-4o模型。
- Result: Janus-4o在文本到图像生成上显著优于前代模型，并新增了文本和图像到图像生成功能，仅用91K样本和6小时训练即取得优异性能。
- Conclusion: 开源ShareGPT-4o-Image和Janus-4o有望促进逼真、指令对齐的图像生成研究。


### [80] [Enhancing VICReg: Random-Walk Pairing for Improved Generalization and Better Global Semantics Capturing](https://arxiv.org/abs/2506.18104)
*Idan Simai,Ronen Talmon,Uri Shaham*

Main category: cs.CV

TL;DR: 论文分析了VICReg在自监督学习中的潜在不足，提出改进方法SAG-VICReg，通过新训练技术提升泛化能力，实验显示其优于现有方法。

- Motivation: VICReg在泛化性上可能不足，需要改进以提升对未见数据的表现。
- Method: 提出SAG-VICReg，结合新训练技术增强全局语义捕捉和泛化能力。
- Result: SAG-VICReg在泛化性和全局语义理解上优于现有方法，同时保持局部指标竞争力。
- Conclusion: SAG-VICReg有效解决泛化问题，并提出无标签的全局评估新指标。


### [81] [Targeted False Positive Synthesis via Detector-guided Adversarial Diffusion Attacker for Robust Polyp Detection](https://arxiv.org/abs/2506.18134)
*Quan Zhou,Gan Luo,Qiang Hu,Qingyong Zhang,Jinhua Zhang,Yinjiao Tian,Qiang Li,Zhiwei Wang*

Main category: cs.CV

TL;DR: 提出了一种对抗性扩散框架，用于合成高价值的假阳性样本，以改进结肠息肉检测模型的性能。

- Motivation: 现有模型受限于数据规模和多样性，且生成模型多关注息肉多样性而忽略假阳性问题。
- Method: 设计了区域噪声匹配策略和检测器引导的对抗性扩散攻击模块（DADA），用于合成多样背景和高价值假阳性。
- Result: 在公开和内部数据集上验证了方法的优越性，合成数据使检测器F1分数分别提升至少2.6%和2.7%。
- Conclusion: 该方法为病灶检测中的假阳性合成提供了新范式，有望提升结肠癌筛查的临床可靠性。


### [82] [See-in-Pairs: Reference Image-Guided Comparative Vision-Language Models for Medical Diagnosis](https://arxiv.org/abs/2506.18140)
*Ruinan Jin,Gexin Huang,Xinwei Shen,Qiong Zhang,Yan Shuo Tan,Xiaoxiao Li*

Main category: cs.CV

TL;DR: 论文探讨了在医学影像诊断中引入比较推理的视觉语言模型（VLM），通过参考图像提升诊断准确性。

- Motivation: 医学影像诊断存在疾病模仿正常解剖结构和患者间差异大的问题，现有医学VLM缺乏比较推理机制，而通用VLM缺乏医学领域知识。
- Method: 利用查询图像和匹配的参考图像，结合临床启发的比较提示，通过监督微调（SFT）提升通用VLM的诊断性能。
- Result: 实验表明，该方法在多个医学视觉问答（VQA）任务中显著优于单图像基线。
- Conclusion: 比较图像分析在医学诊断中具有临床相关性，为VLM引入参考图像提供了新策略。


### [83] [Pattern-Based Phase-Separation of Tracer and Dispersed Phase Particles in Two-Phase Defocusing Particle Tracking Velocimetry](https://arxiv.org/abs/2506.18157)
*Christian Sax,Jochen Kriegseis*

Main category: cs.CV

TL;DR: 提出了一种基于后处理的相分离方法，用于散焦粒子跟踪测速中的分散两相流，通过单相机实现两相粒子的3D定位，利用卷积神经网络（如Faster R-CNN和YOLOv4）进行分类，并通过生成对抗网络生成训练数据。

- Motivation: 传统基于波长、大小或集合相关性的相分离方法在某些场景下不适用，需要一种更灵活且高精度的解决方案。
- Method: 利用散焦粒子图像的图案差异区分两相粒子，训练卷积神经网络进行分类，并通过生成对抗网络生成实验特定的训练数据。
- Result: 在合成和真实数据集上验证，检测精度和分类准确率高达95-100%，即使存在领域偏移。
- Conclusion: 证实了CNN在分散两相DPTV中实现稳健相分离的可行性，尤其在传统方法不适用时。


### [84] [CDG-MAE: Learning Correspondences from Diffusion Generated Views](https://arxiv.org/abs/2506.18164)
*Varun Belagali,Pierre Marza,Srikar Yellapragada,Zilinghan Li,Tarak Nath Nandi,Ravi K Madduri,Joel Saltz,Stergios Christodoulidis,Maria Vakalopoulou,Dimitris Samaras*

Main category: cs.CV

TL;DR: CDG-MAE是一种基于MAE的自监督方法，通过图像条件扩散模型生成多样合成视图，解决了视频和裁剪图像数据不足的问题，显著提升了性能。

- Motivation: 手动标注密集对应关系耗时且难以扩展，现有自监督方法依赖视频或简单图像裁剪，数据获取困难且多样性不足。
- Method: 利用图像条件扩散模型生成多样合成视图，提出多锚点策略调整预训练任务难度，并定量评估生成图像的局部和全局一致性。
- Result: CDG-MAE显著优于仅依赖图像的MAE方法，大幅缩小了与基于视频方法的性能差距。
- Conclusion: 通过合成视图和多锚点策略，CDG-MAE有效解决了数据多样性问题，提升了自监督学习的性能。


### [85] [STACT-Time: Spatio-Temporal Cross Attention for Cine Thyroid Ultrasound Time Series Classification](https://arxiv.org/abs/2506.18172)
*Irsyad Adam,Tengyue Zhang,Shrayes Raman,Zhuyu Qiu,Brandon Taraku,Hexiang Feng,Sile Wang,Ashwath Radhachandran,Shreeram Athreya,Vedrana Ivezic,Peipei Ping,Corey Arnold,William Speier*

Main category: cs.CV

TL;DR: 提出了一种名为STACT-Time的深度学习模型，通过结合超声动态视频和分割掩模特征，优化甲状腺结节的恶性预测，减少不必要的活检。

- Motivation: 当前甲状腺结节评估方法（如FNA活检）存在不必要的良性结节活检问题，且现有系统（如TI-RADS）受限于观察者间差异。动态超声视频的时空信息未被充分利用。
- Method: 开发了STACT-Time模型，利用自注意力和交叉注意力机制，整合超声动态视频和分割掩模特征，捕捉时空上下文。
- Result: 模型在恶性预测中表现优异，交叉验证精度为0.91（±0.02），F1分数为0.89（±0.02）。
- Conclusion: STACT-Time模型能减少良性结节活检，同时保持高恶性检测灵敏度，有望改善临床决策和患者预后。


### [86] [DExNet: Combining Observations of Domain Adapted Critics for Leaf Disease Classification with Limited Data](https://arxiv.org/abs/2506.18173)
*Sabbir Ahmed,Md. Bakhtiar Hasan,Tasnim Ahmed,Md. Hasanul Kabir*

Main category: cs.CV

TL;DR: 提出了一种少样本学习框架DExNet，用于植物病害分类，通过结合多个预训练CNN架构的特征嵌入，显著减少了对大规模训练数据的需求。

- Motivation: 解决深度学习模型在有限样本下植物病害分类性能不足的问题。
- Method: 使用预训练的CNN架构提取特征嵌入，结合特征融合块和Bi-LSTM分类器。
- Result: 在PlantVillage数据集上，5-shot、10-shot和15-shot分类分别达到89.06%、92.46%和94.07%的准确率，80-shot分类达到98.09%。
- Conclusion: DExNet在少样本条件下表现出色，显著减少数据需求，优于现有方法。


### [87] [Multimodal Fusion SLAM with Fourier Attention](https://arxiv.org/abs/2506.18204)
*Youjie Zhou,Guofeng Mei,Yiming Wang,Yi Wan,Fabio Poiesi*

Main category: cs.CV

TL;DR: FMF-SLAM是一种高效的多模态融合SLAM方法，利用快速傅里叶变换（FFT）提升算法效率，适用于噪声、光照变化和黑暗环境。

- Motivation: 传统基于光流的视觉SLAM方法在噪声、光照变化和黑暗环境下表现不佳且计算资源需求高。
- Method: 引入基于傅里叶的自注意力和跨注意力机制，从RGB和深度信号中提取特征，并结合多尺度知识蒸馏增强多模态特征交互。
- Result: 在TUM、TartanAir和真实数据集上验证，展示了在噪声、光照变化和黑暗条件下的先进性能。
- Conclusion: FMF-SLAM通过FFT和多模态融合实现了高效且实用的SLAM解决方案，适用于复杂环境。


### [88] [Limitations of NERF with pre-trained Vision Features for Few-Shot 3D Reconstruction](https://arxiv.org/abs/2506.18208)
*Ankit Sanjyal*

Main category: cs.CV

TL;DR: DINO增强的NeRF模型在极少量样本场景中表现不如基线NeRF，PSNR值较低，表明预训练视觉特征可能对少样本3D重建无益甚至有害。

- Motivation: 探索预训练视觉特征（如DINO）在少样本3D重建中的有效性，尤其是在极端少样本场景下。
- Method: 系统评估DINO增强的NeRF模型，包括基线NeRF、冻结DINO特征、LoRA微调特征和多尺度特征融合。
- Result: 所有DINO变体表现均不如基线NeRF，PSNR值较低（12.9-13.0 vs 14.71）。
- Conclusion: 预训练视觉特征可能不适合少样本3D重建，建议关注几何一致性的简单架构。


### [89] [Deep Learning-based Alignment Measurement in Knee Radiographs](https://arxiv.org/abs/2506.18209)
*Zhisen Hu,Dominic Cullen,Peter Thompson,David Johnson,Chang Bian,Aleksei Tiulpin,Timothy Cootes,Claudia Lindner*

Main category: cs.CV

TL;DR: 提出了一种基于深度学习的膝关节对齐（KA）测量方法，通过自动定位膝关节解剖标志，提高了测量效率和准确性。

- Motivation: 传统KA测量方法耗时且依赖长腿X光片，需要自动化解决方案以提高效率和准确性。
- Method: 采用沙漏网络结合注意力门结构，自动定位100多个膝关节解剖标志，并测量解剖胫股角。
- Result: 方法在术前和术后图像上均表现出高准确性（平均绝对差异约1°），与临床测量结果一致性良好（术前ICC=0.97，术后ICC=0.86）。
- Conclusion: 研究表明，KA评估可以高精度自动化，为数字化临床工作流程提供了可能。


### [90] [Shape from Polarization of Thermal Emission and Reflection](https://arxiv.org/abs/2506.18217)
*Kazuma Kitazawa,Tsuyoshi Takatani*

Main category: cs.CV

TL;DR: 利用长波红外偏振技术（LWIR SfP）解决透明物体形状估计的挑战，通过改进偏振模型和结合学习方法实现高精度。

- Motivation: 透明物体因复杂的光传输特性难以估计形状，而长波红外光谱中大多数材料不透明且具有发射性，为解决这一问题提供了新思路。
- Method: 提出一个考虑发射和反射的偏振模型，结合基于模型和基于学习的方法（神经网络），并建立真实数据集ThermoPol。
- Result: 实验证明该方法在多种材料上具有高精度和广泛适用性，包括可见光谱中透明的材料。
- Conclusion: 通过改进偏振模型和系统误差建模，LWIR SfP技术在透明物体形状估计中表现出色。


### [91] [Cross-Architecture Knowledge Distillation (KD) for Retinal Fundus Image Anomaly Detection on NVIDIA Jetson Nano](https://arxiv.org/abs/2506.18220)
*Berk Yilmaz,Aniruddh Aiyengar*

Main category: cs.CV

TL;DR: 开发轻量级边缘设备可部署的视网膜疾病分类器，通过知识蒸馏压缩ViT模型，保留高准确性。

- Motivation: 解决低资源环境下视网膜疾病早期准确诊断的设备不足问题。
- Method: 使用ViT教师模型和CNN学生模型，结合PCA投影器和GL投影器进行知识蒸馏。
- Result: 学生模型参数比教师模型少97.4%，分类准确率达89%，保留93%教师模型性能。
- Conclusion: 该方法为资源有限地区提供了可扩展的AI视网膜疾病筛查解决方案。


### [92] [Make It Efficient: Dynamic Sparse Attention for Autoregressive Image Generation](https://arxiv.org/abs/2506.18226)
*Xunzhi Xiang,Qi Fan*

Main category: cs.CV

TL;DR: 论文提出了一种无需训练的上下文优化方法ADSA，通过动态稀疏注意力机制和动态KV缓存更新，显著减少了推理时的内存和计算开销。

- Motivation: 自回归图像生成模型在推理时因长上下文导致内存和计算延迟问题，需要优化。
- Method: 提出ADSA方法，动态识别关键历史令牌以优化注意力计算，并引入动态KV缓存更新机制。
- Result: 实验表明ADSA在生成质量和资源效率上均表现优越，GPU内存消耗减少约50%。
- Conclusion: ADSA是一种高效且无需训练的优化方法，显著提升了自回归图像生成的性能。


### [93] [Drive-R1: Bridging Reasoning and Planning in VLMs for Autonomous Driving with Reinforcement Learning](https://arxiv.org/abs/2506.18234)
*Yue Li,Meng Tian,Dechang Zhu,Jiangtong Zhu,Zhenyu Lin,Zhiwei Xiong,Xinhai Zhao*

Main category: cs.CV

TL;DR: 论文提出Drive-R1模型，通过结合场景推理和运动规划解决自动驾驶中视觉语言模型的挑战。

- Motivation: 解决视觉语言模型在自动驾驶中过度依赖历史信息和推理与规划结果不一致的问题。
- Method: Drive-R1通过监督微调和强化学习框架，逐步推理视觉输入至规划决策。
- Result: 在nuScenes和DriveLM-nuScenes基准测试中表现优于现有模型。
- Conclusion: Drive-R1为自动驾驶中推理与规划的结合提供了新方向。


### [94] [Referring Expression Instance Retrieval and A Strong End-to-End Baseline](https://arxiv.org/abs/2506.18246)
*Xiangzhao Hao,Kuan Zhu,Hongyu Guo,Haiyun Guo,Ming Tang,JinQiao Wang*

Main category: cs.CV

TL;DR: 论文提出新任务REIR，结合实例级检索与定位，并构建REIRCOCO基准和基线方法CLARE，实现高性能与泛化能力。

- Motivation: 解决TIR缺乏精度和REC缺乏扩展性的问题，满足现实场景中实例级检索与定位的需求。
- Method: 提出CLARE方法，采用双流架构和MORE模块，结合目标检测、REC预训练和CLIA进行端到端优化。
- Result: CLARE在REIR任务上达到SOTA性能，并泛化至TIR和REC任务。
- Conclusion: REIR任务和CLARE方法有效填补了现有技术的空白，具有实际应用潜力。


### [95] [Semantic Structure-Aware Generative Attacks for Enhanced Adversarial Transferability](https://arxiv.org/abs/2506.18248)
*Jongoh Jeong,Hunmin Yang,Jaeseok Jeong,Kuk-Jin Yoon*

Main category: cs.CV

TL;DR: 提出了一种基于Mean Teacher的语义结构感知攻击框架，通过特征蒸馏增强对抗性扰动的语义一致性和转移性。

- Motivation: 现有生成对抗攻击未充分利用生成模型的语义信息，限制了扰动与目标显著区域的对齐，从而影响对抗性转移性。
- Method: 利用Mean Teacher作为时间平滑特征参考，通过特征蒸馏指导学生生成器的早期层激活与语义丰富的教师模型一致。
- Result: 实验表明，该方法在多种模型、领域和任务中均优于现有生成对抗攻击方法。
- Conclusion: 通过增强语义一致性，显著提升了对抗性扰动的转移性和攻击效果。


### [96] [Improving Weakly Supervised Temporal Action Localization by Exploiting Multi-resolution Information in Temporal Domain](https://arxiv.org/abs/2506.18261)
*Rui Su,Dong Xu,Luping Zhou,Wanli Ouyang*

Main category: cs.CV

TL;DR: 提出了一种两阶段方法，利用多分辨率信息生成高质量帧级伪标签，以解决弱监督时间动作定位问题。

- Motivation: 弱监督时间动作定位任务中仅有视频级标注可用，需生成高质量帧级伪标签以提升性能。
- Method: 第一阶段通过初始标签生成模块（ILG）生成可靠伪标签；第二阶段通过渐进式时间标签细化框架（PTLR）迭代优化伪标签。
- Result: 利用多分辨率信息交换优化伪标签，提升了时间动作定位性能。
- Conclusion: 两阶段方法有效利用多分辨率信息，显著提升了弱监督时间动作定位的效果。


### [97] [YouTube-Occ: Learning Indoor 3D Semantic Occupancy Prediction from YouTube Videos](https://arxiv.org/abs/2506.18266)
*Haoming Chen,Lichen Yuan,TianFang Sun,Jingyu Gong,Xin Tan,Zhizhong Zhang,Yuan Xie*

Main category: cs.CV

TL;DR: 论文提出了一种仅使用室内互联网数据（无需相机参数）实现3D语义占据预测的自监督方法，并通过YouTube-Occ数据集验证其零样本性能。

- Motivation: 解决复杂室内环境中数据采集困难和隐私问题，探索无需精确几何关系的3D语义占据预测方法。
- Method: 利用YouTube-Occ数据集，通过自监督模型将2D先验知识（如超像素分组）蒸馏到3D占据网络中。
- Result: 在NYUv2和OccScanNet基准测试中实现了零样本性能的领先水平。
- Conclusion: 证明了仅依赖互联网数据和自监督学习即可实现高效的3D室内感知。


### [98] [ThermalLoc: A Vision Transformer-Based Approach for Robust Thermal Camera Relocalization in Large-Scale Environments](https://arxiv.org/abs/2506.18268)
*Yu Liu,Yangtao Meng,Xianfei Pan,Jie Jiang,Changhao Chen*

Main category: cs.CV

TL;DR: ThermalLoc是一种新型端到端深度学习方法，专门用于热图像重定位，通过结合EfficientNet和Transformers提取特征，并在公开和自有数据集上表现优于现有方法。

- Motivation: 传统基于可见光的重定位方法不适用于热图像，而针对热相机的深度学习方法研究不足。
- Method: ThermalLoc整合EfficientNet和Transformers提取局部和全局特征，并使用两个MLP网络进行绝对位姿回归。
- Result: ThermalLoc在公开和自有数据集上表现优于AtLoc、MapNet、PoseNet和RobustLoc等方法，具有更高的准确性和鲁棒性。
- Conclusion: ThermalLoc填补了热相机重定位方法的空白，并展示了优越性能。


### [99] [Adaptive Mask-guided K-space Diffusion for Accelerated MRI Reconstruction](https://arxiv.org/abs/2506.18270)
*Qinrong Cai,Yu Guan,Zhibo Chen,Dong Liang,Qiuyun Fan,Qiegen Liu*

Main category: cs.CV

TL;DR: 该论文提出了一种基于自适应掩码的扩散模型（AMDM），用于MRI重建，通过自适应调整k空间数据的频率分布，有效分离高低频成分，提升重建质量。

- Motivation: MRI重建需要从欠采样的k空间数据中恢复高质量图像，但传统方法未充分考虑k空间不同频率区域的重要性。
- Method: 采用自适应掩码机制，根据k空间数据的频率分布生成自适应掩码，并指导闭环扩散过程。
- Result: 实验证明该方法能有效学习特定频率信息，显著提升MRI重建质量。
- Conclusion: AMDM为未来利用掩码优化k空间数据提供了灵活框架。


### [100] [ReFrame: Rectification Framework for Image Explaining Architectures](https://arxiv.org/abs/2506.18272)
*Debjyoti Das Adhikary,Aritra Hazra,Partha Pratim Chakrabarti*

Main category: cs.CV

TL;DR: 提出了一种可解释的框架，用于改进图像解释中的不一致性和不完整性，显著提升了图像描述、视觉问答和基于提示的AI模型的性能。

- Motivation: 现有图像解释方法常存在幻觉对象或遗漏对象的问题，需要一种新方法来提高解释的一致性和完整性。
- Method: 提出一种可解释框架，可集成到多种图像解释框架（如图像描述、视觉问答和基于提示的AI模型）中，纠正错误或缺失的对象。
- Result: 在图像描述、视觉问答和基于提示的AI模型中，分别显著提升了完整性和一致性指标。
- Conclusion: 所提框架有效解决了图像解释中的不一致性和不完整性问题，性能优于现有方法。


### [101] [Open Set Recognition for Endoscopic Image Classification: A Deep Learning Approach on the Kvasir Dataset](https://arxiv.org/abs/2506.18284)
*Kasra Moazzami,Seoyoun Son,John Lin,Sun Min Lee,Daniel Son,Hayeon Lee,Jeongho Lee,Seongji Lee*

Main category: cs.CV

TL;DR: 该论文探讨了在开放世界临床环境中应用开放集识别（OSR）技术于内窥镜图像分类，以解决传统封闭集分类框架的局限性。

- Motivation: 传统封闭集分类在临床环境中无法应对未知情况，影响模型可靠性，因此研究OSR技术以提升内窥镜图像分类的鲁棒性。
- Method: 在Kvasir数据集上评估了ResNet-50、Swin Transformer和混合ResNet-Transformer模型的OSR能力，并采用OpenMax作为基线方法。
- Result: 研究为医学图像分析中的OSR性能提供了基准，并展示了模型在临床现实环境中的行为。
- Conclusion: OSR技术对于内窥镜AI系统的安全部署至关重要，研究为其应用提供了实践基础和见解。


### [102] [Selective Social-Interaction via Individual Importance for Fast Human Trajectory Prediction](https://arxiv.org/abs/2506.18291)
*Yota Urano,Hiromu Taketsugu,Norimichi Ukita*

Main category: cs.CV

TL;DR: 提出了一种通过选择重要邻居预测主人物轨迹的架构，使用重要性估计器和Gumbel Softmax解决梯度问题，实验显示方法高效且准确。

- Motivation: 预测主人物轨迹时，选择重要邻居是关键，但传统方法可能因非可微操作阻碍梯度传播。
- Method: 提出重要性估计器模块评估邻居重要性，并用Gumbel Softmax解决梯度问题。
- Result: 在JRDB数据集上实验表明，方法在保持预测精度的同时提高了效率。
- Conclusion: 该方法通过智能邻居选择和梯度优化，实现了高效且准确的轨迹预测。


### [103] [Rapeseed population point cloud completion network (RP-PCN) with dynamic graph convolution for 3D reconstruction of crop canopy occlusion architecture](https://arxiv.org/abs/2506.18292)
*Ziyue Guo,Xin Yang,Yutao Shen,Yang Zhu,Lixi Jiang,Haiyan Cen*

Main category: cs.CV

TL;DR: 提出了一种基于多视角成像的油菜群体点云补全模型（RP-PCN），用于从苗期到角果期的三维重建，并通过虚拟-现实集成方法优化训练数据集，显著提高了产量预测精度。

- Motivation: 植物冠层结构的精确三维重建对评估光合作用和产量至关重要，但现有技术因遮挡和复杂结构难以实现准确描述。
- Method: 开发了点云补全框架，结合虚拟-现实集成（VRI）模拟和遮挡点检测算法训练数据集，设计了RP-PCN网络，包含多分辨率动态图卷积编码器（MRDG）和点金字塔解码器（PPD）。
- Result: RP-PCN在不同生长阶段的CD值分别为3.35 cm、3.46 cm、4.32 cm和4.51 cm，MRDG和DGCFE模块分别降低CD值10%和23%，SEI指标将产量预测精度提高11.2%。
- Conclusion: RP-PCN可推广至其他作物，显著提升田间群体冠层结构的分析能力。


### [104] [Attention-Based Ensemble Learning for Crop Classification Using Landsat 8-9 Fusion](https://arxiv.org/abs/2506.18321)
*Zeeshan Ramzan,Nisar Ahmed,Qurat-ul-Ain Akram,Shahzad Asif,Muhammad Shahbaz,Rabin Chakrabortty,Ahmed F. Elaksher*

Main category: cs.CV

TL;DR: 该研究利用遥感技术和高级建模方法，结合实地调查和卫星影像，提高了巴基斯坦旁遮普中部灌溉区作物分类的准确性。

- Motivation: 通过遥感技术获取准确的作物种植面积和类型信息，以支持灌溉农业区的精准管理。
- Method: 分两阶段收集数据：实地调查和卫星影像获取，并进行预处理、图像融合和分类建模。
- Result: 构建了包含50,835个数据点的数据集，并提取植被指数，通过多种分类方法提高了分类准确性。
- Conclusion: 结合遥感数据和高级建模技术，显著提升了灌溉农业区的作物分类效果。


### [105] [Escaping the SpuriVerse: Can Large Vision-Language Models Generalize Beyond Seen Spurious Correlations?](https://arxiv.org/abs/2506.18322)
*Yiwei Yang,Chung Peng Lee,Shangbin Feng,Dora Zhao,Bingbing Wen,Anthony Z. Liu,Yulia Tsvetkov,Bill Howe*

Main category: cs.CV

TL;DR: 论文提出了SpuriVerse基准，用于研究多模态大型视觉语言模型（LVLM）中的虚假相关性，并通过合成数据和微调提升模型性能。

- Motivation: 研究LVLM中非本质特征与目标标签之间的虚假相关性，避免传统基准的局限性和人为设置。
- Method: 利用GPT-4的错误数据构建SpuriVerse基准，包含124种虚假相关性类型，通过LVLM-人类标注和合成反事实评估筛选数据。
- Result: 15种LVLM在SpuriVerse上表现不佳（最高37.1%准确率），但通过微调合成数据后性能提升至78.40%。
- Conclusion: 模型通过多样化虚假模式训练能更好地避免‘捷径’并关注整体图像上下文。


### [106] [A Multi-Scale Spatial Attention-Based Zero-Shot Learning Framework for Low-Light Image Enhancement](https://arxiv.org/abs/2506.18323)
*Muhammad Azeem Aslam,Hassan Khalid,Nisar Ahmed*

Main category: cs.CV

TL;DR: LucentVisionNet是一种零样本学习框架，用于低光图像增强，结合多尺度空间注意力和深度曲线估计网络，通过复合损失函数优化，在多项指标上优于现有方法。

- Motivation: 解决低光图像增强中缺乏配对训练数据的挑战，提升语义和感知保真度。
- Method: 集成多尺度空间注意力与深度曲线估计网络，采用循环增强策略和复合损失函数优化。
- Result: 在配对和非配对数据集上优于现有监督、无监督和零样本方法，实现高视觉质量和计算效率。
- Conclusion: LucentVisionNet适用于移动摄影、监控和自主导航等实际应用。


### [107] [NSFW-Classifier Guided Prompt Sanitization for Safe Text-to-Image Generation](https://arxiv.org/abs/2506.18325)
*Yu Xie,Chengjie Zeng,Lingyun Zhang,Yanwei Fu*

Main category: cs.CV

TL;DR: 论文提出PromptSan方法，通过两种变体（PromptSan-Modify和PromptSan-Suffix）净化有害文本提示，避免生成不良内容，同时保持模型生成能力。

- Motivation: 文本到图像（T2I）模型的快速发展带来了滥用风险（如生成色情、暴力等内容），违背伦理目标并阻碍可持续发展。
- Method: 提出NSFW-Classifier Guided Prompt Sanitization（PromptSan），包括PromptSan-Modify（迭代替换有害标记）和PromptSan-Suffix（训练优化后缀序列中和有害意图）。
- Result: 实验表明PromptSan在多指标下显著减少有害内容生成，平衡安全性与可用性。
- Conclusion: PromptSan是一种无需修改模型架构即可有效净化有害提示的新方法，具有实际应用价值。


### [108] [Geometry-Aware Preference Learning for 3D Texture Generation](https://arxiv.org/abs/2506.18331)
*AmirHossein Zamani,Tianhao Xie,Amir G. Aghdam,Tiberiu Popa,Eugene Belilovsky*

Main category: cs.CV

TL;DR: 提出了一种端到端的可微分偏好学习框架，通过几何感知的奖励函数优化3D生成模型，以更好地符合人类主观偏好和任务需求。

- Motivation: 现有3D生成模型生成的内容可能不符合人类主观偏好或任务需求，且依赖2D文本到图像模型，缺乏对3D结构的理解。
- Method: 提出了一种端到端的可微分偏好学习框架，通过几何感知的奖励函数反向传播人类偏好。
- Result: 使用四种新颖的几何感知奖励函数验证了框架的有效性。
- Conclusion: 该框架为从自然语言生成高质量3D内容提供了更可控和可解释的途径。


### [109] [Rethinking Decoder Design: Improving Biomarker Segmentation Using Depth-to-Space Restoration and Residual Linear Attention](https://arxiv.org/abs/2506.18335)
*Saad Wazir,Daeyoung Kim*

Main category: cs.CV

TL;DR: 提出了一种新的医学图像分割方法，通过多尺度特征提取和高效解码器设计，显著提升了分割精度。

- Motivation: 解决Transformer和CNN在医学图像分割中因染色和形态变化导致的特征提取不足问题，以及预训练编码器与解码器特征传递效率低的挑战。
- Method: 设计了一种能够捕获多尺度局部和全局上下文信息的架构，以及一种新型解码器，有效整合编码器特征并强调重要通道和区域。
- Result: 在四个数据集上表现优于现有SOTA方法，绝对性能提升分别为2.76%（MoNuSeg）、3.12%（DSB）、2.87%（Electron Microscopy）和4.03%（TNBC）。
- Conclusion: 提出的方法通过改进特征整合和解码器设计，显著提升了医学图像分割的准确性，具有广泛适用性。


### [110] [BSMamba: Brightness and Semantic Modeling for Long-Range Interaction in Low-Light Image Enhancement](https://arxiv.org/abs/2506.18346)
*Tongshun Zhang,Pingping Liu,Mengen Cai,Zijian Zhang,Yubing Lu,Qiuzhan Zhou*

Main category: cs.CV

TL;DR: BSMamba是一种新型视觉Mamba架构，通过亮度Mamba和语义Mamba组件，解决了低光图像增强中亮度提升与语义一致性的问题。

- Motivation: 现有低光图像增强方法在提升亮度时难以同时保持语义一致性和细节，且现有视觉Mamba方法因固定扫描规则限制了长距离依赖的捕捉。
- Method: 提出BSMamba架构，包含亮度Mamba（基于亮度相似性连接远距离令牌）和语义Mamba（基于语义相似性连接令牌），以改进令牌交互模式。
- Result: 实验表明BSMamba在低光图像增强任务中实现了最先进的性能，同时保持了语义一致性。
- Conclusion: BSMamba通过亮度与语义引导的令牌交互，克服了传统方法的限制，为低光图像增强提供了高效解决方案。


### [111] [Spatial frequency information fusion network for few-shot learning](https://arxiv.org/abs/2506.18364)
*Wenqing Zhao,Guojia Xie,Han Pan,Biao Yang,Weichuan Zhang*

Main category: cs.CV

TL;DR: 本文提出了一种结合频域和空间域信息的SFIFNet方法，以提升小样本学习中的分类性能。

- Motivation: 小样本学习中，传统方法常忽略频域信息，导致特征利用不足和分类性能下降。
- Method: 基于常规数据增强，提出SFIFNet，通过结合频域和空间域信息提升特征表示准确性。
- Result: 实验证明该方法能有效提升分类性能。
- Conclusion: 结合频域和空间域信息的方法在小样本学习中具有显著优势。


### [112] [Sequential keypoint density estimator: an overlooked baseline of skeleton-based video anomaly detection](https://arxiv.org/abs/2506.18368)
*Anja Delić,Matej Grcić,Siniša Šegvić*

Main category: cs.CV

TL;DR: SeeKer是一种通过自回归分解关键点级骨架序列密度来检测异常人体行为的方法，优于现有方法。

- Motivation: 在医疗监控、工作场所安全或公共监控等安全关键应用中，检测异常人体行为至关重要，异常通常表现为不寻常的姿势。
- Method: 通过自回归分解关键点级骨架序列密度，建模条件高斯分布的联合分布，计算异常分数。
- Result: 在UBnormal、MSAD-HR数据集上表现最优，在ShanghaiTech数据集上具有竞争力。
- Conclusion: SeeKer方法简单有效，显著提升了异常行为检测的性能。


### [113] [RePIC: Reinforced Post-Training for Personalizing Multi-Modal Language Models](https://arxiv.org/abs/2506.18369)
*Yeongtak Oh,Jisoo Mok,Dohyun Chung,Juhyeon Shin,Sangha Park,Johan Barthelemy,Sungroh Yoon*

Main category: cs.CV

TL;DR: 提出了一种基于强化学习的后训练框架，显著提升了多模态大语言模型在个性化图像描述任务中的表现。

- Motivation: 现有基于监督微调的后训练方法在复杂场景（如多概念图像描述）中表现不佳，且高质量标注数据获取成本高。
- Method: 采用强化学习（RL）后训练框架，替代传统的监督微调（SFT）。
- Result: 该方法显著提升了模型的视觉识别和个性化生成能力，在多概念图像描述任务中表现优于现有基线。
- Conclusion: 强化学习后训练框架是解决多模态大语言模型个性化图像描述问题的有效方法。


### [114] [OpenEvents V1: Large-Scale Benchmark Dataset for Multimodal Event Grounding](https://arxiv.org/abs/2506.18372)
*Hieu Nguyen,Phuc-Tan Nguyen,Thien-Phuc Tran,Minh-Quang Nguyen,Tam V. Nguyen,Minh-Triet Tran,Trung-Nghia Le*

Main category: cs.CV

TL;DR: OpenEvents V1是一个大规模基准数据集，旨在推动事件为中心的视觉语言理解，包含20万篇新闻文章和40万张相关图片，支持事件感知图像描述生成和事件相关图像检索任务。

- Motivation: 传统图像描述和检索数据集仅关注表面描述，而OpenEvents V1旨在通过上下文和时间基础，推动对复杂现实事件的深度推理。
- Method: 数据集包含CNN和The Guardian的新闻文章及图片，提供基线结果和标准化评估协议。
- Result: OpenEvents V1为开发能够深度推理复杂事件的多模态模型奠定了基础。
- Conclusion: 该数据集为事件为中心的视觉语言理解提供了重要资源，并公开可用。


### [115] [InternSpatial: A Comprehensive Dataset for Spatial Reasoning in Vision-Language Models](https://arxiv.org/abs/2506.18385)
*Nianchen Deng,Lixin Gu,Shenglong Ye,Yinan He,Zhe Chen,Songze Li,Haomin Wang,Xingguang Wei,Tianshuo Yang,Min Dou,Tong He,Wenqi Shao,Kaipeng Zhang,Yi Wang,Botian Shi,Yanting Zhang,Jifeng Dai,Yu Qiao,Hongjie Zhang,Wenhai Wang*

Main category: cs.CV

TL;DR: 介绍了InternSpatial，一个用于视觉语言模型（VLM）空间推理的最大开源数据集，以及评估基准InternSpatial-Bench。

- Motivation: 现有资源在规模、视觉多样性和指令表达性方面有限，需要更大、更多样化的数据集和评估方法。
- Method: 构建了包含1200万QA对的InternSpatial数据集，支持19种指令格式，并设计了InternSpatial-Bench评估基准，包括单视图和多视图任务。
- Result: 使用InternSpatial训练的模型在InternSpatial-Bench上提升了12.1%，在VSI-Bench上提升了10.7%，同时在通用基准上保持良好表现。
- Conclusion: InternSpatial和InternSpatial-Bench有望推动空间推理能力在机器人学和具身AI等实际应用中的发展。


### [116] [Distributed Poisson multi-Bernoulli filtering via generalised covariance intersection](https://arxiv.org/abs/2506.18397)
*Ángel F. García-Fernández,Giorgio Battistelli*

Main category: cs.CV

TL;DR: 本文提出了一种基于广义协方差交集（GCI）融合规则的分布式泊松多伯努利（PMB）滤波器，用于分布式多目标滤波。通过近似PMB密度的幂作为未归一化的PMB密度，实现了GCI融合的闭式解，并展示了其优于其他分布式多目标滤波器的性能。

- Motivation: 解决分布式多目标滤波中PMB密度的GCI融合难以精确计算的问题。
- Method: 近似PMB密度的幂作为未归一化的PMB密度，并通过GCI融合规则得到闭式解的泊松多伯努利混合（PMBM）。
- Result: 实验结果表明，该方法优于其他分布式多目标滤波器。
- Conclusion: 提出的方法在分布式多目标滤波中具有优势，并可通过闭式解实现高效计算。


### [117] [Latent Space Analysis for Melanoma Prevention](https://arxiv.org/abs/2506.18414)
*Ciro Listone,Aniello Murano*

Main category: cs.CV

TL;DR: 论文提出了一种基于条件变分自编码器的新方法，用于皮肤病变的连续风险评估，结合SVM分类器，实现了高分类性能，同时提供可解释的潜在空间。

- Motivation: 黑色素瘤的高死亡率需要早期诊断工具，现有深度学习模型仅提供二元分类，缺乏临床可解释性。
- Method: 使用条件变分自编码器学习结构化潜在空间，捕获病变语义关系，并结合SVM进行分类。
- Result: 方法在区分良性痣和黑色素瘤上表现优异，潜在空间支持视觉和几何解释。
- Conclusion: 该方法结合预测性能和临床适用性，通过透明决策提升AI辅助诊断的信任度。


### [118] [Benchmarking Foundation Models and Parameter-Efficient Fine-Tuning for Prognosis Prediction in Medical Imaging](https://arxiv.org/abs/2506.18434)
*Filippo Ruffini,Elena Mulero Ayllon,Linlin Shen,Paolo Soda,Valerio Guarrasi*

Main category: cs.CV

TL;DR: 该论文提出了一个结构化基准，用于评估和比较卷积神经网络和基础模型在COVID-19患者临床预后预测中的迁移能力，并探索了多种微调策略。

- Motivation: 人工智能在医学影像预后预测中具有潜力，但实际应用仍面临挑战。本文旨在通过系统评估，推动AI在临床预后中的实际部署。
- Method: 采用多种微调策略（如全微调、线性探测、参数高效微调方法等），在多种学习范式（如全数据场景和少样本学习）下评估模型的迁移能力。
- Result: 通过大规模比较分析，详细评估了不同模型在数据稀缺和类别不平衡条件下的适应性和泛化能力。
- Conclusion: 该基准为临床预后预测中AI解决方案的实际部署提供了重要参考，揭示了不同微调策略的优势和局限性。


### [119] [Frequency-Domain Fusion Transformer for Image Inpainting](https://arxiv.org/abs/2506.18437)
*Sijin He,Guangfeng Lin,Tao Li,Yajun Chen*

Main category: cs.CV

TL;DR: 本文提出了一种基于Transformer的图像修复方法，结合频域融合技术，通过引入小波变换和Gabor滤波的注意力机制，以及可学习的频域滤波器，有效提升了高频细节的保留能力。

- Motivation: 传统图像修复方法在处理复杂纹理和大面积遮挡时表现不佳，而现有Transformer方法因自注意力的低通特性难以保留高频细节且计算成本高。
- Method: 提出了一种结合小波变换和Gabor滤波的注意力机制，设计了基于快速傅里叶变换的可学习频域滤波器，并采用四层编码器-解码器结构和新型损失策略。
- Result: 实验结果表明，该方法显著提升了图像修复质量，尤其在保留高频信息方面表现突出。
- Conclusion: 该方法通过频域融合和新型注意力机制，成功解决了Transformer在图像修复中的高频细节丢失问题，同时降低了计算成本。


### [120] [CPAM: Context-Preserving Adaptive Manipulation for Zero-Shot Real Image Editing](https://arxiv.org/abs/2506.18438)
*Dinh-Khoi Vo,Thanh-Toan Do,Tam V. Nguyen,Minh-Triet Tran,Trung-Nghia Le*

Main category: cs.CV

TL;DR: CPAM是一种零样本框架，用于复杂非刚性真实图像编辑，通过自适应模块和掩码引导技术保持背景和对象一致性。

- Motivation: 现有方法在保持纹理和身份、处理复杂非刚性对象以及编辑特定区域时存在局限性，CPAM旨在解决这些问题。
- Method: 提出保护适应模块调整自注意力机制，开发局部提取模块减少干扰，并引入多种掩码引导策略。
- Result: 在IMBA基准测试中，CPAM优于现有技术，成为人类评估者的首选。
- Conclusion: CPAM通过创新模块和策略，实现了高质量、一致性的真实图像编辑。


### [121] [DIP: Unsupervised Dense In-Context Post-training of Visual Representations](https://arxiv.org/abs/2506.18463)
*Sophia Sirko-Galouchenko,Spyros Gidaris,Antonin Vobecky,Andrei Bursuc,Nicolas Thome*

Main category: cs.CV

TL;DR: DIP是一种无监督的后训练方法，通过模拟下游任务的伪任务增强预训练视觉编码器的密集图像表示，提升场景理解能力。

- Motivation: 现有方法依赖复杂的自蒸馏架构，而DIP旨在通过伪任务模拟下游场景，简化并提升密集表示的效率。
- Method: 利用预训练扩散模型和视觉编码器自动生成伪任务，基于元学习原则进行无监督训练。
- Result: DIP在多种下游场景理解任务中表现优异，计算高效（单A100 GPU耗时<9小时），优于初始编码器和现有方法。
- Conclusion: DIP为密集表示改进提供了简单、高效且实用的解决方案。


### [122] [AViLA: Asynchronous Vision-Language Agent for Streaming Multimodal Data Interaction](https://arxiv.org/abs/2506.18472)
*Gengyuan Zhang,Tanveer Hannan,Hermine Kleiner,Beste Aydemir,Xinyu Xie,Jian Lan,Thomas Seidl,Volker Tresp,Jindong Gu*

Main category: cs.CV

TL;DR: 论文提出了一种处理动态数据流中查询与证据异步问题的框架AViLA，通过三个关键模块提升多模态大语言模型在流数据交互中的表现。

- Motivation: 解决现实应用中（如自动驾驶和具身智能体）用户查询与支持证据异步到达的挑战，要求智能体具备时间感知能力。
- Method: 提出AViLA框架，包含全面记忆保留、证据识别和证据触发的三个模块，以处理流数据中的临时查询。
- Result: 实验表明，现有模型在时间感知上表现不佳，而AViLA显著提升了准确性和时间感知能力。
- Conclusion: AViLA为流数据交互中的异步问题提供了有效解决方案，代码和数据集将公开。


### [123] [Context Consistency Learning via Sentence Removal for Semi-Supervised Video Paragraph Grounding](https://arxiv.org/abs/2506.18476)
*Yaokun Zhong,Siyu Jiang,Jian Zhu,Jian-Fang Hu*

Main category: cs.CV

TL;DR: SSVPG任务旨在用有限的时间标注从视频中定位多个句子。现有方法忽略了扰动查询上下文的重要性。本文提出CCL框架，结合一致性正则化和伪标签，显著提升性能。

- Motivation: 现有方法忽视了扰动查询上下文对生成强监督信号的重要性，限制了半监督学习的效果。
- Method: 提出CCL框架，通过教师-学生学习和伪标签重训练，利用强增强样本和预测一致性提升模型性能。
- Result: CCL在实验中大幅超越现有方法。
- Conclusion: CCL通过结合一致性学习和伪标签，有效提升了半监督视频段落定位的性能。


### [124] [GANs vs. Diffusion Models for virtual staining with the HER2match dataset](https://arxiv.org/abs/2506.18484)
*Pascal Klöckner,José Teixeira,Diana Montezuma,Jaime S. Cardoso,Hugo M. Horlings,Sara P. Oliveira*

Main category: cs.CV

TL;DR: 本文介绍了首个公开的H&E-HER2染色匹配数据集HER2match，并比较了GANs和DMs在H&E-HER2染色转换任务中的性能，发现GANs总体表现更优。

- Motivation: 虚拟染色技术缺乏公开数据集和明确的模型框架选择标准，阻碍了H&E-HER2染色转换的研究进展。
- Method: 引入HER2match数据集，比较多种GANs和DMs，并提出新的Brownian Bridge Diffusion Model。
- Result: GANs整体表现优于DMs，仅BBDM与之相当；数据对齐显著提升模型效果。
- Conclusion: HER2match数据集和模型比较为H&E-HER2染色转换研究提供了重要资源和指导。


### [125] [ShowFlow: From Robust Single Concept to Condition-Free Multi-Concept Generation](https://arxiv.org/abs/2506.18493)
*Trong-Vu Hoang,Quang-Binh Nguyen,Thanh-Toan Do,Tam V. Nguyen,Minh-Triet Tran,Trung-Nghia Le*

Main category: cs.CV

TL;DR: ShowFlow是一个解决图像生成中身份保持和提示对齐挑战的框架，包括单概念（ShowFlow-S）和多概念（ShowFlow-M）生成模块。

- Motivation: 解决可控图像合成中单概念和多概念生成的身份保持与提示对齐问题。
- Method: ShowFlow-S使用KronA-WED适配器和解耦学习方法；ShowFlow-M复用ShowFlow-S模型，结合SAMA和布局一致性策略。
- Result: 实验和用户研究验证了ShowFlow在广告和虚拟试衣等实际应用中的有效性。
- Conclusion: ShowFlow为单概念和多概念图像生成提供了高效解决方案，具有实际应用潜力。


### [126] [Biased Teacher, Balanced Student](https://arxiv.org/abs/2506.18496)
*Seonghak Kim*

Main category: cs.CV

TL;DR: 提出了长尾知识蒸馏（LTKD）框架，针对类别不平衡数据优化知识蒸馏，通过分解KL散度并引入重平衡损失函数，显著提升模型在长尾数据上的性能。

- Motivation: 传统知识蒸馏在长尾数据分布中表现不佳，因教师模型偏向头部类别，对尾部类别监督不足。
- Method: 将标准KD目标分解为组间和组内KL散度，引入重平衡组间损失和均匀组内损失。
- Result: 在多个数据集上，LTKD显著优于现有KD方法，整体准确率和尾部类别性能均有提升。
- Conclusion: LTKD能有效从有偏教师模型中转移知识，适用于资源受限和不平衡场景。


### [127] [Generalizing Vision-Language Models to Novel Domains: A Comprehensive Survey](https://arxiv.org/abs/2506.18504)
*Xinyao Li,Jingjing Li,Fengling Li,Lei Zhu,Yang Yang,Heng Tao Shen*

Main category: cs.CV

TL;DR: 综述探讨了视觉语言模型（VLMs）的泛化能力，总结了其方法、基准和结果，并比较了VLMs与多模态大语言模型（MLLMs）的异同。

- Motivation: 尽管VLMs在零样本任务中表现优异，但在特定领域任务中性能下降，因此需要研究如何将其知识泛化到下游应用。
- Method: 综述将现有文献分为基于提示、参数和特征的方法，并总结了每类的特点与差异。
- Result: 通过系统回顾，提供了VLMs泛化的清晰研究现状，并比较了不同方法的性能。
- Conclusion: 该综述为当前和未来的多模态研究提供了清晰的视角，并探讨了VLMs与MLLMs的关系。


### [128] [MedTVT-R1: A Multimodal LLM Empowering Medical Reasoning and Diagnosis](https://arxiv.org/abs/2506.18512)
*Yuting Zhang,Kaishen Yuan,Hao Lu,Yutao Yue,Jintai Chen,Kaishun Wu*

Main category: cs.CV

TL;DR: 提出了一种名为MedTVT-R1的多模态大语言模型框架，用于整合临床多模态数据进行多疾病诊断，并通过GRPO强化微调和Jaccard奖励函数优化诊断推理。

- Motivation: 解决当前多疾病诊断中依赖单模态数据的局限性，提升对复杂疾病的全面理解。
- Method: 构建MedTVT-QA数据集，设计模态感知层捕捉模态间依赖关系，采用GRPO强化微调和Jaccard奖励函数优化推理。
- Result: 实验证明MedTVT-R1在多模态特征利用和多疾病诊断方面表现优越，具有临床应用潜力。
- Conclusion: MedTVT-R1为多疾病诊断提供了高效且可解释的解决方案，数据集和代码已开源。


### [129] [Enhancing Image Restoration Transformer via Adaptive Translation Equivariance](https://arxiv.org/abs/2506.18520)
*JiaKui Hu,Zhengjian Yao,Lujia Jin,Hangzhou He,Yanye Lu*

Main category: cs.CV

TL;DR: 论文提出了一种名为TEAFormer的Transformer网络，通过滑动索引和组件堆叠策略解决图像修复中注意力机制破坏平移等变性的问题，并引入自适应滑动索引机制平衡计算成本和感受野。

- Motivation: 现代修复Transformer中的注意力机制破坏了平移等变性，影响训练收敛和泛化能力。
- Method: 提出滑动索引和组件堆叠策略，并设计自适应滑动索引机制，结合全局聚合的键值对。
- Result: TEAFormer在多种图像修复任务中表现出色，效果、训练收敛和泛化能力均优于其他方法。
- Conclusion: TEAFormer通过自适应策略有效解决了平移等变性问题，提升了图像修复任务的性能。


### [130] [Multi-Scale Representation of Follicular Lymphoma Pathology Images in a Single Hyperbolic Space](https://arxiv.org/abs/2506.18523)
*Kei Taguchi,Kazumasa Ohara,Tatsuya Yokota,Hiroaki Miyoshi,Noriaki Hashimoto,Ichiro Takeuchi,Hidekata Hontani*

Main category: cs.CV

TL;DR: 提出了一种在双曲空间中表示恶性淋巴瘤病理图像的方法，通过自监督学习捕捉多尺度形态变化。

- Motivation: 为了捕捉疾病进展中跨尺度的形态变化，需要一种能够有效编码组织与细胞核层次结构的方法。
- Method: 使用自监督学习，将高分辨率细胞核图像与低分辨率组织图像嵌入双曲空间（Poincaré球），基于包含关系使其靠近。
- Result: 学习到的表示能够同时捕捉疾病状态和细胞类型的变化。
- Conclusion: 该方法成功地在双曲空间中编码了病理图像的层次结构，为疾病分析提供了有效工具。


### [131] [Auto-Regressively Generating Multi-View Consistent Images](https://arxiv.org/abs/2506.18527)
*JiaKui Hu,Yuxiao Yang,Jialun Liu,Jinbo Wu,Chen Zhao,Yanye Lu*

Main category: cs.CV

TL;DR: MV-AR方法通过自回归模型生成多视角图像，解决了视角一致性和多样条件下的形状与纹理合成问题。

- Motivation: 多视角图像生成对3D内容创作至关重要，但面临视角一致性和多样条件合成的挑战。
- Method: 利用自回归模型逐步生成多视角图像，引入条件注入模块和渐进训练策略，并采用数据增强技术扩展训练数据。
- Result: MV-AR能生成一致的多视角图像，性能与领先的扩散模型相当。
- Conclusion: MV-AR在多视角图像生成中表现出色，代码和模型将开源。


### [132] [A Set-to-Set Distance Measure in Hyperbolic Space](https://arxiv.org/abs/2506.18529)
*Pengxiang Li,Wei Wu,Zhi Gao,Xiaomeng Fan,Peilin Yu,Yuwei Wu,Zhipeng Lu,Yunde Jia,Mehrtash Harandi*

Main category: cs.CV

TL;DR: 提出了一种双曲集合间距离度量HS2SD，结合全局和局部结构信息，优于现有方法。

- Motivation: 现实应用中需要比较双曲数据集合，而现有方法未能充分捕捉集合的全局和局部结构信息。
- Method: HS2SD通过双曲集合的Einstein中点测地距离（全局）和拓扑特征（局部）计算距离，使用Thue-Morse序列近似拓扑结构。
- Result: 在实体匹配、标准图像分类和小样本图像分类任务中表现优异。
- Conclusion: HS2SD能更细致地建模双曲集合间的层次和复杂关系。


### [133] [Geometry-aware Distance Measure for Diverse Hierarchical Structures in Hyperbolic Spaces](https://arxiv.org/abs/2506.18533)
*Pengxiang Li,Yuwei Wu,Zhi Gao,Xiaomeng Fan,Wei Wu,Zhipeng Lu,Yunde Jia,Mehrtash Harandi*

Main category: cs.CV

TL;DR: 提出了一种动态适应不同层次结构的双曲空间几何感知距离度量方法，通过定制投影和曲率优化数据点对的距离计算，显著提升了分类和少样本学习任务的性能。

- Motivation: 现有双曲学习方法使用固定距离度量，假设所有数据点具有统一的层次结构，而现实中的层次结构具有多样性，这种假设过于限制性。
- Method: 提出几何感知距离度量，动态适应不同层次结构；引入低秩分解方案和硬对挖掘机制以减少计算成本；使用Talagrand集中不等式确保理论鲁棒性。
- Result: 在标准图像分类、层次分类和少样本学习任务中表现优异，尤其在少样本学习任务中性能提升超过5%。
- Conclusion: 自适应距离度量能更好地捕捉多样化的层次结构，可视化结果显示更清晰的类别边界和原型分离。


### [134] [Normality Prior Guided Multi-Semantic Fusion Network for Unsupervised Image Anomaly Detection](https://arxiv.org/abs/2506.18544)
*Muhao Xu,Xueying Zhou,Xizhan Gao,Weiye Song,Guang Feng,Sijie Niu*

Main category: cs.CV

TL;DR: 论文提出了一种基于多语义融合网络的异常检测方法，通过引入正常样本的多语义特征来引导异常重构，显著提升了逻辑异常检测的性能。

- Motivation: 逻辑异常检测比结构异常更具挑战性，现有方法通过低维瓶颈压缩输入，但逻辑异常的全局语义与正常模式差异显著，可能导致异常重构误导性高。
- Method: 提出多语义融合网络，利用预训练的视觉-语言网络提取正常样本的全局语义，构建可学习的语义码本，并将多语义特征融合后输入解码器以引导异常重构。
- Result: 在MVTec LOCO AD数据集上，像素级sPRO提升5.7%，图像级AUROC提升2.6%，达到SOTA性能。
- Conclusion: 该方法通过引入正常样本的多语义特征，有效解决了逻辑异常检测的挑战，显著提升了性能。


### [135] [Object-aware Sound Source Localization via Audio-Visual Scene Understanding](https://arxiv.org/abs/2506.18557)
*Sung Jin Um,Dongjin Kim,Sangmin Lee,Jung Uk Kim*

Main category: cs.CV

TL;DR: 提出了一种基于多模态大语言模型（MLLMs）的声源定位框架，通过生成细粒度语义信息区分发声物体与静默物体，并引入两种新的损失函数（OCA和ORI），显著提升了复杂场景中的定位性能。

- Motivation: 现有方法在复杂场景中难以准确区分发声物体与视觉相似的静默物体，主要依赖简单的视听对应关系，缺乏细粒度语义信息。
- Method: 利用MLLMs生成详细上下文信息，明确区分发声前景物体与静默背景物体，并设计OCA和ORI两种损失函数进行优化。
- Result: 在MUSIC和VGGSound数据集上表现优异，显著优于现有方法，适用于单源和多源定位场景。
- Conclusion: 提出的框架通过细粒度语义信息和新型损失函数，有效解决了复杂场景中的声源定位问题。


### [136] [VQ-Insight: Teaching VLMs for AI-Generated Video Quality Understanding via Progressive Visual Reinforcement Learning](https://arxiv.org/abs/2506.18564)
*Xuanyu Zhang,Weiqi Li,Shijie Zhao,Junlin Li,Li Zhang,Jian Zhang*

Main category: cs.CV

TL;DR: VQ-Insight是一个新的推理式视觉语言模型框架，用于评估AI生成视频的质量，解决了现有方法的局限性。

- Motivation: 当前AI生成视频质量评估方法存在泛化能力不足、缺乏时间感知、依赖大规模标注数据等问题。
- Method: 提出VQ-Insight框架，结合渐进式视频质量学习方案和多维度评分奖励设计。
- Result: 实验表明VQ-Insight在偏好比较、多维度评分和自然视频评分中优于现有方法。
- Conclusion: VQ-Insight显著提升了视频生成任务的质量评估效果。


### [137] [VisualChef: Generating Visual Aids in Cooking via Mask Inpainting](https://arxiv.org/abs/2506.18569)
*Oleh Kuzyk,Zuoyue Li,Marc Pollefeys,Xi Wang*

Main category: cs.CV

TL;DR: VisualChef是一种生成烹饪场景中上下文视觉辅助的方法，通过基于掩码的视觉接地简化对齐，无需额外标注。

- Motivation: 烹饪过程中缺乏一致的视觉指导，现有方法依赖复杂的文本-视觉对齐和额外标注。
- Method: VisualChef通过识别动作相关对象并分类，实现针对性修改，同时保持环境一致，并提出自动化提取高质量帧的流程。
- Result: 在三个第一人称视频数据集上的定量和定性评估显示，VisualChef优于现有方法。
- Conclusion: VisualChef简化了视觉辅助生成，提升了烹饪场景中的实用性。


### [138] [2D Triangle Splatting for Direct Differentiable Mesh Training](https://arxiv.org/abs/2506.18575)
*Kaifeng Sheng,Zheng Zhou,Yingliang Peng,Qianwei Wang*

Main category: cs.CV

TL;DR: 提出了一种名为2D Triangle Splatting（2DTS）的新方法，用2D三角形面片替代3D高斯基元，以解决渲染速度和高级渲染效果的问题。

- Motivation: 3D高斯基元在渲染速度和高级效果（如重光照和阴影渲染）上仍存在不足，而基于网格的模型表现更优。
- Method: 使用2D三角形面片形成离散的类网格结构，同时保留连续体积建模的优势，并通过紧凑性参数直接训练逼真网格。
- Result: 实验表明，该方法在未调优紧凑性的情况下，比现有高斯基元方法具有更高的保真度，且重建网格的视觉质量更优。
- Conclusion: 2DTS方法在渲染速度和视觉效果上优于现有方法，为3D场景重建提供了新的解决方案。


### [139] [Resampling Augmentation for Time Series Contrastive Learning: Application to Remote Sensing](https://arxiv.org/abs/2506.18587)
*Antoine Saget,Baptiste Lafabregue,Antoine Cornuéjols,Pierre Gançarski*

Main category: cs.CV

TL;DR: 论文提出了一种基于重采样的对比学习增强策略，用于卫星图像时间序列（SITS），在农业分类任务中表现优于传统方法。

- Motivation: 由于卫星图像时间序列中未标记数据丰富而标记数据稀缺，需要一种有效的自监督预训练方法来利用未标记数据。
- Method: 提出了一种新的重采样增强策略，通过上采样时间序列并提取不重叠的子序列来生成正样本对，同时保持时间覆盖范围。
- Result: 在多个农业分类基准测试中验证了方法的有效性，优于抖动、调整大小和掩码等传统方法，并在S2-Agri100数据集上达到最优性能。
- Conclusion: 该方法为遥感时间序列提供了一种简单而有效的对比学习增强策略。


### [140] [SpaNN: Detecting Multiple Adversarial Patches on CNNs by Spanning Saliency Thresholds](https://arxiv.org/abs/2506.18591)
*Mauricio Byrd Victorica,György Dán,Henrik Sandberg*

Main category: cs.CV

TL;DR: SpaNN是一种新型对抗攻击检测器，其计算复杂度与对抗补丁数量无关，通过构建二值化特征图集合和聚类检测攻击。

- Motivation: 现有防御方法多针对单补丁攻击，对多补丁攻击效果不佳或计算成本高。
- Method: SpaNN通过应用一组显著性阈值生成二值化特征图集合，进行聚类后输入分类器检测攻击。
- Result: 在四个数据集上，SpaNN在目标检测和图像分类任务中分别优于现有方法11和27个百分点。
- Conclusion: SpaNN在多补丁攻击场景下表现优异，且计算高效。


### [141] [RDPO: Real Data Preference Optimization for Physics Consistency Video Generation](https://arxiv.org/abs/2506.18655)
*Wenxu Qian,Chaoyue Wang,Hou Peng,Zhiyu Tan,Hao Li,Anxiang Zeng*

Main category: cs.CV

TL;DR: RDPO是一种无需标注的框架，通过从真实视频中提取物理先验，显著提升了生成视频的动作连贯性和物理真实性。

- Motivation: 当前视频生成技术在视觉质量上取得了显著进展，但在真实物理一致性方面仍有不足，且现有方法依赖昂贵的人工标注数据或奖励模型。
- Method: 提出RDPO框架，通过反向采样真实视频序列自动构建偏好对，并采用多阶段迭代训练优化生成器。
- Result: 在多个基准测试和人工评估中，RDPO在动作连贯性和物理真实性方面均表现出显著提升。
- Conclusion: RDPO通过利用真实视频的动态信息，有效解决了视频生成中的物理一致性问题，无需依赖人工标注。


### [142] [Historical Report Guided Bi-modal Concurrent Learning for Pathology Report Generation](https://arxiv.org/abs/2506.18658)
*Ling Zhang,Boxiang Yun,Qingli Li,Yan Wang*

Main category: cs.CV

TL;DR: BiGen框架通过历史报告引导的双模态并行学习，解决了WSI中语义内容不足和信息冗余问题，显著提升了病理报告生成性能。

- Motivation: 解决WSI中视觉特征缺乏语义内容和信息冗余的挑战，模拟病理学家的诊断推理过程。
- Method: 提出知识检索机制和双模态并行学习策略，结合视觉和文本令牌动态提取关键特征，并通过多模态解码器生成报告。
- Result: 在PathText数据集上表现优异，NLP指标提升7.4%，Her-2预测分类指标提升19.1%。
- Conclusion: BiGen框架有效提供语义内容并抑制冗余信息，模块必要性通过消融实验验证。


### [143] [Benchmarking histopathology foundation models in a multi-center dataset for skin cancer subtyping](https://arxiv.org/abs/2506.18668)
*Pablo Meseguer,Rocío del Amor,Valery Naranjo*

Main category: cs.CV

TL;DR: 该论文提出了一种新的基准测试方法，用于评估病理学基础模型作为补丁级特征提取器在多实例学习框架中的表现，并引入了一种新的度量标准FM-SI来衡量模型对分布变化的鲁棒性。

- Motivation: 由于病理学基础模型的多样性，需要设计真实世界的挑战来评估其有效性，尤其是在多实例学习框架中。
- Method: 利用AI4SkIN数据集，设计了一个基准测试，并在多实例学习分类框架中评估基础模型的特征提取能力，同时提出了FM-SI度量标准。
- Result: 实验表明，提取较少偏差的特征可以提高分类性能，尤其是在基于相似性的多实例学习分类器中。
- Conclusion: 该研究为病理学基础模型的评估提供了新方法，并展示了其在复杂任务中的潜力。


### [144] [MedSeg-R: Medical Image Segmentation with Clinical Reasoning](https://arxiv.org/abs/2506.18669)
*Hao Shao,Qibin Hou*

Main category: cs.CV

TL;DR: MedSeg-R是一个轻量级双阶段框架，通过结合医学报告的语义先验和SAM模型，显著提升了小病灶分割的敏感性和准确性。

- Motivation: 医学图像分割面临小病灶边界模糊和类别不平衡的挑战，现有方法缺乏语义先验，泛化能力不足。
- Method: MedSeg-R分为认知阶段（解析医学报告生成语义先验）和感知阶段（通过空间注意力、动态卷积和可变形采样调制SAM模型）。
- Result: 在复杂基准测试中，MedSeg-R显著提升了重叠和模糊结构的分割性能，兼容SAM系统。
- Conclusion: MedSeg-R通过语义先验和精细调制，有效解决了医学图像分割中的挑战，具有实用性和兼容性。


### [145] [Reconstructing Tornadoes in 3D with Gaussian Splatting](https://arxiv.org/abs/2506.18677)
*Adam Yang,Nadula Kadawedduwa,Tianfu Wang,Maria Molina,Christopher Metzler*

Main category: cs.CV

TL;DR: 论文提出了一种基于实验室的小型龙卷风多视角数据集，并使用3D高斯泼溅（3DGS）技术成功重建了其3D结构。

- Motivation: 龙卷风的3D结构重建对理解和预防其破坏性至关重要，但目前缺乏可控的数据集来开发和验证相关技术。
- Method: 捕获并发布了一个实验室小型龙卷风的多视角数据集，并采用3DGS技术进行3D重建。
- Result: 成功利用3DGS技术重建并可视化了龙卷风的3D结构。
- Conclusion: 该数据集和方法为龙卷风3D结构研究提供了有价值的工具。


### [146] [MCN-SLAM: Multi-Agent Collaborative Neural SLAM with Hybrid Implicit Neural Scene Representation](https://arxiv.org/abs/2506.18678)
*Tianchen Deng,Guole Shen,Xun Chen,Shenghai Yuan,Hongming Shen,Guohao Peng,Zhenyu Wu,Jingchuan Wang,Lihua Xie,Danwei Wang,Hesheng Wang,Weidong Chen*

Main category: cs.CV

TL;DR: 提出首个分布式多Agent协同神经SLAM框架，结合混合场景表示、分布式相机跟踪、局部到全局闭环及在线蒸馏子图融合，并发布首个真实世界密集SLAM数据集。

- Motivation: 现有隐式SLAM算法局限于单Agent场景，且在大规模场景和长序列中表现不佳，而现有NeRF多Agent框架无法满足通信带宽限制。
- Method: 提出三平面网格联合场景表示方法改进重建，设计局部到全局闭环方法保证一致性，并采用在线蒸馏融合子图信息。
- Result: 实验证明该方法在映射、跟踪和通信方面表现优越。
- Conclusion: 提出的框架和数据集将推动SLAM、3D重建和视觉基础模型的研究发展。


### [147] [MARL-MambaContour: Unleashing Multi-Agent Deep Reinforcement Learning for Active Contour Optimization in Medical Image Segmentation](https://arxiv.org/abs/2506.18679)
*Ruicheng Zhang,Yu Sun,Zeyu Zhang,Jinai Li,Xiaofan Liu,Au Hoi Fan,Haowei Guo,Puxin Yan*

Main category: cs.CV

TL;DR: MARL-MambaContour是一种基于多智能体强化学习的医学图像分割框架，通过生成拓扑一致的轮廓解决传统像素方法的局限性。

- Motivation: 传统像素级分割方法缺乏拓扑约束和整体结构意识，难以处理医学图像中的模糊边缘和复杂形态。
- Method: 将每个轮廓点建模为智能体，通过迭代调整位置对齐目标边界，使用改进的SAC算法和Mamba策略网络优化。
- Result: 在五个医学影像数据集上表现优异，展示了其准确性和鲁棒性。
- Conclusion: MARL-MambaContour是一种有潜力的临床工具，能够实现高精度医学图像分割。


### [148] [Multi-Scale Spectral Attention Module-based Hyperspectral Segmentation in Autonomous Driving Scenarios](https://arxiv.org/abs/2506.18682)
*Imad Ali Shah,Jiarong Li,Tim Brophy,Martin Glavin,Edward Jones,Enda Ward,Brian Deegan*

Main category: cs.CV

TL;DR: 本文提出了一种多尺度光谱注意力模块（MSAM），通过结合不同核大小的1D卷积和自适应特征聚合机制，显著提升了高光谱图像（HSI）的语义分割性能，适用于自动驾驶中的环境感知。

- Motivation: 高光谱成像（HSI）在自动驾驶中具有潜力，但其高维数据处理效率低，需要改进特征提取方法。
- Method: 提出MSAM模块，集成三种不同核大小的1D卷积和自适应特征聚合机制，并将其嵌入UNet的跳跃连接中（UNet-MSAM）。
- Result: 在三个HSI数据集上，UNet-MSAM平均提升3.61%的mIoU和3.80%的mF1，计算开销仅增加0.02%参数和0.82%GFLOPS。
- Conclusion: 多尺度核组合优于单尺度配置，为自动驾驶中的HSI处理提供了高效的特征提取方法。


### [149] [SIM-Net: A Multimodal Fusion Network Using Inferred 3D Object Shape Point Clouds from RGB Images for 2D Classification](https://arxiv.org/abs/2506.18683)
*Youcef Sklab,Hanane Ariouat,Eric Chenin,Edi Prifti,Jean-Daniel Zucker*

Main category: cs.CV

TL;DR: SIM-Net是一种新型2D图像分类架构，通过将2D图像转换为3D点云，融合纹理和几何特征，显著提升了分类性能，尤其在植物标本分类任务中表现优异。

- Motivation: 解决传统2D图像分类模型在植物标本分类中因背景复杂、非植物元素和遮挡等问题导致的性能不足。
- Method: 提出像素到点的转换方法，将2D对象掩码转为3D点云，结合CNN和PointNet编码器，融合纹理与几何特征。
- Result: 在植物标本数据集上，SIM-Net比ResNet101准确率提升9.9%，F-score提升12.3%，并优于多种先进模型。
- Conclusion: SIM-Net证明了在2D图像分类中引入3D几何特征的潜力，尤其在复杂场景下表现突出。


### [150] [Matrix-Game: Interactive World Foundation Model](https://arxiv.org/abs/2506.18701)
*Yifan Zhang,Chunli Peng,Boyang Wang,Puyi Wang,Qingcheng Zhu,Fei Kang,Biao Jiang,Zedong Gao,Eric Li,Yang Liu,Yahui Zhou*

Main category: cs.CV

TL;DR: Matrix-Game是一个用于可控游戏世界生成的交互式世界基础模型，通过两阶段训练实现高精度控制和视觉质量。

- Motivation: 开发一个能够精确控制角色动作和相机移动的游戏世界生成模型，同时保持高视觉质量和时间一致性。
- Method: 采用两阶段训练流程：大规模无标签预训练用于环境理解，随后进行带标签的训练以生成交互式视频。模型基于参考图像、运动上下文和用户动作进行可控的图像到世界生成。
- Result: Matrix-Game在视觉质量、时间质量、动作可控性和物理规则理解方面均优于现有开源模型（如Oasis和MineWorld），特别是在可控性和物理一致性方面表现突出。
- Conclusion: Matrix-Game能够生成感知上真实且精确可控的视频，为交互式图像到世界生成的研究提供了新的基准和工具。


### [151] [Including Semantic Information via Word Embeddings for Skeleton-based Action Recognition](https://arxiv.org/abs/2506.18721)
*Dustin Aganian,Erik Franze,Markus Eisenbach,Horst-Michael Gross*

Main category: cs.CV

TL;DR: 提出了一种基于骨架的动作识别新方法，通过词嵌入编码语义信息，显著提升了分类性能和泛化能力。

- Motivation: 传统骨架方法在复杂交互中丢失关键点语义信息，限制了其有效性。
- Method: 利用词嵌入编码语义信息，替换独热编码，生成语义体积以捕捉关节与物体间的关系。
- Result: 在多个装配数据集上的实验表明，该方法显著提升了分类性能，并支持不同骨架类型和物体类别。
- Conclusion: 结合语义信息可有效增强骨架动作识别在动态多样环境中的表现。


### [152] [Deep CNN Face Matchers Inherently Support Revocable Biometric Templates](https://arxiv.org/abs/2506.18731)
*Aman Bhatta,Michael C. King,Kevin W. Bowyer*

Main category: cs.CV

TL;DR: 该论文提出了一种基于深度CNN的可撤销生物特征认证方案，解决了生物特征被泄露后无法撤销的问题，并验证了其有效性。

- Motivation: 解决生物特征认证中生物特征被泄露后无法撤销的问题，提供一种可撤销的生物特征认证方案。
- Method: 利用现代深度CNN人脸匹配器生成多个具有等效识别能力但模板不兼容的模型，实现可撤销性。
- Result: 生成的模型具有等效识别能力且模板不兼容，泄露的模板在撤销后几乎无用。Vision Transformer在此方案中表现不如ResNet。
- Conclusion: 深度CNN可有效支持可撤销生物特征认证，而Vision Transformer在此场景下表现较差。


### [153] [USVTrack: USV-Based 4D Radar-Camera Tracking Dataset for Autonomous Driving in Inland Waterways](https://arxiv.org/abs/2506.18737)
*Shanliang Yao,Runwei Guan,Yi Ni,Sen Xu,Yong Yue,Xiaohui Zhu,Ryan Wen Liu*

Main category: cs.CV

TL;DR: 论文介绍了USVTrack数据集和RCM方法，用于提升内河水道中物体跟踪的准确性和可靠性。

- Motivation: 内河水道中的物体跟踪对安全和经济应用至关重要，但复杂环境下的跟踪仍具挑战性。
- Method: 利用配备多种传感器的USV收集数据，并提出雷达-相机匹配方法RCM。
- Result: 实验证明RCM能有效提升跟踪精度和可靠性。
- Conclusion: USVTrack数据集和RCM方法为新一代水运系统的自动驾驶提供了实用工具。


### [154] [SWA-SOP: Spatially-aware Window Attention for Semantic Occupancy Prediction in Autonomous Driving](https://arxiv.org/abs/2506.18785)
*Helin Cao,Rafael Materla,Sven Behnke*

Main category: cs.CV

TL;DR: 论文提出了一种名为空间感知窗口注意力（SWA）的新机制，通过将局部空间上下文融入注意力计算，提升了语义占用预测（SOP）的性能，尤其在稀疏或遮挡区域表现优异。

- Motivation: 自动驾驶中的感知系统常因遮挡和数据稀疏性无法获取完整环境信息，现有基于Transformer的SOP方法缺乏对空间结构的显式建模，导致几何感知能力有限。
- Method: 提出空间感知窗口注意力（SWA）机制，将局部空间上下文引入注意力计算，增强几何感知能力。
- Result: SWA显著提升了场景补全效果，在LiDAR和相机两种模态的SOP基准测试中均取得了最优性能。
- Conclusion: SWA通过显式建模空间结构，有效解决了稀疏和遮挡区域的语义占用预测问题，具有跨模态的通用性。


### [155] [3D Arena: An Open Platform for Generative 3D Evaluation](https://arxiv.org/abs/2506.18787)
*Dylan Ebert*

Main category: cs.CV

TL;DR: 3D Arena是一个开放平台，通过大规模人类偏好收集评估图像到3D生成模型，解决了现有指标与人类感知质量不一致的问题。

- Motivation: 当前评估生成3D模型的指标存在不足，图像指标忽略3D结构，几何指标无法捕捉感知吸引力。
- Method: 3D Arena通过成对比较收集人类偏好，使用ELO排名系统评估模型，并确保数据真实性。
- Result: 平台收集了123,243票，发现高斯溅射输出比网格模型有16.6 ELO优势，带纹理模型比无纹理模型有144.1 ELO优势。
- Conclusion: 3D Arena成为生成3D模型的基准平台，推动了以人为中心的评估方法发展。


### [156] [Focus Your Attention: Towards Data-Intuitive Lightweight Vision Transformers](https://arxiv.org/abs/2506.18791)
*Suyash Gaurav,Muhammad Farhan Humayun,Jukka Heikkonen,Jatin Chaudhary*

Main category: cs.CV

TL;DR: 提出了一种基于超像素的补丁池化（SPPP）技术和轻量潜在注意力（LLA）模块，以降低Vision Transformers的计算和内存需求，提高效率。

- Motivation: 解决Vision Transformers对计算和内存资源的高依赖以及任务特定迁移学习的困难。
- Method: 采用SPPP生成语义丰富的补丁嵌入，结合LLA模块降低注意力机制的复杂度。
- Result: 显著提高了计算效率，同时性能与现有最优方法相当。
- Conclusion: 该方法适合边缘部署，为高效Transformer提供了新思路。


### [157] [ViDAR: Video Diffusion-Aware 4D Reconstruction From Monocular Inputs](https://arxiv.org/abs/2506.18792)
*Michal Nazarczuk,Sibi Catley-Chandar,Thomas Tanay,Zhensong Zhang,Gregory Slabaugh,Eduardo Pérez-Pellitero*

Main category: cs.CV

TL;DR: ViDAR是一种新型4D重建框架，利用个性化扩散模型生成伪多视角监督信号，用于训练高斯溅射表示，以解决动态新视角合成任务中的单目视频挑战。

- Motivation: 动态新视角合成任务在单目视频中具有挑战性，因为解构运动和结构的监督稀缺且问题不明确。
- Method: ViDAR通过场景特定特征条件化，利用扩散感知损失函数和相机姿态优化策略，恢复细节并减少单目模糊带来的伪影。
- Result: 在DyCheck基准测试中，ViDAR在视觉质量和几何一致性上优于所有现有方法，尤其在动态区域表现突出。
- Conclusion: ViDAR通过扩散模型和优化策略，显著提升了动态新视角合成的性能，并提供了新的基准测试。


### [158] [OC-SOP: Enhancing Vision-Based 3D Semantic Occupancy Prediction by Object-Centric Awareness](https://arxiv.org/abs/2506.18798)
*Helin Cao,Sven Behnke*

Main category: cs.CV

TL;DR: 论文提出了一种基于对象中心的语义占用预测框架（OC-SOP），通过整合检测分支提取的高层对象中心线索，显著提升了前景物体的预测准确性。

- Motivation: 自动驾驶感知因环境中的遮挡和不完整场景数据面临挑战，传统相机方法对所有类别平等处理且依赖局部特征，导致预测效果不佳。
- Method: 提出OC-SOP框架，将检测分支提取的对象中心线索整合到语义占用预测流程中。
- Result: 显著提升了前景物体的预测准确性，并在SemanticKITTI上实现了所有类别的最优性能。
- Conclusion: OC-SOP通过对象中心的方法有效解决了传统方法的局限性，提升了语义占用预测的整体性能。


### [159] [PicoSAM2: Low-Latency Segmentation In-Sensor for Edge Vision Applications](https://arxiv.org/abs/2506.18807)
*Pietro Bonazzi,Nicola Farronato,Stefan Zihlmann,Haotong Qi,Michele Magno*

Main category: cs.CV

TL;DR: PicoSAM2是一个轻量级、可提示的分割模型，专为边缘和传感器内执行优化，满足实时性和隐私需求。

- Motivation: 实时、设备端分割对延迟敏感和隐私保护应用（如智能眼镜和物联网设备）至关重要。
- Method: 基于深度可分离U-Net，结合知识蒸馏和固定点提示编码，从SAM2学习。
- Result: 在COCO和LVIS上分别达到51.9%和44.9% mIoU，量化模型（1.22MB）在IMX500上运行时间为14.3毫秒。
- Conclusion: PicoSAM2证明高效、可提示的分割可直接在相机上实现，无需云端或主机处理。


### [160] [4Real-Video-V2: Fused View-Time Attention and Feedforward Reconstruction for 4D Scene Generation](https://arxiv.org/abs/2506.18839)
*Chaoyang Wang,Ashkan Mirzaei,Vidit Goel,Willi Menapace,Aliaksandr Siarohin,Avalon Vinella,Michael Vasilkovsky,Ivan Skorokhodov,Vladislav Shakhrai,Sergey Korolev,Sergey Tulyakov,Peter Wonka*

Main category: cs.CV

TL;DR: 提出首个4D时空网格框架，结合视频帧和3D高斯粒子，通过前馈架构实现。

- Motivation: 现有4D视频扩散架构在时空注意力处理上存在局限性，需改进以提升视觉质量和重建能力。
- Method: 采用融合架构，单层处理时空注意力；扩展3D重建算法，引入高斯头和动态层。
- Result: 在4D生成任务中达到新SOTA，视觉质量和重建能力均提升。
- Conclusion: 提出的框架有效解决了现有方法的局限性，显著提升了4D生成性能。


### [161] [Phantom-Data : Towards a General Subject-Consistent Video Generation Dataset](https://arxiv.org/abs/2506.18851)
*Zhuowei Chen,Bingchuan Li,Tianxiang Ma,Lijie Liu,Mingcong Liu,Yi Zhang,Gen Li,Xinghui Li,Siyu Zhou,Qian He,Xinglong Wu*

Main category: cs.CV

TL;DR: 论文提出了Phantom-Data数据集，解决了现有主题到视频生成模型在遵循文本指令时的局限性，显著提升了生成质量。

- Motivation: 现有模型因使用同场景参考图像训练，导致主题身份与背景属性纠缠（即复制粘贴问题），限制了生成效果。
- Method: 通过三阶段流程构建跨对主题一致性数据集：1) 主题检测；2) 大规模跨上下文主题检索；3) 先验引导的身份验证。
- Result: 实验表明，使用Phantom-Data训练显著提升了提示对齐和视觉质量，同时保持了身份一致性。
- Conclusion: Phantom-Data是首个通用跨对主题到视频一致性数据集，有效解决了现有模型的局限性。


### [162] [RAG-6DPose: Retrieval-Augmented 6D Pose Estimation via Leveraging CAD as Knowledge Base](https://arxiv.org/abs/2506.18856)
*Kuanning Wang,Yuqian Fu,Tianyu Wang,Yanwei Fu,Longfei Liang,Yu-Gang Jiang,Xiangyang Xue*

Main category: cs.CV

TL;DR: RAG-6DPose是一种基于检索增强的6D姿态估计方法，结合视觉和几何线索，利用3D CAD模型知识库提升精度。

- Motivation: 6D姿态估计对机器人操作（如抓取）至关重要，需要高精度的物体定位。
- Method: 1) 构建多模态CAD知识库；2) 通过ReSPC模块检索相关CAD特征；3) 利用检索信息优化姿态预测。
- Result: 在标准基准和实际机器人任务中表现优异，尤其在遮挡和新视角下鲁棒性强。
- Conclusion: RAG-6DPose通过检索增强方法显著提升了6D姿态估计的精度和鲁棒性。


### [163] [TAMMs: Temporal-Aware Multimodal Model for Satellite Image Change Understanding and Forecasting](https://arxiv.org/abs/2506.18862)
*Zhongbin Guo,Yuhao Wang,Ping Jian,Xinyue Chen,Wei Peng,Ertai E*

Main category: cs.CV

TL;DR: TAMMs模型通过轻量级时间模块和语义融合控制注入机制，提升了多模态大语言模型在卫星图像时间序列分析中的时空推理能力。

- Motivation: 现有MLLMs在卫星图像时间序列分析中的时空推理能力不足，需要更精细的建模方法。
- Method: 提出TAMMs模型，结合轻量级时间模块和SFCI机制，增强MLLMs的时空推理和图像生成能力。
- Result: TAMMs在时间变化理解和未来图像预测任务中优于基线MLLMs。
- Conclusion: 精心设计的时间推理和语义融合能充分发挥MLLMs在时空理解中的潜力。


### [164] [OmniAvatar: Efficient Audio-Driven Avatar Video Generation with Adaptive Body Animation](https://arxiv.org/abs/2506.18866)
*Qijun Gan,Ruizi Yang,Jianke Zhu,Shaofei Xue,Steven Hoi*

Main category: cs.CV

TL;DR: OmniAvatar是一种创新的音频驱动全身视频生成模型，通过改进唇同步和自然动作，解决了现有方法在全身动画和精细控制方面的不足。

- Motivation: 现有音频驱动人体动画方法主要关注面部动作，难以生成自然同步和流畅的全身动画，且缺乏精细提示控制。
- Method: 采用像素级多层次音频嵌入策略和基于LoRA的训练方法，以更好地捕捉音频特征并保留基础模型的提示控制能力。
- Result: 实验表明，OmniAvatar在面部和半身视频生成方面优于现有模型，并提供精确的文本控制能力。
- Conclusion: OmniAvatar通过创新方法提升了音频驱动动画的质量和控制灵活性，适用于多种场景。


### [165] [OmniGen2: Exploration to Advanced Multimodal Generation](https://arxiv.org/abs/2506.18871)
*Chenyuan Wu,Pengfei Zheng,Ruiran Yan,Shitao Xiao,Xin Luo,Yueze Wang,Wanli Li,Xiyan Jiang,Yexin Liu,Junjie Zhou,Ze Liu,Ziyi Xia,Chaofan Li,Haoge Deng,Jiahao Wang,Kun Luo,Bo Zhang,Defu Lian,Xinlong Wang,Zhongyuan Wang,Tiejun Huang,Zheng Liu*

Main category: cs.CV

TL;DR: OmniGen2是一个多功能开源生成模型，支持文本到图像、图像编辑和上下文生成任务，通过分离的解码路径和反射机制实现高效性能。

- Motivation: 为解决多模态生成任务的统一解决方案，同时保留文本生成能力并提升性能。
- Method: 采用分离的文本和图像解码路径，使用非共享参数和解耦的图像标记器，并引入反射机制和专用数据集。
- Result: 在多个任务基准测试中表现优异，特别是在文本到图像和图像编辑任务中，并在OmniContext基准上达到开源模型的最先进一致性。
- Conclusion: OmniGen2通过创新的设计和数据管道，为多模态生成任务提供了高效且统一的解决方案，并开源模型和工具以支持未来研究。


### [166] [Let Your Video Listen to Your Music!](https://arxiv.org/abs/2506.18881)
*Xinyu Zhang,Dong Gong,Zicheng Duan,Anton van den Hengel,Lingqiao Liu*

Main category: cs.CV

TL;DR: MVAA框架自动将视频与音乐节拍对齐，保留原始内容，通过关键帧对齐和节奏感知修复实现高效编辑。

- Motivation: 提升视频与音乐节奏对齐的效率与质量，减少人工编辑负担，增强视觉吸引力。
- Method: 两步骤：关键帧对齐音乐节拍，节奏感知视频修复；采用预训练与快速微调结合策略。
- Result: 实验表明MVAA能高质量对齐节拍并保持视觉流畅性。
- Conclusion: MVAA为视频音乐对齐提供高效灵活解决方案。


### [167] [Light of Normals: Unified Feature Representation for Universal Photometric Stereo](https://arxiv.org/abs/2506.18882)
*Hong Li,Houyuan Chen,Chongjie Ye,Zhaoxi Chen,Bohan Li,Shaocong Xu,Xianda Guo,Xuhui Liu,Yikai Wang,Baochang Zhang,Satoshi Ikehata,Boxin Shi,Anyi Rao,Hao Zhao*

Main category: cs.CV

TL;DR: 通用光度立体（PS）旨在从任意光照条件下的物体中恢复高质量表面法线，无需依赖特定光照模型。尽管有SDM-UniPS和Uni MS-PS等进展，仍存在两个挑战：光照与法线特征的深度耦合，以及复杂表面高频几何细节的保留。

- Motivation: 解决通用光度立体中光照与法线特征耦合的模糊性，以及复杂表面几何细节的准确捕捉问题。
- Method: 通过分析光照变化与表面法线的关系，改进特征处理操作以保留高频几何细节。
- Result: 提出了一种能够处理任意光照条件并保留复杂表面细节的方法。
- Conclusion: 该方法在通用光度立体中有效解决了光照模糊性和几何细节保留问题。


### [168] [Universal Video Temporal Grounding with Generative Multi-modal Large Language Models](https://arxiv.org/abs/2506.18883)
*Zeqian Li,Shangzhe Di,Zhonghua Zhai,Weilin Huang,Yanfeng Wang,Weidi Xie*

Main category: cs.CV

TL;DR: UniTime是一个通用的视频时间定位模型，利用生成式多模态大语言模型（MLLMs）的能力，精准定位视频中的时间片段，适用于多样化的视频和复杂语言查询。

- Motivation: 现有方法通常局限于特定视频领域或时长，无法处理多样化视频和复杂查询，因此需要一种更通用的解决方案。
- Method: UniTime通过插入时间戳标记与视频标记结合，利用自适应帧缩放处理不同长度的视频，实现精准时间定位。
- Result: 在五个公开时间定位基准测试中，UniTime在零样本和微调设置下均优于现有方法，并在长视频问答任务中显著提升准确性。
- Conclusion: UniTime展示了在复杂视频理解任务中的潜力，为通用视频时间定位提供了有效解决方案。


### [169] [4D-LRM: Large Space-Time Reconstruction Model From and To Any View at Any Time](https://arxiv.org/abs/2506.18890)
*Ziqiao Ma,Xuweiyi Chen,Shoubin Yu,Sai Bi,Kai Zhang,Chen Ziwen,Sihan Xu,Jianing Yang,Zexiang Xu,Kalyan Sunkavalli,Mohit Bansal,Joyce Chai,Hao Tan*

Main category: cs.CV

TL;DR: 4D-LRM是一种大规模4D重建模型，能够从任意视角和时间点渲染物体，解决了传统方法在效率、泛化性和真实性上的不足。

- Motivation: 探索如何通过4D预训练学习通用的时空表示，从少量视角和时间点重建物体到任意视角和时间点。
- Method: 4D-LRM通过学习统一的时空表示，直接从时间序列的姿势图像标记预测每像素的4D高斯基元，实现快速高质量渲染。
- Result: 4D-LRM在单次前向传播中重建24帧序列，耗时少于1.5秒，泛化能力强，支持时间插值和多样化相机设置。
- Conclusion: 4D-LRM证明了时空预训练的扩展性，能够高效准确地完成4D重建任务。


### [170] [Vision as a Dialect: Unifying Visual Understanding and Generation via Text-Aligned Representations](https://arxiv.org/abs/2506.18898)
*Jiaming Han,Hao Chen,Yang Zhao,Hanyu Wang,Qi Zhao,Ziyan Yang,Hao He,Xiangyu Yue,Lu Jiang*

Main category: cs.CV

TL;DR: 本文提出了一种多模态框架Tar，通过共享的离散语义表示统一视觉理解和生成，核心是文本对齐的Tokenizer（TA-Tok）。

- Motivation: 旨在将视觉和文本模态统一到一个共享空间中，避免模态特定设计，提升跨模态输入和输出的效率。
- Method: 使用TA-Tok将图像转换为离散标记，结合扩展词汇表的多模态LLM Tar，提出尺度自适应编解码和生成式去标记器。
- Result: 实验表明Tar在视觉理解和生成任务中表现优异，收敛更快且训练效率更高。
- Conclusion: Tar框架在多模态任务中具有高效性和通用性，为视觉与文本的统一提供了新思路。


### [171] [FilMaster: Bridging Cinematic Principles and Generative AI for Automated Film Generation](https://arxiv.org/abs/2506.18899)
*Kaiyi Huang,Yukun Huang,Xintao Wang,Zinan Lin,Xuefei Ning,Pengfei Wan,Di Zhang,Yu Wang,Xihui Liu*

Main category: cs.CV

TL;DR: FilMaster是一个端到端AI系统，通过整合真实世界的电影原则，生成专业级电影内容，解决了现有系统在镜头语言和节奏上的不足。

- Motivation: 现有电影生成系统缺乏多样化的镜头语言和电影节奏，导致视觉效果模板化和叙事乏味。
- Method: FilMaster基于两个关键原则：从大量电影数据中学习摄影技术，并模拟以观众为中心的后期制作流程。系统分为参考引导生成阶段和生成后期制作阶段。
- Result: FilMaster在镜头语言设计和电影节奏控制方面表现优异，推动了生成AI在专业电影制作中的应用。
- Conclusion: FilMaster通过结合真实电影原则和生成AI技术，显著提升了AI生成电影的质量和专业性。


### [172] [Audit & Repair: An Agentic Framework for Consistent Story Visualization in Text-to-Image Diffusion Models](https://arxiv.org/abs/2506.18900)
*Kiymet Akdemir,Tahira Kazimi,Pinar Yanardag*

Main category: cs.CV

TL;DR: 提出了一种多智能体协作框架，用于解决多面板故事可视化中的视觉一致性问题，优于现有方法。

- Motivation: 故事可视化中保持角色和对象的视觉一致性是一个挑战，现有方法难以解决。
- Method: 采用协作多智能体框架，通过迭代循环实现面板级更新，兼容多种扩散模型。
- Result: 定量和定性实验表明，该方法在多面板一致性上优于现有方法。
- Conclusion: 提出的框架能有效提升故事可视化的视觉一致性，且具有模型无关性。


### [173] [From Virtual Games to Real-World Play](https://arxiv.org/abs/2506.18901)
*Wenqiang Sun,Fangyun Wei,Jinjing Zhao,Xi Chen,Zilong Chen,Hongyang Zhang,Jun Zhang,Yan Lu*

Main category: cs.CV

TL;DR: RealPlay是一个基于神经网络的实时游戏引擎，能够根据用户控制信号生成交互式视频，目标是生成逼真且时间一致的视频序列。

- Motivation: 旨在解决现有技术在生成逼真视频和交互性方面的不足，特别是在低延迟反馈和时间一致性上的挑战。
- Method: 采用迭代分块预测技术，结合标记的游戏数据和无标记的真实世界视频进行训练，无需真实世界动作标注。
- Result: 实现了控制信号从虚拟到真实场景的映射，并能控制多种真实世界实体（如自行车和行人）。
- Conclusion: RealPlay展示了在逼真视频生成和交互性方面的潜力，特别是在跨场景和实体泛化上的能力。


### [174] [VMem: Consistent Interactive Video Scene Generation with Surfel-Indexed View Memory](https://arxiv.org/abs/2506.18903)
*Runjia Li,Philip Torr,Andrea Vedaldi,Tomas Jakab*

Main category: cs.CV

TL;DR: 提出了一种新颖的记忆机制（VMem），用于构建能交互式探索环境的视频生成器，解决了现有方法在长期场景一致性上的不足。

- Motivation: 现有方法（如2D视图重建3D几何或短上下文窗口视频生成器）在长期场景一致性和计算成本上存在局限性。
- Method: 引入Surfel-Indexed View Memory（VMem），通过几何索引记住过去视图，仅检索相关视图以生成新视图。
- Result: 在长期场景合成基准测试中表现优异，优于现有方法，保持了场景一致性和相机控制。
- Conclusion: VMem是一种高效且有效的记忆机制，显著提升了视频生成器的长期场景一致性。


### [175] [TC-Light: Temporally Consistent Relighting for Dynamic Long Videos](https://arxiv.org/abs/2506.18904)
*Yang Liu,Chuanchen Luo,Zimo Tang,Yingyan Li,Yuran Yang,Yuanyong Ning,Lue Fan,Junran Peng,Zhaoxiang Zhang*

Main category: cs.CV

TL;DR: TC-Light是一种新颖的视频重光照方法，通过两阶段优化机制实现全局光照对齐和细粒度纹理优化，具有时间一致性和计算效率。

- Motivation: 现有视频重光照技术主要局限于肖像视频或面临时间一致性和计算效率的瓶颈，TC-Light旨在解决这些问题。
- Method: 提出两阶段后优化机制：第一阶段优化外观嵌入以对齐全局光照，第二阶段优化唯一视频张量（UVT）以对齐细粒度纹理和光照。
- Result: 实验表明，TC-Light能够实现物理上合理且时间一致的重光照效果，计算成本低。
- Conclusion: TC-Light为复杂动态视频的重光照提供了一种高效且一致的解决方案。
## cs.MM

### [176] [Can Generated Images Serve as a Viable Modality for Text-Centric Multimodal Learning?](https://arxiv.org/abs/2506.17623)
*Yuesheng Huang,Peng Zhang,Riliang Liu,Jiaqi Liang*

Main category: cs.MM

TL;DR: 研究探讨了文本到图像（T2I）模型生成的图像是否能作为文本中心任务的补充模态，发现其有效性取决于语义对齐、任务的可视化基础及T2I模型质量。

- Motivation: 解决文本数据与多模态模型之间的模态差距，探索T2I模型生成的图像对文本任务的潜在增益。
- Method: 通过文本分类任务，评估T2I模型质量、提示工程策略和多模态融合架构的影响。
- Result: 合成感知能显著提升性能，但效果高度依赖于语义对齐、任务的可视化基础和T2I模型的生成保真度。
- Conclusion: 研究为这一范式建立了首个严格基准，展示了其在丰富语言理解中的潜力与局限性。
## cs.DB

### [177] [LIGHTHOUSE: Fast and precise distance to shoreline calculations from anywhere on earth](https://arxiv.org/abs/2506.18842)
*Patrick Beukema,Henry Herzog,Yawen Zhang,Hunter Pitelka,Favyen Bastani*

Main category: cs.DB

TL;DR: 提出了一种新的高精度全球海岸线数据集（10米分辨率）和高效计算算法（Lighthouse），显著提升了现有数据的精度和计算效率。

- Motivation: 现有全球海岸数据集分辨率较低（1-4公里），限制了其应用潜力。通过结合卫星图像和计算机视觉技术，可以实现更高精度的海岸线计算。
- Method: 开发了Lighthouse库，采用分层迭代地理空间层次化地形导向统一搜索算法，实现了高效且资源节约的计算。
- Result: 提供了10米分辨率的全球海岸线数据集，精度提升100倍以上；Lighthouse仅需1 CPU和2GB RAM即可实现毫秒级在线推理。
- Conclusion: 该研究为资源受限环境下的实时应用提供了高精度且高效的海岸距离计算解决方案。
## cs.DL

### [178] [Unfolding the Past: A Comprehensive Deep Learning Approach to Analyzing Incunabula Pages](https://arxiv.org/abs/2506.18069)
*Klaudia Ropel,Krzysztof Kutt,Luiz do Valle Miranda,Grzegorz J. Nalepa*

Main category: cs.DL

TL;DR: 开发了一种自动分析早期印刷书籍页面结构和内容的方法，结合自定义数据集和公开数据集，使用YOLO模型进行目标检测，Tesseract和Kraken进行OCR，ResNet18进行图像分类，CLIP生成语义描述，验证了机器学习在早期书籍分析中的潜力。

- Motivation: 探索机器学习在分析早期印刷书籍（如incunabula）页面结构和内容中的应用，以提升数字化档案的自动化处理能力。
- Method: 创建包含500页标注数据的自定义数据集，结合DocLayNet数据集，使用YOLO11n和YOLO11s进行目标检测，Tesseract和Kraken进行OCR，ResNet18进行图像分类，CLIP生成语义描述。
- Result: YOLO11n在自定义数据集上表现最佳（F1=0.94），Tesseract在OCR中优于Kraken，ResNet18图像分类准确率达98.7%，CLIP成功生成插图语义描述。
- Conclusion: 机器学习在早期书籍分析中具有潜力，但OCR性能和视觉内容解释仍需改进。
## physics.geo-ph

### [179] [Pix2Geomodel: A Next-Generation Reservoir Geomodeling with Property-to-Property Translation](https://arxiv.org/abs/2506.17747)
*Abdulrahman Al-Fakih,Ardiansyah Koeshidayatullah,Nabil A. Saraih,Tapan Mukerji,Rayan Kanfar,Abdulmohsen Alali,SanLinn I. Kaka*

Main category: physics.geo-ph

TL;DR: Pix2Geomodel是一种基于Pix2Pix的cGAN框架，用于预测储层属性，展示了高精度和地质真实性，但存在2D限制。

- Motivation: 传统地质建模方法难以处理复杂的地下异质性和观测数据条件，需要更高效的方法。
- Method: 使用Pix2Pix的cGAN框架，结合数据预处理和增强，训练U-Net生成器和PatchGAN判别器。
- Result: 在岩相和水饱和度预测中表现优异（PA 0.88-0.96），孔隙度和渗透率预测中等（PA 0.70-0.74）。
- Conclusion: Pix2Geomodel提升了储层属性映射的准确性，未来需扩展至3D建模和多模态数据。
## cs.LG

### [180] [PCaM: A Progressive Focus Attention-Based Information Fusion Method for Improving Vision Transformer Domain Adaptation](https://arxiv.org/abs/2506.17232)
*Zelin Zang,Fei Wang,Liangyu Li,Jinlin Wu,Chunshui Zhao,Zhen Lei,Baigui Sun*

Main category: cs.LG

TL;DR: 论文提出了一种名为PCaM的渐进式聚焦交叉注意力机制，用于解决无监督域适应中前景对象不匹配的问题，显著提升了域适应性能。

- Motivation: 现有基于Vision Transformers的无监督域适应方法因前景对象大小和空间分布差异导致注意力一致性不足，影响域对齐效果。
- Method: 提出PCaM机制，逐步过滤背景信息，聚焦并融合跨域的前景语义；引入注意力引导损失，增强任务相关区域的注意力一致性。
- Result: 在多个数据集上的实验表明，PCaM显著提升了域适应性能，并取得了新的最优结果。
- Conclusion: PCaM通过注意力引导的前景融合，有效解决了域适应中的前景不匹配问题，具有轻量级、架构无关的特点。


### [181] [Learning to Adapt Frozen CLIP for Few-Shot Test-Time Domain Adaptation](https://arxiv.org/abs/2506.17307)
*Zhixiang Chi,Li Gu,Huan Liu,Ziqiang Wang,Yanan Wu,Yang Wang,Konstantinos N Plataniotis*

Main category: cs.LG

TL;DR: 本文提出了一种新方法，通过在学习输入空间补充CLIP的冻结特征，结合贪婪文本集成和领域提示，显著提升了小样本测试时领域适应的性能。

- Motivation: 现有方法依赖CLIP的预训练特征空间，但其性能在较弱骨干网络（如ViT-B/16）上显著下降，需要补充数据集特定知识。
- Method: 引入独立分支并行学习输入空间知识，通过反向注意力和贪婪文本集成增强文本特征，结合领域提示逐步融合视觉与文本特征。
- Result: 在5个大规模基准测试（WILDS和DomainNet）上表现优越，ViT-B/16网络在iWildCam和FMoW上分别提升5.1 F1和3.1% WC Acc。
- Conclusion: 直接学习输入空间知识能有效补充CLIP的冻结特征，显著提升小样本测试时领域适应性能。


### [182] [Origins of Creativity in Attention-Based Diffusion Models](https://arxiv.org/abs/2506.17324)
*Emma Finn,T. Anderson Keller,Manos Theodosis,Demba E. Ba*

Main category: cs.LG

TL;DR: 论文探讨了扩散模型中创造性的来源，特别是自注意力机制在生成全局一致图像中的作用。

- Motivation: 随着扩散模型在图像生成中的广泛应用，理解其创造性来源变得重要。现有理论未能解释自注意力机制的作用，本研究旨在填补这一空白。
- Method: 通过理论分析和实验验证，研究了CNN结合自注意力层的扩散模型，探讨其对图像生成的影响。
- Result: 理论表明自注意力机制能促进局部特征的全局一致性，实验验证了这一行为。
- Conclusion: 自注意力机制在扩散模型中起到了关键作用，推动了全局一致的图像生成。


### [183] [DRIMV_TSK: An Interpretable Surgical Evaluation Model for Incomplete Multi-View Rectal Cancer Data](https://arxiv.org/abs/2506.17552)
*Wei Zhang,Zi Wang,Hanwen Zhou,Zhaohong Deng,Weiping Ding,Yuxi Ge,Te Zhang,Yuanpeng Zhang,Kup-Sze Choi,Shitong Wang,Shudong Hu*

Main category: cs.LG

TL;DR: 本文提出了一种可解释的不完整多视图手术评估模型，结合双表示学习和TSK模糊系统，用于直肠癌手术难度的可靠评估。

- Motivation: 当前直肠癌手术难度评估主要依赖临床数据，但技术发展提供了更多数据来源，人工智能的应用成为可能。
- Method: 构建多视图直肠癌数据集，提出双表示不完整多视图学习模型，结合缺失视图填补和二阶相似性约束，并基于TSK模糊系统构建多视图手术评估模型。
- Result: 在MVRC数据集上，DRIMV_TSK模型优于其他先进算法。
- Conclusion: 该模型为直肠癌手术难度评估提供了更全面的解决方案，具有实际应用潜力。


### [184] [Decoding Federated Learning: The FedNAM+ Conformal Revolution](https://arxiv.org/abs/2506.17872)
*Sree Bhargavi Balija,Amitash Nanda,Debashis Sahoo*

Main category: cs.LG

TL;DR: FedNAM+是一个结合神经加法模型和新型保形预测方法的联邦学习框架，旨在提供可解释且可靠的预测不确定性估计。

- Motivation: 现有联邦学习框架在不确定性量化、可解释性和鲁棒性方面存在不足，FedNAM+旨在填补这一空白。
- Method: FedNAM+通过动态水平调整技术和基于梯度的敏感度图，识别影响预测的关键输入特征，实现可解释性和像素级不确定性估计。
- Result: 在CT扫描、MNIST和CIFAR数据集上验证，FedNAM+表现出高预测精度（MNIST仅0.1%损失）和透明的不确定性度量。
- Conclusion: FedNAM+为联邦学习提供了一个鲁棒、可解释且计算高效的框架，增强了分散预测建模的信任和透明度。


### [185] [Adapting Vision-Language Models for Evaluating World Models](https://arxiv.org/abs/2506.17967)
*Mariya Hendriksen,Tabish Rashid,David Bignell,Raluca Georgescu,Abdelhak Lemkhenter,Katja Hofmann,Sam Devlin,Sarah Parisot*

Main category: cs.LG

TL;DR: 论文提出了一种名为UNIVERSE的评估方法，利用视觉语言模型（VLMs）对世界模型的动态模拟进行细粒度评估，解决了现有评估指标的不足。

- Motivation: 现有评估方法无法捕捉世界模型动态模拟中的动作对齐和语义一致性，需要一种更精细、时间敏感的评估工具。
- Method: 引入UNIVERSE方法，通过适应视觉语言模型（VLMs），在数据和计算资源受限的情况下，评估动作识别和角色识别任务。
- Result: UNIVERSE在多种任务格式和条件下表现优异，与任务专用基线性能相当，且与人类评估结果高度一致。
- Conclusion: UNIVERSE是一种可扩展、语义感知的评估工具，适用于世界模型的动态模拟评估。


### [186] [h-calibration: Rethinking Classifier Recalibration with Probabilistic Error-Bounded Objective](https://arxiv.org/abs/2506.17968)
*Wenjian Huang,Guiping Cao,Jiahao Xia,Jingkun Chen,Hao Wang,Jianguo Zhang*

Main category: cs.LG

TL;DR: 本文总结了深度神经网络校准问题的三种策略，提出了一种新的概率学习框架h-calibration，解决了以往方法的十大局限性，并在实验中表现优异。

- Motivation: 深度神经网络的概率输出常存在校准不足问题，导致不可靠性。本文旨在通过新方法解决这一问题，同时保持分类性能。
- Method: 提出h-calibration框架，设计了一种简单有效的后校准算法，并通过理论和实验验证其优越性。
- Result: 新方法克服了以往十大局限性，在标准基准测试中达到最优性能。
- Conclusion: h-calibration框架为学习可靠概率提供了理论支持，并在实验中验证了其有效性，为相关领域提供了参考。


### [187] [Pitfalls of Conformal Predictions for Medical Image Classification](https://arxiv.org/abs/2506.18162)
*Hendrik Mehrtens,Tabea Bucher,Titus J. Brinker*

Main category: cs.LG

TL;DR: 本文探讨了在医学分类任务中，基于保形预测（conformal predictions）的不确定性估计方法的局限性，特别是在输入和标签变量分布变化时的不可靠性。

- Motivation: 医学分类任务需要可靠的不确定性估计方法，保形预测因其可证明的校准保证而受到关注，但其在医学等安全关键领域的应用存在潜在问题。
- Method: 通过皮肤病学和组织病理学的实例，分析了保形预测在输入和标签变量分布变化时的表现。
- Result: 保形预测在分布变化时不可靠，不适用于提高准确性的预测选择，且对数据子集（如特定类别或患者属性）不具可靠性。在类别较少的医学图像分类任务中，其实用价值有限。
- Conclusion: 保形预测在医学分类任务中存在显著局限性，需谨慎使用。


### [188] [No Training Wheels: Steering Vectors for Bias Correction at Inference Time](https://arxiv.org/abs/2506.18598)
*Aviral Gupta,Armaan Sethi,Ameesh Sethi*

Main category: cs.LG

TL;DR: 提出了一种无需重新训练的低成本方法，通过计算多数和少数群体激活均值的差异定义“偏差向量”，并在推理时减去该向量以减少分类偏差。

- Motivation: 神经网络分类器在数据分布不均时容易继承类别偏差，现有方法通常需要重新训练或高计算成本。
- Method: 通过计算多数和少数群体激活均值的差异定义“偏差向量”，并在推理时从模型的残差流中减去该向量。
- Result: 减少了分类偏差并提高了最差群体准确率。
- Conclusion: 展示了在分类模型中无需训练即可低成本缓解偏差的有效方法。
## cs.IR

### [189] [LLM-Enhanced Multimodal Fusion for Cross-Domain Sequential Recommendation](https://arxiv.org/abs/2506.17966)
*Wangyu Wu,Zhenhong Chen,Xianglin Qiu,Siqi Song,Xiaowei Huang,Fei Ma,Jimin Xiao*

Main category: cs.IR

TL;DR: LLM-EMF是一种跨域序列推荐方法，通过融合多模态数据和LLM知识提升推荐性能。

- Motivation: 解决跨域用户行为预测问题，利用多模态数据增强推荐效果。
- Method: 使用冻结的CLIP模型生成图像和文本嵌入，结合多重注意力机制学习单域和跨域偏好。
- Result: 在四个电商数据集上表现优于现有方法，验证了多模态数据整合的有效性。
- Conclusion: LLM-EMF通过多模态数据整合显著提升了跨域序列推荐的性能。
## cs.CY

### [190] [MAARTA:Multi-Agentic Adaptive Radiology Teaching Assistant](https://arxiv.org/abs/2506.17320)
*Akash Awasthi,Brandon V. Chang,Anh M. Vu,Ngan Le,Rishi Agrawal,Zhigang Deng,Carol Wu,Hien Van Nguyen*

Main category: cs.CY

TL;DR: MAARTA是一个多智能体框架，通过分析视线模式和放射学报告提供个性化反馈，帮助学生改进视觉搜索和诊断推理。

- Motivation: 放射学学生因缺乏专家指导时间而难以培养感知技能，导致视觉搜索和诊断解释错误，现有AI系统未能有效解决这些问题。
- Method: MAARTA通过动态选择智能体分析视线行为差异，使用结构化图表比较专家与学生行为，并分配感知错误教师智能体提供逐步提示。
- Result: 系统能识别遗漏发现并分析差异，帮助学生理解错误并改进诊断推理。
- Conclusion: MAARTA推动了AI驱动的放射学教育，提供了一种自适应且高效的教学辅助工具。


### [191] [AI-based Multimodal Biometrics for Detecting Smartphone Distractions: Application to Online Learning](https://arxiv.org/abs/2506.17364)
*Alvaro Becerra,Roberto Daza,Ruth Cobos,Aythami Morales,Mutlu Cukurova,Julian Fierrez*

Main category: cs.CY

TL;DR: 研究利用多模态生物特征检测在线学习中因手机使用导致的注意力分散，提出AI方法结合生理信号和头部姿态数据，多模态模型准确率达91%。

- Motivation: 在线学习中，学习者面临内部、系统和上下文因素的干扰，传统平台缺乏详细行为数据，多模态学习分析和生物传感器为注意力研究提供新视角。
- Method: 提出基于AI的方法，结合生理信号（如脑电波、心率）和头部姿态数据，检测手机使用行为。
- Result: 单一生理信号准确率有限，头部姿态数据达87%，多模态模型整合所有信号后准确率提升至91%。
- Conclusion: 多模态模型在在线学习环境中具有实时支持潜力，但需考虑部署的局限性和影响。


### [192] [Multimodal Political Bias Identification and Neutralization](https://arxiv.org/abs/2506.17372)
*Cedric Bernard,Xavier Pleimling,Amun Kharel,Chase Vickery*

Main category: cs.CY

TL;DR: 提出了一种结合文本和图像偏见的去偏见模型，通过四个步骤实现：图像文本对齐、图像偏见评分、文本去偏见和最终的去偏见替换。初步结果显示该方法有效，但需要更多训练时间和资源。

- Motivation: 政治回音室现象导致需要从政治文章的文字和图像中检测并消除主观偏见和情绪化语言，而现有研究仅关注文本部分。
- Method: 模型包含四个步骤：1) 图像文本对齐（CLIP模型），2) 图像偏见评分（ViT分类器），3) 文本去偏见（BERT模型），4) 替换为中性内容。
- Result: 文本去偏见能识别大量偏见词汇，ViT模型训练有效，语义对齐效率高，但需更多训练时间和资源。
- Conclusion: 该方法前景良好，但需进一步优化和人工评估以确保语义一致性。
## cs.RO

### [193] [A workflow for generating synthetic LiDAR datasets in simulation environments](https://arxiv.org/abs/2506.17378)
*Abhishek Phadke,Shakib Mahmud Dipto,Pratip Rana*

Main category: cs.RO

TL;DR: 本文提出了一种生成合成LiDAR数据集的仿真工作流，用于支持自动驾驶感知、机器人研究和传感器安全分析。

- Motivation: 为自动驾驶和机器人研究提供高质量、多模态的合成LiDAR数据集，并探索LiDAR数据的安全漏洞。
- Method: 利用CoppeliaSim仿真环境和Python API，集成多种传感器（LiDAR、图像传感器、二维扫描仪）于模拟车辆平台，自动化数据捕获、存储和标注。
- Result: 生成了大规模点云及同步的RGB和深度图像，验证了工作流的有效性，并展示了合成数据在评估防御策略中的应用。
- Conclusion: 该工作流为生成高保真合成LiDAR数据提供了可复现的框架，未来可进一步优化环境真实性和传感器噪声建模。


### [194] [General-Purpose Robotic Navigation via LVLM-Orchestrated Perception, Reasoning, and Acting](https://arxiv.org/abs/2506.17462)
*Bernard Lange,Anil Yildiz,Mansur Arief,Shehryar Khattak,Mykel Kochenderfer,Georgios Georgakis*

Main category: cs.RO

TL;DR: ARNA是一个基于LVLM的通用导航框架，通过自主定义任务工作流实现未知环境中的导航和推理，性能优于现有方法。

- Motivation: 现有导航系统依赖任务特定神经网络和固定数据流，泛化能力有限；LVLM提供了类似人类的知识推理能力，但现有集成方法依赖预映射空间和硬编码表示。
- Method: ARNA结合LVLM和机器人模块库，运行时自主定义任务工作流，迭代查询模块、推理多模态输入并选择导航动作。
- Result: 在HM-EQA基准测试中，ARNA实现了最先进的性能，无需手工计划或预建地图。
- Conclusion: ARNA为机器人堆栈设计提供了新视角，展示了在未知环境中导航和推理的潜力。


### [195] [EASE: Embodied Active Event Perception via Self-Supervised Energy Minimization](https://arxiv.org/abs/2506.17516)
*Zhou Chen,Sanjoy Kundu,Harsimran S. Baweja,Sathyanarayanan N. Aakur*

Main category: cs.RO

TL;DR: EASE是一个自监督框架，通过自由能最小化统一时空表示学习和具身控制，无需标注或外部奖励，实现动态事件感知。

- Motivation: 现有方法依赖预定义动作空间、标注数据集和外部奖励，限制了在动态现实场景中的适应性和可扩展性。
- Method: EASE结合生成感知模型和动作驱动控制策略，利用预测误差和熵作为内在信号，动态对齐预测与观察。
- Result: EASE在仿真和现实环境中表现出隐私保护、可扩展的事件感知能力，支持隐式记忆和目标连续性等行为。
- Conclusion: EASE为无脚本动态任务中的具身系统提供了鲁棒基础。


### [196] [RoboTwin 2.0: A Scalable Data Generator and Benchmark with Strong Domain Randomization for Robust Bimanual Robotic Manipulation](https://arxiv.org/abs/2506.18088)
*Tianxing Chen,Zanxin Chen,Baijun Chen,Zijian Cai,Yibin Liu,Qiwei Liang,Zixuan Li,Xianliang Lin,Yiheng Ge,Zhenyu Gu,Weiliang Deng,Yubin Guo,Tian Nian,Xuanbing Xie,Qiangyu Chen,Kailun Su,Tianling Xu,Guodong Liu,Mengkang Hu,Huan-ang Gao,Kaixuan Wang,Zhixuan Liang,Yusen Qin,Xiaokang Yang,Ping Luo,Yao Mu*

Main category: cs.RO

TL;DR: RoboTwin 2.0是一个可扩展的仿真框架，用于生成多样化和真实的双机械臂操作数据，通过结合多模态大语言模型和仿真优化，显著提升了代码生成成功率和现实场景泛化能力。

- Motivation: 解决现有合成数据在双机械臂操作中缺乏高效、可扩展的数据生成方法以及仿真环境过于简化的问题。
- Method: 构建大规模对象库，结合多模态大语言模型和仿真优化生成任务级执行代码，并通过结构化域随机化增强数据多样性。
- Result: 代码生成成功率提升10.9%，在未见过的现实场景任务中，微调模型相对提升367%，零样本模型相对提升228%。
- Conclusion: RoboTwin 2.0为双机械臂操作的稳健研究提供了可扩展的数据生成和评估工具。


### [197] [Radar and Event Camera Fusion for Agile Robot Ego-Motion Estimation](https://arxiv.org/abs/2506.18443)
*Yang Lyu,Zhenghao Zou,Yanfeng Li,Chunhui Zhao,Quan Pan*

Main category: cs.RO

TL;DR: 提出了一种无需IMU和特征关联的框架，结合事件相机和毫米波雷达，实现高动态场景下机器人平台的激进自我运动速度估计。

- Motivation: 解决高动态机器人运动中传感器测量模糊、失真和延迟的问题。
- Method: 使用瞬时原始事件和多普勒测量直接推导旋转和平移速度，后端采用连续时间状态空间模型融合混合测量。
- Result: 在自收集的实验数据集中验证了框架的可靠性，能够在挑战性环境中高效输出速度。
- Conclusion: 提出的框架在高动态环境中实现了可靠且高效的自我运动速度估计。


### [198] [TDACloud: Point Cloud Recognition Using Topological Data Analysis](https://arxiv.org/abs/2506.18725)
*Anirban Ghosh,Ian Dahlin,Ayan Dutta*

Main category: cs.RO

TL;DR: 论文提出了一种名为TDACloud的新方法，利用拓扑数据分析（TDA）从点云中提取局部描述符，无需GPU密集型机器学习训练，并在噪声和变换条件下表现出高识别精度。

- Motivation: 点云识别在自动驾驶、场景重建和定位等应用中具有重要意义，但提取可匹配的局部描述符具有挑战性，尤其是在噪声或变换条件下。
- Method: 使用ATOL向量化方法生成点云的固定大小TDA描述符向量，直接处理原始点云。
- Result: 在多个真实和模拟数据集上测试，TDACloud在噪声和变换条件下表现出高识别精度，优于基线方法约14%。
- Conclusion: TDACloud是一种高效的点云识别方法，适用于复杂环境，且无需资源密集型训练。


### [199] [Reproducible Evaluation of Camera Auto-Exposure Methods in the Field: Platform, Benchmark and Lessons Learned](https://arxiv.org/abs/2506.18844)
*Olivier Gamache,Jean-Michel Fortin,Matěj Boxan,François Pomerleau,Philippe Giguère*

Main category: cs.RO

TL;DR: 论文提出了一种利用模拟器生成不同曝光时间图像的方法，解决了传统自动曝光（AE）方法因依赖环境因素而难以复现的问题。基于BorealHDR数据集，该方法实现了低于1.78%的RMSE误差，并验证了经典AE方法的优越性。

- Motivation: 传统AE方法因依赖环境条件难以复现实验，标准数据集也因固定传感器参数而限制了方法比较。
- Method: 利用BorealHDR多曝光立体数据集和模拟器生成不同曝光时间的图像，离线评估AE方法。
- Result: 模拟图像与真实图像的RMSE低于1.78%，经典AE方法表现最佳。
- Conclusion: 提出的离线方法提高了实验复现性，经典AE方法仍是最优选择，数据集和代码已开源。


### [200] [GRAND-SLAM: Local Optimization for Globally Consistent Large-Scale Multi-Agent Gaussian SLAM](https://arxiv.org/abs/2506.18885)
*Annika Thomas,Aneesa Sonawalla,Alex Rose,Jonathan P. How*

Main category: cs.RO

TL;DR: GRAND-SLAM是一种多智能体高斯泼溅SLAM方法，适用于大规模户外环境，结合了局部优化和位姿图优化，显著提升了跟踪性能和渲染质量。

- Motivation: 探索多智能体高斯泼溅SLAM在大规模户外环境中的应用，解决现有方法局限于小规模室内环境的问题。
- Method: 提出GRAND-SLAM，结合局部优化的隐式跟踪模块和位姿图优化的闭环检测方法。
- Result: 在Replica数据集上PSNR提升28%，在Kimera-Multi数据集上多智能体跟踪误差降低91%，渲染质量优于现有方法。
- Conclusion: GRAND-SLAM在大规模多智能体环境中表现出色，为快速探索和重建提供了高效解决方案。
## cs.CL

### [201] [Deciphering Emotions in Children Storybooks: A Comparative Analysis of Multimodal LLMs in Educational Applications](https://arxiv.org/abs/2506.18201)
*Bushra Asseri,Estabraq Abdelaziz,Maha Al Mogren,Tayef Alhefdhi,Areej Al-Wabil*

Main category: cs.CL

TL;DR: 研究评估了GPT-4o和Gemini 1.5 Pro在阿拉伯语儿童故事书插图情感识别中的表现，发现GPT-4o优于Gemini，但两者在文化细微情感和模糊叙事情境中存在局限。

- Motivation: 开发文化敏感的阿拉伯语教育技术工具，需探索多模态AI系统在情感识别方面的能力。
- Method: 使用75张阿拉伯故事书插图，比较GPT-4o和Gemini 1.5 Pro在零样本、少样本和思维链提示策略下的表现，基于Plutchik情感框架进行人类标注对比。
- Result: GPT-4o在所有条件下表现优于Gemini，最高宏F1分数为59%（思维链提示），而Gemini为43%。模型在文化细微情感和模糊情境中表现不佳。
- Conclusion: 当前模型在文化理解上存在局限性，需开发文化敏感的训练方法以支持阿拉伯语学习者的情感感知教育技术。
## stat.ML

### [202] [DRO-Augment Framework: Robustness by Synergizing Wasserstein Distributionally Robust Optimization and Data Augmentation](https://arxiv.org/abs/2506.17874)
*Jiaming Hu,Debarghya Mukherjee,Ioannis Ch. Paschalidis*

Main category: stat.ML

TL;DR: DRO-Augment框架结合Wasserstein分布鲁棒优化与数据增强策略，显著提升深度神经网络在多种数据扰动和对抗攻击下的鲁棒性，同时保持干净数据的准确性。

- Motivation: 现有数据增强方法在同时应对数据损坏和对抗攻击时仍有改进空间，需提升模型的鲁棒性和稳定性。
- Method: 提出DRO-Augment框架，整合Wasserstein分布鲁棒优化（W-DRO）与多种数据增强策略。
- Result: 在CIFAR-10-C等基准数据集上，DRO-Augment在严重数据扰动和对抗攻击下优于现有方法，且保持干净数据准确性。
- Conclusion: DRO-Augment显著提升模型鲁棒性，并提供了理论上的泛化误差界限。
## eess.IV

### [203] [Can Common VLMs Rival Medical VLMs? Evaluation and Strategic Insights](https://arxiv.org/abs/2506.17337)
*Yuan Zhong,Ruinan Jin,Xiaoxiao Li,Qi Dou*

Main category: eess.IV

TL;DR: 研究评估了通用视觉语言模型（VLM）与医学专用VLM在医学影像任务中的表现，发现轻量级微调后通用VLM可媲美甚至超越医学专用模型。

- Motivation: 探讨通用VLM是否可以通过微调在特定医学影像任务中与医学专用VLM竞争，以降低计算和数据资源需求。
- Method: 使用基于CLIP和LLaVA的模型，评估其在疾病诊断和视觉问答（VQA）任务中的表现，包括域内（ID）和域外（OOD）任务。
- Result: 医学专用预训练在ID任务中表现更优，但通用VLM通过轻量级微调（如LoRA）可达到或超越医学专用模型；在OOD任务中，通用VLM展现出较强的适应性。
- Conclusion: 通用VLM结合微调是一种可扩展且经济高效的替代方案，挑战了医学专用预训练的必要性，为未来医学影像研究提供了重要启示。


### [204] [DSA-NRP: No-Reflow Prediction from Angiographic Perfusion Dynamics in Stroke EVT](https://arxiv.org/abs/2506.17501)
*Shreeram Athreya,Carlos Olivares,Ameera Ismail,Kambiz Nael,William Speier,Corey Arnold*

Main category: eess.IV

TL;DR: 论文提出了一种基于机器学习的框架，利用术中数字减影血管造影（DSA）序列和临床变量，预测急性缺血性卒中（AIS）患者血管内血栓切除术（EVT）后的无复流现象。

- Motivation: EVT后无复流现象（微血管低灌注）会损害组织恢复并恶化临床结果，但目前依赖术后24小时的灌注MRI检测，延迟了干预。
- Method: 研究回顾性分析了UCLA医学中心的AIS患者数据，从DSA序列中提取统计和时间灌注特征，训练机器学习分类器预测无复流。
- Result: 新方法显著优于基于临床特征的基线（AUC: 0.7703 vs. 0.5728；准确率: 0.8125 vs. 0.6331），表明DSA灌注动态能实时反映微血管完整性。
- Conclusion: 该方法为即时、准确预测无复流奠定了基础，使临床医生能主动管理高风险患者，无需依赖延迟的影像检查。


### [205] [MTSIC: Multi-stage Transformer-based GAN for Spectral Infrared Image Colorization](https://arxiv.org/abs/2506.17540)
*Tingting Liu,Yuan Liu,Jinhui Tang,Liyin Yuan,Chengyu Liu,Chunlai Li,Xiubao Sui,Qian Chen*

Main category: eess.IV

TL;DR: 提出了一种基于GAN的多波段红外图像彩色化框架，通过多阶段光谱自注意力Transformer网络（MTSIC）提升图像质量和语义准确性。

- Motivation: TIR图像缺乏颜色和纹理信息，现有方法因单波段限制导致图像失真和语义模糊，多波段红外图像提供更丰富的光谱数据。
- Method: 采用GAN框架，设计MTSIC作为生成器，结合空间-光谱注意力残差块（SARB）和多尺度小波块（MSWB）优化特征提取和语义对齐。
- Result: 实验表明，该方法显著优于传统技术，有效提升红外图像的视觉质量。
- Conclusion: 提出的MTSIC框架在多波段红外图像彩色化中表现出色，解决了语义模糊和图像失真的问题。


### [206] [LVPNet: A Latent-variable-based Prediction-driven End-to-end Framework for Lossless Compression of Medical Images](https://arxiv.org/abs/2506.17983)
*Chenyue Song,Chen Hui,Qing Lin,Wei Zhang,Siqiao Li,Shengping Zhang,Haiqi Zhu,Zhixuan Li,Shaohui Liu,Feng Jiang,Xiang Li*

Main category: eess.IV

TL;DR: LVPNet是一种基于预测的无损医学图像压缩方法，通过全局潜在变量预测像素值并编码预测概率，解决了现有方法中潜在变量信息分布不均的问题。

- Motivation: 现有方法中，图像分割导致潜在变量信息分布不均，引发后验崩溃和潜在变量利用效率低的问题。
- Method: 提出LVPNet，引入全局多尺度感知模块（GMSM）提取紧凑的潜在表示，并提出量化补偿模块（QCM）减少量化误差。
- Result: 在多个基准测试中，LVPNet的压缩效率优于现有无损图像压缩方法，同时保持推理速度。
- Conclusion: LVPNet通过全局潜在变量和量化补偿，显著提升了无损医学图像压缩的性能。


### [207] [Multimodal Medical Image Binding via Shared Text Embeddings](https://arxiv.org/abs/2506.18072)
*Yunhao Liu,Suyang Xi,Shiqi Liu,Hong Ding,Chicheng Jin,Chenxi Yang,Junjun He,Yiqing Shen*

Main category: eess.IV

TL;DR: M³Bind是一种新型预训练框架，通过共享文本表示空间实现多模态医学图像对齐，无需显式配对数据。

- Motivation: 医学图像分析需要整合多模态图像以提高诊断准确性，但现有方法需要显式配对数据，难以获取。
- Method: M³Bind通过微调CLIP-like模型对齐模态特定文本嵌入空间，并蒸馏为统一模型。
- Result: 在X光、CT等多种任务中，M³Bind在零样本、少样本分类和跨模态检索中表现最佳。
- Conclusion: M³Bind有效实现了医学图像跨模态对齐，优于现有方法。


### [208] [Transforming H&E images into IHC: A Variance-Penalized GAN for Precision Oncology](https://arxiv.org/abs/2506.18371)
*Sara Rehmat,Hafeez Ur Rehman*

Main category: eess.IV

TL;DR: 提出了一种基于深度学习的图像转换框架，从H&E染色样本生成高保真IHC图像，用于HER2评估。

- Motivation: HER2阳性乳腺癌需要精确诊断，但传统IHC方法成本高且依赖抗体选择，而H&E染色缺乏特异性。
- Method: 改进金字塔pix2pix的损失函数，引入方差惩罚以增强生成图像的结构多样性。
- Result: 模型在HER2阳性图像转换上表现优异，优于现有方法，并在通用图像转换任务中表现突出。
- Conclusion: 该模型为AI驱动的精准肿瘤学提供了高效可靠的HER2诊断替代方案。


### [209] [Taming Vision-Language Models for Medical Image Analysis: A Comprehensive Review](https://arxiv.org/abs/2506.18378)
*Haoneng Lin,Cheng Xu,Jing Qin*

Main category: eess.IV

TL;DR: 本文综述了视觉语言模型（VLMs）在医学图像分析中的适应策略、挑战及未来方向。

- Motivation: 医学领域需要多模态整合，VLMs因其跨模态语义理解能力成为潜在解决方案，但适应医学领域面临诸多挑战。
- Method: 总结了医学VLMs的核心学习策略（预训练、微调、提示学习）和五种主要适应策略，并分析了11项医学影像任务的实际应用。
- Result: 系统梳理了当前进展，指出了领域差距、病理变化复杂性和任务多样性等挑战。
- Conclusion: 文章旨在帮助研究者理解VLMs的能力与局限，推动其在临床中的创新、稳健和安全应用，并提供了开放文献库。


### [210] [A Deep Convolutional Neural Network-Based Novel Class Balancing for Imbalance Data Segmentation](https://arxiv.org/abs/2506.18474)
*Atifa Kalsoom,M. A. Iftikhar,Amjad Ali,Zubair Shah,Shidin Balakrishnan,Hazrat Ali*

Main category: eess.IV

TL;DR: 提出了一种基于深度学习和双层次类别平衡方案（BLCB-CNN）的新方法，用于视网膜血管分割，解决了数据分布不平衡和血管厚度变化的问题。

- Motivation: 视网膜血管分割在医学影像分析中具有重要意义，但数据分布不平衡和血管厚度变化导致准确分割困难。
- Method: 使用CNN架构和双层次类别平衡方案（Level-I用于血管/非血管平衡，Level-II用于厚/薄血管平衡），结合预处理技术（GCN、CLAHE、gamma校正）增强图像对比度。
- Result: 在标准数据集上表现优异，ROC曲线下面积为98.23%，准确率为96.22%，灵敏度为81.57%，特异性为97.65%。
- Conclusion: BLCB-CNN方法在视网膜血管分割中表现出高效性和泛化能力，适用于临床实践。


### [211] [Temporal Neural Cellular Automata: Application to modeling of contrast enhancement in breast MRI](https://arxiv.org/abs/2506.18720)
*Daniel M. Lang,Richard Osuala,Veronika Spieker,Karim Lekadir,Rickmer Braren,Julia A. Schnabel*

Main category: eess.IV

TL;DR: 论文提出了一种名为TeNCA的方法，用于合成对比增强图像，解决了现有方法在时间演化一致性上的不足，并在乳腺MRI数据上取得了优于现有方法的效果。

- Motivation: 乳腺MRI的长时间采集和高成本限制了其广泛应用，合成对比增强技术可以避免静脉注射对比剂的需求，但现有方法在时间演化一致性上表现不足。
- Method: 提出了TeNCA（Temporal Neural Cellular Automata），通过改进神经细胞自动机（NCA）架构和训练策略，适应稀疏和非均匀采样的时间数据，模拟生理上合理的对比增强演化。
- Result: 在乳腺MRI数据集上的实验表明，TeNCA生成的图像与真实对比增强序列更一致，性能优于现有方法。
- Conclusion: TeNCA为合成对比增强提供了一种高效且生理合理的解决方案，有望推动乳腺MRI的广泛应用。
## cs.GR

### [212] [BlenderFusion: 3D-Grounded Visual Editing and Generative Compositing](https://arxiv.org/abs/2506.17450)
*Jiacheng Chen,Ramin Mehran,Xuhui Jia,Saining Xie,Sanghyun Woo*

Main category: cs.GR

TL;DR: BlenderFusion是一个生成式视觉合成框架，通过重新组合物体、相机和背景合成新场景，采用分层-编辑-合成流程，显著优于现有方法。

- Motivation: 解决复杂场景编辑任务中现有方法的不足，提供更灵活和可控的视觉合成能力。
- Method: 采用分层-编辑-合成流程：分层将输入转换为可编辑3D实体，编辑在Blender中进行3D控制，合成通过扩展的扩散模型实现。训练策略包括源掩码和模拟物体抖动。
- Result: 在复杂场景编辑任务中显著优于现有方法。
- Conclusion: BlenderFusion为视觉合成提供了高效、灵活且可控的解决方案。


### [213] [3D Gaussian Splatting for Fine-Detailed Surface Reconstruction in Large-Scale Scene](https://arxiv.org/abs/2506.17636)
*Shihan Chen,Zhaojin Li,Zeyu Chen,Qingsong Yan,Gaoyang Shen,Ran Duan*

Main category: cs.GR

TL;DR: 论文提出了一种新方法，通过粗到细的策略和自适应场景分割，解决了大规模3D高斯重建中的计算和动态外观问题。

- Motivation: 现有3D高斯重建方法在大规模场景中面临高计算需求和动态外观的挑战，限制了其在航测和自动驾驶中的应用。
- Method: 采用粗到细策略，结合自适应场景分割、解耦外观模型和瞬态掩模模型，并扩展多视角约束和单视角正则化。
- Result: 在GauU-Scene V2数据集上表现优于现有方法，实现了高保真视觉结果和精确表面重建。
- Conclusion: 该方法有效解决了大规模场景重建的挑战，为航测和自动驾驶提供了实用解决方案。


### [214] [Collaborative Texture Filtering](https://arxiv.org/abs/2506.17770)
*Tomas Akenine-Möller,Pontus Ebelin,Matt Pharr,Bartlomiej Wronski*

Main category: cs.GR

TL;DR: 论文提出了一种利用GPU波通信内在特性避免重复纹理解压缩的新算法，显著提高了纹理放大过滤的质量和效率。

- Motivation: 现有随机纹理过滤（STF）技术在放大时可能导致视觉外观变化和噪声，尽管使用了时空去噪器。
- Method: 利用GPU波通信内在特性，在活动执行的着色器之间共享解码的纹理值，避免重复解压缩。
- Result: 在足够大的放大因子下，实现了零误差过滤（每像素≤1次纹理评估），其他情况下也提出了更高质量的过滤回退方法。
- Conclusion: 新算法显著提高了纹理放大过滤的质量和效率，优于现有方法。


### [215] [Auto-Regressive Surface Cutting](https://arxiv.org/abs/2506.18017)
*Yang Li,Victor Cheung,Xinhai Liu,Yuguang Chen,Zhongjin Luo,Biwen Lei,Haohan Weng,Zibo Zhao,Jingwei Huang,Zhuo Chen,Chunchao Guo*

Main category: cs.GR

TL;DR: SeamGPT是一种自回归模型，通过模仿专业工作流程生成切割缝，将表面切割任务转化为下一个标记预测任务，显著提升了UV展开和3D分割的性能。

- Motivation: 现有方法在表面切割中常产生技术有效但语义不连贯的碎片化图集，需要更智能的解决方案。
- Method: 将表面切割任务转化为下一个标记预测任务，使用点云采样和GPT风格变换器预测切割缝段。
- Result: 在包含流形和非流形网格的UV展开基准测试中表现优异，并为3D分割工具提供清晰边界。
- Conclusion: SeamGPT通过自回归模型和形状条件编码，显著改进了表面切割的语义连贯性和实用性。


### [216] [Morse: Dual-Sampling for Lossless Acceleration of Diffusion Models](https://arxiv.org/abs/2506.18251)
*Chao Li,Jiawei Fan,Anbang Yao*

Main category: cs.GR

TL;DR: Morse提出了一种无损加速扩散模型的双采样框架，通过跳跃采样和自适应残差反馈策略提升效率。

- Motivation: 扩散模型生成过程通常耗时，Morse旨在通过双采样框架在不损失性能的情况下加速生成。
- Method: Morse包含Dash和Dot两个模型：Dash进行跳跃采样，Dot生成残差反馈以匹配Dash的下一步估计。两者通过时间交错运行提升效率。
- Result: 实验显示Morse在6个图像生成任务上平均加速1.78X至3.31X，且可推广至Latent Consistency Model。
- Conclusion: Morse通过双采样框架实现了无损加速，适用于多种扩散模型和任务。


### [217] [What You Think Is What You Get: Bridge User Intent and Transfer Function Design through Multimodal Large Language Models](https://arxiv.org/abs/2506.18407)
*Yiyao Wang,Bo Pan,Ke Wang,Han Liu,Jinyuan Mao,Yuxin Liu,Minfeng Zhu,Bo Zhang,Weifeng Chen,Xiuqi Huang,Wei Chen*

Main category: cs.GR

TL;DR: 论文提出了一种名为WYTWYG的框架，利用多模态大语言模型（MLLMs）指导基于用户意图的传递函数（TF）优化，解决了现有方法在探索空间大和泛化能力弱方面的挑战。

- Motivation: 传递函数（TFs）在直接体积渲染（DVR）中至关重要，但设计有效的TFs仍不直观，存在用户意图与TF参数空间之间的语义鸿沟。
- Method: 提出WYTWYG框架，包含基于进化的TF空间探索器和基于MLLMs的体积渲染质量评估器，并开发了交互式TF设计系统。
- Result: 通过三个案例研究展示了框架的通用性，并通过实验验证了各组件的有效性。
- Conclusion: WYTWYG框架显著提升了TF优化的效率和泛化能力，为DVR提供了更直观的设计工具。


### [218] [BulletGen: Improving 4D Reconstruction with Bullet-Time Generation](https://arxiv.org/abs/2506.18601)
*Denys Rozumnyi,Jonathon Luiten,Numair Khan,Johannes Schönberger,Peter Kontschieder*

Main category: cs.GR

TL;DR: BulletGen利用生成模型修正高斯动态场景表示中的错误和缺失信息，通过扩散模型生成帧监督4D高斯模型优化，实现新视角合成和2D/3D跟踪任务的最优结果。

- Motivation: 解决单目视频动态场景重建中未观测区域和深度估计模糊的挑战。
- Method: 结合生成模型（扩散模型）与4D高斯动态场景表示，生成帧用于监督优化。
- Result: 在新视角合成和2D/3D跟踪任务中达到最优性能。
- Conclusion: BulletGen成功将生成内容与动态场景融合，显著提升重建质量。


### [219] [DuetGen: Music Driven Two-Person Dance Generation via Hierarchical Masked Modeling](https://arxiv.org/abs/2506.18680)
*Anindita Ghosh,Bing Zhou,Rishabh Dabral,Jian Wang,Vladislav Golyanik,Christian Theobalt,Philipp Slusallek,Chuan Guo*

Main category: cs.GR

TL;DR: DuetGen是一个新颖的框架，用于从音乐生成交互式双人舞蹈，通过两阶段方法（编码和生成）实现同步和互动。

- Motivation: 双人舞蹈的同步和互动复杂性是主要挑战，需要解决舞伴之间以及与音乐的协调问题。
- Method: 采用两阶段方法：1) 使用VQ-VAE将双人动作编码为离散令牌；2) 使用生成式掩码变换器从音乐生成这些令牌。
- Result: DuetGen在动作真实性、音乐舞蹈对齐和舞伴协调方面表现出色，用户研究和实验验证了其先进性能。
- Conclusion: DuetGen通过分层掩码建模和专用交互表示，成功生成了同步且互动的双人舞蹈，适用于多种音乐风格。
## cs.SD

### [220] [TCDiff++: An End-to-end Trajectory-Controllable Diffusion Model for Harmonious Music-Driven Group Choreography](https://arxiv.org/abs/2506.18671)
*Yuqin Dai,Wanlu Zhu,Ronghui Li,Xiu Li,Zhenyu Zhang,Jun Li,Jian Yang*

Main category: cs.SD

TL;DR: TCDiff++是一个音乐驱动的端到端框架，用于生成和谐的群舞，解决了多舞者碰撞、单舞者脚滑动和长群舞生成中的突然交换问题。

- Motivation: 群舞生成在工业应用中具有广泛需求，但现有方法在多舞者碰撞、单舞者脚滑动和长群舞生成中的突然交换问题上表现不佳。
- Method: TCDiff++采用舞者定位嵌入、距离一致性损失、交换模式嵌入、Footwork Adaptor、长群扩散采样策略和序列解码器层等技术。
- Result: 实验表明，TCDiff++在长时场景中表现优异，实现了高质量和连贯的群舞生成。
- Conclusion: TCDiff++通过创新方法解决了群舞生成中的关键问题，显著提升了生成质量。
## cs.AI

### [221] [Chain-of-Memory: Enhancing GUI Agents for Cross-Application Navigation](https://arxiv.org/abs/2506.18158)
*Xinzge Gao,Chuanrui Hu,Bin Chen,Teng Li*

Main category: cs.AI

TL;DR: 提出了一种名为Chain-of-Memory (CoM)的新方法，通过显式建模短期和长期记忆，提升GUI代理在跨应用任务中的性能。

- Motivation: 现有方法依赖历史截图或动作隐式表示任务状态，导致GUI代理难以准确理解任务状态，且缺乏存储关键信息的机制。
- Method: CoM通过捕获动作描述、整合任务相关屏幕信息，并维护专用内存模块来存储和管理信息。
- Result: 实验表明，CoM显著提升了GUI代理在跨应用任务中的性能，且7B模型可实现与72B模型相当的内存管理能力。
- Conclusion: CoM为GUI代理提供了显式记忆表示，解决了复杂任务中的信息存储问题，并开源了数据集和代码。


### [222] [ConciseHint: Boosting Efficient Reasoning via Continuous Concise Hints during Generation](https://arxiv.org/abs/2506.18810)
*Siao Tang,Xinyin Ma,Gongfan Fang,Xinchao Wang*

Main category: cs.AI

TL;DR: 论文提出ConciseHint框架，通过生成过程中注入提示，减少大型推理模型的冗余输出，同时保持性能。

- Motivation: 现有大型推理模型在复杂任务中表现优异，但推理过程冗长低效，现有方法未解决生成过程中的简洁性问题。
- Method: 提出ConciseHint框架，在推理生成过程中动态注入提示（手动设计或基于简洁数据训练），自适应调整提示强度。
- Result: 在DeepSeek-R1和Qwen-3等模型上验证，推理长度减少65%（GSM8K基准），几乎无精度损失。
- Conclusion: ConciseHint能有效生成简洁推理过程，且不影响模型性能，填补了现有方法的空白。
