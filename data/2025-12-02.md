[[toc]]

## cs.CV

### [1] [MOTION: ML-Assisted On-Device Low-Latency Motion Recognition](https://arxiv.org/abs/2512.00008)
*Veeramani Pugazhenthi,Wei-Hsiang Chu,Junwei Lu,Jadyn N. Miyahira,Soheil Salehi*

Main category: cs.CV

TL;DR: 该研究提出了一种基于三轴加速度计的高效手势识别方法，利用AutoML管道提取关键特征并训练轻量级机器学习模型，在WeBe Band可穿戴设备上实现实时手势识别。

- Motivation: 在医疗监测领域（如跌倒检测、康复跟踪、患者监护）需要低延迟、高效的手势识别解决方案，避免误报，同时满足嵌入式设备的资源限制。
- Method: 使用三轴加速度计传感器数据，通过AutoML管道自动提取最重要的特征，然后训练多个轻量级机器学习算法，在WeBe Band多传感器可穿戴设备的MCU上实现完全设备端的手势识别。
- Result: 在探索的模型中，神经网络在准确性、延迟和内存使用之间提供了最佳平衡。研究证明WeBe Band能够实现可靠的实时手势识别，为需要安全快速响应的实时医疗监测解决方案提供了巨大潜力。
- Conclusion: 该研究展示了仅使用三轴加速度计传感器构建高效运动识别模型的可行性，通过AutoML特征提取和轻量级机器学习算法，在资源受限的可穿戴设备上实现了实时手势识别，为医疗监测应用提供了实用解决方案。


### [2] [Closing the Gap: Data-Centric Fine-Tuning of Vision Language Models for the Standardized Exam Questions](https://arxiv.org/abs/2512.00042)
*Egemen Sert,Şeyda Ertekin*

Main category: cs.CV

TL;DR: 通过高质量多模态数据集的监督微调，Qwen-2.5VL-32B模型在标准化考试基准上达到接近最先进性能，仅比Gemini 2.0 Flash低1.0%

- Motivation: 当前多模态推理研究主要关注算法改进（如强化学习），而数据中心的视觉语言推理基础研究不足。标准化考试问题提供了结构化视觉上下文和可验证答案的严格测试平台。
- Method: 构建包含1.614亿token的多模态数据集（教科书问题-解决方案对、课程对齐图表、上下文材料），使用优化的推理语法（QMSA）对Qwen-2.5VL-32B模型进行监督微调。
- Result: 微调后的模型在新发布的YKSUniform基准（包含1,854个多模态考试问题，覆盖309个课程主题）上达到78.6%准确率，仅比Gemini 2.0 Flash低1.0%。
- Conclusion: 数据组成和表示语法在多模态推理中起决定性作用。精心策划的课程基础多模态数据可以将监督微调提升到接近最先进性能，为开放权重视觉语言模型建立了数据中心框架。


### [3] [PEFT-DML: Parameter-Efficient Fine-Tuning Deep Metric Learning for Robust Multi-Modal 3D Object Detection in Autonomous Driving](https://arxiv.org/abs/2512.00060)
*Abdolazim Rezaei,Mehdi Sookhak*

Main category: cs.CV

TL;DR: PEFT-DML是一个参数高效的深度度量学习框架，用于自动驾驶中的鲁棒多模态3D目标检测，能够在传感器丢失或未知模态组合下保持可靠性能。

- Motivation: 传统多模态3D检测模型通常假设传感器固定可用，但在实际自动驾驶场景中，传感器可能丢失或出现未知组合，需要更鲁棒的检测方案。
- Method: 将多种模态（LiDAR、雷达、相机、IMU、GNSS）映射到共享潜在空间，集成LoRA和适配器层实现参数高效学习，增强对快速运动、天气变化和域偏移的鲁棒性。
- Result: 在nuScenes基准测试中展现出优越的检测精度，同时实现了显著的训练效率提升。
- Conclusion: PEFT-DML为自动驾驶中的多模态3D目标检测提供了参数高效且鲁棒的解决方案，能够应对实际场景中的传感器不确定性和环境变化。


### [4] [DL-CapsNet: A Deep and Light Capsule Network](https://arxiv.org/abs/2512.00061)
*Pouya Shiri,Amirali Baniasadi*

Main category: cs.CV

TL;DR: 提出DL-CapsNet：一种深度胶囊网络变体，通过胶囊总结层减少参数复杂度，实现高精度、快速训练和推理

- Motivation: CapsNet作为CNN的潜在替代者，在检测重叠类别和仿射变换图像方面更准确，但需要改进其深度架构和参数效率
- Method: 提出深度胶囊网络变体（DL-CapsNet），包含多个胶囊层，并设计胶囊总结层来减少参数数量
- Result: DL-CapsNet在保持高精度的同时，使用较少参数，实现更快的训练和推理速度，能处理类别数量多的复杂数据集
- Conclusion: DL-CapsNet通过深度架构和参数优化，为胶囊网络的实际应用提供了更高效、可扩展的解决方案


### [5] [Satellite to Street : Disaster Impact Estimator](https://arxiv.org/abs/2512.00065)
*Sreesritha Sai,Sai Venkata Suma Sreeja,Deepthi,Nikhil*

Main category: cs.CV

TL;DR: 提出Satellite-to-Street框架，通过改进的双输入U-Net架构和类别感知加权损失函数，从卫星图像中实现细粒度像素级灾害损害评估，相比传统方法能更好地检测高度损坏区域。

- Motivation: 传统人工卫星图像解释速度慢、主观性强且难以扩展，而现有的深度学习分割模型（如U-Net）和变化检测模型在处理细微结构变化和严重类别不平衡时表现不佳，特别是对高度损坏区域的检测效果差。
- Method: 提出Satellite-to-Street灾害影响评估器，采用改进的双输入U-Net架构，增强特征融合以捕捉局部结构变化和更广泛的上下文线索，并集成类别感知加权损失函数来处理灾害数据集中未损坏像素占主导的问题。
- Result: 在公开可用的灾害数据集上实验表明，相比传统分割和基线变化检测模型，该方法在结构损害的定位和分类方面有显著改进，能生成更准确的像素级损害地图。
- Conclusion: 该框架提供了一种快速、一致的评估机制，旨在支持而非替代专家决策，从而实现更高效、数据驱动的灾害管理。


### [6] [ProvRain: Rain-Adaptive Denoising and Vehicle Detection via MobileNet-UNet and Faster R-CNN](https://arxiv.org/abs/2512.00073)
*Aswinkumar Varathakumaran,Nirmala Paramanandham*

Main category: cs.CV

TL;DR: ProvRain：一种用于夜间雨天车辆预检测的轻量级MobileNet-U-Net去噪管道，通过课程训练提升恶劣天气下的检测性能

- Motivation: 夜间车辆预检测（通过车灯等特征提前检测车辆）在雨雪等恶劣天气下受噪声影响严重，需要解决噪声问题同时保持检测精度
- Method: 提出ProvRain管道，采用轻量级MobileNet-U-Net架构，通过课程训练概念增强对恶劣天气的泛化能力，使用合成数据和PVDN数据集混合训练
- Result: 相比基于PVDN训练的Faster RCNN，在雨天夜间帧中车辆检测准确率提升8.94%，召回率提升10.25%；去噪网络PSNR提升10-15%，SSIM提升5-6%，感知误差降低67%
- Conclusion: ProvRain管道有效解决了夜间雨天车辆检测中的噪声问题，显著提升了检测性能，为恶劣天气下的车辆预检测提供了实用解决方案


### [7] [Adapter Shield: A Unified Framework with Built-in Authentication for Preventing Unauthorized Zero-Shot Image-to-Image Generation](https://arxiv.org/abs/2512.00075)
*Jun Jia,Hongyi Miao,Yingjie Zhou,Wangqiu Zhou,Jianbo Zhang,Linhan Cao,Dandan Zhu,Hua Yang,Xiongkuo Min,Wei Sun,Guangtao Zhai*

Main category: cs.CV

TL;DR: 提出Adapter Shield，首个通用且集成认证的防御方案，保护个人图像免遭零样本生成场景的滥用，通过可逆加密和对抗扰动实现授权访问控制

- Motivation: 随着扩散模型的快速发展，零样本图像到图像生成技术能够在无需修改模型权重的情况下，仅用一张肖像或艺术品就能实现高保真的人脸身份或艺术风格复制。虽然这些技术显著增强了创作可能性，但也带来了与知识产权侵权相关的重大风险，包括未经授权的身份克隆和风格模仿。
- Method: 首先研究当前零样本方法如何使用图像编码器从输入图像中提取嵌入，这些嵌入随后通过交叉注意力层输入到扩散模型的UNet中。受此机制启发，构建一个可逆加密系统，根据不同的密钥将原始嵌入映射到不同的加密表示。授权用户可以通过解密模块和正确密钥恢复真实嵌入，实现授权生成任务的正常使用。为保护目的，设计了一种多目标对抗扰动方法，主动将原始嵌入向指定的加密模式偏移，从而为受保护图像嵌入防御层，确保未经授权的用户只能产生扭曲或加密的输出。
- Result: 广泛的评估表明，该方法在阻止未经授权的零样本图像合成方面超越了现有的最先进防御方法，同时支持灵活且安全的验证用户访问控制。
- Conclusion: 提出了Adapter Shield，这是首个通用且集成认证的解决方案，旨在保护个人图像在零样本生成场景中免遭滥用，通过可逆加密和对抗扰动机制实现了有效的访问控制，平衡了创意使用和知识产权保护的需求。


### [8] [Diffusion-Based Synthetic Brightfield Microscopy Images for Enhanced Single Cell Detection](https://arxiv.org/abs/2512.00078)
*Mario de Jesus da Graca,Jörg Dahlkemper,Peer Stelldinger*

Main category: cs.CV

TL;DR: 使用无条件扩散模型生成合成明场显微镜图像，用于增强细胞检测模型的训练数据，减少对大量手动标注的依赖

- Motivation: 明场显微镜中的准确单细胞检测对生物学研究至关重要，但数据稀缺和标注瓶颈限制了深度学习方法的发展
- Method: 使用基于U-Net的扩散模型生成合成明场显微镜图像，创建不同比例的合成与真实图像混合数据集，并用YOLOv8、YOLOv9和RT-DETR进行实验评估
- Result: 使用合成数据训练可以提高检测准确率（成本最低），人类专家调查显示生成图像具有高度真实感（区分准确率50%），无法区分合成与真实图像
- Conclusion: 基于扩散的合成数据生成是增强显微镜图像分析中真实数据集的有前景方法，减少对大量手动标注的依赖，并可能提高细胞检测模型的鲁棒性


### [9] [Conceptual Evaluation of Deep Visual Stereo Odometry for the MARWIN Radiation Monitoring Robot in Accelerator Tunnels](https://arxiv.org/abs/2512.00080)
*André Dehne,Juri Zach,Peer Stelldinger*

Main category: cs.CV

TL;DR: MARWIN机器人采用深度视觉立体里程计（DVSO）替代现有导航方案，以提升在加速器隧道中的自主导航能力

- Motivation: 现有导航方案（激光雷达边缘检测+轮式/激光雷达里程计+QR码参考）在预定义区域表现稳健，但缺乏对未知几何结构和障碍物的灵活性
- Method: 采用深度视觉立体里程计（DVSO），利用立体视差、光流和自监督学习联合估计深度和自我运动，无需标记数据
- Result: 概念性评估显示DVSO在加速器隧道环境中具有潜力，预期优势包括：通过立体视觉减少尺度漂移、低成本传感、可扩展数据收集
- Conclusion: DVSO为MARWIN在受限、安全关键基础设施中实现更自主导航提供了研究方向，但仍需解决低纹理表面、光照变化、计算负载和辐射鲁棒性等挑战


### [10] [Exploring Diagnostic Prompting Approach for Multimodal LLM-based Visual Complexity Assessment: A Case Study of Amazon Search Result Pages](https://arxiv.org/abs/2512.00082)
*Divendar Murtadak,Yoon Kim,Trilokya Akula*

Main category: cs.CV

TL;DR: 诊断提示法能提升多模态大语言模型评估亚马逊搜索结果页视觉复杂度的可靠性，但绝对性能仍有限

- Motivation: 研究诊断提示法是否能改善多模态大语言模型在评估亚马逊搜索结果页视觉复杂度方面的可靠性，探索更接近人类判断的评估方法
- Method: 比较诊断提示法与基于格式塔原理的标准提示法，使用200个亚马逊搜索结果页和人类专家标注数据，通过决策树分析模型推理模式
- Result: 诊断提示法显著提升了预测人类复杂度判断的能力，F1分数从0.031提升到0.297（相对提升858%），但绝对性能仍有限（Cohen's κ = 0.071）。模型更关注视觉设计元素（徽章杂乱度占38.6%重要性），而人类更强调内容相似性
- Conclusion: 诊断提示法是实现人类对齐的多模态大语言模型评估的有希望的第一步，但在产品相似性和颜色强度评估方面仍存在挑战，需要更大的标注数据集和提示方法改进才能实现可靠的实际部署


### [11] [A Fast and Efficient Modern BERT based Text-Conditioned Diffusion Model for Medical Image Segmentation](https://arxiv.org/abs/2512.00084)
*Venkata Siddharth Dhara,Pawan Kumar*

Main category: cs.CV

TL;DR: FastTextDiff是一种基于扩散模型的标签高效医学图像分割方法，通过整合医学文本标注来增强语义表示，使用ModernBERT替代Clinical BioBERT，提高了分割精度和训练效率。

- Motivation: 医学图像分割通常需要密集的像素级标注，这些标注昂贵、耗时且需要专业知识。现有的扩散模型在医学图像生成和去噪方面有效，但在分割任务中受到标注限制。
- Method: 提出FastTextDiff模型，整合医学文本标注来增强语义表示。使用ModernBERT处理长临床笔记，将文本标注与医学图像的语义内容紧密连接。通过跨模态注意力机制在视觉和文本特征之间建立联系。
- Result: 在MIMIC-III和MIMIC-IV数据集上训练，ModernBERT编码临床知识并指导跨模态注意力。相比传统扩散模型，FastTextDiff提高了分割精度和训练效率，ModernBERT成为Clinical BioBERT的快速、可扩展替代方案。
- Conclusion: FastTextDiff展示了多模态技术在医学图像分析中的潜力，通过整合文本标注实现了标签高效的分割，ModernBERT在扩散分割流程中表现出色，为医学图像分析提供了新方向。


### [12] [Multi-modal On-Device Learning for Monocular Depth Estimation on Ultra-low-power MCUs](https://arxiv.org/abs/2512.00086)
*Davide Nadalini,Manuele Rusci,Elia Cereda,Luca Benini,Francesco Conti,Daniele Palossi*

Main category: cs.CV

TL;DR: 提出了一种用于超低功耗物联网平台的多模态设备端学习技术，通过稀疏更新方案在MCU上实现单目深度估计模型的自适应微调，显著降低部署误差。

- Motivation: 物联网平台上的单目深度估计模型参数有限，当现场传感器数据与训练数据集存在显著域偏移时，会导致严重的精度下降。需要解决设备端域偏移问题，同时保持低功耗特性。
- Method: 1) 在物联网设备上部署包含107k参数的μPyD-Net模型进行单目图像推理；2) 通常关闭深度传感器以节能，仅在新环境中激活深度传感器收集伪标签；3) 提出内存驱动的稀疏更新方案，将微调内存降至1.2MB；4) 完全在MCU上执行设备端训练。
- Result: 1) 微调内存减少2.2倍（1.2MB vs 完整更新）；2) 在KITTI和NYUv2数据集上精度仅下降2%和1.5%；3) 现场测试中，设备端学习仅需17.8分钟，使用3k自标记样本将均方根误差从4.9m降至0.6m。
- Conclusion: 首次在物联网节点上实现了单目深度估计的设备端学习，通过多模态伪标签收集和内存优化稀疏更新方案，有效解决了域偏移问题，同时保持了超低功耗特性。


### [13] [Exploring Automated Recognition of Instructional Activity and Discourse from Multimodal Classroom Data](https://arxiv.org/abs/2512.00087)
*Ivo Bueno,Ruikun Hou,Babette Bühler,Tim Fütterer,James Drimalla,Jonathan Kyle Foster,Peter Youngs,Peter Gerjets,Ulrich Trautwein,Enkelejda Kasneci*

Main category: cs.CV

TL;DR: AI驱动的课堂多模态分析系统，通过视频和文本并行处理，实现对教学活动和话语的自动识别，为教师提供可扩展的反馈。

- Motivation: 传统课堂观察依赖人工标注，资源密集且难以规模化。需要开发自动化系统来分析课堂录像，为教师提供可扩展的反馈。
- Method: 使用164小时视频和68节课程转录的密集标注数据集，设计并行模态特定管道：视频方面评估零样本多模态LLM、微调视觉语言模型和自监督视频Transformer（24个活动标签）；文本方面微调基于Transformer的分类器并与基于提示的LLM比较（19个话语标签）。采用标签特定阈值、上下文窗口和不平衡感知损失函数处理类别不平衡和多标签复杂性。
- Result: 微调模型在视频分析上达到0.577的宏F1分数，在转录分析上达到0.460的宏F1分数，始终优于基于提示的方法，证明了自动化课堂分析的可行性。
- Conclusion: 研究展示了AI驱动课堂分析的可行性，为可扩展的教师反馈系统奠定了基础。微调方法比提示方法更有效，但仍有改进空间。


### [14] [SemImage: Semantic Image Representation for Text, a Novel Framework for Embedding Disentangled Linguistic Features](https://arxiv.org/abs/2512.00088)
*Mohammad Zare*

Main category: cs.CV

TL;DR: SemImage将文本文档表示为二维语义图像，每个单词作为像素，使用HSV颜色空间编码不同语言特征（主题、情感、强度），通过CNN处理实现文档分类

- Motivation: 传统文本分类方法（如BERT）缺乏直观的可解释性，无法将语言特征可视化。作者希望创建一种既能保持分类性能又能提供视觉可解释性的文档表示方法
- Method: 1. 将文档转换为二维语义图像：行对应句子，插入边界行标记语义转换；2. 每个单词作为像素，在解耦的HSV颜色空间中编码：色调编码主题（考虑循环性），饱和度编码情感，明度编码强度；3. 通过多任务学习框架强制解耦：ColorMapper网络将词嵌入映射到HSV空间，辅助监督应用于色调和饱和度通道预测主题和情感标签；4. 使用标准2D CNN（如ResNet）进行分类
- Result: 在多标签数据集（同时有主题和情感标注）和单标签基准测试中，SemImage能够达到或超过BERT和分层注意力网络等强基线方法的准确率，同时提供更好的可解释性。消融研究证实了多通道HSV表示和动态边界行的重要性
- Conclusion: SemImage提供了一种新颖的文档表示方法，将语言特征编码为视觉可解释的语义图像，在保持竞争力的分类性能的同时，实现了主题转换和情感变化的可视化，为人类和机器都提供了直观的理解方式


### [15] [TeleViT1.0: Teleconnection-aware Vision Transformers for Subseasonal to Seasonal Wildfire Pattern Forecasts](https://arxiv.org/abs/2512.00089)
*Ioannis Prapas,Nikolaos Papadopoulos,Nikolaos-Ioannis Bountos,Dimitrios Michail,Gustau Camps-Valls,Ioannis Papoutsis*

Main category: cs.CV

TL;DR: TeleViT是一个融合局部火灾驱动因素、全球场和遥相关指数的多尺度Vision Transformer模型，用于提前数周至数月预测野火，在4个月预测期内显著优于现有方法。

- Motivation: 提前数周至数月预测野火对于燃料处理和资源分配至关重要，但长期预测需要考虑地球系统的相互关联性，包括全球模式和遥相关现象。
- Method: 提出TeleViT模型，采用非对称标记化策略将(i)细尺度局部火灾驱动因素、(ii)粗化全球场和(iii)遥相关指数融合为异质标记，通过Transformer编码器联合处理，解码器保持空间结构将局部标记映射到预测区域。
- Result: 使用SeasFire数据集(2001-2021，8天分辨率)，TeleViT在所有预测时间（包括长达4个月）的AUPRC性能均优于U-Net++、ViT和气候学基准。在零延迟时AUPRC达0.630，4个月延迟时仍保持0.601-0.603，显著超过基准方法。
- Conclusion: 明确编码大尺度地球系统上下文的架构可以扩展野火在次季节到季节时间尺度上的可预测性，预测主要依赖局部标记，全球场和指数提供粗尺度上下文信息。


### [16] [Deep Filament Extraction for 3D Concrete Printing](https://arxiv.org/abs/2512.00091)
*Karam Mawas,Mehdi Maboudi,Pedro Achanccaray,Markus Gerke*

Main category: cs.CV

TL;DR: 提出一种用于挤出式和喷射式3D混凝土打印的自动化丝状体质量控制方法，适用于多种传感器和材料状态

- Motivation: 3D混凝土打印中丝状体几何质量对打印结构至关重要，需要自动化质量控制方法来确保打印质量
- Method: 开发独立于传感器的自动化质量控制工作流程，适用于相机、结构光系统或地面激光扫描仪等多种数据采集设备，可用于新鲜或固化状态的材料
- Result: 提出了一种可用于在线和打印后质量控制的自动化程序，能够适应不同的3D混凝土打印技术和传感器类型
- Conclusion: 该方法为3D混凝土打印提供了灵活、自动化的质量控制解决方案，有助于提高建筑行业的可持续性和效率


### [17] [Comparative Analysis of Vision Transformer, Convolutional, and Hybrid Architectures for Mental Health Classification Using Actigraphy-Derived Images](https://arxiv.org/abs/2512.00103)
*Ifeanyi Okala*

Main category: cs.CV

TL;DR: 比较VGG16、ViT-B/16和CoAtNet-Tiny三种图像模型在基于活动记录图像识别抑郁、精神分裂和健康对照的表现，发现CoAtNet-Tiny最稳定可靠。

- Motivation: 研究不同图像识别方法在基于日常活动记录图像进行心理健康状态识别（抑郁、精神分裂、健康对照）的性能差异，探索最适合这类任务的模型架构。
- Method: 使用Psykose和Depresjon数据集的手腕活动信号，转换为30×48像素的图像；采用三折受试者分层交叉验证评估VGG16、ViT-B/16和CoAtNet-Tiny三种模型。
- Result: CoAtNet-Tiny表现最佳，平均准确率最高且最稳定，在抑郁和精神分裂等少数类别的精确率、召回率和F1分数也最强；VGG16训练稳定但最终准确率较低；ViT-B/16在某些折中表现好但稳定性差。
- Conclusion: CoAtNet-Tiny在活动记录图像的心理健康识别任务中表现最一致可靠，表明某些混合架构设计特别适合基于活动记录图像的心理健康研究。


### [18] [TinyViT: Field Deployable Transformer Pipeline for Solar Panel Surface Fault and Severity Screening](https://arxiv.org/abs/2512.00117)
*Ishwaryah Pandiarajan,Mohamed Mansoor Roomi Sindha,Uma Maheswari Pandyan,Sharafia N*

Main category: cs.CV

TL;DR: 提出TinyViT系统，仅使用可见光图像就能对太阳能光伏板进行表面故障分类和严重程度评估，无需依赖昂贵的多模态成像设备。

- Motivation: 太阳能光伏资产的大规模运维需要准确检测表面故障，但传统的多模态成像方法存在物流和经济障碍，限制了在资源有限场景下的常规部署。
- Method: 开发了TinyViT紧凑型管道，整合了基于Transformer的分割、光谱空间特征工程和集成回归，仅使用消费级彩色相机拍摄的平面可见光图像。
- Result: 在真实公共数据集上验证了分类和回归子模块，能够准确分类七种细微表面故障并生成可操作的严重程度等级，性能与专用方法相当。
- Conclusion: 该方法消除了对电致发光或红外传感器的依赖，为资源有限的安装提供了经济实惠、可扩展的维护方案，推动了太阳能健康监测向普遍现场可访问性发展。


### [19] [Hybrid Synthetic Data Generation with Domain Randomization Enables Zero-Shot Vision-Based Part Inspection Under Extreme Class Imbalance](https://arxiv.org/abs/2512.00125)
*Ruo-Syuan Mei,Sixian Jia,Guangze Li,Soo Yeon Lee,Brian Musser,William Keller,Sreten Zakula,Jorge Arinez,Chenhui Shao*

Main category: cs.CV

TL;DR: 提出混合合成数据生成框架，结合仿真渲染、领域随机化和真实背景合成，实现零样本学习的工业零件视觉检测，无需人工标注

- Motivation: 工业质量检测中，深度学习需要大量高质量标注数据，但缺陷样本稀少导致类别不平衡，且标注成本高昂，限制了机器学习在真实生产环境中的应用
- Method: 混合SDG框架：集成仿真渲染、领域随机化和真实背景合成，1小时生成12,960张标注图像；使用YOLOv8n进行目标检测和MobileNetV3-small进行质量分类的两阶段架构
- Result: 在300个真实工业零件上评估：检测mAP@0.5达0.995，分类准确率96%，平衡准确率90.1%；相比少样本真实数据基线方法（仅50%准确率）有显著提升
- Conclusion: 提出的SDG方法实现了无需标注、可扩展且鲁棒的工业质量检测，在严重类别不平衡下仍能达到90-91%的平衡准确率，适用于实际制造应用


### [20] [Analysis of Incursive Breast Cancer in Mammograms Using YOLO, Explainability, and Domain Adaptation](https://arxiv.org/abs/2512.00129)
*Jayan Adhikari,Prativa Joshi,Susish Baral*

Main category: cs.CV

TL;DR: 该研究提出了一种结合ResNet50 OOD过滤与YOLO架构的乳腺癌检测系统，通过严格拒绝非乳腺X光图像来提升系统在分布外数据上的可靠性。

- Motivation: 深度学习乳腺癌检测模型在面对分布外输入（如其他成像模态或设备变化）时存在可靠性问题，导致检测不可靠和误诊，需要解决这一根本问题。
- Method: 采用综合方法：1) 使用ResNet50基于余弦相似度建立域内图库，严格拒绝非乳腺X光图像；2) 结合YOLO架构（YOLOv8、YOLOv11、YOLOv12）进行准确检测；3) 通过Grad-CAM可视化增强可解释性。
- Result: OOD检测组件达到99.77%的总体准确率，在OOD测试集上实现100%准确率；联合框架检测性能mAP@0.5为0.947；系统可靠性显著提升，有效防止分布外输入的误报。
- Conclusion: 该研究为在数据异质性临床环境中部署可靠的AI乳腺癌检测系统提供了基础，通过OOD过滤确保系统仅处理域内图像，同时保持高检测精度。


### [21] [Local and Global Context-and-Object-part-Aware Superpixel-based Data Augmentation for Deep Visual Recognition](https://arxiv.org/abs/2512.00130)
*Fadi Dornaika,Danyang Sun*

Main category: cs.CV

TL;DR: LGCOAMix提出了一种基于超像素的网格混合数据增强方法，通过超像素注意力策略学习局部特征，解决了传统CutMix方法在局部上下文关注不足和对象部分信息丢失的问题。

- Motivation: 现有CutMix方法主要关注全局语义，过度减少对类别判别性局部上下文的关注，导致性能提升瓶颈；同时矩形切割会丢失对象部分信息，且现有方法需要双重前向传播或依赖预训练网络进行对象居中，效率低下。
- Method: 提出LGCOAMix：基于超像素的网格混合方法，使用超像素注意力策略进行标签混合，从判别性超像素区域和跨图像超像素对比中学习局部特征。
- Result: 在各种基准数据集上的实验表明，LGCOAMix在分类任务上优于最先进的CutMix数据增强方法，并在CUB200-2011上实现了弱监督对象定位，对CNN和Transformer网络都有效。
- Conclusion: LGCOAMix通过超像素注意力策略有效解决了传统CutMix方法的局限性，实现了更高效、更精确的数据增强，在多种任务和网络架构上都表现出优越性能。


### [22] [Efficient Edge-Compatible CNN for Speckle-Based Material Recognition in Laser Cutting Systems](https://arxiv.org/abs/2512.00179)
*Mohamed Abdallah Salem,Nourhan Zein Diab*

Main category: cs.CV

TL;DR: 提出轻量级CNN用于激光散斑材料识别，在59类材料上达到95.05%准确率，参数量仅341k，比ResNet-50少70倍，可在边缘设备部署。

- Motivation: 准确的材料识别对激光切割安全至关重要，现有散斑传感方法要么计算成本高，要么只能识别有限材料类别。
- Method: 设计专门针对散斑模式的轻量级卷积神经网络，最小化参数数量同时保持高判别能力，使用完整的SensiCut数据集（59类材料）。
- Result: 在59类材料上达到95.05%测试准确率，F1分数0.951；参数量仅341k（约1.3MB），推理速度295图像/秒；材料分组后召回率超过98%接近100%。
- Conclusion: 紧凑的领域特定CNN在散斑材料分类中优于大型骨干网络，推动了可部署在边缘设备的材料感知激光切割系统的可行性。


### [23] [AutocleanEEG ICVision: Automated ICA Artifact Classification Using Vision-Language AI](https://arxiv.org/abs/2512.00194)
*Zag ElSayed,Grace Westerkamp,Gavin Gammoh,Yanchen Liu,Peyton Siekierski,Craig Erickson,Ernest Pedapati*

Main category: cs.CV

TL;DR: ICVision是首个通过AI视觉和自然语言推理模拟专家级EEG ICA成分分类的系统，直接解读ICA仪表板可视化，超越传统基于手工特征的方法。

- Motivation: 传统EEG ICA成分分类方法（如ICLabel）依赖手工特征，无法像专家那样直观解读可视化信息。需要一种能像神经学家一样"看到"并解释EEG成分的AI系统。
- Method: 使用多模态大语言模型（GPT-4 Vision）直接解读ICA仪表板可视化：地形图、时间序列、功率谱和ERP图，将每个成分分类为六种标准类别，并提供置信度和类人解释。
- Result: 在124个EEG数据集的3,168个ICA成分上评估，ICVision与专家共识的kappa一致性达到0.677，超越MNE ICLabel，在模糊情况下保留临床相关脑信号，97%以上输出被专家评为可解释和可操作。
- Conclusion: ICVision标志着科学AI的范式转变，模型不仅能分类，还能"看到"、推理和沟通，为全球可扩展、可解释和可复现的EEG工作流程打开了大门，预示着AI代理在脑科学等领域专家级视觉决策能力的出现。


### [24] [Mammo-FM: Breast-specific foundational model for Integrated Mammographic Diagnosis, Prognosis, and Reporting](https://arxiv.org/abs/2512.00198)
*Shantanu Ghosh,Vedant Parthesh Joshi,Rayan Syed,Aya Kassem,Abhishek Varshney,Payel Basak,Weicheng Dai,Judy Wawira Gichoya,Hari M. Trivedi,Imon Banerjee,Shyam Visweswaran,Clare B. Poynton,Kayhan Batmanghelich*

Main category: cs.CV

TL;DR: Mammo-FM是首个专门针对乳腺X线摄影的领域特定基础模型，在140,677名患者的大规模数据集上预训练，统一支持癌症诊断、病灶定位、结构化报告生成和风险预后等临床任务。

- Motivation: 乳腺癌是全球女性主要死因之一，现有通用基础模型在乳腺影像领域表现不足，缺乏专门针对乳腺X线摄影的领域特定模型，且临床需要可解释性和透明度的AI系统。
- Method: 在四个美国机构的140,677名患者（821,326张乳腺X线片）数据集上预训练，采用图像-文本对齐架构，支持多任务学习，使用原生分辨率图像，参数规模仅为通用基础模型的三分之一。
- Result: 在分布内和分布外数据集上，Mammo-FM在诊断、预后和报告生成任务中均优于最先进的通用基础模型，尽管参数更少且处理原生分辨率图像。
- Conclusion: 领域特定基础模型在临床应用中比通用模型更高效有效，图像-文本对齐提高了可解释性和临床可审计性，强调领域对齐评估的重要性。


### [25] [ReactionMamba: Generating Short &Long Human Reaction Sequences](https://arxiv.org/abs/2512.00208)
*Hajra Anwar Beg,Baptiste Chopin,Hao Tang,Mohamed Daoudi*

Main category: cs.CV

TL;DR: ReactionMamba：基于Mamba状态空间模型的新型3D人体反应动作生成框架，能够生成长短序列动作，在真实感、多样性和长序列生成方面表现优异，同时显著提升推理速度。

- Motivation: 现有方法在生成长序列3D人体反应动作时面临挑战，特别是在保持时间一致性和处理复杂动作（如舞蹈和武术）方面存在不足，需要更高效的框架来生成高质量的长序列反应动作。
- Method: 提出ReactionMamba框架，结合运动VAE进行高效动作编码，使用基于Mamba的状态空间模型解码时间一致的反应动作。该设计支持从简单短序列到复杂长序列（如舞蹈、武术）的生成。
- Result: 在NTU120-AS、Lindy Hop和InterX三个数据集上评估，在真实感、多样性和长序列生成方面与InterFormer、ReMoS、Ready-to-React等方法相比具有竞争力，同时推理速度有显著提升。
- Conclusion: ReactionMamba是一个有效的3D人体反应动作生成框架，能够生成高质量的长短序列动作，在保持时间一致性的同时大幅提升推理效率，为复杂动作生成提供了新解决方案。


### [26] [DenseScan: Advancing 3D Scene Understanding with 2D Dense Annotation](https://arxiv.org/abs/2512.00226)
*Zirui Wang,Tao Zhang*

Main category: cs.CV

TL;DR: DenseScan是一个包含详细多层次描述的3D场景理解数据集，通过自动化流程生成，结合多视角2D图像和多模态大语言模型，提供密集场景元素标注和场景化问题生成，增强3D环境的语义理解能力。

- Motivation: 当前3D场景理解数据集通常只提供几何和实例级信息，缺乏丰富的语义标注，限制了视觉语言任务的精细化发展。高质量数据对推动3D理解社区发展至关重要。
- Method: 采用自动化流程，利用多视角2D图像和多模态大语言模型生成密集的场景元素描述，确保全面的对象级描述捕捉上下文敏感细节。通过场景化问题生成扩展标注，产生整合对象属性、空间关系和场景上下文的高层次查询。
- Result: 实验结果表明，与传统标注流程相比，该方法显著提升了3D环境中的对象级理解和问答性能。数据集和标注流程已公开发布，支持机器人、增强现实等领域的未来研究和应用。
- Conclusion: DenseScan通过结合几何细节和语义丰富性，拓宽了下游任务范围，从详细的视觉语言导航到交互式问答。该工作旨在催化3D场景理解的新途径，使研究人员能够用更丰富、更具上下文感知的标注应对真实世界环境的复杂性。


### [27] [Relightable Holoported Characters: Capturing and Relighting Dynamic Human Performance from Sparse Views](https://arxiv.org/abs/2512.00255)
*Kunwar Maheep Singh,Jianchun Chen,Vladislav Golyanik,Stephan J. Garbin,Thabo Beeler,Rishabh Dabral,Marc Habermann,Christian Theobalt*

Main category: cs.CV

TL;DR: RHC是一种基于稀疏RGB视频的人物特定方法，能够实现自由视角渲染和全身动态人物的重光照，通过单次网络前向传播预测重光照外观，避免了传统OLAT方法的昂贵采集过程。

- Motivation: 传统基于OLAT（一次一光）的人物重光照方法需要昂贵的采集过程和多次计算，无法高效处理动态人物。需要一种能够从稀疏视角RGB视频中直接进行自由视角渲染和重光照的方法。
- Method: 1）提出新的采集策略和数据集：在多视角光舞台上交替使用随机环境光照和均匀光照帧，实现精确运动跟踪和多样化光照覆盖；2）基于渲染方程推导物理感知特征：编码几何、反照率、着色和虚拟相机视角；3）设计RelightNet：基于Transformer架构，通过交叉注意力机制将特征与新光照条件结合，回归重光照外观（基于网格代理的3D高斯溅射表示）。
- Result: 实验表明，RHC在视觉保真度和光照再现方面优于现有最先进方法，能够高效地在单次前向传播中计算渲染方程。
- Conclusion: RHC提供了一种高效的人物特定重光照方法，仅需稀疏视角RGB视频输入，通过物理感知特征和Transformer架构实现了高质量的动态人物自由视角渲染和重光照。


### [28] [UniDiff: Parameter-Efficient Adaptation of Diffusion Models for Land Cover Classification with Multi-Modal Remotely Sensed Imagery and Sparse Annotations](https://arxiv.org/abs/2512.00261)
*Yuzhen Hu,Saurabh Prasad*

Main category: cs.CV

TL;DR: UniDiff：一个参数高效的框架，使用单个ImageNet预训练的扩散模型适应多种遥感模态，仅需目标域数据，解决了稀疏标注下的多模态遥感挑战。

- Motivation: 稀疏标注严重制约了多模态遥感的发展，即使是先进的监督方法如MSFMamba也受限于标注数据的可用性。ImageNet预训练模型提供了丰富的视觉表示，但将其适应到异质模态（如高光谱成像和合成孔径雷达）而无需大量标注数据仍然具有挑战性。
- Method: 提出UniDiff框架，结合FiLM-based时间步-模态条件化、仅调整约5%参数的参数高效适应方法，以及伪RGB锚定技术来保持预训练表示并防止灾难性遗忘。
- Result: 在两个成熟的多模态基准数据集上的结果表明，预训练扩散模型的无监督适应有效缓解了标注约束，实现了多模态遥感数据的有效融合。
- Conclusion: UniDiff框架通过参数高效的无监督适应方法，使单个ImageNet预训练扩散模型能够有效处理多种遥感模态，解决了稀疏标注下的多模态遥感挑战。


### [29] [HeartFormer: Semantic-Aware Dual-Structure Transformers for 3D Four-Chamber Cardiac Point Cloud Reconstruction](https://arxiv.org/abs/2512.00264)
*Zhengda Ma,Abhirup Banerjee*

Main category: cs.CV

TL;DR: 提出首个基于点云表示的几何深度学习框架HeartFormer，用于从cine MRI数据重建3D四腔心脏，并创建了首个公开的大规模数据集HeartCompv1。

- Motivation: 传统cine MRI仅提供2D切片图像，限制了全面理解心脏形态和生理机制，特别是在健康和病理条件下的分析。
- Method: 提出HeartFormer点云补全网络，包含两个关键组件：语义感知双结构Transformer网络（SA-DSTNet）生成初始粗点云，语义感知几何特征细化Transformer网络（SA-GFRTNet）逐步细化输出。
- Result: 在HeartCompv1和UK Biobank数据集上的跨域实验表明，HeartFormer实现了鲁棒、准确且可泛化的性能，一致超越现有最先进方法。
- Conclusion: HeartFormer为3D心脏重建提供了有效的几何深度学习解决方案，并建立了该新兴研究方向的首个通用基准数据集。


### [30] [USB: Unified Synthetic Brain Framework for Bidirectional Pathology-Healthy Generation and Editing](https://arxiv.org/abs/2512.00269)
*Jun Wang,Peirong Liu*

Main category: cs.CV

TL;DR: USB是一个统一的端到端框架，通过配对扩散机制建模病变与脑解剖结构的联合分布，实现病理与健康脑图像的双向生成和编辑。

- Motivation: 病理与健康脑结构关系对神经影像学至关重要，但配对的病理-健康数据极难获取。现有方法多为领域特定，独立处理病理和健康图像建模，缺乏统一框架。
- Method: 提出USB框架，通过配对扩散机制建模病变与脑解剖结构的联合分布，采用一致性引导算法在双向病理-健康编辑中保持解剖一致性和病变对应关系。
- Result: 在六个公共脑MRI数据集（健康对照、中风、阿尔茨海默病患者）上的实验表明，USB能够产生多样且真实的结果，建立了首个脑图像生成与编辑的统一基准。
- Conclusion: USB为可扩展的数据集创建和稳健的神经影像分析开辟了机会，是首个统一病理与健康脑图像双向生成和编辑的框架。


### [31] [HIMOSA: Efficient Remote Sensing Image Super-Resolution with Hierarchical Mixture of Sparse Attention](https://arxiv.org/abs/2512.00275)
*Yi Liu,Yi Wan,Xinyi Liu,Qiong Wu,Panwang Xia,Xuejun Huang,Yongjun Zhang*

Main category: cs.CV

TL;DR: 提出HIMOSA轻量级遥感图像超分辨率框架，通过内容感知稀疏注意力机制和分层窗口扩展，在保持高性能的同时实现快速推理。

- Motivation: 遥感应用（如灾害检测与响应）需要实时效率和模型轻量化，现有方法在模型性能和计算效率之间存在权衡问题。
- Method: 利用遥感图像固有冗余性，引入内容感知稀疏注意力机制；采用分层窗口扩展有效利用多尺度重复模式，通过调整注意力稀疏度降低计算复杂度。
- Result: 在多个遥感数据集上的大量实验表明，该方法在保持计算效率的同时达到了最先进的性能。
- Conclusion: HIMOSA框架成功解决了遥感图像超分辨率中性能与效率的权衡问题，实现了高性能与快速推理的平衡。


### [32] [Rethinking Lung Cancer Screening: AI Nodule Detection and Diagnosis Outperforms Radiologists, Leading Models, and Standards Beyond Size and Growth](https://arxiv.org/abs/2512.00281)
*Sylvain Bodard,Pierre Baudot,Benjamin Renoust,Charles Voyton,Gwendoline De Bie,Ezequiel Geremia,Van-Khoa Le,Danny Francis,Pierre-Henri Siot,Yousra Haddou,Vincent Bobin,Jean-Christophe Brisset,Carey C. Thomson,Valerie Bourdes,Benoit Huet*

Main category: cs.CV

TL;DR: AI系统通过直接在低剂量CT扫描的结节层面进行检测和恶性诊断，重新定义了肺癌筛查，在各项指标上超越放射科医生和现有AI模型。

- Motivation: 早期发现恶性肺结节至关重要，但传统筛查依赖结节大小和生长速度，这本质上延迟了诊断。需要开发能够同时进行检测和恶性诊断的AI系统，以克服数据集规模和可解释性的限制。
- Method: 设计了一个集成系统，结合浅层深度学习和基于特征的专业模型。在25,709次扫描和69,449个标注结节上进行训练和评估，系统直接对低剂量CT扫描进行结节层面的检测和恶性诊断。
- Result: 系统在内部验证中AUC达到0.98，在独立队列中达到0.945。每扫描0.5个假阳性下达到99.3%的灵敏度。在所有结节大小和分期上都超越放射科医生，特别在1期癌症中表现优异，在所有基于生长的指标（包括最不准确的体积倍增时间）上都更优，对不确定和缓慢生长结节的诊断比放射科医生提前最多一年。
- Conclusion: 该AI系统通过直接在结节层面进行检测和恶性诊断，克服了传统肺癌筛查的延迟问题，在准确性和早期诊断能力上显著超越放射科医生和现有AI模型，为AI在肺癌筛查中的实际应用解决了关键障碍。


### [33] [Words into World: A Task-Adaptive Agent for Language-Guided Spatial Retrieval in AR](https://arxiv.org/abs/2512.00294)
*Lixing Guo,Tobias Höllerer*

Main category: cs.CV

TL;DR: 提出模块化AR代理系统，整合多模态大语言模型与视觉模型，实现空间关系推理和语言条件空间检索，支持从简单物体识别到多物体关系推理的复杂查询。

- Motivation: 传统AR系统依赖固定类别检测器或标记物，无法处理复杂的开放词汇自然语言查询，需要增强对物理环境的交互式场景理解能力。
- Method: 开发自适应任务代理，协调MLLMs和坐标感知感知工具，构建动态AR场景图编码九种关系类型，支持任务自适应感兴趣区域高亮和上下文空间检索。
- Result: 系统能够处理从简单物体识别到多物体关系推理的复杂查询，返回米级精度的3D锚点，支持选择、测量、比较和驱动等物理操作。
- Conclusion: 模块化架构支持即插即用的视觉语言模型，无需重新训练，使AR代理成为增强MLLMs现实世界空间智能的中介，并引入GroundedAR-Bench评估框架。


### [34] [TGSFormer: Scalable Temporal Gaussian Splatting for Embodied Semantic Scene Completion](https://arxiv.org/abs/2512.00300)
*Rui Qian,Haozhi Cao,Tianchen Deng,Tianxin Hu,Weixiang Guo,Shenghai Yuan,Lihua Xie*

Main category: cs.CV

TL;DR: TGSFormer：一个用于具身3D语义场景补全的可扩展时序高斯泼溅框架，通过持久高斯内存和置信感知融合实现高效长时场景建模

- Motivation: 现有高斯方法存在随机初始化导致冗余、可扩展性差的问题，深度引导方法虽缓解但仍有局部性、延迟和内存开销大的局限，需要更高效的具身场景补全方案
- Method: 提出TGSFormer框架：1) 持久高斯内存用于时序预测；2) 双时序编码器通过置信感知交叉注意力处理当前和历史高斯特征；3) 置信感知体素融合模块将重叠基元合并为体素对齐表示
- Result: 在局部和具身SSC基准测试中达到SOTA，使用更少基元实现更高精度和可扩展性，保持长时场景完整性
- Conclusion: TGSFormer通过时序高斯泼溅框架解决了现有方法的冗余和可扩展性问题，为具身3D语义场景补全提供了高效且准确的解决方案


### [35] [Optimizing Distributional Geometry Alignment with Optimal Transport for Generative Dataset Distillation](https://arxiv.org/abs/2512.00308)
*Xiao Cui,Yulei Qin,Wengang Zhou,Hongsheng Li,Houqiang Li*

Main category: cs.CV

TL;DR: 提出基于最优传输(OT)的数据集蒸馏方法，通过全局和实例级别的细粒度对齐，在ImageNet-1K上实现至少4%的准确率提升

- Motivation: 现有大规模数据集蒸馏方法主要匹配全局分布统计量（如均值和方差），但忽略了关键的实例级特征和类内变化，导致泛化性能不佳
- Method: 将数据集蒸馏重新表述为最优传输距离最小化问题，包含三个组件：OT引导的扩散采样、标签-图像对齐的软重标记、基于OT的logit匹配
- Result: 在多种架构和大规模数据集上的实验表明，该方法始终优于最先进方法，在IPC=10设置下，每个架构在ImageNet-1K上至少获得4%的准确率提升
- Conclusion: 基于最优传输的数据集蒸馏方法能够有效保留复杂高维分布的几何特性，实现全局和实例级别的细粒度对齐，显著提升蒸馏性能


### [36] [ART-ASyn: Anatomy-aware Realistic Texture-based Anomaly Synthesis Framework for Chest X-Rays](https://arxiv.org/abs/2512.00310)
*Qinyi Cao,Jianan Fan,Weidong Cai*

Main category: cs.CV

TL;DR: ART-ASyn：一种用于胸部X光片的解剖感知真实纹理异常合成框架，通过渐进二值阈值分割方法生成解剖一致的真实肺不透明异常，支持显式分割监督和零样本异常分割。

- Motivation: 现有合成异常方法生成的异常在视觉上与真实病理模式差异明显，且忽略了解剖结构。需要一种能生成解剖一致且真实的异常合成方法，以提供更有效的监督信号。
- Method: 提出ART-ASyn框架，使用渐进二值阈值分割方法进行肺部分割，然后基于纹理增强生成解剖一致的肺不透明相关异常，为每个正常样本生成配对的合成异常及其精确像素级异常掩码。
- Result: 该方法能够生成真实且解剖一致的异常，支持显式分割监督。与之前仅限于单类分类的工作不同，ART-ASyn在零样本异常分割任务上表现出良好的泛化能力，在未见数据集上无需目标域标注即可工作。
- Conclusion: ART-ASyn通过生成解剖一致的真实异常，为无监督异常检测提供了有效的显式监督信号，并在零样本异常分割任务中展示了良好的泛化能力，为医学图像分析提供了新的解决方案。


### [37] [Odometry Without Correspondence from Inertially Constrained Ruled Surfaces](https://arxiv.org/abs/2512.00327)
*Chenqi Zhu,Levi Burner,Yiannis Aloimonos*

Main category: cs.CV

TL;DR: 提出一种基于直线特征和惯性测量的视觉里程计新方法，通过分析图像序列中直线扫过的直纹曲面来估计运动，避免传统点特征匹配的高计算成本和精度问题。

- Motivation: 传统视觉里程计依赖图像序列中的特征点提取和光流计算，这种点对点对应关系计算成本高且精度不稳定，影响里程计估计质量。虽然已有研究尝试使用直线特征或融合其他传感器（如事件相机、IMU）来改善性能，但仍严重依赖对应关系匹配。
- Method: 提出一种新颖算法，利用相机运动时观察到的直线在图像时空域中扫过的直纹曲面进行分析。该方法仅需通过点-线关联的微分计算更新来估计曲面，并利用机载IMU的惯性测量约束曲面，从而大幅降低解空间的维度。
- Result: 该方法能够从直纹曲面重建3D场景并计算视觉里程计，特别适合事件相机擅长边缘检测的特性，提供了一种更高效、更稳定的运动估计方案。
- Conclusion: 通过分析直线在图像时空域中形成的直纹曲面，并结合惯性测量约束，可以开发出计算效率更高、更稳健的视觉里程计方法，避免传统点特征匹配的局限性。


### [38] [MVAD : A Comprehensive Multimodal Video-Audio Dataset for AIGC Detection](https://arxiv.org/abs/2512.00336)
*Mengxue Hu,Yunfeng Diao,Changtao Miao,Jianshu Li,Zhe Li,Joey Tianyi Zhou*

Main category: cs.CV

TL;DR: MVAD是首个专门用于检测AI生成多模态视频-音频内容的综合数据集，包含三种真实伪造模式、高质量生成样本和广泛多样性。

- Motivation: 当前AI生成的多模态视频-音频内容快速发展，引发了信息安全与内容真实性的严重担忧。现有合成视频数据集大多只关注视觉模态，少数包含音频的数据集也主要局限于面部深度伪造，这无法应对日益扩大的通用多模态AI生成内容，严重阻碍了可信检测系统的发展。
- Method: 创建了多模态视频-音频数据集(MVAD)，具有三个关键特征：1) 真正的多模态性，包含三种真实视频-音频伪造模式生成的样本；2) 通过多种最先进的生成模型实现高感知质量；3) 全面的多样性，涵盖现实和动漫视觉风格、四个内容类别（人类、动物、物体、场景）和四种视频-音频多模态数据类型。
- Result: 成功构建了首个专门用于检测AI生成多模态视频-音频内容的综合数据集，填补了现有研究空白，为开发可信检测系统提供了重要资源。
- Conclusion: MVAD数据集填补了多模态AI生成内容检测领域的关键空白，通过提供高质量、多样化的真实伪造样本，将显著促进可信检测系统的开发，应对日益严峻的信息安全和内容真实性挑战。


### [39] [Assimilation Matters: Model-level Backdoor Detection in Vision-Language Pretrained Models](https://arxiv.org/abs/2512.00343)
*Zhongqi Wang,Jie Zhang,Shiguang Shan,Xilin Chen*

Main category: cs.CV

TL;DR: AMDET：无需先验知识的视觉语言预训练模型后门检测框架，通过分析文本编码器的特征同化特性来识别后门模型

- Motivation: 现有后门检测方法通常依赖训练数据集、后门触发器或下游分类器的先验知识，这在现实应用中不切实际。需要一种无需任何先验知识的模型级检测框架。
- Method: 1. 发现后门文本编码器的特征同化特性：后门样本中所有token的表示高度相似，这归因于注意力权重集中在触发token上。2. 通过基于梯度的token嵌入反演来恢复能激活后门行为的隐式特征。3. 通过分析损失景观来区分自然后门特征和真实注入的后门。
- Result: 在3,600个后门和良性微调模型上的实验表明，AMDET以89.90%的F1分数检测后门，在RTX 4090 GPU上约5分钟完成一次完整检测，并对自适应攻击表现出强鲁棒性。
- Conclusion: AMDET是一种无需先验知识的有效后门检测框架，不仅能检测故意注入的后门，还能识别OpenAI官方CLIP模型中存在的自然后门特征，为视觉语言预训练模型的安全部署提供了重要保障。


### [40] [mmPred: Radar-based Human Motion Prediction in the Dark](https://arxiv.org/abs/2512.00345)
*Junqiao Fan,Haocong Rao,Jiarui Zhang,Jianfei Yang,Lihua Xie*

Main category: cs.CV

TL;DR: 提出了首个基于毫米波雷达的人体运动预测方法mmPred，采用扩散模型框架，通过双域历史运动表示和全局骨架关系Transformer解决雷达信号噪声问题。

- Motivation: 现有基于RGB-D摄像头的HMP方法对光照条件敏感且存在隐私问题，限制了在消防、医疗等实际场景的应用。毫米波雷达具有鲁棒性和隐私保护特性，但雷达信号存在镜面反射和多径效应等噪声问题。
- Method: 提出mmPred扩散框架：1）双域历史运动表示：时域姿态细化分支学习细粒度细节，频域主导运动分支捕获全局运动趋势并抑制帧级不一致性；2）全局骨架关系Transformer作为扩散主干，建模关节间全局协作。
- Result: 在mmBody和mm-Fi数据集上达到最先进性能，分别超越现有方法8.6%和22%。
- Conclusion: 首次将毫米波雷达引入人体运动预测，提出的mmPred框架有效解决了雷达信号噪声问题，为隐私保护型运动预测提供了新解决方案。


### [41] [SMamDiff: Spatial Mamba for Stochastic Human Motion Prediction](https://arxiv.org/abs/2512.00355)
*Junqiao Fan,Pengfei Liu,Haocong Rao*

Main category: cs.CV

TL;DR: SMamDiff：基于空间Mamba的单阶段扩散模型，通过残差DCT运动编码和骨架绘制空间Mamba模块提升人体运动预测的时空一致性，在保持概率多样性的同时减少计算开销。

- Motivation: 现有人体运动预测方法存在局限性：确定性方法忽略不确定性，概率模型牺牲运动学合理性，扩散模型虽改善准确性与多样性权衡但多阶段流程计算成本高，不适合边缘部署。需要开发既保证时空一致性又高效的单阶段扩散模型。
- Method: 提出SMamDiff模型：1) 残差DCT运动编码：减去最后观测姿态后进行时域DCT，减少直流分量主导，突出高频信息，让模型学习关节如何运动而非位置；2) 骨架绘制空间Mamba模块：按顺序逐关节处理，使后处理关节依赖先前关节，建立长距离跨关节依赖关系。
- Result: 在Human3.6M和HumanEva数据集上，该模型在单阶段概率HMP方法中达到最先进性能，同时比多阶段扩散基线具有更低的延迟和内存消耗。
- Conclusion: 通过残差DCT编码和空间Mamba模块的时空一致性机制，SMamDiff实现了高效且准确的人体运动预测，为边缘部署提供了可行的单阶段扩散模型解决方案。


### [42] [MM-DETR: An Efficient Multimodal Detection Transformer with Mamba-Driven Dual-Granularity Fusion and Frequency-Aware Modality Adapters](https://arxiv.org/abs/2512.00363)
*Jianhong Han,Yupei Wang,Yuan Zhang,Liang Chen*

Main category: cs.CV

TL;DR: 提出MM-DETR，一个轻量高效的多模态目标检测框架，通过Mamba-based双粒度融合编码器、区域感知2D选择性扫描补全分支和轻量频率感知模态适配器，在保持高性能的同时大幅减少参数。

- Motivation: 现有基于注意力或可变形卷积的多模态融合方法难以平衡性能与轻量化设计；共享主干网络提取模态特征导致表征次优，而双流架构参数翻倍，限制了实际部署。
- Method: 1) Mamba-based双粒度融合编码器：将全局交互重构为通道级动态门控，利用1D选择性扫描实现线性复杂度的跨模态建模；2) 将多模态融合重新解释为模态补全问题，引入区域感知2D选择性扫描补全分支恢复模态特定线索；3) 在共享主干中插入轻量频率感知模态适配器，采用空间-频率共专家结构捕获模态特定线索，像素级路由器动态平衡专家贡献。
- Result: 在四个多模态基准数据集上的广泛实验证明了该方法的有效性和泛化能力。
- Conclusion: MM-DETR通过创新的融合编码器、模态补全机制和轻量适配器设计，实现了高性能与轻量化的平衡，为多模态目标检测的实际部署提供了有效解决方案。


### [43] [Towards aligned body representations in vision models](https://arxiv.org/abs/2512.00365)
*Andrey Gizdov,Andrea Procopio,Yichen Li,Daniel Harari,Tomer Ullman*

Main category: cs.CV

TL;DR: 小型视觉分割模型会自然形成类似人类的粗略身体表征，而大型模型则倾向于过度详细的细粒度编码，表明粗略表征可以在有限计算资源下涌现。

- Motivation: 人类物理推理依赖于内部的"身体"表征——粗略的、体积化的近似，能捕捉物体的范围并支持对运动和物理的直觉预测。虽然心理物理学证据表明人类使用这种粗略表征，但其内部结构仍然未知。本文旨在测试为分割训练的视觉模型是否发展出可比较的表征。
- Method: 将针对50名人类参与者的心理物理学实验改编为语义分割任务，测试了7个不同大小的分割网络家族。比较了小型模型和大型模型在形成表征方面的差异。
- Result: 发现较小的模型自然地形成类似人类的粗略身体表征，而较大的模型倾向于形成过度详细的细粒度编码。这表明粗略表征可以在有限的计算资源下涌现。
- Conclusion: 机器表征可以为理解大脑中物理推理的结构提供可扩展的途径，粗粒度表征在计算资源受限时自然形成，这与人类认知机制相似。


### [44] [THCRL: Trusted Hierarchical Contrastive Representation Learning for Multi-View Clustering](https://arxiv.org/abs/2512.00368)
*Jian Zhu*

Main category: cs.CV

TL;DR: 提出THCRL方法解决多视图聚类中的不可信融合问题，通过深度对称层次融合和平均K近邻对比学习模块实现可信表示学习，在深度多视图聚类任务中达到SOTA性能。

- Motivation: 多视图聚类面临不可信融合问题，主要源于两个因素：1)现有方法忽略单视图中的固有噪声；2)传统对比学习方法仅关注同一实例的不同视图，而忽略同一簇内最近邻的结构信息，导致多视图融合方向错误。
- Method: 提出可信层次对比表示学习(THCRL)，包含两个关键模块：1)深度对称层次融合(DSHF)模块，利用UNet架构集成多种去噪机制实现多视图数据的可信融合；2)平均K近邻对比学习(AKCL)模块，将融合表示与视图特定表示对齐，增强同一簇内样本的表示相似性。
- Result: 大量实验表明THCRL在深度多视图聚类任务中实现了最先进的性能。
- Conclusion: THCRL通过解决多视图聚类中的不可信融合问题，提供了一种有效的可信表示学习方法，在深度多视图聚类任务中表现出优越性能。


### [45] [POLARIS: Projection-Orthogonal Least Squares for Robust and Adaptive Inversion in Diffusion Models](https://arxiv.org/abs/2512.00369)
*Wenshuo Chen,Haosen Li,Shaofeng Liang,Lei Wang,Haozhe Jia,Kaishen Yuan,Jieming Wu,Bowen Tian,Yutao Yue*

Main category: cs.CV

TL;DR: POLARIS提出了一种新的扩散模型反演方法，通过将引导尺度ω作为步长变量并推导数学公式来最小化每一步的反演误差，显著改善了反演潜变量质量。

- Motivation: 当前基于扩散模型的Inversion-Denoising范式在图像编辑和修复任务中表现出色，但存在重建退化问题。研究发现关键因素是近似噪声误差，即在步骤t用步骤t-1的预测来近似噪声，导致反演过程中严重的误差累积。
- Method: 提出POLARIS方法，将反演从误差补偿问题重新表述为误差起源问题。不优化嵌入或潜代码来抵消累积漂移，而是将引导尺度ω作为步长变量，推导出数学基础公式来最小化每一步的反演误差。
- Result: POLARIS仅需一行代码即可显著改善反演潜变量质量，性能开销可忽略不计，能大幅减少噪声近似误差，并持续提升下游任务的准确性。
- Conclusion: POLARIS通过数学推导直接解决反演误差的根源问题，为扩散模型的反演过程提供了更稳健和自适应的解决方案，显著提升了图像编辑和修复任务的性能。


### [46] [Pore-scale Image Patch Dataset and A Comparative Evaluation of Pore-scale Facial Features](https://arxiv.org/abs/2512.00381)
*Dong Li,HuaLiang Lin,JiaYu Li*

Main category: cs.CV

TL;DR: 本文提出了PorePatch数据集和DMCE框架来解决面部弱纹理区域描述符匹配的挑战，虽然深度学习描述符在匹配任务上表现优异，但在3D重建任务中优势有限。

- Motivation: 面部皮肤区域的弱纹理特性给局部描述符匹配带来了重大挑战，而缺乏毛孔尺度的图像补丁数据集阻碍了深度学习描述符在面部领域的发展。
- Method: 提出了PorePatch数据集和Data-Model Co-Evolution (DMCE)框架，从高分辨率面部图像生成渐进细化的高质量数据集，并在该数据集上训练现有SOTA模型进行实验评估。
- Result: SOTA模型在匹配任务上达到1.91%的FPR95值，显著优于PSIFT的22.41%，但在3D重建任务中优势不明显，整体性能与传统描述符相比没有显著提升。
- Conclusion: 深度学习描述符在解决面部弱纹理区域挑战方面仍有局限性，该领域还需要更多研究工作。


### [47] [EZ-SP: Fast and Lightweight Superpoint-Based 3D Segmentation](https://arxiv.org/abs/2512.00385)
*Louis Geist,Loic Landrieu,Damien Robert*

Main category: cs.CV

TL;DR: 提出EZ-SP：一种完全GPU加速的可学习超点分割算法，比现有方法快13倍，结合轻量级分类器实现实时推理，在多个3D语义分割数据集上达到SOTA精度。

- Motivation: 现有的超点分割方法通常受限于CPU绑定的分区步骤，成为性能瓶颈。需要一种完全GPU加速的可学习分区算法来提高效率。
- Method: 提出可学习的全GPU分区算法，生成几何和语义一致的超点。模块紧凑（<60k参数），使用可微分代理损失训练，无需手工特征。结合轻量级超点分类器。
- Result: 分区速度快13倍，推理速度快72倍，参数减少120倍。在室内扫描（S3DIS）、自动驾驶（KITTI-360）和航空LiDAR（DALES）三个领域达到点基SOTA模型的精度。
- Conclusion: EZ-SP提供高效、紧凑的3D语义分割解决方案，支持实时推理和大规模场景处理，在多个应用领域保持高精度。


### [48] [WiseEdit: Benchmarking Cognition- and Creativity-Informed Image Editing](https://arxiv.org/abs/2512.00387)
*Kaihang Pan,Weile Chen,Haiyi Qiu,Qifan Yu,Wendong Bu,Zehan Wang,Yun Zhu,Juncheng Li,Siliang Tang*

Main category: cs.CV

TL;DR: WiseEdit是一个知识密集型基准测试，用于全面评估认知和创造力驱动的图像编辑能力，包含1,220个测试案例，揭示了当前最先进图像编辑模型在知识推理和创造性构图方面的局限性。

- Motivation: 现有图像编辑基准测试评估范围过于狭窄，无法全面评估新一代图像编辑模型的高级认知和创造力能力，需要更全面的评估框架。
- Method: 基于人类认知创作过程，将图像编辑分解为三个级联步骤：感知、解释和想象，每个步骤对应一个任务挑战；同时包含三种基本知识类型：陈述性知识、程序性知识和元认知知识。
- Result: 构建了包含1,220个测试案例的基准测试，客观揭示了当前最先进图像编辑模型在基于知识的认知推理和创造性构图能力方面的局限性。
- Conclusion: WiseEdit为全面评估认知和创造力驱动的图像编辑提供了新的基准测试框架，有助于推动该领域的发展，相关资源将公开提供。


### [49] [Better, Stronger, Faster: Tackling the Trilemma in MLLM-based Segmentation with Simultaneous Textual Mask Prediction](https://arxiv.org/abs/2512.00395)
*Jiazhen Liu,Mingkuan Feng,Long Chen*

Main category: cs.CV

TL;DR: STAMP提出了一种新的多模态大语言模型范式，通过分离自回归对话生成和非自回归掩码预测，同时解决了对话能力、分割性能和推理速度的三难问题。

- Motivation: 当前将分割集成到多模态大语言模型中的方法面临三难困境：需要同时保持对话能力、实现高分割性能和确保快速推理。现有方法被迫做出妥协，要么引入冲突的像素级目标损害对话能力，要么采用自回归方法在分割性能和推理速度之间权衡。
- Method: 提出全掩码预测范式，将自回归对话生成与非自回归掩码预测解耦。STAMP模型在生成文本响应后，通过将分割掩码预测视为图像块的并行"填空"任务，在单次前向传播中预测整个分割掩码。
- Result: STAMP在多个分割基准测试中显著优于最先进的方法，在保持对话能力的同时实现了高分割性能和快速推理，解决了三难困境。
- Conclusion: 全掩码预测范式为多模态大语言模型中的分割任务提供了一种有效的解决方案，能够在对话能力、分割性能和推理速度三个方面同时取得优异表现，无需妥协。


### [50] [Low-Bitrate Video Compression through Semantic-Conditioned Diffusion](https://arxiv.org/abs/2512.00408)
*Lingdong Wang,Guan-Ming Su,Divya Kothandaraman,Tsung-Wei Huang,Mohammad Hajiesmaili,Ramesh K. Sitaraman*

Main category: cs.CV

TL;DR: DiSCo是一个语义视频压缩框架，通过传输文本描述、降质视频和可选草图/姿态等紧凑模态，利用视频扩散模型重建高质量视频，在低比特率下比传统编解码器性能提升2-10倍。

- Motivation: 传统视频编解码器在超低比特率下会严重失真，因为像素保真度与人类感知存在根本性不匹配。需要一种能传输最核心语义信息并利用生成先验进行细节合成的方法。
- Method: 将源视频分解为三个紧凑模态：文本描述（语义）、时空降质视频（外观）、可选草图/姿态（运动线索）。使用条件视频扩散模型从这些表示中重建高质量时序一致视频。提出时序前向填充、令牌交错和模态特定编解码器来改进多模态生成和模态紧凑性。
- Result: 在低比特率下，该方法在感知指标上比基线语义和传统编解码器性能提升2-10倍。
- Conclusion: DiSCo框架通过传输紧凑的语义表示并利用生成模型重建细节，解决了传统编解码器在超低比特率下的失效问题，实现了感知质量的大幅提升。


### [51] [SplatFont3D: Structure-Aware Text-to-3D Artistic Font Generation with Part-Level Style Control](https://arxiv.org/abs/2512.00413)
*Ji Gan,Lingxu Chen,Jiaxu Leng,Xinbo Gao*

Main category: cs.CV

TL;DR: SplatFont3D：基于3D高斯泼溅的结构感知文本到3D艺术字体生成框架，支持细粒度部件级风格控制

- Motivation: 现有研究主要关注2D平面艺术字体，3D艺术字体生成探索不足。3D字体不仅能在游戏、动画等沉浸式3D环境中应用，还能通过渲染新视角增强2D字体生成。3D字体具有精确语义和强结构约束，需要细粒度部件级风格控制。
- Method: 提出SplatFont3D框架：1) Glyph2Cloud模块逐步增强2D字形（或部件）的形状和风格，生成对应3D点云用于高斯初始化；2) 通过分数蒸馏采样与预训练2D扩散模型交互优化3D高斯；3) 动态部件分配策略利用3D高斯的几何先验进行部件分割，缓解优化过程中的漂移纠缠。
- Result: SplatFont3D在风格-文本一致性、视觉质量和渲染效率方面优于现有3D模型。相比NeRF，提供更明确有效的部件级风格控制，渲染效率更高。
- Conclusion: SplatFont3D成功解决了3D艺术字体生成的挑战，实现了从多样化风格文本提示生成3D艺术字体，并具备精确的部件级风格控制能力。


### [52] [PhysGen: Physically Grounded 3D Shape Generation for Industrial Design](https://arxiv.org/abs/2512.00422)
*Yingxuan You,Chen Zhao,Hantao Zhang,Mingda Xu,Pascal Fua*

Main category: cs.CV

TL;DR: 提出了一种基于物理的3D形状生成管道，通过流匹配模型和物理感知正则化，将物理属性（如空气动力学效率）融入形状生成过程，提升工业设计的真实性。

- Motivation: 现有3D形状生成模型缺乏物理知识，无法将物理属性（如空气动力学效率）融入形状生成，导致工程设计中形状的真实性不足。
- Method: 提出统一的物理驱动3D形状生成管道：1）交替更新过程（速度更新+物理细化）；2）物理感知正则化；3）形状-物理变分自编码器（SP-VAE）联合编码形状和物理信息到统一潜在空间。
- Result: 在三个基准测试中，该方法超越了仅视觉逼真的形状生成，显著提升了形状的真实性。
- Conclusion: 通过将物理知识融入生成过程，实现了更符合工程设计的3D形状生成，为工业设计应用提供了更真实的形状合成方案。


### [53] [Recovering Origin Destination Flows from Bus CCTV: Early Results from Nairobi and Kigali](https://arxiv.org/abs/2512.00424)
*Nthenya Kyatha,Jay Taneja*

Main category: cs.CV

TL;DR: 利用公交车上已有的CCTV监控，通过目标检测、跟踪、重识别等技术，为撒哈拉以南非洲的公共交通恢复乘客起讫点（OD）流量数据，在良好条件下准确率高，但在拥挤、光照变化等现实压力下性能显著下降。

- Motivation: 撒哈拉以南非洲的公共交通经常过度拥挤，现有的自动化系统无法可靠地捕捉乘客流量数据。利用已部署用于安全的车载CCTV监控，需要开发适合当地条件的乘客流量监测方法。
- Method: 提出一个基线管道，结合YOLOv12检测、BotSORT跟踪、OSNet嵌入特征提取、基于OCR的时间戳标记和基于车辆运动数据的站点分类，来恢复公交车的起讫点（OD）流量。
- Result: 在内罗毕和基加利公交车的标注CCTV片段上，系统在低密度、光照良好条件下达到高计数准确率（召回率≈95%，精确率≈91%，F1≈93%），产生的OD矩阵与人工计数结果接近。但在现实压力下（如过度拥挤、彩色转单色、姿势变化、非标准车门使用），性能急剧下降（例如高峰时段上车计数低估约40%，单色片段召回率下降约17个百分点）。
- Conclusion: 研究揭示了部署特定的失败模式，并表明需要为撒哈拉以南非洲的公共交通开发更鲁棒、更注重实际部署的重识别方法，以应对现实世界中的各种挑战。


### [54] [What about gravity in video generation? Post-Training Newton's Laws with Verifiable Rewards](https://arxiv.org/abs/2512.00425)
*Minh-Quan Le,Yuanzhi Zhu,Vicky Kalogeiton,Dimitris Samaras*

Main category: cs.CV

TL;DR: 提出NewtonRewards框架，通过可验证的物理奖励改进视频生成模型的物理真实性，使用光学流和外观特征作为速度和质量的代理，强制执行牛顿运动学约束和质量守恒。

- Motivation: 当前视频扩散模型虽然能生成视觉上吸引人的片段，但经常违反基本物理定律（如物体漂浮、加速度漂移、碰撞不一致），存在视觉真实性与物理真实性之间的差距。
- Method: 提出NewtonRewards框架：1) 使用冻结的实用模型从生成视频中提取可测量代理（光学流作为速度代理，高级外观特征作为质量代理）；2) 通过两个互补的奖励强制执行牛顿结构：牛顿运动学约束（强制恒定加速度动力学）和质量守恒奖励（防止退化解）。
- Result: 在新建的大规模基准NewtonBench-60K上评估五个牛顿运动基元（自由落体、水平/抛物线投掷、斜坡下滑/上滑），NewtonRewards在所有基元的视觉和物理指标上都一致提高了物理合理性、运动平滑性和时间连贯性，优于先前的后训练方法，并在高度、速度和摩擦力的分布外偏移下保持强性能。
- Conclusion: 基于物理的可验证奖励为物理感知的视频生成提供了一条可扩展的路径，能够有效弥合视觉真实性与物理真实性之间的差距。


### [55] [Recognizing Pneumonia in Real-World Chest X-rays with a Classifier Trained with Images Synthetically Generated by Nano Banana](https://arxiv.org/abs/2512.00428)
*Jiachuan Peng,Kyle Lam,Jianing Qiu*

Main category: cs.CV

TL;DR: 使用Nano Banana生成的合成胸部X光图像训练分类器，在真实世界数据上验证肺炎识别性能，证明了合成数据在医学AI开发中的潜力。

- Motivation: 探索使用AI生成的合成医学图像数据来训练分类器的可行性，解决医学AI开发中真实标注数据稀缺的问题。
- Method: 使用Google最新AI模型Nano Banana生成合成胸部X光图像，仅用合成数据训练肺炎分类器，然后在两个真实世界数据集（RSNA肺炎检测数据集和胸部X光数据集）上进行外部验证。
- Result: 在RSNA数据集上获得AUROC 0.923和AUPR 0.900，在胸部X光数据集上获得AUROC 0.824和AUPR 0.913，表明仅用合成数据训练的分类器在真实数据上表现良好。
- Conclusion: 该方法展示了合成数据在医学AI开发中的可行性，但存在提示设计多样性控制、后处理对齐等限制，临床转化前需要大量验证、监管批准和伦理监督。


### [56] [FR-TTS: Test-Time Scaling for NTP-based Image Generation with Effective Filling-based Reward Signal](https://arxiv.org/abs/2512.00438)
*Hang Xu,Linjiang Huang,Feng Zhao*

Main category: cs.CV

TL;DR: FR-TTS提出了一种基于填充的奖励机制，用于解决测试时缩放技术在文本生成中的挑战，通过填充中间序列来评估样本质量，显著提升了生成效果。

- Motivation: 测试时缩放技术在图像生成中效果显著，但在文本生成中面临挑战。主要问题是中间标记序列的奖励与最终生成文本的奖励相关性低，导致中间表示无法有效指导剪枝方向。
- Method: 提出了基于填充的奖励机制，通过寻找合理的填充方案来补全中间序列，从而估计样本的未来轨迹。在此基础上开发了FR-TTS策略，结合多样性奖励和动态权重调度来全面评估中间样本。
- Result: 实验验证了FR-TTS在多个基准测试和奖励模型上的优越性。中间样本与最终样本的奖励相关性显著提高，内在信号如标记置信度也表明FR提供了可靠的质量评估指标。
- Conclusion: FR-TTS成功解决了文本生成中测试时缩放的挑战，通过创新的填充奖励机制实现了对中间样本的准确评估，为文本生成质量提升提供了有效解决方案。


### [57] [RecruitView: A Multimodal Dataset for Predicting Personality and Interview Performance for Human Resources Applications](https://arxiv.org/abs/2512.00450)
*Amit Kumar Gupta,Farhan Sheth,Hammad Shaikh,Dheeraj Kumar,Angkul Puniya,Deepak Panwar,Sandeep Chaurasia,Priya Mathur*

Main category: cs.CV

TL;DR: RecruitView数据集包含2011个自然视频面试片段，带有27,000对比较标注，涵盖12个维度。提出CRMF几何深度学习框架，在多流形上建模行为表征，显著优于基线方法。

- Motivation: 当前基于多模态行为数据的个性与软技能评估面临数据集有限、方法无法捕捉人类特质几何结构的挑战。需要更有效的数据集和建模方法。
- Method: 提出Cross-Modal Regression with Manifold Fusion (CRMF)框架，在双曲、球面和欧几里得流形上显式建模行为表征。使用几何特定专家网络捕捉层次结构、方向性模式和连续变化，通过自适应路由机制动态加权专家贡献，采用切空间融合减少参数量。
- Result: CRMF显著优于基线方法，Spearman相关系数提升达11.4%，一致性指数提升6.0%。相比大型多模态模型，训练参数量减少40-50%。RecruitView数据集已公开可用。
- Conclusion: RecruitView数据集和CRMF框架为个性与软技能评估提供了有效的多模态解决方案，通过几何深度学习在多流形上建模行为表征，实现了更好的性能与效率平衡。


### [58] [CausalAffect: Causal Discovery for Facial Affective Understanding](https://arxiv.org/abs/2512.00456)
*Guanyu Hu,Tangzheng Lian,Dimitrios Kollias,Oya Celiktutan,Xinyu Yang*

Main category: cs.CV

TL;DR: CausalAffect：首个用于面部情感分析的因果图发现框架，通过两级因果层次建模AU间及AU-表情的依赖关系，无需联合标注数据或手工因果先验，在AU检测和表情识别上达到SOTA。

- Motivation: 现有面部情感分析方法虽然使用动作单元(AU)作为基础，但很少从数据中推断AU与表情之间的心理学合理因果关系。需要建立可解释的因果推理框架来理解面部肌肉激活与情感表达之间的潜在依赖关系。
- Method: 提出CausalAffect框架：1) 两级极性感知因果层次结构，整合群体级规律与样本自适应结构；2) 特征级反事实干预机制，增强真实因果效应并抑制虚假相关性；3) 无需联合标注数据集或手工因果先验。
- Result: 在六个基准测试上的实验表明：1) 恢复的因果结构与既定心理学理论一致；2) 揭示了新的抑制性和先前未表征的依赖关系；3) 在AU检测和表情识别任务上均达到最先进水平。
- Conclusion: CausalAffect建立了因果发现与可解释面部行为之间的原则性连接，为面部情感分析提供了首个因果图发现框架，推动了该领域向更结构化、可解释的方向发展。


### [59] [RealGen: Photorealistic Text-to-Image Generation via Detector-Guided Rewards](https://arxiv.org/abs/2512.00473)
*Junyan Ye,Leiqi Zhu,Yuncheng Guo,Dongzhi Jiang,Zilong Huang,Yifan Zhang,Zhiyuan Yan,Haohuan Fu,Conghui He,Weijia Li*

Main category: cs.CV

TL;DR: RealGen是一个通过检测器奖励机制和GRPO算法优化的逼真文本到图像生成框架，显著提升了图像真实感和细节，超越了现有通用和专用模型。

- Motivation: 当前先进的文本到图像生成模型（如GPT-Image-1和Qwen-Image）虽然在文本一致性方面表现良好，但在逼真图像生成方面仍有不足，常产生带有明显AI伪影的"假"图像，如"过度光滑的皮肤"和"油光满面"等问题。研究旨在重新实现"与现实无法区分"的生成目标。
- Method: 提出RealGen框架，包含LLM组件用于提示优化和扩散模型用于逼真图像生成。引入"检测器奖励"机制，通过语义级和特征级合成图像检测器量化伪影并评估真实感。使用GRPO算法优化整个生成流程，提升图像真实感和细节。同时提出RealBench自动评估基准，采用检测器评分和竞技场评分实现无需人工的逼真度评估。
- Result: 实验表明，RealGen在真实感、细节和美学方面显著优于通用模型（如GPT-Image-1和Qwen-Image）以及专用逼真模型（如FLUX-Krea）。
- Conclusion: RealGen通过创新的检测器奖励机制和优化算法，有效解决了当前文本到图像生成模型在逼真度方面的不足，实现了更接近真实世界的图像生成效果，并提供了可靠的自动评估方法。


### [60] [Structured Context Learning for Generic Event Boundary Detection](https://arxiv.org/abs/2512.00475)
*Xin Gu,Congcong Li,Xinyao Wang,Dexiang Hong,Libo Zhang,Tiejian Luo,Longyin Wen,Heng Fan*

Main category: cs.CV

TL;DR: 提出结构化上下文学习（SCL）方法，通过结构化序列划分（SPoS）为通用事件边界检测提供结构化上下文，实现更好的速度-精度平衡

- Motivation: 通用事件边界检测（GEBD）旨在识别人类感知的事件边界时刻。现有方法在时间信息建模和计算效率方面存在局限，需要更灵活高效的解决方案
- Method: 提出结构化上下文学习（SCL）方法，包含：1）结构化序列划分（SPoS）将输入帧序列分区并提供结构化上下文；2）计算组间相似度捕捉帧间差异；3）使用轻量级全卷积网络基于分组相似度图确定事件边界；4）采用高斯核预处理标注边界以解决标注模糊问题
- Result: 在Kinetics-GEBD、TAPOS和镜头转换检测数据集上进行了广泛评估，证明了该方法优于现有最先进方法，且计算复杂度与视频长度呈线性关系
- Conclusion: 提出的结构化上下文学习方法为通用事件边界检测提供了灵活高效的解决方案，通过结构化序列划分实现了更好的速度-精度平衡，并在多个数据集上展现了优越性能


### [61] [Learning What Helps: Task-Aligned Context Selection for Vision Tasks](https://arxiv.org/abs/2512.00489)
*Jingyu Guo,Emir Konuk,Fredrik Strand,Christos Matsoukas,Kevin Smith*

Main category: cs.CV

TL;DR: TACS框架通过学习选择真正提升任务性能的配对示例，而非仅外观相似的示例，将检索融入学习目标，在多个数据集上优于基于相似性的检索方法。

- Motivation: 人类通过比较相关示例来解决视觉不确定性，但ViTs缺乏识别哪些示例能真正改进预测的能力。现有方法通常基于外观相似性选择示例，这可能无法真正提升任务性能。
- Method: 提出任务对齐上下文选择(TACS)框架，联合训练选择器网络和任务模型，采用梯度监督和强化学习的混合优化方案，使检索成为学习目标的一部分，通过任务奖励对齐选择过程。
- Result: 在18个数据集（涵盖细粒度识别、医学图像分类和医学图像分割）上，TACS始终优于基于相似性的检索方法，特别是在具有挑战性或数据有限的场景中表现更佳。
- Conclusion: TACS通过将检索与任务奖励对齐，使判别模型能够发现真正有帮助的上下文示例，为解决视觉不确定性提供了更有效的方法，在多种视觉任务中展现出优越性能。


### [62] [CC-FMO: Camera-Conditioned Zero-Shot Single Image to 3D Scene Generation with Foundation Model Orchestration](https://arxiv.org/abs/2512.00493)
*Boshi Tang,Henry Zheng,Rui Huang,Gao Huang*

Main category: cs.CV

TL;DR: CC-FMO：一种零样本、相机条件化的单图像到3D场景生成方法，通过混合实例生成器和相机条件化尺度求解算法，实现高质量、空间一致的场景生成。

- Motivation: 现有方法在单图像到3D场景生成中存在两个主要问题：1）早期方法依赖专门模型，泛化能力有限；2）现有大规模3D基础模型在场景级生成中，由于物体姿态估计不准确和空间不一致性，难以生成连贯场景。
- Method: 提出CC-FMO框架：1）混合实例生成器，结合语义感知的向量集表示和细节丰富的结构化潜在表示，生成语义合理且高质量的物体几何；2）相机条件化尺度求解算法，将基础姿态估计模型应用于场景生成任务，确保场景级一致性。
- Result: 大量实验表明，CC-FMO能够一致地生成高保真、相机对齐的组合场景，在所有最先进方法中表现最优。
- Conclusion: CC-FMO通过零样本、相机条件化的方法解决了单图像到3D场景生成的挑战，实现了物体布局对齐和实例保真度的平衡，为AR/VR和具身AI应用提供了有效的解决方案。


### [63] [Terrain Sensing with Smartphone Structured Light: 2D Dynamic Time Warping for Grid Pattern Matching](https://arxiv.org/abs/2512.00514)
*Tanaka Nobuaki*

Main category: cs.CV

TL;DR: 提出基于智能手机的结构光系统，通过投影网格到地面并分析变形来感知地形不平度，开发了拓扑约束的二维动态时间规整算法用于网格匹配。

- Motivation: 低成本移动机器人在不平坦地形上运行时，视觉难以感知的小颠簸或倾斜会显著影响运动稳定性，需要一种简单有效的地形感知方法。
- Method: 使用智能手机结构光系统投影网格到地面，提出拓扑约束的二维动态时间规整算法，在全局网格一致性约束下进行列对齐，匹配变形网格模式。
- Result: 开发了可在资源有限平台上运行的2D-DTW算法，不仅能用于地形感知，还可作为图像处理中结构化网格匹配的通用工具。
- Conclusion: 提出的智能手机结构光系统和2D-DTW算法为低成本地形感知提供了有效解决方案，同时扩展了动态时间规整在二维网格匹配中的应用。


### [64] [Image Generation as a Visual Planner for Robotic Manipulation](https://arxiv.org/abs/2512.00532)
*Ye Pang*

Main category: cs.CV

TL;DR: 利用预训练图像生成模型作为机器人视觉规划器，通过LoRA微调生成连贯的机器人操作视频

- Motivation: 现有视频扩散模型需要大量领域特定数据且泛化能力有限，而预训练语言-图像模型展现出强大的组合能力和时间连贯性，暗示其具备视频生成潜力，可作为机器人视觉规划器
- Method: 提出两部分框架：1) 文本条件生成：使用语言指令和第一帧图像；2) 轨迹条件生成：使用2D轨迹覆盖和相同初始帧。通过LoRA微调预训练图像生成模型
- Result: 在Jaco Play、Bridge V2和RT1数据集上的实验表明，两种模式都能生成平滑、连贯且与条件对齐的机器人操作视频
- Conclusion: 预训练图像生成器编码了可迁移的时间先验，能够在最小监督下作为视频式机器人规划器，为统一感知、规划和行动提供了新途径


### [65] [Cross-Temporal 3D Gaussian Splatting for Sparse-View Guided Scene Update](https://arxiv.org/abs/2512.00534)
*Zeyuan An,Yanghang Xiao,Zhiying Leng,Frederick W. B. Li,Xiaohui Liang*

Main category: cs.CV

TL;DR: 提出Cross-Temporal 3DGS框架，利用稀疏图像和历史场景先验，高效重建和更新不同时间段的3D场景

- Motivation: 现实应用中（如城市规划、灾害评估、历史遗址保护）通常无法获取密集扫描数据，需要从稀疏视角观测中更新3D场景表示，保持时间一致性是重要挑战
- Method: 三阶段方法：1)跨时间相机对齐，估计和对齐不同时间戳的相机位姿；2)基于干扰的置信度初始化，识别时间戳间未变化区域以指导更新；3)渐进式跨时间优化，迭代整合历史先验信息到3D场景中提升重建质量
- Result: 实验结果显示在重建质量和数据效率方面显著优于基线方法，支持非连续捕获，既能用新稀疏视图更新现有场景，也能借助当前捕获从有限数据恢复过去场景
- Conclusion: 该方法为场景版本控制、跨时间数字孪生和长期空间文档记录提供了有前景的解决方案，展示了仅用稀疏图像实现时间变化检测并重建为详细3D表示的潜力


### [66] [SAIDO: Generalizable Detection of AI-Generated Images via Scene-Aware and Importance-Guided Dynamic Optimization in Continual Learning](https://arxiv.org/abs/2512.00539)
*Yongkang Hu,Yu Cheng,Yushuo Zhang,Yuan Xie,Zhaoxia Yin*

Main category: cs.CV

TL;DR: SAIDO框架：一种场景感知和重要性引导的动态优化检测框架，通过持续学习解决AI生成图像检测的泛化问题，在开放世界数据集上比现有SOTA方法平均检测准确率提升9.47%

- Motivation: AI生成图像技术的滥用引发安全担忧，现有检测方法面临泛化挑战，难以适应新兴生成方法和真实场景中的内容类型
- Method: 提出SAIDO框架：1) 场景感知专家模块(SAEM)利用VLLMs动态识别新场景并分配独立专家模块；2) 重要性引导动态优化机制(IDOM)通过重要性引导的梯度投影策略优化每个神经元，平衡模型可塑性和稳定性
- Result: 在持续学习任务中，相比当前SOTA方法，平均检测错误率和遗忘率分别相对降低44.22%和40.57%；在开放世界数据集上，平均检测准确率提升9.47%
- Conclusion: SAIDO框架有效解决了AI生成图像检测的泛化问题，通过场景感知和重要性引导的动态优化，在持续学习环境中实现了更好的稳定性和可塑性平衡


### [67] [Asset-Driven Sematic Reconstruction of Dynamic Scene with Multi-Human-Object Interactions](https://arxiv.org/abs/2512.00547)
*Sandika Biswas,Qianyi Wu,Biplab Banerjee,Hamid Rezatofighi*

Main category: cs.CV

TL;DR: 提出混合方法结合3D生成模型、语义感知变形和GS优化，解决多人多物体动态场景的3D几何建模难题

- Motivation: 现实世界中人造环境高度动态，包含多人与物体的复杂交互，但现有3D几何建模方法难以处理此类场景，特别是在单目设置下，严重的遮挡问题使得结构一致性难以保持
- Method: 混合方法：1) 使用3D生成模型生成场景元素的高保真网格；2) 语义感知变形（刚性物体的刚性变换和基于LBS的人体变形）；3) 基于3D高斯泼溅的优化进一步细化场景中对齐
- Result: 在HOI-M3数据集上评估，该方法在多人多物体交互动态场景的表面重建方面优于现有最先进方法
- Conclusion: 提出的混合方法能有效处理多人多物体动态场景的3D几何建模，即使在严重遮挡情况下也能保持物体结构，产生多视角和时间一致的几何结果


### [68] [NeuroVolve: Evolving Visual Stimuli toward Programmable Neural Objectives](https://arxiv.org/abs/2512.00557)
*Haomiao Chen,Keith W Jamison,Mert R. Sabuncu,Amy Kuceyeski*

Main category: cs.CV

TL;DR: NeuroVolve是一个生成框架，通过优化预训练视觉语言模型嵌入空间中的神经目标函数，实现大脑引导的图像合成，能够激活或抑制单个或多个脑区，揭示神经表征的语义轨迹。

- Motivation: 现有方法主要关注孤立脑区的类别选择性（如FFA的面孔识别），但无法揭示在复杂自然视觉过程中脑区如何相互作用。需要开发能够探索分布式脑区模式如何组合形成神经表征的新方法。
- Method: 提出NeuroVolve生成框架，在预训练视觉语言模型的嵌入空间中优化神经目标函数。通过可编程的神经目标（激活或抑制单个或多个脑区）引导图像生成，并跟踪优化步骤以揭示语义轨迹。
- Result: 验证了NeuroVolve能够恢复已知的单个脑区选择性，同时扩展到合成满足复杂多脑区约束的连贯场景。能够生成针对单个ROI的低级和语义特征特异性刺激，以及符合定制神经目标的刺激，揭示脑区间的协同和拮抗调谐关系。
- Conclusion: NeuroVolve统一了大脑引导的图像编辑和偏好刺激生成，能够捕捉受试者特异性偏好，支持个性化大脑驱动合成，为映射、分析和探测视觉信息的神经表征提供了可解释的约束。


### [69] [Describe Anything Anywhere At Any Moment](https://arxiv.org/abs/2512.00565)
*Nicolas Gorlo,Lukas Schmid,Luca Carlone*

Main category: cs.CV

TL;DR: DAAAM是一个实时4D场景理解框架，通过优化前端加速语义描述推理，构建层次化4D场景图，在时空问答和任务落地任务中实现SOTA性能。

- Motivation: 现有方法在丰富开放词汇描述和实时3D落地之间存在权衡，需要同时满足几何结构准确性和语义细节，以支持增强现实、机器人自主等大规模环境应用。
- Method: 提出DAAAM框架：1) 优化前端利用批量处理加速局部描述模型的语义推理；2) 构建层次化4D场景图作为全局时空一致的内存表示；3) 与工具调用代理良好接口进行推理。
- Result: 在NaVQA基准上实现时空问答SOTA，在SG3D基准上展示序列任务落地泛化能力。OC-NaVQA问答准确率提升53.6%，位置误差降低21.9%，时间误差降低21.6%，SG3D任务落地准确率提升27.8%。
- Conclusion: DAAAM能够构建具有详细几何基础描述的4D场景图，同时保持实时性能，为大规模实时4D场景理解提供了有效解决方案，并开源数据和代码。


### [70] [Integrating Skeleton Based Representations for Robust Yoga Pose Classification Using Deep Learning Models](https://arxiv.org/abs/2512.00572)
*Mohammed Mohiuddin,Syed Mohammod Minhaz Hossain,Sumaiya Khanam,Prionkar Barua,Aparup Barua,MD Tamim Hossain*

Main category: cs.CV

TL;DR: 该研究创建了Yoga-16数据集，系统评估了三种深度学习架构在三种输入模态下的瑜伽姿势分类性能，发现基于骨架的表示优于原始图像输入，VGG16+MediaPipe Pose骨架输入达到96.09%的最高准确率。

- Motivation: 瑜伽姿势不正确可能导致受伤，自动瑜伽姿势分类可以减少对专家指导的依赖。现有研究在瑜伽姿势识别方面缺乏系统性基准测试，通常只关注原始图像或单一姿势提取模型。
- Method: 创建了Yoga-16数据集，系统评估了VGG16、ResNet50和Xception三种深度学习架构，使用三种输入模态：直接图像、MediaPipe Pose骨架图像和YOLOv8 Pose骨架图像，并通过Grad-CAM进行可解释性分析。
- Result: 骨架表示优于原始图像输入，VGG16与MediaPipe Pose骨架输入组合达到96.09%的最高准确率。交叉验证分析提供了模型鲁棒性的深入见解。
- Conclusion: 基于骨架的表示在瑜伽姿势分类中表现优异，VGG16+MediaPipe Pose是最佳组合。该研究为瑜伽姿势识别提供了系统性基准测试框架和可解释性分析。


### [71] [SatireDecoder: Visual Cascaded Decoupling for Enhancing Satirical Image Comprehension](https://arxiv.org/abs/2512.00582)
*Yue Jiang,Haiwei Xue,Minghao Han,Mingcheng Li,Xiaolu Hou,Dingkang Yang,Lihua Zhang,Xu Zheng*

Main category: cs.CV

TL;DR: SatireDecoder：一个无需训练的多智能体框架，通过视觉级联解耦和不确定性引导的思维链推理，提升视觉讽刺图像的理解能力，减少幻觉并提高解释准确性。

- Motivation: 视觉讽刺理解对当前视觉语言模型具有挑战性，需要检测讽刺、解读其微妙含义并识别相关实体。现有模型难以有效整合局部实体关系与全局上下文，导致误解、理解偏差和幻觉。
- Method: 提出SatireDecoder训练免费框架：1）多智能体系统执行视觉级联解耦，将图像分解为细粒度局部和全局语义表示；2）引入不确定性分析引导的思维链推理策略，将复杂讽刺理解过程分解为顺序子任务以最小化不确定性。
- Result: 实验验证SatireDecoder在理解视觉讽刺方面优于现有基线，显著提高解释准确性同时减少幻觉，为细微、高级语义任务的视觉语言推理提供了有前景的方向。
- Conclusion: SatireDecoder通过创新的多智能体解耦和不确定性引导推理，有效解决了视觉讽刺理解的挑战，为复杂视觉语言理解任务提供了新的解决方案。


### [72] [Scaling Down to Scale Up: Towards Operationally-Efficient and Deployable Clinical Models via Cross-Modal Low-Rank Adaptation for Medical Vision-Language Models](https://arxiv.org/abs/2512.00597)
*Thuraya Alzubaidi,Farhad R. Nezami,Muzammil Behzad*

Main category: cs.CV

TL;DR: MedCT-VLM是一个参数高效的医学CT视觉语言模型，通过LoRA微调CT-CLIP基础模型，仅训练0.38%参数即可在18种胸部病理零样本分类任务上显著提升性能。

- Motivation: 尽管视觉语言预训练基础模型在多个图像领域展现出强大的零样本能力，但在医学体积成像（如CT）中的应用仍然有限。医学领域标注数据稀缺，需要能够有效利用大规模预训练模型的方法来适应下游临床任务。
- Method: 提出MedCT-VLM框架，采用参数高效的LoRA（低秩适应）方法微调CT-CLIP模型。CT-CLIP是在25,692个胸部CT体积上训练的对比视觉语言模型。LoRA通过在视觉和文本编码器的注意力层中插入低秩分解矩阵，仅训练1.67M参数（占总参数440M的0.38%），而不直接微调整个模型。
- Result: 在18种胸部病理的零样本分类任务中，LoRA微调使平均AUROC从61.3%提升至68.9%（+7.6个百分点），准确率从67.2%提升至73.6%（+6.4个百分点），宏平均F1分数从32.1%提升至36.9%（+4.8个百分点）。
- Conclusion: 参数高效方法（如LoRA）能够有效将大规模预训练知识迁移到下游医学成像任务中，特别是在标注数据稀缺的零样本场景下，为医学影像分析提供了实用的解决方案。


### [73] [Automatic Pith Detection in Tree Cross-Section Images Using Deep Learning](https://arxiv.org/abs/2512.00625)
*Tzu-I Liao,Mahmoud Fakhry,Jibin Yesudas Varghese*

Main category: cs.CV

TL;DR: 本研究评估了多种深度学习模型（YOLOv9、U-Net、Swin Transformer、DeepLabV3、Mask R-CNN）在树木横截面髓心检测中的性能，通过动态数据增强提升泛化能力，其中Swin Transformer在细粒度分割中表现最佳（准确率0.94）。

- Motivation: 树木横截面髓心检测对林业和木材质量分析至关重要，但目前仍依赖人工操作，存在误差率高的问题。需要开发自动化、高效的检测方法来替代传统人工方法。
- Method: 使用582张标注图像的数据集，通过动态数据增强提高泛化能力。评估了YOLOv9、U-Net、Swin Transformer、DeepLabV3和Mask R-CNN五种深度学习模型。使用俄勒冈州立大学树木年轮实验室的11张橡树图像测试泛化能力，并对最差模型使用额外64张图像进行探索性训练。
- Result: Swin Transformer表现最佳（准确率0.94），擅长细粒度分割；YOLOv9在边界框检测中表现良好但边界精度不足；U-Net对结构化模式有效；DeepLabV3能捕捉多尺度特征但边界精度稍差；Mask R-CNN初始IoU为0.45，应用NMS后提升至0.80。模型在橡树数据集上展示了泛化能力。
- Conclusion: 深度学习在树木横截面髓心检测中具有巨大潜力，模型选择应基于数据集特性和应用需求。Swin Transformer在细粒度分割中表现最优，而通过数据增强和超参数调优可以解决张量不匹配和边界不一致等关键挑战。


### [74] [XAI-Driven Skin Disease Classification: Leveraging GANs to Augment ResNet-50 Performance](https://arxiv.org/abs/2512.00626)
*Kim Gerard A. Villanueva,Priyanka Kumar*

Main category: cs.CV

TL;DR: 该研究提出一个可信赖的皮肤病变CAD系统，使用DCGAN解决数据不平衡问题，结合ResNet-50分类器和XAI技术，在HAM10000数据集上达到92.50%准确率和98.82%宏AUC。

- Motivation: 皮肤病变多类别诊断面临主观方法、数据集不平衡（如HAM10000）和深度学习模型"黑箱"问题，需要开发既准确又可信赖的计算机辅助诊断系统。
- Method: 使用DCGAN进行每类数据增强解决类别不平衡，然后训练微调的ResNet-50分类器，并集成LIME和SHAP等XAI技术提供模型透明度。
- Result: 系统达到92.50%的整体准确率和98.82%的宏AUC，优于多种基准架构，并通过XAI验证预测基于临床相关特征（如不规则形态）。
- Conclusion: 该研究成功验证了一个结合高性能与临床可解释性的可验证框架，为安全诊断部署提供了基础。未来研究应优先提升对关键类别（如黑色素瘤）的鉴别能力。


### [75] [Doppler-Enhanced Deep Learning: Improving Thyroid Nodule Segmentation with YOLOv5 Instance Segmentation](https://arxiv.org/abs/2512.00639)
*Mahmoud El Hussieni*

Main category: cs.CV

TL;DR: YOLOv5算法在甲状腺结节超声图像实例分割中表现优异，包含多普勒图像可显著提升分割性能，YOLOv5-Large模型达到最佳效果（Dice分数91%，mAP 0.87）。

- Motivation: 甲状腺癌发病率上升，需要开发计算机辅助检测方法。甲状腺结节准确分割是AI辅助临床决策支持系统的关键第一步。
- Method: 使用YOLOv5算法进行甲状腺结节实例分割，评估多个变体（Nano、Small、Medium、Large、XLarge），在两个数据集版本（包含/不包含多普勒图像）上进行测试。
- Result: YOLOv5-Large算法在包含多普勒图像的数据集上表现最佳，Dice分数91%，mAP 0.87。包含多普勒图像显著提升所有模型变体的分割性能（如YOLOv5-Small从79%提升）。
- Conclusion: YOLOv5实例分割为甲状腺结节检测提供了有效的实时方法，多普勒图像虽常被医生排除但能显著改善分割性能，具有自动化诊断系统的临床应用潜力。


### [76] [Graph-Attention Network with Adversarial Domain Alignment for Robust Cross-Domain Facial Expression Recognition](https://arxiv.org/abs/2512.00641)
*Razieh Ghaedi,AmirReza BabaAhmadi,Reyer Zwiggelaar,Xinqi Fan,Nashid Alam*

Main category: cs.CV

TL;DR: GAT-ADA：结合图注意力网络与对抗域对齐的跨域面部表情识别框架，通过建模样本间关系和域对齐提升跨域性能

- Motivation: 跨域面部表情识别面临严重的域偏移问题，训练数据与部署数据之间存在显著分布差异，导致模型性能下降
- Method: 使用ResNet-50作为主干网络，结合批级图注意力网络建模样本间关系，将小批量数据构建为稀疏环形图，通过注意力机制聚合跨样本信息。采用梯度反转层进行对抗学习，结合CORAL和MMD进行统计对齐
- Result: 在标准无监督域适应协议下，平均跨域准确率达到74.39%。在RAF-DB到FER2013的迁移任务中达到98.0%准确率，比最佳基线提升约36个百分点
- Conclusion: GAT-ADA通过结合图注意力网络建模样本关系和多种域对齐技术，有效解决了跨域面部表情识别中的域偏移问题，显著提升了模型在目标域上的性能


### [77] [MambaScope: Coarse-to-Fine Scoping for Efficient Vision Mamba](https://arxiv.org/abs/2512.00647)
*Shanhui Liu,Rui Xu,Yunke Wang*

Main category: cs.CV

TL;DR: CF-ViM提出了一种自适应粗到细的视觉Mamba框架，通过动态分辨率分配策略，根据图像复杂度自适应分配计算资源，在保持准确性的同时显著提升效率。

- Motivation: 现有视觉Mamba的效率受限于输入token数量，而传统的token剪枝或合并方法会导致信息丢失。问题在于这些方法对所有图像都采用统一的细粒度处理，忽视了不同图像视觉复杂度的差异。
- Method: CF-ViM采用自适应粗到细处理框架：首先将图像划分为大块进行粗粒度推理，大幅减少token数量和计算量；当模型预测置信度低时，选择性地对关键区域进行细粒度重处理，恢复重要视觉细节。
- Result: 在ImageNet上的实验表明，CF-ViM在准确性和效率方面均优于基线视觉Mamba和最先进的token缩减技术。
- Conclusion: CF-ViM通过根据图像复杂度自适应分配计算资源，实现了高效的视觉处理，避免了不必要的信息损失，为视觉Mamba的高效推理提供了新思路。


### [78] [Realistic Handwritten Multi-Digit Writer (MDW) Number Recognition Challenges](https://arxiv.org/abs/2512.00676)
*Kiri L. Wagstaff*

Main category: cs.CV

TL;DR: 论文提出基于NIST手写数字图像创建更真实的多数字作者基准数据集，发现孤立数字分类器在多数字识别中表现不佳，需要新方法提升真实场景下的数字识别性能。

- Motivation: 现实场景中数字通常以多数字形式出现（如邮政编码、支票金额、预约时间），且由同一人书写。现有孤立数字分类基准无法反映真实多数字识别问题，需要更贴近实际应用的评估标准。
- Method: 利用NIST数字图像中的作者信息创建多数字作者基准数据集，设计任务特定的性能指标，超越传统错误率计算，更贴近实际应用影响。
- Result: 研究发现孤立数字分类器在多数字识别任务中表现不佳，证实需要专门针对多数字识别开发新方法。新基准为利用任务特定知识提升性能提供了机会。
- Conclusion: 要解决真实数字识别问题，需要超越孤立数字分类的额外进展。多数字作者基准提供了更贴近实际应用的评估框架，促进开发能利用任务特定知识的改进方法。


### [79] [Dynamic-eDiTor: Training-Free Text-Driven 4D Scene Editing with Multimodal Diffusion Transformer](https://arxiv.org/abs/2512.00677)
*Dong In Lee,Hyungjun Doh,Seunggeun Chi,Runlin Duan,Sangpil Kim,Karthik Ramani*

Main category: cs.CV

TL;DR: Dynamic-eDiTor：基于MM-DiT和4DGS的无训练文本驱动4D场景编辑框架，通过时空子网格注意力和上下文令牌传播实现多视角和时间一致性编辑

- Motivation: 现有的4D场景重建技术（如Dynamic NeRF和4DGS）已取得进展，但文本驱动的4D场景编辑仍面临挑战。现有方法依赖2D扩散模型独立编辑帧，导致运动失真、几何漂移和不完整编辑，缺乏跨空间和时间的多视角与时间一致性。
- Method: 提出Dynamic-eDiTor框架，结合多模态扩散变换器（MM-DiT）和4D高斯泼溅（4DGS）。核心机制包括：1）时空子网格注意力（STGA）用于局部一致的跨视角和时间融合；2）上下文令牌传播（CTP）通过令牌继承和光流引导的令牌替换实现全局传播。无需额外训练，可直接优化预训练的源4DGS。
- Result: 在DyNeRF多视角视频数据集上的实验表明，该方法在编辑保真度、多视角一致性和时间一致性方面优于现有方法，实现了无缝、全局一致的多视角视频编辑。
- Conclusion: Dynamic-eDiTor成功解决了文本驱动4D场景编辑中的多视角和时间一致性问题，通过创新的STGA和CTP机制实现了高质量编辑，为动态4D场景编辑提供了有效的无训练解决方案。


### [80] [Silhouette-based Gait Foundation Model](https://arxiv.org/abs/2512.00691)
*Dingqiang Ye,Chao Fan,Kartik Narayan,Bingzhe Wu,Chengwen Luo,Jianqiang Li,Vishal M. Patel*

Main category: cs.CV

TL;DR: FoundationGait是首个可扩展的自监督预训练步态理解框架，拥有1.3亿参数，在12个数据集上预训练，在多种步态任务上表现出色

- Motivation: 当前步态识别模型受限于小规模、窄设计，无法扩展或泛化。需要解决两个长期障碍：(1) 可扩展性 - 为什么步态模型未能遵循缩放定律？(2) 泛化能力 - 能否用一个模型服务多样化的步态任务？
- Method: 提出FoundationGait框架，采用自监督预训练方法，最大版本有近1.3亿参数，在12个公共步态数据集（超过200万行走序列）上进行预训练
- Result: 在多种步态数据集、条件、任务（人类识别、脊柱侧弯筛查、抑郁预测、属性估计）和输入模态上表现稳健。在Gait3D数据集上达到48.0%的零样本rank-1准确率，在OU-MVLP数据集上达到64.5%，创下新里程碑
- Conclusion: FoundationGait是首个可扩展的步态基础模型，成功解决了步态模型的扩展和泛化问题，为统一步态理解框架奠定了基础


### [81] [Affordance-First Decomposition for Continual Learning in Video-Language Understanding](https://arxiv.org/abs/2512.00694)
*Mengzhu Xu,Hanzhi Liu,Ningkang Peng,Qianyu Chen,Canran Xiao*

Main category: cs.CV

TL;DR: AFD是一种持续学习框架，通过将视频映射到缓慢变化的可供性token作为共享时间对齐基底，结合轻量级查询路由调度器实现针对性适应，在视频-语言理解任务上取得SOTA性能。

- Motivation: 现有持续学习方法在视频-语言理解中存在三个问题：1) 模糊了稳定性和适应性的边界；2) 依赖静态路由/容量；3) 需要回放过去视频。需要在现实内存和隐私约束下明确区分稳定部分和适应部分。
- Method: 提出Affordance-First Decomposition (AFD)：1) 将视频映射到缓慢变化的可供性token，形成共享的时间对齐基底；2) 使用轻量级、查询路由、冲突感知的调度器集中适应并仅在需要时扩展容量；3) 通过弱对齐和教师一致性稳定基底；4) 训练时使用仅问题回放。
- Result: 在多个协议上达到SOTA：1) 领域增量VideoQA：平均准确率51.6%，遗忘率-1.8%；2) ViLCo：R@1@0.5为29.6%(MQ)和20.7%(NLQ)，stAP@0.25为18.4%(VQ)；3) 时间增量iVQA：准确率39.5%，遗忘率-1.6%。
- Conclusion: AFD提供了稳定交互中心基底与针对性适应之间的明确、可解释分离，在视频-语言持续学习任务中表现出色，平衡了稳定性和适应性需求。


### [82] [CAR-Net: A Cascade Refinement Network for Rotational Motion Deblurring under Angle Information Uncertainty](https://arxiv.org/abs/2512.00700)
*Ka Chung Lai,Ahmet Cetinkaya*

Main category: cs.CV

TL;DR: CAR-net是一种用于旋转运动模糊图像去模糊的级联细化网络，专门处理半盲场景（仅有模糊角度的噪声信息），通过渐进式细化过程逐步抑制伪影并恢复细节。

- Motivation: 针对旋转运动模糊图像的去模糊问题，特别是在半盲场景下（只有带噪声的旋转模糊角度信息可用），需要一种能够有效处理参数不确定性的去模糊方法。
- Method: 提出CAR-net架构：1）从频域反演获得初始去模糊估计；2）通过一系列细化阶段对当前去模糊图像进行残差校正预测和应用；3）可选角度检测模块可端到端训练以处理参数不确定性。
- Result: 通过合成和真实图像实验验证了该方法的有效性，代码、模型和数据集链接已在GitHub上公开。
- Conclusion: CAR-net能够有效处理旋转运动模糊的半盲去模糊问题，通过渐进式细化过程显著提升去模糊质量，且架构灵活可扩展。


### [83] [Optimizing LVLMs with On-Policy Data for Effective Hallucination Mitigation](https://arxiv.org/abs/2512.00706)
*Chengzhi Yu,Yifan Xu,Yifan Chen,Wenyi Zhang*

Main category: cs.CV

TL;DR: 提出了一种新的幻觉缓解方法，通过幻觉分类器和动态样本重加权DPO算法，显著降低LVLM的幻觉率，使开源模型性能超越GPT-4V

- Motivation: 大型视觉语言模型在多模态任务中表现出色，但幻觉缓解仍是一个关键挑战。现有标注方法会在训练样本中引入额外幻觉，可能增强模型的幻觉模式，需要更有效的解决方案。
- Method: 1) 分析发现on-policy数据显著优于off-policy数据，需要高效可靠的偏好标注；2) 提出训练幻觉分类器提供二元标注，确保后续对齐的样本干净；3) 设计鲁棒的迭代DPO算法，采用动态样本重加权方案
- Result: 在三个基准测试中与8个SOTA基线比较：LLaVA-1.5-7B在MMHalBench上的幻觉率降低50.8%，在Object HalBench上的平均幻觉率降低79.5%；LLaVA-1.5-13B性能甚至超越GPT-4V
- Conclusion: 该方法通过幻觉分类器和动态重加权DPO算法，有效缓解LVLM的幻觉问题，充分挖掘开源模型潜力，在多个基准测试中取得显著效果提升


### [84] [Deep Learning-Based Computer Vision Models for Early Cancer Detection Using Multimodal Medical Imaging and Radiogenomic Integration Frameworks](https://arxiv.org/abs/2512.00714)
*Emmanuella Avwerosuoghene Oghenekaro*

Main category: cs.CV

TL;DR: 深度学习在医学影像分析中实现癌症早期检测，通过多模态影像与放射基因组学融合，实现无创肿瘤基因型和治疗反应预测

- Motivation: 癌症早期检测是现代医疗的关键挑战，延迟诊断显著降低生存率。传统放射学评估存在局限性，需要更精准的检测方法。
- Method: 采用深度学习计算机视觉模型（CNN、Transformer、混合注意力架构），从多模态影像数据（MRI、CT、PET、乳腺摄影、组织病理、超声）中自动提取复杂特征。结合放射基因组学，将定量影像特征与基因组学、转录组学、表观遗传生物标志物融合。
- Result: 深度学习模型超越传统放射学评估，能够识别人眼无法察觉的细微组织异常和肿瘤微环境变化。放射基因组学融合可以无创预测肿瘤基因型、免疫反应、分子亚型和治疗耐药性。
- Conclusion: 深度学习驱动的多模态影像分析与放射基因组学融合为个性化肿瘤学引入了新范式，有望实现更早、更精准的癌症检测和个性化治疗。


### [85] [RS-ISRefiner: Towards Better Adapting Vision Foundation Models for Interactive Segmentation of Remote Sensing Images](https://arxiv.org/abs/2512.00718)
*Deliang Wang,Peng Liu*

Main category: cs.CV

TL;DR: RS-ISRefiner：针对遥感图像的点击式交互分割框架，通过适配器调优和混合注意力机制，在多个遥感数据集上超越现有方法

- Motivation: 现有交互式图像分割方法主要针对自然图像设计，难以泛化到遥感领域，因为遥感图像存在尺度变化、不规则边界和复杂背景等挑战，且标注数据有限、计算开销大
- Method: 提出RS-ISRefiner框架：1）采用适配器调优策略，保留视觉基础模型的通用表示，同时高效学习遥感特定的空间和边界特征；2）混合注意力机制结合卷积局部建模和Transformer全局推理；3）改进的概率图调制方案有效整合历史用户交互
- Result: 在iSAID、ISPRS Potsdam、SandBar、NWPU、LoveDA Urban和WHUBuilding六个遥感数据集上的实验表明，RS-ISRefiner在分割精度、效率和交互成本方面均优于现有最先进的交互分割方法
- Conclusion: RS-ISRefiner框架有效解决了遥感图像交互分割的挑战，具有高泛化性和实用性，适合实际遥感场景中的高质量实例分割任务


### [86] [TrajDiff: End-to-end Autonomous Driving without Perception Annotation](https://arxiv.org/abs/2512.00723)
*Xingtai Gui,Jianbo Zhao,Wencheng Han,Jikai Wang,Jiahao Gong,Feiyang Tan,Cheng-zhong Xu,Jianbing Shen*

Main category: cs.CV

TL;DR: TrajDiff：一种无需感知标注的端到端自动驾驶轨迹生成框架，通过轨迹导向的BEV条件扩散模型直接生成多样且合理的轨迹。

- Motivation: 当前端到端自动驾驶系统依赖辅助感知任务，但感知标注成本高昂。需要开发无需感知标注的规划范式，降低系统开发成本。
- Method: 提出TrajDiff框架：1）构建高斯BEV热图目标捕获驾驶模式；2）设计轨迹导向BEV编码器提取TrajBEV特征；3）引入轨迹导向BEV扩散变换器（TB-DiT），利用自车状态和TrajBEV特征直接生成轨迹。
- Result: 在NAVSIM基准测试中达到87.5 PDMS，在所有无需标注方法中达到SOTA。通过数据扩展提升至88.5 PDMS，与先进感知方法相当。
- Conclusion: TrajDiff实现了完全无需感知标注的端到端自动驾驶轨迹生成，在性能上与感知方法相当，同时探索了数据扩展的潜力。


### [87] [Multi-GRPO: Multi-Group Advantage Estimation for Text-to-Image Generation with Tree-Based Trajectories and Multiple Rewards](https://arxiv.org/abs/2512.00743)
*Qiang Lyu,Zicong Chen,Chongxiao Wang,Haolin Shi,Shibo Gao,Ran Piao,Youwei Zeng,Jianlou Si,Fei Ding,Jing Li,Chun Pong Lau,Weiqiang Wang*

Main category: cs.CV

TL;DR: Multi-GRPO：一种改进的文本到图像模型对齐方法，通过多组优势估计框架解决现有GRPO方法的共享信用分配和奖励混合问题

- Motivation: 现有GRPO方法存在两个关键限制：1）共享信用分配问题，轨迹级优势均匀应用于所有时间步，无法准确估计早期去噪步骤的潜力；2）奖励混合问题，预定义权重组合多目标奖励导致梯度不稳定和冲突更新
- Method: 提出Multi-GRPO框架，包含两种正交分组机制：1）基于树的时间分组，受蒙特卡洛树搜索启发，在早期去噪步骤分支形成时间组，通过后代叶子准确估计早期步骤优势；2）基于奖励的分组，独立计算每个奖励函数的优势后再聚合，解耦冲突信号
- Result: 在单奖励PickScore-25k和多目标OCR-Color-10基准测试中，Multi-GRPO实现了优越的稳定性和对齐性能，有效平衡冲突目标
- Conclusion: Multi-GRPO通过多组优势估计框架解决了GRPO方法的局限性，在文本到图像模型对齐中表现出更好的稳定性和性能，并创建了OCR-Color-10数据集用于多目标对齐评估


### [88] [Joint Multi-scale Gated Transformer and Prior-guided Convolutional Network for Learned Image Compression](https://arxiv.org/abs/2512.00744)
*Zhengxin Chen,Xiaohai He,Tingrong Zhang,Shuhua Xiong,Chao Ren*

Main category: cs.CV

TL;DR: 提出MGTPCN图像压缩网络，结合多尺度门控Transformer和先验引导卷积，在性能与复杂度间取得更好平衡

- Motivation: 学习型图像压缩方法通过非线性变换编码超越传统编码器，但卷积层和Swin-T块的表示能力仍有提升空间，需要增强局部和非局部特征提取能力
- Method: 1) 提出先验引导卷积(PGConv)，使用非对称卷积增强骨架元素，差异卷积提取高频信息，并通过重参数化降低计算复杂度；2) 提出多尺度门控Transformer(MGT)，使用不同膨胀率的膨胀窗口多头自注意力块和不同核大小的深度卷积层提取多尺度特征，引入门机制增强非线性；3) 将两者结合为MGTPCN网络
- Result: 实验结果表明MGTPCN在性能与复杂度权衡方面超越了现有最先进算法
- Conclusion: 提出的MGTPCN通过学习型图像压缩方法，通过增强局部和非局部特征提取能力，实现了更好的压缩性能与复杂度平衡


### [89] [Probabilistic Modeling of Multi-rater Medical Image Segmentation for Diversity and Personalization](https://arxiv.org/abs/2512.00748)
*Ke Liu,Shangde Gao,Yichao Fu,Shangqi Gao,Chunhua Shen*

Main category: cs.CV

TL;DR: ProSeg提出了一种概率建模方法，用于多标注者医学图像分割，同时实现多样化和个性化分割，通过建模专家标注偏好和图像边界模糊性来生成既多样又个性化的分割结果。

- Motivation: 医学图像分割面临数据不确定性的挑战，包括医学扫描中的模糊边界和诊断中的观察者间差异。现有模型要么只能生成缺乏专家特异性的多样化分割，要么只能产生简单复制单个标注者的个性化输出，无法同时满足多样化和个性化需求。
- Method: 提出ProSeg概率建模框架，引入两个潜在变量分别建模专家标注偏好和图像边界模糊性。通过变分推断获得这些变量的条件概率分布，然后从这些分布中采样生成分割输出，实现同时多样化和个性化。
- Result: 在鼻咽癌数据集（NPC）和肺结节数据集（LIDC-IDRI）上的广泛实验表明，ProSeg达到了新的最先进性能，能够提供既多样又专家个性化的分割结果。
- Conclusion: ProSeg成功解决了多标注者医学图像分割中同时实现多样化和个性化的挑战，通过概率建模方法有效捕捉了专家标注偏好和图像边界模糊性，为医学图像分割提供了更准确和实用的解决方案。


### [90] [Charts Are Not Images: On the Challenges of Scientific Chart Editing](https://arxiv.org/abs/2512.00752)
*Shawn Li,Ryan Rossi,Sungchul Kim,Sunav Choudhary,Franck Dernoncourt,Puneet Mathur,Zhengzhong Tu,Yue Zhao*

Main category: cs.CV

TL;DR: FigEdit是一个用于科学图表编辑的大规模基准测试，包含3万多个样本，涵盖10种图表类型和复杂编辑指令，揭示了当前生成模型在结构化图表编辑上的不足。

- Motivation: 现有生成模型（如扩散和自回归模型）在自然图像编辑上表现出色，但应用于科学图表时存在根本性不匹配：图表不是像素排列而是结构化数据的视觉表示，遵循图形语法。图表编辑本质上是结构化转换问题，而非像素操作任务。
- Method: 引入FigEdit基准测试，基于真实数据构建，包含30,000多个样本，涵盖10种图表类型和丰富的复杂编辑指令。基准分为五个渐进挑战性任务：单编辑、多编辑、对话式编辑、视觉引导编辑和风格迁移。
- Result: 评估多个最先进模型发现它们在科学图表编辑上表现不佳，无法处理所需的结构化转换。分析还表明传统评估指标（如SSIM、PSNR）在捕捉图表编辑语义正确性方面存在局限性。
- Conclusion: FigEdit基准揭示了像素级操作的深刻局限性，为开发和评估未来结构感知模型提供了坚实基础。通过发布该基准，旨在促进结构感知图表编辑的系统性进展，为公平比较提供共同基础，并鼓励理解科学图表视觉和语义层的模型研究。


### [91] [Seeing the Wind from a Falling Leaf](https://arxiv.org/abs/2512.00762)
*Zhiyuan Gao,Jiageng Mao,Hong-Xing Yu,Haozhe Lou,Emily Yue-Ting Jia,Jernej Barbic,Jiajun Wu,Yue Wang*

Main category: cs.CV

TL;DR: 提出一个端到端可微的逆向图形框架，能够从视频中恢复不可见的物理力场（如风场），通过联合建模物体几何、物理属性和相互作用，实现从物体运动反推力场表示。

- Motivation: 计算机视觉中长期目标是建模视频中的运动，但运动背后的表示——即导致物体变形和移动的不可见物理相互作用——在很大程度上尚未被探索。本文研究如何从视觉观察中恢复这些不可见的力，例如通过观察叶子落地来估计风场。
- Method: 开发了一个端到端可微的逆向图形框架，能够从视频中联合建模物体几何、物理属性和相互作用。通过反向传播，该方法能够从物体运动中恢复力场表示。
- Result: 在合成和真实世界场景中验证了该方法，结果表明能够从视频中推断出合理的力场。还展示了该方法在基于物理的视频生成和编辑方面的潜在应用。
- Conclusion: 该方法为理解和建模像素背后的物理过程提供了新思路，有助于弥合视觉与物理学之间的鸿沟，为物理感知的计算机视觉开辟了新方向。


### [92] [The Outline of Deception: Physical Adversarial Attacks on Traffic Signs Using Edge Patches](https://arxiv.org/abs/2512.00765)
*Haojie Jia,Te Hu,Haowen Li,Long Jin,Chongshi Xin,Yuchi Yao,Jiarui Xiao*

Main category: cs.CV

TL;DR: TESP-Attack：一种基于边缘对齐掩码和U-Net生成器的隐蔽对抗补丁方法，针对交通标志分类系统，在保持高攻击成功率的同时实现视觉隐蔽性

- Motivation: 当前物理对抗攻击缺乏隐蔽性，大多数方法在交通标志中心区域添加扰动，产生视觉上明显的模式，容易被人类观察者检测到，限制了实际应用。V2X网络中误分类可能传播并导致级联故障，影响整体交通流和系统稳定性。
- Method: 基于人类视觉注意力主要关注交通标志中心区域的观察，使用实例分割生成边缘对齐掩码以符合标志形状特征。采用U-Net生成器制作对抗补丁，通过颜色和纹理约束以及频域分析进行优化，实现与背景环境的无缝融合。
- Result: 该方法在不同架构的交通标志分类模型上表现出色，在有限查询预算下攻击成功率超过90%。具有强大的跨模型可迁移性，在不同角度和距离下保持稳定的现实世界性能。
- Conclusion: TESP-Attack通过结合边缘对齐掩码和视觉隐蔽优化，实现了既高效又隐蔽的交通标志对抗攻击，解决了当前物理攻击缺乏隐蔽性的关键限制，具有实际应用潜力。


### [93] [EAG3R: Event-Augmented 3D Geometry Estimation for Dynamic and Extreme-Lighting Scenes](https://arxiv.org/abs/2512.00771)
*Xiaoshan Wu,Yifei Yu,Xiaoyang Lyu,Yihua Huang,Bo Wang,Baoheng Zhang,Zhongrui Wang,Xiaojuan Qi*

Main category: cs.CV

TL;DR: EAG3R：结合RGB和事件流进行鲁棒3D几何估计的新框架，在动态低光场景中显著优于RGB-only方法

- Motivation: 现有RGB-only方法在动态物体和极端光照条件下表现不佳，因为传统相机存在固有局限性。需要利用事件流增强几何估计的鲁棒性。
- Method: 基于MonST3R骨干网络，引入：1）Retinex启发的图像增强模块和轻量级事件适配器，带有SNR感知融合机制；2）新颖的事件驱动光度一致性损失，增强时空一致性。
- Result: EAG3R在单目深度估计、相机姿态跟踪和动态重建任务中显著优于最先进的RGB-only基线方法，无需在夜间数据上重新训练。
- Conclusion: 通过融合RGB和事件流，EAG3R能够在具有挑战性的动态低光场景中实现鲁棒的3D几何估计，克服了传统RGB-only方法的局限性。


### [94] [DEJIMA: A Novel Large-scale Japanese Dataset for Image Captioning and Visual Question Answering](https://arxiv.org/abs/2512.00773)
*Toshiki Katsube,Taiga Fukuhara,Kenichiro Ando,Yusuke Mukuta,Kohei Uehara,Tatsuya Harada*

Main category: cs.CV

TL;DR: 构建了日本首个大规模视觉语言数据集DEJIMA（包含3.88M图像-文本对），通过可扩展的流水线实现高质量数据收集，显著提升日本多模态模型性能。

- Motivation: 解决日本视觉语言建模领域高质量大规模数据资源稀缺的问题。现有数据集要么规模小，要么通过翻译或人工标注，缺乏日本文化背景的真实性和自然性。
- Method: 开发了可扩展、可复现的流水线：大规模网络收集→严格过滤/去重→基于目标检测的证据提取→在接地约束下使用LLM进行精炼。构建了两个资源：图像-字幕数据集（DEJIMA-Cap）和VQA数据集（DEJIMA-VQA）。
- Result: 创建了包含3.88M图像-文本对的数据集，远超现有日本V&L数据集规模。人工评估显示DEJIMA在"日本性"和语言自然性上显著优于翻译或人工标注数据集，事实正确性与人工标注语料相当。图像特征分布分析证实其广泛覆盖日本特色视觉领域。
- Conclusion: 文化接地的大规模资源对提升模型性能至关重要。基于DEJIMA训练的模型在多个日本多模态基准测试中表现一致提升。所有数据源和模块均允许商业使用，公开发布数据集和元数据以促进日本V&L建模的研究和工业应用。


### [95] [PolarGS: Polarimetric Cues for Ambiguity-Free Gaussian Splatting with Accurate Geometry Recovery](https://arxiv.org/abs/2512.00794)
*Bo Guo,Sijia Wen,Yifan Zhao,Jia Li,Zhiming Zheng*

Main category: cs.CV

TL;DR: PolarGS：利用偏振光学先验增强3D高斯泼溅的表面重建，解决反射和无纹理区域的模糊性问题

- Motivation: 现有3DGS表面重建方法在反射和无纹理等光度模糊区域性能下降，因为这些区域的不可靠线索破坏了光度一致性并阻碍几何估计。反射光通常具有部分偏振特性，能够揭示表面方向，因此偏振可作为光度线索的光学补充来解决这些模糊性。
- Method: 提出PolarGS，包含两个互补模块：1）偏振引导的光度校正策略，通过线性偏振度识别反射区域，并使用颜色细化图优化反射高斯；2）偏振增强的高斯致密化机制，将角度和线性偏振度集成到基于PatchMatch的深度补全过程中，实现新高斯投影和融合。
- Result: PolarGS是框架无关的，相比最先进方法实现了更优的几何精度，特别是在反射和无纹理区域。
- Conclusion: 偏振作为光学先验能有效解决3DGS中的光度模糊问题，PolarGS通过偏振引导的校正和致密化机制显著提升了表面重建的完整性和准确性。


### [96] [CircleFlow: Flow-Guided Camera Blur Estimation using a Circle Grid Target](https://arxiv.org/abs/2512.00796)
*Jiajian He,Enjie Hu,Shiqi Chen,Tianchen Qiu,Huajun Feng,Zhihai Xu,Yueting Chen*

Main category: cs.CV

TL;DR: CircleFlow：一种通过流引导边缘定位实现高保真PSF估计的框架，利用圆形网格目标编码各向异性和空间变化的PSF，通过联合优化实现精确的模糊表征。

- Motivation: 点扩散函数（PSF）是连接真实场景与捕获信号的基本描述符，表现为相机模糊。准确的PSF估计对于光学表征和计算视觉都至关重要，但由于强度反卷积的固有模糊性和不适定性，这仍然是一个挑战。
- Method: CircleFlow采用结构化捕获，通过成像圆形网格目标编码局部各向异性和空间变化的PSF，利用目标的二值亮度先验解耦图像和核估计。然后通过光学流引导的初始化二值结构亚像素对齐重建潜在清晰图像，而PSF建模为能量约束的隐式神经表示。两者在去马赛克感知的可微分框架内联合优化。
- Result: 在模拟和真实数据上的广泛实验表明，CircleFlow实现了最先进的准确性和可靠性，验证了其在实际PSF校准中的有效性。
- Conclusion: CircleFlow通过流引导边缘定位实现了高保真PSF估计，为光学表征和计算视觉提供了物理一致且鲁棒的PSF校准方法。


### [97] [Thinking with Drafts: Speculative Temporal Reasoning for Efficient Long Video Understanding](https://arxiv.org/abs/2512.00805)
*Pengfei Hu,Meng Cao,Yingyao Wang,Yi Wang,Jiahua Dong,Jun Song,Yu Cheng,Bo Zheng,Xiaodan Liang*

Main category: cs.CV

TL;DR: SpecTemp：基于强化学习的推测性时序推理框架，通过双模型协作设计解耦时序感知与推理，显著提升长视频理解效率

- Motivation: 现有"thinking-with-frames"范式虽然提升了视频多模态大语言模型的推理能力，但由于多模态上下文不断增长和冗余，存在显著的效率瓶颈。需要平衡长视频理解中的效率与准确性。
- Method: 提出SpecTemp框架：1）轻量级草稿MLLM快速探索密集采样时序区域并提议关键帧；2）强大目标MLLM专注于时序推理并验证草稿提议，迭代优化注意力直至收敛；3）构建SpecTemp-80K数据集，包含粗粒度证据跨度和细粒度帧级证据的双层标注。
- Result: 在多个视频理解基准测试中，SpecTemp不仅保持了竞争力的准确性，而且相比现有thinking-with-frames方法显著加速了推理过程。
- Conclusion: SpecTemp通过模仿人脑协作路径的双模型设计，有效解决了长视频理解中的效率瓶颈问题，实现了效率与准确性的平衡，为视频多模态大语言模型的发展提供了新思路。


### [98] [IRPO: Boosting Image Restoration via Post-training GRPO](https://arxiv.org/abs/2512.00814)
*Haoxuan Xu. Yi Liu,Boyuan Jiang,Jinlong Peng,Donghao Luo,Xiaobin Hu,Shuicheng Yan,Haoang Li*

Main category: cs.CV

TL;DR: IRPO提出了一种基于GRPO的低层视觉后训练范式，通过数据筛选和奖励建模解决图像恢复中的过平滑和泛化问题，在多个基准测试中达到SOTA性能。

- Motivation: 现有图像恢复方法依赖像素级硬拟合真实图像，存在过平滑和泛化能力差的问题。后训练范式在高层生成任务中表现优异，但在低层视觉领域尚未充分探索。
- Method: 提出IRPO低层GRPO后训练范式：1）数据筛选原则：从预训练阶段选择表现不佳的样本进行后训练；2）三层奖励系统：通用奖励（结构保真度）、专家奖励（基于Qwen-VL的感知对齐）、恢复奖励（任务特定低层质量）。
- Result: 在6个域内和5个域外低层基准测试中，IRPO在多种退化类型上达到SOTA，相比AdaIR基线在域内任务提升0.83dB，域外任务提升3.43dB。
- Conclusion: IRPO成功将后训练范式应用于低层视觉任务，通过创新的数据筛选和奖励建模策略，显著提升了图像恢复的性能和泛化能力。


### [99] [PanFlow: Decoupled Motion Control for Panoramic Video Generation](https://arxiv.org/abs/2512.00832)
*Cheng Zhang,Hanwen Liang,Donny Y. Chen,Qianyi Wu,Konstantinos N. Plataniotis,Camilo Cruz Gambardella,Jianfei Cai*

Main category: cs.CV

TL;DR: PanFlow：一种利用全景球面特性解耦相机旋转与光流条件的新方法，通过球面噪声扭曲策略提升边界一致性，在大型动态运动控制上优于现有方法

- Motivation: 现有全景视频生成方法缺乏显式运动控制，难以处理大规模复杂运动，需要更精确的动态运动控制方案
- Method: 利用全景球面特性解耦相机旋转与输入光流条件，引入球面噪声扭曲策略确保全景边界运动一致性，构建大规模带姿态和光流标注的运动丰富数据集
- Result: 在运动保真度、视觉质量和时间一致性方面显著优于现有方法，支持运动转移和视频编辑等应用
- Conclusion: PanFlow通过球面解耦和噪声扭曲策略有效解决了全景视频生成中的大规模动态运动控制问题，为虚拟现实和沉浸式媒体提供了更好的解决方案


### [100] [AFRAgent : An Adaptive Feature Renormalization Based High Resolution Aware GUI agent](https://arxiv.org/abs/2512.00846)
*Neeraj Anand,Rishabh Jain,Sohan Patnaik,Balaji Krishnamurthy,Mausoom Sarkar*

Main category: cs.CV

TL;DR: AFRAgent是一个基于instruct-BLIP的多模态架构，通过自适应特征重归一化技术增强图像嵌入，在移动UI自动化任务中实现了最先进性能，模型尺寸仅为最接近竞争对手的四分之一。

- Motivation: 移动UI自动化需求日益增长，现有视觉语言模型在GUI自动化中存在两个主要问题：1) 由于视觉编码器特征空间信息有限，难以准确识别控件和确定操作；2) 高性能模型通常体积庞大，需要大量训练且推理延迟高。
- Method: 提出AFRAgent，基于instruct-BLIP的多模态架构，引入自适应特征重归一化技术（基于token级别的仿射变换），有效增强低分辨率图像嵌入并融合高分辨率细节，提升LLM管道中的图像表示质量。
- Result: 在Meta-GUI和AITW基准测试中建立了新的最先进基线，性能优于现有方法，同时模型尺寸小于最接近竞争对手的四分之一。
- Conclusion: AFRAgent通过创新的自适应特征重归一化技术，在保持小模型尺寸的同时实现了GUI自动化的最先进性能，为移动UI自动化提供了高效解决方案。


### [101] [Smol-GS: Compact Representations for Abstract 3D Gaussian Splatting](https://arxiv.org/abs/2512.00850)
*Haishan Wang,Mohammad Hassan Vali,Arno Solin*

Main category: cs.CV

TL;DR: Smol-GS是一种用于3D高斯泼溅的新型紧凑表示学习方法，通过递归体素层次结构和泼溅特征编码实现高压缩比，在保持渲染质量的同时达到最先进的压缩效果。

- Motivation: 3D高斯泼溅（3DGS）需要大量存储空间，限制了其在资源受限环境中的应用。需要开发既能保持高质量渲染又能大幅压缩场景表示的方法。
- Method: 采用递归体素层次结构捕获泼溅坐标，同时使用泼溅特征存储颜色、透明度、变换和材质属性等抽象信息，将空间和语义信息集成到高效的三维编码中。
- Result: 在标准基准测试中实现了最先进的压缩效果，将3D场景压缩数个数量级而不损失灵活性，同时保持高渲染质量。
- Conclusion: Smol-GS提供了一种高效紧凑的3D场景表示方法，不仅保持视觉保真度，其离散表示还可作为导航、规划和更广泛3D场景理解等下游任务的基础。


### [102] [TAP-CT: 3D Task-Agnostic Pretraining of Computed Tomography Foundation Models](https://arxiv.org/abs/2512.00872)
*Tim Veenboer,George Yiasemis,Eric Marcus,Vivien Van Veldhuizen,Cees G. M. Snoek,Jonas Teuwen,Kevin B. W. Groot Lipman*

Main category: cs.CV

TL;DR: TAP-CT：一种用于3D CT扫描的任务无关基础模型，通过自监督预训练生成无需微调的稳健特征表示

- Motivation: 现有医学基础模型通常需要大量微调或依赖资源密集的解码器训练，且编码器预训练目标偏向特定任务，需要一种任务无关、只需特征提取即可使用的强大基础模型
- Method: 将Vision Transformers和DINOv2适配到3D CT数据，修改补丁嵌入、位置编码和体积增强，实现可扩展的自监督预训练，在105K CT扫描上训练
- Result: 大规模3D预训练产生稳定、鲁棒的冻结表示，在下游任务中表现出强大的泛化能力，无需额外微调
- Conclusion: TAP-CT为医学影像研究提供了强大的低资源基准，所有预训练模型、实验配置和基准代码将开源以促进透明度和可重复性


### [103] [Neural Discrete Representation Learning for Sparse-View CBCT Reconstruction: From Algorithm Design to Prospective Multicenter Clinical Evaluation](https://arxiv.org/abs/2512.00873)
*Haoshen Wang,Lei Chen,Wei-Hua Zhang,Linxia Wu,Yong Luo,Zengmao Wang,Yuan Xiong,Chengcheng Zhu,Wenjuan Tang,Xueyi Zhang,Wei Zhou,Xuhua Duan,Lefei Zhang,Gao-Jun Teng,Bo Du,Huangxuan Zhao*

Main category: cs.CV

TL;DR: DeepPriorCBCT是一种三阶段深度学习框架，可将CBCT辐射剂量降至常规的1/6，在大型多中心数据集上验证，并通过前瞻性临床试验证明其临床适用性。

- Motivation: CBCT引导穿刺已成为胸廓肿瘤诊疗的常规方法，但辐射暴露会增加继发性恶性肿瘤风险。现有低剂量CBCT策略缺乏大规模多中心验证和前瞻性临床评估。
- Method: 提出DeepPriorCBCT三阶段深度学习框架，使用12个中心的4102名患者8675次CBCT扫描进行开发和验证，并进行前瞻性交叉试验（NCT07035977）评估临床适用性。
- Result: 11名医师评估显示重建图像与原始扫描无法区分；诊断性能和图像质量与标准重建算法相当；前瞻性试验中5名放射科医师和25名介入医师均未发现显著差异；辐射暴露降至常规的1/6。
- Conclusion: DeepPriorCBCT能够在稀疏采样条件下实现高质量CBCT重建，显著降低术中辐射风险，具有临床适用性。


### [104] [Feed-Forward 3D Gaussian Splatting Compression with Long-Context Modeling](https://arxiv.org/abs/2512.00877)
*Zhening Liu,Rui Song,Yushi Huang,Yingdong Hu,Xinjie Zhang,Jiawei Shao,Zehong Lin,Jun Zhang*

Main category: cs.CV

TL;DR: 提出一种新型前馈式3D高斯泼溅压缩框架，通过大规模上下文结构和精细空间-通道自回归熵模型，实现20倍压缩比和SOTA性能

- Motivation: 3D高斯泼溅(3DGS)作为革命性3D表示方法，但其庞大的数据规模限制了广泛应用。现有前馈压缩方法难以建模长程空间依赖关系，因为变换编码网络的感受野有限且熵模型上下文容量不足。
- Method: 1) 基于Morton序列化构建包含数千个高斯的大规模上下文结构；2) 设计精细空间-通道自回归熵模型充分利用扩展上下文；3) 开发基于注意力的变换编码模型，通过聚合广泛邻域高斯特征提取信息丰富的潜在先验。
- Result: 实现了20倍压缩比，在前馈推理中达到通用编解码器中的最先进性能。
- Conclusion: 该方法通过有效建模长程相关性，实现了高度紧凑且通用的3D表示，解决了3DGS数据规模过大的问题，推动了该技术的广泛应用。


### [105] [Quantum-Inspired Spectral Geometry for Neural Operator Equivalence and Structured Pruning](https://arxiv.org/abs/2512.00880)
*Haijian Shao,Wei Liu,Xing Deng*

Main category: cs.CV

TL;DR: 提出量子启发的几何框架，将神经算子表示为布洛赫超球面上的归一化奇异值谱，建立谱与功能的等价关系，用于跨模态跨架构的算子替换和结构化剪枝。

- Motivation: 多模态智能在资源受限的异构硬件上快速发展，面临多模态特征异构性、动态场景实时性要求、硬件特定算子冗余等瓶颈问题。
- Method: 引入量子启发的几何框架，将算子表示为布洛赫超球面上的归一化奇异值谱；证明谱与功能的等价定理；提出量子度量驱动的功能冗余图和一次性结构化剪枝方法。
- Result: 控制模拟验证了所提度量优于幅度和随机基线；大规模多模态变换器和异构硬件（华为昇腾、寒武纪MLU、昆仑芯）的广泛实验验证将在扩展期刊版本中呈现。
- Conclusion: 该工作为跨模态和跨架构的算子可替换性建立了首个严格理论基础，为解决异构硬件上的多模态智能瓶颈提供了新方法。


### [106] [Look, Recite, Then Answer: Enhancing VLM Performance via Self-Generated Knowledge Hints](https://arxiv.org/abs/2512.00882)
*Xisheng Feng*

Main category: cs.CV

TL;DR: 提出"看、背、答"参数高效框架，通过自生成知识提示增强视觉语言模型在专业领域性能，解决推理驱动幻觉问题

- Motivation: 视觉语言模型在精准农业等专业领域存在性能瓶颈，主要由于"推理驱动幻觉"问题——语言先验覆盖视觉感知，以及"模态鸿沟"——视觉嵌入无法有效激活模型中已有的细粒度专业知识
- Method: 提出三阶段框架：1) Look阶段生成客观视觉描述和候选集；2) Recite阶段使用轻量级1.7B路由器将视觉线索转化为针对性查询，触发候选特定参数知识；3) Answer阶段并行证据对齐，在描述和背诵知识间选择最一致标签
- Result: 在AgroBench上取得SOTA结果，杂草识别准确率比Qwen-VL提高23.6%，超越GPT-4o且无需外部搜索开销
- Conclusion: 模块化设计通过将被动感知转化为主动可控的知识检索，有效缓解幻觉问题，为专业领域视觉语言模型应用提供参数高效解决方案


### [107] [HanDyVQA: A Video QA Benchmark for Fine-Grained Hand-Object Interaction Dynamics](https://arxiv.org/abs/2512.00885)
*Masatoshi Tateno,Gido Kato,Hirokatsu Kataoka,Yoichi Sato,Takuma Yagi*

Main category: cs.CV

TL;DR: 提出了HanDyVQA基准，这是一个细粒度的手-物交互视频问答数据集，包含6种问题类型和11.1K个QA对，用于评估模型对手-物交互动态的理解能力。

- Motivation: 现有手-物交互基准要么关注操作本身，要么关注粗略的结果效果，缺乏对HOI底层动态的细粒度时空推理能力评估。
- Method: 构建了包含6种互补问题类型（动作、过程、物体、位置、状态变化、物体部件）的HanDyVQA基准，总计11.1K个多项选择QA对，并包含10.3K个分割掩码用于物体和部件级推理评估。
- Result: 最佳模型Gemini-2.5-Pro仅达到73%平均准确率，远低于人类表现（97%）。分析显示模型在空间关系、运动和部件级几何理解方面仍面临挑战。
- Conclusion: HanDyVQA基准揭示了当前视频基础模型在理解手-物交互动态方面的局限性，将显式HOI相关线索整合到视觉特征中可以提升性能，为开发更深入理解HOI动态的未来模型提供了见解。


### [108] [Multilingual Training-Free Remote Sensing Image Captioning](https://arxiv.org/abs/2512.00887)
*Carlos Rebelo,Gil Rocha,João Daniel Silva,Bruno Martins*

Main category: cs.CV

TL;DR: 提出首个免训练多语言遥感图像描述方法，基于检索增强提示，通过SigLIP2编码器检索相关描述和少样本示例，结合图基重排序策略，在10种语言上取得与全监督英语系统相当的性能。

- Motivation: 现有遥感图像描述方法依赖大规模标注数据集且主要针对英语，限制了全球适用性。需要开发免训练、多语言的方法来提升包容性和可扩展性。
- Method: 提出基于检索增强提示的免训练方法：1) 使用领域适应的SigLIP2编码器从数据存储中检索相关描述和少样本示例；2) 探索两种变体：仅文本提示的多语言LLM生成，以及联合处理图像和提示的VLM；3) 引入基于PageRank的图基重排序策略提升检索内容连贯性。
- Result: 在4个基准数据集、10种语言上的实验表明：1) 方法性能与全监督英语系统相当；2) PageRank重排序带来高达35%的性能提升；3) VLM生成视觉基础但词汇多样的描述，LLM在BLEU和CIDEr得分上更强；4) 直接生成目标语言描述优于翻译策略。
- Conclusion: 该工作首次系统评估了多语言免训练遥感图像描述方法，推动了更具包容性和可扩展性的多模态地球观测系统发展，为全球应用提供了有效解决方案。


### [109] [Accelerating Streaming Video Large Language Models via Hierarchical Token Compression](https://arxiv.org/abs/2512.00891)
*Yiyu Wang,Xuyang Liu,Xiyan Gui,Xinying Lin,Boxue Yang,Chenfei Liao,Tailai Chen,Linfeng Zhang*

Main category: cs.CV

TL;DR: STC是一个用于流式视频大语言模型的即插即用分层框架，通过缓存相似帧特征和剪枝冗余视觉token来加速处理，在保持高准确率的同时显著降低延迟。

- Motivation: 流式视频大语言模型在处理连续视频流时面临计算成本高的问题，主要瓶颈在于ViT编码阶段对时间相似帧的冗余处理，以及LLM预填充阶段token序列过长导致的延迟和内存开销。
- Method: 提出STC框架，包含两个token级加速器：1) STC-Cacher：通过缓存和重用时间相似帧的特征来减少ViT编码开销；2) STC-Pruner：在视觉token进入LLM前压缩序列，基于空间和时间相关性保留最显著的token。
- Result: 在4个基线流式VideoLLM和5个基准测试上的实验表明，STC优于其他压缩方法。在ReKV框架上保持99%准确率的同时，将ViT编码延迟降低24.5%，LLM预填充延迟降低45.3%。
- Conclusion: STC是一个有效的流式视频大语言模型加速框架，通过分层token压缩策略在保持模型性能的同时显著提升处理效率，解决了流式视频场景下的计算瓶颈问题。


### [110] [SwiftVLA: Unlocking Spatiotemporal Dynamics for Lightweight VLA Models at Minimal Overhead](https://arxiv.org/abs/2512.00903)
*Chaojun Ni,Cheng Chen,Xiaofeng Wang,Zheng Zhu,Wenzhao Zheng,Boyuan Wang,Tianrun Chen,Guosheng Zhao,Haoyun Li,Zhehao Dong,Qiang Zhang,Yun Ye,Yang Wang,Guan Huang,Wenjun Mei*

Main category: cs.CV

TL;DR: SwiftVLA是一种高效的VLA架构，通过4D视觉几何变换器和融合令牌增强紧凑模型，在保持设计效率的同时提升时空推理能力，在边缘设备上实现高性能。

- Motivation: 现有基于预训练视觉语言模型（VLM）构建的VLA模型参数量大，实用性受限；轻量级VLM虽然参数少但牺牲了时空推理能力；现有方法即使加入3D输入也依赖大型VLM且缺乏时间维度理解。
- Method: 1) 使用预训练的4D视觉几何变换器（带时间缓存）从2D图像提取4D特征；2) 引入融合令牌（Fusion Tokens），通过未来预测目标训练生成统一表示；3) 采用掩码重构策略，训练VLA重构被掩码的4D输入，使VLM学习有效4D表示，推理时可丢弃4D分支。
- Result: 在真实和模拟环境中，SwiftVLA超越轻量级基线，性能媲美参数量7倍大的VLA模型，在边缘设备上实现相当性能的同时速度快18倍，内存占用减少12倍。
- Conclusion: SwiftVLA通过创新的4D特征提取、融合令牌和掩码重构策略，成功解决了轻量级VLA模型的时空推理限制，实现了高效实用的边缘部署。


### [111] [Hierarchical Semantic Alignment for Image Clustering](https://arxiv.org/abs/2512.00904)
*Xingyu Zhu,Beier Zhu,Yunfan Li,Junfeng Fang,Shuo Wang,Kesen Zhao,Hanwang Zhang*

Main category: cs.CV

TL;DR: CAE是一种无需训练的图像聚类方法，通过结合名词级概念和描述级语义，利用最优传输对齐图像特征与文本语义，显著提升聚类性能。

- Motivation: 现有方法使用名词作为外部语义知识，但忽略了名词的固有歧义性，这会扭曲语义表示并降低聚类质量。需要解决名词歧义问题，同时利用更丰富的语义信息。
- Method: 提出分层语义对齐方法CAE：1）从WordNet选择相关名词，从字幕数据集选择描述，构建与图像特征对齐的语义空间；2）通过最优传输将图像特征与选定的名词和描述对齐，获得更具判别性的语义空间；3）结合增强的语义特征和图像特征进行聚类。
- Result: 在8个数据集上的广泛实验证明该方法有效，在ImageNet-1K数据集上，准确率比最先进的无训练方法提升4.2%，调整兰德指数提升2.9%。
- Conclusion: CAE通过结合名词级概念和描述级语义，有效解决了名词歧义问题，以无需训练的方式显著提升了图像聚类性能。


### [112] [TalkingPose: Efficient Face and Gesture Animation with Feedback-guided Diffusion Model](https://arxiv.org/abs/2512.00909)
*Alireza Javanmardi,Pragati Jaiswal,Tewodros Amberbir Habtegebrial,Christen Millerdurai,Shaoxiang Wang,Alain Pagani,Didier Stricker*

Main category: cs.CV

TL;DR: TalkingPose是一个基于扩散模型的框架，专门用于生成长时间、时序一致的人体上半身动画，通过反馈驱动机制解决现有方法在长视频生成中的计算和内存限制问题。

- Motivation: 现有扩散模型在角色驱动动画方面取得了进展，但生成时序一致的长视频内容仍然具有挑战性。现有方法受计算和内存限制，通常只在短视频片段上训练，限制了其在长视频生成中的潜力。
- Method: 提出TalkingPose框架：1) 利用驱动帧精确捕捉面部和手部表情动作，通过稳定扩散主干网络无缝转移到目标演员；2) 引入基于图像扩散模型的反馈驱动机制，确保连续运动和时序一致性；3) 该机制无需额外计算成本或二次训练阶段，可实现无限时长动画生成。
- Result: 1) 提出了专门用于人体上半身动画生成的新框架；2) 引入了反馈驱动机制解决长视频时序一致性问题；3) 创建了大规模数据集作为人体上半身动画的新基准。
- Conclusion: TalkingPose通过创新的反馈驱动机制解决了长视频动画生成的时序一致性问题，能够生成无限时长的连贯动画，同时引入了新的大规模数据集推动该领域发展。


### [113] [Dual-Projection Fusion for Accurate Upright Panorama Generation in Robotic Vision](https://arxiv.org/abs/2512.00911)
*Yuhao Shan,Qianyi Yuan,Jingguo Liu,Shigang Li,Jianfeng Li,Tong Chen*

Main category: cs.CV

TL;DR: 提出双流角度感知生成网络，联合估计相机倾角并重建直立全景图像，通过CNN和ViT分支融合局部几何与全局上下文，在SUN360和M3D数据集上表现优于现有方法。

- Motivation: 全景相机在机器人视觉中很重要，但机器人姿态不稳定导致非直立全景图像会阻碍下游任务。传统IMU校正方法存在漂移和外部干扰问题，而基于视觉的方法提供了有前景的替代方案。
- Method: 提出双流角度感知生成网络：CNN分支从等距柱状投影提取局部几何结构，ViT分支从立方体贴图投影捕获全局上下文线索，通过双投影自适应融合模块对齐空间特征。还引入高频增强块、循环填充和通道注意力机制来保持360°连续性并提高几何敏感性。
- Result: 在SUN360和M3D数据集上的实验表明，该方法在倾角估计和直立全景生成方面均优于现有方法。消融研究进一步验证了每个模块的贡献，并突出了两个任务之间的协同作用。
- Conclusion: 该研究提出的双流角度感知生成网络有效解决了非直立全景图像的校正问题，通过融合局部几何和全局上下文信息，在倾角估计和图像重建方面取得了优异性能，为机器人视觉中的全景图像处理提供了有效解决方案。


### [114] [ForamDeepSlice: A High-Accuracy Deep Learning Framework for Foraminifera Species Classification from 2D Micro-CT Slices](https://arxiv.org/abs/2512.00912)
*Abdelghafour Halimi,Ali Alibrahim,Didier Barradas-Bautista,Ronell Sicat,Abdulkader M. Afifi*

Main category: cs.CV

TL;DR: 开发了一个深度学习流水线，使用2D微CT切片自动分类12种有孔虫物种，最终集成模型达到95.64%的测试准确率，并创建了交互式仪表板用于实际部署。

- Motivation: 建立AI辅助的微体古生物学识别新基准，为有孔虫分类研究提供可复现框架，弥合深度学习与应用地球科学之间的差距。
- Method: 使用97个微CT扫描标本创建数据集，采用标本级数据分割防止数据泄漏，评估7种最先进的2D CNN架构进行迁移学习，最终构建ConvNeXt-Large和EfficientNetV2-Small的集成模型。
- Result: 集成模型测试准确率达到95.64%，top-3准确率为99.6%，所有物种的ROC曲线下面积(AUC)为0.998，创建了支持实时切片分类和3D切片匹配的交互式高级仪表板。
- Conclusion: 该研究为AI辅助微体古生物学识别建立了新基准，提供了完全可复现的有孔虫分类框架，成功将深度学习技术应用于地球科学领域。


### [115] [LAHNet: Local Attentive Hashing Network for Point Cloud Registration](https://arxiv.org/abs/2512.00927)
*Wentao Qu,Xiaoshui Huang,Liang Xiao*

Main category: cs.CV

TL;DR: LAHNet提出了一种用于点云配准的局部注意力哈希网络，通过局部注意力机制和分组Transformer捕获合理的远程上下文，使用局部敏感哈希均匀划分点云，并采用交叉窗口策略扩展特征感受野，在室内外基准测试中取得显著配准结果。

- Motivation: 现有基于学习的点云描述符主要关注感知点云的局部信息来生成区分性特征，但合理且更广的感受野对于增强特征区分性至关重要。
- Method: 提出LAHNet，引入具有卷积类算子局部性归纳偏置的局部注意力机制。设计Group Transformer通过局部敏感哈希的线性邻域搜索策略捕获点之间的合理远程上下文，将点云均匀划分为非重叠窗口。采用高效交叉窗口策略进一步扩展特征感受野。基于此有效窗口策略，提出Interaction Transformer通过计算重叠矩阵来增强点云对重叠区域的特征交互。
- Result: LAHNet能够学习到鲁棒且区分性强的特征，在真实世界的室内和室外基准测试中取得了显著的配准结果。
- Conclusion: LAHNet通过局部注意力机制和创新的窗口策略，有效扩展了点云特征的感受野，提升了点云配准的性能，在室内外场景中都表现出色。


### [116] [SceneProp: Combining Neural Network and Markov Random Field for Scene-Graph Grounding](https://arxiv.org/abs/2512.00936)
*Keita Otani,Tatsuya Harada*

Main category: cs.CV

TL;DR: SceneProp：将场景图定位重新表述为马尔可夫随机场中的MAP推理问题，通过全局推理解决复杂视觉查询的定位问题

- Motivation: 现有方法在定位包含多个对象和关系的复杂视觉查询时表现不佳，特别是当查询图变大时性能反而下降，未能充分利用本应使定位更容易的关系信息
- Method: 将场景图定位重新表述为马尔可夫随机场中的最大后验概率推理问题，通过可微分的置信传播算法进行全局推理，找到满足所有约束的图像区域到节点的最优分配
- Result: 在四个基准测试中显著优于先前工作，且随着查询图规模和复杂度的增加，准确率持续提升，首次证明更多关系上下文可以带来更好的定位效果
- Conclusion: SceneProp通过全局推理方法有效解决了复杂场景图定位问题，证明了关系上下文对视觉定位的重要性，为复杂视觉查询的定位提供了新思路


### [117] [Binary-Gaussian: Compact and Progressive Representation for 3D Gaussian Segmentation](https://arxiv.org/abs/2512.00944)
*An Yang,Chenyu Liu,Jun Du,Jianqing Gao,Jia Pan,Jinshui Hu,Baocai Yin,Bing Yin,Cong Liu*

Main category: cs.CV

TL;DR: 提出一种基于3D高斯泼溅的粗到细二进制编码方案，通过二进制到十进制映射将每个高斯特征压缩为单个整数，大幅减少内存使用，并采用渐进训练策略提升细粒度分割性能。

- Motivation: 现有3D-GS分割方法依赖高维类别特征导致内存开销大，细粒度分割面临标签空间拥挤和缺乏稳定多粒度控制机制的问题，需要解决内存效率和分割精度之间的矛盾。
- Method: 1) 粗到细二进制编码方案：将每个高斯的类别表示压缩为单个整数；2) 渐进训练策略：将全景分割分解为独立子任务；3) 不透明度微调：解决光度渲染与语义分割之间的不兼容性。
- Result: 在多个基准测试中达到最先进的分割性能，同时显著减少内存消耗并加速推理。
- Conclusion: 提出的方法有效解决了3D-GS分割中的内存效率和细粒度分割挑战，实现了高性能、低内存消耗的3D场景语义理解。


### [118] [Adaptive Evidential Learning for Temporal-Semantic Robustness in Moment Retrieval](https://arxiv.org/abs/2512.00953)
*Haojian Huang,Kaijing Ma,Jin Chen,Haodong Chen,Zhou Wu,Xianghao Zang,Han Fang,Chao Ban,Hao Sun,Mulin Chen,Zhongjiang He*

Main category: cs.CV

TL;DR: 提出DEMR框架，通过去偏证据学习改进视频时刻检索，解决传统方法在模态不平衡和不确定性估计偏差的问题，显著提升检索准确性和鲁棒性。

- Motivation: 传统时刻检索方法使用预训练模型，难以处理细粒度信息和确定性推理，在复杂或模糊时刻对齐方面存在困难。现有方法缺乏对复杂视频场景的适应性，且证据回归方法存在模态不平衡和不确定性估计偏差问题。
- Method: 提出DEMR框架：1) 使用反射翻转融合(RFF)块进行跨模态对齐；2) 引入查询重构任务增强文本敏感性；3) 设计几何正则器(Geom-regularizer)优化不确定性预测，实现与困难时刻的自适应对齐。
- Result: 在标准数据集和去偏数据集ActivityNet-CD、Charades-CD上进行了广泛测试，在有效性、鲁棒性和可解释性方面均取得显著提升，证明了该方法在时刻检索中的优越性。
- Conclusion: DEMR框架通过去偏证据学习解决了时刻检索中的模态不平衡和不确定性估计偏差问题，为时序语义鲁棒性提供了有前景的解决方案，代码已开源。


### [119] [Efficient and Scalable Monocular Human-Object Interaction Motion Reconstruction](https://arxiv.org/abs/2512.00960)
*Boran Wen,Ye Lu,Keyan Wan,Sirui Wang,Jiahong Zhou,Junxuan Liang,Xinpeng Liu,Bang Xiao,Dingbang Huang,Ruiyang Liu,Yong-Lu Li*

Main category: cs.CV

TL;DR: 提出4DHOISolver优化框架，利用稀疏人工标注的接触点约束4D人-物交互重建，构建大规模Open4DHOI数据集，并展示其在机器人模仿学习中的应用价值。

- Motivation: 单目互联网视频提供了近乎无限的人-物交互数据，但从中准确、可扩展地提取4D交互数据仍是一个未解决的重大挑战。
- Method: 提出4DHOISolver优化框架，利用稀疏的人工标注接触点约束4D重建问题，保持高时空一致性和物理合理性。
- Result: 构建了Open4DHOI大规模4D人-物交互数据集，包含144种物体类型和103种动作；通过RL智能体验证了重建动作的可模仿性；现有3D基础模型在预测精确接触对应关系方面仍有不足。
- Conclusion: 4DHOISolver框架有效解决了从野外视频中提取4D交互数据的挑战，Open4DHOI数据集为相关研究提供了宝贵资源，但精确接触预测仍是未解决的开放问题。


### [120] [MM-ACT: Learn from Multimodal Parallel Generation to Act](https://arxiv.org/abs/2512.00975)
*Haotian Liang,Xinyi Chen,Bin Wang,Mingkang Chen,Yitian Liu,Yuhao Zhang,Zanxin Chen,Tianshuo Yang,Yilun Chen,Jiangmiao Pang,Dong Liu,Xiaokang Yang,Yao Mu,Wenqi Shao,Ping Luo*

Main category: cs.CV

TL;DR: MM-ACT是一个统一的视觉-语言-动作模型，通过共享token空间集成文本、图像和动作，采用重新掩码并行解码策略生成文本和图像，以及一步并行解码策略生成动作，实现了多模态的统一生成。

- Motivation: 通用机器人策略需要语义理解进行任务规划，同时需要预测能力与环境交互。现有方法通常单独处理这些能力，缺乏统一的多模态生成框架。
- Method: 提出MM-ACT模型，在共享token空间中集成文本、图像和动作；采用重新掩码并行解码策略生成文本和图像，一步并行解码策略生成动作；引入上下文共享多模态学习训练范式，从共享上下文中监督所有三种模态的生成。
- Result: 在LIBERO仿真中达到96.3%成功率，在真实Franka机器人的三个任务中达到72.0%成功率，在RoboTwin2.0的八个双手任务中达到52.38%成功率，跨模态学习带来额外9.25%的性能提升。
- Conclusion: MM-ACT通过统一的视觉-语言-动作模型和上下文共享多模态学习，有效提升了机器人策略的语义理解和动作生成能力，在仿真和真实机器人任务中都表现出色。


### [121] [PhotoFramer: Multi-modal Image Composition Instruction](https://arxiv.org/abs/2512.00993)
*Zhiyuan You,Ke Wang,He Zhang,Xin Cai,Jinjin Gu,Tianfan Xue,Chao Dong,Zhoutong Zhang*

Main category: cs.CV

TL;DR: PhotoFramer是一个多模态构图指导框架，通过自然语言描述和生成示例图像来帮助用户改善照片构图。

- Motivation: 许多普通用户在拍照时难以获得良好构图，需要提供构图指导来帮助他们改善照片质量。
- Method: 构建大规模数据集，将构图指导分为移位、放大和视角变化三个子任务；使用两阶段流程合成训练数据，并微调能同时处理文本和图像的模型。
- Result: 文本指令能有效引导图像构图，结合示例图像比仅使用示例的基线方法有持续改进。
- Conclusion: PhotoFramer向构图助手迈出了实用一步，使日常用户能够获得专业摄影先验知识。


### [122] [S2AM3D: Scale-controllable Part Segmentation of 3D Point Cloud](https://arxiv.org/abs/2512.00995)
*Han Su,Tianyu Huang,Zichen Wan,Xiaohe Wu,Wangmeng Zuo*

Main category: cs.CV

TL;DR: S2AM3D：通过多视图2D分割先验与3D一致性监督解决部件级点云分割的泛化与一致性挑战，提出点一致性编码器和尺度感知提示解码器，并构建大规模高质量数据集

- Motivation: 现有部件级点云分割面临两大挑战：原生3D模型因数据稀缺缺乏泛化能力，而引入2D预训练知识常导致不同视图间分割结果不一致
- Method: 提出S2AM3D框架：1）点一致性部件编码器通过原生3D对比学习聚合多视图2D特征，生成全局一致的点特征；2）尺度感知提示解码器通过连续尺度信号实时调整分割粒度；3）构建超过10万样本的大规模高质量部件级点云数据集
- Result: S2AM3D在多个评估设置中取得领先性能，在处理复杂结构和尺寸变化显著的部件时表现出卓越的鲁棒性和可控性
- Conclusion: 通过结合2D分割先验与3D一致性监督，S2AM3D有效解决了部件级点云分割的泛化与一致性挑战，为3D计算机视觉中的部件级理解提供了有力工具


### [123] [Provenance-Driven Reliable Semantic Medical Image Vector Reconstruction via Lightweight Blockchain-Verified Latent Fingerprints](https://arxiv.org/abs/2512.00999)
*Mohsin Rasheed,Abdullah Al-Mamun*

Main category: cs.CV

TL;DR: 提出结合语义感知医学图像重建与轻量级区块链溯源层的框架，提升临床相关结构保持与重建过程可验证性

- Motivation: 现实医疗影像常受损坏、噪声和篡改影响，传统重建方法注重像素级恢复但可能损害解剖保真度，影响临床结果可靠性
- Method: 语义感知医学图像重建框架：集成高级潜在嵌入与混合U-Net架构；轻量级区块链溯源层：采用无标度图设计记录重建事件
- Result: 多数据集和损坏类型评估显示，相比现有方法，在结构一致性、重建准确性和溯源完整性方面均有改进
- Conclusion: 通过语义引导重建与安全可追溯性结合，推进医疗影像可靠AI发展，增强诊断信心和医疗环境监管合规性


### [124] [LISA-3D: Lifting Language-Image Segmentation to 3D via Multi-View Consistency](https://arxiv.org/abs/2512.01008)
*Zhongbin Guo,Jiahe Liu,Wenyu Gao,Yushan Li,Chengzhi Li,Ping Jian*

Main category: cs.CV

TL;DR: LISA-3D是一个两阶段框架，通过将语言-图像分割提升到3D，使用几何感知的LoRA层改进LISA模型，并结合冻结的SAM-3D重建器，实现无需额外3D-文本监督的文本驱动3D重建。

- Motivation: 文本驱动的3D重建需要一个能够同时理解开放词汇指令并在不同视角下保持一致的掩码生成器。现有方法在跨视角一致性和开放词汇理解方面存在挑战。
- Method: 采用两阶段框架：1）使用几何感知LoRA层改进LISA模型，通过可微分重投影损失强制跨视角一致性；2）将生成的掩码与RGB图像拼接形成RGBA提示，输入冻结的SAM-3D重建器输出高斯溅射或纹理网格。
- Result: 在ScanRefer和Nr3D数据集上，LISA-3D将语言到3D的准确率比单视角基线提高了最多15.6个百分点，仅需适应1160万个参数。系统具有模块化、数据高效的特点，支持零样本部署到未见类别。
- Conclusion: LISA-3D提供了一个实用的语言引导3D内容创建方案，通过结合指令跟随模型和3D重建器，实现了无需额外3D-文本监督的高质量文本驱动3D重建。


### [125] [Lotus-2: Advancing Geometric Dense Prediction with Powerful Image Generative Model](https://arxiv.org/abs/2512.01030)
*Jing He,Haodong Li,Mingzhi Sheng,Ying-Cong Chen*

Main category: cs.CV

TL;DR: Lotus-2是一个两阶段确定性框架，利用预训练扩散模型作为世界先验进行几何密集预测，仅需少量训练数据即可在单目深度估计和表面法线预测中取得SOTA性能

- Motivation: 从单张图像恢复像素级几何属性本质上是病态问题。现有方法要么依赖大规模监督数据但物理推理有限，要么直接使用扩散模型的随机生成公式不适合确定性几何推断。需要一种能充分利用预训练生成先验的优化适配方案
- Method: 两阶段确定性框架：第一阶段核心预测器采用单步确定性公式，包含干净数据目标和轻量级局部连续性模块，生成全局一致结构；第二阶段细节锐化器在核心预测器定义的流形内执行约束多步校正流细化，通过无噪声确定性流匹配增强细粒度几何
- Result: 仅使用59K训练样本（不到现有大规模数据集的1%），在单目深度估计中取得新的SOTA结果，在表面法线预测中达到高度竞争力
- Conclusion: 扩散模型可以作为确定性世界先验，实现超越传统判别式和生成式范式的高质量几何推理，为几何密集预测提供了新的有效途径


### [126] [TRoVe: Discovering Error-Inducing Static Feature Biases in Temporal Vision-Language Models](https://arxiv.org/abs/2512.01048)
*Maya Varma,Jean-Benoit Delbrouck,Sophie Ostmeier,Akshay Chaudhari,Curtis Langlotz*

Main category: cs.CV

TL;DR: TRoVe：自动发现时序视觉语言模型中导致错误的静态特征偏差的方法

- Motivation: 视觉语言模型在处理时序理解任务时，可能依赖静态特征偏差（如背景或物体特征）而非动态视觉变化，这会导致系统性的预测错误。识别这些偏差对于实际部署至关重要。
- Method: TRoVe从标注验证数据集中提取候选静态特征，通过两个维度评分：(1)特征对分类错误的影响；(2)模型预测时对该特征的依赖程度。
- Result: 在包含101个训练好的时序VLM和真实标注偏差的评估框架中，TRoVe比最接近的基线方法提升了28.6%的准确性。应用于7个现成VLM和2个时序理解任务时，发现了先前未知的静态特征偏差。
- Conclusion: TRoVe能有效识别时序VLM中的错误诱导静态特征偏差，了解这些偏差有助于提升模型在测试时的性能，为实际部署前的模型评估提供了重要工具。


### [127] [Parameter Reduction Improves Vision Transformers: A Comparative Study of Sharing and Width Reduction](https://arxiv.org/abs/2512.01059)
*Anantha Padmanaban Krishna Kumar*

Main category: cs.CV

TL;DR: 研究发现在ViT-B/16模型中，MLP层存在过度参数化问题，通过两种简单的参数减少策略（分组MLP和浅层MLP）可以在减少32.7%参数的同时保持甚至略微提升性能。

- Motivation: 尽管缩放定律和经验结果表明增大Vision Transformers通常能提升性能，但模型准确率和训练行为并不总是随规模单调增加。研究者想探索在ViT-B/16模型上，MLP块是否存在过度参数化问题，以及是否可以通过参数减少策略来优化模型设计。
- Method: 提出了两种简单的参数减少策略应用于MLP块：1) GroupedMLP：在相邻transformer块之间共享MLP权重；2) ShallowMLP：将MLP隐藏维度减半。两种方法都减少了32.7%的基线参数。
- Result: GroupedMLP达到81.47% top-1准确率（保持基线计算成本），ShallowMLP达到81.25% top-1准确率（推理吞吐量提升38%）。两者都优于86.6M参数的基线模型（81.05%），并显著改善了训练稳定性，将峰值到最终准确率下降从0.47%减少到0.03%-0.06%。
- Conclusion: 对于ImageNet-1K上的ViT-B/16模型，MLP层存在过度参数化，减少MLP容量不会损害性能甚至可能略微改善。参数共享和减少宽度等架构约束可以作为有用的归纳偏置，参数分配方式在Vision Transformer设计中很重要。


### [128] [Generalized Medical Phrase Grounding](https://arxiv.org/abs/2512.01085)
*Wenjun Zhang,Shekhar S. Chandra,Aaron Nicolson*

Main category: cs.CV

TL;DR: 论文提出通用医学短语定位(GMPG)任务，解决现有MPG系统只能返回单个边界框的问题，并开发了MedGrounder模型，在零样本迁移和多区域定位方面表现优异。

- Motivation: 现有医学短语定位(MPG)系统遵循指代表达理解(REC)范式，每个短语只能返回一个边界框。但真实医疗报告常包含多区域发现、非诊断性文本、不可定位短语(如否定描述或正常解剖描述)，因此需要更通用的任务定义。
- Method: 提出通用医学短语定位(GMPG)任务，将每个句子映射到零个、一个或多个评分区域。开发MedGrounder模型，采用两阶段训练：首先在报告句子-解剖框对齐数据集上预训练，然后在报告句子-人工标注框数据集上微调。
- Result: 在PadChest-GR和MS-CXR数据集上，MedGrounder实现了强大的零样本迁移能力，在多区域和不可定位短语方面优于REC风格和基础报告生成基线，同时使用更少的人工框标注。还能与现有报告生成器组合，无需重新训练生成器即可生成基础报告。
- Conclusion: 通用医学短语定位(GMPG)是更符合实际医疗报告需求的改进任务定义，MedGrounder模型在该任务上表现优异，能够处理多区域发现和不可定位短语，且具有零样本迁移能力和与现有系统的良好兼容性。


### [129] [Accelerating Inference of Masked Image Generators via Reinforcement Learning](https://arxiv.org/abs/2512.01094)
*Pranav Subbaraman,Shufan Li,Siyan Zhao,Aditya Grover*

Main category: cs.CV

TL;DR: Speed-RL：使用强化学习加速预训练掩码生成模型，实现3倍加速同时保持图像质量

- Motivation: 掩码生成模型（MGM）虽然能生成高质量图像，但需要大量采样步骤导致推理速度慢。传统蒸馏方法将加速问题视为分布匹配问题，但作者认为这可以重新定义为强化学习问题。
- Method: 提出Speed-RL范式，将加速问题视为强化学习问题。结合质量奖励和速度奖励，使用强化学习微调基础模型，优化目标为组合奖励。
- Result: 实验表明，该方法能够将基础模型加速3倍，同时保持可比的图像质量。
- Conclusion: Speed-RL为加速预训练掩码生成模型提供了一种新颖有效的强化学习方法，相比传统蒸馏方法有更好的加速效果。


### [130] [CycliST: A Video Language Model Benchmark for Reasoning on Cyclical State Transitions](https://arxiv.org/abs/2512.01095)
*Simon Kohaut,Daniel Ochs,Shun Zhang,Benedict Flade,Julian Eggert,Kristian Kersting,Devendra Singh Dhami*

Main category: cs.CV

TL;DR: CycliST是一个评估视频语言模型在循环状态转换上文本推理能力的新基准数据集，通过合成视频序列测试模型对周期性模式的理解，发现现有模型在这方面存在显著不足。

- Motivation: 现有视频语言模型在理解周期性状态转换方面存在不足，缺乏对循环运动模式和视觉属性变化的时间理解能力，需要专门的基准来评估和改进这方面的能力。
- Method: 创建CycliST基准数据集，生成具有周期性模式（物体运动和视觉属性变化）的合成结构化视频序列，采用分层评估系统，通过增加循环物体数量、场景杂乱度和光照条件来逐步提高难度。
- Result: 实验显示当前最先进的视频语言模型（包括开源和专有模型）在泛化到循环动态（如线性和轨道运动）以及时间依赖的视觉属性变化方面存在局限，无法可靠检测和利用循环模式，缺乏时间理解概念，无法从场景中提取定量信息。
- Conclusion: CycliST为视觉推理模型提供了有针对性的挑战和全面的评估框架，揭示了当前模型在理解周期性模式方面的技术差距，为开发超越现有技术水平的新模型铺平了道路。


### [131] [Learning Eigenstructures of Unstructured Data Manifolds](https://arxiv.org/abs/2512.01103)
*Roy Velich,Arkadi Piven,David Bensaïd,Daniel Cremers,Thomas Dagès,Ron Kimmel*

Main category: cs.CV

TL;DR: 提出一种直接从非结构化数据学习谱基的新框架，无需传统算子选择、离散化和特征求解器，为几何处理提供数据驱动的替代方案。

- Motivation: 传统几何处理方法需要手动选择算子、进行离散化和特征分解，这些步骤在非结构化数据和高维空间中变得复杂且受限。需要一种能够直接从数据学习谱基的统一框架。
- Method: 基于最优逼近理论，训练网络通过最小化重构误差来分解隐式逼近算子。通过选择合适的探测函数分布，可以近似拉普拉斯算子及其特征分解。该方法无监督，不假设数据流形结构。
- Result: 在3D表面点云和高维图像流形上，该方法能够产生有意义的谱基，类似于拉普拉斯算子的特征函数，而无需显式构造算子。同时还能恢复隐式度量的采样密度和底层算子的特征值。
- Conclusion: 该框架为几何处理提供了一种原则性的数据驱动替代方案，特别适用于非结构化数据和高维空间，开启了新的可能性。


### [132] [Structural Prognostic Event Modeling for Multimodal Cancer Survival Analysis](https://arxiv.org/abs/2512.01116)
*Yilan Zhang,Li Nanbo,Changchun Yang,Jürgen Schmidhuber,Xin Gao*

Main category: cs.CV

TL;DR: SlotSPE：基于槽位的结构预后事件建模框架，通过槽注意力将多模态输入压缩为紧凑的互异槽表示，有效捕捉稀疏但关键的预后事件，提升癌症生存预测性能。

- Motivation: 当前方法难以高效建模组织学图像和基因谱之间的模态内和模态间交互，主要挑战在于捕捉少数但关键的预后事件，这些事件表现为高级结构信号（如空间组织学模式或通路共激活），通常稀疏、患者特异且无标注。
- Method: 提出SlotSPE框架，受因子编码原理启发，使用槽注意力将每个患者的多模态输入压缩为紧凑的模态特异性互异槽集合。这些槽表示作为预后事件的编码，支持复杂模态交互建模，并能无缝整合增强预后相关性的生物学先验。
- Result: 在十个癌症基准测试中，SlotSPE在8/10队列中优于现有方法，整体性能提升2.9%。在基因组数据缺失情况下保持稳健，并通过结构化事件分解显著提升可解释性。
- Conclusion: SlotSPE通过槽位表示有效建模稀疏的预后结构事件，在多模态癌症生存预测中实现了性能提升、鲁棒性和可解释性的改进，为复杂生物医学数据分析提供了新框架。


### [133] [OmniFD: A Unified Model for Versatile Face Forgery Detection](https://arxiv.org/abs/2512.01128)
*Haotian Liu,Haoyu Chen,Chenhui Pan,You Hu,Guoying Zhao,Xiaobai Li*

Main category: cs.CV

TL;DR: OmniFD是一个统一框架，在单个模型中同时处理图像/视频分类、空间定位和时间定位四个核心人脸伪造检测任务，通过共享编码器、跨任务交互模块和轻量解码头实现高效多任务学习。

- Motivation: 当前人脸伪造检测方法通常采用任务特定的独立模型，导致计算冗余且忽略了相关任务之间的潜在关联，需要更统一高效的解决方案。
- Method: 1) 共享Swin Transformer编码器提取统一4D时空表示；2) 跨任务交互模块通过可学习查询和注意力机制动态捕获任务间依赖；3) 轻量解码头将精炼表示转换为各任务预测。
- Result: OmniFD在多个基准测试中优于任务特定模型，通过多任务学习实现知识迁移（如视频分类准确率提升4.63%），同时减少63%参数和50%训练时间，实现高效可扩展的统一检测。
- Conclusion: OmniFD为实际应用中的人脸伪造检测提供了实用且可泛化的统一解决方案，通过单一框架整合图像、视频和四个核心任务，实现了高性能、高效率和高可扩展性。


### [134] [Weakly Supervised Continuous Micro-Expression Intensity Estimation Using Temporal Deep Neural Network](https://arxiv.org/abs/2512.01145)
*Riyadh Mohammed Almushrafy*

Main category: cs.CV

TL;DR: 提出首个仅使用稀疏时间标注（起始点、顶点、结束点）的连续微表情强度估计统一框架，通过三角先验生成伪强度轨迹，结合ResNet18编码器和双向GRU进行时序回归，在SAMM和CASME II数据集上取得优异性能。

- Motivation: 现有微表情研究主要关注离散分类，而连续强度时序演化研究较少。由于缺乏帧级强度标注，完全监督回归方法不切实际，需要开发仅使用弱时间标注的连续强度估计方法。
- Method: 使用三角先验将稀疏时间标注（起始点、顶点、结束点）转换为密集伪强度轨迹，构建轻量级时序回归模型，结合ResNet18编码器和双向GRU直接从图像序列预测帧级强度，无需帧级标注，通过统一预处理和时间对齐流程应用于不同数据集。
- Result: 在SAMM数据集上达到Spearman相关系数0.9014和Kendall相关系数0.7999，优于帧级基线；在CASME II数据集上分别达到0.9116和0.8168（无顶点排序项时）。消融研究证实时序建模和结构化伪标签对捕捉微表情的"上升-顶点-下降"动态至关重要。
- Conclusion: 这是首个仅使用稀疏时间标注的连续微表情强度估计统一方法，通过简单三角先验和轻量时序模型有效捕捉微表情动态演化，为连续强度估计提供了实用解决方案。


### [135] [SocialFusion: Addressing Social Degradation in Pre-trained Vision-Language Models](https://arxiv.org/abs/2512.01148)
*Hamza Tahboub,Weiyan Shi,Gang Hua,Huaizu Jiang*

Main category: cs.CV

TL;DR: 论文发现预训练的视觉语言模型在多任务社交感知中存在负迁移问题，提出SocialFusion框架解决这一问题，在五个社交任务上实现正迁移和可比性能。

- Motivation: 当前强大的预训练视觉语言模型在统一学习多个社交感知任务时表现出负迁移，作者发现这是由于"社交退化"问题导致的——VLM的预训练过程损害了视觉编码器表示细微社交信息的能力。
- Method: 提出SocialFusion框架，在冻结的视觉编码器和语言模型之间学习最小连接。通过线性表示探测和梯度冲突分析两个角度研究社交退化问题，发现VLM预训练显著损害了表示的可解码性。
- Result: SocialFusion在五个社交任务上表现出正迁移，利用任务间的协同效应提升整体性能，在各种基准测试中达到与任务特定SOTA模型相当的性能。
- Conclusion: 当前VLM预训练策略可能不利于获得通用的社交能力，需要更注重社交意识的训练范式。SocialFusion为解决多任务社交感知中的负迁移问题提供了有效方案。


### [136] [DPAC: Distribution-Preserving Adversarial Control for Diffusion Sampling](https://arxiv.org/abs/2512.01153)
*Han-Jin Lee,Han-Ju Lee,Jin-Seong Kim,Seok-Hwan Choi*

Main category: cs.CV

TL;DR: 提出DPAC方法，通过将对抗梯度投影到生成分数几何定义的切空间，在保持攻击成功率的同时降低FID和路径KL散度，实现分布保持的对抗控制。

- Motivation: 现有对抗引导的扩散采样虽然能实现目标类别分类，但随着对抗控制轨迹与名义轨迹偏差的累积，样本质量会下降。需要一种既能保持攻击成功率又能维持样本质量的方法。
- Method: 1. 将质量退化形式化为路径空间KL散度，通过Girsanov定理证明其等于控制能量；2. 从变分角度推导最优控制条件：在获得相同分类增益的方向中，与对数密度等值面相切的分量最小化路径KL；3. 提出DPAC方法，将对抗梯度投影到生成分数几何定义的切空间。
- Result: 理论分析表明：切向投影在离散求解器中消除了Wasserstein距离的O(Δt)主导误差项，达到O(Δt²)质量差距；对分数或度量近似保持二阶鲁棒性。ImageNet-100实验验证了理论预测，DPAC在相同攻击成功率下实现了更低的FID和估计路径KL。
- Conclusion: DPAC通过将对抗控制限制在生成分布的切空间，实现了分布保持的对抗引导，在维持攻击有效性的同时显著提升了样本质量，为扩散模型的对抗控制提供了理论指导和实用方法。


### [137] [Real-Time On-the-Go Annotation Framework Using YOLO for Automated Dataset Generation](https://arxiv.org/abs/2512.01165)
*Mohamed Abdallah Salem,Ahmed Harb Rabia*

Main category: cs.CV

TL;DR: 提出基于YOLO模型的实时标注方法，在边缘设备上实现图像采集时的即时标注，显著减少农业应用中数据集准备时间。

- Motivation: 传统标注方法劳动密集且耗时，特别是在农业等需要快速决策的领域，数据集标注成为部署YOLO等目标检测模型的主要瓶颈。
- Method: 在边缘设备上部署YOLO模型实现实时标注，比较了YOLOv5、YOLOv8、YOLOv12三种架构，评估单类vs多类标注、预训练vs从头训练等配置。
- Result: 预训练和单类配置在模型收敛、性能和鲁棒性方面表现显著优势，验证了实时标注框架的可行性和有效性，大幅减少标注时间同时保持高质量。
- Conclusion: 提出的实时标注方法能显著降低数据集准备时间，为农业等实时应用场景提供高效准确的标注解决方案。


### [138] [VSRD++: Autolabeling for 3D Object Detection via Instance-Aware Volumetric Silhouette Rendering](https://arxiv.org/abs/2512.01178)
*Zihua Liu,Hiroki Sakuma,Masatoshi Okutomi*

Main category: cs.CV

TL;DR: VSRD++：一种弱监督单目3D目标检测框架，无需3D标注，通过神经场体渲染和2D监督实现多视图自动标注和单目检测器训练

- Motivation: 现有单目3D目标检测方法严重依赖大量3D标注，这些标注通常来自LiDAR点云且标注成本高昂。需要一种无需3D标注的弱监督方法来解决这个问题。
- Method: 采用两阶段框架：1）多视图3D自动标注阶段，使用有符号距离场表示物体表面，通过实例感知体轮廓渲染生成实例掩码，将SDF分解为长方体SDF和残差距离场来优化3D边界框；2）单目3D检测器训练阶段，使用优化的3D边界框作为伪标签训练单目检测器。针对动态物体引入速度属性和置信度机制。
- Result: 在KITTI-360数据集上的实验表明，VSRD++在静态和动态场景中都显著优于现有的弱监督单目3D目标检测方法。
- Conclusion: VSRD++成功实现了无需3D标注的弱监督单目3D目标检测，通过神经场体渲染和2D监督有效解决了标注成本问题，在静态和动态场景中都表现出色。


### [139] [TabletopGen: Instance-Level Interactive 3D Tabletop Scene Generation from Text or Single Image](https://arxiv.org/abs/2512.01204)
*Ziqian Wang,Yonghao He,Licheng Yang,Wei Zou,Hongxuan Ma,Liu Liu,Wei Sui,Yuxin Guo,Hu Su*

Main category: cs.CV

TL;DR: TabletopGen：无需训练的自动框架，从参考图像生成高质量、可交互的3D桌面场景，通过实例分割、3D重建和空间对齐实现物理合理的布局。

- Motivation: 当前基于文本或图像的3D场景生成方法主要关注大尺度场景，难以捕捉桌面场景的高密度布局和复杂空间关系，而高质量的交互式3D桌面场景对具身AI和机器人操作至关重要。
- Method: TabletopGen采用训练免费的全自动框架：1）输入参考图像（可由文本生成图像模型合成）；2）实例分割和补全获取每个实例图像；3）3D重建和规范坐标对齐；4）姿态和尺度估计；5）组装成无碰撞的仿真就绪场景。核心创新是两阶段空间对齐：可微分旋转优化器用于精确旋转恢复，俯视图空间对齐机制用于鲁棒的平移和尺度估计。
- Result: 大量实验和用户研究表明，TabletopGen在视觉保真度、布局准确性和物理合理性方面达到最先进水平，显著超越现有方法，能够生成具有丰富风格和空间多样性的逼真桌面场景。
- Conclusion: TabletopGen成功解决了桌面场景生成的挑战，通过创新的两阶段空间对齐方法实现了从2D参考到3D场景的高质量重建，为具身AI和机器人操作提供了有效的场景生成解决方案。


### [140] [Closing the Approximation Gap of Partial AUC Optimization: A Tale of Two Formulations](https://arxiv.org/abs/2512.01213)
*Yangbangyan Jiang,Qianqian Xu,Huiyang Shao,Zhiyong Yang,Shilong Bao,Xiaochun Cao,Qingming Huang*

Main category: cs.CV

TL;DR: 提出两种实例级极小极大重构方法，用于优化部分AUC（PAUC），解决了现有方法近似误差不可控和可扩展性有限的问题。

- Motivation: PAUC是处理类别不平衡和决策约束的重要评估指标，但其计算中在约束区间内选择实例是NP难问题，现有方法存在近似误差不可控和可扩展性有限的问题。
- Method: 提出两种实例级极小极大重构：一种具有渐近消失的近似误差，另一种无偏但需要更多变量。通过建立等效实例级问题降低时间复杂度，通过阈值学习简化复杂样本选择过程，并应用不同平滑技术。
- Result: 算法具有线性迭代计算复杂度（相对于样本大小）和O(ε^{-1/3})收敛率。提供了紧密的泛化界，明确展示了TPR/FPR约束α/β对泛化的影响，呈现了$\tilde{O}(α^{-1}n_+^{-1} + β^{-1}n_-^{-1})$的尖锐阶。
- Conclusion: 提出的方法在多个基准数据集上验证了其优势，成功解决了PAUC优化中的近似误差问题，提供了高效且理论保证的解决方案。


### [141] [M4-BLIP: Advancing Multi-Modal Media Manipulation Detection through Face-Enhanced Local Analysis](https://arxiv.org/abs/2512.01214)
*Hang Wu,Ke Sun,Jiayi Ji,Xiaoshuai Sun,Rongrong Ji*

Main category: cs.CV

TL;DR: M4-BLIP框架利用BLIP-2提取局部特征，结合面部先验知识，通过对齐融合模块整合局部与全局特征，并与大语言模型结合提升可解释性，用于多模态媒体篡改检测。

- Motivation: 当前多模态媒体篡改检测方法忽视局部信息的重要性，而篡改通常发生在特定区域（尤其是面部），这威胁到信息传播的可靠性和完整性。
- Method: 使用BLIP-2模型提取局部特征，结合面部先验知识，设计对齐融合模块整合局部和全局特征，并与大语言模型集成提升结果可解释性。
- Result: 大量定量和可视化实验证明，该框架在检测效果上优于当前最先进方法。
- Conclusion: M4-BLIP框架通过有效利用局部特征和面部先验知识，结合大语言模型的可解释性，显著提升了多模态媒体篡改检测的准确性和可靠性。


### [142] [S$^2$-MLLM: Boosting Spatial Reasoning Capability of MLLMs for 3D Visual Grounding with Structural Guidance](https://arxiv.org/abs/2512.01223)
*Beining Xu,Siting Zhu,Zhao Jin,Junxian Li,Hesheng Wang*

Main category: cs.CV

TL;DR: S²-MLLM：通过隐式空间推理增强MLLM在3D视觉定位中的空间理解能力，避免低效的点云重建，实现性能、泛化性和效率的统一。

- Motivation: 现有方法主要依赖点云重建的视角相关渲染为MLLM提供显式结构指导，导致效率低下且空间推理能力有限。MLLM主要处理2D视觉输入，难以从有限视角理解3D场景的空间结构。
- Method: 提出S²-MLLM框架，采用隐式空间推理策略：1）利用前馈3D重建的结构感知能力获取空间指导；2）设计结构增强模块（SE），使用视图内和视图间注意力机制捕获依赖关系，并集成多级位置编码关联视觉表示与空间位置及视角信息。
- Result: 在ScanRefer、Nr3D和Sr3D数据集上均显著超越现有方法，实现了优越性能、良好泛化性和高效率的统一。
- Conclusion: S²-MLLM通过隐式空间推理有效解决了MLLM在3D视觉定位中的空间理解瓶颈，避免了传统点云重建的低效问题，为3DVG任务提供了更高效的解决方案。


### [143] [PSR: Scaling Multi-Subject Personalized Image Generation with Pairwise Subject-Consistency Rewards](https://arxiv.org/abs/2512.01236)
*Shulei Wang,Longhui Wei,Xin He,Jianbo Ouyang,Hui Lu,Zhou Zhao,Qi Tian*

Main category: cs.CV

TL;DR: 提出PSR方法，通过多主体数据生成管道和强化学习奖励机制，解决多主体个性化图像生成中的主体一致性和文本控制问题

- Motivation: 现有单主体个性化生成模型在多主体场景下性能下降，特别是在保持主体一致性和遵循文本提示方面存在局限，主要原因是缺乏高质量多主体数据集和精细的后训练策略
- Method: 1) 提出可扩展的多主体数据生成管道，利用单主体生成模型构建高质量多主体训练数据；2) 设计成对主体一致性奖励和通用奖励，通过强化学习阶段提升主体一致性和文本可控性；3) 引入包含7个子集、3个维度的新基准评估多主体个性化生成
- Result: 大量实验证明该方法在多主体个性化图像生成方面具有显著效果，能够有效提升主体一致性和文本控制能力
- Conclusion: PSR方法通过高质量多主体数据集和强化学习奖励机制，成功解决了多主体个性化图像生成中的关键挑战，推动了该领域的发展


### [144] [Generative Adversarial Gumbel MCTS for Abstract Visual Composition Generation](https://arxiv.org/abs/2512.01242)
*Zirui Zhao,Boye Niu,David Hsu,Wee Sun Lee*

Main category: cs.CV

TL;DR: 提出约束引导框架，结合几何推理与神经语义，通过AlphaGo式搜索确保可行性，用微调视觉语言模型评分语义对齐，在七巧板组装任务中超越扩散和自回归基线。

- Motivation: 研究抽象视觉组合问题，其中身份主要由少量几何基元的空间配置和关系决定。这类问题对纹理和逼真细节具有不变性，但在几何约束和模糊目标规范下组合这些结构具有挑战性，因为存在组合放置选择、数据有限和离散可行性等问题，形成稀疏解流形，不适合纯统计像素空间生成器。
- Method: 提出约束引导框架，结合显式几何推理与神经语义。采用AlphaGo式搜索确保可行性，使用微调视觉语言模型评分语义对齐作为奖励信号。算法在蒙特卡洛树搜索中使用策略网络作为启发式，并通过搜索生成的计划微调网络。受生成对抗网络启发，使用生成实例进行对抗奖励细化。
- Result: 在七巧板组装任务中，该方法在有效性和语义保真度方面优于扩散和自回归基线，特别是在约束收紧时表现更佳。随着时间推移，当奖励模型无法区分生成实例和真实数据时，生成结果应更接近实际数据。
- Conclusion: 提出的约束引导框架成功解决了抽象视觉组合问题，通过结合几何推理与神经语义的方法，在具有严格几何约束的任务中实现了更好的生成质量和可行性。


### [145] [TRivia: Self-supervised Fine-tuning of Vision-Language Models for Table Recognition](https://arxiv.org/abs/2512.01248)
*Junyuan Zhang,Bin Wang,Qintong Zhang,Fan Wu,Zichen Wen,Jialin Lu,Junjie Shan,Ziqi Zhao,Shuya Yang,Ziling Wang,Ziyang Miao,Huaping Zhong,Yuhang Zang,Xiaoyi Dong,Ka-Ho Chow,Conghui He*

Main category: cs.CV

TL;DR: TRivia：一种基于自监督微调的表格识别方法，无需标注数据，通过问答奖励机制让视觉语言模型从无标注表格图像中学习，实现了开源模型性能超越商业模型

- Motivation: 表格识别传统依赖监督学习，需要大量标注数据，成本高昂。开源模型因资源有限且受隐私法规限制，性能远落后于商业模型。需要一种无需标注数据的自监督方法来缩小这一差距。
- Method: 基于Group Relative Policy Optimization的自监督微调方法，通过注意力引导模块为每个表格图像生成多样化问题，利用问答正确性作为奖励反馈优化模型，形成闭环学习过程。
- Result: 提出的TRivia-3B模型在三个流行基准测试中超越了现有系统（如Gemini 2.5 Pro、MinerU2.5），成为开源、紧凑且最先进的表格识别模型。
- Conclusion: TRivia方法成功实现了无需标注数据的表格识别，通过自监督学习让模型自主学习表格的结构化表示和推理能力，显著提升了开源模型的性能水平。


### [146] [ViscNet: Vision-Based In-line Viscometry for Fluid Mixing Process](https://arxiv.org/abs/2512.01268)
*Jongwon Sohn,Juhyeon Moon,Hyunjoon Jung,Jaewook Nam*

Main category: cs.CV

TL;DR: 基于计算机视觉的粘度计，通过分析混合过程中自由表面变形引起的光学畸变来测量粘度，无需接触样品，适用于自动化实验室环境。

- Motivation: 传统粘度计具有侵入性，需要在受控实验室环境下操作，与实际工艺条件差异较大，限制了过程监测和自动化实验室操作。
- Method: 利用计算机视觉技术，通过固定背景图案在混合驱动的连续变形自由表面折射产生的光学畸变来推断粘度。采用多图案策略增强视觉线索，并加入不确定性量化确保传感器可靠性。
- Result: 在不同光照条件下，系统在log m² s⁻¹单位上达到0.113的平均绝对误差，粘度等级预测准确率最高达81%。多图案策略提高了鲁棒性。
- Conclusion: 这种非接触式粘度计为现有粘度测量方法提供了实用的、适合自动化的替代方案，能够在实际工艺条件下进行可靠的粘度监测。


### [147] [nnMobileNet++: Towards Efficient Hybrid Networks for Retinal Image Analysis](https://arxiv.org/abs/2512.01273)
*Xin Li,Wenhui Zhu,Xuanzhao Dong,Hao Wang,Yujian Xiong,Oana Dumitrascu,Yalin Wang*

Main category: cs.CV

TL;DR: nnMobileNet++：一种结合卷积与Transformer的混合架构，用于视网膜图像分析，在保持低计算成本的同时实现SOTA性能

- Motivation: 传统CNN架构难以捕捉视网膜图像中的长距离依赖关系、不规则病变和细长血管模式，而这些特征对临床诊断至关重要。需要一种轻量级但更有效的架构来改进视网膜图像分析。
- Method: 提出nnMobileNet++混合架构，包含三个关键组件：1) 动态蛇形卷积用于边界感知特征提取；2) 在第二个下采样阶段后引入阶段特定的Transformer块进行全局上下文建模；3) 视网膜图像预训练以提高泛化能力
- Result: 在多个公共视网膜数据集上的分类实验表明，nnMobileNet++实现了最先进或极具竞争力的准确率，同时保持低计算成本
- Conclusion: nnMobileNet++作为一种轻量级但有效的视网膜图像分析框架具有巨大潜力，成功结合了卷积和Transformer的优势


### [148] [Supervised Contrastive Machine Unlearning of Background Bias in Sonar Image Classification with Fine-Grained Explainable AI](https://arxiv.org/abs/2512.01291)
*Kamal Basha S,Athira Nambiar*

Main category: cs.CV

TL;DR: 提出TCU和UESF框架，通过针对性对比性遗忘减少声纳图像分析中对海底特征的过度依赖，提高泛化能力和可解释性

- Motivation: 现有声纳图像AI模型过度依赖海底特征，导致泛化能力差，需要解决背景偏差问题并提高模型可解释性
- Method: 提出两个模块：1) TCU模块扩展三元组损失减少海底背景偏差；2) UESF框架提供可视化解释，并适配LIME生成更准确的归因分析
- Result: 在真实和合成声纳数据集上的实验验证了该方法在遗忘效果、模型鲁棒性和可解释性方面的显著改进
- Conclusion: 提出的TCU-UESF框架有效解决了声纳图像分析中的背景偏差问题，提高了模型的泛化能力和可解释性


### [149] [Diffusion Model in Latent Space for Medical Image Segmentation Task](https://arxiv.org/abs/2512.01292)
*Huynh Trinh Ngoc,Toan Nguyen Hai,Ba Luong Son,Long Tran Quoc*

Main category: cs.CV

TL;DR: MedSegLatDiff：一种基于扩散的医学图像分割框架，结合VAE和潜在扩散模型，能高效生成多种分割假设和置信度图，在保持小结构的同时提升计算效率。

- Motivation: 传统医学图像分割方法只生成单一分割掩码，无法捕捉不确定性；现有生成模型虽能生成多种可能分割，但计算负担重。需要一种既能生成多样化分割假设又高效的解决方案。
- Method: 提出MedSegLatDiff框架：1) 使用VAE将输入压缩到低维潜在空间，减少噪声并加速训练；2) 在潜在空间中进行扩散过程；3) 在VAE掩码重建路径中用加权交叉熵损失替代传统MSE损失，以更好地保留微小结构。
- Result: 在ISIC-2018（皮肤病变）、CVC-Clinic（息肉）和LIDC-IDRI（肺结节）数据集上评估，达到了最先进或极具竞争力的Dice和IoU分数，同时能生成多样化的分割假设和置信度图。
- Conclusion: MedSegLatDiff相比确定性基线提供了更好的可解释性和可靠性，特别适合临床部署，既能高效生成多种分割可能性，又能保持对小结构的敏感度。


### [150] [EGG-Fusion: Efficient 3D Reconstruction with Geometry-aware Gaussian Surfel on the Fly](https://arxiv.org/abs/2512.01296)
*Xiaokun Pan,Zhenzhe Li,Zhichao Ye,Hongjia Zhai,Guofeng Zhang*

Main category: cs.CV

TL;DR: EGG-Fusion：基于可微渲染的实时3D重建系统，通过鲁棒的稀疏到稠密相机跟踪和几何感知的高斯面元映射模块，实现高精度表面重建，在保持24FPS实时处理的同时，表面重建误差达到0.6cm。

- Motivation: 当前基于可微渲染的SLAM系统面临实时计算和传感器噪声敏感性的双重挑战，导致场景重建的几何保真度下降和实用性受限。需要解决这些问题以实现高精度、实时的3D重建。
- Method: 提出EGG-Fusion系统，包含鲁棒的稀疏到稠密相机跟踪模块和几何感知的高斯面元映射模块。引入基于信息滤波的融合方法，显式考虑传感器噪声，实现高精度表面重建。可微高斯面元映射有效建模多视角一致的表面，同时支持高效参数优化。
- Result: 在Replica和ScanNet++等标准基准数据集上，系统表面重建误差达到0.6cm，相比最先进的基于高斯溅射的方法精度提升超过20%。同时系统保持24FPS的实时处理能力。
- Conclusion: EGG-Fusion是当前最准确的基于可微渲染的实时重建系统之一，成功解决了实时计算和传感器噪声敏感性的挑战，实现了高精度表面重建和实时处理能力的平衡。


### [151] [TBT-Former: Learning Temporal Boundary Distributions for Action Localization](https://arxiv.org/abs/2512.01298)
*Thisara Rathnayaka,Uthayasanker Thayasivam*

Main category: cs.CV

TL;DR: TBT-Former 是一个新的时序动作定位架构，通过增强的Transformer骨干、跨尺度特征金字塔和边界分布回归头，解决了动作边界模糊和多尺度信息融合问题，在多个基准数据集上取得了最先进性能。

- Motivation: 现有单阶段、无锚框的时序动作定位模型（如ActionFormer）虽然利用Transformer取得了良好效果，但在处理模糊时间边界和有效融合多尺度上下文信息方面仍存在困难。论文旨在直接解决这些限制。
- Method: 提出了Temporal Boundary Transformer (TBT-Former)，包含三个核心贡献：1) 更高容量的缩放Transformer骨干，增加注意力头数和MLP维度以增强时序特征提取；2) 跨尺度特征金字塔网络，通过自上而下路径和横向连接融合高层语义和低层时序细节；3) 新颖的边界分布回归头，将边界回归重新定义为概率分布学习问题，显式建模边界不确定性。
- Result: 在竞争激烈的THUMOS14和EPIC-Kitchens 100数据集上建立了新的性能水平，同时在大规模ActivityNet-1.3数据集上保持竞争力。
- Conclusion: TBT-Former在基于Transformer的架构范式中推进了先前模型设定的基准，通过增强的特征提取能力、改进的多尺度融合和创新的边界不确定性建模，显著提升了时序动作定位的性能。


### [152] [DCText: Scheduled Attention Masking for Visual Text Generation via Divide-and-Conquer Strategy](https://arxiv.org/abs/2512.01302)
*Jaewoo Song,Jooyoung Choi,Kanghyun Baek,Sangyub Lee,Daemin Park,Sungroh Yoon*

Main category: cs.CV

TL;DR: DCText：一种无需训练的可视化文本生成方法，采用分治策略解决长文本/多文本生成问题，在保持图像质量的同时实现最佳文本准确率和最低生成延迟

- Motivation: 尽管现有文本到图像模型在文本渲染方面取得了高保真度，但由于全局注意力稀释，它们仍然难以处理长文本或多个文本
- Method: 采用分治策略，利用多模态扩散变换器的可靠短文本生成能力。首先通过提取和分割目标文本分解提示，然后将每个片段分配到指定区域。引入两种注意力掩码（文本聚焦和上下文扩展）在去噪过程中顺序应用，同时使用局部噪声初始化进一步提高文本准确性和区域对齐
- Result: 在单句和多句基准测试中，DCText实现了最佳的文本准确性，同时不损害图像质量，并且提供了最低的生成延迟
- Conclusion: DCText通过分治策略有效解决了文本到图像模型中长文本/多文本生成的挑战，在文本准确性、图像质量和生成效率方面均表现出色


### [153] [Gaussian Swaying: Surface-Based Framework for Aerodynamic Simulation with 3D Gaussians](https://arxiv.org/abs/2512.01306)
*Hongru Yan,Xiang Zhang,Zeyuan Chen,Fangyin Wei,Zhuowen Tu*

Main category: cs.CV

TL;DR: 提出Gaussian Swaying框架，使用3D高斯表示表面进行空气动力学模拟，统一模拟与渲染，实现高效精细的交互效果。

- Motivation: 自然界中树枝摇曳、旗帜飘动、船只摇晃等空气动力学效应对于视觉和图形的真实感至关重要，但现有方法存在局限性：基于网格的方法需要昂贵的网格化，基于粒子的方法依赖离散位置数据。
- Method: 提出基于表面的框架，使用3D高斯连续建模表面，通过高斯补丁统一模拟和渲染，支持动力学力计算同时提供法线用于轻量级着色。
- Result: 在合成和真实数据集上的综合实验表明，Gaussian Swaying在多个指标上实现了最先进的性能和效率，为真实空气动力学场景模拟提供了可扩展方法。
- Conclusion: Gaussian Swaying框架通过3D高斯表示实现了高效精细的空气动力学模拟，统一了模拟与渲染，为真实感场景模拟提供了创新解决方案。


### [154] [Lost in Distortion: Uncovering the Domain Gap Between Computer Vision and Brain Imaging - A Study on Pretraining for Age Prediction](https://arxiv.org/abs/2512.01310)
*Yanteng Zhang,Songheng Li,Zeyu Shen,Qizhen Lan,Lipei Zhang,Yang Liu,Vince Calhoun*

Main category: cs.CV

TL;DR: 该研究探讨了在脑影像数据预训练中数据质量的作用，发现不同质量水平的数据对下游任务性能有显著影响，揭示了低质量数据在预训练中的机会与限制。

- Motivation: 大规模脑影像数据集为领域基础模型预训练提供了机会，但这些数据存在高度异质性（从结构良好的扫描到严重失真或不完整的脑容积）。核心问题是：噪声或低质量扫描能否对预训练做出有意义的贡献，还是会阻碍模型学习？
- Method: 系统探索数据质量水平在预训练中的作用及其对下游任务的影响。具体方法：在不同质量水平的数据集上进行预训练，然后在外部队列上进行脑年龄预测的微调。
- Result: 结果显示不同质量水平之间存在显著的性能差异，揭示了低质量数据在预训练中的机会和限制。高质量数据通常带来更好的下游任务性能，但低质量数据在某些情况下也可能提供有用的学习信号。
- Conclusion: 计算机视觉实践与临床神经影像标准之间存在差距，需要领域感知的数据管理来确保可信且可泛化的领域特定基础模型。数据质量是脑影像预训练中的关键因素，需要针对性的质量评估和管理策略。


### [155] [IVCR-200K: A Large-Scale Multi-turn Dialogue Benchmark for Interactive Video Corpus Retrieval](https://arxiv.org/abs/2512.01312)
*Ning Han,Yawen Zeng,Shaohua Long,Chengqing Li,Sijie Yang,Dun Tan,Jianfeng Dong,Jingjing Chen*

Main category: cs.CV

TL;DR: 提出交互式视频语料库检索任务IVCR，构建多轮对话数据集IVCR-200K，并基于多模态大语言模型开发交互框架

- Motivation: 现有视频检索系统缺乏与用户的交互，单向检索模式无法满足80.8%用户的个性化和动态需求，需要更真实的交互式检索系统
- Method: 引入IVCR任务，构建高质量双语多轮对话数据集IVCR-200K，提出基于多模态大语言模型的综合交互框架，支持多种交互模式
- Result: 实验证明数据集和框架的有效性，能够实现多轮、对话式、真实的用户-系统交互
- Conclusion: IVCR任务和框架为视频检索系统提供了更现实的交互范式，满足用户个性化需求，是视频检索领域的重要进展


### [156] [TokenPure: Watermark Removal through Tokenized Appearance and Structural Guidance](https://arxiv.org/abs/2512.01314)
*Pei Yang,Yepeng Liu,Kelly Peng,Yuan Gao,Yiren Song*

Main category: cs.CV

TL;DR: TokenPure是一个基于扩散Transformer的水印去除框架，通过将水印图像分解为视觉token和结构token来条件化生成过程，在彻底去除水印的同时保持内容一致性。

- Motivation: 在数字经济时代，数字水印对于AI生成内容和其他虚拟资产的所有权证明至关重要。设计能够抵抗各种攻击和处理操作的鲁棒水印非常重要，但同时也需要有效的去除方法。现有方法在水印彻底去除和内容一致性之间存在权衡问题。
- Method: TokenPure采用基于扩散Transformer的框架，将水印去除任务重新定义为条件生成问题。它将水印图像分解为两个互补的token集合：用于纹理的视觉token和用于几何的结构token。这些token联合条件化扩散过程，使框架能够合成无水印图像，同时保持细粒度一致性和结构完整性。
- Result: 综合实验表明，TokenPure在水印去除和重建保真度方面达到了最先进的性能，在感知质量和一致性方面显著优于现有基线方法。
- Conclusion: TokenPure通过token化条件重建解决了水印彻底去除与内容一致性之间的权衡问题，为数字水印去除提供了有效的解决方案，在数字经济时代具有重要应用价值。


### [157] [FOD-S2R: A FOD Dataset for Sim2Real Transfer Learning based Object Detection](https://arxiv.org/abs/2512.01315)
*Ashish Vashist,Qiranul Saadiyean,Suresh Sundaram,Chandra Sekhar Seelamantula*

Main category: cs.CV

TL;DR: 提出了首个针对飞机油箱内异物碎片检测的数据集FOD-S2R，包含真实和合成图像，用于评估合成数据在封闭环境检测中的效果，并证明合成数据能提升检测精度和泛化能力。

- Motivation: 飞机油箱内的异物碎片（FOD）会带来严重安全隐患，但目前缺乏针对这种封闭复杂环境的专用数据集。现有数据集主要关注外部或开放环境，无法满足油箱内部检测需求。
- Method: 创建了FOD-S2R数据集，包含3,114张在受控油箱复制品中拍摄的高清真实图像和3,137张使用Unreal Engine生成的合成图像。数据集涵盖不同视场角、物体距离、光照条件、颜色和物体大小。
- Result: 基准测试显示，引入合成数据能显著提升目标检测模型的准确率，并增强模型在真实条件下的泛化能力，有效缩小了模拟到现实的差距。
- Conclusion: 该研究证明了合成数据在封闭环境异物碎片检测中的有效性，为开发自动化航空维护检测系统提供了宝贵基础，解决了该领域数据集缺乏的问题。


### [158] [Rethinking Intracranial Aneurysm Vessel Segmentation: A Perspective from Computational Fluid Dynamics Applications](https://arxiv.org/abs/2512.01319)
*Feiyang Xiao,Yichi Zhang,Xigui Li,Yuanye Zhou,Chen Jiang,Xin Guo,Limei Han,Yuxin Li,Fengping Zhu,Yuan Cheng*

Main category: cs.CV

TL;DR: 提出了首个全面的颅内动脉瘤血管分割数据集IAVS，包含641个3D MRA图像和587个标注，并建立了包含血流动力学分析的标准化CFD适用性评估系统。

- Motivation: 现有颅内动脉瘤分割方法主要关注图像评估指标，忽视了在后续计算流体动力学（CFD）应用中的实际有效性，缺乏考虑拓扑完整性和CFD适用性的数据集。
- Method: 构建了IAVS多中心数据集，包含图像-掩码对和血流动力学分析结果；建立了两个评估基准（动脉瘤全局定位和精细分割）和两阶段框架；开发了标准化的CFD适用性评估系统，实现分割掩码到CFD模型的自动转换。
- Result: 创建了首个包含血流动力学分析的综合颅内动脉瘤血管分割数据集，提供了即用型方法和强基线，建立了标准化的CFD适用性评估框架，所有资源将公开可用。
- Conclusion: IAVS数据集填补了现有数据集在拓扑完整性和CFD适用性方面的空白，为开发临床相关技术提供了全面评估平台，促进了分割方法在实际血流动力学分析中的应用价值评估。


### [159] [Optimizing Stroke Risk Prediction: A Machine Learning Pipeline Combining ROS-Balanced Ensembles and XAI](https://arxiv.org/abs/2512.01333)
*A S M Ahsanul Sarkar Akib,Raduana Khawla,Abdul Hasib*

Main category: cs.CV

TL;DR: 该研究开发了一个结合集成建模和可解释AI的机器学习框架，用于中风风险预测，在Stroke Prediction Dataset上达到99.09%的准确率，并识别出年龄、高血压和血糖水平三个关键临床变量。

- Motivation: 中风是全球主要的死亡和永久性损伤原因，早期风险评估对于及时干预和有效预防策略至关重要。需要开发准确且可解释的预测模型来支持临床决策。
- Method: 采用集成建模和可解释AI技术，包括数据预处理、特征工程、使用随机过采样处理类别不平衡问题。评估了10种不同机器学习模型，使用5折交叉验证，最终优化了集成模型（随机森林+ExtraTrees+XGBoost）。使用LIME进行可解释性分析。
- Result: 优化的集成模型在Stroke Prediction Dataset上取得了99.09%的准确率。通过LIME可解释性分析识别出三个关键临床变量：年龄、高血压和血糖水平。
- Conclusion: 集成学习与可解释AI的结合能够提供高准确性和可解释性的中风风险评估，通过早期预测支持数据驱动的预防和个性化临床决策，有望改变中风预测和心血管风险管理。


### [160] [AlignVid: Training-Free Attention Scaling for Semantic Fidelity in Text-Guided Image-to-Video Generation](https://arxiv.org/abs/2512.01334)
*Yexin Liu,Wen-Jie Shu,Zile Huang,Haoze Zheng,Yueze Wang,Manyuan Zhang,Ser-Nam Lim,Harry Yang*

Main category: cs.CV

TL;DR: AlignVid是一个无需训练的框架，通过注意力缩放调制和引导调度来改善文本引导图像到视频生成中的语义遵循问题，特别是在需要图像显著变换的场景中。

- Motivation: 现有文本引导图像到视频生成方法在处理需要图像显著变换（如对象添加、删除或修改）的提示时，存在语义忽视问题，无法充分遵循细粒度提示语义。
- Method: 提出AlignVid框架，包含两个组件：1) 注意力缩放调制(ASM)，通过轻量级的Q或K缩放直接重新加权注意力；2) 引导调度(GS)，在transformer块和去噪步骤中选择性应用ASM以减少视觉质量退化。还提出了OmitI2V评估数据集。
- Result: 实验表明AlignVid能够显著增强语义保真度，在需要图像显著变换的场景中改善提示遵循能力，同时限制美学质量退化。
- Conclusion: AlignVid通过简单的注意力调制机制有效解决了TI2V生成中的语义忽视问题，为改善文本引导视频生成的语义遵循提供了有效的训练免费解决方案。


### [161] [EvalTalker: Learning to Evaluate Real-Portrait-Driven Multi-Subject Talking Humans](https://arxiv.org/abs/2512.01340)
*Yingjie Zhou,Xilei Zhu,Siyu Ren,Ziyi Zhao,Ziwen Wang,Farong Wen,Yu Zhou,Jiezhang Cao,Xiongkuo Min,Fengjiao Chen,Xiaoyu Li,Xuezhi Cao,Guangtao Zhai,Xiaohong Liu*

Main category: cs.CV

TL;DR: 论文构建了首个大规模多说话人生成质量评估数据集THQA-MT，并提出EvalTalker评估框架，用于评估多说话人生成的视频质量。

- Motivation: 当前多说话人生成技术存在质量下降问题，导致用户体验不佳，需要建立有效的质量评估方法来推动高质量多说话人生成技术的发展。
- Method: 1) 构建THQA-MT数据集：包含5,492个多说话人生成视频，来自15个代表性模型和400个真实肖像；2) 提出EvalTalker评估框架：感知全局质量、人物特征、身份一致性，并集成Qwen-Sync感知多模态同步性。
- Result: 通过主观实验分析了不同多说话人生成模型的感知差异，识别了12种常见失真类型。EvalTalker在主观评分相关性方面表现优异。
- Conclusion: THQA-MT数据集和EvalTalker框架为未来高质量多说话人生成和评估研究提供了坚实基础，有助于推动该领域的发展。


### [162] [InternVideo-Next: Towards General Video Foundation Models without Video-Text Supervision](https://arxiv.org/abs/2512.01342)
*Chenting Wang,Yuhan Zhu,Yicheng Xu,Jiange Yang,Ziang Yan,Yali Wang,Yi Wang,Limin Wang*

Main category: cs.CV

TL;DR: 论文提出InternVideo-Next框架，通过两阶段预训练解决视频表示学习中的语义与细节冲突问题，在公开无标签视频上实现SOTA性能。

- Motivation: 现有大规模视频-文本预训练依赖噪声合成字幕且语义覆盖有限，忽视隐式世界知识（如物体运动、3D几何、物理线索）；而掩码视频建模（MVM）直接利用时空结构但在通用任务上落后于文本监督方法。这种差距源于被忽视的架构问题：像素级重建收敛困难且低层需求与语义冲突，而潜在预测常导致捷径学习。
- Method: 提出Encoder-Predictor-Decoder（EPD）框架，将传统编码器-解码器设计解耦，其中预测器作为潜在世界模型。采用两阶段预训练方案：第一阶段使用条件扩散解码器并注入可靠的图像级语义先验，增强语义和收敛性；第二阶段在已建立的潜在空间中预测冻结的第一阶段目标，学习世界知识并缓解捷径学习。
- Result: 在公开无标签视频上训练的InternVideo-Next在多个基准测试中实现了最先进的结果，为通用视频表示学习提供了可扩展的路径。
- Conclusion: 通过解耦编码器-预测器-解码器架构和两阶段预训练，成功构建了语义一致且保留细节的潜在空间，有效解决了视频表示学习中语义抽象与像素保真度的冲突问题。


### [163] [Handwritten Text Recognition for Low Resource Languages](https://arxiv.org/abs/2512.01348)
*Sayantan Dey,Alireza Alaei,Partha Pratim Roy*

Main category: cs.CV

TL;DR: 提出BharatOCR，一种无需分割的段落级手写印地语和乌尔都语文本识别系统，采用ViT-Transformer解码器-语言模型架构，在多个数据集上取得最佳性能。

- Motivation: 印地语、乌尔都语等低资源语言缺乏全面的语言资源，段落级手写文本识别仍然具有挑战性，需要开发鲁棒的光学字符识别系统。
- Method: 提出ViT-Transformer解码器-语言模型架构：使用Vision Transformer提取视觉特征，Transformer解码器生成文本序列，预训练语言模型优化输出。采用DeiT进行掩码图像建模，RoBERTa进行掩码语言建模，实现隐式行分割的逐行处理。
- Result: 在NUST-UHWR数据集上字符识别率达到96.24%，PUCIT-OUHL达到92.05%，Parimal-Urdu达到94.80%，印地语数据集达到80.64%，均优于现有最先进的乌尔都语文本识别方法。
- Conclusion: BharatOCR系统在低资源语言的段落级手写文本识别方面表现出色，为印地语和乌尔都语等类似文字提供了有效的OCR解决方案，在多个数据集上建立了新的基准。


### [164] [OpenBox: Annotate Any Bounding Boxes in 3D](https://arxiv.org/abs/2512.01352)
*In-Jae Lee,Mungyeom Kim,Kwonyoung Ryu,Pierre Musacchio,Jaesik Park*

Main category: cs.CV

TL;DR: OpenBox：利用2D视觉基础模型的两阶段自动标注流水线，无需自训练即可生成高质量3D边界框标注

- Motivation: 现有无监督和开放词汇3D目标检测方法存在三个主要问题：1）统一标注3D边界框，忽略物体物理状态；2）需要多次自训练迭代进行标注细化；3）导致标注质量不优且计算开销大。这些问题在自动驾驶中尤为关键，因为降低标注成本和识别未见物体对安全性和可扩展性至关重要。
- Method: OpenBox采用两阶段流水线：第一阶段通过跨模态实例对齐，将2D视觉基础模型处理的图像实例级线索与对应3D点云关联；第二阶段根据刚性和运动状态对实例分类，然后使用类别特定尺寸统计生成自适应边界框。
- Result: 在Waymo Open Dataset、Lyft Level 5 Perception dataset和nuScenes数据集上的实验表明，OpenBox在准确性和效率上均优于基线方法，无需自训练即可生成高质量3D边界框标注。
- Conclusion: OpenBox成功解决了现有3D目标自动标注方法的局限性，通过利用2D视觉基础模型和物理状态感知的自适应边界框生成，实现了高效、高质量的3D标注，为自动驾驶等应用提供了实用的解决方案。


### [165] [BlinkBud: Detecting Hazards from Behind via Sampled Monocular 3D Detection on a Single Earbud](https://arxiv.org/abs/2512.01366)
*Yunzhe Li,Jiajun Yan,Yuzhou Wei,Kechen Liu,Yize Zhao,Chong Zhang,Hongzi Zhu,Li Lu,Shan Chang,Minyi Guo*

Main category: cs.CV

TL;DR: BlinkBud：利用单耳塞和配对手机检测后方危险车辆的系统，通过3D目标跟踪算法和强化学习优化图像采样，实现低功耗高精度检测

- Motivation: 行人和骑行者无法察觉后方快速接近的车辆构成重大安全威胁，需要一种低功耗、高精度的实时危险检测系统
- Method: 结合卡尔曼滤波轨迹估计和强化学习优化图像采样策略的3D目标跟踪算法，利用耳塞摄像头和手机处理，通过头部姿态校正消除运动干扰
- Result: 系统功耗极低（耳塞29.8mW，手机702.6mW），检测精度高（平均假阳性率4.90%，假阴性率1.47%）
- Conclusion: BlinkBud系统通过创新的3D跟踪算法和头部姿态校正技术，实现了高效、低功耗的后方危险车辆检测，显著提升道路安全


### [166] [SRAM: Shape-Realism Alignment Metric for No Reference 3D Shape Evaluation](https://arxiv.org/abs/2512.01373)
*Sheng Liu,Tianyu Luan,Phani Nuney,Xuelu Feng,Junsong Yuan*

Main category: cs.CV

TL;DR: 提出Shape-Realism Alignment Metric，利用大语言模型作为3D网格形状信息与真实感评估之间的桥梁，无需地面真值即可评估3D形状的真实感。

- Motivation: 传统3D形状评估方法依赖地面真值测量网格保真度，但在许多实际应用中，形状的真实感并不需要地面真值参考。现有方法无法有效评估无参考情况下的形状真实感。
- Method: 1) 采用网格编码方法将3D形状转换为语言标记空间；2) 设计专门的真实感解码器，将语言模型输出与人类真实感感知对齐；3) 引入新的数据集RealismGrading，包含16种不同算法生成的形状，提供无需地面真值的人类标注真实感分数。
- Result: 通过不同对象的k折交叉验证验证了度量的性能和泛化能力。实验结果表明，该度量与人类感知相关性良好，优于现有方法，并具有良好的泛化性。
- Conclusion: 提出的Shape-Realism Alignment Metric能够有效评估3D形状的真实感，无需地面真值参考，在3D生成和重建应用中具有实用价值。


### [167] [Textured Geometry Evaluation: Perceptual 3D Textured Shape Metric via 3D Latent-Geometry Network](https://arxiv.org/abs/2512.01380)
*Tianyu Luan,Xuelu Feng,Zixin Zhu,Phani Nuney,Sheng Liu,Xuan Gong,David Doermann,Chunming Qiao,Junsong Yuan*

Main category: cs.CV

TL;DR: 提出TGE方法，直接基于带纹理的3D网格评估保真度，无需渲染，结合几何和颜色信息，在真实世界失真数据集上优于现有方法。

- Motivation: 现有3D模型保真度评估方法存在三个主要问题：1) 传统几何指标（如Chamfer Distance）与人类感知不一致；2) 基于渲染和2D图像质量的方法存在结构覆盖不全和视角选择敏感问题；3) 大多数方法在合成失真数据上训练，与真实世界失真存在领域差距。
- Method: 提出Textured Geometry Evaluation (TGE)方法，直接基于带纹理的3D网格进行评估，无需渲染步骤。该方法联合使用几何和颜色信息来计算输入纹理网格相对于参考彩色形状的保真度。为训练和评估该方法，构建了人工标注的真实世界失真数据集。
- Result: 实验表明，TGE在真实世界失真数据集上的表现优于基于渲染的方法和仅使用几何信息的方法。
- Conclusion: TGE通过直接处理带纹理的3D网格，避免了渲染方法的局限性，能够更准确地评估3D模型的保真度，与人类感知更加一致。


### [168] [Reversible Inversion for Training-Free Exemplar-guided Image Editing](https://arxiv.org/abs/2512.01382)
*Yuke Li,Lianli Gao,Ji Zhang,Pengpeng Zeng,Lichuan Xiang,Hongkai Wen,Heng Tao Shen,Jingkuan Song*

Main category: cs.CV

TL;DR: 提出ReInversion方法，通过两阶段去噪和掩码引导选择性去噪，实现高效免训练的示例引导图像编辑

- Motivation: 现有示例引导图像编辑方法需要大规模预训练计算成本高，而标准反转技术效果差且效率低，需要更好的免训练解决方案
- Method: ReInversion：两阶段去噪过程，先以源图像为条件，再以参考图像为条件；Mask-Guided Selective Denoising策略限制编辑到目标区域，保持背景结构一致性
- Result: 定性和定量比较表明，ReInversion方法在示例引导图像编辑任务上达到最先进性能，且计算开销最低
- Conclusion: ReInversion为示例引导图像编辑提供了有效且高效的免训练解决方案，解决了现有方法的计算成本和效果问题


### [169] [PointNet4D: A Lightweight 4D Point Cloud Video Backbone for Online and Offline Perception in Robotic Applications](https://arxiv.org/abs/2512.01383)
*Yunze Liu,Zifan Wang,Peiran Wu,Jiayang Ao*

Main category: cs.CV

TL;DR: PointNet4D：轻量级4D骨干网络，结合Mamba状态空间模型和Transformer，优化实时点云视频处理，支持在线和离线场景，在多种任务和数据集上表现优异。

- Motivation: 机器人系统和交互应用需要实时处理动态4D环境（3D空间随时间演化），但现有4D骨干网络依赖计算密集的时空卷积和Transformer，不适合实时应用和资源受限场景。
- Method: 提出PointNet4D轻量级4D骨干网络，核心是混合Mamba-Transformer时序融合模块，结合Mamba的高效状态空间建模和Transformer的双向建模能力。引入4DMAP帧级掩码自回归预训练策略，捕捉跨帧运动线索。
- Result: 在7个数据集的9个任务上进行广泛评估，在不同领域均取得一致改进。构建了两个机器人应用系统：4D Diffusion Policy和4D Imitation Learning，在RoboTwin和HandoverSim基准测试中取得显著提升。
- Conclusion: PointNet4D是一个高效轻量的4D骨干网络，能够处理可变长度的在线序列，适用于实时机器人应用，在多种任务和数据集上表现出色，为动态4D环境理解提供了实用解决方案。


### [170] [FRAMER: Frequency-Aligned Self-Distillation with Adaptive Modulation Leveraging Diffusion Priors for Real-World Image Super-Resolution](https://arxiv.org/abs/2512.01390)
*Seungho Choi,Jeahun Sung,Jihyong Oh*

Main category: cs.CV

TL;DR: FRAMER是一种即插即用的训练方案，通过频域分解和对比学习解决扩散模型在真实图像超分辨率中的低频偏见问题，无需修改主干网络即可提升高频细节重建。

- Motivation: 扩散模型在真实图像超分辨率中虽然感知质量优于GAN，但由于低频偏见和"先低频后高频"的深度层次结构，导致高频细节重建不足。
- Method: 提出FRAMER训练方案：1) 使用最终层特征图指导所有中间层；2) 通过FFT掩码将特征分解为低频/高频分量；3) 低频使用IntraCL稳定全局结构；4) 高频使用InterCL增强实例特定细节；5) 引入FAW和FAM自适应调制器调整各层信号权重。
- Result: 在U-Net和DiT主干网络（如Stable Diffusion 2、3）上，FRAMER一致提升了PSNR/SSIM和感知指标（LPIPS、NIQE、MANIQA、MUSIQ）。消融实验验证了最终层教师和随机层负样本的有效性。
- Conclusion: FRAMER通过频域对齐的对比学习有效解决了扩散模型在真实图像超分辨率中的高频细节重建问题，是一种无需修改主干网络的高效训练方案。


### [171] [Rice-VL: Evaluating Vision-Language Models for Cultural Understanding Across ASEAN Countries](https://arxiv.org/abs/2512.01419)
*Tushar Pranav,Eshan Pandey,Austria Lyka Diane Bala,Aman Chadha,Indriyati Atmosukarto,Donny Soh Cheng Lock*

Main category: cs.CV

TL;DR: RICE-VL是一个评估视觉语言模型文化理解能力的新基准，专注于东南亚11个东盟国家，包含超过28,000个VQA样本和1,000个图像-边界框对，揭示了现有模型在文化多样性理解上的局限性。

- Motivation: 现有视觉语言模型存在西方中心偏见，在东南亚等文化多元地区的表现受限，需要专门的基准来评估和改进模型的文化理解能力。
- Method: 创建RICE-VL基准，包含人类专家标注的VQA样本（真/假、填空、开放式）和视觉定位任务；提出SEA-LAVE评估指标，衡量文本准确性、文化对齐和国家识别能力。
- Result: 评估6个开源和闭源VLM显示，在低资源国家和抽象文化领域存在显著性能差距；视觉定位任务测试了模型在复杂场景中定位文化重要元素的能力。
- Conclusion: RICE-VL暴露了VLM在文化理解上的局限性，强调需要更具包容性的模型开发来更好地服务全球多样化人群。


### [172] [MDiff4STR: Mask Diffusion Model for Scene Text Recognition](https://arxiv.org/abs/2512.01422)
*Yongkun Du,Miaomiao Zhao,Songlin Fan,Zhineng Chen,Caiyan Jia,Yu-Gang Jiang*

Main category: cs.CV

TL;DR: 将掩码扩散模型首次引入场景文本识别任务，提出MDiff4STR模型，通过改进噪声策略和预测机制，在保持高效推理的同时超越自回归模型的准确率。

- Motivation: 掩码扩散模型在视觉语言任务中展现出效率和准确性的良好平衡，但尚未应用于场景文本识别任务。研究发现原始掩码扩散模型在STR任务中准确率落后于自回归模型，需要改进以充分发挥其潜力。
- Method: 提出MDiff4STR模型，针对STR任务的两个关键挑战：训练与推理的噪声差距、推理过程中的过度自信预测。开发了六种噪声策略以对齐训练与推理行为，并提出token替换噪声机制来修正过度自信的错误预测。
- Result: 在标准STR基准和挑战性场景（不规则、艺术、遮挡、中文文本等）上全面评估，MDiff4STR在多种设置下均优于流行的STR模型，超越最先进的自回归模型准确率，同时仅需三步去噪实现快速推理。
- Conclusion: 成功将掩码扩散模型应用于场景文本识别任务，通过针对性的改进策略解决了关键挑战，实现了在准确率和效率上的双重优势，为STR任务提供了新的有效解决方案。


### [173] [\textit{ViRectify}: A Challenging Benchmark for Video Reasoning Correction with Multimodal Large Language Models](https://arxiv.org/abs/2512.01424)
*Xusen Hei,Jiali Chen,Jinyu Yang,Mengchen Zhao,Yi Cai*

Main category: cs.CV

TL;DR: ViRectify是一个评估多模态大语言模型视频推理错误纠正能力的基准，包含3万多个实例，涵盖动态感知、科学推理和具身决策领域，GPT-5仅达到31.94%的纠正准确率。

- Motivation: 多模态大语言模型在复杂视频推理场景中经常出错，但现有基准缺乏对这些模型识别和纠正错误能力的系统评估。需要建立一个全面的基准来揭示模型的弱点并提升性能。
- Method: 通过AI辅助标注流程和人工验证构建超过3万个实例的数据集。提出轨迹证据驱动的纠正框架，包括逐步错误轨迹和视觉证据基础纠正的奖励建模，使模型专注于错误传播和关键时间戳。
- Result: 在16个先进MLLM上的广泛评估显示，ViRectify是一个具有挑战性的测试平台，GPT-5仅达到31.94%的纠正准确率。提出的框架使Qwen2.5-VL-7B模型在ViRectify上持续优于72B变体。
- Conclusion: ViRectify为全面评估MLLM在视频推理中的能力提供了新方向，揭示了模型在错误纠正中的系统性不对称性，数据集也可用于反思学习，是宝贵的数据资源。


### [174] [ResDiT: Evoking the Intrinsic Resolution Scalability in Diffusion Transformers](https://arxiv.org/abs/2512.01426)
*Yiyang Ma,Feng Zhou,Xuedan Yin,Pu Cao,Yonghao Dang,Jianqin Yin*

Main category: cs.CV

TL;DR: ResDiT：一种无需训练的扩散Transformer分辨率缩放方法，通过位置嵌入缩放和局部增强机制解决高分辨率图像合成中的布局崩溃和纹理退化问题。

- Motivation: 预训练的扩散Transformer（DiTs）在高分辨率图像合成中经常出现空间布局崩溃和纹理保真度下降的问题。现有方法通常采用复杂的多阶段流程，而本文旨在探索DiTs的内在生成机制，开发更高效的无训练分辨率缩放方法。
- Method: 提出ResDiT方法：1）识别位置嵌入（PEs）是控制空间布局的核心因素，开发PE缩放技术纠正分辨率变化时的位置编码；2）基于基础分辨率局部注意力设计局部增强机制；3）设计补丁级融合模块聚合全局和局部线索；4）采用高斯加权拼接策略消除网格伪影。
- Result: 综合评估表明，ResDiT能够持续生成高保真度的高分辨率图像，并可与下游任务（包括空间控制生成）无缝集成。
- Conclusion: ResDiT通过分析扩散Transformer的内在生成机制，提出了一种无需训练的高效分辨率缩放方法，有效解决了高分辨率图像合成中的布局崩溃和纹理退化问题，为扩散模型的实际应用提供了实用解决方案。


### [175] [Language-Guided Open-World Anomaly Segmentation](https://arxiv.org/abs/2512.01427)
*Klara Reichard,Nikolas Brasch,Nassir Navab,Federico Tombari*

Main category: cs.CV

TL;DR: Clipomaly：首个基于CLIP的自动驾驶开放世界与异常分割方法，无需异常训练数据，能动态扩展词汇表并给未知物体分配可解释的名称

- Motivation: 现有开放世界和异常分割方法无法给未知区域分配语义上有意义的标签，也难以区分和学习未知类别的表示。开放词汇分割方法虽然能泛化到新类别，但需要固定的推理词汇表，无法直接应用于类别不受限制的异常分割场景。
- Method: 提出Clipomaly，基于CLIP的零样本方法，无需异常特定训练数据。利用CLIP共享的图像-文本嵌入空间，既能分割未知物体，又能为它们分配人类可解释的名称。与开放词汇方法不同，该模型在推理时能动态扩展词汇表而无需重新训练。
- Result: 在已建立的异常分割基准测试中实现了最先进的性能，同时提供了实际部署所需的可解释性和灵活性。
- Conclusion: Clipomaly是首个基于CLIP的自动驾驶开放世界与异常分割方法，通过零样本方法解决了现有方法的局限性，能够检测和命名超出常见类别定义（如Cityscapes）的异常，为实际应用提供了重要价值。


### [176] [FastAnimate: Towards Learnable Template Construction and Pose Deformation for Fast 3D Human Avatar Animation](https://arxiv.org/abs/2512.01444)
*Jian Shu,Nanjie Yao,Gangjian Zhang,Junlong Ren,Yu Feng,Hao Wang*

Main category: cs.CV

TL;DR: 提出统一学习框架解决3D人体化身动画中的两个核心问题：通过U-Net快速生成人体模板，并通过数据驱动优化提升变形质量

- Motivation: 现有方法将3D人体化身动画分为模板构建和目标姿态变形两个阶段，但模板构建需要大量骨骼绑定且会产生伪影，而目标姿态变形因线性混合蒙皮导致结构失真，影响动画真实感
- Method: 提出统一学习框架：1) 使用U-Net架构在正向传播过程中解耦纹理和姿态信息，快速生成人体模板；2) 提出数据驱动的优化技术增强结构完整性
- Result: 实验表明该模型在不同姿态下表现一致，在效率和质量之间达到最佳平衡，超越了现有最先进方法
- Conclusion: 提出的统一学习框架有效解决了3D人体化身动画中的模板构建和目标姿态变形问题，实现了高质量且高效的动画生成


### [177] [CourtMotion: Learning Event-Driven Motion Representations from Skeletal Data for Basketball](https://arxiv.org/abs/2512.01478)
*Omer Sela,Michael Chertok,Lior Wolf*

Main category: cs.CV

TL;DR: CourtMotion：一个用于分析和预测职业篮球比赛事件与战术发展的时空建模框架，通过骨骼追踪数据和图神经网络捕捉细微运动模式，结合Transformer建模球员交互，显著优于仅基于位置的基线方法。

- Motivation: 预测篮球事件需要理解物理运动模式及其在比赛中的语义意义。传统仅使用球员位置的方法无法捕捉身体朝向、防守姿态或投篮准备动作等关键指标，因此需要更全面的运动分析框架。
- Method: 采用两阶段方法：1）使用图神经网络处理骨骼追踪数据捕捉细微运动模式；2）使用具有专门注意力机制的Transformer架构建模球员交互。引入事件投影头，将球员动作与篮球事件（传球、投篮、抢断）明确连接，训练模型将物理运动模式与战术目的关联。
- Result: 在NBA追踪数据上的实验显示：相比最先进的基于位置模型，轨迹预测误差减少35%；在关键篮球分析任务上表现一致提升；预训练模型作为多个下游任务的强大基础，在挡拆检测、投篮者识别、助攻预测、投篮位置分类和投篮类型识别等任务上显著优于现有方法。
- Conclusion: CourtMotion框架通过整合骨骼追踪数据和语义事件建模，显著提升了篮球事件预测和分析能力，为篮球战术分析和预测提供了更全面的解决方案。


### [178] [ChronosObserver: Taming 4D World with Hyperspace Diffusion Sampling](https://arxiv.org/abs/2512.01481)
*Qisen Wang,Yifan Zhao,Peisen Shen,Jialu Li,Jia Li*

Main category: cs.CV

TL;DR: ChronosObserver：无需训练的4D世界生成方法，通过世界状态超空间和超空间引导采样实现高保真、3D一致的时间同步多视角视频生成

- Motivation: 现有相机控制视频生成模型难以直接扩展到3D一致、高保真的时间同步多视角视频生成，而这是驯服4D世界的关键能力。现有方法依赖数据增强或测试时优化，但受限于模型泛化能力和可扩展性问题。
- Method: 提出ChronosObserver方法，包含两个核心组件：1) 世界状态超空间：表示4D世界场景的时空约束；2) 超空间引导采样：利用超空间同步多个视角的扩散采样轨迹。该方法无需训练或微调扩散模型。
- Result: 实验结果表明，该方法能够在不训练或微调扩散模型的情况下，实现高保真、3D一致的时间同步多视角视频生成。
- Conclusion: ChronosObserver提供了一种无需训练的解决方案，成功解决了4D世界场景中多视角视频生成的时空同步和3D一致性问题，具有更好的泛化能力和可扩展性。


### [179] [A variational method for curve extraction with curvature-dependent energies](https://arxiv.org/abs/2512.01494)
*Majid Arthaud,Antonin Chambolle,Vincent Duval*

Main category: cs.CV

TL;DR: 提出了一种基于变分方法和Smirnov分解定理的曲线提取方法，能够从图像中自动提取曲线和1D结构，并扩展到曲率相关能量。

- Motivation: 需要一种能够自动从图像中提取曲线和1D结构的方法，特别是在给定端点列表的情况下，同时希望方法具有无监督特性。
- Method: 基于能量离散化和Smirnov向量场分解定理的变分方法，采用双层最小化框架，并扩展到曲率相关能量，使用位置-方向空间中的子黎曼或Finsler度量提升。
- Result: 开发了一种主要无监督的曲线提取方法，能够处理端点列表，并能扩展到考虑曲率约束的情况。
- Conclusion: 该方法提供了一种有效的曲线提取框架，结合了变分方法、向量场分解和几何提升技术，适用于图像中的1D结构检测。


### [180] [ELVIS: Enhance Low-Light for Video Instance Segmentation in the Dark](https://arxiv.org/abs/2512.01495)
*Joanne Lin,Ruirui Lin,Yini Li,David Bull,Nantheera Anantrasirichai*

Main category: cs.CV

TL;DR: ELVIS是一个用于低光视频实例分割的新框架，通过无监督合成低光视频管道、退化特征解耦和增强解码器，显著提升了低光场景下的分割性能。

- Motivation: 低光视频实例分割面临噪声、模糊、低对比度等成像问题，缺乏大规模标注数据集，现有合成管道难以模拟时间退化，且现有VIS方法对低光退化不鲁棒。
- Method: ELVIS包含三个核心组件：1) 无监督合成低光视频管道，建模空间和时间退化；2) 无需校准的退化特征合成网络(VDP-Net)；3) 增强解码器头，将退化特征与内容特征解耦。
- Result: 在合成的低光YouTube-VIS 2019数据集上，ELVIS将性能提升了高达+3.7AP。
- Conclusion: ELVIS通过有效的域适应策略，显著提升了最先进VIS模型在低光场景下的性能，为解决低光视频实例分割的挑战提供了新思路。


### [181] [Semantic-aware Random Convolution and Source Matching for Domain Generalization in Medical Image Segmentation](https://arxiv.org/abs/2512.01510)
*Franz Thaler,Martin Urschler,Mateusz Kozinski,Matthias AF Gsell,Gernot Plank,Darko Stern*

Main category: cs.CV

TL;DR: 提出SRCSM方法解决医学图像分割中的单源域泛化问题，通过语义感知随机卷积增强源域多样性，在测试时通过强度映射使目标域图像与源域相似，在多种跨模态和跨中心分割任务中达到SOTA性能。

- Motivation: 解决医学图像分割中的单源域泛化挑战：训练时只使用一个域（如CT）的数据，测试时直接应用于不同域（如MR），无需模型适应或新域的训练数据。
- Method: 提出SRCSM方法：1）训练时使用语义感知随机卷积增强源域多样性，根据标注标签对图像不同区域进行差异化增强；2）测试时通过强度映射使目标域图像与源域数据相似。
- Result: 在腹部、全心和前列腺分割的多种跨模态和跨中心泛化设置中，SRCSM在绝大多数实验中优于现有DG技术；在CT/MR到不同扫描硬件采集的舒张/收缩期cine MR数据的更挑战性设置中，显著缩小了域差距。
- Conclusion: SRCSM成为医学图像分割域泛化的新SOTA方法，在多个设置中甚至达到了域内基线的分割性能，为解决医学图像分割中的域泛化问题提供了有效方案。


### [182] [QuantumCanvas: A Multimodal Benchmark for Visual Learning of Atomic Interactions](https://arxiv.org/abs/2512.01519)
*Can Polat,Erchin Serpedin,Mustafa Kurban,Hasan Kurban*

Main category: cs.CV

TL;DR: QuantumCanvas是一个大规模多模态基准数据集，将双体量子系统作为物质的基本单元，包含2850个元素-元素对，提供18种电子、热力学和几何性质，以及十通道图像表示，用于学习可转移的量子相互作用。

- Motivation: 当前分子和材料机器学习模型大多缺乏物理可转移性，它们拟合整个分子或晶体的相关性，而不是学习原子对之间的量子相互作用。然而，键合、电荷重分布、轨道杂化和电子耦合都源于这些双体相互作用，这些相互作用定义了多体系统中的局域量子场。
- Method: 引入QuantumCanvas数据集，涵盖2850个元素-元素对，每个对标注18种电子、热力学和几何性质，并配对十通道图像表示（包括l-和m-分辨轨道密度、角场变换、共占据图和电荷密度投影）。这些基于物理的图像编码了空间、角和静电对称性，无需显式坐标。基准测试了8种架构在18个目标上的性能。
- Result: GATv2在能隙上达到0.201 eV的MAE，EGNN在HOMO和LUMO上分别达到0.265 eV和0.274 eV的MAE。DimeNet在总能量上达到2.27 eV MAE，在排斥能量上达到0.132 eV MAE。多模态融合模型在Mermin自由能上达到2.15 eV MAE。在QuantumCanvas上预训练可提高在QM9、MD17和CrysMTM等更大数据集上的收敛稳定性和泛化能力。
- Conclusion: 通过将轨道物理与基于视觉的表征学习相结合，QuantumCanvas为通过耦合视觉和数值模态学习可转移的量子相互作用提供了原则性和可解释的基础。


### [183] [Diffusion Fuzzy System: Fuzzy Rule Guided Latent Multi-Path Diffusion Modeling](https://arxiv.org/abs/2512.01533)
*Hailong Yang,Te Zhang,Kup-sze Choi,Zhaohong Deng*

Main category: cs.CV

TL;DR: 本文提出了一种基于模糊规则的潜在空间多路径扩散模型（DFS），通过多个专门学习不同图像特征的扩散路径和规则链推理，解决了传统扩散模型在处理特征差异大的图像集合时的局限性，同时降低了计算成本。

- Motivation: 扩散模型在生成高分辨率真实图像方面表现出色，但在处理特征差异显著的图像集合时存在困难，难以捕捉复杂特征且会产生冲突结果。现有多路径方法存在路径间协调效率低和计算成本高的问题。
- Method: 提出扩散模糊系统（DFS）：1）使用多个专门学习特定类别图像特征的扩散路径；2）采用基于规则链的推理动态引导扩散过程，实现多路径高效协调；3）引入基于模糊隶属度的潜在空间压缩机制降低计算成本。
- Result: 在LSUN Bedroom、LSUN Church和MS COCO三个公开数据集上的实验表明，DFS相比现有单路径和多路径扩散模型具有更稳定的训练和更快的收敛速度，在图像质量、文本-图像对齐度以及生成图像与目标参考的匹配精度方面均优于基线模型。
- Conclusion: DFS通过模糊规则引导的多路径扩散架构，有效解决了传统扩散模型在处理异质图像特征时的局限性，实现了更高效的路径协调和更低的计算成本，在多个指标上超越了现有方法。


### [184] [Deep Unsupervised Anomaly Detection in Brain Imaging: Large-Scale Benchmarking and Bias Analysis](https://arxiv.org/abs/2512.01534)
*Alexander Frotscher,Christian F. Baumgartner,Thomas Wolfers*

Main category: cs.CV

TL;DR: 大规模多中心脑影像无监督异常检测基准研究：评估多种算法性能，发现重建方法（特别是扩散模型）在病灶分割上表现最佳，但存在系统性偏差，当前方法主要受算法而非数据限制。

- Motivation: 脑磁共振成像中的深度无监督异常检测无需病灶标注即可识别病理偏差，但碎片化评估、异质数据集和不一致指标阻碍了临床转化，需要建立标准化基准。
- Method: 建立大规模多中心基准：训练集包含6台扫描仪的2,976个T1和2,972个T2健康扫描；验证集92个扫描调参；测试集2,221个T1w和1,262个T2w扫描涵盖健康与临床队列。系统评估算法对扫描仪、病灶类型/大小、人口统计学（年龄、性别）的鲁棒性。
- Result: 所有算法的Dice分割性能在0.03-0.65间波动，差异显著。重建方法（特别是扩散模型）病灶分割最强，特征方法在分布偏移下更鲁棒。多数算法存在系统性偏差：小病灶和低对比度病灶易漏检，假阳性随年龄性别变化。增加健康训练数据仅带来有限改善。
- Conclusion: 当前无监督异常检测框架主要受算法而非数据限制。基准为未来研究提供透明基础，临床转化需关注：图像原生预训练、原则性偏差度量、公平感知建模和鲁棒域适应。


### [185] [FlashVGGT: Efficient and Scalable Visual Geometry Transformers with Compressed Descriptor Attention](https://arxiv.org/abs/2512.01540)
*Zipeng Wang,Dan Xu*

Main category: cs.CV

TL;DR: FlashVGGT提出了一种高效的3D重建方法，通过描述符注意力机制替代VGGT的全自注意力，显著降低计算复杂度，实现长序列在线推理。

- Motivation: 现有基于全自注意力的3D重建方法（如VGGT）存在可扩展性问题，因为自注意力的二次复杂度和长图像序列产生的大量token导致计算开销巨大。
- Method: 提出描述符注意力机制：将每帧的空间信息压缩为紧凑的描述符token集合，然后在完整图像token集合和较小描述符集合之间进行交叉注意力计算；同时采用分块递归机制实现长序列在线推理。
- Result: FlashVGGT在重建精度上与VGGT相当，但对1000张图像的推理时间仅为VGGT的9.3%，并能高效扩展到超过3000张图像的长序列。
- Conclusion: FlashVGGT通过描述符注意力机制有效解决了3D重建中全自注意力的可扩展性问题，在保持精度的同时大幅提升效率，支持长序列在线推理。


### [186] [MasHeNe: A Benchmark for Head and Neck CT Mass Segmentation using Window-Enhanced Mamba with Frequency-Domain Integration](https://arxiv.org/abs/2512.01563)
*Thao Thi Phuong Dao,Tan-Cong Nguyen,Nguyen Chi Thanh,Truong Hoang Viet,Trong-Le Do,Mai-Khiem Tran,Minh-Khoi Pham,Trung-Nghia Le,Minh-Triet Tran,Thanh Dinh Le*

Main category: cs.CV

TL;DR: 提出了MasHeNe数据集和WEMF模型，用于头颈部肿块分割，超越了现有仅关注恶性肿瘤的数据集限制

- Motivation: 现有公开数据集主要关注恶性肿瘤，忽视了头颈部其他占位性病变，需要更全面的数据集来支持相关研究
- Method: 1) 创建MasHeNe数据集：包含3,779张增强CT切片，涵盖肿瘤和囊肿，提供像素级标注；2) 提出WEMF模型：采用三窗增强丰富输入外观，在多频注意力机制下融合跳跃连接信息，基于U型Mamba架构
- Result: WEMF在MasHeNe数据集上取得最佳性能：Dice 70.45%，IoU 66.89%，NSD 72.33%，HD95 5.12mm。模型在该挑战性任务上表现出稳定且强大的结果
- Conclusion: MasHeNe为超越仅恶性肿瘤的头颈部肿块分割提供了基准，观察到的错误模式表明该任务仍具挑战性，需要进一步研究。数据集和代码已开源


### [187] [RoleMotion: A Large-Scale Dataset towards Robust Scene-Specific Role-Playing Motion Synthesis with Fine-grained Descriptions](https://arxiv.org/abs/2512.01582)
*Junran Peng,Yiheng Huang,Silei Shen,Zeji Wei,Jingwei Yang,Baojie Wang,Yonghao He,Chuanchen Luo,Man Zhang,Xucheng Yin,Wei Sui*

Main category: cs.CV

TL;DR: RoleMotion是一个大规模人体动作数据集，专注于角色扮演和功能性动作，包含25个场景、110个角色、500多种行为，提供高质量的身体和手部动作序列及细粒度文本标注。

- Motivation: 现有文本驱动动作数据集存在以下问题：数据分散且非功能性、动作质量不一致、文本标注缺乏细粒度细节、难以覆盖各种社交场景。需要构建一个专注于场景和角色的高质量数据集。
- Method: 精心设计和收集数据集，包含25个经典场景、110个功能角色、500多种行为、10296个高质量身体和手部动作序列，并标注27831个细粒度文本描述。构建比现有更强的评估器并验证其可靠性。
- Result: 实验结果表明该数据集在文本驱动全身动作生成方面具有高质量和功能性。评估了多种文本到动作方法，并探索了身体和手部动作生成的相互作用。
- Conclusion: RoleMotion数据集填补了现有数据集的不足，为文本驱动的人体动作生成研究提供了高质量、功能性强、场景丰富的资源，推动了全身动作生成的发展。


### [188] [Toward Content-based Indexing and Retrieval of Head and Neck CT with Abscess Segmentation](https://arxiv.org/abs/2512.01589)
*Thao Thi Phuong Dao,Tan-Cong Nguyen,Trong-Le Do,Truong Hoang Viet,Nguyen Chi Thanh,Huynh Nguyen Thuan,Do Vo Cong Nguyen,Minh-Khoi Pham,Mai-Khiem Tran,Viet-Tham Huynh,Trong-Thuan Nguyen,Trung-Nghia Le,Vo Thanh Toan,Tam V. Nguyen,Minh-Triet Tran,Thanh Dinh Le*

Main category: cs.CV

TL;DR: AbscessHeNe数据集：包含4,926张增强CT切片，用于头颈部脓肿语义分割，为临床决策提供支持

- Motivation: 头颈部脓肿是急性感染性疾病，可能导致败血症或死亡，需要及时诊断和治疗。准确识别和分割这些病灶对临床决策至关重要。
- Method: 构建了AbscessHeNe数据集，包含临床确认的头颈部脓肿增强CT切片，评估了CNN、Transformer和Mamba等多种分割架构的性能。
- Result: 最佳模型Dice相似系数为0.39，IoU为0.27，归一化表面距离为0.67，表明该任务具有挑战性，需要进一步研究。
- Conclusion: AbscessHeNe数据集为头颈部脓肿分割提供了基准，支持未来基于内容的医学图像检索和知识驱动的临床工作流，数据集将公开可用。


### [189] [Depth Matching Method Based on ShapeDTW for Oil-Based Mud Imager](https://arxiv.org/abs/2512.01611)
*Fengfeng Li,Zhou Feng,Hongliang Wu,Hao Zhang,Han Tian,Peng Liu,Lixin Yuan*

Main category: cs.CV

TL;DR: 提出基于ShapeDTW算法的井眼图像深度匹配方法，解决油基泥浆微电阻率成像仪上下极板图像深度错位问题

- Motivation: 油基泥浆微电阻率成像仪采用交错设计的上下极板，即使在速度校正后，极板图像之间仍存在深度错位问题，需要更精确的深度匹配方法
- Method: 基于Shape Dynamic Time Warping算法，提取局部形态特征构建形态敏感距离矩阵，采用一维梯度方向直方图与原始信号组合作为形态描述符
- Result: 现场测试表明，该方法能精确对齐具有复杂纹理、深度偏移或局部缩放的图像，为复杂地质特征的深度匹配提供了有效解决方案
- Conclusion: 提出的ShapeDTW深度匹配方法能有效解决井眼图像深度错位问题，且具有灵活的特征扩展框架，可根据特定地质特征集成其他描述符


### [190] [SPARK: Sim-ready Part-level Articulated Reconstruction with VLM Knowledge](https://arxiv.org/abs/2512.01629)
*Yumeng He,Ying Jiang,Jiayin Lu,Yin Yang,Chenfanfu Jiang*

Main category: cs.CV

TL;DR: SPARK：从单张RGB图像重建物理一致、运动学部件级铰接物体的框架

- Motivation: 铰接3D物体对于具身AI、机器人和交互场景理解至关重要，但创建仿真就绪的资产仍然劳动密集，需要专家建模部件层次结构和运动结构。
- Method: 1. 使用视觉语言模型提取粗略URDF参数并生成部件级参考图像；2. 将部件图像指导和推断的结构图集成到生成扩散变换器中，合成一致的部件和完整铰接物体形状；3. 通过可微分前向运动学和可微分渲染优化关节类型、轴和原点。
- Result: SPARK在多样化类别中生成高质量的仿真就绪铰接资产，支持机器人操作和交互建模等下游应用。
- Conclusion: SPARK框架能够从单张RGB图像有效重建物理一致的运动学部件级铰接物体，解决了创建仿真就绪资产的劳动密集问题。


### [191] [Generative Editing in the Joint Vision-Language Space for Zero-Shot Composed Image Retrieval](https://arxiv.org/abs/2512.01636)
*Xin Wang,Haipeng Zhang,Mang Li,Zhaohui Xia,Yueguo Chen,Yu Zhang,Chunyu Wei*

Main category: cs.CV

TL;DR: Fusion-Diff：一种用于零样本组合图像检索的生成式编辑框架，通过多模态融合特征编辑和轻量级Control-Adapter，在有限合成数据上实现最先进性能

- Motivation: 监督式组合图像检索方法依赖昂贵的三元组标注，而现有的零样本方法难以有效弥合视觉-语言模态鸿沟，需要更高效的数据利用方案
- Method: 提出Fusion-Diff框架：1）在联合视觉-语言空间中引入多模态融合特征编辑策略，显著缩小模态鸿沟；2）集成轻量级Control-Adapter，仅需在20万合成样本的小规模数据集上进行微调
- Result: 在CIRR、FashionIQ和CIRCO等标准基准测试中，Fusion-Diff显著优于先前的零样本方法，并通过可视化融合多模态表征增强了模型可解释性
- Conclusion: Fusion-Diff通过创新的多模态融合特征编辑和高效数据利用策略，为组合图像检索提供了有效的零样本解决方案，在性能和效率方面均取得突破


### [192] [ViT$^3$: Unlocking Test-Time Training in Vision](https://arxiv.org/abs/2512.01643)
*Dongchen Han,Yining Li,Tianyu Li,Zixuan Cao,Ziming Wang,Jun Song,Yu Cheng,Bo Zheng,Gao Huang*

Main category: cs.CV

TL;DR: 本文系统研究了视觉序列建模中的测试时训练设计，提出了ViT³模型，在线性复杂度下实现了与优化视觉Transformer相当的性能。

- Motivation: 测试时训练为高效序列建模提供了新方向，但视觉领域的TTT设计缺乏系统研究和实用指南，需要填补这一空白。
- Method: 通过系统实证研究，提炼出六条实用设计原则，并基于此构建了Vision Test-Time Training模型，实现线性复杂度和并行计算。
- Result: ViT³在图像分类、生成、检测和分割等任务中，性能匹配或优于Mamba等线性复杂度模型，有效缩小了与优化视觉Transformer的差距。
- Conclusion: 本研究为视觉TTT模型提供了设计原则和ViT³基准，有望推动该领域的未来发展。


### [193] [DB-KAUNet: An Adaptive Dual Branch Kolmogorov-Arnold UNet for Retinal Vessel Segmentation](https://arxiv.org/abs/2512.01657)
*Hongyu Xu,Panpan Meng,Meng Wang,Dayu Hu,Liming Liang,Xiaoqi Sheng*

Main category: cs.CV

TL;DR: 提出DB-KAUNet用于视网膜血管分割，结合CNN与Transformer的双分支编码器，引入KANConv和KAT块，通过CCI和SFE-GAF模块增强特征交互与空间特征，在多个数据集上取得领先性能。

- Motivation: 传统CNN方法在视网膜血管分割中存在局限性，难以捕捉长距离依赖和复杂非线性关系，需要更有效的模型来提升分割精度。
- Method: 提出自适应双分支Kolmogorov-Arnold UNet (DB-KAUNet)，包含异构双分支编码器(HDBE)，并行CNN和Transformer路径，集成KANConv和KAT块，加入跨分支通道交互(CCI)模块和基于注意力的空间特征增强(SFE)模块，进一步开发SFE-GAF模块进行自适应采样。
- Result: 在DRIVE、STARE和CHASE_DB1数据集上的广泛实验验证了DB-KAUNet取得了领先的分割性能，并展示了卓越的鲁棒性。
- Conclusion: DB-KAUNet通过创新的双分支架构和特征增强模块，有效解决了传统CNN在视网膜血管分割中的局限性，为临床诊断提供了更准确的分割工具。


### [194] [Bridging the Scale Gap: Balanced Tiny and General Object Detection in Remote Sensing Imagery](https://arxiv.org/abs/2512.01665)
*Zhicheng Zhao,Yin Huang,Lingma Sun,Chenglong Li,Jin Tang*

Main category: cs.CV

TL;DR: ScaleBridge-Det：首个专为遥感图像中微小目标检测设计的大型检测框架，通过尺度自适应专家路由和密度引导查询分配，实现不同尺度目标的平衡检测性能。

- Motivation: 遥感图像中密集微小目标与大型目标共存时，现有方法难以实现跨尺度的平衡检测性能。虽然大型基础模型在通用视觉任务中表现出色，但由于遥感图像中极端的尺度变化和密度分布特性，这些模型尚未应用于微小目标检测领域。
- Method: 提出ScaleBridge-Det框架，包含两个核心模块：1）路由增强混合注意力模块（REM），通过自适应路由动态选择和融合尺度特定的专家特征，生成互补且具有判别性的多尺度表示；2）密度引导动态查询模块（DGQ），通过预测目标密度自适应调整查询位置和数量，实现不同尺度目标的高效资源分配。
- Result: 在基准数据集AI-TOD-V2和DTOD上达到最先进的性能，同时在VisDrone数据集上展现出优异的跨域鲁棒性。该框架能够同时优化密集微小目标和一般目标的检测性能，无需权衡取舍。
- Conclusion: ScaleBridge-Det是首个专为遥感图像微小目标检测设计的大型检测框架，通过创新的尺度自适应专家路由和密度引导查询分配机制，成功解决了跨尺度目标检测的平衡性问题，在多个数据集上实现了最先进的性能。


### [195] [GRASP: Guided Residual Adapters with Sample-wise Partitioning](https://arxiv.org/abs/2512.01675)
*Felix Nützel,Mischa Dombrowski,Bernhard Kainz*

Main category: cs.CV

TL;DR: GRASP：一种解决文本到图像扩散模型在长尾分布（如医学影像）中模式崩溃问题的方法，通过样本聚类和残差适配器微调，提升罕见类别的生成质量和多样性。

- Motivation: 现有文本到图像扩散模型在长尾分布场景（如医学影像中罕见病理）表现不佳，出现模式崩溃问题，导致罕见类别生成质量差、多样性不足，无法有效支持数据增强。主要原因是频繁类别与罕见类别之间的梯度冲突。
- Method: GRASP（Guided Residual Adapters with Sample-wise Partitioning）：1）使用外部先验知识静态划分样本到不同聚类，最小化组内梯度冲突；2）在预训练模型的transformer前馈层注入聚类特定的残差适配器进行微调，绕过学习门控机制以保证稳定性和效率。
- Result: 在MIMIC-CXR-LT数据集上，GRASP在FID和多样性指标上表现优异，尤其在罕见类别上超越基线方法（如普通微调和MoE变体）。在NIH-CXR-LT的下游分类任务中，罕见标签的分类性能显著提升。在ImageNet-LT上的实验证实了方法的广泛适用性。
- Conclusion: GRASP是一种轻量级、可扩展的方法，能有效解决扩散模型在长尾分布中的梯度冲突问题，提升罕见类别的生成质量，易于集成到现有扩散管道中，在医学影像等长尾场景具有重要应用价值。


### [196] [Open-world Hand-Object Interaction Video Generation Based on Structure and Contact-aware Representation](https://arxiv.org/abs/2512.01677)
*Haodong Yan,Hang Yu,Zhide Zhong,Weilin Yuan,Xin Gong,Zehang Luo,Chengxi Heyu,Junfeng Li,Wenxuan Song,Shunbo Zhou,Haoang Li*

Main category: cs.CV

TL;DR: 提出SCAR方法，通过结构和接触感知表示生成逼真的手-物体交互视频，无需3D标注，在开放世界场景中表现优异

- Motivation: 当前手-物体交互视频生成方法面临2D和3D表示的困境：2D表示可扩展但交互保真度低，3D表示保真度高但可扩展性差。需要一种既能保证可扩展性又能保证交互保真度的表示方法。
- Method: 提出结构和接触感知表示(SCAR)，捕捉手-物体接触、遮挡和整体结构上下文，无需3D标注。采用共享-专业化策略的联合生成范式，同时生成交互导向表示和视频。
- Result: 在两个真实世界数据集上超越现有方法，生成物理逼真且时间连贯的手-物体交互视频。在具有挑战性的开放世界场景中表现出强大的泛化能力。
- Conclusion: SCAR表示提供了一种可扩展且交互保真的监督信号，能够学习细粒度交互物理并在开放世界场景中泛化，为手-物体交互视频生成提供了有效解决方案。


### [197] [Cross-Domain Validation of a Resection-Trained Self-Supervised Model on Multicentre Mesothelioma Biopsies](https://arxiv.org/abs/2512.01681)
*Farzaneh Seyedshahi,Francesca Damiola,Sylvie Lantuejoul,Ke Yuan,John Le Quesne*

Main category: cs.CV

TL;DR: 基于自监督编码器的AI模型能够利用切除组织训练的模型分析活检样本，预测间皮瘤亚型和患者生存期

- Motivation: 间皮瘤的准确亚型分类和预后预测对指导治疗至关重要，但现有计算病理模型大多基于切除组织训练，难以应用于临床常见的小活检样本
- Method: 使用切除组织训练的自监督编码器，将其应用于活检材料以捕获有意义的形态学模式，利用这些模式预测患者生存期和肿瘤亚型
- Result: 模型能够成功应用于活检样本，捕获有意义的形态学模式，有效预测患者生存期和肿瘤亚型
- Conclusion: 该方法展示了AI驱动工具在支持间皮瘤诊断和治疗规划方面的潜力，特别是在活检样本分析中的应用价值


### [198] [DreamingComics: A Story Visualization Pipeline via Subject and Layout Customized Generation using Video Models](https://arxiv.org/abs/2512.01686)
*Patrick Kwon,Chen Chen*

Main category: cs.CV

TL;DR: DreamingComics是一个布局感知的故事可视化框架，通过区域感知的位置编码和掩码条件损失来提升角色一致性和空间准确性，相比之前方法在角色一致性上提升29.2%，风格相似度提升36.2%。

- Motivation: 当前故事可视化方法仅通过文本定位主体，难以保持艺术一致性。现有方法在角色身份和风格一致性方面存在挑战，需要更好的布局控制和一致性保持机制。
- Method: 基于预训练的视频扩散变换器模型，提出RegionalRoPE区域感知位置编码方案，通过掩码条件损失约束视觉特征到指定区域，并集成基于LLM的布局生成器从自然语言脚本推断漫画风格布局。
- Result: 相比之前方法，角色一致性提升29.2%，风格相似度提升36.2%，同时展现出高空间准确性。框架能够生成具有艺术一致性的漫画风格故事可视化结果。
- Conclusion: DreamingComics通过布局感知的故事可视化框架，有效解决了角色一致性和风格一致性问题，实现了从自然语言脚本到漫画风格布局的灵活可控生成。


### [199] [SSR: Semantic and Spatial Rectification for CLIP-based Weakly Supervised Segmentation](https://arxiv.org/abs/2512.01701)
*Xiuli Bi,Die Xiao,Junchao Fan,Bin Xiao*

Main category: cs.CV

TL;DR: 提出SSR方法解决CLIP-based WSSS中的过激活问题：通过CMPA对齐跨模态特征减少类间重叠，通过SGC利用超像素空间先验过滤背景干扰，在VOC和COCO上达到SOTA性能。

- Motivation: 现有基于CLIP的弱监督语义分割方法存在两个主要问题：1）在非目标前景区域的过激活；2）在背景区域的过激活。这些问题限制了CLIP在WSSS任务中的性能提升。
- Method: 提出语义和空间矫正（SSR）方法：1）语义层面：跨模态原型对齐（CMPA）建立对比学习机制，强制跨模态特征空间对齐，减少类间重叠同时增强语义相关性；2）空间层面：超像素引导矫正（SGC）利用基于超像素的空间先验，在亲和力传播过程中精确过滤非目标区域的干扰。
- Result: 在PASCAL VOC和MS COCO数据集上的实验表明，该方法超越了所有单阶段方法以及更复杂的多阶段方法，分别达到了79.5%和50.6%的mIoU分数。
- Conclusion: SSR方法通过语义和空间两个层面的矫正，有效解决了CLIP-based WSSS中的过激活问题，在弱监督语义分割任务中取得了显著的性能提升。


### [200] [StreamGaze: Gaze-Guided Temporal Reasoning and Proactive Understanding in Streaming Videos](https://arxiv.org/abs/2512.01707)
*Daeun Lee,Subhojyoti Mukherjee,Branislav Kveton,Ryan A. Rossi,Viet Dac Lai,Seunghyun Yoon,Trung Bui,Franck Dernoncourt,Mohit Bansal*

Main category: cs.CV

TL;DR: StreamGaze是首个评估MLLMs在流式视频中利用人类注视信号进行时序和前瞻推理的基准测试，包含注视引导的过去、现在和前瞻任务，揭示了当前模型在注视理解方面的显著不足。

- Motivation: 现有流式视频基准测试仅评估时序推理能力，但缺乏对MLLMs是否能够解释和利用人类注视信号的评估。为了填补这一空白，需要创建能够衡量模型在流式视频中利用注视进行时序和前瞻推理能力的基准测试。
- Method: 开发了注视-视频QA生成流水线，通过注视点提取、区域特定视觉提示和扫描路径构建，将自我中心视频与原始注视轨迹对齐，生成时空基础的QA对，反映人类感知动态。
- Result: 在所有StreamGaze任务中，最先进的MLLMs与人类表现之间存在显著性能差距，揭示了模型在注视基础时序推理、意图建模和前瞻预测方面的根本局限性。
- Conclusion: StreamGaze基准测试揭示了当前MLLMs在注视引导流式视频理解方面的不足，为未来模型发展提供了重要见解，所有数据和代码将公开以支持进一步研究。


### [201] [FreqEdit: Preserving High-Frequency Features for Robust Multi-Turn Image Editing](https://arxiv.org/abs/2512.01755)
*Yucheng Liao,Jiajun Liang,Kaiqian Cui,Baoquan Zhao,Haoran Xie,Wei Liu,Qing Li,Xudong Mao*

Main category: cs.CV

TL;DR: FreqEdit是一个无需训练的图像编辑框架，通过高频特征注入、自适应注入策略和路径补偿机制，解决了多轮编辑中的高频信息丢失问题，实现10+轮稳定编辑。

- Motivation: 当前基于指令的图像编辑模型在单次编辑中表现优异，但在多轮编辑中会出现严重的质量退化问题。研究发现高频信息逐渐丢失是导致质量退化的主要原因。
- Method: FreqEdit包含三个核心组件：1）从参考速度场注入高频特征以保留细节；2）自适应注入策略，空间调制注入强度实现区域控制；3）路径补偿机制，定期重新校准编辑轨迹防止过度约束。
- Result: 在7个最先进基线的对比实验中，FreqEdit在身份保持和指令遵循方面都表现出优越性能，能够稳定进行10+轮连续编辑。
- Conclusion: FreqEdit通过解决多轮编辑中的高频信息丢失问题，实现了稳定、高质量的多轮图像编辑，为基于自然语言的图像编辑提供了有效的解决方案。


### [202] [HiconAgent: History Context-aware Policy Optimization for GUI Agents](https://arxiv.org/abs/2512.01763)
*Xurui Zhou,Gongwei Chen,Yuquan Xie,Zaijing Li,Kaiwen Zhou,Shuai Wang,Shuo Yang,Zhuotao Tian,Rui Shao*

Main category: cs.CV

TL;DR: HiconAgent：一种通过历史上下文感知策略优化（HCPO）训练的GUI代理，包含动态上下文采样和锚点引导历史压缩，在GUI导航任务中实现高效历史信息利用，性能优于更大模型且计算效率更高。

- Motivation: GUI代理需要有效利用历史上下文进行顺序导航任务，但直接使用完整历史会导致计算开销过大和无关信息干扰，需要更高效的历史信息利用方法。
- Method: 提出历史上下文感知策略优化（HCPO），包含两个组件：1）动态上下文采样（DCS）：在采样阶段提供可变长度历史，使代理能自适应使用最相关上下文；2）锚点引导历史压缩（AHC）：在策略更新阶段采用双分支策略，压缩分支移除历史观察但保留历史动作作为信息流锚点，通过历史增强对齐损失耦合两个分支。
- Result: 在主流GUI导航基准测试中表现优异：HiconAgent-3B在GUI-Odyssey上比GUI-R1-7B提升8.46%的grounding准确率和11.32%的步骤成功率；在AndroidControl和AITW上达到可比结果，同时实现最高2.47倍计算加速和60%FLOPs减少。
- Conclusion: HiconAgent通过HCPO框架实现了GUI代理中历史上下文的高效有效利用，在保持较小模型规模的同时超越了更大模型的性能，并显著提升了计算效率。


### [203] [VideoScoop: A Non-Traditional Domain-Independent Framework For Video Analysis](https://arxiv.org/abs/2512.01769)
*Hafsa Billah*

Main category: cs.CV

TL;DR: 提出通用视频情境分析框架，结合关系模型和图模型，通过参数化模板实现跨领域情境检测，解决传统方法依赖人工或特定算法的局限性。

- Motivation: 当前视频情境分析主要依赖人工或针对特定视频类型/情境的定制算法，这些方法存在错误率高、劳动密集、缺乏通用性等问题，无法适应新领域或新情境的需求。
- Method: 1) 使用先进视频内容提取技术提取内容；2) 采用扩展关系模型(R++)和图模型两种表示方式；3) R++支持连续查询处理；4) 图模型检测关系模型难以识别的复杂情境；5) 通过参数化模板实现跨领域通用性。
- Result: 在辅助生活、市政监控和一般监控三个领域的多种情境下进行了广泛实验，评估了所提方法在准确性、效率和鲁棒性方面的表现，使用不同长度的视频数据集验证了框架的有效性。
- Conclusion: 该通用视频情境分析框架克服了现有方法的局限性，能够跨领域检测多种情境，为视频分析提供了更通用、高效的解决方案。


### [204] [Robust Rigid and Non-Rigid Medical Image Registration Using Learnable Edge Kernels](https://arxiv.org/abs/2512.01771)
*Ahsan Raza Siyal,Markus Haltmeier,Ruth Steiger,Malik Galijasevic,Elke Ruth Gizewski,Astrid Ellen Grams*

Main category: cs.CV

TL;DR: 提出一种结合可学习边缘核与学习式刚性/非刚性配准的医学图像配准方法，通过自适应边缘检测提升多模态图像对齐性能。

- Motivation: 传统医学图像配准方法在处理对比度差异、空间扭曲和多模态变化时存在困难，需要更有效的特征提取机制来提升配准精度。
- Method: 集成可学习边缘核与学习式配准技术：从预定义边缘检测核开始，加入随机噪声扰动，在训练中学习提取任务特定的最优边缘特征；设计了刚性配准和非刚性配准各四个变体模型。
- Result: 在医学大学提供的三个实验设置（带/不带颅骨移除的刚性配准、非刚性配准）和两个公开数据集上，该方法均优于现有最佳技术。
- Conclusion: 该方法通过自适应边缘检测有效提升了医学图像配准性能，在多模态图像对齐和解剖结构分析方面具有重要应用潜力。


### [205] [Evaluating SAM2 for Video Semantic Segmentation](https://arxiv.org/abs/2512.01774)
*Syed Hesham Syed Ariff,Yun Liu,Guolei Sun,Jing Yang,Henghui Ding,Xue Geng,Xudong Jiang*

Main category: cs.CV

TL;DR: SAM2扩展用于视频语义分割的两种方法：使用SAM2提取对象掩码配合分割网络，以及提取特征向量进行分类，最终结合分类结果和掩码生成分割

- Motivation: 虽然SAM2在图像和视频对象分割中表现出色，但将其扩展到密集视频语义分割面临空间准确性、时间一致性和复杂边界跟踪等挑战
- Method: 提出两种方法：1) 使用SAM2从图像中提取对象掩码，配合分割网络生成和细化初始预测；2) 使用预测掩码提取特征向量，通过简单网络进行分类，最后结合分类结果和掩码生成最终分割
- Result: 实验表明利用SAM2能够提升视频语义分割的整体性能，主要得益于其对对象边界的精确预测
- Conclusion: SAM2可以作为视频语义分割的有效基础模型，其精确的边界预测能力有助于提升分割性能，但扩展过程中需要解决空间准确性和时间一致性等挑战


### [206] [Learned Image Compression for Earth Observation: Implications for Downstream Segmentation Tasks](https://arxiv.org/abs/2512.01788)
*Christian Mollière,Iker Cumplido,Marco Zeulner,Lukas Liesenhoff,Matthias Schubert,Julia Gottfriedsen*

Main category: cs.CV

TL;DR: 评估学习压缩算法在卫星地球观测数据中的表现，相比传统JPEG 2000，学习压缩在大规模多通道光学图像上表现更好，但在小规模单通道热红外数据上传统方法仍有竞争力。

- Motivation: 卫星地球观测系统产生的数据快速增长，给数据传输和存储带来巨大挑战，需要评估任务特定的学习压缩算法能否在减少数据量的同时保留关键信息。
- Method: 比较传统压缩（JPEG 2000）与学习压缩方法（离散混合高斯似然）在三个地球观测分割任务上的表现：火灾、云和建筑物检测。
- Result: 学习压缩在大规模多通道光学图像上显著优于JPEG 2000，在重建质量（PSNR）和分割精度方面都表现更好。但对于小规模单通道热红外数据集，传统编解码器仍具有竞争力。联合端到端优化压缩和分割模型并未比独立优化带来性能提升。
- Conclusion: 学习压缩算法在处理大规模多通道地球观测数据时具有优势，但在数据有限或架构受限的情况下，传统压缩方法仍有价值。联合优化策略在当前设置下未显示出额外收益。


### [207] [SAM3-UNet: Simplified Adaptation of Segment Anything Model 3](https://arxiv.org/abs/2512.01789)
*Xinyu Xiong,Zihuang Wu,Lei Lu,Yufa Xia*

Main category: cs.CV

TL;DR: SAM3-UNet是Segment Anything Model 3的简化变体，通过添加适配器和轻量级U-Net解码器，以低成本适配下游分割任务，在多个任务上表现优于SAM2-UNet等现有方法，且训练内存需求低。

- Motivation: 为了以低成本将强大的SAM3模型适配到下游分割任务，需要解决参数高效微调和计算资源消耗的问题。
- Method: 提出SAM3-UNet架构，包含三个组件：SAM3图像编码器、参数高效微调的简单适配器、轻量级U-Net风格解码器。
- Result: 在镜像检测和显著性目标检测等多个任务上，SAM3-UNet优于SAM2-UNet和其他SOTA方法，训练时批大小为12时GPU内存需求低于6GB。
- Conclusion: SAM3-UNet能够以低成本有效适配SAM3到下游任务，在保持高性能的同时显著降低计算资源需求。


### [208] [Generative Action Tell-Tales: Assessing Human Motion in Synthesized Videos](https://arxiv.org/abs/2512.01803)
*Xavier Thomas,Youngsun Lim,Ananya Srinivasan,Audrey Zheng,Deepti Ghadiyaram*

Main category: cs.CV

TL;DR: 提出一种基于真实人类动作学习潜在空间的新评估指标，用于评估生成视频中复杂人类动作的视觉和时间正确性，相比现有方法提升68%以上。

- Motivation: 现有视频生成模型评估指标存在严重缺陷：纯视觉编码器和多模态大语言模型具有强烈的外观偏见，缺乏时间理解能力，难以识别生成视频中复杂的运动动态和解剖学不合理性。
- Method: 通过融合外观无关的人类骨骼几何特征和基于外观的特征，捕捉真实世界运动的细微差别、约束和时间平滑性，构建真实世界动作分布的鲁棒表示。对生成视频，通过测量其底层表示与学习到的真实世界动作分布之间的距离来量化动作质量。
- Result: 在新设计的多方面基准测试中，该指标相比现有最先进方法提升超过68%；在已有外部基准测试中表现具有竞争力；与人类感知有更强的相关性。
- Conclusion: 该方法揭示了当前视频生成模型的关键局限性，为视频生成领域的先进研究建立了新标准，提供了一种更准确评估人类动作真实性的评估框架。


### [209] [Envision: Benchmarking Unified Understanding & Generation for Causal World Process Insights](https://arxiv.org/abs/2512.01816)
*Juanxi Tian,Siyuan Li,Conghui He,Lijun Wu,Cheng Tan*

Main category: cs.CV

TL;DR: 本文提出了Envision基准测试，用于评估多图像序列生成中的因果事件进展能力，揭示了当前模型在时空一致性和世界知识内化方面的局限性。

- Motivation: 当前多模态模型主要关注单图像生成，导致过度拟合静态模式匹配，缺乏对动态时间过程的建模能力。需要评估模型是否真正内化了世界知识并遵循因果时空约束。
- Method: 提出Envision基准测试：包含1000个四阶段提示，涵盖6个科学和人文领域；引入Envision-Score综合指标，整合多维度一致性、物理性和美学；评估15个模型（10个专业T2I模型，5个统一模型）。
- Result: 专业T2I模型在美学渲染方面表现良好但缺乏内在世界知识；统一多模态模型在因果叙事连贯性上优于专业模型，但仍落后于闭源模型，且在时空一致性方面存在困难。
- Conclusion: 专注于因果孤立的单图像会阻碍多帧推理和生成，促进静态模式匹配而非动态世界建模，最终限制了世界知识的内化和生成能力。


### [210] [Seeing through Imagination: Learning Scene Geometry via Implicit Spatial World Modeling](https://arxiv.org/abs/2512.01821)
*Meng Cao,Haokun Lin,Haoyuan Li,Haoran Tang,Rongtao Xu,Dong An,Xue Liu,Ian Reid,Xiaodan Liang*

Main category: cs.CV

TL;DR: MILO提出了一种隐式空间世界建模范式，通过视觉生成器提供几何感知反馈，结合RePE相对位置编码方案，显著提升了多模态大语言模型的空间推理能力。

- Motivation: 当前多模态大语言模型的空间推理能力不足，主要依赖文本描述调优，存在视觉文盲问题——仅通过文本符号学习空间概念，缺乏与视觉表现的连接。
- Method: 提出MILO隐式空间世界建模范式，集成视觉生成器提供几何感知反馈；提出RePE相对位置编码方案捕捉相对相机姿态变换；构建GeoGen大规模几何感知生成数据集。
- Result: 实验表明该方法显著提升了多个基线和基准测试中的空间推理能力，提供了对3D空间更全面的理解。
- Conclusion: MILO通过模拟人类空间想象，将符号推理隐式地锚定在感知经验中，为多模态大语言模型的空间推理能力提供了有效解决方案。


### [211] [CauSight: Learning to Supersense for Visual Causal Discovery](https://arxiv.org/abs/2512.01827)
*Yize Zhang,Meiqi Chen,Sirui Chen,Bo Peng,Yanxi Zhang,Tianyu Li,Chaochao Lu*

Main category: cs.CV

TL;DR: 论文提出视觉因果发现任务，构建VCG-32K数据集，开发CauSight模型，通过因果感知推理实现视觉因果发现，性能超越GPT-4.1

- Motivation: 人类因果思维能理解现象背后的原因，而当前AI系统缺乏这种能力。为了在AI中复制这种因果推理能力，需要让模型不仅能感知视觉实体，还能推断它们之间的因果关系。
- Method: 1. 构建VCG-32K数据集（32,000+图像，带实体级因果图标注）；2. 开发CauSight视觉语言模型；3. 训练方法包括：VCG-32K数据整理、Tree-of-Causal-Thought生成推理轨迹、强化学习配合因果奖励优化推理策略。
- Result: CauSight在视觉因果发现任务上显著超越GPT-4.1，性能提升超过三倍（绝对增益21%）。
- Conclusion: 该研究成功实现了视觉因果发现任务，通过数据集构建和因果感知推理模型开发，显著提升了AI系统的因果推理能力，为更智能的AI系统奠定了基础。


### [212] [OpenREAD: Reinforced Open-Ended Reasoing for End-to-End Autonomous Driving with LLM-as-Critic](https://arxiv.org/abs/2512.01830)
*Songyan Zhang,Wenhui Huang,Zhan Chen,Chua Jiahao Collister,Qihang Huang,Chen Lv*

Main category: cs.CV

TL;DR: OpenREAD是一个基于视觉语言模型的端到端强化微调自动驾驶框架，通过构建大规模思维链标注和使用Qwen3 LLM作为奖励模型中的评判者，实现了从高层推理到低层轨迹规划的全谱系强化学习。

- Motivation: 当前两阶段微调策略（SFT+RFT）存在局限性：SFT的泛化推理能力有限，而RFT主要应用于下游任务，因为场景理解是开放性问题难以量化奖励。需要解决这些限制以充分发挥自动驾驶性能潜力。
- Method: 1) 在开源驾驶知识数据集上构建大规模思维链标注；2) 使用强大的Qwen3大语言模型作为RFT中的评判者，量化开放性问题推理质量进行奖励建模；3) 实现从高层推理到低层轨迹规划的端到端联合强化微调。
- Result: 广泛的实验证实，联合端到端RFT在上游和下游任务中都带来了显著改进，使OpenREAD在推理和规划基准测试中达到了最先进的性能。
- Conclusion: OpenREAD通过端到端强化微调框架，成功解决了现有两阶段策略的局限性，实现了从高层推理到低层规划的全面性能提升，为知识驱动的自动驾驶范式提供了有效解决方案。


### [213] [PhyDetEx: Detecting and Explaining the Physical Plausibility of T2V Models](https://arxiv.org/abs/2512.01843)
*Zeqing Wang,Keze Wang,Lei Zhang*

Main category: cs.CV

TL;DR: 本文构建了物理不可行性检测数据集PID，并提出了轻量级微调方法PhyDetEx，使视觉语言模型能够检测视频中的物理不可行内容并生成解释，用于评估文本到视频生成模型的物理合理性。

- Motivation: 尽管文本到视频生成模型在视频质量和长度方面取得了进展，但其是否理解物理并生成物理上合理的视频仍存疑问。现有的视觉语言模型难以识别生成视频中的物理不可能内容，因此需要专门的方法来评估T2V模型的物理合理性。
- Method: 1) 构建PID数据集：包含500个手动标注的测试视频和2,588个配对视频的训练集，通过重写真实视频的标题诱导T2V模型生成物理不可行内容；2) 提出轻量级微调方法，使VLMs能够检测物理不可行事件并生成违反物理原理的文本解释；3) 将微调后的VLM作为物理合理性检测器和解释器PhyDetEx，用于评估T2V模型。
- Result: 研究结果表明，尽管最近的T2V模型在生成物理合理内容方面取得了显著进展，但理解和遵守物理定律仍然是一个挑战，特别是对于开源模型。提出的PhyDetEx方法能够有效检测物理不可行性并提供解释。
- Conclusion: 本文通过构建PID数据集和开发PhyDetEx方法，为评估T2V模型的物理合理性提供了系统框架。研究表明当前T2V模型在物理理解方面仍有不足，特别是开源模型，这为未来改进指明了方向。数据集、训练代码和检查点已开源。


### [214] [Register Any Point: Scaling 3D Point Cloud Registration by Flow Matching](https://arxiv.org/abs/2512.01850)
*Yue Pan,Tao Sun,Liyuan Zhu,Lucas Nunes,Iro Armeni,Jens Behley,Cyrill Stachniss*

Main category: cs.CV

TL;DR: 提出RAP方法，将点云配准视为条件生成问题，通过学习连续点级速度场将噪声点传输到配准场景，直接生成配准点云而非传统匹配变换方法。

- Motivation: 传统点云配准方法通过对应点匹配估计变换，然后优化成对变换实现多视图配准，这种方法在低重叠情况下效果不佳。作者希望开发更直接的方法来处理多视图配准问题。
- Method: 将配准视为条件生成问题，学习连续点级速度场将噪声点传输到配准场景，然后从配准场景中恢复每个视图的位姿。使用轻量级局部特征提取器和测试时刚性约束。
- Result: 在成对和多视图配准基准测试中达到最先进结果，特别是在低重叠情况下表现优异，能够跨尺度和传感器模态泛化。
- Conclusion: RAP方法通过将配准重新定义为生成问题，提供了一种新颖有效的点云配准解决方案，支持重定位、多机器人SLAM和多会话地图融合等下游任务。


### [215] [COACH: Collaborative Agents for Contextual Highlighting - A Multi-Agent Framework for Sports Video Analysis](https://arxiv.org/abs/2512.01853)
*Tsz-To Wong,Ching-Chun Huang,Hong-Han Shuai*

Main category: cs.CV

TL;DR: 提出一个可重构的多智能体系统作为体育视频理解的基础框架，通过专业化的智能体作为"认知工具"，能够灵活组合构建自适应分析流程，解决现有端到端模型在时间层次理解、泛化能力、开发成本和可解释性方面的不足。

- Motivation: 现有端到端模型在处理体育视频时面临三个主要问题：1) 难以处理从微观动作到宏观策略的时间层次结构；2) 缺乏泛化能力，新任务开发成本高；3) 可解释性差。需要一种更灵活、可扩展且可解释的框架来支持跨任务的体育视频智能分析。
- Method: 提出可重构的多智能体系统框架，每个智能体作为专门的"认知工具"负责特定分析方面。通过智能体的迭代调用和灵活组合，能够构建自适应分析管道，支持从短期分析推理（如回合问答）到长期生成式摘要（如比赛总结）的各种任务。
- Result: 在羽毛球分析的两个代表性任务中展示了该框架的适应性，证明了其能够桥接细粒度事件检测和全局语义组织。该系统实现了从固定端到端模型向灵活、可扩展、可解释的体育视频智能分析范式的转变。
- Conclusion: 该工作提出了一种新的范式，通过可重构的多智能体系统为体育视频理解提供了灵活、可扩展且可解释的解决方案，能够支持跨任务的鲁棒分析，为体育视频智能分析开辟了新方向。


### [216] [TransientTrack: Advanced Multi-Object Tracking and Classification of Cancer Cells with Transient Fluorescent Signals](https://arxiv.org/abs/2512.01885)
*Florian Bürger,Martim Dias Gomes,Nica Gutu,Adrián E. Granada,Noémie Moreau,Katarzyna Bozek*

Main category: cs.CV

TL;DR: TransientTrack是一个基于深度学习的细胞追踪框架，专门用于处理具有瞬态荧光信号的多通道显微镜视频数据，能够检测细胞分裂和死亡事件，构建完整的细胞轨迹和谱系信息。

- Motivation: 现有细胞追踪方法主要针对单一恒定信号的视频，无法检测细胞死亡等关键事件，且不适用于随时间波动的瞬态荧光信号（如细胞昼夜节律）。需要开发能够处理多通道瞬态信号并识别关键细胞事件的追踪方法。
- Method: 采用轻量级深度学习框架，直接在细胞检测嵌入上进行匹配，无需量化追踪特异性特征。整合Transformer网络、使用所有检测框的多阶段匹配，以及用卡尔曼滤波器插补缺失的轨迹片段。
- Result: 该框架在不同条件下表现出强大性能，有效追踪细胞并捕捉细胞分裂和死亡事件。成功应用于化疗药物疗效的单细胞水平分析，能够详细表征治疗反应和耐药机制。
- Conclusion: TransientTrack为癌症细胞动力学的定量研究提供了先进工具，特别适用于具有瞬态荧光信号的多通道显微镜数据，能够构建完整的细胞轨迹和谱系信息，促进治疗反应和耐药机制的详细分析。


### [217] [KM-ViPE: Online Tightly Coupled Vision-Language-Geometry Fusion for Open-Vocabulary Semantic SLAM](https://arxiv.org/abs/2512.01889)
*Zaid Nasser,Mikhail Iumanov,Tianhao Li,Maxim Popov,Jaafar Mahmoud,Malik Mohrat,Ilya Obrubov,Ekaterina Derevyanka,Ivan Sosin,Sergey Kolyubin*

Main category: cs.CV

TL;DR: KM-ViPE是一个实时开放词汇SLAM框架，适用于动态环境中未标定的单目相机，无需深度传感器和离线标定，直接处理原始RGB流，结合几何约束和视觉特征进行在线定位和语义建图。

- Motivation: 现有SLAM系统要么需要深度传感器和离线标定，要么缺乏对动态场景的鲁棒性，无法满足以自我为中心的应用和互联网规模视频数据训练的需求。需要一种能在动态环境中实时运行、无需标定且支持开放词汇语义理解的SLAM框架。
- Method: KM-ViPE将DINO视觉特征与几何约束紧密耦合，通过基于高级特征的自适应鲁棒核处理移动物体和可移动静态物体。系统融合几何特征和深度视觉特征，并与语言嵌入对齐，实现同时在线定位和开放词汇语义建图。
- Result: KM-ViPE在性能上与最先进方法竞争，同时具备在线操作、未标定单目输入、动态场景鲁棒处理等独特优势。系统受益于互联网规模训练，适用于自主机器人和AR/VR应用。
- Conclusion: KM-ViPE通过结合在线操作、未标定单目输入和动态场景鲁棒处理，推进了具身AI的实际空间智能能力，为自主机器人和AR/VR应用提供了良好解决方案。


### [218] [StyleYourSmile: Cross-Domain Face Retargeting Without Paired Multi-Style Data](https://arxiv.org/abs/2512.01895)
*Avirup Dey,Vinay Namboodiri*

Main category: cs.CV

TL;DR: StyleYourSmile：一种无需多风格配对数据的单样本跨域人脸重定向方法，通过双编码器框架和扩散模型实现身份、表情和风格属性的解耦控制。

- Motivation: 现有跨域人脸重定向方法存在局限性：要么无法跨域泛化，要么需要测试时优化，要么需要精心策划的多风格数据集进行微调。需要一种无需多风格配对数据就能实现跨域人脸重定向的方法。
- Method: 提出高效数据增强策略和双编码器框架：一个编码器提取域不变的身份特征，另一个捕获域特定的风格变化。利用这些解耦的控制信号，通过扩散模型实现跨域面部表情重定向。
- Result: StyleYourSmile在广泛的视觉域中实现了优越的身份保持和重定向保真度，无需精心策划的多风格配对数据。
- Conclusion: 该方法成功解决了跨域人脸重定向中身份、表情和风格属性的解耦控制问题，提供了一种高效的单样本解决方案。


### [219] [SARL: Spatially-Aware Self-Supervised Representation Learning for Visuo-Tactile Perception](https://arxiv.org/abs/2512.01908)
*Gurmeher Khurana,Lan Wei,Dandan Zhang*

Main category: cs.CV

TL;DR: SARL是一个空间感知的自监督学习框架，通过三个地图级目标增强BYOL架构，在融合视觉-触觉数据上实现更好的机器人感知性能。

- Motivation: 机器人操作需要编码局部几何的表示。视觉提供全局上下文但缺乏纹理和硬度等直接测量，而触觉提供这些线索。现有的自监督学习框架将特征图压缩为全局向量，丢弃了空间结构，与操作任务的需求不匹配。
- Method: 提出SARL框架，在BYOL架构基础上增加三个地图级目标：显著性对齐(SAL)、补丁原型分布对齐(PPDA)和区域亲和匹配(RAM)，以保持跨视图的注意力焦点、部件组合和几何关系一致性。
- Result: SARL在六个下游任务中持续优于九个自监督学习基线。在几何敏感的边姿态回归任务上，SARL达到0.3955的MAE，比次优方法(0.5682 MAE)相对提升30%，接近监督学习的上限。
- Conclusion: 对于融合视觉-触觉数据，最有效的信号是结构化的空间等变性，其中特征随对象几何可预测地变化，这实现了更强大的机器人感知能力。


### [220] [Med-VCD: Mitigating Hallucination for Medical Large Vision Language Models through Visual Contrastive Decoding](https://arxiv.org/abs/2512.01922)
*Zahra Mahdavi,Zahra Khodakaramimaghsoud,Hooman Khaloo,Sina Bakhshandeh Taleshani,Erfan Hashemi,Javad Mirzapour Kaleybar,Omid Nejati Manzari*

Main category: cs.CV

TL;DR: Med-VCD是一种稀疏视觉对比解码方法，用于减少医疗大视觉语言模型中的幻觉输出，无需二次解码的时间开销，在8个医疗数据集上平均提升事实准确性13%

- Motivation: 医疗大视觉语言模型在医疗应用中存在幻觉输出问题，现有解决方案要么依赖二次解码导致推理速度慢，要么是领域特定的可能引入模态不对齐
- Method: 提出Med-VCD稀疏视觉对比解码方法，包含新颖的令牌稀疏化策略，动态选择视觉信息丰富的令牌，在保留关键视觉上下文的同时减少冗余
- Result: 在眼科、放射学和病理学的8个医疗数据集上评估，Med-VCD相比基线医疗LVLMs平均提升事实准确性13%，幻觉准确性提升6%
- Conclusion: Med-VCD有效缓解医疗大视觉语言模型的幻觉问题，在保持效率的同时提升可靠性，平衡了视觉证据强化与推理速度


### [221] [Physical ID-Transfer Attacks against Multi-Object Tracking via Adversarial Trajectory](https://arxiv.org/abs/2512.01934)
*Chenyi Wang,Yanmao Man,Raymond Muller,Ming Li,Z. Berkay Celik,Ryan Gerdes,Jonathan Petit*

Main category: cs.CV

TL;DR: AdvTraj：首个针对检测跟踪式MOT的在线物理ID操纵攻击，通过对抗轨迹将攻击者ID转移给目标物体，无需攻击目标检测模块

- Motivation: 多目标跟踪(MOT)在计算机视觉中至关重要，但对其算法的威胁研究不足。现有攻击要么针对单个物体跟踪器，要么通过攻击目标检测模块操纵ID，这些方法模型特定、不鲁棒且仅影响离线数据集中的特定样本
- Method: 提出AdvTraj攻击，在检测跟踪式MOT系统中，攻击者使用对抗轨迹将其ID转移给目标物体以混淆跟踪系统，而不攻击目标检测模块。在CARLA中进行仿真，针对SORT进行白盒攻击，并测试对其他SOTA MOT算法的可迁移性
- Result: AdvTraj在多种场景下对SORT的白盒攻击成功率100%，对其他SOTA MOT算法攻击可迁移性高达93%。识别了AdvTraj生成的轨迹模式，提出了两种可由人类步行者/驾驶员在日常场景中执行的通用对抗机动
- Conclusion: 揭示了SOTA MOT系统在物体关联阶段的未充分探索的弱点，为增强此类系统的鲁棒性提供了见解


### [222] [Script: Graph-Structured and Query-Conditioned Semantic Token Pruning for Multimodal Large Language Models](https://arxiv.org/abs/2512.01949)
*Zhongyu Yang,Dannong Xu,Wei Pang,Yingfang Yuan*

Main category: cs.CV

TL;DR: Script是一种无需重新训练的即插即用剪枝方法，通过图结构剪枝和查询条件语义剪枝模块，在保持查询相关视觉信息的同时去除冗余视觉标记，显著提升多模态大语言模型的推理效率和准确性。

- Motivation: 多模态大语言模型中的视觉标记快速增长导致内存消耗和推理延迟过高，尤其是在处理高分辨率图像和视频时。现有的标记剪枝方法往往忽略用户查询相关性或受注意力机制限制，降低了适应性和有效性。
- Method: 提出Script方法，包含两个模块：1) 图结构剪枝模块，去除视觉冗余标记；2) 查询条件语义剪枝模块，保留查询相关的视觉信息。该方法无需重新训练，可泛化到不同的多模态大语言模型。
- Result: 在14个图像和视频理解基准测试中，Script相比现有剪枝方法在模型效率和预测准确性方面表现更优。在LLaVA-NeXT-7B上，实现了最高6.8倍的预填充加速和10倍的FLOP减少，同时保持96.88%的原始性能。
- Conclusion: Script作为一种即插即用的剪枝方法，通过结合视觉冗余去除和查询相关语义保留，有效解决了多模态大语言模型中视觉标记过多的问题，显著提升了模型效率和任务性能。


### [223] [GrndCtrl: Grounding World Models via Self-Supervised Reward Alignment](https://arxiv.org/abs/2512.01952)
*Haoyang He,Jay Patrikar,Dong-Ki Kim,Max Smith,Daniel McGann,Ali-akbar Agha-mohammadi,Shayegan Omidshafiei,Sebastian Scherer*

Main category: cs.CV

TL;DR: RLWG框架通过几何和感知奖励对预训练世界模型进行自监督后训练，实现物理可验证的结构对齐，提升导航任务中的空间一致性和长时稳定性。

- Motivation: 现有视频世界模型虽然视觉保真度高，但缺乏几何基础，限制了在需要空间一致性和长时稳定性的导航任务中的应用。
- Method: 提出RLWG自监督后训练框架，使用几何和感知奖励（姿态循环一致性、深度重投影、时间一致性）对齐预训练世界模型与物理可验证结构；基于GRPO实现GrndCtrl奖励对齐方法。
- Result: GrndCtrl产生的世界模型在户外环境中保持稳定轨迹、一致几何和可靠rollout，在空间一致性和导航稳定性上优于监督微调方法。
- Conclusion: RLWG框架通过可验证奖励桥接生成预训练与接地行为，类似于大语言模型的后训练对齐，为具身导航提供了具有几何基础的世界模型。


### [224] [SpriteHand: Real-Time Versatile Hand-Object Interaction with Autoregressive Video Generation](https://arxiv.org/abs/2512.01960)
*Zisu Li,Hengye Lyu,Jiaxin Shi,Yufeng Zeng,Mingming Fan,Hanwang Zhang,Chen Liang*

Main category: cs.CV

TL;DR: SpriteHand是一个自回归视频生成框架，能够实时合成各种手-物体交互视频，支持多种物体类型和运动模式，在单GPU上达到约18FPS的实时生成速度。

- Motivation: 传统基于仿真的方法依赖明确定义的刚性物体模型和预设手势，无法有效处理与非刚性或铰接实体（如可变形织物、弹性材料、铰链结构、毛绒表面甚至生物）的动态交互。需要一种更通用的手-物体交互建模方法。
- Method: SpriteHand采用自回归视频生成框架，输入静态物体图像和手部交互视频流，通过因果推理架构进行自回归生成，并使用混合后训练方法增强视觉真实性和时间一致性。
- Result: 1.3B参数模型在单NVIDIA RTX 5090 GPU上支持约18FPS、640x368分辨率的实时流式生成，延迟约150毫秒，可连续输出超过一分钟。实验显示在视觉质量、物理合理性和交互保真度方面优于生成式和基于引擎的基线方法。
- Conclusion: SpriteHand提供了一个通用的实时手-物体交互视频生成框架，能够处理多种物体类型，克服了传统仿真方法的局限性，在视觉质量和物理合理性方面表现出色。


### [225] [SGDiff: Scene Graph Guided Diffusion Model for Image Collaborative SegCaptioning](https://arxiv.org/abs/2512.01975)
*Xu Zhang,Jin Yuan,Hanwang Zhang,Guojin Zhong,Yongsheng Zang,Jiacheng Lin,Zhiyong Li*

Main category: cs.CV

TL;DR: 提出SegCaptioning新任务：通过简单提示（如边界框）生成多样化的（描述，掩码）对，使用场景图引导的扩散模型实现相关掩码-描述预测

- Motivation: 传统图像语义理解任务需要用户输入复杂提示且输出单一，存在高成本输入和有限信息输出的问题。需要一种能从简单提示生成多样化语义解释的方法
- Method: 提出场景图引导的扩散模型SGDiff：1) 提示中心场景图适配器将用户提示映射到场景图；2) 扩散过程使用场景图引导的双模态Transformer预测相关描述-掩码对；3) 多实体对比学习损失确保视觉和文本实体对齐
- Result: 在两个数据集上的实验表明，SGDiff在SegCaptioning任务上表现优异，能以最小提示输入同时获得有前景的描述和分割结果
- Conclusion: SegCaptioning任务通过简单提示生成多样化语义解释，提出的SGDiff模型能有效捕捉用户意图并预测对齐的描述-掩码对，为图像理解提供了灵活的新方法


### [226] [Artemis: Structured Visual Reasoning for Perception Policy Learning](https://arxiv.org/abs/2512.01988)
*Wei Tang,Yanpeng Sun,Shan Zhang,Xiaofan Li,Piotr Koniusz,Wei Li,Na Zhao,Zechao Li*

Main category: cs.CV

TL;DR: Artemis是一个视觉感知策略学习框架，采用结构化提案推理（标签-边界框对）代替纯语言中间推理，在空间和物体中心表示中执行推理，提升感知任务性能。

- Motivation: 现有基于自然语言的中间推理链在视觉感知任务中性能下降，核心问题在于推理形式不匹配：语言推理在非结构化语义空间进行，而视觉感知需要在空间和物体中心的空间中进行推理。
- Method: 提出Artemis框架，采用结构化提案推理，每个中间步骤表示为（标签，边界框）对，捕捉可验证的视觉状态。基于Qwen2.5-VL-3B构建，支持中间状态显式跟踪、提案质量直接监督，避免语言推理的模糊性。
- Result: 在定位和检测任务上表现优异，在计数和几何感知任务上展现显著泛化能力。在通用MLLM基准测试中达到竞争性性能，证实空间对齐推理能增强感知策略学习。
- Conclusion: 将推理与空间表示对齐能有效提升感知策略学习，空间基础推理为可扩展和通用的感知策略提供了原则性路径。


### [227] [PAI-Bench: A Comprehensive Benchmark For Physical AI](https://arxiv.org/abs/2512.01989)
*Fengzhe Zhou,Jiannan Huang,Jialuo Li,Deva Ramanan,Humphrey Shi*

Main category: cs.CV

TL;DR: PAI-Bench是一个评估物理AI能力的统一基准，包含2808个真实案例，用于测试视频生成、条件视频生成和视频理解任务。研究发现当前视频生成模型物理一致性不足，多模态大语言模型预测和因果推理能力有限。

- Motivation: 当前多模态大语言模型和视频生成模型在感知和预测真实世界物理动态方面的能力尚未得到充分理解，需要建立一个统一的评估基准来系统评估这些模型的物理AI能力。
- Method: 提出了PAI-Bench基准，包含2,808个真实世界案例，涵盖视频生成、条件视频生成和视频理解三个任务维度，设计了任务对齐的度量标准来评估物理合理性和领域特定推理能力。
- Result: 视频生成模型虽然视觉保真度高，但往往难以保持物理一致的动态；多模态大语言模型在预测和因果解释方面表现有限。当前系统在处理物理AI的感知和预测需求方面仍处于早期阶段。
- Conclusion: PAI-Bench为评估物理AI建立了现实基础，揭示了未来系统需要解决的关键差距，强调了开发具有更好物理一致性和预测能力的模型的重要性。


### [228] [Learning Visual Affordance from Audio](https://arxiv.org/abs/2512.02005)
*Lidong Lu,Guo Chen,Zhu Wei,Yicheng Liu,Tong Lu*

Main category: cs.CV

TL;DR: 提出音频-视觉可供性定位(AV-AG)新任务，通过动作声音分割物体交互区域，构建首个AV-AG数据集，并提出AVAGFormer模型实现跨模态融合

- Motivation: 现有方法依赖文本指令或演示视频，常受模糊性或遮挡限制，而音频提供实时、语义丰富且视觉独立的线索，能更直观理解交互区域
- Method: 构建首个AV-AG数据集，包含动作声音、物体图像和像素级可供性标注；提出AVAGFormer模型，配备语义条件跨模态混合器和双头解码器，有效融合音频和视觉信号进行掩码预测
- Result: AVAGFormer在AV-AG任务上达到最先进性能，超越相关任务基线；分析显示AV-AG与AVS的区别、端到端建模的优势以及各组件贡献
- Conclusion: 音频为可供性定位提供有价值的线索，AVAGFormer通过有效融合音频-视觉信号实现优越性能，为跨模态理解开辟新方向


### [229] [MV-TAP: Tracking Any Point in Multi-View Videos](https://arxiv.org/abs/2512.02006)
*Jahyeok Koo,Inès Hyeonsu Kim,Mungyeom Kim,Junghyun Park,Seohyun Park,Jaeyeong Kim,Jung Yi,Seokju Cho,Seungryong Kim*

Main category: cs.CV

TL;DR: MV-TAP是一个新颖的多视角点跟踪器，利用跨视角注意力机制和相机几何信息，在多视角动态场景视频中实现更完整可靠的点轨迹估计。

- Motivation: 多视角相机系统能够对复杂真实世界场景进行丰富观测，理解多视角设置中的动态物体已成为各种应用的核心。现有方法在多视角点跟踪方面存在不足，需要更有效的方法来聚合跨视角的时空信息。
- Method: MV-TAP利用相机几何和跨视角注意力机制，聚合跨视角的时空信息。该方法构建了大规模合成训练数据集和真实世界评估集，专门针对多视角跟踪任务。
- Result: 在具有挑战性的基准测试中，MV-TAP优于现有的点跟踪方法，为推进多视角点跟踪研究建立了有效的基线。
- Conclusion: MV-TAP通过结合相机几何和跨视角注意力机制，在多视角动态场景点跟踪方面取得了显著进展，为相关研究提供了新的基准和方向。


### [230] [AirSim360: A Panoramic Simulation Platform within Drone View](https://arxiv.org/abs/2512.02009)
*Xian Ge,Yuling Pan,Yuhang Zhang,Xiang Li,Weijun Zhang,Dizhe Zhang,Zhaoliang Wan,Xin Lin,Xiangkai Zhang,Juntao Liang,Jason Li,Wenjie Jiang,Bo Du,Ming-Hsuan Yang,Lu Qi*

Main category: cs.CV

TL;DR: AirSim360是一个用于无人机视角的360度全景数据仿真平台，提供大规模多样化的全景数据集，支持几何、语义和实体级理解，包含交互式行人感知系统和自动轨迹生成功能。

- Motivation: 360度全景理解领域缺乏大规模多样化数据，限制了空间智能的发展。现有仿真器无法系统性地在全方位设置下建模4D真实世界。
- Method: 1) 渲染对齐的数据和标注范式，支持像素级几何、语义和实体级理解；2) 交互式行人感知系统，用于建模人类行为；3) 自动轨迹生成范式，支持导航任务。收集了超过60K个全景样本。
- Result: 构建了首个系统性地在全方位设置下建模4D真实世界的仿真平台，通过多个任务的广泛实验证明了平台的有效性。平台工具包、插件和收集的数据集将公开可用。
- Conclusion: AirSim360填补了360度全景理解领域缺乏大规模多样化数据的空白，为空间智能研究提供了重要的仿真平台和数据集资源。


### [231] [Improved Mean Flows: On the Challenges of Fastforward Generative Models](https://arxiv.org/abs/2512.02012)
*Zhengyang Geng,Yiyang Lu,Zongze Wu,Eli Shechtman,J. Zico Kolter,Kaiming He*

Main category: cs.CV

TL;DR: 提出改进的MeanFlow (iMF)方法，解决原MF框架在训练目标和引导机制上的问题，在ImageNet 256×256上实现1.72 FID（单步评估），显著优于同类方法

- Motivation: 原始MeanFlow框架存在两个关键问题：1）训练目标不仅依赖于真实场还依赖于网络本身，导致训练不稳定；2）分类器自由引导在训练时固定尺度，牺牲了测试时的灵活性
- Method: 1）将训练目标重新表述为对瞬时速度v的损失，通过预测平均速度u的网络重新参数化；2）将引导机制表述为显式条件变量，使用上下文条件处理不同条件，保持测试灵活性
- Result: iMF在ImageNet 256×256上实现1.72 FID（单步评估），大幅优于同类方法，缩小了与多步方法的差距，且无需蒸馏训练
- Conclusion: 改进的MeanFlow方法解决了原框架的关键问题，推进了快速前向生成建模作为一个独立范式的发展


### [232] [TUNA: Taming Unified Visual Representations for Native Unified Multimodal Models](https://arxiv.org/abs/2512.02014)
*Zhiheng Liu,Weiming Ren,Haozhe Liu,Zijian Zhou,Shoufa Chen,Haonan Qiu,Xiaoke Huang,Zhaochong An,Fanny Yang,Aditya Patel,Viktar Atliha,Tony Ng,Xiao Han,Chuyan Zhu,Chenyang Zhang,Ding Liu,Juan-Manuel Perez-Rua,Sen He,Jürgen Schmidhuber,Wenhu Chen,Ping Luo,Wei Liu,Tao Xiang,Jonas Schult,Yuren Cong*

Main category: cs.CV

TL;DR: TUNA提出了一种统一多模态模型，通过级联VAE编码器和表示编码器构建统一的连续视觉表示空间，在理解和生成任务上都实现了SOTA性能。

- Motivation: 现有统一多模态模型通常使用解耦的表示，导致表示格式不匹配问题。TUNA旨在通过构建统一的视觉表示空间来解决这一问题，实现更好的多模态理解和生成。
- Method: TUNA采用级联结构：VAE编码器 + 表示编码器，构建统一的连续视觉表示空间。这种设计允许端到端处理图像和视频，支持理解和生成任务。使用更强的预训练表示编码器提升性能，并通过联合训练理解和生成数据实现任务间的相互促进。
- Result: TUNA在图像和视频理解、图像和视频生成、图像编辑等多个基准测试中取得了最先进的结果。实验表明统一表示设计优于解耦方案，且更强的表示编码器在所有多模态任务中都能带来性能提升。
- Conclusion: TUNA的统一表示设计有效解决了表示格式不匹配问题，证明了统一视觉表示空间在多模态理解和生成任务中的优越性。联合训练理解和生成任务能够相互促进而非干扰，展示了该方法的可扩展性和有效性。


### [233] [Generative Video Motion Editing with 3D Point Tracks](https://arxiv.org/abs/2512.02015)
*Yao-Chih Lee,Zhoutong Zhang,Jiahui Huang,Jui-Hsien Wang,Joon-Young Lee,Jia-Bin Huang,Eli Shechtman,Zhengqi Li*

Main category: cs.CV

TL;DR: 提出基于3D点轨迹跟踪的视频到视频编辑框架，能够联合编辑相机和物体运动，解决复杂运动编辑的挑战

- Motivation: 当前视频编辑方法在复杂物体运动控制方面存在局限：图像到视频方法缺乏全场景上下文，视频到视频方法只能提供基本视角变化或简单平移，难以精细控制物体运动
- Method: 提出轨迹条件化的V2V框架，通过3D点轨迹建立源视频和目标运动之间的稀疏对应关系，利用3D轨迹提供的深度线索解决遮挡和深度顺序问题，采用合成和真实数据两阶段训练
- Result: 模型支持多种运动编辑：联合相机/物体操控、运动转移、非刚性变形，能够保持时空一致性并处理复杂运动场景
- Conclusion: 基于3D轨迹的视频编辑框架显著提升了运动控制的精细度，为视频编辑开辟了新的创作可能性，特别是在复杂运动场景下


### [234] [Objects in Generated Videos Are Slower Than They Appear: Models Suffer Sub-Earth Gravity and Don't Know Galileo's Principle...for now](https://arxiv.org/abs/2512.02016)
*Varun Varma Thozhiyoor,Shivam Tripathi,Venkatesh Babu Radhakrishnan,Anand Bhattad*

Main category: cs.CV

TL;DR: 视频生成器在模拟重力时存在系统性误差，物体下落加速度明显偏慢，即使经过时间缩放也无法纠正。研究者通过无单位双物体测试协议发现其违反伽利略等效原理，但通过少量数据微调可以显著改善物理模拟能力。

- Motivation: 随着视频生成器被评估为潜在的世界模型，需要测试它们是否能够编码和理解物理定律。本研究聚焦于一个基本物理定律——重力，探究视频生成器是否能够准确模拟重力加速度。
- Method: 1. 首先测试现成视频生成器的重力模拟能力，发现物体下落加速度偏慢
2. 排除尺度模糊性（如帧率假设错误）的干扰
3. 引入无单位双物体测试协议，测试时间平方比与高度比的关系，该关系独立于重力加速度、焦距和尺度
4. 使用轻量级低秩适配器在100个单球下落视频上进行微调
- Result: 1. 现成视频生成器生成物体下落加速度仅为1.81 m/s²，远低于地球重力加速度9.8 m/s²
2. 即使进行时间缩放也无法纠正高方差的重力伪影
3. 相对测试揭示了违反伽利略等效原理的现象
4. 微调后有效重力加速度提升到6.43 m/s²，达到地球重力的65%
5. 微调后的适配器能够零样本泛化到双球下落和斜面场景
- Conclusion: 视频生成器在重力模拟方面存在系统性缺陷，但通过针对性的少量数据微调可以显著改善其物理模拟能力。这表明特定物理定律可以通过最小化数据得到纠正，为构建更准确的世界模型提供了可能。


### [235] [Visual Sync: Multi-Camera Synchronization via Cross-View Object Motion](https://arxiv.org/abs/2512.02017)
*Shaowei Liu,David Yifan Yao,Saurabh Gupta,Shenlong Wang*

Main category: cs.CV

TL;DR: VisualSync是一个基于多视角动态的优化框架，能够以毫秒级精度对齐未标定、未同步的视频，通过利用运动3D点的极线约束来实现跨相机流同步。

- Motivation: 随着消费级相机的普及，人们可以轻松记录各种重要时刻，但跨相机视频流的同步仍然具有挑战性。现有方法需要受控设置、特定目标、手动校正或昂贵硬件，无法满足实际需求。
- Method: VisualSync利用现成的3D重建、特征匹配和密集跟踪技术提取轨迹片段、相对位姿和跨视角对应关系，然后通过联合最小化极线误差来估计每个相机的时间偏移。
- Result: 在四个多样化、具有挑战性的数据集上的实验表明，VisualSync优于基线方法，实现了中位数同步误差低于50毫秒的精度。
- Conclusion: VisualSync提供了一种有效的解决方案，能够在无需受控设置、特定目标或昂贵硬件的情况下，实现跨相机视频流的高精度同步，具有实际应用价值。


### [236] [Data-Centric Visual Development for Self-Driving Labs](https://arxiv.org/abs/2512.02018)
*Anbang Liu,Guanzhong Hu,Jiayi Wang,Ping Guo,Han Liu*

Main category: cs.CV

TL;DR: 本文提出了一种融合真实和虚拟数据生成的混合管道，用于解决自驱动实验室中气泡检测的数据稀缺问题，特别是负样本的获取困难。

- Motivation: 自驱动实验室需要高度鲁棒的模型，但训练这些模型需要大量标注数据，而这类数据在常规实践中难以获取，特别是负样本（如移液过程中的气泡）。数据稀缺限制了自驱动实验室的视觉反馈能力。
- Method: 构建了一个混合管道，包含两个轨道：1）真实轨道采用人机协同方案，结合自动采集和选择性人工验证；2）虚拟轨道使用参考条件、提示引导的图像生成来增强真实数据，并进行筛选和验证。两者结合产生类别平衡的数据集。
- Result: 在保留的真实测试集上，仅使用自动采集的真实图像训练的模型达到99.6%的准确率；混合使用真实和生成数据进行训练时，准确率维持在99.4%，同时减少了数据收集和审查的工作量。
- Conclusion: 该方法为自驱动实验室工作流程提供了一种可扩展且经济高效的视觉反馈数据供应策略，为罕见事件检测和更广泛的视觉任务中的数据稀缺问题提供了实用解决方案。
## cs.NE

### [237] [Revisiting Direct Encoding: Learnable Temporal Dynamics for Static Image Spiking Neural Networks](https://arxiv.org/abs/2512.01687)
*Huaxu He*

Main category: cs.NE

TL;DR: 该论文重新审视了SNNs中静态图像处理的性能差距问题，发现主要源于卷积可学习性和替代梯度公式，而非编码方案本身，并提出了一种最小可学习时间编码方法。

- Motivation: 处理缺乏固有时间动态的静态图像是脉冲神经网络（SNNs）面临的基本挑战。在直接训练的SNNs中，静态输入通常跨时间步重复，导致时间维度坍缩为类似速率的表示，阻碍了有意义的时间建模。
- Method: 引入了一种最小可学习时间编码，通过添加自适应相移来从静态输入中诱导有意义的时间变化。该方法旨在澄清机制层面的问题，而非编码方案本身。
- Result: 研究表明，直接编码和基于速率编码之间的性能差距主要源于卷积可学习性和替代梯度公式，而不是编码方案本身。通过提出的最小可学习时间编码，能够从静态输入中创建有意义的时间变化。
- Conclusion: 该工作澄清了SNNs中静态图像处理的根本问题，指出性能差距的真正原因在于学习机制而非编码方案，并提出了一种有效的解决方案来改善静态输入的时间建模能力。
## cs.LG

### [238] [TIE: A Training-Inversion-Exclusion Framework for Visually Interpretable and Uncertainty-Guided Out-of-Distribution Detection](https://arxiv.org/abs/2512.00229)
*Pirzada Suhail,Rehna Afroz,Amit Sethi*

Main category: cs.LG

TL;DR: TIE框架通过训练-反演-排除的闭环过程，在标准分类器基础上增加垃圾类，实现可解释的异常检测和不确定性估计，无需外部OOD数据集。

- Motivation: 深度神经网络难以识别训练分布外的输入，导致不可靠和过度自信的预测。需要统一的方法来估计预测不确定性和检测OOD样本。
- Method: TIE框架扩展标准n类分类器为(n+1)类模型，引入用高斯噪声初始化的垃圾类表示异常输入。每个epoch执行训练-反演-排除的闭环过程：从刚训练的分类器重构高度不确定的反演样本，将其排除到垃圾类中。
- Result: TIE在MNIST和FashionMNIST上训练，对多种未见数据集测试，实现了近乎完美的OOD检测（≈0 FPR@95%TPR）。反演样本从噪声伪影转变为视觉连贯的类原型，提供模型学习流形组织的透明洞察。
- Conclusion: TIE提供了一个统一且可解释的框架，用于鲁棒的异常检测和校准的不确定性估计，无需依赖外部OOD数据集，通过迭代细化联合解决OOD检测和不确定性估计的挑战。


### [239] [Time-Series at the Edge: Tiny Separable CNNs for Wearable Gait Detection and Optimal Sensor Placement](https://arxiv.org/abs/2512.00396)
*Andrea Procopio,Marco Esposito,Sara Raggiunto,Andrey Gizdov,Alberto Belli,Paola Pierleoni*

Main category: cs.LG

TL;DR: 该研究开发了用于帕金森病步态检测的超轻量1D CNN模型，在资源受限的可穿戴设备上实现了高精度和低延迟，参数数量比基线模型减少10倍。

- Motivation: 针对帕金森病步态检测在资源受限的可穿戴设备和边缘节点上的应用需求，需要开发既准确又高效的算法，以替代传统的幅度阈值方法。
- Method: 比较了幅度阈值法和三种1D CNN模型：文献基线（可分离卷积）、纯可分离模型和带残差连接的可分离模型。使用BioStampRC21数据集，2秒窗口30Hz采样，采用留一受试者交叉验证。
- Result: 残差可分离模型（533参数）达到PR-AUC=94.5%，F1=91.2%，MCC=89.4%，性能优于基线模型（5552参数）。最小模型（305参数）也表现优异。胸部和腿部传感器最可靠，前臂传感器因非步态手臂运动而性能下降。
- Conclusion: 超轻量可分离CNN在准确率、效率和泛化能力方面优于固定阈值方法，适合边缘部署，能够在STM32级MCU上实现亚10毫秒延迟，支持传感器端的数据传输/存储门控。


### [240] [SelfAI: Building a Self-Training AI System with LLM Agents](https://arxiv.org/abs/2512.00403)
*Xiao Wu,Ting-Zhu Huang,Liang-Jian Deng,Xiaobing Yu,Yu Zhong,Shangqi Deng,Ufaq Khan,Jianghao Wu,Xiaofeng Liu,Imran Razzak,Xiaojun Chang,Yutong Xie*

Main category: cs.LG

TL;DR: SelfAI是一个多智能体平台，通过用户代理、认知代理和实验管理器协同工作，实现自主科学发现，引入新评估指标，在多个领域超越传统方法。

- Motivation: 现有自主科学发现系统存在领域局限、实时交互不足、缺乏停止机制等问题，导致效率低下、可重复性差和人类专业知识未充分利用。
- Method: 提出SelfAI多智能体平台：用户代理将研究目标转化为实验配置；认知代理基于LLM使用最优停止准则迭代优化超参数搜索；实验管理器协调并行容错训练工作流并维护结构化知识库。
- Result: 在回归、NLP、计算机视觉、科学计算、医学成像和药物发现等多个基准测试中，SelfAI表现优异，相比传统贝叶斯优化和LLM基线减少了冗余试验。
- Conclusion: SelfAI提供了一个通用、高效的自主科学发现平台，能够与人类研究者无缝交互，并通过新评估指标量化发现效率和搜索多样性。


### [241] [REM: Evaluating LLM Embodied Spatial Reasoning through Multi-Frame Trajectories](https://arxiv.org/abs/2512.00736)
*Jacob Thompson,Emiliano Garcia-Lopez,Yonatan Bisk*

Main category: cs.LG

TL;DR: 论文提出REM基准测试，用于评估多模态大语言模型在具身空间推理方面的能力，发现现有模型在复杂空间任务中表现不佳，远逊于人类。

- Motivation: 人类通过导航建立视角独立的认知地图，能够进行直观的对象持久性和空间关系推理。多模态大语言模型尽管经过大量视频训练，但缺乏这种基本的空间推理能力，这对具身应用是一个关键限制。
- Method: 引入REM（Reasoning over Embodied Multi-Frame Trajectories）基准测试，使用可控的3D环境进行长时程具身空间推理评估。系统评估对象持久性/区分、空间关系和动态视角下的数值追踪等关键方面。
- Result: 评估显示当前最佳模型表现出有希望的整体性能，但在中等复杂度的任务上就变得不可靠，而这些任务对人类来说很容易处理。模型在从序列视觉输入中发展稳健空间表示方面面临挑战。
- Conclusion: REM提供了有针对性的指标和诊断工具，以促进未来模型空间理解能力的改进。研究突显了多模态大语言模型在具身空间推理方面的局限性，为未来研究指明了方向。


### [242] [Open-Set Domain Adaptation Under Background Distribution Shift: Challenges and A Provably Efficient Solution](https://arxiv.org/abs/2512.01152)
*Shravan Chaudhari,Yoav Wald,Suchi Saria*

Main category: cs.LG

TL;DR: 论文提出了一种名为Ours的方法，用于解决背景分布变化下的开放集识别问题，该方法在理论和实验上都优于现有方法。

- Motivation: 现实世界机器学习部署中，数据分布会发生变化，包括新类别的出现（开放集识别）和已知类别分布的变化。现有开放集识别方法大多假设背景分布固定，但实际中背景分布也会变化，需要能同时处理这两种变化的鲁棒方法。
- Method: 提出Ours方法，该方法在理论上保证即使在背景分布变化的情况下也能解决开放集识别问题。方法基于新类别与非新类别可分离的良性假设，在简化过参数化设置中提供理论保证优于基线方法。还开发了使方法可扩展和鲁棒的技术。
- Result: 在图像和文本数据上进行了全面的实证评估，结果显示Ours方法在背景分布变化下显著优于现有开放集识别方法。还提供了关于新类别大小等因素如何影响性能的新见解，这是先前工作中未深入探索的方面。
- Conclusion: Ours方法能够有效解决背景分布变化下的开放集识别问题，在理论和实验上都表现出优越性能，为这一具有挑战性的问题提供了新的解决方案和见解。


### [243] [First On-Orbit Demonstration of a Geospatial Foundation Model](https://arxiv.org/abs/2512.01181)
*Andrew Du,Roberto Del Prete,Alejandro Mousist,Nick Manser,Fabrice Marre,Andrew Barton,Carl Seubert,Gabriele Meoni,Tat-Jun Chin*

Main category: cs.LG

TL;DR: 开发紧凑型地理空间基础模型变体，通过模型压缩和领域适应实现在资源受限的航天硬件上部署，保持下游任务性能的同时支持在轨推理。

- Motivation: 地理空间基础模型具有广泛泛化能力，但其大尺寸成为在资源受限的航天硬件上部署的障碍。需要解决模型大小与部署可行性之间的矛盾。
- Method: 开发基于Vision Transformer的紧凑型地理空间基础模型变体，采用模型压缩和领域适应技术，在五个下游任务上进行评估，并在两个代表性飞行环境中验证。
- Result: 模型压缩和领域适应能有效减少模型尺寸和资源需求，同时在操作条件下保持高性能。在国际空间站的IMAGIN-e载荷上成功演示了可靠的轨道推理。
- Conclusion: 建立了从大型地理空间基础模型到飞行就绪、资源高效部署的路径，扩展了地球观测任务中机载人工智能的可行性。


### [244] [Efficient Training of Diffusion Mixture-of-Experts Models: A Practical Recipe](https://arxiv.org/abs/2512.01252)
*Yahui Liu,Yang Yue,Jingyuan Zhang,Chenxi Sun,Yang Zhou,Wencong Zeng,Ruiming Tang,Guorui Zhou*

Main category: cs.LG

TL;DR: 本文系统研究了扩散专家混合模型的架构配置空间，发现通过精心调整专家模块、中间宽度、专家数量和注意力位置编码等关键因素，可以显著提升模型性能，超越单纯路由机制改进的效果。

- Motivation: 当前扩散专家混合模型研究主要集中在路由机制改进，但架构配置空间尚未充分探索。受大语言模型中MoE设计范式启发，作者认为系统研究扩散MoE的架构配置对于释放其全部潜力至关重要。
- Method: 识别并系统研究扩散MoE的关键架构因素：DeepSeek风格专家模块、替代中间宽度、不同专家数量、增强注意力位置编码。通过大量实验探索这些配置对模型性能的影响。
- Result: 研究发现精心调整架构配置可以显著提升扩散MoE模型性能，效果超过单纯路由机制改进。提出的新架构能高效应用于潜空间和像素空间扩散框架，在激活参数相等或更少的情况下超越强基线。
- Conclusion: 扩散MoE模型的架构配置空间至关重要，系统调整关键因素能释放模型潜力。提出的训练方案实用高效，代码和模型已开源。


### [245] [Stay Unique, Stay Efficient: Preserving Model Personality in Multi-Task Merging](https://arxiv.org/abs/2512.01461)
*Kuangpu Guo,Yuhe Ding,Jian Liang,Zilei Wang,Ran He*

Main category: cs.LG

TL;DR: DTS是一种基于近似的个性化模型合并框架，通过奇异值分解、阈值化和缩放策略保留任务特定信息，仅需1%额外存储，并在未见任务上实现更好泛化。

- Motivation: 现有模型合并方法相比单独微调模型存在显著性能下降，即使对于相似任务也是如此，这凸显了保留任务特定信息的必要性。
- Method: DTS框架：1) 对任务特定信息进行奇异值分解，仅保留少量奇异值和向量；2) 提出新颖阈值策略，将奇异向量元素分组并为每组分配缩放因子；3) 扩展变体基于任务特征语义相似性以无数据方式融合任务特定信息。
- Result: DTS在广泛实验中始终优于最先进的基线方法，每个任务仅需1%额外存储。在未见任务上，DTS变体实现了显著更好的泛化性能。
- Conclusion: DTS是一个有效的个性化模型合并框架，能够以最小存储开销保留任务特定信息，并在多任务场景中实现优越性能，同时具备良好的泛化能力。


### [246] [Forget Less, Retain More: A Lightweight Regularizer for Rehearsal-Based Continual Learning](https://arxiv.org/abs/2512.01818)
*Lama Alssum,Hasan Abed Al Kader Hammoud,Motasem Alfarra,Juan C Leon Alcazar,Bernard Ghanem*

Main category: cs.LG

TL;DR: 提出一种基于信息最大化的类无关正则化策略，用于改进基于记忆的持续学习方法，减少灾难性遗忘并加速收敛，在图像和视频数据上均有效。

- Motivation: 深度神经网络存在灾难性遗忘问题，即训练新任务后会忘记先前任务的知识。现有方法需要平衡记忆和正则化，但通常依赖类别信息或计算复杂。
- Method: 提出信息最大化（IM）正则化器，仅基于期望标签分布，使其成为类无关的正则化方法。可轻松集成到各种基于排练的持续学习方法中，通过最大化信息来减少遗忘。
- Result: 实验表明，IM正则化器在不同数据集和任务数量下都能持续提升基线性能，计算开销极小。在视频数据上也能改进性能，证明了其数据无关性。
- Conclusion: IM正则化器是一种轻量级、实用且可扩展的解决方案，适用于实际持续学习场景，能有效减少灾难性遗忘并加速收敛。
## physics.geo-ph

### [247] [Coarse-to-Fine Non-Rigid Registration for Side-Scan Sonar Mosaicking](https://arxiv.org/abs/2512.00052)
*Can Lei,Nuno Gracias,Rafael Garcia,Hayat Rajani,Huigang Wang*

Main category: physics.geo-ph

TL;DR: 提出分层非刚性配准框架用于侧扫声纳图像拼接，通过粗到细策略处理复杂非线性变形，显著优于现有方法

- Motivation: 侧扫声纳拼接面临复杂非线性、空间变化的变形挑战，现有刚性/仿射方法无法建模复杂变形，传统非刚性方法在稀疏纹理声纳数据中容易过拟合且缺乏鲁棒性
- Method: 分层非刚性配准框架：1) 稀疏对应点的全局薄板样条初始化；2) 超像素引导分割将图像划分为结构一致区域；3) 预训练SynthMorph网络无监督细化每个区域；4) 融合策略整合全局和局部变形为平滑统一变形场
- Result: 在挑战性声纳数据集上，该方法在准确性、结构一致性和变形平滑度方面显著优于最先进的刚性、经典非刚性和基于学习的方法
- Conclusion: 提出的分层非刚性配准框架有效解决了侧扫声纳图像拼接中的复杂变形问题，为大规模海底测绘提供了鲁棒解决方案
## cs.AR

### [248] [Ternary-Input Binary-Weight CNN Accelerator Design for Miniature Object Classification System with Query-Driven Spatial DVS](https://arxiv.org/abs/2512.00138)
*Yuyang Li,Swasthik Muloor,Jack Laudati,Nickolas Dematteis,Yidam Park,Hana Kim,Nathan Chang,Inhee Lee*

Main category: cs.AR

TL;DR: 本文提出了一种用于微型成像系统的CNN硬件加速器，通过使用三元DVS输出和三元输入-二元权重神经网络，显著降低了计算和内存需求，在28nm CMOS工艺下实现了低功耗高效能的目标检测。

- Motivation: 微型成像系统受限于内存和功耗约束，虽然机器学习可以提取关键特征减少数据量，但其高能耗需求往往超过小型电池的容量，需要专门优化的硬件加速器。
- Method: 设计了一种CNN硬件加速器，处理来自空间动态视觉传感器（DVS）的数据，可通过像素共享重新配置为时间DVS以最小化传感器面积。采用三元DVS输出和三输入-二元权重神经网络，减少计算和内存需求。
- Result: 在28nm CMOS工艺下制造，数据量减少81%，MAC操作减少27%。在仅1.6mW功耗下实现440ms推理时间，相比先前微型系统CNN加速器的品质因数（FoM）提高了7.3倍。
- Conclusion: 该硬件加速器通过创新的传感器配置和神经网络量化策略，成功解决了微型成像系统的功耗和内存限制问题，为空间受限应用提供了高效的物体分类解决方案。
## cs.CL

### [249] [InnoGym: Benchmarking the Innovation Potential of AI Agents](https://arxiv.org/abs/2512.01822)
*Jintian Zhang,Kewei Xu,Jingsheng Zheng,Zhuoyun Yu,Yuqi Zhu,Yujie Luo,Lanning Wei,Shuofei Qiao,Lun Du,Da Zheng,Shumin Deng,Huajun Chen,Ningyu Zhang*

Main category: cs.CL

TL;DR: InnoGym是首个系统评估AI智能体创新潜力的基准和框架，包含性能增益和新颖性两个互补指标，涵盖18个真实世界工程与科学任务。

- Motivation: 现有基准主要衡量正确性，忽略了解决方案背后方法的多样性。真正的创新不仅需要正确答案，还需要方法的原创性。需要能同时评估创造性和有效性的基准。
- Method: 提出InnoGym基准和框架，包含两个互补指标：性能增益（衡量相对于已知最佳方案的改进）和新颖性（捕捉与先前方法的方法学差异）。基准包含18个精心策划的真实世界工程和科学任务，通过资源过滤、评估器验证和解决方案收集进行标准化。同时提供iGym统一执行环境，用于可重复和长视野评估。
- Result: 实验显示，虽然某些智能体能产生新颖方法，但其缺乏鲁棒性限制了性能增益。这突显了创造性与有效性之间的关键差距。
- Conclusion: 需要同时评估创造性和有效性的基准，InnoGym填补了这一空白，为系统评估AI智能体的创新潜力提供了首个框架。
## cs.AI

### [250] [Med-CMR: A Fine-Grained Benchmark Integrating Visual Evidence and Clinical Logic for Medical Complex Multimodal Reasoning](https://arxiv.org/abs/2512.00818)
*Haozhen Gong,Xiaozhong Ji,Yuansen Liu,Wenbin Wu,Xiaoxiao Yan,Jingjing Liu,Kai Wu,Jiazhen Pan,Bailiang Jian,Jiangning Zhang,Xiaobin Hu,Hongwei Bran Li*

Main category: cs.AI

TL;DR: Med-CMR是一个细粒度医学复杂多模态推理基准，用于评估MLLMs在临床工作流中的复杂医学推理能力，包含20,653个VQA对，涵盖11个器官系统和12种成像模态。

- Motivation: 尽管MLLMs开始应用于临床工作流，但其执行复杂医学推理的能力尚不清楚。现有基准缺乏对医学多模态推理的细粒度评估，需要更系统、更具挑战性的评估框架。
- Method: 1）系统能力分解：将医学多模态推理分解为细粒度视觉理解和多步推理；2）挑战性任务设计：视觉理解涵盖小目标检测、细节辨别、空间理解三个维度，推理涵盖四个临床相关场景；3）广泛高质量数据覆盖：20,653个VQA对，经过两阶段（专家+模型辅助）审查确保临床真实性。
- Result: 评估18个最先进的MLLMs，GPT-5表现最佳：多选题准确率57.81%，开放式问题得分48.70%，优于Gemini 2.5 Pro和开源模型Qwen3-VL-235B-A22B。专业医学MLLMs未持续优于通用模型，长尾泛化是主要失败模式。
- Conclusion: Med-CMR为医学MLLMs的视觉-推理整合和罕见病例鲁棒性提供了压力测试，为未来临床系统建立了严格基准。该基准揭示了当前模型在复杂医学推理中的局限性，特别是长尾泛化能力不足。


### [251] [Chain-of-Ground: Improving GUI Grounding via Iterative Reasoning and Reference Feedback](https://arxiv.org/abs/2512.01979)
*Aiden Yiliu Li,Bizhi Yu,Daoan Lei,Tianhe Ren,Shilong Liu*

Main category: cs.AI

TL;DR: 提出Chain of Ground (CoG)框架，通过多步迭代视觉推理和优化，无需训练即可提升GUI grounding精度，在ScreenSpot Pro基准上提升4.8点，在工业控制面板数据集上提升6.9点。

- Motivation: 现有多模态大语言模型在GUI grounding中仍面临小目标、视觉相似目标和真实布局模糊性的挑战，这些限制源于有限的grounding能力和未充分利用现有推理潜力。
- Method: 提出Chain of Ground (CoG)训练免费的多步grounding框架，使用多模态大语言模型进行迭代视觉推理和优化。模型不是直接预测，而是逐步反思和调整假设，实现更准确和可解释的定位。
- Result: 在ScreenSpot Pro基准上达到68.4%准确率，提升4.8点。在TPanel UI工业控制面板数据集（含模糊和遮挡等视觉失真）上，相比Qwen3 VL 235B基线提升6.9点。
- Conclusion: 通过结构化迭代优化而非额外训练，可以解锁grounding潜力，该方法在真实世界和数字界面中均有效，为提升GUI grounding性能提供了新方向。
## hep-ex

### [252] [Panda: Self-distillation of Reusable Sensor-level Representations for High Energy Physics](https://arxiv.org/abs/2512.01324)
*Samuel Young,Kazuhiro Terao*

Main category: hep-ex

TL;DR: Panda是一个直接从原始未标记LArTPC数据学习可重用传感器级表示的模型，通过分层稀疏3D编码器和多视图原型自蒸馏目标，在模拟数据集上显著提高标签效率和重建质量。

- Motivation: 传统LArTPC物理重建依赖复杂的探测器特定流水线，需要大量手工设计的模式识别算法或任务特定神经网络，这些都需要大量标记模拟数据和耗时的校准过程。
- Method: Panda模型结合分层稀疏3D编码器和多视图原型自蒸馏目标，直接从原始未标记LArTPC数据学习可重用传感器级表示。
- Result: 在模拟数据集上，Panda显著提高标签效率和重建质量，比先前最先进的语义分割模型少用1000倍标签；一个仅骨干网络1/20大小的集合预测头就能实现与最先进重建工具相当的粒子识别性能。
- Conclusion: Panda展示了直接从原始未标记LArTPC数据学习可重用表示的潜力，大幅减少对标记数据和手工设计的依赖，为粒子物理重建提供更高效的解决方案。
## cs.RO

### [253] [A Comprehensive Survey on Surgical Digital Twin](https://arxiv.org/abs/2512.00019)
*Afsah Sharaf Khan,Falong Fan,Doohwan DH Kim,Abdurrahman Alshareef,Dong Chen,Justin Kim,Ernest Carter,Bo Liu,Jerzy W. Rozenblit,Bernard Zeigler*

Main category: cs.RO

TL;DR: 这是一篇关于手术数字孪生（SDTs）的综述论文，系统回顾了SDTs在术前、术中、术后护理中的发展现状、挑战和未来研究方向。

- Motivation: 随着多模态手术数据的加速可用和实时计算能力的提升，手术数字孪生作为虚拟对应物出现，但面临异构数据融合、计算效率、鲁棒性、互操作性等多重挑战，需要系统性的综述来指导该领域发展。
- Method: 采用结构化综述方法，明确术语和范围，提出基于目的、模型保真度和数据源的分类法，综合分析了变形配准与跟踪、实时仿真、AR/VR引导、边缘-云协同、AI场景理解等关键技术。
- Result: 系统梳理了SDTs领域的最新进展，对比了非机器人孪生与机器人闭环架构，识别了验证基准、安全保障、数字线程集成、数据治理等开放性问题，提出了可信赖、标准对齐的SDTs研究议程。
- Conclusion: 通过统一术语、组织能力、突出差距，本文旨在指导SDT设计和部署，推动从实验室原型到常规手术护理的转化，最终实现可衡量临床效益的可信手术数字孪生系统。


### [254] [Foundation Models for Trajectory Planning in Autonomous Driving: A Review of Progress and Open Challenges](https://arxiv.org/abs/2512.00021)
*Kemal Oksuz,Alexandru Buburuzan,Anthony Knittel,Yuhan Yao,Puneet K. Dokania*

Main category: cs.RO

TL;DR: 这篇综述论文系统回顾了基于多模态基础模型的自动驾驶轨迹规划方法，提出了统一的分类法来评估37种最新方法的架构设计、优缺点，并分析了代码和数据的开放性。

- Motivation: 多模态基础模型的出现显著改变了自动驾驶技术，从传统的手工设计转向统一的基于基础模型的方法，能够直接从原始传感器输入推断运动轨迹。这类新方法还可以将自然语言作为额外模态，VLA模型就是典型代表。需要对这些方法进行全面评估。
- Method: 通过统一的分类法对37种最近提出的方法进行系统审查，涵盖基础模型轨迹规划的各个方面。评估方法包括：分析架构设计选择、方法论优势、固有能力和限制，以及代码和数据的开放性。
- Result: 提供了对37种基于基础模型的自动驾驶轨迹规划方法的全面评估，创建了基于分类法的网页目录，为从业者和研究人员提供了有价值的信息资源。
- Conclusion: 多模态基础模型正在重塑自动驾驶轨迹规划领域，从传统方法转向更统一的端到端方法。这篇综述通过系统分类和评估为研究社区提供了重要参考，并强调了开放代码和数据集的重要性。


### [255] [Learning from Watching: Scalable Extraction of Manipulation Trajectories from Human Videos](https://arxiv.org/abs/2512.00024)
*X. Hu,G. Ye*

Main category: cs.RO

TL;DR: 提出结合大型视频理解基础模型与点跟踪技术的新方法，从网络人类演示视频中提取密集轨迹，实现更全面的机器人学习数据利用

- Motivation: 传统机器人数据收集依赖真实机器人平台，成本高且效率低；现有利用网络人类操作视频的方法主要关注手部检测或物体姿态估计，未能充分利用视频中的丰富交互线索
- Method: 结合大型视频理解基础模型与点跟踪技术，提取操作过程中所有任务相关关键点的密集轨迹
- Result: 实验结果表明，该方法能够准确跟踪整个操作过程中的关键点，为更可扩展和数据高效的机器人学习铺平道路
- Conclusion: 该方法能够更全面地利用网络规模的人类演示视频，实现更可扩展和数据高效的机器人学习


### [256] [A Survey on Improving Human Robot Collaboration through Vision-and-Language Navigation](https://arxiv.org/abs/2512.00027)
*Nivedan Yakolli,Avinash Gautam,Abhijit Das,Yuankai Qi,Virendra Singh Shekhawat*

Main category: cs.RO

TL;DR: 本文对视觉语言导航（VLN）领域进行了全面综述，分析了约200篇相关文献，总结了当前进展、挑战及未来方向，特别关注多机器人协调和实际应用。

- Motivation: 视觉语言导航作为多模态协作任务，要求智能体能够理解人类指令、在3D环境中导航并在模糊情况下有效沟通。尽管已有进展，但现有模型在双向通信、模糊性解决和多智能体协作决策方面仍面临挑战。本文旨在通过全面综述为VLN与机器人交叉领域的研究提供资源。
- Method: 通过对约200篇相关文献的系统性综述，深入分析当前VLN研究现状，特别关注多机器人协调问题。采用文献分析方法，识别关键挑战并提出未来发展方向。
- Result: 综述发现当前VLN系统在双向通信、模糊性解决和协作决策方面存在不足。提出了未来VLN系统应支持主动澄清、实时反馈和上下文推理，并需要去中心化决策框架和动态角色分配机制。
- Conclusion: 未来的VLN系统需要通过先进的自然语言理解技术增强人机交互能力，采用去中心化决策框架实现可扩展的多机器人协作。这些创新将推动VLN在医疗、物流、灾难响应等领域的实际应用部署。


### [257] [ICD-Net: Inertial Covariance Displacement Network for Drone Visual-Inertial SLAM](https://arxiv.org/abs/2512.00037)
*Tali Orlev Shapira,Itzik Klein*

Main category: cs.RO

TL;DR: ICD-Net通过神经网络处理原始惯性测量数据，生成位移估计和不确定性量化，增强视觉惯性SLAM性能，在高速无人机场景中显著提升轨迹估计精度。

- Motivation: 视觉惯性SLAM系统在无人机应用中常因传感器校准不完美、噪声测量、快速运动、低光照等因素导致性能下降，传统惯性导航方法难以处理真实世界中的传感器缺陷。
- Method: 提出ICD-Net框架，直接从传感器数据中学习提取位移图并预测测量协方差，将输出作为附加残差约束集成到VINS-Fusion优化框架中，通过预测的不确定性适当加权神经网络贡献。
- Result: 在挑战性的高速无人机序列上，相比标准VINS-Fusion，平均绝对轨迹误差(APE)改善超过38%，不确定性估计对维持系统鲁棒性至关重要，同时保持实时性能要求。
- Conclusion: 神经网络增强能有效解决SLAM中的多种退化源，ICD-Net通过学习的位移约束提供互补信息，补偿SLAM管道中的各种误差源，在相机不一致或视觉退化情况下仍能工作。


### [258] [VISTAv2: World Imagination for Indoor Vision-and-Language Navigation](https://arxiv.org/abs/2512.00041)
*Yanjia Huang,Xianshun Jiang,Xiangbo Gao,Mingyang Wu,Zhengzhong Tu*

Main category: cs.RO

TL;DR: VISTAv2提出了一种生成式世界模型，通过条件扩散Transformer预测未来视角，结合语言指令生成在线价值地图，用于视觉语言导航的鲁棒规划。

- Motivation: 现有基于图像想象的VLN方法存在局限性：缺乏在线、动作条件的预测，不产生明确的规划价值，且许多方法用长时域目标替代规划器，导致脆弱且缓慢。
- Method: 使用动作感知的条件扩散Transformer视频预测器合成短时域未来视角，通过视觉语言评分器与自然语言指令对齐，在可微分想象到价值头中融合多个推演，输出想象的自中心价值地图。为提升效率，在VAE潜在空间进行推演，使用蒸馏采样器和稀疏解码。
- Result: 在MP3D和RoboTHOR数据集上评估，VISTAv2优于强基线。消融实验表明动作条件想象、指令引导价值融合和在线价值地图规划器都是关键组件。
- Conclusion: VISTAv2为鲁棒视觉语言导航提供了一条实用且可解释的路径，通过生成式世界模型和在线价值地图规划，解决了现有方法的局限性。


### [259] [Bootstrap Dynamic-Aware 3D Visual Representation for Scalable Robot Learning](https://arxiv.org/abs/2512.00074)
*Qiwei Liang,Boyang Cai,Minghao Lai,Sitong Zhuang,Tao Lin,Yan Qin,Yixuan Ye,Jiaming Liang,Renjing Xu*

Main category: cs.RO

TL;DR: AFRO是一个自监督框架，通过生成扩散过程学习动态感知的3D表示，无需动作或重建监督，显著提升机器人操作任务的性能。

- Motivation: 当前3D视觉预训练方法在机器人操作任务上表现不佳，主要原因是缺乏状态-动作-状态动态建模，以及显式几何重建带来的不必要冗余。
- Method: AFRO将状态预测建模为生成扩散过程，在共享潜在空间中联合建模前向和逆向动态以捕捉因果转移结构。采用特征差分和逆向一致性监督防止动作学习中的特征泄漏。
- Result: 与Diffusion Policy结合时，AFRO在16个模拟和4个真实世界任务中显著提高操作成功率，优于现有预训练方法，且能随数据量和任务复杂度良好扩展。
- Conclusion: AFRO学习到语义丰富、判别性强的特征，为机器人领域的3D表示学习提供了有效的预训练解决方案。


### [260] [Arcadia: Toward a Full-Lifecycle Framework for Embodied Lifelong Learning](https://arxiv.org/abs/2512.00076)
*Minghe Gao,Juncheng Li,Yuze Lin,Xuqi Liu,Jiaming Ji,Xiaoran Pan,Zihan Xu,Xian Li,Mingjie Li,Wei Ji,Rong Wei,Rui Tang,Qizhou Wang,Kai Shen,Jun Xiao,Qi Wu,Siliang Tang,Yueting Zhuang*

Main category: cs.RO

TL;DR: Arcadia是一个闭环的具身终身学习框架，通过紧密耦合自主数据采集、生成式场景重建、共享表征学习和仿真评估四个阶段，实现持续改进和泛化，超越了单阶段优化方法。

- Motivation: 现有具身学习系统通常只优化单一环节（数据收集、仿真、学习或部署），难以实现持续改进或泛化到狭窄场景之外。作者认为具身学习本质上是生命周期问题而非单阶段优化。
- Method: Arcadia框架包含四个紧密耦合的阶段：1）自主环境探索与数据采集；2）生成式场景重建与增强；3）统一导航与操作的共享多模态表征架构；4）基于仿真的评估与演化形成闭环反馈。这四个阶段不可分解，移除任一都会破坏改进循环。
- Result: Arcadia在导航和操作基准测试中取得持续改进，并能稳健地迁移到物理机器人上。结果表明紧密耦合的生命周期（连续真实世界数据采集、生成式仿真更新、共享表征学习）支持终身改进和端到端泛化。
- Conclusion: Arcadia为通用具身智能体提供了可扩展的基础，通过标准化接口支持可复现评估和跨模型比较，展示了紧密耦合的生命周期方法对实现终身学习和泛化的重要性。


### [261] [RealAppliance: Let High-fidelity Appliance Assets Controllable and Workable as Aligned Real Manuals](https://arxiv.org/abs/2512.00287)
*Yuzheng Gao,Yuxing Long,Lei Kang,Yuchong Guo,Ziyan Yu,Shangqing Mao,Jiyao Zhang,Ruihai Wu,Dongjiang Li,Hui Shen,Hao Dong*

Main category: cs.RO

TL;DR: 提出RealAppliance数据集和RealAppliance-Bench基准，用于评估多模态大语言模型和具身操作规划模型在家电操作任务上的性能

- Motivation: 现有家电资产存在渲染质量差、机制不完整、与说明书不匹配等问题，导致仿真与现实之间的差距，阻碍了家电操作技术的发展
- Method: 1) 创建RealAppliance数据集，包含100个高保真家电，具有完整的物理、电子机制和与说明书一致的程序逻辑；2) 基于这些资产提出RealAppliance-Bench基准，评估多模态大语言模型和具身操作规划模型
- Result: 基准评估涵盖家电操作规划的四个关键任务：说明书页面检索、家电部件定位、开环操作规划、闭环规划调整
- Conclusion: 模型在RealAppliance-Bench上的性能分析为推进家电操作研究提供了重要见解


### [262] [MILE: A Mechanically Isomorphic Exoskeleton Data Collection System with Fingertip Visuotactile Sensing for Dexterous Manipulation](https://arxiv.org/abs/2512.00324)
*Jinda Du,Jieji Ren,Qiaojun Yu,Ningbin Zhang,Yu Deng,Xingyu Wei,Yufei Liu,Guoying Gu,Xiangyang Zhu*

Main category: cs.RO

TL;DR: MILE是一个机械同构的遥操作系统，用于灵巧手操作的数据收集，通过消除非线性重定向和集成高分辨率指尖视觉触觉传感器，显著提高了数据收集效率和操作性能。

- Motivation: 模仿学习在灵巧手操作中很有前景，但缺乏大规模、高保真数据。现有数据收集方法存在运动重定向不准确、数据收集效率低、缺少高分辨率指尖触觉感知等问题。
- Method: 设计MILE系统：从人手到外骨骼再到机器人手的机械同构遥操作系统。外骨骼基于人手解剖结构设计，机器人手保持一对一关节位置同构，消除非线性重定向。集成紧凑的指尖视觉触觉模块提供高分辨率触觉观测。
- Result: 外骨骼多关节平均绝对角度误差低于1度。遥操作管道平均成功率提高64%。加入指尖触觉观测后，成功率比仅视觉基线平均提高25%。高效收集了包含高分辨率指尖视觉触觉信号、RGB-D图像和关节位置的多模态数据集。
- Conclusion: MILE系统通过机械同构设计和集成高分辨率触觉感知，解决了灵巧手操作数据收集的关键瓶颈，验证了数据集的保真度和实用性，为模仿学习提供了高质量数据基础。


### [263] [Fast, Robust, Permutation-and-Sign Invariant SO(3) Pattern Alignment](https://arxiv.org/abs/2512.00659)
*Anik Sarker,Alan T. Asbeck*

Main category: cs.RO

TL;DR: 提出了一种无对应关系的旋转集对齐方法，通过将旋转分解为变换基向量，在球面上进行快速鲁棒匹配，并引入排列符号不变性包装器处理轴重标记和符号翻转，实现线性复杂度的高效对齐。

- Motivation: 在标定和配准任务中，两个旋转集的对齐常受到时间对齐缺失、异常值和未知轴约定的阻碍，传统方法复杂度高且需要对应关系搜索。
- Method: 将每个旋转分解为三个变换基向量（TBVs），在球面上使用快速鲁棒匹配器（SPMC、FRS和混合方法）进行每轴对齐。引入排列符号不变性（PASI）包装器枚举24种适当符号排列，通过相关性和评估，并通过投影/Karcher均值将每轴估计融合为单一旋转。
- Result: 在EuRoC Machine Hall模拟（轴一致）和ETH Hand-Eye基准测试（轴模糊）中，方法准确、比传统方法快6-60倍，在极端异常值比例（高达90%）下鲁棒，且无需对应关系搜索。
- Conclusion: 提出的TBV-PASI框架为旋转集对齐提供了一种高效、鲁棒的解决方案，线性复杂度使其适用于大规模应用，无需对应关系搜索即可处理轴重标记和符号翻转问题。


### [264] [Sign Language Recognition using Bidirectional Reservoir Computing](https://arxiv.org/abs/2512.00777)
*Nitin Kumar Singh,Arie Rachmad Syulistyo,Yuichiro Tanaka,Hakaru Tamukoh*

Main category: cs.RO

TL;DR: 提出使用MediaPipe提取手部关节坐标，结合回声状态网络(ESN)的双向储层计算(BRC)架构，实现高效的美国手语识别系统，在WLASL数据集上达到57.71%准确率，训练时间仅9秒。

- Motivation: 深度学习在手语识别中广泛应用，但计算密集且需要大量资源，不适合资源受限的边缘设备。需要开发更高效的手语识别系统。
- Method: 使用MediaPipe提取手部关节坐标作为特征，输入到基于ESN的双向储层计算(BRC)架构。BRC在正向和反向两个方向处理特征，有效捕捉时间依赖性，将BRC的状态拼接形成鲁棒表示用于分类。
- Result: 在WLASL视频数据集上评估，达到57.71%的竞争性准确率，训练时间仅9秒，相比基于深度学习的Bi-GRU方法（需要55分38秒）显著降低。
- Conclusion: 基于BRC的手语识别系统计算效率高，训练时间短，适合部署在边缘设备上，为资源受限环境下的手语识别提供了可行解决方案。


### [265] [FOM-Nav: Frontier-Object Maps for Object Goal Navigation](https://arxiv.org/abs/2512.01009)
*Thomas Chabal,Shizhe Chen,Jean Ponce,Cordelia Schmid*

Main category: cs.RO

TL;DR: FOM-Nav是一个用于目标物体导航的模块化框架，通过前沿-物体地图和视觉语言模型提升探索效率，在MP3D和HM3D基准测试中达到SOTA性能。

- Motivation: 现有方法存在局限性：基于隐式记忆的方法难以保持长期记忆和规划，而基于显式地图的方法缺乏丰富的语义信息。需要一种能同时解决这些问题的解决方案。
- Method: 提出FOM-Nav框架，包含三个关键组件：1）在线构建的前沿-物体地图，联合编码空间前沿和细粒度物体信息；2）视觉语言模型进行多模态场景理解和高级目标预测；3）低级规划器执行高效轨迹生成。使用真实世界扫描环境自动构建大规模导航数据集进行训练。
- Result: 在MP3D和HM3D基准测试中达到最先进性能，特别是在导航效率指标SPL上表现优异。在真实机器人上也取得了有希望的结果。
- Conclusion: FOM-Nav通过结合前沿-物体地图和视觉语言模型，有效解决了物体目标导航中的长期记忆保留和语义信息不足问题，在模拟和真实环境中都表现出色。


### [266] [Opening the Sim-to-Real Door for Humanoid Pixel-to-Action Policy Transfer](https://arxiv.org/abs/2512.01061)
*Haoru Xue,Tairan He,Zi Wang,Qingwei Ben,Wenli Xiao,Zhengyi Luo,Xingye Da,Fernando Castañeda,Guanya Shi,Shankar Sastry,Linxi "Jim" Fan,Yuke Zhu*

Main category: cs.RO

TL;DR: 提出教师-学生-引导学习框架，通过GPU加速的光线追踪仿真生成大规模数据，训练基于纯RGB视觉的人形机器人关节物体操作策略，实现零样本的仿真到现实迁移。

- Motivation: GPU加速的光线追踪仿真为机器人学习提供了可扩展的数据生成路径，但如何利用这些仿真数据训练出能够在真实世界中鲁棒执行复杂关节物体操作任务的视觉策略仍是一个挑战。
- Method: 1. 教师-学生-引导学习框架；2. 阶段重置探索策略稳定长时程特权策略训练；3. GRPO微调程序缓解部分可观测性并提升仿真到现实强化学习的闭环一致性。
- Result: 训练出的策略在多种门类型上实现鲁棒的零样本性能，在相同全身控制栈下，任务完成时间比人类遥操作快31.7%，是首个基于纯RGB感知实现多样化关节操作的人形机器人仿真到现实策略。
- Conclusion: 该研究展示了通过大规模物理和视觉随机化的仿真数据训练，能够实现人形机器人复杂关节物体操作的仿真到现实迁移，为视觉基础的机器人操作提供了有效解决方案。


### [267] [Estimation of Kinematic Motion from Dashcam Footage](https://arxiv.org/abs/2512.01104)
*Evelyn Zhang,Alex Richardson,Jonathan Sprinkle*

Main category: cs.RO

TL;DR: 使用车载摄像头视频预测车辆运动状态（速度、偏航角）及前车信息的神经网络方法研究

- Motivation: 探索车载摄像头（行车记录仪）视频能否准确预测车辆的实际运动状态，这对于自动驾驶、驾驶行为分析等应用具有重要意义
- Method: 通过车辆CAN总线获取地面真实数据，与时间同步的行车记录仪视频配对，收集18小时驾驶数据，构建神经网络模型预测车辆速度、偏航角、前车存在性、相对距离和速度
- Result: 开发了能够量化预测车辆速度、偏航角、前车存在性及其相对距离和速度准确度的神经网络模型
- Conclusion: 证明了使用车载摄像头视频预测车辆运动状态的可行性，并提供了使用开源工具和现成技术收集类似数据的完整方法，便于其他研究者复现和扩展研究


### [268] [NavForesee: A Unified Vision-Language World Model for Hierarchical Planning and Dual-Horizon Navigation Prediction](https://arxiv.org/abs/2512.01550)
*Fei Liu,Shichao Xie,Minghua Luo,Zedong Chu,Junjun Hu,Xiaolong Wu,Mu Xu*

Main category: cs.RO

TL;DR: NavForesee：一个统一的视觉语言模型，将高层语言规划与世界模型预测相结合，用于长时程导航任务，在R2R-CE和RxR-CE基准测试中表现出色。

- Motivation: 现有导航代理在复杂自然语言指令引导的长时程任务中表现不佳，缺乏对未见环境的鲁棒长期规划能力，导致高失败率。
- Method: 提出NavForesee模型，在单一框架中统一语言规划和预测性世界模型想象。模型同时执行任务分解、进度跟踪、子目标制定，并作为生成式世界模型预测短期环境动态和长期导航里程碑。
- Result: 在R2R-CE和RxR-CE基准测试中取得高度竞争力的性能，证明了在复杂场景中的有效性。
- Conclusion: 融合显式语言规划与隐式时空预测具有巨大潜力，为更智能、更强大的具身智能体开辟了新途径。


### [269] [Guardian: Detecting Robotic Planning and Execution Errors with Vision-Language Models](https://arxiv.org/abs/2512.01946)
*Paul Pacaud,Ricardo Garcia,Shizhe Chen,Cordelia Schmid*

Main category: cs.RO

TL;DR: 提出自动机器人失败合成方法，通过扰动成功轨迹生成多样化失败数据，构建新失败检测基准，并训练Guardian VLM模型，在仿真和真实机器人中提升任务成功率。

- Motivation: 当前视觉语言模型在机器人失败检测方面受限于失败数据的稀缺性，导致准确性和泛化能力有限。需要解决失败数据不足的问题来提升机器人操作的鲁棒性。
- Method: 提出自动机器人失败合成方法：通过程序化扰动成功轨迹生成多样化的规划和执行失败。该方法不仅产生二元分类标签，还生成细粒度失败类别和逐步推理轨迹。构建了三个新失败检测基准：RLBench-Fail、BridgeDataV2-Fail和UR5-Fail。基于这些数据训练Guardian模型，这是一个使用多视角图像进行详细失败推理和检测的视觉语言模型。
- Result: Guardian在现有和新引入的基准测试中均达到最先进性能。当集成到最先进的操纵系统中时，在仿真和真实机器人中有效提高了任务成功率，证明了生成失败数据的影响。
- Conclusion: 提出的自动失败合成方法有效解决了机器人失败数据稀缺问题，构建的新基准显著扩展了失败数据集的多样性和规模。Guardian模型展示了生成失败数据对提升机器人操作鲁棒性的实际价值。


### [270] [RoaD: Rollouts as Demonstrations for Closed-Loop Supervised Fine-Tuning of Autonomous Driving Policies](https://arxiv.org/abs/2512.01993)
*Guillermo Garcia-Cobo,Maximilian Igl,Peter Karkus,Zhejun Zhang,Michael Watson,Yuxiao Chen,Boris Ivanovic,Marco Pavone*

Main category: cs.RO

TL;DR: RoaD通过利用策略自身的闭环rollouts作为额外训练数据，有效缓解自动驾驶策略部署时的协变量偏移问题，显著提升闭环性能。

- Motivation: 自动驾驶策略通常通过开环行为克隆人类演示进行训练，但在闭环部署时会出现协变量偏移，导致误差累积。现有方法要么需要大量数据（如强化学习），要么有严格假设限制应用范围。
- Method: RoaD方法在生成rollouts时融入专家指导，将轨迹偏向高质量行为，产生信息丰富且真实的演示数据用于微调。这种方法结合了策略自身的闭环rollouts和专家指导，避免了传统CL-SFT方法的限制性假设。
- Result: 在WOSAC大规模交通仿真基准测试中，RoaD表现与现有CL-SFT方法相当或更好；在AlpaSim高保真神经重建端到端驾驶仿真器中，驾驶分数提升41%，碰撞减少54%。
- Conclusion: RoaD提供了一种简单高效的闭环自适应方法，仅需比强化学习少几个数量级的数据，就能在多种自动驾驶场景中显著提升策略的闭环性能，具有广泛的应用潜力。


### [271] [EfficientFlow: Efficient Equivariant Flow Policy Learning for Embodied AI](https://arxiv.org/abs/2512.02020)
*Jianlei Chang,Ruofeng Mei,Wei Ke,Xiangyu Xu*

Main category: cs.RO

TL;DR: EfficientFlow：基于流匹配的高效具身AI框架，通过引入等变性和加速正则化，解决了生成策略的数据效率和采样效率问题。

- Motivation: 现有生成策略在具身AI中存在两个关键问题：1）数据效率低，需要大规模演示数据；2）采样效率低，推理时动作生成缓慢。需要一种既能减少数据需求又能加速推理的框架。
- Method: 提出EfficientFlow统一框架：1）引入等变性到流匹配中，使用各向同性高斯先验和等变速度预测网络，确保动作分布保持等变性；2）提出加速正则化策略，通过推导替代损失函数，仅使用条件轨迹实现稳定可扩展的训练。
- Result: 在多种机器人操作基准测试中，该算法在有限数据下实现了竞争性或更优的性能，同时提供了显著更快的推理速度。
- Conclusion: EfficientFlow为高性能具身AI提供了一个强大而高效的范式，通过等变性和加速正则化同时解决了数据效率和采样效率问题。
## cs.CR

### [272] [HMARK: Radioactive Multi-Bit Semantic-Latent Watermarking for Diffusion Models](https://arxiv.org/abs/2512.00094)
*Kexin Li,Guozhen Ding,Ilya Grishchenko,David Lie*

Main category: cs.CR

TL;DR: HMARK是一种用于图像扩散模型的多比特水印方案，通过在语义潜在空间嵌入所有权信息，实现放射性、鲁棒性和高感知质量的水印保护。

- Motivation: 现代生成扩散模型依赖大量训练数据，其中可能包含所有权或使用权限不明确的图像。放射性水印可以检测未经授权的训练数据使用，但现有水印方案需要同时满足不可感知性、鲁棒性和多比特容量等要求。
- Method: HMARK将所有权信息编码为秘密比特，嵌入到图像扩散模型的语义潜在空间（h-space）。利用h-space的可解释性和语义重要性，确保水印信号对应有意义的语义属性，从而实现放射性、鲁棒性和最小化感知影响。
- Result: 实验结果显示，HMARK在经LoRA微调的下游对抗模型生成的各种失真图像上，达到98.57%的水印检测准确率、95.07%的比特级恢复准确率、100%的召回率和1.0的AUC。
- Conclusion: HMARK通过语义潜在空间水印嵌入，有效解决了扩散模型训练数据保护问题，实现了放射性、鲁棒性和高质量感知的多比特水印方案。
## eess.IV

### [273] [MedCondDiff: Lightweight, Robust, Semantically Guided Diffusion for Medical Image Segmentation](https://arxiv.org/abs/2512.00350)
*Ruirui Huang,Jiacheng Li*

Main category: eess.IV

TL;DR: MedCondDiff：基于扩散模型的多器官医学图像分割框架，通过语义引导和轻量化设计提高效率

- Motivation: 传统扩散模型在医学图像分割中存在推理时间长、显存占用大的问题，需要开发更高效且解剖学基础的方法
- Method: 使用金字塔视觉变换器（PVT）提取语义先验，将其作为条件引导去噪过程，构建语义引导的轻量级扩散架构
- Result: 在多器官、多模态数据集上表现出色，相比传统扩散模型提高了鲁棒性，同时减少了推理时间和显存使用
- Conclusion: 语义引导的扩散模型是医学成像任务中一类有效的架构，具有实际应用潜力


### [274] [Disentangling Progress in Medical Image Registration: Beyond Trend-Driven Architectures towards Domain-Specific Strategies](https://arxiv.org/abs/2512.01913)
*Bailiang Jian,Jiazhen Pan,Rohit Jena,Morteza Ghahremani,Hongwei Bran Li,Daniel Rueckert,Christian Wachinger,Benedikt Wiestler*

Main category: eess.IV

TL;DR: 该研究通过模块化框架系统分析医学图像配准中两种范式：低层"趋势驱动"计算模块（如大核CNN、Transformer）与高层配准特定设计（如运动金字塔、迭代优化）。研究发现后者贡献更大，建议未来研究应更关注领域特定设计而非通用架构趋势。

- Motivation: 当前医学图像配准方法常结合计算机视觉中的"趋势驱动"计算模块和配准特定设计，但两者的相对贡献不明确且相互纠缠。需要厘清未来配准研究应更关注通用架构趋势还是领域特定设计原则。
- Method: 开发模块化框架，涵盖脑、肺、心脏和腹部配准任务，系统分离两种范式的影响。建立透明、模块化的基准平台，支持即插即用比较新架构和配准任务。
- Result: 低层"趋势驱动"计算模块仅提供边际或不一致的改进，而高层配准特定设计能持续提供更准确、更平滑、更鲁棒的形变。领域先验显著提升标准U-Net基线性能，平均相对改进约3%，远超"趋势驱动"模块变体。
- Conclusion: 研究主张转变研究重点：从追随架构趋势转向拥抱领域特定设计原则，这些原则才是学习型医学图像配准真正进步的驱动力。提供了可扩展平台供社区进行可重复、公平的评估。
## cs.GR

### [275] [TagSplat: Topology-Aware Gaussian Splatting for Dynamic Mesh Modeling and Tracking](https://arxiv.org/abs/2512.01329)
*Hanzhi Guo,Dongdong Weng,Mo Su,Yixiao Chen,Xiaonuo Dongye,Chenyu Xu*

Main category: cs.GR

TL;DR: 提出基于高斯泼溅的拓扑感知动态重建框架，通过高斯拓扑结构显式编码空间连接性，实现拓扑一致的高质量网格序列重建

- Motivation: 现有4D重建方法难以生成高质量拓扑一致的网格序列，而拓扑一致的动态模型序列对于动画和模型编辑等应用至关重要
- Method: 基于高斯泼溅的拓扑感知动态重建框架，引入高斯拓扑结构显式编码空间连接性，实现拓扑感知的密度化和剪枝，保持高斯表示的流形一致性；使用时序正则化项确保拓扑时间一致性，结合可微分网格光栅化提升网格质量
- Result: 实验结果表明，该方法重建的拓扑一致网格序列精度显著优于现有方法，生成的网格支持精确的3D关键点跟踪
- Conclusion: 提出的拓扑感知动态重建框架能够有效生成高质量拓扑一致的网格序列，为动画和模型编辑等应用提供了更好的解决方案
## cs.MM

### [276] [Audio-Visual World Models: Towards Multisensory Imagination in Sight and Sound](https://arxiv.org/abs/2512.00883)
*Jiahua Wang,Shannan Yan,Leqi Zheng,Jialong Wu,Yaoxin Mao*

Main category: cs.MM

TL;DR: 首个音频-视觉世界模型(AVWM)框架，通过多模态扩散变换器(AV-CDiT)联合建模双耳空间音频和视觉动态，在连续导航任务中提升智能体性能。

- Motivation: 现有世界模型主要关注视觉观测，但真实世界感知本质上是多模态的。音频提供关键的空间和时间线索（如声源定位、声学场景属性），然而将其整合到世界模型中的研究仍很缺乏。目前没有工作正式定义什么是音频-视觉世界模型，也没有研究如何在精确动作控制和任务奖励预测下联合捕捉双耳空间音频和视觉动态。
- Method: 1. 提出首个音频-视觉世界模型(AVWM)正式框架，将多模态环境模拟形式化为具有同步音频-视觉观测、细粒度动作和任务奖励的部分可观测马尔可夫决策过程。2. 构建AVW-4k数据集：包含30小时双耳音频-视觉轨迹，带有动作标注和奖励信号，覆盖76个室内环境。3. 提出AV-CDiT（音频-视觉条件扩散变换器），采用新颖的模态专家架构平衡视觉和听觉学习，通过三阶段训练策略优化多模态整合。
- Result: AV-CDiT在视觉和听觉模态上实现了高保真度的多模态预测（含奖励）。在连续音频-视觉导航任务中，AVWM显著提升了智能体的性能表现。
- Conclusion: 该工作首次正式定义了音频-视觉世界模型框架，通过创新的多模态建模方法成功整合了音频和视觉信息，为多模态环境模拟和智能体规划提供了新的研究方向和实践工具。
## cs.SD

### [277] [MoLT: Mixture of Layer-Wise Tokens for Efficient Audio-Visual Learning](https://arxiv.org/abs/2512.00115)
*Kyeongha Rho,Hyeongkeun Lee,Jae Won Cho,Joon Son Chung*

Main category: cs.SD

TL;DR: MoLT是一种参数和内存高效的音频-视觉学习适应框架，通过并行提取和融合后期层的层间令牌来替代传统的逐层顺序适应。

- Motivation: 传统音频-视觉学习中的适应方法通常在每个transformer层进行顺序处理，计算量大且参数效率低。需要一种更轻量、高效的适应框架来提升性能同时减少计算开销。
- Method: 1. 使用两种类型的适配器从后期层提取模态特定信息和跨模态交互，蒸馏为紧凑的潜在令牌；2. 令牌融合模块动态融合层间令牌，考虑其相对重要性；3. 应用正交正则化防止潜在令牌冗余；4. 仅在预训练transformer的后期层提取令牌，避免早期层特征的不稳定性。
- Result: MoLT在多个音频-视觉基准测试中优于现有方法，包括音频-视觉问答、音频-视觉分割和音频-视觉事件定位任务。
- Conclusion: MoLT通过并行轻量级适应策略，在保持参数和内存效率的同时，避免了早期层特征的不稳定性，显著提升了音频-视觉学习性能，为高效的多模态适应提供了新思路。


### [278] [Art2Music: Generating Music for Art Images with Multi-modal Feeling Alignment](https://arxiv.org/abs/2512.00120)
*Jiaying Hong,Ting Zhu,Thanet Markchom,Huizhi Liang*

Main category: cs.SD

TL;DR: Art2Music：一个轻量级跨模态框架，通过艺术图像和用户评论生成情感对齐的音乐，使用两阶段方法（图像-文本融合到梅尔频谱图，再到音频波形），在感知自然度、频谱保真度和语义一致性方面表现优异。

- Motivation: 随着AI生成内容（AIGC）的兴起，从多模态输入生成感知自然且情感对齐的音乐成为核心挑战。现有方法通常依赖需要昂贵标注的显式情感标签，因此需要更灵活的情感对齐方法。
- Method: 1. 构建ArtiCaps数据集：通过语义匹配ArtEmis和MusicCaps的描述创建伪情感对齐的图像-音乐-文本数据集；2. 提出Art2Music框架：第一阶段使用OpenCLIP编码图像和文本，通过门控残差模块融合，双向LSTM解码为梅尔频谱图（使用频率加权L1损失增强高频保真度）；第二阶段使用微调的HiFi-GAN声码器重建高质量音频波形。
- Result: 在ArtiCaps上的实验显示在梅尔倒谱失真、弗雷歇音频距离、对数谱距离和余弦相似度方面有明显改进。基于小型LLM的评分研究进一步验证了一致的跨模态情感对齐，并提供了跨模态匹配和不匹配的可解释性分析。
- Conclusion: Art2Music在感知自然度、频谱保真度和语义一致性方面表现优异，仅需5万训练样本就能保持稳健性能，为交互艺术、个性化声景和数字艺术展览中的情感对齐创意音频生成提供了可扩展的解决方案。
