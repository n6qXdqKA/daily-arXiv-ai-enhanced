[[toc]]

## cs.CV

### [1] [SOSControl: Enhancing Human Motion Generation through Saliency-Aware Symbolic Orientation and Timing Control](https://arxiv.org/abs/2601.14258)
*Ho Yin Au,Junkun Jiang,Jie Chen*

Main category: cs.CV

TL;DR: 提出SOS脚本作为可编程符号框架，用于在关键帧精确控制身体部位朝向和运动时序，并开发SOSControl框架提升运动生成质量与可控性

- Motivation: 传统文本到运动框架缺乏精确控制，现有基于关节关键帧位置的方法只能提供位置指导，难以直观指定身体部位朝向和运动时序
- Method: 1) 提出SOS脚本作为符号框架；2) 开发自动SOS提取流水线，使用时序约束聚合聚类进行帧显著性检测和基于显著性的掩码方案；3) 提出SOSControl框架，优先满足稀疏SOS脚本中的方向符号约束，结合SMS数据增强和梯度迭代优化，采用ControlNet-based ACTOR-PAE解码器确保运动平滑自然
- Result: SOS提取流水线生成具有符号标注的人类可解释脚本，SOSControl框架在运动质量、可控性和泛化性方面优于现有基线，特别是在运动时序和身体部位朝向控制方面
- Conclusion: SOS脚本和SOSControl框架有效解决了传统文本到运动框架中精确控制身体部位朝向和运动时序的挑战，提供了更直观、可控的运动生成方案


### [2] [A Cloud-Based Cross-Modal Transformer for Emotion Recognition and Adaptive Human-Computer Interaction](https://arxiv.org/abs/2601.14259)
*Ziwen Zhong,Zhitao Shu,Yue Zhao*

Main category: cs.CV

TL;DR: 提出基于云的跨模态Transformer框架，通过整合视觉、听觉和文本信号实现多模态情感识别，在基准数据集上达到SOTA性能，并利用云计算实现低延迟实时交互。

- Motivation: 现有情感识别系统通常依赖单模态分析（如面部表情、语音语调或文本情感），在真实环境中鲁棒性有限、泛化能力差。需要开发能够整合多模态信号并实现实时响应的系统。
- Method: 提出Cloud-Based Cross-Modal Transformer (CMT)框架：使用预训练编码器（Vision Transformer、Wav2Vec2和BERT）整合视觉、听觉和文本信号；采用跨模态注意力机制捕捉异构特征间的复杂依赖关系；基于Kubernetes和TensorFlow Serving的云计算基础设施实现分布式训练和可扩展部署。
- Result: 在IEMOCAP、MELD和AffectNet基准数据集上达到SOTA性能：F1分数提升3.0%，交叉熵损失降低12.9%；云部署评估显示平均响应延迟为128ms，比传统Transformer融合系统降低35%。
- Conclusion: 该框架实现了高效、实时的情感识别和自适应反馈，可应用于智能客服、虚拟教学系统和情感计算界面，标志着向云原生情感计算和情感智能交互系统迈出了重要一步。


### [3] [Intelligent Power Grid Design Review via Active Perception-Enabled Multimodal Large Language Models](https://arxiv.org/abs/2601.14261)
*Taoliang Tan,Chengwei Ma,Zhen Tian,Zhao Lin,Dongdong Li,Si Shi*

Main category: cs.CV

TL;DR: 本文提出了一种基于多模态大语言模型的三阶段智能电网工程设计图纸审查框架，通过提示工程驱动，模仿专家审查流程，显著提升了超高分辨率图纸的审查准确性和可靠性。

- Motivation: 当前自动化系统在处理超高分辨率电网工程设计图纸时面临计算需求高、信息丢失和缺乏整体语义理解等问题，难以有效识别设计错误，需要更智能可靠的审查方法。
- Method: 提出三阶段框架：1) 利用MLLM进行全局语义理解，从低分辨率概览中智能提取领域特定语义区域；2) 在提议区域内进行高分辨率细粒度识别，获取带置信度的详细信息；3) 综合决策模块整合置信感知结果，准确诊断设计错误并进行可靠性评估。
- Result: 在真实电网图纸上的初步结果显示，该方法显著增强了MLLM把握宏观语义信息的能力，相比传统被动MLLM推理，在缺陷发现准确性和审查判断可靠性方面均有提升。
- Conclusion: 该研究为智能可靠的电网图纸审查提供了一种新颖的提示驱动范式，通过模仿人类专家审查流程，有效解决了超高分辨率图纸审查的挑战。


### [4] [LURE: Latent Space Unblocking for Multi-Concept Reawakening in Diffusion Models](https://arxiv.org/abs/2601.14330)
*Mengyu Sun,Ziyuan Yang,Andrew Beng Jin Teoh,Junxu Liu,Haibo Hu,Yi Zhang*

Main category: cs.CV

TL;DR: 本文提出LURE方法，通过重构潜在空间和引导采样轨迹来重新唤醒被擦除的概念，解决了现有概念擦除方法的脆弱性问题。

- Motivation: 现有概念擦除方法存在脆弱性，被擦除的概念仍可能被重新唤醒。现有重新唤醒方法主要依赖提示级优化，忽略了其他生成因素，限制了对其底层动态的全面理解。
- Method: 提出LURE方法：1) 语义重新绑定机制重构潜在空间，通过对齐去噪预测与目标分布来重建被切断的文本-视觉关联；2) 梯度场正交化解决多概念场景中的梯度冲突和特征纠缠；3) 潜在语义识别引导采样确保重新唤醒过程的稳定性。
- Result: 大量实验表明，LURE能够在多种擦除任务和方法中同时、高保真地重新唤醒多个被擦除的概念。
- Conclusion: 通过将生成过程建模为隐函数并进行全面理论分析，揭示了扰动文本条件、模型参数和潜在状态等因子都能重新唤醒被擦除概念。LURE方法有效解决了现有概念擦除方法的脆弱性问题。


### [5] [CityCube: Benchmarking Cross-view Spatial Reasoning on Vision-Language Models in Urban Environments](https://arxiv.org/abs/2601.14339)
*Haotian Xu,Yue Hu,Zhengqiu Zhu,Chen Gao,Ziyou Wang,Junreng Rao,Wenhao Lu,Weishi Li,Quanjun Yin,Yong Li*

Main category: cs.CV

TL;DR: CityCube：首个针对开放城市空间跨视角推理的基准测试，包含5,022个多视角问答对，评估33个视觉语言模型，发现与人类存在显著性能差距。

- Motivation: 现有基准主要关注室内或街道场景，忽略了开放城市空间的独特挑战（丰富语义、复杂几何、视角变化），需要专门基准评估视觉语言模型在城市环境中的跨视角推理能力。
- Method: 创建CityCube基准，整合四种视角动态模拟相机运动，涵盖车辆、无人机、卫星等多平台视角。包含5,022个标注的多视角问答对，分为五个认知维度和三种空间关系表达。
- Result: 评估33个视觉语言模型：大规模模型最高准确率仅54.1%，比人类低34.2%；小规模微调模型可达60.0%以上。分析显示任务相关性和模型与人类推理的根本认知差异。
- Conclusion: CityCube揭示了当前视觉语言模型在城市空间跨视角推理方面的显著不足，强调了专门基准的必要性，并为开发更接近人类认知能力的模型提供了方向。


### [6] [Large-Scale Label Quality Assessment for Medical Segmentation via a Vision-Language Judge and Synthetic Data](https://arxiv.org/abs/2601.14406)
*Yixiong Chen,Zongwei Zhou,Wenxuan Li,Alan Yuille*

Main category: cs.CV

TL;DR: SegAE是一个轻量级视觉语言模型，用于自动评估医学分割标签质量，在142个解剖结构上实现高质量预测，显著提升数据效率和训练性能。

- Motivation: 大规模医学分割数据集通常包含质量不均的手动和伪标签，低质量标签会损害模型训练和评估的鲁棒性，需要有效的质量评估工具。
- Method: 提出SegAE（Segmentation Assessment Engine），一个轻量级视觉语言模型，在超过400万个带质量分数的图像-标签对上进行训练，自动预测标签质量。
- Result: SegAE与真实Dice相似度相关系数达0.902，评估3D掩码仅需0.06秒；分析显示公共数据集普遍存在低质量标签；在主动和半监督学习中提升数据效率和训练性能，减少1/3标注成本和70%质量检查时间。
- Conclusion: SegAE为大规模医学分割数据集提供了简单有效的质量控制解决方案，代码、模型权重和数据集已开源。


### [7] [Vision-Based Natural Language Scene Understanding for Autonomous Driving: An Extended Dataset and a New Model for Traffic Scene Description Generation](https://arxiv.org/abs/2601.14438)
*Danial Sadrian Zadeh,Otman A. Basir,Behzad Moshiri*

Main category: cs.CV

TL;DR: 提出新框架将单目前视图像转换为自然语言描述，通过混合注意力机制增强特征提取，并构建新数据集进行验证。

- Motivation: 交通场景理解对自动驾驶安全至关重要，但现有方法在将视觉信息转换为自然语言描述方面存在不足，且缺乏专门的数据集。
- Method: 使用混合注意力机制增强空间和语义特征提取，整合特征生成丰富场景描述；基于BDD100K构建新数据集，提供详细构建指南。
- Result: 在新建数据集上，使用CIDEr、SPICE等指标和人工评估，模型表现出色，有效实现了从图像到自然语言描述的转换目标。
- Conclusion: 提出的框架能有效生成详细的交通场景自然语言描述，混合注意力机制和新建数据集为自动驾驶场景理解提供了有价值的解决方案。


### [8] [Gaussian Based Adaptive Multi-Modal 3D Semantic Occupancy Prediction](https://arxiv.org/abs/2601.14448)
*A. Enes Doruk*

Main category: cs.CV

TL;DR: 提出基于高斯分布的自适应相机-LiDAR多模态3D占据预测模型，通过内存高效的3D高斯模型融合相机语义优势与LiDAR几何优势，解决现有体素化方法计算复杂、融合脆弱的问题。

- Motivation: 稀疏目标检测范式向密集3D语义占据预测转变对自动驾驶应对长尾安全挑战至关重要。现有体素化方法存在计算复杂度高、融合过程脆弱静态、在动态环境下易失效等问题。
- Method: 提出四个关键组件：1) LiDAR深度特征聚合(LDFA)，使用深度可变形采样处理几何稀疏性；2) 基于熵的特征平滑，使用交叉熵处理领域特定噪声；3) 自适应相机-LiDAR融合，基于模型输出动态重新校准传感器输出；4) Gauss-Mamba头，使用选择性状态空间模型进行全局上下文解码，具有线性计算复杂度。
- Result: 该方法通过内存高效的3D高斯模型无缝桥接相机模态的语义优势与LiDAR模态的几何优势，提供更鲁棒、计算效率更高的3D占据预测解决方案。
- Conclusion: 提出的高斯基自适应相机-LiDAR多模态3D占据预测模型有效解决了现有方法的计算复杂度和融合脆弱性问题，为自动驾驶的长尾安全挑战提供了更优解决方案。


### [9] [Real-Time Wildfire Localization on the NASA Autonomous Modular Sensor using Deep Learning](https://arxiv.org/abs/2601.14475)
*Yajvan Ravan,Aref Malek,Chester Dolph,Nikhil Behari*

Main category: cs.CV

TL;DR: NASA开发了首个基于12通道多光谱航空影像的野火数据集，用于训练深度学习模型实现实时野火边界检测，能在夜间和云层遮挡下准确识别火场。

- Motivation: 高海拔多光谱航空影像稀缺且昂贵，但却是野火检测等关键应用的必要数据。现有数据不足限制了机器学习算法在野火检测等高风险问题上的发展。
- Method: 1) 创建NASA自主模块传感器(AMS)的12通道多光谱数据集，包含红外、短波红外和热成像数据；2) 从20个野火任务中随机采样生成4000+图像；3) 训练两个深度神经网络：图像分类和像素级分割；4) 结合两个网络构建实时分割模型。
- Result: 模型达到96%分类准确率、74%IoU和84%召回率，超越卫星数据训练模型和传统颜色规则算法。能检测夜间和云层后的野火，并区分误报。发现SWIR、IR和热成像波段对火场边界识别最重要。
- Conclusion: 多光谱航空数据集显著提升了野火检测性能，实现了实时火场边界自动化确定。该数据集和代码已开源，为野火监测研究提供了重要资源。


### [10] [XD-MAP: Cross-Modal Domain Adaptation using Semantic Parametric Mapping](https://arxiv.org/abs/2601.14477)
*Frank Bieder,Hendrik Königshof,Haohao Hu,Fabian Immel,Yinzhe Shen,Jan-Hendrik Pauls,Christoph Stiller*

Main category: cs.CV

TL;DR: XD-MAP：一种将相机图像检测转换为LiDAR语义伪标签的新方法，无需人工标注，实现跨传感器域适应

- Motivation: 当前深度学习模型性能严重依赖数据集质量，需要与目标类别、传感器特性和模态对齐。现有数据集与部署领域存在差距，需要域适应策略。本文旨在解决从相机图像到LiDAR这种完全不同传感域的跨传感器知识迁移问题。
- Method: 提出XD-MAP方法，利用神经网络在相机图像上的检测结果创建语义参数化地图。地图元素被建模以在目标域（LiDAR）中生成伪标签，无需人工标注。该方法不需要传感器直接重叠，可将前视相机的角度感知范围扩展到360度全景。
- Result: 在大规模道路特征数据集上，XD-MAP在2D语义分割上比单次基线方法提升+19.5 mIoU，2D全景分割提升+19.5 PQth，3D语义分割提升+32.3 mIoU。结果表明该方法在LiDAR数据上实现了强性能且无需人工标注。
- Conclusion: XD-MAP是一种有效的跨传感器域适应方法，能够将相机图像知识迁移到LiDAR域，无需人工标注，显著提升分割性能，并支持从有限视角扩展到全景感知。


### [11] [GutenOCR: A Grounded Vision-Language Front-End for Documents](https://arxiv.org/abs/2601.14490)
*Hunter Heidenreich,Ben Elliott,Olivia Dinica,Yosheb Getachew*

Main category: cs.CV

TL;DR: GutenOCR是基于Qwen2.5-VL模型微调的OCR前端模型系列，通过统一提示接口支持阅读、检测和定位功能，在业务文档和科学文章上表现优异。

- Motivation: 开发一个统一的OCR系统，能够同时处理文本阅读、检测和定位任务，避免传统OCR系统需要多个独立组件的复杂性，提高在业务文档和科学文章上的处理能力。
- Method: 通过微调Qwen2.5-VL-3B和Qwen2.5-VL-7B模型，在业务文档、科学文章和合成定位数据上进行训练，创建支持全页和局部阅读的单一检查点视觉语言模型。
- Result: GutenOCR-7B在10.5K个保留的业务和科学页面上，将基础模型的综合定位OCR分数从0.40提升到0.82（翻倍以上）。在Fox和OmniDocBench v1.5基准测试中，显著改进了区域和行级OCR以及文本检测召回率。
- Conclusion: GutenOCR展示了通过单一模型统一OCR任务的可行性，在文本检测和定位方面表现优异，但在页面级线性化、颜色引导OCR和公式密集布局方面存在权衡，为未来OCR系统设计提供了新方向。


### [12] [PAS-Mamba: Phase-Amplitude-Spatial State Space Model for MRI Reconstruction](https://arxiv.org/abs/2601.14530)
*Xiaoyan Kui,Zijie Fan,Zexin Ji,Qinsong Li,Hao Xu,Weixin Si,Haodong Xu,Beiji Zou*

Main category: cs.CV

TL;DR: PAS-Mamba：一种用于MRI重建的相位-幅度-空间状态空间模型，通过在频域解耦相位和幅度建模，并结合图像域特征，实现更好的重建效果。

- Motivation: 现有MRI重建方法通常将频域作为一个整体处理，忽略了其内部组件（相位和幅度）携带不同信息的差异。相位和幅度在傅里叶变换理论中代表不同类型的图像信息，统一建模会导致特征学习相互干扰。
- Method: 提出PAS-Mamba框架：1）图像域使用LocalMamba保持空间局部性以锐化细节；2）频域将幅度和相位解耦为两个专门分支；3）提出圆形频域扫描（CFDS）按频率从低到高序列化特征；4）双域互补融合模块（DDCFM）自适应融合幅度相位表示并实现频域与图像域的双向交换。
- Result: 在IXI和fastMRI膝关节数据集上的大量实验表明，PAS-Mamba在MRI重建任务上持续优于现有最先进的重建方法。
- Conclusion: 通过解耦频域相位和幅度建模，并结合图像域特征，PAS-Mamba能够更有效地利用频域信息，实现更优的MRI重建性能，验证了分别处理相位和幅度的重要性。


### [13] [Scribble-Supervised Medical Image Segmentation with Dynamic Teacher Switching and Hierarchical Consistency](https://arxiv.org/abs/2601.14563)
*Thanh-Huy Nguyen,Hoang-Loc Cao,Dat T. Chung,Mai-Anh Vu,Thanh-Minh Nguyen,Minh Le,Phat K. Huynh,Ulas Bagci*

Main category: cs.CV

TL;DR: SDT-Net：一种双教师单学生框架，通过动态教师切换和分层一致性模块，从稀疏标注中学习更准确的医学图像分割

- Motivation: 医学图像分割的标注成本极高，涂鸦标注虽然减轻了标注负担，但其稀疏性导致伪标签传播噪声大，难以学习鲁棒的解剖边界
- Method: 提出SDT-Net双教师单学生框架，包含动态教师切换模块选择最可靠的教师，通过选择可靠像素机制精炼高置信度伪标签，以及分层一致性模块实现多级特征对齐
- Result: 在ACDC和MSCMRseg数据集上达到最先进性能，产生更准确且解剖学上合理的分割结果
- Conclusion: SDT-Net通过自适应教师选择和分层监督机制，有效解决了涂鸦标注中的模糊性问题，为弱监督医学图像分割提供了有效解决方案


### [14] [Breaking the accuracy-resource dilemma: a lightweight adaptive video inference enhancement](https://arxiv.org/abs/2601.14568)
*Wei Ma,Shaowu Chen,Junjie Ye,Peichang Zhang,Lei Huang*

Main category: cs.CV

TL;DR: 提出基于模糊控制器的视频推理增强框架，通过动态切换不同规模模型来平衡资源利用与推理性能

- Motivation: 现有视频推理增强方法通常通过扩大模型规模和复杂网络架构来提升性能，但忽视了资源效率与推理效果之间的权衡，导致资源利用效率低下和推理性能欠佳
- Method: 开发基于关键系统参数和推理相关指标的模糊控制器(FC-r)，提出视频推理增强框架，利用相邻视频帧中目标的时空相关性，根据目标设备的实时资源条件在推理过程中动态切换不同规模的模型
- Result: 实验结果表明，所提方法能有效实现资源利用与推理性能之间的平衡
- Conclusion: 提出的基于模糊控制器的视频推理增强框架能够根据设备资源条件动态调整模型规模，在保证推理性能的同时提高资源利用效率


### [15] [Anatomically Guided Latent Diffusion for Brain MRI Progression Modeling](https://arxiv.org/abs/2601.14584)
*Cheng Wan,Bahram Jafrasteh,Ehsan Adeli,Miaomiao Zhang,Qingyu Zhao*

Main category: cs.CV

TL;DR: AG-LDM：一种基于分割引导的潜在扩散模型，用于生成解剖一致的大脑MRI进展图像，简化了训练流程并提高了临床协变量利用效率。

- Motivation: 现有大脑MRI进展建模方法（如BrLP）存在架构复杂、临床协变量利用不足、解剖一致性保证有限等问题，需要更高效且解剖可靠的建模框架。
- Method: 提出AG-LDM框架，直接在输入层融合基线解剖、噪声随访状态和临床协变量，避免辅助控制网络；使用轻量级3D组织分割模型（WarpSeg）在自编码器微调和扩散模型训练中提供解剖监督。
- Result: 在ADNI纵向数据上实验显示，AG-LDM达到或超越更复杂的扩散模型，图像质量最优，体积误差降低15-20%；临床协变量敏感性比BrLP高31.5倍，能生成生物学合理的反事实轨迹。
- Conclusion: AG-LDM是一个高效、解剖基础可靠的大脑MRI进展建模框架，能准确捕捉阿尔茨海默病进展特征，为神经退行性疾病研究提供有力工具。


### [16] [From Volumes to Slices: Computationally Efficient Contrastive Learning for Sequential Abdominal CT Analysis](https://arxiv.org/abs/2601.14593)
*Po-Kai Chiu,Hung-Hsuan Chen*

Main category: cs.CV

TL;DR: 提出2D-VoCo方法，將3D對比學習框架適應到2D切片層面，用於CT圖像的自監督預訓練，降低計算成本並提升多器官損傷分類性能。

- Motivation: 醫學圖像分析中專家標註需求限制了深度學習效果，現有3D自監督方法計算成本高、內存消耗大，需要更高效的解決方案。
- Method: 將VoCo框架改進為2D-VoCo，在未標註的2D CT切片上進行對比學習預訓練，然後將預訓練的CNN骨幹整合到CNN-LSTM架構中進行多器官損傷分類。
- Result: 在RSNA 2023腹部創傷數據集上，2D-VoCo預訓練顯著提高了mAP、精確率、召回率和RSNA評分，相比從頭訓練有明顯優勢。
- Conclusion: 2D-VoCo提供了一種實用方法，減少對標註數據的依賴，提升臨床CT分析性能，代碼已開源以確保可重現性。


### [17] [LFS: Learnable Frame Selector for Event-Aware and Temporally Diverse Video Captioning](https://arxiv.org/abs/2601.14594)
*Lianying Chao,Linfeng Yin,Peiyu Ren,Yifan Jiang,Qiaoyu Ren,Dingcheng Shan,Jing-cheng Pang,Sijie Wu,Xubin Li,Kai Zhang*

Main category: cs.CV

TL;DR: 本文提出可学习的帧选择器（LFS），通过选择时间多样且事件相关的帧来改进视频描述生成，并引入ICH-CC基准来评估人类一致性理解。

- Motivation: 现有视频描述模型使用均匀采样帧，但忽略了视频事件分布不均匀的问题，导致无法有效捕捉重要事件。同时现有基准与人类认知存在差距。
- Method: 提出可学习的帧选择器（LFS），显式建模时间重要性以平衡时间多样性和事件相关性，采用分层策略确保时间覆盖并避免聚类。利用冻结的视频LLM的标题反馈来学习直接优化下游描述质量的帧选择。还构建了ICH-CC基准，包含反映人类一致性理解的精心设计问题。
- Result: LFS在两个代表性社区基准和ICH-CC上持续改进详细视频描述，在VDC上获得高达2.0%的提升，在ICH-CC上获得超过4%的提升。增强的描述还提高了视频问答性能。
- Conclusion: LFS为详细视频描述提供了有效且易于集成的解决方案，通过智能帧选择平衡时间多样性和事件相关性，显著提升描述质量和下游任务性能。


### [18] [3D Space as a Scratchpad for Editable Text-to-Image Generation](https://arxiv.org/abs/2601.14602)
*Oindrila Saha,Vojtech Krs,Radomir Mech,Subhransu Maji,Matheus Gadelha,Kevin Blackburn-Matzen*

Main category: cs.CV

TL;DR: 提出空间草稿本概念，通过3D推理基板连接语言意图与图像合成，实现更精确可控的图像生成

- Motivation: 现有视觉语言模型缺乏空间推理机制，难以生成准确反映几何关系、物体身份和组合意图的图像
- Method: 引入空间草稿本框架：解析文本提示中的主体和背景元素，实例化为可编辑3D网格，通过智能场景规划进行放置、定向和视角选择，最后渲染回图像域
- Result: 在GenAI-Bench上实现32%的文本对齐改进，支持直观的3D编辑并能可靠传播到最终图像
- Conclusion: 展示了视觉语言模型不仅能在语言层面推理，还能在空间层面进行推理的新范式，显式3D推理能显著提升图像生成的精确性和可控性


### [19] [U-Harmony: Enhancing Joint Training for Segmentation Models with Universal Harmonization](https://arxiv.org/abs/2601.14605)
*Weiwei Ma,Xiaobing Yu,Peijie Qiu,Jin Yang,Pan Xiao,Xiaoqi Zhao,Xiaofeng Liu,Tomo Miyazaki,Shinichiro Omachi,Yongsong Huang*

Main category: cs.CV

TL;DR: 提出U-Harmony方法，通过领域门控头和特征分布归一化/反归一化，使单一分割模型能同时学习异构医学数据集，支持新模态和类别适应。

- Motivation: 临床实践中医学分割数据集通常有限且异构（不同模态、协议、解剖目标），现有深度学习模型难以同时学习这类数据，往往牺牲泛化性或领域特定知识。
- Method: 提出通用协调(U-Harmony)联合训练方法，集成到带领域门控头的深度学习架构中。通过顺序归一化和反归一化特征分布来减少领域特定变异，同时保留原始数据集特定知识。支持通用模态适应，可无缝学习新成像模态和解剖类别。
- Result: 在跨机构脑病变数据集上的广泛实验证明了方法的有效性，为真实临床环境中稳健且可适应的3D医学图像分割模型建立了新基准。
- Conclusion: U-Harmony方法能够有效处理异构医学分割数据，实现单一模型的多领域学习，支持新模态适应，在临床应用中具有实用价值。


### [20] [Learning Consistent Taxonomic Classification through Hierarchical Reasoning](https://arxiv.org/abs/2601.14610)
*Zhenghong Li,Kecheng Zheng,Haibin Ling*

Main category: cs.CV

TL;DR: VL-Taxon是一个两阶段的层次推理框架，通过自上而下的过程提高叶级分类准确性，然后利用准确的叶级输出来确保整个分类层次的一致性，显著提升了视觉语言模型在分类学任务中的表现。

- Motivation: 视觉语言模型在视觉理解方面表现出色，但在理解层次知识方面存在不足，经常在正确识别最具体层级（叶级）的同时，错误分类更粗的分类层级。现有方法大多忽略了这一问题，未能建模层次推理。
- Method: 提出VL-Taxon两阶段层次推理框架：第一阶段采用自上而下的过程增强叶级分类准确性；第二阶段利用准确的叶级输出确保整个分类层次的一致性。每个阶段先通过监督微调注入分类学知识，然后通过强化学习优化模型的推理和泛化能力。
- Result: 在Qwen2.5-VL-7B模型上实现VL-Taxon框架，在iNaturalist-2021数据集上，叶级准确性和层次一致性准确率平均超过原始72B模型10%以上。这一显著提升仅通过对少量数据子集进行微调实现，无需依赖其他VLM生成的示例。
- Conclusion: VL-Taxon框架有效解决了视觉语言模型在层次知识理解方面的不足，通过层次推理显著提升了分类学任务中的准确性和一致性，证明了层次推理在视觉语言模型中的重要性。


### [21] [Diffusion Epistemic Uncertainty with Asymmetric Learning for Diffusion-Generated Image Detection](https://arxiv.org/abs/2601.14625)
*Yingsong Huang,Hui Guo,Jing Huang,Bing Bai,Qi Xiong*

Main category: cs.CV

TL;DR: 提出DEUA框架，通过区分扩散模型中的认知不确定性和偶然不确定性来提升生成图像检测性能，使用拉普拉斯近似估计认知不确定性并结合非对称损失函数训练分类器。

- Motivation: 现有基于扩散模型的生成图像检测方法虽然利用重建误差等测量指标，但忽略了偶然不确定性和认知不确定性对重建误差的不同影响。偶然不确定性源于数据固有噪声，会阻碍生成图像的准确检测；而认知不确定性反映模型对陌生模式的知识缺乏，有助于检测区分。
- Method: 提出DEUA框架：1) 使用拉普拉斯近似估计扩散认知不确定性(DEU)，评估数据与扩散生成样本流形的接近程度；2) 引入非对称损失函数训练具有更大边界的平衡分类器，提升泛化能力。
- Result: 在大规模基准测试上进行广泛实验，验证了该方法达到了最先进的性能水平。
- Conclusion: 通过区分扩散模型中的认知不确定性和偶然不确定性，并引入非对称学习策略，DEUA框架能够有效提升生成图像检测的准确性和泛化能力。


### [22] [Forest-Chat: Adapting Vision-Language Agents for Interactive Forest Change Analysis](https://arxiv.org/abs/2601.14637)
*James Brock,Ce Zhang,Nantheera Anantrasirichai*

Main category: cs.CV

TL;DR: Forest-Chat：基于大语言模型的森林变化分析智能体，整合视觉语言模型与遥感影像，支持自然语言查询和多任务森林变化解释

- Motivation: 高分辨率卫星影像与深度学习结合为森林监测带来新机遇，但像素级变化检测和语义变化解释仍是挑战。现有大语言模型在遥感影像变化解释方面，特别是在森林等非城市环境中的应用仍不足
- Method: 提出Forest-Chat框架，采用多级变化解释视觉语言骨干网络与大语言模型编排，结合零样本变化检测基础模型和交互式点提示界面，支持细粒度用户指导
- Result: 在Forest-Change数据集和LEVIR-MCI-Trees子集上表现出色，实现联合变化检测和描述，验证了交互式LLM驱动遥感影像变化解释系统在森林变化分析中的有效性
- Conclusion: Forest-Chat展示了交互式LLM驱动遥感影像变化解释系统在提高森林变化分析的可访问性、可解释性和分析效率方面的潜力


### [23] [READ-Net: Clarifying Emotional Ambiguity via Adaptive Feature Recalibration for Audio-Visual Depression Detection](https://arxiv.org/abs/2601.14651)
*Chenglizhao Chen,Boze Li,Mengke Song,Dehao Feng,Xinyu Liu,Shanchen Pang,Jufeng Yang,Hui Yu*

Main category: cs.CV

TL;DR: READ-Net：首个通过自适应特征重校准解决情感模糊性的视听抑郁检测框架，能动态调整情感特征权重以增强抑郁相关信号，在三个公开数据集上平均准确率提升4.55%

- Motivation: 现有视听抑郁检测方法存在两个问题：1）忽略情感线索的方法无法捕捉隐藏在情感表达中的抑郁信号；2）包含情感的方法经常混淆短暂情感表达与稳定抑郁症状（情感模糊性），导致检测错误
- Method: 提出READ-Net框架，核心是自适应特征重校准（AFR）：动态调整情感特征权重，创新性地识别并保留情感特征中的抑郁相关线索，同时自适应过滤无关的情感噪声，可轻松集成到现有框架中
- Result: 在三个公开数据集上的广泛评估显示，READ-Net优于最先进方法，平均准确率提升4.55%，F1分数提升1.26%，证明其对情感干扰的鲁棒性
- Conclusion: READ-Net通过解决情感模糊性显著改善了视听抑郁检测，能够有效区分抑郁症状与情感表达，为自动抑郁检测提供了更可靠的解决方案


### [24] [Mirai: Autoregressive Visual Generation Needs Foresight](https://arxiv.org/abs/2601.14671)
*Yonghao Yu,Lang Huang,Zerun Wang,Runyi Li,Toshihiko Yamasaki*

Main category: cs.CV

TL;DR: Mirai框架通过注入未来信息改进自回归视觉生成，无需架构改变或额外推理开销，显著加速收敛并提升生成质量

- Motivation: 传统自回归视觉生成器使用严格的因果监督，每个步骤仅通过下一个标记进行优化，这削弱了全局连贯性并减缓收敛速度。研究探索未来信息（foresight）是否能帮助自回归视觉生成。
- Method: 提出Mirai框架，通过两种方式注入未来信息：Mirai-E使用来自单向表示中多个未来位置的显式未来信息；Mirai-I利用匹配的双向表示中的隐式未来信息。关键洞察是将未来信息与自回归模型在2D图像网格上的内部表示对齐。
- Result: Mirai显著加速收敛并提高生成质量。例如，Mirai可将LlamaGen-B的收敛速度提升高达10倍，在ImageNet类条件图像生成基准上将生成FID从5.34降低到4.34。
- Conclusion: 研究表明视觉自回归模型需要未来信息，Mirai框架通过注入未来信息有效解决了传统自回归模型全局连贯性差和收敛慢的问题，为自回归视觉生成提供了新的改进方向。


### [25] [LaVR: Scene Latent Conditioned Generative Video Trajectory Re-Rendering using Large 4D Reconstruction Models](https://arxiv.org/abs/2601.14674)
*Mingyang Xie,Numair Khan,Tianfu Wang,Naina Dhingra,Seonghyeon Nam,Haitao Yang,Zhuo Hui,Christopher Metzler,Andrea Vedaldi,Hamed Pirsiavash,Lei Luo*

Main category: cs.CV

TL;DR: 提出LAVR方法，利用大型4D重建模型的隐式几何知识进行视频重渲染，避免显式重建的误差问题

- Motivation: 现有视频重渲染方法面临两大挑战：几何无约束模型缺乏空间感知导致视角变化时出现漂移和变形；几何约束模型依赖估计深度和显式重建，易受深度不准确和校准误差影响
- Method: 利用大型4D重建模型潜在空间中的隐式几何知识来约束视频生成过程，这些潜在表示在连续空间中捕获场景结构而无需显式重建，同时结合源相机位姿进行联合约束
- Result: 在视频重渲染任务上取得了最先进的结果
- Conclusion: 通过利用4D重建模型的隐式几何潜在表示，提供了一种灵活的表征方式，使预训练扩散先验能更有效地正则化误差，解决了现有方法的局限性


### [26] [A comprehensive overview of deep learning models for object detection from videos/images](https://arxiv.org/abs/2601.14677)
*Sukana Zulfqar,Sadia Saeed,M. Azam Zia,Anjum Ali,Faisal Mehmood,Abid Ali*

Main category: cs.CV

TL;DR: 这篇综述论文系统回顾了视频和图像监控中的现代目标检测技术，重点关注深度学习进展、架构创新、生成模型集成和时序信息利用，并分析了监控特定挑战和未来趋势。

- Motivation: 视频和图像监控中的目标检测是一个成熟但快速发展的任务，受到深度学习进展的强烈影响。本文旨在总结现代技术，评估当前语义目标检测的有效性，分析深度学习模型及其实际应用，同时解决监控特定挑战如动态环境、遮挡、光照变化和实时需求。
- Method: 通过分类方法基于核心架构、数据处理策略和监控特定挑战，系统回顾了CNN-based检测器、GAN辅助方法和时序融合方法。涵盖预处理流程、特征提取进展、基准数据集和比较评估，特别关注生成模型在重建缺失帧、减少遮挡和光照归一化等任务中的应用。
- Result: 综述系统总结了现代目标检测技术，突出了架构创新和生成模型集成如何增强鲁棒性和准确性。识别了生成模型在解决监控挑战中的关键作用，并提供了各种方法的比较评估，展示了当前技术的有效性。
- Conclusion: 论文确定了低延迟、高效和时空学习方法等新兴趋势作为未来研究方向。强调了监控目标检测领域需要持续创新以应对动态环境、实时处理等挑战，为研究人员提供了全面的技术路线图。


### [27] [Transfer Learning from One Cancer to Another via Deep Learning Domain Adaptation](https://arxiv.org/abs/2601.14678)
*Justin Cheung,Samuel Savine,Calvin Nguyen,Lin Lu,Alhassan S. Yasin*

Main category: cs.CV

TL;DR: 该研究评估了深度学习模型在癌症组织病理学中的跨域泛化能力，发现传统监督学习模型在未见癌症类型上表现不佳，而域对抗神经网络（DANN）能显著提升跨域分类性能，染色归一化的效果因目标域而异。

- Motivation: 监督深度学习模型在训练分布内表现优异，但在癌症组织病理学中难以泛化到未见癌症类型。尽管不同器官的腺癌具有共享的形态特征，但直接解决域偏移对于稳健性能至关重要。域适应提供了一种将知识从标记的癌症类型转移到未标记数据的方法，有助于缓解医学图像标注稀缺的问题。
- Method: 研究评估了肺、结肠、乳腺和肾脏腺癌的跨域分类性能。使用ResNet50作为基础模型，比较了单域监督训练、多模型集成和域对抗神经网络（DANN）方法。同时研究了染色归一化对域适应的影响，并使用集成梯度分析模型关注的区域。
- Result: 单域训练的ResNet50在自身域上达到98%以上准确率，但对其他域泛化能力极低。集成方法无法解决此限制。DANN显著提升未标记目标域性能：在乳腺和结肠数据上训练并适应未标记肺数据时达到95.56%准确率。染色归一化效果因目标域而异：对肺目标域准确率从95.56%降至66.60%，而对乳腺和结肠目标域则分别从49.22%提升至81.29%和从78.48%提升至83.36%。集成梯度分析显示DANN持续关注生物学意义区域（如密集细胞核）。
- Conclusion: 域对抗神经网络能有效提升癌症组织病理学中的跨域泛化能力，学习临床相关特征并应用于未标记癌症类型。染色归一化的效果高度依赖于目标域，需谨慎应用。模型通过关注生物学意义区域表明其学习到了临床相关特征。


### [28] [FeedbackSTS-Det: Sparse Frames-Based Spatio-Temporal Semantic Feedback Network for Infrared Small Target Detection](https://arxiv.org/abs/2601.14690)
*Yian Huang,Qing Qin,Aji Mao,Xiangyu Qiu,Liang Xu,Xian Zhang,Zhenming Peng*

Main category: cs.CV

TL;DR: 提出FeedbackSTS-Det网络，通过时空语义反馈策略和结构化稀疏时序建模，在复杂背景下实现高效的红外小目标检测

- Motivation: 复杂背景下的红外小目标检测面临信噪比极低、动态干扰持续、目标特征不明显等挑战。现有多帧检测方法在长距离依赖建模效率不足和鲁棒性不够方面仍有局限
- Method: 提出基于稀疏帧的时空语义反馈网络FeedbackSTS-Det，核心是包含前向和后向细化模块的闭环语义关联机制，两个模块都嵌入了结构化稀疏语义模块(SSM)，以低计算成本捕获长距离依赖
- Result: 在多个基准数据集上的大量实验证实了FeedbackSTS-Det的有效性
- Conclusion: 提出的时空语义反馈策略和结构化稀疏时序建模能够有效抑制虚警，保持一致的训练-推理流程确保了可靠的性能迁移和模型鲁棒性


### [29] [RegFreeNet: A Registration-Free Network for CBCT-based 3D Dental Implant Planning](https://arxiv.org/abs/2601.14703)
*Xinquan Yang,Xuguang Li,Mianjie Zheng,Xuefen Liu,Kun Tang,Kian Ming Lim,He Meng,Jianfeng Ren,Linlin Shen*

Main category: cs.CV

TL;DR: 提出ImplantFairy数据集和RegFreeNet网络，通过掩码植入体解决训练数据获取难题，实现无需配准的植入位置预测

- Motivation: 商业手术导板设计软件通常不支持导出植入位置数据，现有方法需要扫描术后数据并通过配准映射到术前空间，过程耗时且依赖配准精度。同时，并非所有医院都有配对的CBCT数据，限制了多中心数据集的构建。
- Method: 1. 提出掩码植入体范式：在术后数据中掩码植入体，使任何包含植入体的CBCT都能作为训练数据，无需配准过程；2. 构建ImplantFairy数据集：包含1622个CBCT数据的公开数据集，具有体素级3D标注；3. 设计RegFreeNet网络：包含邻近距离感知模块提取牙齿区域变化特征，以及植入体斜率预测分支通过额外监督信息学习更鲁棒特征。
- Result: 在ImplantFairy和两个公共数据集上的广泛实验表明，提出的RegFreeNet实现了最先进的性能。
- Conclusion: 通过掩码植入体范式解决了训练数据获取难题，提出的ImplantFairy数据集和RegFreeNet网络为牙科植入体位置预测提供了有效的解决方案，支持大规模多中心数据集的构建。


### [30] [LookBench: A Live and Holistic Open Benchmark for Fashion Image Retrieval](https://arxiv.org/abs/2601.14706)
*Chao Gao,Siqiao Xue,Yimin Peng,Jiwen Fu,Tingyi Gu,Shanshan Li,Fan Zhou*

Main category: cs.CV

TL;DR: LookBench是一个用于时尚图像检索的实时、全面且具有挑战性的基准测试，包含实时电商图像和AI生成图像，支持污染感知评估，并定期更新以反映最新趋势。

- Motivation: 现有时尚图像检索基准存在过时、缺乏实时性、无法反映真实电商场景等问题，需要建立一个能持续更新、包含真实电商数据和AI生成图像、支持污染感知评估的基准测试。
- Method: 构建包含实时电商网站产品图像和AI生成时尚图像的数据集，基于细粒度属性分类法，涵盖单品和搭配级别的检索任务，采用时间戳机制支持污染感知评估，并计划每半年更新一次。
- Result: LookBench对现有强基线模型构成显著挑战，许多模型Recall@1低于60%；作者专有模型在LookBench上表现最佳，开源模型排名第二，两者在传统Fashion200K评估中都达到SOTA。
- Conclusion: LookBench提供了一个持久衡量时尚图像检索进展的基准，通过定期更新测试样本和逐步增加任务难度，能够持续反映领域发展，已公开排行榜、数据集、评估代码和训练模型。


### [31] [Context Patch Fusion With Class Token Enhancement for Weakly Supervised Semantic Segmentation](https://arxiv.org/abs/2601.14718)
*Yiyang Fu,Hui Li,Wangyu Wu*

Main category: cs.CV

TL;DR: 提出CPF-CTE框架，通过上下文补丁融合和类别令牌增强，利用补丁间上下文关系来改进弱监督语义分割性能

- Motivation: 现有弱监督语义分割方法主要关注类间区分和数据增强，但忽略了图像补丁间复杂的上下文依赖关系，导致局部表示不完整和分割精度受限
- Method: 提出CPF-CTE框架，包含CF-BiLSTM模块捕获补丁间空间依赖和双向信息流，以及可学习的类别令牌动态编码和细化类别特定语义
- Result: 在PASCAL VOC 2012和MS COCO 2014数据集上的广泛实验验证了CPF-CTE持续超越先前的WSSS方法
- Conclusion: 通过有效整合空间和语义线索，CPF-CTE能够产生更丰富准确的图像内容表示，提升弱监督语义分割性能


### [32] [HERMES: KV Cache as Hierarchical Memory for Efficient Streaming Video Understanding](https://arxiv.org/abs/2601.14724)
*Haowei Zhang,Shudong Yang,Jinlan Fu,See-Kiong Ng,Xipeng Qiu*

Main category: cs.CV

TL;DR: HERMES是一种无需训练的视频流实时理解架构，通过分层KV缓存机制实现高效视频流处理，在保持准确性的同时显著降低计算开销。

- Motivation: 现有多模态大语言模型在离线视频理解方面表现良好，但在处理视频流输入时面临挑战：难以同时维持稳定的理解性能、实时响应和低GPU内存开销。
- Method: 基于注意力机制分析，将KV缓存概念化为分层记忆框架，封装多粒度视频信息；在推理时重用紧凑的KV缓存，实现资源受限下的高效流式理解。
- Result: 相比之前SOTA方法，TTFT提升10倍；即使视频token减少68%，在所有基准测试中仍达到相当或更优的准确性，在流式数据集上最高提升11.4%。
- Conclusion: HERMES通过创新的分层KV缓存架构，成功解决了视频流实时理解的挑战，在性能、速度和资源效率方面取得显著改进。


### [33] [DeepMoLM: Leveraging Visual and Geometric Structural Information for Molecule-Text Modeling](https://arxiv.org/abs/2601.14732)
*Jing Lan,Hexiao Ding,Hongzhao Chen,Yufeng Jiang,Nga-Chun Ng,Gwing Kei Yip,Gerald W. Y. Cheng,Yunlin Mao,Jing Cai,Liang-ting Lin,Jung Sun Yoo*

Main category: cs.CV

TL;DR: DeepMoLM是一个双视图分子语言建模框架，通过融合高分辨率分子图像和3D几何不变特征，实现物理基础生成，在分子图像描述和属性预测任务上优于通用基线模型。

- Motivation: 现有分子语言模型大多依赖字符串或图表示，而视觉语言模型往往忽略立体化学细节，难以将连续3D结构映射到离散标记中。需要一种能同时处理分子图像和3D几何信息的方法。
- Method: 提出DeepMoLM双视图框架：1) 从1024×1024高分辨率分子图像中提取高频证据；2) 将构象邻域编码为离散的扩展3D指纹；3) 通过交叉注意力融合视觉和几何流，实现无需原子坐标的物理基础生成。
- Result: 在PubChem图像描述任务上相对最强通用基线获得12.3%的METEOR提升；在属性预测任务中，分子量MAE为13.64 g/mol，复杂度MAE为37.89；在ChEBI-20图像描述生成任务上超越通用基线，与最先进的视觉语言模型相当。
- Conclusion: DeepMoLM通过融合分子图像和3D几何不变特征，实现了更好的分子理解和生成能力，为药物发现和化学文献挖掘提供了有效的多模态解决方案。


### [34] [Safeguarding Facial Identity against Diffusion-based Face Swapping via Cascading Pathway Disruption](https://arxiv.org/abs/2601.14738)
*Liqin Wang,Qianyue Hu,Wei Lu,Xiangyang Luo*

Main category: cs.CV

TL;DR: VoidFace是一种针对扩散模型人脸交换系统的主动防御方法，通过注入扰动破坏身份信息，防止隐私泄露

- Motivation: 扩散模型的人脸交换技术快速发展，但现有防御方法（主要来自图像编辑攻击）对此无效，因为忽略了人脸交换系统的结构韧性和独特的静态条件引导机制
- Method: 1. 将人脸交换视为耦合身份通路；2. 在关键瓶颈处注入扰动引发级联破坏；3. 定位破坏和身份擦除以降低物理回归和语义嵌入；4. 在生成域干预：解耦注意力机制切断身份注入，破坏扩散特征防止身份重建；5. 在潜在流形中进行对抗搜索，使用感知自适应策略平衡攻击效果和图像质量
- Result: VoidFace在各种基于扩散的交换模型中优于现有防御方法，同时生成具有优越视觉质量的对抗性人脸
- Conclusion: VoidFace为扩散模型人脸交换提供了一种有效的系统性防御方法，通过破坏身份信息通路保护隐私安全


### [35] [Enhancing Text-to-Image Generation via End-Edge Collaborative Hybrid Super-Resolution](https://arxiv.org/abs/2601.14741)
*Chongbin Yi,Yuxin Liang,Ziqi Zhou,Peng Yang*

Main category: cs.CV

TL;DR: 提出端边协同的生成-增强框架，通过自适应选择去噪步数和超分辨率尺度，结合区域感知的混合超分辨率策略，在保持图像质量的同时将服务延迟降低33%。

- Motivation: 高分辨率文本到图像生成在提升用户体验质量方面日益重要，但资源受限的边缘计算虽然能支持快速低分辨率生成，高分辨率输出仍面临图像保真度与延迟之间的权衡挑战。
- Method: 端边协同的生成-增强框架：边缘侧基于自适应选择的去噪步数和超分辨率尺度生成低分辨率图像，然后分区处理，采用区域感知混合超分辨率策略，对前景区域使用基于扩散的超分辨率模型恢复细节，对背景区域使用轻量级学习型超分辨率模型进行高效放大，最后拼接增强后的图像。
- Result: 实验表明，该系统在保持竞争力的图像质量的同时，相比基线方法将服务延迟降低了33%。
- Conclusion: 提出的端边协同框架通过智能分区和混合超分辨率策略，有效解决了高分辨率文本到图像生成中的延迟与保真度权衡问题，为边缘计算环境下的高质量图像生成提供了实用解决方案。


### [36] [SimD3: A Synthetic drone Dataset with Payload and Bird Distractor Modeling for Robust Detection](https://arxiv.org/abs/2601.14742)
*Ami Pandat,Kanyala Muvva,Punna Rajasekhar,Gopika Vinod,Rohit Shukla*

Main category: cs.CV

TL;DR: SimD3是一个大规模高保真合成无人机检测数据集，通过建模异质载荷无人机、鸟类干扰物和多样化环境，显著提升了无人机检测的鲁棒性和泛化能力。

- Motivation: 无人机检测面临三大挑战：真实世界标注数据有限、外观变化大、存在鸟类等视觉相似干扰物。现有合成数据集无法充分解决这些问题。
- Method: 构建SimD3合成数据集：1) 建模带异质载荷的无人机；2) 加入多种鸟类作为真实干扰物；3) 使用Unreal Engine 5创建多样化环境，控制天气、光照和飞行轨迹；4) 采用360度六相机系统采集数据。在YOLOv5框架中引入注意力增强变体Yolov5m+C3b，将标准C3模块替换为C3b模块。
- Result: SimD3为小目标无人机检测提供了有效监督，Yolov5m+C3b在领域内和跨数据集评估中均优于基线模型，证明了SimD3在训练和评估鲁棒无人机检测模型方面的实用性。
- Conclusion: SimD3合成数据集能够有效解决无人机检测中的数据稀缺和干扰问题，结合注意力增强的检测框架，显著提升了在复杂空中环境下的无人机检测鲁棒性和泛化能力。


### [37] [ReinPath: A Multimodal Reinforcement Learning Approach for Pathology](https://arxiv.org/abs/2601.14757)
*Kangcheng Zhou,Jun Jiang,Qing Zhang,Shuang Zheng,Qingli Li,Shugong Xu*

Main category: cs.CV

TL;DR: 提出一种具有强推理能力的多模态病理学大语言模型，通过语义奖励策略和高质量VQA数据集提升病理图像与文本的推理解释性

- Motivation: 现有病理学多模态方法由于缺乏支持显式推理的高质量数据集和简单推理过程，导致可解释性有限
- Method: 设计语义奖励策略结合群体相对策略优化，构建高质量病理视觉问答数据集支持复杂推理任务
- Result: 在构建的数据集上超越现有方法，仅用20%数据训练即可达到优异性能，在零样本图像分类任务上与CLIP相当
- Conclusion: 提出的多模态病理大语言模型显著提升了病理图像与文本的推理能力和可解释性


### [38] [Using Multi-Instance Learning to Identify Unique Polyps in Colon Capsule Endoscopy Images](https://arxiv.org/abs/2601.14771)
*Puneet Sharma,Kristian Dalsbø Hindberg,Eibe Frank,Benedicte Schelde-Olesen,Ulrik Deding*

Main category: cs.CV

TL;DR: 该论文提出了一种基于多示例学习（MIL）和注意力机制的框架，用于识别结肠胶囊内镜图像中独特的息肉，通过注意力机制和自监督学习提升模型性能。

- Motivation: 结肠胶囊内镜（CCE）图像中识别独特息肉具有挑战性，因为图像数量庞大、给临床医生带来认知负担，且特定帧的标注存在模糊性。需要自动化方法来减轻人工负担并提高识别准确性。
- Method: 将问题构建为多示例学习（MIL）任务，提出多示例验证（MIV）框架，结合注意力机制（方差激发多头注意力VEMA和基于距离的注意力DBA），并研究使用SimCLR进行自监督学习生成鲁棒嵌入。
- Result: 在754名患者的1912个息肉数据集上，注意力机制显著提升性能，DBA L1结合ConvNeXt骨干网络和SimCLR预训练获得最高测试准确率86.26%和测试AUC 0.928。
- Conclusion: 多示例学习和自监督学习在结肠胶囊内镜图像自动化分析中具有重要潜力，注意力机制能有效提升模型性能，对更广泛的医学影像应用具有启示意义。


### [39] [Does medical specialization of VLMs enhance discriminative power?: A comprehensive investigation through feature distribution analysis](https://arxiv.org/abs/2601.14774)
*Keita Takeda,Tomoya Sakai*

Main category: cs.CV

TL;DR: 医疗视觉语言模型（VLMs）的特征表示分析：研究发现医疗VLMs能提取有效的诊断特征，但非医疗VLMs通过文本编码器改进（如LLM2CLIP）能产生更精细的特征表示，表明文本编码器增强比密集医疗图像训练更重要。

- Motivation: 医疗VLMs被期望能捕捉诊断相关特征，但其学习到的特征表示尚未充分探索。标准评估（如分类准确率）不能完全揭示它们是否真正获得了具有区分性的病灶特异性特征。理解这些特征表示对于揭示医学图像结构和改进医学图像分析的下游任务至关重要。
- Method: 分析多个代表性医疗VLMs在不同模态的病灶分类数据集上提取的特征分布，并与非医疗VLMs进行比较，评估领域特异性医疗训练的影响。
- Result: 医疗VLMs能提取对医疗分类任务有效的区分性特征。但研究发现，通过上下文丰富化改进的非医疗VLMs（如LLM2CLIP）能产生更精细的特征表示。增强文本编码器比密集训练医疗图像更为关键。非医疗模型特别容易受到图像上叠加文本字符串引入的偏见影响。
- Conclusion: 开发医疗VLMs时，增强文本编码器比密集医疗图像训练更重要。需要根据下游任务仔细选择模型，并注意图像中文本信息等背景偏见带来的潜在推理风险。


### [40] [M2I2HA: A Multi-modal Object Detection Method Based on Intra- and Inter-Modal Hypergraph Attention](https://arxiv.org/abs/2601.14776)
*Xiaofan Yang,Yubin Liu,Wei Pan,Guoqing Chu,Junming Zhang,Jie Zhao,Zhuoqi Man,Xuanming Cao*

Main category: cs.CV

TL;DR: 提出基于超图理论的多模态感知网络M2I2HA，通过超图增强模块和融合模块解决多模态检测中的特征提取和对齐问题，在多个数据集上达到SOTA性能。

- Motivation: 多模态检测虽然提高了准确性，但仍面临模态内任务相关信息提取、跨模态精确对齐等挑战。现有CNN、Transformer和SSM模型各有局限：CNN感受野受限，Transformer计算复杂度高，SSM破坏空间结构。需要新方法来解决这些问题。
- Method: 提出M2I2HA网络，包含：1）模态内超图增强模块，捕获每个模态内的全局多对多高阶关系；2）模态间超图融合模块，通过桥接配置和空间差距来对齐、增强和融合跨模态特征；3）M2-FullPAD模块，实现自适应多级融合并增强数据分布和流动。
- Result: 在多个公共数据集上进行目标检测实验，与基线方法相比，M2I2HA在多模态目标检测任务中实现了最先进的性能。
- Conclusion: 基于超图理论的M2I2HA网络有效解决了多模态检测中的特征提取和对齐问题，通过超图增强和融合模块显著提升了检测性能，在多模态目标检测任务中表现出色。


### [41] [FunCineForge: A Unified Dataset Toolkit and Model for Zero-Shot Movie Dubbing in Diverse Cinematic Scenes](https://arxiv.org/abs/2601.14777)
*Jiaxuan Liu,Yang Xiang,Han Zhao,Xiangang Li,Zhenhua Ling*

Main category: cs.CV

TL;DR: FunCineForge提出端到端配音数据集生产流程和基于MLLM的配音模型，解决现有方法在数据集质量、唇音同步和情感表达方面的局限性，在多种影视场景中超越SOTA方法。

- Motivation: 现有电影配音方法面临两大限制：1）高质量多模态配音数据集规模有限、错误率高、标注稀疏、依赖人工标注且仅限于独白场景；2）现有模型仅依赖唇部区域学习音视频对齐，在复杂实景影视场景中适用性有限，唇音同步、语音质量和情感表达表现不佳。
- Method: 提出FunCineForge，包含端到端大规模配音数据集生产流程和基于MLLM的配音模型。首先构建首个中文电视配音数据集，然后设计适用于多样化影视场景的MLLM配音模型。
- Result: 在独白、旁白、对话和多说话者场景的实验中，FunCineForge在音频质量、唇音同步、音色转换和指令跟随方面持续超越SOTA方法。构建的数据集质量得到验证。
- Conclusion: FunCineForge通过创新的数据集生产流程和MLLM模型架构，有效解决了现有配音方法的局限性，在多样化影视场景中实现了高质量的配音效果。


### [42] [Reconstruction-Anchored Diffusion Model for Text-to-Motion Generation](https://arxiv.org/abs/2601.14788)
*Yifei Liu,Changxing Ding,Ling Guo,Huaiguang Jiang,Qiong Cao*

Main category: cs.CV

TL;DR: RAM提出了一种重建锚定的扩散模型，通过运动潜空间监督和重建误差指导来解决文本驱动运动生成中的表示差距和误差传播问题。

- Motivation: 当前运动扩散模型面临两个主要限制：1) 预训练文本编码器缺乏运动特定信息导致的表示差距；2) 迭代去噪过程中的误差传播问题。
- Method: 1) 使用运动潜空间作为中间监督，通过自正则化和运动中心潜空间对齐来增强运动空间判别性；2) 提出重建误差指导(REG)，利用扩散模型的自校正能力，通过放大当前预测与重建估计之间的残差来减轻误差传播。
- Result: 大量实验表明，RAM实现了显著改进和最先进的性能。
- Conclusion: RAM通过运动潜空间监督和重建误差指导机制，有效解决了文本驱动运动生成中的表示差距和误差传播问题，取得了优异性能。


### [43] [Synthetic Data Augmentation for Multi-Task Chinese Porcelain Classification: A Stable Diffusion Approach](https://arxiv.org/abs/2601.14791)
*Ziyao Ling,Silvia Mirri,Paola Salomoni,Giovanni Delnevo*

Main category: cs.CV

TL;DR: 使用Stable Diffusion与LoRA生成的合成图像来增强中国瓷器分类的有限真实数据集，通过多任务CNN模型验证合成数据在不同分类任务中的效果。

- Motivation: 考古文物分类中训练数据稀缺是深度学习应用的主要挑战，特别是对于稀有的中国瓷器类型。需要探索合成图像是否能有效增强有限真实数据集。
- Method: 使用Stable Diffusion与LoRA生成合成图像，采用MobileNetV3进行迁移学习，对比纯真实数据与混合真实-合成数据集（95:5和90:10比例）在四个分类任务上的表现：朝代、釉色、窑口和类型识别。
- Result: 结果显示任务特定的效果：类型分类改进最显著（90:10比例下F1-macro提高5.5%），朝代和窑口任务有适度提升（3-4%），表明合成增强效果取决于生成特征与任务相关视觉特征的匹配程度。
- Conclusion: 研究为考古研究中部署生成式AI提供了实用指南，展示了在平衡考古真实性与数据多样性时，合成数据的潜力和局限性。


### [44] [UniRoute: Unified Routing Mixture-of-Experts for Modality-Adaptive Remote Sensing Change Detection](https://arxiv.org/abs/2601.14797)
*Qingling Shu,Sibao Chen,Wei Lu,Zhihui You,Chengzhuang Liu*

Main category: cs.CV

TL;DR: UniRoute是一个统一的遥感变化检测框架，通过条件路由实现模态自适应学习，解决了传统专用模型在跨模态和几何未对齐场景下的局限性。

- Motivation: 当前遥感变化检测方法主要依赖专用模型，限制了模态自适应的扩展性。同质变化检测需要精细空间线索，而异质变化检测需要更广泛的上下文信息来抑制噪声和几何失真。传统差异算子在同质图像中有效，但在跨模态或几何未对齐场景中会产生伪影。
- Method: 提出UniRoute统一框架，将特征提取和融合重新定义为条件路由问题。包括：1) AR2-MoE模块解耦局部空间细节和全局语义上下文；2) MDR-MoE模块自适应选择每个像素的最佳融合原语；3) CASD策略通过强制多级一致性来稳定数据稀缺异质设置下的统一训练。
- Result: 在五个公共数据集上的广泛实验表明，UniRoute在统一部署设置下实现了强大的整体性能，具有良好的精度-效率权衡。
- Conclusion: UniRoute通过条件路由机制实现了模态自适应的变化检测，解决了传统专用模型的局限性，为遥感变化检测提供了一个统一且高效的解决方案。


### [45] [UBATrack: Spatio-Temporal State Space Model for General Multi-Modal Tracking](https://arxiv.org/abs/2601.14799)
*Qihua Liang,Liang Chen,Yaozong Zheng,Jian Nong,Zhiyi Mo,Bineng Zhong*

Main category: cs.CV

TL;DR: UBATrack是一个基于Mamba状态空间模型的多模态目标跟踪框架，通过时空Mamba适配器和动态多模态特征混合器，有效捕捉时空线索并增强多模态表示能力，在多个RGB-T、RGB-D和RGB-E跟踪基准上达到SOTA性能。

- Motivation: 当前通用多模态跟踪器虽然通过提示学习统一了多种模态跟踪任务，但忽视了时空线索的有效捕捉。需要一种能同时建模跨模态依赖和时空视觉线索的高效方法。
- Method: 提出UBATrack框架，包含两个核心模块：1) 时空Mamba适配器(STMA)，利用Mamba的长序列建模能力以适配器调优方式联合建模跨模态依赖和时空视觉线索；2) 动态多模态特征混合器，在多个特征维度增强多模态表示能力以提高跟踪鲁棒性。
- Result: 在RGB-T、RGB-D和RGB-E跟踪基准上超越现有方法，在LasHeR、RGBT234、RGBT210、DepthTrack、VOT-RGBD22和VisEvent数据集上取得优异结果。
- Conclusion: UBATrack通过Mamba状态空间模型有效捕捉时空线索，无需昂贵的全参数微调，提高了多模态跟踪算法的训练效率，在多个多模态跟踪任务中表现出色。


### [46] [LocBAM: Advancing 3D Patch-Based Image Segmentation by Integrating Location Contex](https://arxiv.org/abs/2601.14802)
*Donnate Hooft,Stefan M. Fischer,Cosmin Bercea,Jan C. Peeken,Julia A. Schnabel*

Main category: cs.CV

TL;DR: 提出LocBAM注意力机制，在基于patch的3D医学图像分割中显式处理空间位置信息，提升分割性能

- Motivation: 基于patch的3D医学图像分割方法通常忽略patch在全局体积中的位置信息，这限制了分割性能，特别是在解剖学上下文重要的情况下
- Method: 提出LocBAM注意力机制，显式处理空间位置信息，将位置上下文整合到patch-based分割中
- Result: 在BTCV、AMOS22和KiTS23数据集上，LocBAM稳定了训练并提高了分割性能，特别是在低patch-to-volume覆盖率下表现更好，且优于传统的CoordConv坐标编码
- Conclusion: 位置上下文在patch-based 3D分割中至关重要，LocBAM机制能有效利用空间信息提升分割性能


### [47] [Symmetry Informative and Agnostic Feature Disentanglement for 3D Shapes](https://arxiv.org/abs/2601.14804)
*Tobias Weißberg,Weikang Wang,Paul Roetzer,Nafie El Amrani,Florian Bernard*

Main category: cs.CV

TL;DR: 提出一种同时具备对称性感知和对称性无关的特征解耦方法，通过特征精炼技术提升对称性特征鲁棒性，在多种形状分析任务中优于现有方法

- Motivation: 现有方法虽然能从语义感知描述符中提取对称性特征，但特征维度单一（仅一维），忽略了其他有价值的语义信息，且提取的对称性特征通常噪声大、存在小范围误分类
- Method: 提出特征解耦方法，同时提取对称性感知特征和对称性无关特征；进一步提出特征精炼技术，提升预测对称性特征的鲁棒性
- Result: 在内在对称性检测、左/右分类和形状匹配等任务中，相比多种最先进方法，在定性和定量评估上都表现出更好的效果
- Conclusion: 提出的框架能有效解决现有对称性特征提取方法的局限性，为形状分析任务提供更鲁棒和全面的特征表示


### [48] [POTR: Post-Training 3DGS Compression](https://arxiv.org/abs/2601.14821)
*Bert Ramlot,Martijn Courteaux,Peter Lambert,Glenn Van Wallendael*

Main category: cs.CV

TL;DR: POTR是一种后训练3DGS压缩编解码器，通过新型剪枝技术和光照系数重计算方法，显著减少存储需求并加速推理，无需训练即可超越现有后训练压缩方法。

- Motivation: 3D高斯泼溅（3DGS）在3D场景重建和实时新视角合成方面表现出色，但相比NeRF有更高的存储需求。需要开发有效的压缩方法来减少3DGS的存储占用，同时保持其速度和性能优势。
- Method: 提出POTR后训练压缩框架：1）使用改进的3DGS光栅化器同时计算每个splat的移除效果，实现高效剪枝；2）提出光照系数重计算方法，显著降低熵值而不需要训练；3）扩展简单微调方案进一步提升性能。
- Result: POTR相比其他后训练剪枝技术减少2-4倍splat数量，推理速度提升1.5-2倍；AC光照系数稀疏度从70%提升至97%；在率失真性能和推理速度上均优于所有其他后训练压缩技术。
- Conclusion: POTR是一种高效的后训练3DGS压缩解决方案，通过创新的剪枝和光照系数优化技术，在保持质量的同时显著减少存储需求并加速推理，无需训练即可实现优越的压缩性能。


### [49] [Multimodal system for skin cancer detection](https://arxiv.org/abs/2601.14822)
*Volodymyr Sydorskyi,Igor Krashenyi,Oleksii Yakubenko*

Main category: cs.CV

TL;DR: 提出一个使用常规照片图像的多模态黑色素瘤检测系统，结合图像和元数据，通过多阶段管道提高检测准确性

- Motivation: 现有基于皮肤镜图像的深度学习模型需要专业设备，限制了在更广泛临床环境中的应用。需要开发更易获取、设备独立的解决方案
- Method: 多模态神经网络结合图像和元数据处理；支持有无元数据的双模型；三阶段管道通过提升算法优化预测；针对不平衡数据集采用特定技术
- Result: 达到峰值部分ROC AUC 0.18068（最大0.2），top-15检索灵敏度0.78371。结果显示结合照片图像和元数据能显著提升性能
- Conclusion: 该系统通过提供可扩展、设备独立的解决方案，推进了黑色素瘤检测，适用于多样化的医疗环境，弥合了专业和一般临床实践之间的差距


### [50] [MTFlow: Time-Conditioned Flow Matching for Microtubule Segmentation in Noisy Microscopy Images](https://arxiv.org/abs/2601.14841)
*Sidi Mohamed Sid El Moctar,Achraf Ait Laydi,Yousef El Mourabit,Hélène Bouvrais*

Main category: cs.CV

TL;DR: MTFlow是一种基于时间条件流匹配的微管分割模型，通过迭代学习向量场将噪声掩码逐步优化到真实标注，在微管等细长结构分割中表现优异。

- Motivation: 微管是细胞骨架的重要组成部分，在许多细胞过程中起关键作用，也是多种疾病的重要治疗靶点。然而，由于微管具有弯曲、密集交叉和图像噪声等特点，准确分割微管网络仍然具有挑战性。现有方法难以处理这些复杂特征，需要更精确、高效的分割工具。
- Method: 提出MTFlow模型，这是一种时间条件流匹配模型。与传统的U-Net变体单次预测掩码不同，MTFlow学习向量场，通过迭代方式将噪声掩码逐步传输到真实标注。模型架构结合U-Net主干网络和时间嵌入，能够捕捉沿细长结构边界的不确定性解析动态。模型在合成和真实微管数据集上训练，并在视网膜血管和神经等公开生物医学数据集上评估泛化能力。
- Result: MTFlow在微管分割任务上取得了与最先进模型相当的竞争性分割精度。该模型提供了比手动或半自动方法更精确的标注，是分析细长结构的强大且时间高效的工具。模型在泛化到其他细长结构数据集（如视网膜血管和神经）时也表现出良好的性能。
- Conclusion: MTFlow通过流匹配方法为微管分割提供了一种新颖的解决方案，实现了可解释的、基于轨迹的细化过程。该方法不仅提高了分割精度，还为细长结构的分析提供了更高效的工具，具有在生物医学图像分析中广泛应用的潜力。


### [51] [GAT-NeRF: Geometry-Aware-Transformer Enhanced Neural Radiance Fields for High-Fidelity 4D Facial Avatars](https://arxiv.org/abs/2601.14875)
*Zhe Chang,Haodong Jin,Ying Sun,Yan Song,Hui Yu*

Main category: cs.CV

TL;DR: 提出GAT-NeRF框架，通过结合Transformer机制增强NeRF，实现从单目视频重建高保真4D动态面部头像，特别提升对皱纹等高频细节的捕捉能力。

- Motivation: 沉浸式虚拟人应用对高保真4D动态面部头像重建需求增加，但现有NeRF方法在从信息受限的单目视频流中捕捉高频面部细节（如动态皱纹和细微纹理）方面能力有限。
- Method: 提出GAT-NeRF混合神经辐射场框架，将Transformer机制集成到NeRF流程中。结合坐标对齐的MLP和轻量级Transformer模块（GAT），融合3D空间坐标、3DMM表情参数和可学习潜在码等多模态输入特征，增强细粒度几何特征表示。
- Result: 综合实验明确证明GAT-NeRF在视觉保真度和高频细节恢复方面达到最先进性能，为多媒体应用创建逼真动态数字人开辟新途径。
- Conclusion: GAT-NeRF通过Transformer增强的NeRF框架，成功解决了从单目视频重建高保真4D动态面部头像的挑战，特别在捕捉高频面部细节方面表现优异，推动了逼真数字人技术的发展。


### [52] [SpatialMem: Unified 3D Memory with Metric Anchoring and Fast Retrieval](https://arxiv.org/abs/2601.14895)
*Xinyi Zheng,Yunze Liu,Chi-Hao Wu,Fan Zhang,Hao Zheng,Wenqi Zhou,Walterio W. Mayol-Cuevas,Junxiao Shen*

Main category: cs.CV

TL;DR: SpatialMem是一个内存中心系统，将3D几何、语义和语言统一为单一可查询表示，从RGB视频重建室内环境，支持语言引导导航和物体检索。

- Motivation: 需要一种能够统一3D几何、语义和语言信息的系统，支持对空间关系进行可解释推理，并实现语言引导导航和物体检索等下游任务，而无需专用传感器。
- Method: 从RGB视频重建度量缩放的室内环境，检测结构3D锚点（墙、门、窗）作为第一层支架，构建分层记忆，将证据补丁、视觉嵌入和两层文本描述链接到3D坐标。
- Result: 在三个真实室内场景实验中，SpatialMem在增加杂乱和遮挡情况下保持强大的锚点描述级导航完成度和分层检索准确性。
- Conclusion: SpatialMem为具身空间智能提供了一个高效且可扩展的框架，能够统一3D几何、语义和语言表示，支持空间关系推理和下游任务。


### [53] [Erosion Attack for Adversarial Training to Enhance Semantic Segmentation Robustness](https://arxiv.org/abs/2601.14950)
*Yufei Song,Ziqi Zhou,Menghao Deng,Yifan Hu,Shengshan Hu,Minghui Li,Leo Yu Zhang*

Main category: cs.CV

TL;DR: 提出EroSeg-AT对抗训练框架，通过EroSeg生成对抗样本，利用像素级置信度选择敏感像素并传播扰动，破坏样本语义一致性，提升分割模型鲁棒性。

- Motivation: 现有分割模型对对抗攻击高度脆弱，现有对抗训练方法仅考虑全局语义信息而忽略样本内部上下文语义关系，限制了对抗训练效果。
- Method: 提出EroSeg-AT框架，包含EroSeg方法：1)基于像素级置信度选择敏感像素；2)渐进式向高置信度像素传播扰动；3)有效破坏样本语义一致性。
- Result: 实验结果表明，相比现有方法，该方法显著提升攻击效果，并在对抗训练下增强模型鲁棒性。
- Conclusion: EroSeg-AT通过考虑上下文语义关系生成对抗样本，有效提升分割模型的对抗鲁棒性，为对抗训练提供了新思路。


### [54] [TempViz: On the Evaluation of Temporal Knowledge in Text-to-Image Models](https://arxiv.org/abs/2601.14951)
*Carolin Holtermann,Nina Krebs,Anne Lauscher*

Main category: cs.CV

TL;DR: TempViz是首个全面评估文本到图像生成模型中时间知识的数据集，包含7.9k个提示和600+参考图像，研究发现当前T2I模型的时间理解能力普遍较弱，且缺乏可靠的自动评估方法。

- Motivation: 时间会改变物体、地点和动物的视觉外观，对于生成上下文相关的图像至关重要。尽管自然语言处理领域已有大量关于时间理解的研究，但文本到图像模型中时间现象的处理研究仍然匮乏。
- Method: 创建TempViz数据集（7.9k个提示和600+参考图像），用于评估五个T2I模型在五个时间知识类别上的表现。通过人工评估和多种自动评估方法进行比较分析。
- Result: 人工评估显示所有模型的时间能力普遍较弱，没有模型在各类别中超过75%准确率。现有自动评估方法都无法可靠评估时间线索，与人工判断相关性差。
- Conclusion: 文本到图像模型的时间知识理解存在显著不足，需要进一步研究。TempViz数据集为未来研究提供了基准，同时需要开发更可靠的自动评估方法。


### [55] [Towards Holistic Modeling for Video Frame Interpolation with Auto-regressive Diffusion Transformers](https://arxiv.org/abs/2601.14959)
*Xinyu Peng,Han Li,Yuyang Huang,Ziyang Zheng,Yaoming Wang,Xin Chen,Wenrui Dai,Chenglin Li,Junni Zou,Hongkai Xiong*

Main category: cs.CV

TL;DR: LDF-VFI提出了一种视频中心化的帧插值方法，使用自回归扩散变换器建模整个视频序列，通过局部扩散强制确保长时间一致性，支持任意空间分辨率处理。

- Motivation: 现有视频帧插值方法通常采用帧中心化方法，将视频作为独立短片段处理，导致时间不一致和运动伪影。需要一种能够确保长时间一致性的整体视频中心化方法。
- Method: 基于自回归扩散变换器建模整个视频序列，引入跳跃连接采样策略减少误差累积，结合稀疏局部注意力和分块VAE编码实现长序列高效处理，使用增强的条件VAE解码器提升重建质量。
- Result: 在具有挑战性的长序列基准测试中达到最先进性能，表现出优越的单帧质量和时间一致性，特别是在大运动场景中，且能泛化到任意空间分辨率。
- Conclusion: LDF-VFI通过视频中心化方法和局部扩散强制，解决了现有帧插值方法的时间不一致问题，实现了长时间一致的高质量视频插值。


### [56] [Unified Multi-Dataset Training for TBPS](https://arxiv.org/abs/2601.14978)
*Nilanjana Chatterjee,Sidharatha Garg,A V Subramanyam,Brejesh Lall*

Main category: cs.CV

TL;DR: 提出Scale-TBPS方法，通过噪声感知的统一数据集构建策略和可扩展的身份学习框架，训练单一模型在多个TBPS数据集上超越数据集专用模型。

- Motivation: 现有基于文本的行人搜索方法面临训练数据有限、视觉语言模型非行人专用、需要为不同数据集单独微调的问题，需要探索能否训练单一统一模型跨多个数据集工作。
- Method: 提出Scale-TBPS方法：1）噪声感知的统一数据集构建策略，整合多个TBPS数据集；2）可扩展的判别性身份学习框架，有效处理大量独特身份。
- Result: 在CUHK-PEDES、ICFG-PEDES、RSTPReid、IIITD-20K和UFine6926五个数据集上，单一Scale-TBPS模型超越了数据集专用优化模型和简单联合训练方法。
- Conclusion: Scale-TBPS成功实现了跨多个数据集的统一文本行人搜索模型，解决了现有方法需要为不同数据集单独训练的局限性，为TBPS领域提供了更通用的解决方案。


### [57] [LiViBench: An Omnimodal Benchmark for Interactive Livestream Video Understanding](https://arxiv.org/abs/2601.15016)
*Xiaodong Wang,Langling Huang,Zhirong Wu,Xu Zhao,Teng Xu,Xuhong Xia,Peixi Peng*

Main category: cs.CV

TL;DR: 提出首个交互式直播视频全模态基准LiViBench，包含24个任务，并开发LiVi-LLM-7B模型，在交互视频理解上超越更大规模开源模型

- Motivation: 现有视频评估基准主要关注非交互式视频（如电影、录像），缺乏针对交互式直播视频的评估标准。交互式直播视频具有实时评论、音频、语音等多模态特征，需要专门的基准来评估模型理解能力。
- Method: 1. 设计LiViBench基准：包含24个任务，涵盖感知、推理和直播特定挑战；2. 开发半自动标注流程：结合人在回路的多阶段标注，利用多MLLM代理系统进行视频描述，采用种子问题驱动方法构建高质量标注；3. 提出两阶段指令调优和视频到评论检索模块；4. 开发LiVi-LLM-7B模型。
- Result: LiVi-LLM-7B在LiViBench上优于参数量达720亿的开源模型，缩小了与领先专有模型的差距，同时在通用视频基准（VideoMME、LongVideoBench、MLVU、VideoEval-Pro）上表现也得到提升。
- Conclusion: LiViBench填补了交互式直播视频评估的空白，提出的LiVi-LLM-7B模型在交互视频理解方面表现出色，为多模态大语言模型在实时交互视频领域的应用提供了重要基准和解决方案。


### [58] [SpatialV2A: Visual-Guided High-fidelity Spatial Audio Generation](https://arxiv.org/abs/2601.15017)
*Yanan Wang,Linjie Ren,Zihao Li,Junyi Wang,Tian Gan*

Main category: cs.CV

TL;DR: 论文提出首个大规模视频-双耳音频数据集BinauralVGGSound和端到端空间音频生成框架，解决现有视频到音频生成模型缺乏空间感知和沉浸感的问题。

- Motivation: 现有视频到音频生成研究主要关注语义和时间对齐，但忽视了音频的空间感知和沉浸质量。这主要是因为当前模型依赖单声道音频数据集，缺乏双耳空间信息来学习视觉到空间音频的映射。
- Method: 1) 构建首个大规模视频-双耳音频数据集BinauralVGGSound；2) 提出端到端的视觉引导空间音频生成框架，包含视觉引导音频空间化模块，显式建模空间特征，确保生成的音频具有真实空间属性和分层空间深度。
- Result: 实验表明，该方法在空间保真度方面显著优于现有最先进模型，提供更沉浸的听觉体验，同时不牺牲时间或语义一致性。
- Conclusion: 通过构建首个大规模双耳音频数据集和提出视觉引导的空间音频生成框架，成功解决了视频到音频生成中空间感知不足的问题，显著提升了音频的沉浸感和空间保真度。


### [59] [Federated Transformer-GNN for Privacy-Preserving Brain Tumor Localization with Modality-Level Explainability](https://arxiv.org/abs/2601.15042)
*Andrea Protani,Riccardo Taiello,Marc Molina Van Den Bosch,Luigi Serio*

Main category: cs.CV

TL;DR: 提出用于脑肿瘤定位的联邦学习框架，在保护隐私的同时实现多机构协作，性能匹配集中式训练，并通过注意力机制提供可解释性分析。

- Motivation: 脑肿瘤分析需要大量多样化数据，但医疗数据因隐私法规分散在不同机构，难以共享。需要一种能在保护隐私的前提下实现多机构协作的方法。
- Method: 基于CAFEIN联邦学习平台，采用混合Transformer-图神经网络架构，扩展自先前的无解码器超体素GNN。通过Transformer注意力机制进行可解释性分析。
- Result: 在BraTS数据集上，联邦学习能持续改进模型性能，匹配集中式训练效果。孤立训练会过早停止，而联邦学习能充分利用分布式数据。可解释性分析显示深层网络更关注T2和FLAIR模态，符合临床实践。
- Conclusion: 联邦学习在处理复杂任务和高维输入数据时具有显著优势，能通过聚合多机构知识显著改善学习过程。注意力机制分析为模型决策提供了临床可解释性。


### [60] [Deep Leakage with Generative Flow Matching Denoiser](https://arxiv.org/abs/2601.15049)
*Isaac Baglin,Xiatian Zhu,Simon Hadfield*

Main category: cs.CV

TL;DR: 提出一种新的联邦学习深度泄漏攻击方法，通过集成流匹配生成先验来提升重建保真度，在各种设置下优于现有攻击方法。

- Motivation: 联邦学习虽然能保护数据隐私，但仍面临深度泄漏攻击的威胁。现有攻击方法存在稳定性差、保真度低或鲁棒性不足的问题，特别是在实际联邦学习设置下表现不佳。
- Method: 将生成式流匹配先验集成到重建过程中，利用流匹配基础模型引导优化朝向真实图像分布，无需访问私有数据即可提升重建质量。
- Result: 在多个数据集和目标模型上的实验表明，该方法在像素级、感知和特征相似度指标上均优于现有最优攻击方法，且在不同训练轮次、更大客户端批次大小以及常见防御机制下保持有效。
- Conclusion: 该方法展示了生成先验在提升深度泄漏攻击效果方面的强大能力，呼吁开发新的防御策略来应对配备强大生成先验的对手。


### [61] [Differential Privacy Image Generation with Reconstruction Loss and Noise Injection Using an Error Feedback SGD](https://arxiv.org/abs/2601.15061)
*Qiwei Ma,Jun Zhang*

Main category: cs.CV

TL;DR: 提出基于误差反馈随机梯度下降(EFSGD)的差分隐私生成框架，在相同隐私预算下生成更高质量和可用性的图像，在MNIST、Fashion-MNIST和CelebA数据集上达到SOTA

- Motivation: 传统数据掩码技术（如匿名化）无法在隐私保护机器学习中同时实现预期的隐私保护和数据效用。合成数据在生成大量训练样本和防止真实数据信息泄露方面日益重要，但现有方法在隐私和效用之间存在反复权衡的问题。
- Method: 提出新颖的差分隐私生成框架，采用误差反馈随机梯度下降(EFSGD)方法，在训练过程中引入重构损失和噪声注入机制。
- Result: 在相同隐私预算下生成更高质量和可用性的图像。在三个基准测试（MNIST、Fashion-MNIST和CelebA）上，几乎所有指标都达到了最先进的结果。
- Conclusion: 提出的框架在灰度和RGB图像上都表现出有效性和泛化能力，解决了隐私保护机器学习中隐私与效用的权衡问题。


### [62] [Enhancing Few-Shot Out-of-Distribution Detection via the Refinement of Foreground and Background](https://arxiv.org/abs/2601.15065)
*Tianyu Li,Songyue Cai,Zongqian Wu,Ping Hu,Xiaofeng Zhu*

Main category: cs.CV

TL;DR: 提出FoBoR框架，通过自适应背景抑制和可混淆前景矫正来改进CLIP-based前景-背景分解方法，提升少样本OOD检测性能

- Motivation: 现有CLIP-based前景-背景分解方法存在两个主要问题：1）对背景区域采用统一的抑制策略，忽略了不同patch对预测的贡献差异；2）对前景区域未充分考虑某些局部patch可能与其他类别相似，可能误导训练过程
- Method: 提出可插拔框架FoBoR，包含三个核心组件：1）前景-背景分解模块；2）自适应背景抑制模块，自适应加权patch分类熵；3）可混淆前景矫正模块，识别并矫正可混淆前景patch
- Result: 大量实验结果表明，该可插拔框架显著提升了现有前景-背景分解方法的性能
- Conclusion: FoBoR框架通过自适应背景抑制和可混淆前景矫正，有效解决了现有CLIP-based前景-背景分解方法的局限性，提升了少样本OOD检测性能


### [63] [The Pictorial Cortex: Zero-Shot Cross-Subject fMRI-to-Image Reconstruction via Compositional Latent Modeling](https://arxiv.org/abs/2601.15071)
*Jingyang Huo,Yikai Wang,Yanwei Fu,Jianfeng Feng*

Main category: cs.CV

TL;DR: 提出PictorialCortex方法，通过组合潜在建模解决零样本跨被试fMRI到图像重建问题，使用多数据集训练提升性能

- Motivation: 解决视觉体验从大脑活动解码中的核心挑战：由于解剖、功能、认知和实验因素导致的皮层反应变异性，使得fMRI到图像重建成为非单射问题。特别关注零样本跨被试重建这一实际有意义的问题。
- Method: 1) 构建统一皮层表面数据集UniCortex-fMRI；2) 提出PictorialCortex方法，使用组合潜在公式建模fMRI活动，结构化刺激驱动表示；3) 采用潜在因子分解-组合模块，配合因子分解和重因子化一致性正则化；4) 推理时聚合多个已见被试条件下的代理潜在变量，指导基于扩散的图像合成。
- Result: 广泛实验表明PictorialCortex改进了零样本跨被试视觉重建，突出了组合潜在建模和多数据集训练的优势。
- Conclusion: 通过组合潜在建模方法，成功解决了零样本跨被试fMRI到图像重建问题，为神经科学、神经影像和人工智能交叉领域提供了有效解决方案。


### [64] [Three-dimensional visualization of X-ray micro-CT with large-scale datasets: Efficiency and accuracy for real-time interaction](https://arxiv.org/abs/2601.15098)
*Yipeng Yin,Rao Yao,Qingying Li,Dazhong Wang,Hong Zhou,Zhijun Fang,Jianing Chen,Longjie Qian,Mingyue Wu*

Main category: cs.CV

TL;DR: 该论文综述了Micro-CT技术在工业无损检测中的3D可视化方法，重点分析了如何在准确性和效率之间取得平衡，涵盖了从传统重建算法到深度学习技术，以及体积渲染优化方法的发展。

- Motivation: 随着Micro-CT技术产生越来越大的数据集，工业CT超精密检测需要在缺陷3D表征的准确性和效率之间取得平衡。现有方法在这两个维度上存在权衡，需要系统性的综述来帮助研究人员快速掌握高效准确的微观特征3D重建方法。
- Method: 通过选择性综述和分析的方法，比较计算机断层扫描原理与微结构技术的进展，考察CT重建算法从解析方法到深度学习技术的演变，以及体积渲染算法、加速和数据缩减的改进。同时探讨高精度、逼真且高效的体积渲染的先进光照模型。
- Result: 提供了Micro-CT在工业无损检测中准确高效3D可视化方法的全面分析，系统梳理了CT重建算法和体积渲染技术的发展脉络，识别了现有方法的优缺点和适用场景。
- Conclusion: 论文展望了CT重建和体积渲染的未来方向，旨在指导研究人员快速选择高效精确的方法，并为通过虚拟-物理交互实现材料内部缺陷实时在线监测的数字孪生模型在结构健康监测中的应用提供新思路。


### [65] [Pb4U-GNet: Resolution-Adaptive Garment Simulation via Propagation-before-Update Graph Network](https://arxiv.org/abs/2601.15110)
*Aoran Liu,Kun Hu,Clinton Ansun Mo,Qiuxia Wu,Wenxiong Kang,Zhiyong Wang*

Main category: cs.CV

TL;DR: Pb4U-GNet提出了一种分辨率自适应的图神经网络框架，通过在服装模拟中解耦消息传播与特征更新，解决了现有方法跨分辨率泛化能力差的问题。

- Motivation: 传统物理方法计算成本高，现有图神经网络方法在跨分辨率泛化方面表现不佳，特别是在训练分布之外的高分辨率网格上性能显著下降。这源于两个关键因素：固定消息传播深度无法适应网格密度变化，以及顶点位移幅度本质上依赖于分辨率。
- Method: 提出传播-更新分离图网络（Pb4U-GNet），包含两个关键机制：1）动态传播深度控制，根据网格分辨率调整消息传播迭代次数；2）几何感知更新缩放，根据局部网格特征缩放预测结果。
- Result: 实验表明，即使仅使用低分辨率网格训练，Pb4U-GNet在不同网格分辨率上表现出强大的泛化能力，解决了神经服装模拟中的一个基本挑战。
- Conclusion: Pb4U-GNet通过分辨率自适应框架有效解决了服装模拟中图神经网络的跨分辨率泛化问题，为虚拟试穿和数字人体建模等应用提供了更实用的解决方案。


### [66] [Training-Free and Interpretable Hateful Video Detection via Multi-stage Adversarial Reasoning](https://arxiv.org/abs/2601.15115)
*Shuonan Yang,Yuchen Zhang,Zeyu Fu*

Main category: cs.CV

TL;DR: MARS是一个无需训练的多阶段对抗推理框架，用于可靠且可解释的仇恨视频检测，通过客观描述、证据推理和反证据推理来做出可解释的决策。

- Motivation: 仇恨视频会加剧歧视、煽动暴力和破坏在线安全。现有基于训练的方法受限于有限数据和缺乏可解释性，而直接提示大型视觉语言模型在仇恨检测上往往不可靠。
- Method: MARS采用多阶段对抗推理框架：1) 视频内容的客观描述；2) 支持仇恨解释的证据推理；3) 捕捉非仇恨视角的反证据推理；4) 综合这些视角做出可解释的决策。
- Result: 在两个真实数据集上的评估显示，MARS在某些骨干网络和设置下比其他无需训练方法提升高达10%，并在一个数据集上优于最先进的基于训练的方法。
- Conclusion: MARS提供了可靠且可解释的仇恨内容检测，生成人类可理解的解释，支持合规监督并增强内容审核工作流程的透明度。


### [67] [BREPS: Bounding-Box Robustness Evaluation of Promptable Segmentation](https://arxiv.org/abs/2601.15123)
*Andrey Moskalenko,Danil Kuznetsov,Irina Dudko,Anastasiia Iasakova,Nikita Boldyrev,Denis Shepelev,Andrei Spiridonov,Andrey Kuznetsov,Vlad Shakhuro*

Main category: cs.CV

TL;DR: 论文研究了可提示分割模型对边界框提示的鲁棒性，发现SAM类模型对自然提示噪声高度敏感，并提出了BREPS方法来生成对抗性边界框进行鲁棒性评估。

- Motivation: 当前可提示分割模型（如SAM）的训练和评估通常使用简单的启发式方法生成合成提示，无法反映真实世界的鲁棒性。边界框作为最有效的提示方式之一，其自然变化对分割质量的影响尚未得到充分研究。
- Method: 首先进行用户研究收集真实边界框标注，分析分割质量的变化性。然后将鲁棒性评估重新表述为边界框提示空间上的白盒优化问题，提出BREPS方法生成符合自然性约束的对抗性边界框，最小化或最大化分割误差。
- Result: 用户研究显示相同模型和实例在不同用户标注下分割质量存在显著差异，表明SAM类模型对自然提示噪声高度敏感。BREPS方法在10个数据集（包括日常场景和医学影像）上对最先进模型进行了基准测试。
- Conclusion: 可提示分割模型对边界框提示的自然变化缺乏鲁棒性，需要更严格的评估方法。BREPS提供了一种系统评估模型鲁棒性的框架，有助于未来开发更稳健的提示分割模型。


### [68] [Graph Recognition via Subgraph Prediction](https://arxiv.org/abs/2601.15133)
*André Eberhard,Gerhard Neumann,Pascal Friederich*

Main category: cs.CV

TL;DR: 提出GraSP方法，通过子图预测进行视觉图识别，旨在创建统一框架处理多样化的图识别任务

- Motivation: 视觉关系识别（通常建模为从图像中提取图）仍然具有挑战性，主要原因是缺乏规范的方法。现有解决方案通常是特定于问题的，无法在不同上下文之间直接迁移，尽管概念问题是相同的。
- Method: 开发了GraSP（Graph Recognition via Subgraph Prediction）方法，通过子图预测来识别图像中的图。该方法设计具有广泛适用性和简单性。
- Result: 在多个合成基准测试和一个实际应用中展示，该方法适用于多种类型的图及其绘制方式，可以在不同任务之间迁移而无需任务特定修改。
- Conclusion: GraSP为更统一的视觉图识别框架铺平了道路，能够处理多样化的图类型并实现任务间的可迁移性。


### [69] [Large-Scale Multidimensional Knowledge Profiling of Scientific Literature](https://arxiv.org/abs/2601.15170)
*Zhucun Xue,Jiangning Zhang,Juntao Jiang,Jinzhuo Liu,Haoyang He,Teng Hu,Xiaobin Hu,Guangming Yao,Yi Yuan,Yong Liu*

Main category: cs.CV

TL;DR: 该论文构建了一个包含10万+论文的多维分析管道，结合主题聚类、LLM辅助解析和结构化检索，揭示了AI研究主题演变、方法转换、数据集使用模式等趋势。

- Motivation: 机器学习、视觉和语言领域研究快速扩张，传统文献计量工具主要依赖元数据，难以深入分析论文语义内容，难以追踪研究主题随时间演变以及不同领域间的相互影响。
- Method: 收集2020-2025年间22个主要会议的10万+论文构建统一语料库，开发多维分析管道，结合主题聚类、LLM辅助解析和结构化检索技术，系统分析文本内容。
- Result: 分析揭示了多个显著趋势：安全研究、多模态推理和智能体导向研究的增长，以及神经机器翻译和图方法等领域的逐渐稳定化，提供了AI研究演变的证据基础视图。
- Conclusion: 该研究为理解AI研究更广泛趋势和识别新兴方向提供了资源，展示了基于证据的研究演变分析框架，有助于学术界更好地把握领域发展脉络。


### [70] [BBoxMaskPose v2: Expanding Mutual Conditioning to 3D](https://arxiv.org/abs/2601.15200)
*Miroslav Purkrabek,Constantin Kolomiiets,Jiri Matas*

Main category: cs.CV

TL;DR: PMPose是一个结合概率公式和掩码条件的2D姿态估计器，在拥挤场景中表现优异。BMPv2整合PMPose和改进的SAM掩码细化模块，在COCO和OCHuman数据集上超越现有方法，首次在OCHuman上超过50 AP。

- Motivation: 当前2D人体姿态估计基准在标准场景已接近饱和，但在拥挤场景中仍有挑战。需要开发能在拥挤场景中提升性能而不牺牲标准场景表现的方法。
- Method: 提出PMPose，采用概率公式和掩码条件。进一步开发BMPv2，整合PMPose和增强的SAM掩码细化模块。还展示了2D提示对3D模型在拥挤场景中的改进。
- Result: BMPv2在COCO上超越SOTA 1.5 AP，在OCHuman上超越6 AP，首次在OCHuman上超过50 AP。证明2D姿态质量提升直接有益于3D估计，多人体姿态性能更多受姿态预测精度而非检测影响。
- Conclusion: PMPose和BMPv2有效解决了拥挤场景中的姿态估计问题，展示了2D姿态质量对3D估计的重要性，为拥挤场景姿态估计提供了新的解决方案。


### [71] [A Computer Vision Hybrid Approach: CNN and Transformer Models for Accurate Alzheimer's Detection from Brain MRI Scans](https://arxiv.org/abs/2601.15202)
*Md Mahmudul Hoque,Shuvo Karmaker,Md. Hadi Al-Amin,Md Modabberul Islam,Jisun Junayed,Farha Ulfat Mahi*

Main category: cs.CV

TL;DR: 该研究比较了CNN、Transformer和混合模型在阿尔茨海默病MRI分类中的表现，提出的Evan_V2混合模型达到99.99%准确率，显著优于所有单一模型。

- Motivation: 阿尔茨海默病的早期准确诊断对临床干预和患者预后至关重要。需要开发可靠的MRI分类工具来区分不同痴呆阶段（轻度、中度、非痴呆、极轻度）。
- Method: 比较了5种CNN架构（EfficientNetB0、ResNet50、DenseNet201、MobileNetV3、VGG16）、5种Transformer模型（ViT、ConvTransformer、PatchTransformer、MLP-Mixer、SimpleTransformer），并提出Evan_V2混合模型，该模型通过特征级融合整合了10个CNN和Transformer架构的输出。
- Result: CNN模型表现稳定，ResNet50达到98.83%准确率；Transformer模型具有良好泛化能力，ViT达到95.38%准确率；Evan_V2混合模型表现最佳，达到99.99%准确率、0.9989 F1分数和0.9968 ROC AUC，显著减少所有痴呆阶段的误分类。
- Conclusion: 混合集成策略在阿尔茨海默病分类中具有显著优势，Evan_V2模型展示了构建高可靠性临床诊断工具的潜力，能够为不同痴呆阶段提供更准确的分类。


### [72] [ScenDi: 3D-to-2D Scene Diffusion Cascades for Urban Generation](https://arxiv.org/abs/2601.15221)
*Hanlei Guo,Jiahao Shao,Xinya Chen,Xiyang Tan,Sheng Miao,Yujun Shen,Yiyi Liao*

Main category: cs.CV

TL;DR: ScenDi：一种结合3D和2D扩散模型的城市场景生成方法，通过3D高斯生成粗粒度场景，再用2D视频扩散增强细节，实现可控的高质量场景生成。

- Motivation: 现有3D扩散模型在生成城市场景时外观细节会退化，而仅用2D扩散模型则难以控制相机轨迹。需要结合两者优势来生成既真实又可控的3D城市场景。
- Method: 首先训练3D潜在扩散模型生成3D高斯，可渲染低分辨率图像并支持多种条件输入（3D边界框、道路图、文本提示）。然后训练2D视频扩散模型，以3D高斯渲染图像为条件增强外观细节，实现相机轨迹的精确控制。
- Result: 在Waymo和KITTI-360两个真实世界数据集上的实验证明了方法的有效性，能够生成符合输入条件且保持准确相机轨迹的高质量城市场景。
- Conclusion: ScenDi通过结合3D和2D扩散模型的优势，成功解决了城市场景生成中细节保持和相机可控性的平衡问题，为可控的3D城市场景生成提供了有效解决方案。


### [73] [PROGRESSLM: Towards Progress Reasoning in Vision-Language Models](https://arxiv.org/abs/2601.15224)
*Jianshu Zhang,Chengxuan Qian,Haosen Sun,Haoran Lu,Dingcheng Wang,Letian Xue,Han Liu*

Main category: cs.CV

TL;DR: 提出Progress-Bench基准测试评估VLM的任务进度推理能力，发现现有模型表现不佳，通过训练方法ProgressLM-3B获得显著改进

- Motivation: 任务进度估计需要长时程动态推理而非静态视觉识别，现有VLM擅长描述可见内容，但能否从部分观察推断任务进度尚不明确
- Method: 引入Progress-Bench基准测试，探索人类启发的两阶段进度推理范式：无训练提示方法和基于ProgressLM-45K数据集的训练方法
- Result: 14个VLM测试显示大多数模型不擅长任务进度估计，对演示模态和视角变化敏感，处理不可回答情况差；无训练提示改进有限且依赖模型，而ProgressLM-3B即使在小规模下也获得一致改进
- Conclusion: 现有VLM在任务进度推理方面仍有不足，训练方法能显著提升性能，分析揭示了特征性错误模式并阐明了进度推理成功或失败的条件


### [74] [Tracing 3D Anatomy in 2D Strokes: A Multi-Stage Projection Driven Approach to Cervical Spine Fracture Identification](https://arxiv.org/abs/2601.15235)
*Fabi Nahian Madhurja,Rusab Sarmun,Muhammad E. H. Chowdhury,Adam Mushtak,Israa Al-Hashimi,Sohaib Bassam Zoghoul*

Main category: cs.CV

TL;DR: 提出基于2D投影的颈椎骨折检测方法，通过优化2D投影近似3D体积，结合YOLOv8定位、DenseNet121-Unet分割和2.5D时空模型集成，实现高效准确的椎骨级骨折检测。

- Motivation: 颈椎骨折是严重医疗状况，需要精确高效的检测方法。传统3D分割方法计算复杂，本研究探索基于2D投影的椎骨分割在3D CT体积中的可行性，以降低计算复杂度同时保持高性能。
- Method: 1) 通过优化的轴向、矢状和冠状2D投影近似3D体积；2) 使用YOLOv8从所有视图识别感兴趣区域并组合近似3D颈椎区域；3) 基于DenseNet121-Unet的多标签分割；4) 从2D分割掩模战略近似3D椎骨掩模；5) 使用包含原始切片和投影的2.5D时空模型集成分析骨折。
- Result: 3D mIoU达到94.45%，Dice分数87.86%。椎骨级和患者级F1分数分别为68.15和82.26，ROC-AUC分数分别为91.62和83.04。通过可解释性研究和观察者间变异性分析验证，与专家放射科医生表现相当。
- Conclusion: 提出的2D投影方法在降低计算复杂度的同时保持高性能，为颈椎骨折检测提供了有效的自动化解决方案。可解释性分析和与专家比较验证了方法的临床实用性。


### [75] [FlowSSC: Universal Generative Monocular Semantic Scene Completion via One-Step Latent Diffusion](https://arxiv.org/abs/2601.15250)
*Zichen Xi,Hao-Xiang Chen,Nan Xue,Hongyu Yan,Qi-Yuan Feng,Levent Burak Kara,Joaquim Jorge,Qun-Ce Xu*

Main category: cs.CV

TL;DR: FlowSSC：首个应用于单目语义场景补全的生成式框架，通过条件生成和捷径流匹配在紧凑三平面潜在空间中实现实时高质量推理，显著提升现有前馈方法性能。

- Motivation: 单目RGB图像的语义场景补全（SSC）具有固有模糊性，现有前馈方法难以生成遮挡区域的合理细节并保持物体空间关系，而准确的3D空间生成推理能力对实际应用至关重要。
- Method: 将SSC视为条件生成问题，提出FlowSSC框架：1）引入捷径流匹配在紧凑三平面潜在空间中操作；2）通过捷径机制实现单步高保真生成；3）可与现有前馈SSC方法无缝集成。
- Result: 在SemanticKITTI数据集上实现最先进性能，显著超越现有基线方法，同时保持实时推理能力，适用于自动驾驶系统实际部署。
- Conclusion: FlowSSC是首个直接应用于单目语义场景补全的生成式框架，通过捷径流匹配在紧凑潜在空间中实现高质量实时生成，为SSC任务提供了有效的生成式解决方案。


### [76] [DrivIng: A Large-Scale Multimodal Driving Dataset with Full Digital Twin Integration](https://arxiv.org/abs/2601.15260)
*Dominik Rößle,Xujun Xie,Adithya Mohan,Venkatesh Thirugnana Sambandham,Daniel Cremers,Torsten Schön*

Main category: cs.CV

TL;DR: DrivIng是一个大规模多模态自动驾驶数据集，包含完整的数字孪生系统，覆盖城市、郊区和高速公路场景，支持系统化测试和仿真到真实环境的评估。

- Motivation: 现有自动驾驶数据集缺乏高保真数字孪生，限制了系统化测试、边缘案例模拟、传感器修改和仿真到真实环境的评估能力。需要大规模高质量数据集来支持鲁棒的感知算法开发。
- Method: 构建了约18公里路线的完整地理参考数字孪生，包含城市、郊区和高速公路段。使用6个RGB摄像头、1个LiDAR和高精度ADMA定位系统，在白天、黄昏和夜间进行连续录制。所有序列以10Hz频率标注3D边界框和12个类别的跟踪ID。
- Result: 创建了包含约120万个标注实例的数据集，实现了真实交通到仿真的1:1转换，保留了智能体交互，支持真实且灵活的场景测试。发布了数据集、数字孪生、高精地图和代码库。
- Conclusion: DrivIng填补了现有自动驾驶数据集的空白，通过完整的数字孪生系统支持可重复研究和鲁棒验证，为感知算法开发提供了系统化测试和评估平台。


### [77] [RayRoPE: Projective Ray Positional Encoding for Multi-view Attention](https://arxiv.org/abs/2601.15275)
*Yu Wu,Minsik Jeon,Jen-Hao Rick Chang,Oncel Tuzel,Shubham Tulsiani*

Main category: cs.CV

TL;DR: RayRoPE是一种用于多视角Transformer的位置编码方法，它使用射线关联的预测3D点进行几何感知编码，实现SE(3)不变性，并能处理深度不确定性。

- Motivation: 现有多视角注意力机制的位置编码方案（绝对或相对）无法同时满足：1）唯一编码图像块；2）实现SE(3)不变性注意力；3）适应底层场景几何。需要一种新的编码机制来解决这些问题。
- Method: RayRoPE基于关联射线表示图像块位置，但使用沿射线的预测点而非方向进行几何感知编码。为实现SE(3)不变性，它计算查询帧的投影坐标用于多频率相似度计算。此外，针对预测3D点可能不精确的问题，RayRoPE提供了一种机制来解析计算不确定性下的期望位置编码。
- Result: 在CO3D数据集的新视角合成任务中，RayRoPE相比其他位置编码方案取得了15%的相对改进（LPIPS指标）。在立体深度估计任务中也表现一致优于替代方案。RayRoPE还能无缝整合RGB-D输入，相比无法位置编码此类信息的替代方案获得更大提升。
- Conclusion: RayRoPE是一种有效的多视角Transformer位置编码方法，能够满足唯一性、SE(3)不变性和几何适应性要求，在多个视觉任务中显著优于现有编码方案，并能有效利用深度信息。


### [78] [StableWorld: Towards Stable and Consistent Long Interactive Video Generation](https://arxiv.org/abs/2601.15281)
*Ying Yang,Zhengyao Lv,Tianlin Pan,Haofan Wang,Binxin Yang,Hubery Yin,Chen Li,Ziwei Liu,Chenyang Si*

Main category: cs.CV

TL;DR: 提出StableWorld方法，通过动态帧驱逐机制解决交互式视频生成中的稳定性和时间一致性问题

- Motivation: 当前交互式视频生成方法存在严重的稳定性和时间退化问题，在长时交互中容易出现空间漂移和场景崩溃，需要解决累积误差问题
- Method: 提出StableWorld方法，采用动态帧驱逐机制，持续过滤退化帧同时保留几何一致的帧，从源头防止累积漂移
- Result: 在多个交互式视频模型（Matrix-Game、Open-Oasis、Hunyuan-GameCraft）上验证，StableWorld能显著提升稳定性、时间一致性和泛化能力
- Conclusion: StableWorld是模型无关的有效方法，可应用于不同交互式视频生成框架，解决稳定性和时间一致性问题


### [79] [Rethinking Video Generation Model for the Embodied World](https://arxiv.org/abs/2601.15282)
*Yufan Deng,Zilin Pan,Hongyu Zhang,Xiaojie Li,Ruoqing Hu,Yufei Ding,Yiming Zou,Yan Zeng,Daquan Zhou*

Main category: cs.CV

TL;DR: 提出了RBench机器人视频生成基准和RoVid-X数据集，用于评估和训练物理真实的机器人视频生成模型

- Motivation: 当前机器人视频生成缺乏标准化评估基准，且高质量训练数据不足，难以生成物理真实的机器人交互视频
- Method: 1) 创建RBench基准，涵盖5个任务领域和4种机器人形态，评估任务正确性和视觉保真度；2) 开发四阶段数据管道，构建RoVid-X数据集，包含400万标注视频片段
- Result: 评估25个代表性模型发现物理真实行为生成存在显著缺陷；RBench与人类评估的Spearman相关系数达0.96；RoVid-X成为最大的开源机器人视频生成数据集
- Conclusion: 评估基准与数据集的协同生态系统为视频模型的严格评估和可扩展训练提供了坚实基础，加速具身AI向通用智能发展


### [80] [LuxRemix: Lighting Decomposition and Remixing for Indoor Scenes](https://arxiv.org/abs/2601.15283)
*Ruofan Liang,Norman Müller,Ethan Weber,Duncan Zauss,Nandita Vijaykumar,Peter Kontschieder,Christian Richardt*

Main category: cs.CV

TL;DR: 提出了一种从单次多视角采集实现室内场景交互式光照编辑的新方法，通过生成式图像光照分解模型将复杂室内光照分解为独立光源，支持实时交互控制

- Motivation: 现有方法难以从单次多视角采集中分解复杂室内光照并进行交互式编辑，需要一种能够独立控制各个光源状态、色度和强度的解决方案
- Method: 使用生成式图像光照分解模型将室内场景光照分解为独立光源，引入多视角光照协调确保分解一致性，并集成到可重光照的3D高斯泼溅表示中实现实时交互控制
- Result: 在合成和真实数据集上展示了高度逼真的光照分解和重光照效果，定量和定性评估均优于现有技术，支持实时交互式光源控制
- Conclusion: 该方法成功实现了从单次多视角采集的室内场景中分解和交互编辑复杂光照，为室内场景光照编辑提供了有效的解决方案


### [81] [Walk through Paintings: Egocentric World Models from Internet Priors](https://arxiv.org/abs/2601.15284)
*Anurag Bagchi,Zhipeng Bao,Homanga Bharadhwaj,Yu-Xiong Wang,Pavel Tokmakov,Martial Hebert*

Main category: cs.CV

TL;DR: EgoWM将预训练视频扩散模型转化为动作条件世界模型，通过轻量级条件层注入运动指令，实现可控的未来预测，适用于多种机器人平台。

- Motivation: 现有视频生成模型能想象合理未来，但无法准确反映动作带来的世界变化。研究旨在创建能正确预测动作后果的世界模型，实现可控的未来预测。
- Method: 利用互联网规模视频模型的丰富世界先验，通过轻量级条件层注入运动指令，将预训练视频扩散模型转化为动作条件世界模型，无需从头训练。
- Result: EgoWM在导航任务中比先前最先进模型提升80%的结构一致性分数，推理延迟降低6倍，能泛化到未见环境（包括绘画内部导航），支持3-DoF到25-DoF的不同机器人平台。
- Conclusion: EgoWM成功将预训练视频模型转化为动作条件世界模型，实现了准确可控的未来预测，在物理正确性、推理效率和泛化能力方面显著优于现有方法。


### [82] [Iterative Refinement Improves Compositional Image Generation](https://arxiv.org/abs/2601.15286)
*Shantanu Jaiswal,Mihir Prabhudesai,Nikash Bhardwaj,Zheyang Qin,Amir Zadeh,Chuan Li,Katerina Fragkiadaki,Deepak Pathak*

Main category: cs.CV

TL;DR: 提出一种基于迭代自我修正的文本到图像生成方法，使用视觉语言模型作为批评器在推理时逐步优化生成结果，显著提升了复杂组合提示的生成质量。

- Motivation: 现有文本到图像模型在处理需要同时处理多个对象、关系和属性的复杂提示时表现不佳，现有的推理时策略（如并行采样验证或增加去噪步骤）在需要满足多个约束的丰富组合场景中仍然不足。
- Method: 受大语言模型中思维链推理的启发，提出迭代测试时策略：文本到图像模型在多个步骤中逐步优化生成结果，由视觉语言模型作为循环中的批评器提供反馈指导。该方法简单，无需外部工具或先验知识，可灵活应用于各种图像生成器和视觉语言模型。
- Result: 在多个基准测试中取得一致提升：ConceptMix（k=7）的全正确率提高16.9%，T2I-CompBench（3D空间类别）提高13.8%，Visual Jenga场景分解提高12.5%。人类评估者58.7%的时间偏好该方法（基线为41.3%）。
- Conclusion: 迭代自我修正作为组合图像生成的广泛适用原则，通过将复杂提示分解为顺序修正，产生更忠实的生成结果。


### [83] [Towards Understanding Best Practices for Quantization of Vision-Language Models](https://arxiv.org/abs/2601.15287)
*Gautom Das,Vincent La,Ethan Lau,Abhinav Shrivastava,Matthew Gwilliam*

Main category: cs.CV

TL;DR: 该研究探索了多种量化方法（包括GPTQ和AWQ）在多模态管道（视觉模型、语言模型及其连接器）中的应用效果，发现ViT和LLM对性能影响相当，且LLM的低比特量化能在减少权重位数的同时保持高精度。

- Motivation: 大型语言模型（LLMs）需要高性能GPU和大内存，为减少内存占用和延迟，通常采用半精度量化。现有研究主要关注更激进的比特宽度下保持模型性能，但较少应用于多模态管道。本研究旨在探索量化方法在多模态管道中的有效应用。
- Method: 研究应用多种量化方法（包括最先进的GPTQ和AWQ）到多模态管道，包括视觉模型、语言模型及其连接器。分析比特宽度、量化方法以及量化应用位置（管道不同部分）对性能的影响，评估任务包括图像描述、检索和问答。
- Result: 结果显示：1）ViT和LLM对模型性能的影响相当，尽管参数规模差异显著；2）LLM的低比特量化能在减少权重位数（bpw）的同时实现高精度；3）量化方法的选择和应用位置对性能有重要影响。
- Conclusion: 研究为多模态大模型（MLLMs）的高效部署提供了实用见解，强调了对多模态模型组件敏感性进行探索的价值。代码已开源，有助于进一步研究和应用。


### [84] [APPLE: Attribute-Preserving Pseudo-Labeling for Diffusion-Based Face Swapping](https://arxiv.org/abs/2601.15288)
*Jiwon Kang,Yeji Choi,JoungBin Lee,Wooseok Jang,Jinhyeok Choi,Taekeun Kang,Yongjae Park,Myungin Kim,Seungryong Kim*

Main category: cs.CV

TL;DR: APPLE提出了一种基于扩散模型的师生框架，通过属性感知伪标签监督来增强人脸交换中的属性保真度，将人脸交换重新定义为条件去模糊任务，实现了更好的身份转换和属性保留。

- Motivation: 人脸交换需要将源人脸的身份转移到目标人脸，同时保留目标特定的属性（姿态、表情、光照、肤色、妆容等）。由于缺乏真实标注数据，现有方法在准确身份转换和高质量属性保留方面存在挑战。基于扩散的方法通过条件修复改进视觉质量，但掩码条件会移除目标的关键外观线索，导致属性错位。
- Method: 提出APPLE（Attribute-Preserving Pseudo-Labeling）框架：1）将人脸交换重新定义为条件去模糊任务以更忠实地保留目标属性；2）引入属性感知反演方案以改进详细属性保留；3）通过精心设计的属性保留教师学习生成高质量伪标签三元组，为学生提供直接的人脸交换监督。
- Result: APPLE在属性保留和身份转换方面实现了最先进的性能，生成更逼真且忠实于目标的结果。
- Conclusion: APPLE通过属性感知伪标签监督的师生框架，有效解决了人脸交换中身份转换与属性保留的平衡问题，为缺乏真实标注数据的任务提供了有效的监督学习方案。
## cs.AI

### [85] [AutoDriDM: An Explainable Benchmark for Decision-Making of Vision-Language Models in Autonomous Driving](https://arxiv.org/abs/2601.14702)
*Zecong Tang,Zixu Wang,Yifei Wang,Weitong Lian,Tianjian Gao,Haoran Li,Tengju Ru,Lingyi Meng,Zhejun Cui,Yichen Zhu,Qi Kang,Kaixuan Wang,Yu Zhang*

Main category: cs.AI

TL;DR: AutoDriDM是一个面向自动驾驶的决策中心化渐进式基准测试，包含6,650个问题，评估视觉语言模型在感知到决策能力边界，揭示感知与决策性能弱对齐问题。

- Motivation: 现有自动驾驶基准测试过于强调感知能力，未能充分评估决策过程。视觉语言模型展现出推理和泛化能力，为自动驾驶带来新可能，但需要更全面的评估框架。
- Method: 提出AutoDriDM基准测试，包含6,650个问题，涵盖物体、场景和决策三个维度。评估主流视觉语言模型，进行感知到决策能力边界分析，并引入分析器模型来自动化大规模标注。
- Result: 评估揭示了感知与决策性能之间的弱对齐关系。通过可解释性分析识别出逻辑推理错误等关键失败模式。AutoDriDM填补了感知中心化与决策中心化评估之间的空白。
- Conclusion: AutoDriDM为开发更安全可靠的自动驾驶视觉语言模型提供指导，通过决策中心化的评估框架推动实际自动驾驶应用的进步。


### [86] [BayesianVLA: Bayesian Decomposition of Vision Language Action Models via Latent Action Queries](https://arxiv.org/abs/2601.15197)
*Shijie Lian,Bin Yu,Xiaopeng Lin,Laurence T. Yang,Zhaolong Shen,Changti Wu,Yuzhuo Miao,Cong Huang,Kai Chen*

Main category: cs.AI

TL;DR: 论文提出BayesianVLA框架，通过贝叶斯分解解决VLA模型中的信息崩溃问题，强制模型遵循语言指令，显著提升泛化能力。

- Motivation: 当前VLA模型在机器人操作中存在泛化问题，特别是在新指令或多任务场景中。研究发现目标驱动数据收集导致数据集偏差，语言指令仅从视觉观察即可高度预测，造成条件互信息消失（信息崩溃），使模型退化为忽略语言约束的纯视觉策略。
- Method: 提出BayesianVLA框架，引入可学习的潜在动作查询，构建双分支架构分别估计视觉先验p(a|v)和语言条件后验π(a|v,ℓ)。通过最大化动作与指令的条件点互信息来优化策略，惩罚视觉捷径，奖励明确解释语言指令的动作。
- Result: 在不需新数据的情况下，BayesianVLA显著提升泛化性能。在SimplerEnv和RoboCasa上的广泛实验显示明显改进，特别是在具有挑战性的OOD SimplerEnv基准上获得11.3%的提升。
- Conclusion: BayesianVLA通过贝叶斯分解有效解决信息崩溃问题，强制模型遵循语言指令，验证了该方法在将语言可靠地融入动作中的能力。
## eess.IV

### [87] [Self-Supervised Score-Based Despeckling for SAR Imagery via Log-Domain Transformation](https://arxiv.org/abs/2601.14334)
*Junhyuk Heo*

Main category: eess.IV

TL;DR: 提出基于分数生成模型的自监督SAR图像去斑框架，在log域将乘性噪声转换为近似加性高斯噪声，实现快速推理

- Motivation: SAR图像固有的斑点噪声会显著降低图像质量并增加后续分析难度，而SAR斑点噪声具有乘性和Gamma分布特性，使得有效去斑仍然具有挑战性
- Method: 提出自监督框架：1) 将数据转换到log域；2) 将斑点噪声残差转换为近似加性高斯分布；3) 在转换域中使用基于分数的生成模型，通过自监督目标训练模型从输入数据的进一步损坏版本中学习干净信号
- Result: 该方法相比现有自监督技术具有显著更短的推理时间，为SAR图像恢复提供了鲁棒且实用的解决方案
- Conclusion: 基于分数生成模型的自监督框架在log域有效处理SAR乘性噪声，实现了快速高效的SAR图像去斑


### [88] [Unsupervised Deformable Image Registration with Local-Global Attention and Image Decomposition](https://arxiv.org/abs/2601.14337)
*Zhengyong Huang,Xingwen Sun,Xuting Chang,Ning Jiang,Yao Wang,Jianfei Sun,Hongbin Han,Yao Sui*

Main category: eess.IV

TL;DR: 提出LGANet++，一种结合局部-全局注意力机制的无监督可变形图像配准框架，在跨患者、跨时间和跨模态CT-MR配准任务中优于现有方法。

- Motivation: 医学图像配准在临床实践中至关重要，但传统方法计算量大且缺乏泛化能力。现有基于注意力的深度学习方法在处理高解剖变异区域时仍存在挑战。
- Method: 提出LGANet++框架，采用新颖的局部-全局注意力机制，结合独特的特征交互与融合技术，以无监督方式提升配准精度、鲁棒性和泛化能力。
- Result: 在五个公开数据集上的实验表明，LGANet++在跨患者配准中精度提升1.39%，跨时间配准提升0.71%，跨模态CT-MR配准提升6.12%，均优于现有方法。
- Conclusion: LGANet++展示了在临床工作流中提供可靠高效图像配准的潜力，源代码已开源。


### [89] [Partial Decoder Attention Network with Contour-weighted Loss Function for Data-Imbalance Medical Image Segmentation](https://arxiv.org/abs/2601.14338)
*Zhengyong Huang,Ning Jiang,Xingwen Sun,Lihua Zhang,Peng Chen,Jens Domke,Yao Sui*

Main category: eess.IV

TL;DR: 提出一种轮廓加权的分割方法PDANet，通过部分解码器机制解决医学图像中数据不平衡问题，在三个公开数据集上优于九种现有方法

- Motivation: 医学图像分割中常存在数据不平衡问题，如器官体积差异大、样本分布不均，导致模型偏向大器官或常见结构，忽略小结构或罕见结构，影响分割精度和鲁棒性
- Method: 提出轮廓加权的分割方法，开发基于部分解码器机制的轻量高效分割网络PDANet，通过轮廓加权提升模型对小结构和代表性不足结构的表征能力
- Result: 在三个公开数据集（腹部多器官、脑肿瘤、骨盆骨折）上优于九种先进方法，轮廓加权策略使对比方法的Dice分数平均提升2.32%、1.67%和3.60%
- Conclusion: 轮廓加权分割方法在精度和鲁棒性上超越现有方法，作为模型无关策略可无缝集成到各种分割框架中，在医学图像分析中具有广泛应用潜力


### [90] [Filtered 2D Contour-Based Reconstruction of 3D STL Model from CT-DICOM Images](https://arxiv.org/abs/2601.14997)
*K. Punnam Chandar,Y. Ravi Kumar*

Main category: eess.IV

TL;DR: 提出使用过滤后的2D轮廓数据点重建3D STL模型的方法，以改善因CT图像分割不完美导致的几何偏差，并在基础形状和人体骨盆骨ROI上验证了效果。

- Motivation: 从DICOM图像的2D轮廓重建3D STL模型对于理解几何结构和畸形至关重要。然而，低分辨率图像分割产生的2D轮廓数据点可能包含异常值，导致重建的3D结构几何形状与实际不符。
- Method: 1. 对CT图像进行预处理（增强对比度、降噪、平滑）；2. 使用阈值分割技术；3. 提取2D轮廓数据点并进行过滤；4. 对每层图像的过滤后2D轮廓点进行Delaunay三角剖分；5. 逐层连接重建3D STL模型。
- Result: 在基础形状和人体骨盆骨ROI上进行验证。使用过滤后的2D数据点重建的3D STL模型比未过滤的模型在几何形状上有明显改善。
- Conclusion: 提出的过滤2D轮廓数据点方法能有效改善3D STL模型重建的几何精度，特别是在处理分割不完美的医学图像时具有实用价值。


### [91] [Vision Models for Medical Imaging: A Hybrid Approach for PCOS Detection from Ultrasound Scans](https://arxiv.org/abs/2601.15119)
*Md Mahmudul Hoque,Md Mehedi Hassain,Muntakimur Rahaman,Md. Towhidul Islam,Shaista Rani,Md Sharif Mollah*

Main category: eess.IV

TL;DR: 本文提出了两种混合模型用于PCOS检测，最终优化的DenConREST模型在超声图像上达到98.23%准确率，显著提升诊断精度。

- Motivation: PCOS是育龄妇女最常见的内分泌疾病，许多孟加拉国妇女在年龄较大时患有此病。研究旨在识别有效的基于视觉的医学图像分析技术，并评估混合模型以准确检测PCOS。
- Method: 提出两种新颖的混合模型：DenConST（结合DenseNet121、Swin Transformer和ConvNeXt）和DenConREST（结合Swin Transformer、ConvNeXt、DenseNet121、ResNet18和EfficientNetV2）。数据分为"感染"（PCOS阳性）和"未感染"（健康卵巢）两类。
- Result: DenConST模型达到85.69%准确率，最终优化的DenConREST模型表现出最佳性能，达到98.23%准确率。
- Conclusion: 研究为PCOS超声图像检测提供了高效解决方案，显著提高诊断准确性，同时减少检测错误。
## cs.LG

### [92] [Mixture-of-Experts Models in Vision: Routing, Optimization, and Generalization](https://arxiv.org/abs/2601.15021)
*Adam Rokah,Daniel Veress,Caleb Caulk,Sourav Sharan*

Main category: cs.LG

TL;DR: 在CIFAR10图像分类任务中比较密集、SoftMoE和SparseMoE分类头，MoE变体在可比模型容量下获得略高验证准确率，但条件路由在当前规模下未实现推理加速。

- Motivation: 研究MoE在图像分类场景中的行为，关注预测性能、专家利用率和泛化特性，而非传统的大语言模型扩展动机。
- Method: 在CIFAR10数据集上比较密集、SoftMoE和SparseMoE分类头，使用正则化保持专家平衡，通过Hessian锐度度量（最大特征值和迹）分析泛化，并进行损失表面扰动分析。
- Result: 两种MoE变体获得略高于密集基线的验证准确率，避免专家崩溃；SoftMoE显示更高锐度，而密集和SparseMoE处于相似曲率区域；条件路由在当前规模下未实现推理加速。
- Conclusion: MoE在图像分类中能获得略好性能但需正则化保持专家平衡，锐度度量显示架构差异但未直接解释泛化性能，稀疏MoE的理论效率与实际硬件实现存在差距。


### [93] [DeepFedNAS: A Unified Framework for Principled, Hardware-Aware, and Predictor-Free Federated Neural Architecture Search](https://arxiv.org/abs/2601.15127)
*Bostan Khan,Masoud Daneshtalab*

Main category: cs.LG

TL;DR: DeepFedNAS 是一个用于联邦神经架构搜索的两阶段框架，通过帕累托最优超网训练和预测器无关搜索方法，显著提升了搜索效率和模型性能。

- Motivation: 解决联邦神经架构搜索中的两个关键瓶颈：无指导的超网训练导致次优模型，以及后训练子网发现需要多小时的昂贵流程。
- Method: 采用两阶段框架：1) 联邦帕累托最优超网训练，使用预计算的帕累托最优架构缓存作为智能课程来优化共享超网权重；2) 预测器无关搜索方法，利用多目标适应度函数作为零成本精度代理，实现秒级子网发现。
- Result: 在CIFAR-100上达到最高1.21%的绝对精度提升，具有优越的参数和通信效率，后训练搜索流程时间加速约61倍（从20多小时减少到约20分钟），单个子网搜索仅需20秒。
- Conclusion: DeepFedNAS通过大幅减少搜索时间和成本，使硬件感知的联邦学习部署变得即时可行，为隐私保护的自动化模型设计提供了实用解决方案。


### [94] [ZENITH: Automated Gradient Norm Informed Stochastic Optimization](https://arxiv.org/abs/2601.15212)
*Dhrubo Saha*

Main category: cs.LG

TL;DR: ZENITH优化器通过梯度范数的时间演化自动调整学习率，无需人工干预或超参数调优，在图像分类、目标检测等任务中取得更高精度和更快训练速度。

- Motivation: 现有自适应优化器存在计算和内存开销大、与正则化不兼容、学习率选择次优等问题，需要手动调整学习率计划或超参数调优。
- Method: 提出ZENITH优化器，利用梯度范数的时间演化信息自动调整学习率，实现零开销的自适应学习率调度。
- Result: 在6种CNN架构和6个基准测试的图像分类实验中，ZENITH比基线方法获得更高的测试精度和更短的训练时间；在MS COCO的目标检测、关键点检测和实例分割任务中，使用R-CNN系列模型获得更优的mAP。
- Conclusion: ZENITH优化器能够自动高效地调整学习率，兼容正则化技术，在多种计算机视觉任务中实现更好的泛化性能和训练效率。
## cs.RO

### [95] [ExPrIS: Knowledge-Level Expectations as Priors for Object Interpretation from Sensor Data](https://arxiv.org/abs/2601.15025)
*Marian Renz,Martin Günther,Felix Igelbrink,Oscar Lima,Martin Atzmueller*

Main category: cs.RO

TL;DR: ExPrIS项目提出了一种基于3D语义场景图的知识驱动方法，通过整合上下文先验和外部语义知识来增强机器人物体识别，超越了纯数据驱动方法的局限性。

- Motivation: 纯数据驱动的深度学习方法在机器人物体识别中缺乏语义一致性，且未能充分利用环境中已有的先验知识。需要一种能够整合知识级期望的方法来改进从传感器数据中解释物体的能力。
- Method: 基于增量构建3D语义场景图（3DSSG），整合两种期望来源：来自过去观察的上下文先验和来自外部图（如ConceptNet）的语义知识。将这些期望嵌入到异构图神经网络（GNN）中，创建期望偏置的推理过程。
- Result: 该方法超越了静态的逐帧分析，增强了场景理解在时间维度上的鲁棒性和一致性。报告详细描述了该架构及其评估，并规划了在移动机器人平台上的集成。
- Conclusion: ExPrIS项目通过整合知识级期望到3D语义场景图中，提供了一种更稳健、语义一致的机器人场景理解方法，有望改进纯数据驱动方法的局限性。
## cs.CR

### [96] [SpooFL: Spoofing Federated Learning](https://arxiv.org/abs/2601.15055)
*Isaac Baglin,Xiatian Zhu,Simon Hadfield*

Main category: cs.CR

TL;DR: 提出SpooFL防御方法，将联邦学习中的深度泄漏防御重构为欺骗问题，通过生成与私有数据无关的合成样本来误导攻击者

- Motivation: 传统联邦学习防御方法（如添加噪声、变换或加密）虽然有效，但仍会泄露高级信息（如类别分布或特征表示），且容易被强大的去噪攻击破解。需要从根本上不同的防御视角。
- Method: 提出SpooFL欺骗防御框架，使用最先进的生成模型在外部数据集上训练（无类别重叠），生成与私有数据无关但看起来合理的合成样本，误导攻击者以为恢复了真实训练数据
- Result: 成功误导攻击者恢复完全无关的样本，防止有意义的数据泄露，同时保持联邦学习训练完整性，模型性能影响较小
- Conclusion: 将联邦学习防御重构为欺骗问题是一种有效的新方法，SpooFL通过生成无关的合成样本成功误导攻击者，比传统防御方法更安全
## cs.CL

### [97] [Render-of-Thought: Rendering Textual Chain-of-Thought as Images for Visual Latent Reasoning](https://arxiv.org/abs/2601.14750)
*Yifan Wang,Shiyu Li,Peiming Li,Xiaochen Yang,Yang Tang,Zheng Wei*

Main category: cs.CL

TL;DR: Render-of-Thought (RoT) 框架将文本推理链渲染为图像，实现3-4倍的token压缩和推理加速，同时保持竞争力

- Motivation: CoT提示虽然增强了推理能力，但冗长的文本带来巨大计算开销，且现有方法缺乏对中间推理过程的监督，导致潜在推理链难以分析
- Method: 提出Render-of-Thought (RoT)框架，将文本推理步骤渲染为图像，利用现有VLM的视觉编码器作为语义锚点，对齐视觉嵌入和文本空间，实现即插即用
- Result: 在数学和逻辑推理基准测试中，相比显式CoT实现3-4倍token压缩和显著推理加速，同时保持与其他方法竞争的性能
- Conclusion: RoT通过将推理链可视化，使潜在推理过程显式和可追溯，验证了这种范式的可行性，为高效推理提供了新方向
