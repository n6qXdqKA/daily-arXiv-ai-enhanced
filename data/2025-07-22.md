[[toc]]

## cs.CV

### [1] [Comparative Analysis of Algorithms for the Fitting of Tessellations to 3D Image Data](https://arxiv.org/abs/2507.14268)
*Andreas Alpers,Orkun Furat,Christian Jung,Matthias Neumann,Claudia Redenbach,Aigerim Saken,Volker Schmidt*

Main category: cs.CV

TL;DR: 比较分析了多种算法策略用于拟合3D图像数据中的镶嵌模型，评估了优化方法的效果。

- Motivation: 在材料科学中，准确拟合3D图像数据（如多晶体和泡沫）的镶嵌模型是一个不断发展的领域，需要评估不同优化方法的适用性。
- Method: 比较了线性/非线性规划、随机优化（交叉熵法）和梯度下降等方法，用于生成Voronoi、Laguerre和GBPD模型。
- Result: 通过实际数据集评估了拟合质量，发现模型复杂度、优化方法复杂度和近似质量之间存在权衡。
- Conclusion: 研究结果为根据数据特征和应用需求选择合适方法提供了指导。


### [2] [Semantic Segmentation based Scene Understanding in Autonomous Vehicles](https://arxiv.org/abs/2507.14303)
*Ehsan Rassekh*

Main category: cs.CV

TL;DR: 论文探讨了深度学习在语义分割中的应用，提出几种高效模型，并验证了不同主干网络对模型性能的影响。

- Motivation: 人工智能和深度学习在复杂任务中表现出色，尤其在自动驾驶领域。研究旨在通过语义分割提升场景理解能力。
- Method: 使用BDD100k数据集，提出多种高效模型，并尝试不同主干网络作为编码器。
- Result: 结果表明，选择合适的主干网络显著提升语义分割性能，改善了准确率、平均IoU和损失函数。
- Conclusion: 研究证实了主干网络选择对语义分割的重要性，为自动驾驶等领域的场景理解提供了有效方法。


### [3] [CLIPTTA: Robust Contrastive Vision-Language Test-Time Adaptation](https://arxiv.org/abs/2507.14312)
*Marc Lafon,Gustavo Adolfo Vargas Hakim,Clément Rambour,Christian Desrosier,Nicolas Thome*

Main category: cs.CV

TL;DR: CLIPTTA是一种基于梯度的测试时适应方法，针对视觉语言模型（VLMs）在分布偏移下的泛化问题，通过软对比损失和改进的OOD检测方法，显著提升了性能。

- Motivation: 视觉语言模型（如CLIP）在零样本任务中表现优异，但在分布偏移下泛化能力不足。现有的测试时适应方法（如熵最小化）与VLMs的对比训练目标不匹配，导致性能受限和失败模式。
- Method: 提出CLIPTTA方法，使用与CLIP预训练目标一致的软对比损失进行梯度优化，并通过理论分析证明其抗崩溃能力。进一步扩展至开放集设置，引入Outlier Contrastive Exposure（OCE）损失以改进OOD检测。
- Result: 在75个数据集上的实验表明，CLIPTTA在分布偏移下表现优于基于熵的方法，并与最先进的TTA方法竞争，且在多个数据集上表现更稳定。
- Conclusion: CLIPTTA通过软对比损失和OCE损失，显著提升了VLMs在分布偏移下的适应能力，为测试时适应提供了新的解决方案。


### [4] [A Hidden Stumbling Block in Generalized Category Discovery: Distracted Attention](https://arxiv.org/abs/2507.14315)
*Qiyu Xu,Zhanxuan Hu,Yu Duan,Ercheng Pei,Yonghang Tai*

Main category: cs.CV

TL;DR: 论文提出了一种名为注意力聚焦（AF）的机制，通过修剪非信息性标记来解决广义类别发现（GCD）中的注意力分散问题，显著提升了模型性能。

- Motivation: 现有GCD方法在处理未标记数据时容易受到背景区域的干扰，导致特征提取不理想。
- Method: AF由两个组件组成：标记重要性度量（TIME）和多尺度标记自适应修剪（TAP），通过量化标记重要性并修剪非信息性标记来优化注意力。
- Result: 将AF集成到SimGCD方法中，性能提升了15.4%，且计算开销极小。
- Conclusion: AF是一种轻量级、即插即用的模块，能有效提升GCD方法的性能。


### [5] [Hallucination Score: Towards Mitigating Hallucinations in Generative Image Super-Resolution](https://arxiv.org/abs/2507.14367)
*Weiming Ren,Raghav Goyal,Zhiming Hu,Tristan Ty Aumentado-Armstrong,Iqbal Mohomed,Alex Levinshtein*

Main category: cs.CV

TL;DR: 生成超分辨率（GSR）在感知图像质量方面表现优异，但存在与低分辨率图像（LRI）或真实图像（GTI）不匹配的伪影问题。本文提出了一种基于多模态大语言模型（MLLM）的“幻觉评分”（HS）方法，并通过深度特征距离优化GSR模型以减少幻觉。

- Motivation: GSR模型在感知质量上表现优异，但生成的细节与LRI或GTI不匹配的伪影问题限制了其实际应用。现有指标无法有效衡量这一问题。
- Method: 利用MLLM构建提示，评估幻觉视觉元素并生成HS；通过深度特征距离作为可微奖励函数优化GSR模型。
- Result: HS与人类评估高度一致，且为超分辨率模型提供了补充性见解；某些深度特征距离与HS强相关。
- Conclusion: 提出的HS方法有效衡量和缓解了GSR中的幻觉问题，并通过特征对齐优化模型性能。


### [6] [DUSTrack: Semi-automated point tracking in ultrasound videos](https://arxiv.org/abs/2507.14368)
*Praneeth Namburi,Roger Pallarès-López,Jessica Rosendorf,Duarte Folgado,Brian W. Anthony*

Main category: cs.CV

TL;DR: DUSTrack是一种结合深度学习和光流的半自动化工具包，用于在B型超声视频中跟踪任意点，解决了噪声和运动模糊等问题，并在多种应用中表现出色。

- Motivation: B型超声中的组织运动跟踪因噪声和低对比度等问题而具有挑战性，需要一种通用且高精度的解决方案。
- Method: 结合深度学习和光流技术，提供图形界面支持训练数据生成和模型优化，并引入光流滤波技术减少噪声。
- Result: DUSTrack在精度上优于现有零样本跟踪器，与专用方法相当，适用于心脏、肌肉等多种应用场景。
- Conclusion: DUSTrack是一种开源工具，为临床和生物力学研究提供了通用且强大的组织运动量化框架。


### [7] [CRAFT: A Neuro-Symbolic Framework for Visual Functional Affordance Grounding](https://arxiv.org/abs/2507.14426)
*Zhou Chen,Joe Lin,Sathyanarayanan N. Aakur*

Main category: cs.CV

TL;DR: CRAFT是一个神经符号框架，用于可解释的affordance grounding，通过结合ConceptNet和CLIP的视觉证据，迭代优化预测。

- Motivation: 解决场景理解中对象与动作关联的透明性和可解释性问题。
- Method: 整合ConceptNet的常识先验和CLIP的视觉证据，采用基于能量的推理循环迭代优化预测。
- Result: 在多对象、无标签设置中提高了准确性和可解释性。
- Conclusion: CRAFT为稳健且可信的场景理解提供了新方向。


### [8] [Adaptive 3D Gaussian Splatting Video Streaming](https://arxiv.org/abs/2507.14432)
*Han Gong,Qiyue Li,Zhi Liu,Hao Zhou,Peng Yuan Zhou,Zhu Li,Jie Li*

Main category: cs.CV

TL;DR: 提出了一种基于高斯变形场的3DGS视频流框架，通过混合显著性分块和差异化质量建模，实现了高效压缩和带宽适应，性能优于现有方法。

- Motivation: 3D高斯溅射（3DGS）视频数据量大且传输复杂，传统方法难以满足需求。
- Method: 设计基于高斯变形场的3DGS视频构建方法，结合混合显著性分块和差异化质量建模。
- Result: 实验验证了该方法在视频质量、压缩效果和传输速率上的优越性。
- Conclusion: 该框架有效解决了3DGS视频流的高效传输问题。


### [9] [IRGPT: Understanding Real-world Infrared Image with Bi-cross-modal Curriculum on Large-scale Benchmark](https://arxiv.org/abs/2507.14449)
*Zhe Cao,Jin Zhang,Ruiheng Zhang*

Main category: cs.CV

TL;DR: IRGPT是首个针对真实红外图像的多模态大语言模型，基于大规模红外-文本数据集（IR-TD），通过双向跨模态课程迁移学习策略，在9项任务中达到最先进性能。

- Motivation: 真实红外图像因缺乏对齐的文本数据和领域特性，现有方法依赖合成图像，无法捕捉红外模态的独特特征。
- Method: 提出IR-TD数据集（26万真实红外图像-文本对），采用双向跨模态课程迁移学习策略，从可见光到红外领域系统迁移知识。
- Result: 在9项任务（如识别、定位）中，IRGPT性能优于更大规模的模型。
- Conclusion: IRGPT通过真实数据集和创新学习策略，解决了红外图像的多模态建模问题，性能显著提升。


### [10] [GPI-Net: Gestalt-Guided Parallel Interaction Network via Orthogonal Geometric Consistency for Robust Point Cloud Registration](https://arxiv.org/abs/2507.14452)
*Weikang Gu,Mingyue Han,Li Xue,Heng Dong,Changcai Yang,Riqing Chen,Lifang Wei*

Main category: cs.CV

TL;DR: 提出了一种基于Gestalt原则的并行交互网络（GPI-Net），通过正交几何一致性优化点云配准中的特征冗余和空间关系问题。

- Motivation: 点云配准中高质量对应关系的识别受限于局部和全局特征的冗余与复杂空间关系，Gestalt原则为解决这一问题提供了优势。
- Method: 提出GPI-Net，包括正交集成策略减少冗余信息，Gestalt特征注意力块（GFA）捕获几何特征，以及双路径多粒度并行交互聚合块（DMG）促进信息交换。
- Result: 在多个挑战性任务上的实验表明，GPI-Net优于现有方法。
- Conclusion: GPI-Net通过Gestalt原则有效整合局部和全局信息，显著提升了点云配准的性能。


### [11] [Adaptive 3D Gaussian Splatting Video Streaming: Visual Saliency-Aware Tiling and Meta-Learning-Based Bitrate Adaptation](https://arxiv.org/abs/2507.14454)
*Han Gong,Qiyue Li,Jie Li,Zhi Liu*

Main category: cs.CV

TL;DR: 论文提出了一种基于显著性分析的3D高斯泼溅视频（3DGS）流媒体解决方案，包括自适应分块、质量评估和比特率适应算法，显著优于现有方法。

- Motivation: 3DGS流媒体因其沉浸式体验成为研究热点，但分块、质量评估和比特率适应等基础问题仍需解决。
- Method: 提出自适应3DGS分块技术（结合显著性分析）、新型质量评估框架和基于元学习的比特率适应算法。
- Result: 实验表明，所提方法在性能上显著优于现有技术。
- Conclusion: 论文为3DGS流媒体提供了一套全面解决方案，解决了关键挑战并提升了性能。


### [12] [GEMINUS: Dual-aware Global and Scene-Adaptive Mixture-of-Experts for End-to-End Autonomous Driving](https://arxiv.org/abs/2507.14456)
*Chi Wan,Yixin Cui,Jiatong Du,Shuo Yang,Yulong Bai,Yanjun Huang*

Main category: cs.CV

TL;DR: GEMINUS是一个混合专家框架，用于端到端自动驾驶，通过全局专家和场景自适应专家组的动态路由，实现多样场景下的自适应和鲁棒性能。

- Motivation: 现有单模式规划方法难以处理多样化的驾驶场景，需要一种能够适应不同场景的自动驾驶框架。
- Method: 提出GEMINUS框架，包含全局专家、场景自适应专家组和双感知路由器，动态激活专家模块。
- Result: 在Bench2Drive基准测试中表现优异，驾驶分数和成功率均达到最优，单目视觉输入下仍有显著提升。
- Conclusion: GEMINUS通过混合专家框架有效提升了自动驾驶在多样化场景中的适应性和鲁棒性。


### [13] [VisGuard: Securing Visualization Dissemination through Tamper-Resistant Data Retrieval](https://arxiv.org/abs/2507.14459)
*Huayuan Ye,Juntong Chen,Shenzhuo Zhang,Yipeng Zhang,Changbo Wang,Chenhui Li*

Main category: cs.CV

TL;DR: VisGuard是一种抗篡改的可视化图像数据检索框架，通过嵌入元数据链接解决现有方法在图像篡改时的脆弱性问题。

- Motivation: 现有方法在可视化图像传播中容易因裁剪和编辑等篡改操作丢失元数据，导致信息不完整。
- Method: VisGuard采用重复数据平铺、可逆信息广播和基于锚点的裁剪定位技术，增强嵌入数据的鲁棒性。
- Result: 实验表明VisGuard在数据检索准确性、嵌入容量和抗篡改安全性方面表现优异。
- Conclusion: VisGuard能有效保护和促进可视化传播及信息传递。


### [14] [OptiCorNet: Optimizing Sequence-Based Context Correlation for Visual Place Recognition](https://arxiv.org/abs/2507.14477)
*Zhenyu Li,Tianyi Shang,Pengjie Xu,Ruirui Zhang,Fanchen Kong*

Main category: cs.CV

TL;DR: OptiCorNet提出了一种新的序列建模框架，结合空间特征提取和时间差分，通过端到端训练提升动态环境中的视觉地点识别能力。

- Motivation: 动态和感知混淆环境中的视觉地点识别（VPR）是长期定位的核心挑战，现有方法多忽略时间连贯性。
- Method: 采用轻量级1D卷积编码器和可学习的时间差分算子（DSD），结合LSTM优化和四元组损失函数，直接学习序列级嵌入。
- Result: 在多个公开基准测试中，OptiCorNet在季节和视角变化下优于现有方法。
- Conclusion: OptiCorNet通过端到端学习序列级嵌入，显著提升了动态环境中的地点识别效果。


### [15] [DFQ-ViT: Data-Free Quantization for Vision Transformers without Fine-tuning](https://arxiv.org/abs/2507.14481)
*Yujia Tong,Jingling Yuan,Tian Zhang,Jianquan Liu,Chuang Hu*

Main category: cs.CV

TL;DR: DFQ-ViT提出了一种无需真实数据的ViT量化方法，通过合成样本和激活校正矩阵提升量化模型性能。

- Motivation: 现有方法在合成样本时未能平衡全局和局部特征，且量化模型与全精度模型的中间层激活分布差异大，导致性能下降。
- Method: 按难度递增合成样本，并引入激活校正矩阵对齐中间层激活分布。
- Result: DFQ-ViT性能优于现有DFQ方法，接近真实数据量化模型，如3位量化的DeiT-T性能提升4.29%。
- Conclusion: DFQ-ViT无需微调，降低计算开销和部署门槛，符合绿色学习原则。


### [16] [Benefit from Reference: Retrieval-Augmented Cross-modal Point Cloud Completion](https://arxiv.org/abs/2507.14485)
*Hongye Hou,Liu Zhan,Yang Yang*

Main category: cs.CV

TL;DR: 提出了一种基于检索增强的点云补全框架，通过跨模态检索学习结构先验信息，提升补全效果。

- Motivation: 解决现有方法在输入类别有限时生成能力受限的问题，通过引入跨模态检索学习结构先验。
- Method: 设计了结构共享特征编码器（SSFE）和渐进检索增强生成器（PRAG），结合双通道控制门和分层特征融合机制。
- Result: 在多个数据集和真实场景中验证了方法的有效性，尤其在生成细粒度点云和处理稀疏数据及未见类别时表现优异。
- Conclusion: 该方法通过检索增强机制显著提升了点云补全的性能和泛化能力。


### [17] [Efficient Whole Slide Pathology VQA via Token Compression](https://arxiv.org/abs/2507.14497)
*Weimin Lyu,Qingqiao Hu,Kehan Qi,Zhan Shi,Wentao Huang,Saumya Gupta,Chao Chen*

Main category: cs.CV

TL;DR: TCP-LLaVA是一种新型多模态大语言模型架构，通过令牌压缩技术解决病理学全切片图像（WSI）的视觉问答（VQA）问题，显著降低计算资源消耗。

- Motivation: 病理学全切片图像（WSI）的高分辨率和长上下文长度对多模态大语言模型（MLLM）提出了挑战，现有方法在生成能力和资源消耗方面存在不足。
- Method: 提出TCP-LLaVA，通过可训练的压缩令牌和模态压缩模块，将视觉和文本信息聚合为少量压缩令牌，仅将这些令牌输入语言模型生成答案。
- Result: 在十种TCGA肿瘤亚型的实验中，TCP-LLaVA在VQA准确性上优于现有基线，并大幅减少训练资源消耗。
- Conclusion: TCP-LLaVA为WSI的VQA提供了一种高效且准确的解决方案，为病理学领域的多模态分析开辟了新方向。


### [18] [Motion Segmentation and Egomotion Estimation from Event-Based Normal Flow](https://arxiv.org/abs/2507.14500)
*Zhiyuan Hua,Dehao Yuan,Cornelia Fermüller*

Main category: cs.CV

TL;DR: 提出了一种基于事件法向流的运动分割与自运动估计框架，适用于神经形态视觉传感器，无需完整光流计算。

- Motivation: 传统方法依赖光流或深度估计，而神经形态传感器的高时间分辨率事件数据未被充分利用。
- Method: 利用事件数据的稀疏性和高时间分辨率，结合几何约束，通过优化流程进行事件过分割、运动残差分析和层次聚类。
- Result: 在EVIMO2v2数据集上验证了方法的准确性，尤其在物体边界表现优异。
- Conclusion: 该方法在实时机器人及导航应用中具有潜力。


### [19] [Advances in Feed-Forward 3D Reconstruction and View Synthesis: A Survey](https://arxiv.org/abs/2507.14501)
*Jiahui Zhang,Yuelei Li,Anpei Chen,Muyu Xu,Kunhao Liu,Jianyuan Wang,Xiao-Xiao Long,Hanxue Liang,Zexiang Xu,Hao Su,Christian Theobalt,Christian Rupprecht,Andrea Vedaldi,Hanspeter Pfister,Shijian Lu,Fangneng Zhan*

Main category: cs.CV

TL;DR: 该论文综述了基于深度学习的快速3D重建与视图合成的前馈方法，分类了不同表示架构，并探讨了其应用与未来方向。

- Motivation: 传统方法计算复杂度高，限制了实际应用，而深度学习的前馈方法提供了快速且通用的解决方案。
- Method: 通过分类点云、3D高斯泼溅、NeRF等表示架构，分析关键任务如无姿态重建、动态3D重建等。
- Result: 总结了常用数据集和评估协议，展示了前馈方法在数字人、SLAM等领域的应用潜力。
- Conclusion: 前馈方法有望推动3D视觉领域的发展，但仍需解决开放研究挑战。


### [20] [DCHM: Depth-Consistent Human Modeling for Multiview Detection](https://arxiv.org/abs/2507.14505)
*Jiahao Ma,Tianyu Wang,Miaomiao Liu,David Ahmedt-Aristizabal,Chuong Nguyen*

Main category: cs.CV

TL;DR: 提出了一种名为DCHM的框架，通过深度一致性和多视图融合技术，在稀疏视图、大规模和拥挤场景中实现精确的行人建模和定位。

- Motivation: 现有方法在多视图行人检测中常引入噪声且精度低，依赖昂贵的人工标注，难以泛化到多样场景。
- Method: 采用深度一致性行人建模（DCHM），结合超像素级高斯泼溅技术，实现全局坐标系中的多视图深度一致性和融合。
- Result: 显著减少了行人建模中的噪声，优于现有基线方法，并首次在挑战性场景中实现行人重建和多视图分割。
- Conclusion: DCHM无需依赖人工标注，在多视图行人检测中表现出色，为复杂场景提供了高效解决方案。


### [21] [ArtiMuse: Fine-Grained Image Aesthetics Assessment with Joint Scoring and Expert-Level Understanding](https://arxiv.org/abs/2507.14533)
*Shuo Cao,Nan Ma,Jiayang Li,Xiaohui Li,Lihao Shao,Kaiwen Zhu,Yu Zhou,Yuandong Pu,Jiarui Wu,Jiaquan Wang,Bo Qu,Wenhai Wang,Yu Qiao,Dajuin Yao,Yihao Liu*

Main category: cs.CV

TL;DR: 提出ArtiMuse模型和ArtiMuse-10K数据集，解决多模态大语言模型在图像美学评估中的模态偏差和细粒度属性分解不足问题。

- Motivation: 教育应用、艺术创作和AI生成内容的发展对图像美学评估提出更高要求，需兼具定量评分和专业理解能力。
- Method: 开发ArtiMuse模型，结合联合评分和专家级理解能力，并构建ArtiMuse-10K数据集，包含10,000张专家标注图像。
- Result: ArtiMuse模型在多模态大语言模型基础上提升感知和泛化能力，数据集支持细粒度美学分析。
- Conclusion: 公开模型和数据集以推动图像美学评估领域发展。


### [22] [Real Time Captioning of Sign Language Gestures in Video Meetings](https://arxiv.org/abs/2507.14543)
*Sharanya Mukherjee,Md Hishaam Akhtar,Kannadasan R*

Main category: cs.CV

TL;DR: 论文提出了一种浏览器扩展，通过计算机视觉技术将手语实时翻译为字幕，以解决听障人士在视频会议中的沟通障碍。

- Motivation: 听障人士与普通人之间的沟通存在障碍，尤其是在疫情期间视频会议成为主要沟通方式时，手语识别技术显得尤为重要。
- Method: 利用包含2000多个单词级ASL视频的大规模数据集，开发浏览器扩展，实现手语到字幕的自动翻译。
- Result: 该方法旨在为视频会议中的听障人士提供更便捷的沟通方式，减少沟通障碍。
- Conclusion: 通过浏览器扩展实现手语翻译，有望显著改善听障人士在视频会议中的参与度和沟通效率。


### [23] [Multimodal AI for Gastrointestinal Diagnostics: Tackling VQA in MEDVQA-GI 2025](https://arxiv.org/abs/2507.14544)
*Sujata Gaihre,Amir Thapa Magar,Prasuna Pokharel,Laxmi Tiwari*

Main category: cs.CV

TL;DR: 本文介绍了基于Florence模型的医学视觉问答（VQA）方法，用于胃肠道内窥镜图像分析，通过领域增强提升泛化能力，在KASVIR数据集上表现优异。

- Motivation: 解决医学视觉问答（VQA）在胃肠道内窥镜领域的挑战，提升模型的临床相关性。
- Method: 采用Florence多模态基础模型，结合视觉和文本编码器，应用领域特定增强技术。
- Result: 在KASVIR数据集上微调Florence模型，取得官方挑战指标上的准确结果。
- Conclusion: 展示了大型多模态模型在医学VQA中的潜力，为未来研究提供了基线。


### [24] [Synthesizing Images on Perceptual Boundaries of ANNs for Uncovering Human Perceptual Variability on Facial Expressions](https://arxiv.org/abs/2507.14549)
*Haotian Deng,Chi Zhang,Chen Wei,Quanying Liu*

Main category: cs.CV

TL;DR: 研究探讨了人工神经网络（ANN）决策边界与人类情感感知变异性之间的联系，通过生成模糊刺激样本并构建数据集，揭示了ANN与人类感知的共享计算原则。

- Motivation: 解决情感认知科学中外部情感刺激与人类内部体验关系建模的挑战，尤其是ANN在个体感知差异方面的不足。
- Method: 引入新的感知边界采样方法生成模糊面部表情刺激，构建varEmotion数据集，并通过大规模人类行为实验验证。
- Result: 发现ANN难以分类的刺激同样引发人类感知不确定性，通过行为数据微调ANN，实现了与人类感知模式的对齐。
- Conclusion: 建立了ANN决策边界与人类感知变异性的系统性联系，为个性化情感解释建模提供了新视角。


### [25] [Clutter Detection and Removal by Multi-Objective Analysis for Photographic Guidance](https://arxiv.org/abs/2507.14553)
*Xiaoran Wu*

Main category: cs.CV

TL;DR: 论文提出了一种相机引导系统，帮助用户识别和去除照片中的杂乱元素，通过美学评估和图像修复算法提升照片质量。

- Motivation: 业余摄影师常因疏忽或经验不足在照片中留下杂乱元素，影响照片情感表达和故事叙述。
- Method: 系统结合了美学评估算法和基于生成对抗网络的图像修复技术，提供交互式杂乱识别与去除工具。
- Result: 用户研究表明，系统能帮助用户更高效地识别杂乱并提升照片质量。
- Conclusion: 该系统通过灵活界面和精准算法，有效解决了照片杂乱问题，提升了摄影体验。


### [26] [Descrip3D: Enhancing Large Language Model-based 3D Scene Understanding with Object-Level Text Descriptions](https://arxiv.org/abs/2507.14555)
*Jintang Xue,Ganning Zhao,Jie-En Yao,Hong-En Chen,Yue Hu,Meida Chen,Suya You,C. -C. Jay Kuo*

Main category: cs.CV

TL;DR: Descrip3D是一个新框架，通过自然语言编码物体间关系，提升3D场景理解能力，无需任务特定头或额外监督。

- Motivation: 现有3D场景语言模型在关系理解上表现不佳，视觉嵌入无法充分表达物体角色和交互。
- Method: Descrip3D为每个物体添加文本描述，捕捉其属性和上下文关系，并通过嵌入融合和提示级注入实现双级集成。
- Result: 在五个基准数据集上表现优于基线模型，验证了语言引导的关系表示的有效性。
- Conclusion: Descrip3D通过语言增强的关系表示，显著提升了复杂室内场景的理解能力。


### [27] [LEAD: Exploring Logit Space Evolution for Model Selection](https://arxiv.org/abs/2507.14559)
*Zixuan Hu,Xiaotong Li,Shixiang Tang,Jun Liu,Yichun Hu,Ling-Yu Duan*

Main category: cs.CV

TL;DR: LEAD是一种基于网络输出logits的微调对齐方法，通过ODE建模非线性优化过程，有效预测预训练模型在下游任务中的迁移性能。

- Motivation: 预训练模型数量激增，如何高效选择最适合下游任务的模型成为挑战，现有方法未能准确捕捉微调动态的非线性特性。
- Method: 提出LEAD方法，基于logits建模优化过程，推导ODE描述非线性演化，并设计类感知分解方法考虑不同类的动态变化。
- Result: 在24个预训练模型和10个下游数据集上的实验表明，LEAD在性能和适应性上表现优异，尤其在低数据场景中。
- Conclusion: LEAD通过单步优化有效解决迁移性能预测问题，避免了冗长的微调过程，具有广泛适用性。


### [28] [Benchmarking GANs, Diffusion Models, and Flow Matching for T1w-to-T2w MRI Translation](https://arxiv.org/abs/2507.14575)
*Andrea Moschetto,Lemuel Puglisi,Alec Sargood,Pierluigi Dell'Acqua,Francesco Guarnera,Sebastiano Battiato,Daniele Ravì*

Main category: cs.CV

TL;DR: 该论文对生成对抗网络（GANs）、扩散模型和流匹配（FM）技术进行了全面比较，用于T1w到T2w的2D MRI图像转换，发现GAN-based Pix2Pix模型在结构保真度、图像质量和计算效率上表现最佳。

- Motivation: 减少MRI扫描时间和成本，通过计算合成缺失的模态图像，同时保持诊断质量。
- Method: 比较了GANs、扩散模型和FM技术在T1w到T2w MRI图像转换中的表现，使用公开数据集进行评估。
- Result: GAN-based Pix2Pix模型在结构保真度、图像质量和计算效率上优于扩散模型和FM技术。
- Conclusion: GAN-based方法在小型数据集和简单任务中表现更优，为实际MRI工作流程提供了实用指导，并指出了未来研究方向。


### [29] [Performance comparison of medical image classification systems using TensorFlow Keras, PyTorch, and JAX](https://arxiv.org/abs/2507.14587)
*Merjem Bećirović,Amina Kurtović,Nordin Smajlović,Medina Kapo,Amila Akagić*

Main category: cs.CV

TL;DR: 本文比较了TensorFlow、PyTorch和JAX三种深度学习框架在BloodMNIST数据集上的性能，重点关注推理时间和分类准确性。

- Motivation: 血液显微镜图像分析对疾病诊断至关重要，但缺乏对不同深度学习框架性能的详细分析。
- Method: 使用BloodMNIST数据集，比较三种框架在推理时间和分类准确性上的表现。
- Result: JAX和PyTorch的分类准确性接近当前基准，性能受图像分辨率和框架优化影响。
- Conclusion: JAX和PyTorch在医学图像分类中表现高效，适合相关应用。


### [30] [DiSCO-3D : Discovering and segmenting Sub-Concepts from Open-vocabulary queries in NeRF](https://arxiv.org/abs/2507.14596)
*Doriand Petit,Steve Bourgeois,Vincent Gay-Bellile,Florian Chabot,Loïc Barthe*

Main category: cs.CV

TL;DR: DiSCO-3D是一种结合无监督分割和开放词汇引导的方法，用于3D开放词汇子概念发现，在开放词汇和无监督分割的边缘案例中表现优异。

- Motivation: 传统方法仅适应特定任务目标或场景内容，DiSCO-3D旨在解决更广泛的3D开放词汇子概念发现问题，适应场景和用户查询。
- Method: 基于神经场表示，结合无监督分割和弱开放词汇引导。
- Result: DiSCO-3D在开放词汇子概念发现中表现有效，在开放词汇和无监督分割的边缘案例中达到最先进水平。
- Conclusion: DiSCO-3D为3D语义分割提供了一种灵活且适应性强的方法，能够同时满足场景和用户需求。


### [31] [Exp-Graph: How Connections Learn Facial Attributes in Graph-based Expression Recognition](https://arxiv.org/abs/2507.14608)
*Nandani Sharma,Dinesh Singh*

Main category: cs.CV

TL;DR: 提出了一种名为Exp-Graph的新框架，通过图建模结合视觉Transformer和图卷积网络，提升面部表情识别的准确性。

- Motivation: 面部表情识别在人机交互等领域至关重要，但面部属性的结构变化需要被有效捕捉。
- Method: 使用面部关键点作为图的顶点，基于邻近性和局部外观相似性确定边，结合视觉Transformer和图卷积网络。
- Result: 在三个基准数据集上分别达到98.09%、79.01%和56.39%的识别准确率。
- Conclusion: Exp-Graph在实验室和真实环境中均表现出强大的泛化能力，适用于实际应用。


### [32] [Depthwise-Dilated Convolutional Adapters for Medical Object Tracking and Segmentation Using the Segment Anything Model 2](https://arxiv.org/abs/2507.14613)
*Guoping Xu,Christopher Kabat,You Zhang*

Main category: cs.CV

TL;DR: 提出DD-SAM2框架，通过Depthwise-Dilated Adapter高效适配SAM2模型，用于医学视频分割与追踪，减少计算成本并提升性能。

- Motivation: 现有医学图像分割方法多为模态特定设计，适应性差，且SAM2等模型在医学视频场景中需大规模数据集，计算成本高。
- Method: 引入Depthwise-Dilated Adapter（DD-Adapter）增强多尺度特征提取，实现有限数据下的高效微调。
- Result: 在TrackRad2025和EchoNet-Dynamic数据集上分别达到Dice分数0.93和0.97。
- Conclusion: DD-SAM2为医学视频分割与追踪提供了一种高效适配方案，代码与模型将开源。


### [33] [BusterX++: Towards Unified Cross-Modal AI-Generated Content Detection and Explanation with MLLM](https://arxiv.org/abs/2507.14632)
*Haiquan Wen,Tianxiao Li,Zhenglin Huang,Yiwei He,Guangliang Cheng*

Main category: cs.CV

TL;DR: BusterX++是一个新型跨模态检测框架，通过强化学习后训练策略和多阶段训练，显著提升了合成媒体的检测性能。

- Motivation: 生成式AI的快速发展导致合成媒体风险增加，现有单模态检测方法难以应对跨模态合成内容。
- Method: 采用强化学习后训练策略，结合多阶段训练、思维奖励和混合推理，设计BusterX++框架。
- Result: 实验证明BusterX++在跨模态检测任务中表现优异，并提出了高质量基准GenBuster++。
- Conclusion: BusterX++为合成媒体的跨模态检测提供了有效解决方案，具有实际应用潜力。


### [34] [Multispectral State-Space Feature Fusion: Bridging Shared and Cross-Parametric Interactions for Object Detection](https://arxiv.org/abs/2507.14643)
*Jifeng Shen,Haibo Zhan,Shaohua Dong,Xin Zuo,Wankou Yang,Haibin Ling*

Main category: cs.CV

TL;DR: 论文提出了一种基于状态空间模型的多光谱特征融合框架MS2Fusion，通过双路径参数交互机制解决现有方法在局部互补特征和跨模态共享语义上的局限性，并在多个基准测试中表现优异。

- Motivation: 解决多光谱特征融合中的两个关键问题：过度偏好局部互补特征而忽视跨模态共享语义，以及感受野大小与计算复杂度之间的权衡。
- Method: 提出MS2Fusion框架，采用双路径参数交互机制：一条路径通过跨模态隐藏状态解码挖掘互补信息，另一条路径通过参数共享探索跨模态对齐。
- Result: 在FLIR、M3FD和LLVIP等基准测试中显著优于现有方法，并在RGB-T语义分割和RGBT显著目标检测任务中表现出通用性。
- Conclusion: MS2Fusion框架在多光谱特征融合中实现了功能互补和共享语义空间的统一，具有高效性和通用性。


### [35] [AI-Powered Precision in Sport Taekwondo: Enhancing Fairness, Speed, and Trust in Competition (FST.ai)](https://arxiv.org/abs/2507.14657)
*Keivan Shariatmadar,Ahmad Osman*

Main category: cs.CV

TL;DR: FST.ai是一个基于AI的框架，用于提升体育裁判的效率和公平性，特别针对跆拳道中的实时头部踢击检测和评分。

- Motivation: 传统裁判系统存在延迟、主观性和不一致的问题，影响公平性和运动员信任。
- Method: 结合计算机视觉、深度学习和边缘推断技术，实现动作的自动识别与分类。
- Result: 将决策时间从分钟缩短到秒，提高一致性和透明度。
- Conclusion: FST.ai框架具有鲁棒性和可扩展性，适用于多种体育项目。


### [36] [Artificial Intelligence in the Food Industry: Food Waste Estimation based on Computer Vision, a Brief Case Study in a University Dining Hall](https://arxiv.org/abs/2507.14662)
*Shayan Rokhva,Babak Teimourpour*

Main category: cs.CV

TL;DR: 提出了一种基于计算机视觉的成本效益高的框架，用于估计餐盘级食物浪费，通过语义分割RGB图像评估五种伊朗菜肴的浪费情况。

- Motivation: 量化机构餐饮环境中的食物浪费，支持数据驱动的可持续发展策略。
- Method: 使用四种全监督模型（U-Net、U-Net++及其轻量变体），采用动态逆频率损失和AdamW优化器，通过多种指标评估性能。
- Result: 所有模型表现良好，至少一种模型对每种食物类型的DPA接近或超过90%，轻量模型实现实时推理。
- Conclusion: 该框架为大规模餐饮环境中的实时浪费追踪系统奠定了基础，并提供了可行的未来方向。


### [37] [Gene-DML: Dual-Pathway Multi-Level Discrimination for Gene Expression Prediction from Histopathology Images](https://arxiv.org/abs/2507.14670)
*Yaxuan Song,Jianan Fan,Hang Chang,Weidong Cai*

Main category: cs.CV

TL;DR: Gene-DML通过双路径多级判别增强组织病理学图像与基因表达谱的跨模态对齐，提升基因表达预测性能。

- Motivation: 现有方法未能充分利用组织病理学图像与基因表达谱的多层次跨模态对齐，限制了预测性能。
- Method: 提出Gene-DML框架，通过双路径多级判别（多尺度实例级判别和跨级实例组判别）增强形态与转录模态的对应关系。
- Result: 在公共空间转录组数据集上，Gene-DML实现了最先进的基因表达预测性能。
- Conclusion: Gene-DML通过联合建模细粒度和结构级判别，提升了预测准确性和泛化能力。


### [38] [Docopilot: Improving Multimodal Models for Document-Level Understanding](https://arxiv.org/abs/2507.14675)
*Yuchen Duan,Zhe Chen,Yusong Hu,Weiyun Wang,Shenglong Ye,Botian Shi,Lewei Lu,Qibin Hou,Tong Lu,Hongsheng Li,Jifeng Dai,Wenhai Wang*

Main category: cs.CV

TL;DR: 论文提出了Doc-750K数据集和Docopilot模型，解决了多模态大语言模型在复杂文档理解中的不足，无需依赖检索增强生成方法。

- Motivation: 当前多模态大语言模型在复杂、多页文档理解上表现不佳，主要由于缺乏高质量的文档级数据集，且现有检索增强生成方法存在上下文碎片化、多阶段误差累积等问题。
- Method: 构建了Doc-750K数据集，包含多样文档结构和跨页依赖关系，并开发了原生多模态模型Docopilot，直接处理文档级依赖。
- Result: Docopilot在文档理解任务和多轮交互中表现出更高的连贯性、准确性和效率，为文档级多模态理解设定了新基准。
- Conclusion: Doc-750K和Docopilot为复杂文档理解提供了有效解决方案，显著提升了性能，并开源了数据、代码和模型。


### [39] [WSI-Agents: A Collaborative Multi-Agent System for Multi-Modal Whole Slide Image Analysis](https://arxiv.org/abs/2507.14680)
*Xinheng Lyu,Yuci Liang,Wenting Chen,Meidan Ding,Jiaqi Yang,Guolin Huang,Daokun Zhang,Xiangjian He,Linlin Shen*

Main category: cs.CV

TL;DR: WSI-Agents是一种新型协作多代理系统，用于多模态WSI分析，通过任务分配、验证和总结模块提升准确性和多功能性。

- Motivation: 解决多模态大语言模型（MLLMs）在WSI分析中表现不如任务专用模型的问题，探索协作多代理系统在病理学领域的潜力。
- Method: WSI-Agents包含三个组件：任务分配模块（使用模型库分配任务）、验证机制（通过一致性检查和外部验证确保准确性）和总结模块（生成最终摘要和视觉解释图）。
- Result: 在多种任务上，WSI-Agents优于现有的WSI MLLMs和医疗代理框架。
- Conclusion: WSI-Agents通过协作多代理系统实现了任务专用准确性和多任务多功能性的平衡，为病理学领域提供了高效解决方案。


### [40] [From Semantics, Scene to Instance-awareness: Distilling Foundation Model for Open-vocabulary Situation Recognition](https://arxiv.org/abs/2507.14686)
*Chen Cai,Tianyi Liu,Jianjun Gao,Wenyang Liu,Kejun Wu,Ruoyu Wang,Yi Wang,Soo Chin Liew*

Main category: cs.CV

TL;DR: 该论文提出了一种名为MIPD的新框架，通过从多模态大语言模型（MLLM）中蒸馏知识，提升小规模GSR模型的泛化和零样本能力，解决了复杂Grounded Situation Recognition（GSR）任务中的资源消耗和泛化不足问题。

- Motivation: 现有的MLLMs在零样本能力上表现优异，但在复杂GSR任务中资源消耗大且泛化能力不足；传统GSR模型则难以识别未见和罕见场景。
- Method: 提出了Multimodal Interactive Prompt Distillation（MIPD）框架，通过LLM生成的理性判断（JRG）和场景感知提示，对齐视觉信息并蒸馏知识到学生模型。
- Result: 在Ov-SWiG和HICO-DET数据集上，MIPD在可见、罕见和未见场景中均表现优异，并提升了未见场景的检测能力。
- Conclusion: MIPD通过知识蒸馏和提示对齐，显著提升了小规模GSR模型的泛化和零样本能力，为复杂场景理解提供了有效解决方案。


### [41] [GTPBD: A Fine-Grained Global Terraced Parcel and Boundary Dataset](https://arxiv.org/abs/2507.14697)
*Zhiwei Zhang,Zi Ye,Yibin Wen,Shuai Yuan,Haohuan Fu,Jianxi Huang,Juepeng Zheng*

Main category: cs.CV

TL;DR: 论文介绍了首个全球梯田地块精细数据集GTPBD，覆盖复杂梯田地形，支持多种任务，填补了梯田遥感研究的空白。

- Motivation: 现有农业地块提取研究多关注中分辨率或平原农田，缺乏对复杂梯田地形的精细表达，难以满足精准农业需求。
- Method: 构建了包含20万+复杂梯田地块的GTPBD数据集，提供三级标注（边界、掩码、地块），并覆盖全球多气候区域。
- Result: GTPBD在语义分割、边缘检测、地块提取和无监督域适应任务中表现出挑战性，并通过多维评估框架验证其有效性。
- Conclusion: GTPBD填补了梯田遥感研究的空白，为精细农业地形分析和跨场景知识迁移提供了基础支持。


### [42] [MultiRetNet: A Multimodal Vision Model and Deferral System for Staging Diabetic Retinopathy](https://arxiv.org/abs/2507.14738)
*Jeannie She,Katie Spivakovsky*

Main category: cs.CV

TL;DR: MultiRetNet结合视网膜成像、社会经济因素和共病情况，通过多模态融合和临床延迟系统提高糖尿病视网膜病变（DR）分期准确性，尤其针对低收入人群。

- Motivation: 糖尿病视网膜病变是全球可预防失明的主要原因，低收入人群因筛查受限更易进展至晚期。共病条件加速病情发展，需改进早期检测方法。
- Method: 提出MultiRetNet，整合视网膜成像、社会经济因素和共病数据，采用三种多模态融合方法，并通过全连接层实现最优融合。结合对抗性低质量图像和对比学习训练延迟系统，识别需临床复查的样本。
- Result: 全连接层融合方法表现最佳，系统在低质量图像上保持诊断准确性，整合关键健康数据可提高早期检测率。
- Conclusion: MultiRetNet可降低医疗成本，提高早期检测率，减少医疗资源分配不均，促进医疗公平。


### [43] [InterAct-Video: Reasoning-Rich Video QA for Urban Traffic](https://arxiv.org/abs/2507.14743)
*Joseph Raj Vishal,Rutuja Patil,Manas Srinivas Gowda,Katha Naik,Yezhou Yang,Bharatesh Chakravarthi*

Main category: cs.CV

TL;DR: 论文提出InterAct VideoQA数据集，用于提升视频问答模型在复杂交通场景中的表现，包含8小时真实交通视频和25,000个问答对。

- Motivation: 现有视频问答模型难以处理真实交通场景的复杂性，需要领域专用数据集来提升性能。
- Method: 构建InterAct VideoQA数据集，包含多样化的交通视频和问答对，并评估现有模型在该数据集上的表现。
- Result: 模型在InterAct VideoQA上表现不佳，但经过微调后性能显著提升。
- Conclusion: 领域专用数据集对提升视频问答模型在交通监控中的性能至关重要，InterAct VideoQA为未来研究提供了基准。


### [44] [LeAdQA: LLM-Driven Context-Aware Temporal Grounding for Video Question Answering](https://arxiv.org/abs/2507.14784)
*Xinxin Dong,Baoyun Peng,Haokai Ma,Yufei Wang,Zixuan Dong,Fei Hu,Xiaodong Wang*

Main category: cs.CV

TL;DR: LeAdQA通过结合因果感知查询优化和细粒度视觉定位，解决了视频问答中关键帧稀疏和复杂推理的挑战，实现了SOTA性能。

- Motivation: 当前视频问答方法存在任务无关采样和启发式检索的局限性，无法有效捕捉关键事件和因果-时间结构。
- Method: 利用LLM优化问题-选项对以消除因果模糊性，再通过时间定位模型精准检索关键片段，最后通过MLLM生成答案。
- Result: 在NExT-QA、IntentQA和NExT-GQA数据集上实现了SOTA性能，同时保持计算效率。
- Conclusion: LeAdQA通过因果感知和视觉定位的协同作用，显著提升了复杂推理任务的性能。


### [45] [FOCUS: Fused Observation of Channels for Unveiling Spectra](https://arxiv.org/abs/2507.14787)
*Xi Xiao,Aristeidis Tsaris,Anika Tabassum,John Lagergren,Larry M. York,Tianyang Wang,Xiao Wang*

Main category: cs.CV

TL;DR: FOCUS框架首次实现了对冻结Vision Transformers（ViTs）的高效空间-光谱可解释性，解决了现有方法在HSI数据中的挑战。

- Motivation: 由于现有显著性方法难以捕捉有意义的频谱线索且计算成本高，HSI数据中的ViT可解释性研究不足。
- Method: FOCUS引入类特定频谱提示和可学习的[SINK]令牌，通过单次前向传递生成稳定的3D显著性图和频谱重要性曲线。
- Result: FOCUS将波段级IoU提高15%，减少注意力崩溃40%以上，且结果与专家标注高度一致。
- Conclusion: FOCUS以不到1%的参数开销，为真实世界的HSI应用提供了实用的高分辨率ViT可解释性。


### [46] [A Novel Downsampling Strategy Based on Information Complementarity for Medical Image Segmentation](https://arxiv.org/abs/2507.14790)
*Wenbo Yue,Chang Li,Guoping Xu*

Main category: cs.CV

TL;DR: 提出了一种基于信息互补的下采样方法HPD，通过MinMaxPooling替代传统方法，有效保留图像细节特征，提升语义分割性能。

- Motivation: 传统下采样方法可能导致关键空间信息丢失，影响像素级预测精度。
- Method: 使用MinMaxPooling提取局部区域的最大值信息，保留图像明暗对比和细节特征。
- Result: 在ACDC和Synapse数据集上，HPD比传统方法表现更好，DSC系数平均提高0.5%。
- Conclusion: HPD模块为语义分割任务提供了高效解决方案。


### [47] [Distilling Parallel Gradients for Fast ODE Solvers of Diffusion Models](https://arxiv.org/abs/2507.14797)
*Beier Zhu,Ruoyu Wang,Tong Zhao,Hanwang Zhang,Chi Zhang*

Main category: cs.CV

TL;DR: 提出了一种名为EPD的新型ODE求解器，通过并行梯度评估减少截断误差，实现高质量低延迟采样。

- Motivation: 扩散模型因顺序去噪导致采样延迟高，现有加速方法在低延迟下图像质量下降。
- Method: EPD通过并行梯度评估优化可学习参数，可作为插件提升现有ODE采样器。
- Result: 在5 NFE延迟下，EPD在多个数据集上FID显著优于现有方法。
- Conclusion: EPD在低延迟下保持高质量采样，适用于多种图像合成任务。


### [48] [An Evaluation of DUSt3R/MASt3R/VGGT 3D Reconstruction on Photogrammetric Aerial Blocks](https://arxiv.org/abs/2507.14798)
*Xinyi Wu,Steven Landgraf,Markus Ulrich,Rongjun Qin*

Main category: cs.CV

TL;DR: 论文评估了DUSt3R、MASt3R和VGGT模型在航拍图像上的表现，发现它们能从极稀疏图像集（少于10张）中准确重建密集点云，但高分辨率和大图像集下表现受限。

- Motivation: 探索基于Transformer的3D重建模型在航拍图像上的潜力，尤其是处理稀疏图像重叠、遮挡和无纹理区域的能力。
- Method: 在UseGeo数据集的航拍图像块上对预训练的DUSt3R、MASt3R和VGGT模型进行姿态估计和密集3D重建的全面评估。
- Result: 这些方法能从极稀疏图像集（分辨率最高518像素）中重建密集点云，完整性比COLMAP提高50%，VGGT计算效率更高。但高分辨率和大图像集下姿态估计可靠性下降。
- Conclusion: Transformer方法尚无法完全替代传统SfM和MVS，但在低分辨率、稀疏场景中可作为补充方案。


### [49] [Exploring Scalable Unified Modeling for General Low-Level Vision](https://arxiv.org/abs/2507.14801)
*Xiangyu Chen,Kaiwen Zhu,Yuandong Pu,Shuo Cao,Xiaohui Li,Wenlong Zhang,Yihao Liu,Yu Qiao,Jiantao Zhou,Chao Dong*

Main category: cs.CV

TL;DR: 提出了一种基于视觉提示的统一低层视觉任务框架VPIP，通过输入-目标图像对作为视觉提示，支持多种任务。模型GenLV在多任务基准测试中表现优异，展示了可扩展性和泛化能力。

- Motivation: 解决低层视觉任务（如图像修复、增强、风格化等）因任务形式和输出域差异大而难以统一建模的挑战。
- Method: 设计VPIP框架，包含图像处理主干、提示编码器和提示交互模块，支持多种架构和任务特定表示。开发统一模型GenLV，并在大规模任务基准上测试其性能。
- Result: 模型在多任务中表现优异，增加训练任务数量能提升泛化能力，尤其在数据有限的任务中。零样本、少样本和微调场景下均表现出强适应性。
- Conclusion: VPIP框架作为统一低层视觉建模基础，具有高效性、可扩展性和潜力。


### [50] [Seeing Through Deepfakes: A Human-Inspired Framework for Multi-Face Detection](https://arxiv.org/abs/2507.14807)
*Juan Hu,Shaojing Fan,Terence Sim*

Main category: cs.CV

TL;DR: 论文提出了一种基于人类认知的多脸深度伪造视频检测方法HICOM，通过分析人类依赖的四种关键线索，显著提升了检测准确性和泛化能力。

- Motivation: 现有的深度伪造检测方法在单脸场景表现良好，但在多脸场景中因缺乏上下文线索而表现不佳。
- Method: 通过人类研究识别四种关键线索（场景-运动一致性、面部外观兼容性、人际注视对齐和面部-身体一致性），并开发了HICOM框架。
- Result: HICOM在基准数据集上平均准确率提升3.3%，在真实世界扰动下提升2.8%，在未见数据集上优于现有方法5.8%。
- Conclusion: HICOM通过结合人类认知线索和可解释性设计，为多脸深度伪造检测提供了有效且透明的解决方案。


### [51] [Light Future: Multimodal Action Frame Prediction via InstructPix2Pix](https://arxiv.org/abs/2507.14809)
*Zesen Zhong,Duomin Zhang,Yijia Li*

Main category: cs.CV

TL;DR: 提出了一种轻量级机器人动作预测方法，利用InstructPix2Pix模型进行多模态未来帧预测，显著降低计算成本和延迟。

- Motivation: 预测未来运动轨迹对机器人、自动驾驶等领域至关重要，但现有视频预测模型计算成本高且延迟大。
- Method: 基于InstructPix2Pix模型，结合视觉和文本输入，实现多模态未来帧预测。
- Result: 在RoboTWin数据集上，SSIM和PSNR优于现有方法，且仅需单张图像和文本输入。
- Conclusion: 该方法轻量高效，适用于机器人动作预测等对精度要求高的场景。


### [52] [SegQuant: A Semantics-Aware and Generalizable Quantization Framework for Diffusion Models](https://arxiv.org/abs/2507.14811)
*Jiaji Zhang,Ruichao Sun,Hailiang Zhao,Jiaju Wu,Peng Chen,Hao Li,Xinkui Zhao,Kingsum Chow,Gang Xiong,Lin Ye,Shuiguang Deng*

Main category: cs.CV

TL;DR: SegQuant是一个统一的量化框架，通过自适应结合互补技术提升扩散模型的跨模型通用性，解决了现有后训练量化方法的局限性。

- Motivation: 扩散模型计算密集，资源受限或延迟敏感环境中部署困难，现有后训练量化方法通用性不足。
- Method: 提出SegQuant框架，包含SegLinear（分段感知、基于图的量化策略）和DualScale（双尺度量化方案）。
- Result: SegQuant在保持生成输出视觉保真度的同时，广泛适用于非Transformer扩散模型，并与主流部署工具兼容。
- Conclusion: SegQuant为扩散模型提供了一种高效、通用的量化解决方案，适用于工业部署。


### [53] [FinChart-Bench: Benchmarking Financial Chart Comprehension in Vision-Language Models](https://arxiv.org/abs/2507.14823)
*Dong Shu,Haoyang Yuan,Yuchen Wang,Yanguang Liu,Huopu Zhang,Haiyan Zhao,Mengnan Du*

Main category: cs.CV

TL;DR: FinChart-Bench是首个专注于真实世界金融图表的基准测试，包含1200张图表和7016个问题。评估了25种LVLM，揭示了性能差距缩小、模型升级后性能下降、指令遵循困难、空间推理能力不足以及可靠性不足等关键问题。

- Motivation: 金融图表因其复杂的时间结构和领域特定术语而未被充分研究，因此需要专门的基准测试来评估LVLM的性能。
- Method: 收集2015至2024年的1200张金融图表，标注为TF、MC和QA问题，共7016个问题，评估25种LVLM。
- Result: 发现开源与闭源模型性能差距缩小、升级模型性能下降、指令遵循困难、空间推理能力不足、模型可靠性不足。
- Conclusion: 当前LVLM在金融图表理解方面存在显著局限性，FinChart-Bench为未来研究提供了重要基准。


### [54] [PHATNet: A Physics-guided Haze Transfer Network for Domain-adaptive Real-world Image Dehazing](https://arxiv.org/abs/2507.14826)
*Fu-Jen Tsai,Yan-Tsung Peng,Yen-Yu Lin,Chia-Wen Lin*

Main category: cs.CV

TL;DR: 论文提出了一种基于物理引导的雾霾转移网络（PHATNet），用于提升去雾模型在未见真实场景中的适应性。

- Motivation: 现有去雾模型在未见真实雾霾图像上性能下降，因训练数据有限。
- Method: PHATNet通过将目标域的雾霾模式转移到源域无雾图像上，生成特定域微调集，并引入雾霾转移一致性和内容泄漏损失以增强解耦能力。
- Result: 实验表明PHATNet显著提升了现有去雾模型在真实场景数据集上的性能。
- Conclusion: PHATNet通过域适应方法有效提升了去雾模型在未见场景中的表现。


### [55] [Paired Image Generation with Diffusion-Guided Diffusion Models](https://arxiv.org/abs/2507.14833)
*Haoxuan Zhang,Wenju Cui,Yuzhu Cao,Tao Tan,Jie Liu,Yunsong Peng,Jian Zheng*

Main category: cs.CV

TL;DR: 提出了一种用于数字乳腺断层合成（DBT）图像中肿块分割的配对图像生成方法，解决了现有扩散模型在生成高质量肿块区域和对应标注方面的不足。

- Motivation: 高密度乳腺组织导致肿块区域隐蔽，人工标注困难且耗时，缺乏标注数据用于模型训练。
- Method: 通过训练额外的扩散引导器，实现条件扩散模型的配对图像生成，无需外部条件。
- Result: 实验表明，该方法提高了生成质量，缓解了标注数据短缺问题，并提升了下游任务的性能。
- Conclusion: 该方法无需外部条件即可生成高质量配对图像，有效支持肿块分割任务的监督训练。


### [56] [Training Self-Supervised Depth Completion Using Sparse Measurements and a Single Image](https://arxiv.org/abs/2507.14845)
*Rizhao Fan,Zhigen Li,Heping Li,Ning An*

Main category: cs.CV

TL;DR: 提出了一种新的自监督深度补全方法，仅需稀疏深度测量和对应图像，无需密集标签或多帧数据。

- Motivation: 解决现有方法依赖密集标注或多帧数据的局限性，降低数据获取成本并扩展应用场景。
- Method: 利用深度分布特性设计新损失函数，结合视觉基础模型的分割图增强深度估计。
- Result: 实验验证了方法的有效性。
- Conclusion: 该方法在自监督深度补全中表现优异，适用于静态或单帧场景。


### [57] [Grounding Degradations in Natural Language for All-In-One Video Restoration](https://arxiv.org/abs/2507.14851)
*Muhammad Kamran Janjua,Amirhosein Ghasemabadi,Kunlin Zhang,Mohammad Salameh,Chao Gao,Di Niu*

Main category: cs.CV

TL;DR: 提出了一种基于自然语言的视频修复框架，利用基础模型提供可解释和灵活的指导，无需预知退化类型，并在推理时无额外成本。同时呼吁标准化多退化视频修复基准，并提出了新的数据集。

- Motivation: 现有视频修复方法通常需要预知退化类型，限制了灵活性和实用性。本文旨在通过自然语言和基础模型实现无需退化知识的视频修复。
- Method: 利用基础模型学习退化感知的语义上下文，无需训练或测试时退化知识，并在推理时解耦基础模型以减少成本。
- Result: 在多退化基准测试中取得了最先进的性能，包括提出的新数据集（如动态雪强度退化）。
- Conclusion: 提出的框架在无需退化知识的情况下实现了高性能视频修复，同时推动了标准化基准的建立。


### [58] [An Uncertainty-aware DETR Enhancement Framework for Object Detection](https://arxiv.org/abs/2507.14855)
*Xingshu Chen,Sicheng Yu,Chong Cheng,Hao Wang,Ting Tian*

Main category: cs.CV

TL;DR: 本文提出了一种基于DETR的不确定性感知增强框架，通过建模边界框为高斯分布并引入Gromov-Wasserstein距离，提升了定位精度和预测可靠性。

- Motivation: 传统检测器依赖确定性边界框回归，忽略了预测的不确定性，限制了模型的鲁棒性。
- Method: 将边界框建模为多元高斯分布，引入Gromov-Wasserstein距离损失函数，并提出贝叶斯风险公式过滤高风险信息。
- Result: 在COCO基准测试中表现优异，并在白细胞检测任务中达到SOTA。
- Conclusion: 框架在通用和特定领域检测任务中均具有可扩展性。


### [59] [Hybrid-supervised Hypergraph-enhanced Transformer for Micro-gesture Based Emotion Recognition](https://arxiv.org/abs/2507.14867)
*Zhaoqiang Xia,Hexiang Huang,Haoyu Chen,Xiaoyi Feng,Guoying Zhao*

Main category: cs.CV

TL;DR: 本文提出了一种基于超图增强Transformer的混合监督框架，用于通过微手势识别人类情绪状态。

- Motivation: 微手势作为无意识的身体动作，能够传达人类情绪状态，但在情绪建模方面研究不足。
- Method: 采用超图增强的Transformer编码器和解码器，结合自监督和监督学习，捕捉微手势的细微动作。
- Result: 在两个公开数据集（iMiGUE和SMG）上表现最佳，优于现有方法。
- Conclusion: 该方法通过混合监督框架有效建模微手势与情绪的关系，提升了情绪识别性能。


### [60] [Region-aware Depth Scale Adaptation with Sparse Measurements](https://arxiv.org/abs/2507.14879)
*Rizhao Fan,Tianfang Ma,Zhigen Li,Ning An,Jian Cheng*

Main category: cs.CV

TL;DR: 提出一种无需训练或微调的方法，利用稀疏深度测量将基础模型的相对深度预测转换为度量深度，保持模型的泛化能力。

- Motivation: 解决基础模型在零样本单目深度估计中输出相对深度而非度量深度的问题，避免现有方法的高成本和泛化能力损失。
- Method: 采用非学习的方法，利用稀疏深度测量将相对深度预测转换为度量深度，无需额外训练或微调。
- Result: 实验证明该方法有效，能在不增加计算成本或牺牲泛化能力的情况下实现度量深度预测。
- Conclusion: 该方法成功填补了相对深度与度量深度之间的鸿沟，具有实际应用潜力。


### [61] [BeatFormer: Efficient motion-robust remote heart rate estimation through unsupervised spectral zoomed attention filters](https://arxiv.org/abs/2507.14885)
*Joaquim Comas,Federico Sukno*

Main category: cs.CV

TL;DR: BeatFormer是一个轻量级的光谱注意力模型，结合了手工方法和深度学习的优势，用于远程光电容积描记（rPPG）估计，并通过光谱对比学习（SCL）实现无监督训练。

- Motivation: 当前rPPG估计方法中，手工方法依赖生理先验但性能有限，深度学习需要大量数据且泛化能力不足，因此需要结合两者优势。
- Method: 提出BeatFormer模型，整合了放大的正交复数注意力和频域能量测量，并引入SCL实现无监督训练。
- Result: 在PURE、UBFC-rPPG和MMPD数据集上验证了BeatFormer的鲁棒性和性能，尤其在运动场景下的跨数据集评估中表现优异。
- Conclusion: BeatFormer通过结合手工方法和深度学习的优势，提供了一种高效且鲁棒的rPPG估计解决方案。


### [62] [TriCLIP-3D: A Unified Parameter-Efficient Framework for Tri-Modal 3D Visual Grounding based on CLIP](https://arxiv.org/abs/2507.14904)
*Fan Li,Zanyi Wang,Zeyi Huang,Guang Dai,Jingdong Wang,Mengmeng Wang*

Main category: cs.CV

TL;DR: 提出了一种基于统一2D预训练多模态网络的3D视觉定位方法，简化架构并提升性能。

- Motivation: 现有方法依赖多模态分离编码器，导致模型复杂且训练低效。
- Method: 利用2D CLIP双模态模型，通过适配器微调适应三模态设置，并设计GARF模块融合几何特征。
- Result: 参数量减少58%，3D检测任务提升6.52%，3D视觉定位任务提升6.25%。
- Conclusion: 统一多模态特征提取与融合方法显著简化模型并提升性能。


### [63] [Semantic-Aware Representation Learning for Multi-label Image Classification](https://arxiv.org/abs/2507.14918)
*Ren-Dong Xie,Zhi-Fen He,Bo Li,Bin Liu,Jin-Yan Hu*

Main category: cs.CV

TL;DR: 提出了一种语义感知表示学习（SARL）方法，用于多标签图像分类，通过语义相关特征学习和最优传输注意力机制提升性能。

- Motivation: 现有方法（如注意力机制或图卷积网络）在图像表示中可能存在噪声且定位不精确。
- Method: 1. 使用标签语义相关特征学习模块提取特征；2. 设计基于最优传输的注意力机制；3. 采用区域分数聚合策略进行多标签预测。
- Result: 在PASCAL VOC 2007和MS-COCO数据集上，SARL优于现有方法。
- Conclusion: SARL通过语义对齐和精确表示学习，显著提升了多标签图像分类的性能。


### [64] [Stereo-GS: Multi-View Stereo Vision Model for Generalizable 3D Gaussian Splatting Reconstruction](https://arxiv.org/abs/2507.14921)
*Xiufeng Huang,Ka Chun Cheung,Runmin Cong,Simon See,Renjie Wan*

Main category: cs.CV

TL;DR: 提出了一种解耦框架\method，用于高效预测3D高斯，通过立体视觉提取特征并融合，实现无姿态的高质量3D重建。

- Motivation: 现有方法在3D高斯几何和外观预测上耦合，依赖数据驱动先验且回归速度慢，计算资源需求高。
- Method: 使用立体视觉骨干提取局部图像对特征，通过全局注意力块融合，生成几何的多视点点图和外观的高斯特征，结合为GS-map表示3DGS对象，并通过细化网络提升重建质量。
- Result: 实现了无姿态的3D重建，提高了鲁棒性和实用性，同时减少了资源需求。
- Conclusion: \method为现实世界3D内容生成提供了高效、可扩展的解决方案。


### [65] [3-Dimensional CryoEM Pose Estimation and Shift Correction Pipeline](https://arxiv.org/abs/2507.14924)
*Kaishva Chintan Shah,Virajith Boddapati,Karthik S. Gurumoorthy,Sandip Kaledhonkar,Ajit Rajwade*

Main category: cs.CV

TL;DR: 提出了一种基于多维尺度分析（MDS）的稳健方法，用于冷冻电镜中的姿态估计，通过联合优化和迭代平移校正提高重建精度。

- Motivation: 冷冻电镜中极低信噪比（SNR）导致姿态估计和位移校正困难，直接影响3D重建的准确性。
- Method: 使用MDS技术从二面角对估计旋转矩阵，引入基于ℓ1范数的联合优化框架和迭代平移校正算法，严格满足几何约束。
- Result: 方法在欧拉角精度和重建保真度（通过FSC测量）上均优于现有方法。
- Conclusion: 提出的稳健方法在低SNR条件下显著提升了冷冻电镜的姿态估计和重建质量。


### [66] [Probabilistic smooth attention for deep multiple instance learning in medical imaging](https://arxiv.org/abs/2507.14932)
*Francisco M. Castro-Macías,Pablo Morales-Álvarez,Yunan Wu,Rafael Molina,Aggelos K. Katsaggelos*

Main category: cs.CV

TL;DR: 提出了一种新的概率框架，用于多实例学习（MIL）中的注意力机制，通过估计注意力值的概率分布来捕捉不确定性，并在医学图像分类中表现优异。

- Motivation: 现有MIL方法将注意力值视为确定性，可能忽略个体实例贡献的不确定性，限制了模型的解释性和性能。
- Method: 提出了一种概率框架，估计注意力值的分布，同时考虑全局和局部交互。
- Result: 在三个医学数据集和11个基线模型的评估中，该方法在预测性能和不确定性解释方面表现最佳。
- Conclusion: 概率化注意力机制不仅提升了分类性能，还提供了可解释的不确定性图，有助于疾病定位。


### [67] [Open-set Cross Modal Generalization via Multimodal Unified Representation](https://arxiv.org/abs/2507.14935)
*Hai Huang,Yan Xia,Shulei Wang,Hanting Wang,Minghui Fang,Shengpeng Ji,Sashuai Zhou,Tao Jin,Zhou Zhao*

Main category: cs.CV

TL;DR: 论文提出开放集跨模态泛化任务（OSCMG），并设计MICU方法（包含FCMI和CUJP）来解决开放集环境下的多模态统一表示问题。

- Motivation: 现有跨模态泛化研究局限于封闭集环境，无法应对现实中的开放集场景，因此提出OSCMG任务以填补这一空白。
- Method: 提出MICU方法，包括FCMI（通过掩码对比学习增强多模态对齐）和CUJP（通过自监督学习增强特征多样性和模型不确定性）。
- Result: 在CMG和新提出的OSCMG任务上验证了方法的有效性。
- Conclusion: MICU方法在开放集跨模态泛化任务中表现优异，填补了现有研究的不足。


### [68] [Polymorph: Energy-Efficient Multi-Label Classification for Video Streams on Embedded Devices](https://arxiv.org/abs/2507.14959)
*Saeid Ghafouri,Mohsen Fayyaz,Xiangchen Li,Deepu John,Bo Ji,Dimitrios Nikolopoulos,Hans Vandierendonck*

Main category: cs.CV

TL;DR: Polymorph是一个实时多标签视频分类框架，通过动态激活轻量级适配器（LoRA）来优化嵌入式设备的计算和能耗。

- Motivation: 嵌入式设备在实时多标签视频分类中面临计算和能耗限制，而视频流的结构特性（如标签稀疏性、时间连续性和标签共现）可用于高效推理。
- Method: Polymorph利用上下文感知框架，每帧激活最小化的LoRA适配器集，每个适配器专注于共现模式中的子类，并作为共享主干的LoRA权重实现。运行时动态选择和组合所需适配器。
- Result: 在TAO数据集上，Polymorph能耗降低40%，mAP提升9个百分点。
- Conclusion: Polymorph通过模块化策略显著提升了嵌入式设备上视频分类的效率和性能。


### [69] [Decision PCR: Decision version of the Point Cloud Registration task](https://arxiv.org/abs/2507.14965)
*Yaojie Zhang,Tianlun Huang,Weijun Wang,Wei Feng*

Main category: cs.CV

TL;DR: 论文提出了一种基于深度学习的低重叠点云配准（PCR）评估方法，解决了传统指标在极低内点比例下失效的问题。

- Motivation: 传统评估指标在极低内点比例下效果不佳，论文重新审视了PCR任务，将其决策版本作为核心问题。
- Method: 构建基于3DMatch的数据集，训练深度学习分类器评估配准质量，并将其集成到标准PCR流程中。
- Result: 与现有SOTA方法结合后，在3DLoMatch基准上达到86.97%的配准召回率，并在ETH数据集上表现出强泛化能力。
- Conclusion: 论文首次通过深度学习框架解决了PCR决策任务，显著提升了配准性能。


### [70] [Hierarchical Cross-modal Prompt Learning for Vision-Language Models](https://arxiv.org/abs/2507.14976)
*Hao Zheng,Shunzhi Yang,Zhuoxin He,Jinfeng Yang,Zhenhua Huang*

Main category: cs.CV

TL;DR: HiCroPL是一种分层跨模态提示学习框架，通过双向知识流解决模态隔离和层次语义衰减问题，提升视觉语言模型的泛化能力。

- Motivation: 预训练视觉语言模型（如CLIP）在下游任务中难以保持泛化能力，现有提示学习方法存在模态隔离和层次语义衰减的瓶颈。
- Method: 提出HiCroPL框架，通过分层知识映射器和轻量级知识代理，实现文本和视觉模态的双向知识流动。
- Result: 在四个任务和11个基准测试中取得最优性能，显著提升泛化能力。
- Conclusion: HiCroPL通过双向知识流和多尺度语义融合，有效解决了模态隔离和语义衰减问题，提升了模型的泛化能力。


### [71] [Language Integration in Fine-Tuning Multimodal Large Language Models for Image-Based Regression](https://arxiv.org/abs/2507.14997)
*Roy H. Jennings,Genady Paikin,Roy Shaul,Evgeny Soloveichik*

Main category: cs.CV

TL;DR: 论文提出RvTC方法，通过灵活的基于分箱的分类替代预设词汇分类，显著提升图像回归任务性能，并证明数据特定提示的重要性。

- Motivation: 当前多模态大语言模型（MLLMs）在图像回归任务中表现不佳，预设词汇和通用提示无法利用文本输入的语义理解。
- Method: 提出Regression via Transformer-Based Classification (RvTC)，采用基于分箱的灵活分类方法，避免预设词汇限制，并通过数据特定提示提升性能。
- Result: 在四个图像评估数据集上达到最优性能，AVA数据集中添加挑战标题后相关性从0.83提升至0.90。
- Conclusion: 语义提示信息对MLLMs至关重要，强调了在多模态回归任务中融入有意义文本上下文的重要性。


### [72] [Axis-Aligned Document Dewarping](https://arxiv.org/abs/2507.15000)
*Chaoyun Wang,I-Chao Shen,Takeo Igarashi,Nanning Zheng,Caigui Jiang*

Main category: cs.CV

TL;DR: 提出了一种基于轴对齐几何约束的文档去扭曲方法，显著提升了性能。

- Motivation: 现有学习方法依赖标注数据，未充分利用文档的几何特性。
- Method: 在训练阶段引入轴对齐几何约束，推理阶段采用轴对齐预处理策略。
- Result: 在多个基准测试中达到SOTA，AAD指标提升18.2%~34.5%。
- Conclusion: 结合几何特性显著提升文档去扭曲效果。


### [73] [FastSmoothSAM: A Fast Smooth Method For Segment Anything Model](https://arxiv.org/abs/2507.15008)
*Jiasheng Xu,Yewang Chen*

Main category: cs.CV

TL;DR: 本文提出了一种基于B-Spline曲线拟合的新方法，用于改进FastSAM的边缘质量，解决了其生成的锯齿状边缘问题，同时保持实时处理能力。

- Motivation: FastSAM虽然实现了实时分割，但生成的边缘往往锯齿状，偏离真实物体形状，影响了分割的视觉质量和分析准确性。
- Method: 采用B-Spline曲线拟合技术，通过四阶段精炼过程（包括两轮曲线拟合）来平滑锯齿边缘。
- Result: 该方法显著提升了边缘的视觉质量和分析准确性，同时不牺牲实时处理能力。
- Conclusion: 通过改进FastSAM的边缘质量，该方法增强了其实用性，使其在工业自动化、医疗影像和自主系统等场景中更具潜力。


### [74] [Towards Video Thinking Test: A Holistic Benchmark for Advanced Video Reasoning and Understanding](https://arxiv.org/abs/2507.15028)
*Yuanhan Zhang,Yunice Chew,Yuhao Dong,Aria Leo,Bo Hu,Ziwei Liu*

Main category: cs.CV

TL;DR: 论文介绍了Video Thinking Test（Video-TT），用于评估视频大语言模型在理解和解释真实世界视频时的正确性和鲁棒性，发现其与人类表现存在显著差距。

- Motivation: 现有视频大语言模型在正确性和鲁棒性方面与人类智能存在差距，缺乏合适的评估基准。
- Method: 提出Video-TT，包含1000个YouTube Shorts视频，每个视频配有一个开放性问题及四个对抗性问题，用于评估视觉和叙事复杂性。
- Result: 评估显示视频大语言模型与人类表现之间存在显著差距。
- Conclusion: Video-TT揭示了视频大语言模型在复杂视觉叙事理解和对抗性问题处理上的不足，为未来研究提供了方向。


### [75] [OpenBreastUS: Benchmarking Neural Operators for Wave Imaging Using Breast Ultrasound Computed Tomography](https://arxiv.org/abs/2507.15035)
*Zhijun Zeng,Youjia Zheng,Hao Hu,Zeyuan Dong,Yihang Zheng,Xinliang Liu,Jinzhuo Wang,Zuoqiang Shi,Linfeng Zhang,Yubing Li,He Sun*

Main category: cs.CV

TL;DR: OpenBreastUS是一个大规模波动方程数据集，旨在解决传统数值求解器和现有神经算子在真实成像中的局限性，通过提供8000个解剖学真实的人体乳腺模型和1600万次频域波模拟，为神经PDE求解器的开发和实际医学成像应用提供了平台。

- Motivation: 传统波动方程数值求解器计算量大且不稳定，而现有神经算子数据集过于简化，无法满足真实成像需求。OpenBreastUS旨在填补理论与实际应用之间的差距。
- Method: 构建了包含8000个解剖学真实乳腺模型和1600万次频域波模拟的大规模数据集OpenBreastUS，用于评估神经算子在正向模拟和逆向成像任务中的性能。
- Result: OpenBreastUS首次实现了神经算子求解器在人体乳腺活体成像中的高效应用。
- Conclusion: OpenBreastUS为开发创新的神经PDE求解器并应用于实际医学成像问题提供了重要平台。


### [76] [EBA-AI: Ethics-Guided Bias-Aware AI for Efficient Underwater Image Enhancement and Coral Reef Monitoring](https://arxiv.org/abs/2507.15036)
*Lyes Saad Saoud,Irfan Hussain*

Main category: cs.CV

TL;DR: EBA-AI框架通过CLIP嵌入和自适应处理解决水下图像增强中的数据集偏差和高计算成本问题，平衡效率、公平性和可解释性。

- Motivation: 解决AI模型在水下图像增强中的数据集偏差、高计算成本和缺乏透明度问题，以支持可持续的海洋保护。
- Method: 利用CLIP嵌入检测和缓解数据集偏差，集成自适应处理优化能效，并引入不确定性估计和可解释性技术。
- Result: 在LSUI400、Oceanex和UIEB100数据集上，PSNR仅下降1.0 dB，但显著降低GPU使用率，实现实时可行性。
- Conclusion: EBA-AI在效率、公平性和可解释性方面表现优异，为可持续的海洋保护提供了有效的AI解决方案。


### [77] [OmniVTON: Training-Free Universal Virtual Try-On](https://arxiv.org/abs/2507.15037)
*Zhaotong Yang,Yuhui Li,Shengfeng He,Xinzhe Li,Yangyang Xu,Junyu Dong,Yong Du*

Main category: cs.CV

TL;DR: OmniVTON是一种无需训练的统一虚拟试穿框架，通过解耦服装和姿势条件，实现跨场景的高保真纹理和姿势一致性。

- Motivation: 现有虚拟试穿技术存在跨域泛化能力不足或数据偏差问题，需要一个统一的解决方案。
- Method: 提出服装先验生成机制和连续边界缝合技术以保留细节，利用DDIM反演实现精确姿势对齐。
- Result: 实验表明OmniVTON在多样化数据集和场景中表现优异，首次实现多人物虚拟试穿。
- Conclusion: OmniVTON通过解耦条件，解决了扩散模型在多条件处理中的偏差问题，具有广泛适用性。


### [78] [Rethinking Pan-sharpening: Principled Design, Unified Training, and a Universal Loss Surpass Brute-Force Scaling](https://arxiv.org/abs/2507.15059)
*Ran Zhang,Xuanhua He,Li Xueheng,Ke Cao,Liu Liu,Wenbo Xu,Fang Jiabin,Yang Qize,Jie Zhang*

Main category: cs.CV

TL;DR: 提出PanTiny，一种轻量级单步全色锐化框架，通过多数据集联合训练和复合损失函数，实现高效且泛化性强的性能。

- Motivation: 当前全色锐化模型趋向于庞大且复杂，计算开销高且泛化性差，PanTiny旨在解决这一问题。
- Method: 采用多数据集（WV2、WV3、GF2）联合训练和复合损失函数，设计轻量级单步框架。
- Result: PanTiny在性能和效率上优于大型专用模型，泛化能力显著提升。
- Conclusion: 通过模型设计、训练范式和损失函数的优化，PanTiny证明了轻量高效模型的潜力，呼吁社区关注高效泛化模型。


### [79] [StableAnimator++: Overcoming Pose Misalignment and Face Distortion for Human Image Animation](https://arxiv.org/abs/2507.15064)
*Shuyuan Tu,Zhen Xing,Xintong Han,Zhi-Qi Cheng,Qi Dai,Chong Luo,Zuxuan Wu,Yu-Gang Jiang*

Main category: cs.CV

TL;DR: StableAnimator++是一种基于视频扩散模型的框架，通过可学习的姿态对齐和身份保持技术，解决了现有方法在人体图像动画中身份一致性的问题。

- Motivation: 现有的人体图像动画扩散模型在参考图像和驱动视频差异较大时，难以保持身份一致性。
- Method: 提出了StableAnimator++框架，包含可学习的姿态对齐模块、全局内容感知的面部编码器和分布感知的身份适配器，并在推理阶段引入基于HJB的面部优化。
- Result: 实验证明，StableAnimator++在定性和定量上均表现出色，显著提升了身份一致性和生成质量。
- Conclusion: StableAnimator++通过创新的模块设计和优化策略，有效解决了身份一致性问题，为人体图像动画提供了高质量的解决方案。


### [80] [Aesthetics is Cheap, Show me the Text: An Empirical Evaluation of State-of-the-Art Generative Models for OCR](https://arxiv.org/abs/2507.15085)
*Peirong Zhang,Haowei Xu,Jiaxin Zhang,Guitao Xu,Xuhan Zheng,Zhenhua Yang,Junle Liu,Yuyi Zhang,Lianwen Jin*

Main category: cs.CV

TL;DR: 论文评估了当前最先进的生成模型在文本图像生成和编辑方面的能力，并提出了将其作为通用生成模型的基础技能的建议。

- Motivation: 研究动机是探讨专业图像生成器和统一生成模型是否能掌握文本图像生成和编辑的复杂性。
- Method: 方法包括选择33个代表性任务，分为五类，并评估六种模型在闭源和开源领域的表现。
- Result: 结果揭示了当前生成模型在OCR任务中的弱点。
- Conclusion: 结论认为应将逼真的文本图像生成和编辑作为通用生成模型的基础技能，而非依赖专业解决方案。


### [81] [Visual Place Recognition for Large-Scale UAV Applications](https://arxiv.org/abs/2507.15089)
*Ioannis Tsampikos Papapetros,Ioannis Kansizoglou,Antonios Gasteratos*

Main category: cs.CV

TL;DR: 论文提出LASED数据集和可转向CNN，提升无人机视觉地点识别的鲁棒性和泛化能力。

- Motivation: 解决无人机视觉地点识别中数据稀缺和旋转模糊性的问题。
- Method: 引入LASED大规模数据集，并采用可转向CNN处理旋转方差。
- Result: LASED训练模型召回率显著提升，可转向CNN平均提高12%召回率。
- Conclusion: 结合大规模数据集和旋转等变网络，显著提升无人机视觉地点识别的性能。


### [82] [BleedOrigin: Dynamic Bleeding Source Localization in Endoscopic Submucosal Dissection via Dual-Stage Detection and Tracking](https://arxiv.org/abs/2507.15094)
*Mengya Xu,Rulin Zhou,An Wang,Chaoyang Lyu,Zhen Li,Ning Zhong,Hongliang Ren*

Main category: cs.CV

TL;DR: 论文提出了首个ESD出血源数据集BleedOrigin-Bench和双阶段检测-跟踪框架BleedOrigin-Net，用于实时定位和跟踪出血源，显著提升了准确性和效率。

- Motivation: ESD手术中出血源的实时定位和持续监测对止血干预至关重要，但现有AI方法仅关注出血区域分割，缺乏对出血源准确检测和动态跟踪的能力。
- Method: 提出BleedOrigin-Bench数据集和BleedOrigin-Net框架，结合检测和跟踪技术，从出血开始检测到持续空间跟踪。
- Result: BleedOrigin-Net在出血开始检测、初始源定位和点跟踪方面分别达到96.85%、70.24%和96.11%的准确率。
- Conclusion: BleedOrigin-Net在ESD手术中实现了出血源的实时高精度定位和跟踪，填补了现有技术的空白。


### [83] [LoopNet: A Multitasking Few-Shot Learning Approach for Loop Closure in Large Scale SLAM](https://arxiv.org/abs/2507.15109)
*Mohammad-Maher Nakshbandi,Ziad Sharawy,Sorin Grigorescu*

Main category: cs.CV

TL;DR: LoopNet方法通过多任务ResNet架构和在线重训练，解决了SLAM闭环检测的准确性和实时计算问题，并引入新数据集LoopDB。

- Motivation: 解决SLAM闭环检测中的准确性和实时计算问题。
- Method: 基于多任务ResNet架构，采用在线重训练和few-shot学习，结合DISK描述符。
- Result: LoopNet在动态视觉数据集上表现优于传统方法，适应性强。
- Conclusion: LoopNet为嵌入式设备提供了高效的闭环检测解决方案，并开源了代码和数据集。


### [84] [Enhancing Visual Planning with Auxiliary Tasks and Multi-token Prediction](https://arxiv.org/abs/2507.15130)
*Ce Zhang,Yale Song,Ruta Desai,Michael Louis Iuzzolino,Joseph Tighe,Gedas Bertasius,Satwik Kottur*

Main category: cs.CV

TL;DR: VPA通过视频预测用户行为序列，提出辅助任务增强和多令牌预测方法，显著提升性能。

- Motivation: 解决视频规划任务中数据稀缺和结构化动作空间建模的挑战。
- Method: 引入辅助任务增强和多令牌预测，提升模型规划能力。
- Result: 在COIN和CrossTask数据集上性能提升7.3%和3.4%，在Ego4D任务中表现优异。
- Conclusion: VideoPlan方法有效解决了视频规划任务的核心挑战，性能领先。


### [85] [Event-based Graph Representation with Spatial and Motion Vectors for Asynchronous Object Detection](https://arxiv.org/abs/2507.15150)
*Aayush Atul Verma,Arpitsinh Vaghela,Bharatesh Chakravarthi,Kaustav Chanda,Yezhou Yang*

Main category: cs.CV

TL;DR: 提出了一种新颖的时空多图表示方法，用于更好地捕捉事件传感器的稀疏异步数据，提升下游任务性能。

- Motivation: 事件传感器数据稀疏且异步，传统方法将其转换为密集张量会削弱其优势，而现有图方法对时空动态建模不足。
- Method: 构建解耦的空间图（使用B样条基函数建模全局结构）和时间图（基于运动向量的注意力机制建模局部动态变化），替代昂贵的3D核。
- Result: 在Gen1和eTraM数据集上，检测精度提升6%，速度提升5倍，参数减少且计算成本不变。
- Conclusion: 结构化图建模有效提升了异步视觉任务的性能。


### [86] [MeshMamba: State Space Models for Articulated 3D Mesh Generation and Reconstruction](https://arxiv.org/abs/2507.15212)
*Yusuke Yoshiyasu,Leyuan Sun,Ryusuke Sagawa*

Main category: cs.CV

TL;DR: MeshMamba是一种基于Mamba-SSMs的神经网络模型，用于高效学习和生成3D关节网格模型，支持超过10,000个顶点的处理。

- Motivation: 解决传统方法在处理大规模3D网格数据时的效率和扩展性问题，特别是在生成和重建带有衣物和手部几何的复杂人体网格时。
- Method: 通过将网格顶点序列化为适合Mamba处理的顺序，并基于身体部位注释或模板网格的3D顶点位置进行排序。设计了MambaDiff3D（生成模型）和Mamba-HMR（重建模型）。
- Result: MambaDiff3D在生成带有衣物和手部的密集3D人体网格任务中表现优于现有方法；Mamba-HMR扩展了非参数化人体网格重建的能力，支持全身（包括面部和手部）的实时重建。
- Conclusion: MeshMamba及其衍生模型在3D人体网格生成和重建任务中表现出高效性和扩展性，为复杂几何处理提供了新思路。


### [87] [Improving Joint Embedding Predictive Architecture with Diffusion Noise](https://arxiv.org/abs/2507.15216)
*Yuping Qiu,Rui Zhu,Ying-cong Chen*

Main category: cs.CV

TL;DR: 论文提出N-JEPA方法，将扩散噪声引入掩码图像建模（MIM），以增强自监督学习的表示能力，并在下游分类任务中验证其有效性。

- Motivation: 自监督学习在特征学习中表现优异，但在图像生成和细节增强方面不如生成模型。结合两者的优势，进一步提升自监督学习的表示能力。
- Method: 提出N-JEPA方法，通过扩散噪声（视为掩码状态）与MIM结合，利用多级噪声调度增强模型鲁棒性。
- Result: 在下游分类任务中验证了方法的有效性。
- Conclusion: N-JEPA成功结合扩散噪声与MIM，增强了自监督学习的表示能力，为未来研究提供了新方向。


### [88] [Hierarchical Part-based Generative Model for Realistic 3D Blood Vessel](https://arxiv.org/abs/2507.15223)
*Siqi Chen,Guoqing Zhang,Jiahao Lai,Bingzhi Shen,Sihong Zhang,Caixia Dong,Xuejin Chen,Yang Li*

Main category: cs.CV

TL;DR: 提出了一种基于分层的3D血管生成框架，通过分离全局拓扑和局部几何细节，显著提升了复杂血管网络的建模效果。

- Motivation: 尽管3D视觉技术进步显著，但准确表示血管的复杂几何和拓扑结构仍具挑战性，因其分支模式、曲率和形状不规则。
- Method: 采用三阶段方法：1)生成关键图建模全局层次结构；2)基于几何属性生成血管段；3)整合局部段到全局关键图中。
- Result: 在真实数据集上验证，表现优于现有方法，首次成功应用基于部分的生成方法于3D血管建模。
- Conclusion: 该框架为血管数据生成设定了新基准，代码已开源。


### [89] [Mammo-SAE: Interpreting Breast Cancer Concept Learning with Sparse Autoencoders](https://arxiv.org/abs/2507.15227)
*Krishna Kanth Nakka*

Main category: cs.CV

TL;DR: 论文提出了一种基于稀疏自编码器（SAE）的可解释性方法，用于分析乳腺影像中的基础模型Mammo-CLIP，揭示了模型决策的潜在特征和影响因素。

- Motivation: 在高风险领域（如医学影像）中，模型决策的可解释性对临床采用至关重要。本文旨在通过SAE方法提升乳腺影像基础模型的可解释性。
- Method: 使用稀疏自编码器（SAE）分析Mammo-CLIP模型，识别与临床相关乳腺概念（如肿块和可疑钙化）相关的潜在特征。
- Result: 研究发现，SAE潜在空间中激活的神经元与真实区域对齐，并揭示了影响模型决策的混杂因素。此外，还分析了模型在下游任务中依赖的潜在神经元。
- Conclusion: 研究表明，SAE潜在表示能够为乳腺影像基础模型的内部工作机制提供更深层次的见解。


### [90] [Cross-Domain Few-Shot Learning with Coalescent Projections and Latent Space Reservation](https://arxiv.org/abs/2507.15243)
*Naeem Paeedeh,Mahardhika Pratama,Wolfgang Mayer,Jimmy Cao,Ryszard Kowlczyk*

Main category: cs.CV

TL;DR: 提出了一种名为Coalescent Projection (CP)的新方法，结合伪类生成和自监督变换，解决了跨域少样本学习中的过拟合问题，并在BSCD-FSL基准测试中表现优异。

- Motivation: 解决跨域少样本学习中因参数过多导致的过拟合问题，提升模型在未见域样本上的泛化能力。
- Method: 提出Coalescent Projection (CP)替代软提示，结合伪类生成和自监督变换(SSTs)优化模型。
- Result: 在BSCD-FSL极端域偏移场景中表现优于现有方法。
- Conclusion: CP方法有效解决了过拟合问题，提升了跨域少样本学习的性能。


### [91] [FreeCus: Free Lunch Subject-driven Customization in Diffusion Transformers](https://arxiv.org/abs/2507.15249)
*Yanbing Zhang,Zhe Wang,Qin Zhou,Mengping Yang*

Main category: cs.CV

TL;DR: FreeCus是一种无需训练的框架，通过注意力共享机制、动态偏移分析和多模态大语言模型，激活扩散变换器的零样本能力，实现高质量主题驱动合成。

- Motivation: 现有主题驱动技术依赖训练过程，限制了实际应用，且未能充分利用扩散变换器的零样本潜力。
- Method: 提出FreeCus框架，包括注意力共享机制、动态偏移分析改进和多模态大语言模型集成。
- Result: 实验表明，FreeCus在零样本主题合成中表现优异，兼容现有修复和控制模块。
- Conclusion: FreeCus成功激活扩散变换器的零样本能力，为高质量主题驱动合成提供了一种无需训练的解决方案。


### [92] [MinCD-PnP: Learning 2D-3D Correspondences with Approximate Blind PnP](https://arxiv.org/abs/2507.15257)
*Pei An,Jiaqi Yang,Muyao Peng,You Yang,Qiong Liu,Xiaolin Wu,Liangliang Nan*

Main category: cs.CV

TL;DR: 论文提出了一种基于近似盲PnP的对应学习方法（MinCD-PnP），通过最小化学习到的2D和3D关键点之间的Chamfer距离，解决了传统微分PnP对噪声和异常值敏感的问题。

- Motivation: 传统微分PnP在图像到点云（I2P）配准中对噪声和异常值敏感，影响了对应学习的有效性。盲PnP虽鲁棒但计算成本高，因此需要一种更高效的方法。
- Method: 提出MinCD-PnP，将盲PnP简化为最小化Chamfer距离的任务，并设计了轻量级多任务学习模块MinCD-Net，可集成到现有I2P配准架构中。
- Result: 在多个数据集（7-Scenes、RGBD-V2、ScanNet等）上，MinCD-Net在跨场景和跨数据集设置中均优于现有方法，提高了内点比率（IR）和配准召回率（RR）。
- Conclusion: MinCD-PnP和MinCD-Net有效解决了传统PnP的敏感性问题，提升了I2P配准的鲁棒性和性能。


### [93] [Conditional Video Generation for High-Efficiency Video Compression](https://arxiv.org/abs/2507.15269)
*Fangqiu Yi,Jingyu Xu,Jiawei Shao,Chi Zhang,Xuelong Li*

Main category: cs.CV

TL;DR: 提出了一种基于条件扩散模型的视频压缩框架，通过感知优化重建显著提升了压缩质量。

- Motivation: 利用条件扩散模型在人类视觉感知对齐重建方面的优势，优化视频压缩的感知质量。
- Method: 将视频压缩重新定义为条件生成任务，引入多粒度条件、紧凑表示和多条件训练模块。
- Result: 在FVD和LPIPS等感知质量指标上显著优于传统和神经编解码器，尤其在高压缩比下表现突出。
- Conclusion: 该方法通过条件扩散模型实现了感知优化的视频压缩，为高质量压缩提供了新思路。


### [94] [In-context Learning of Vision Language Models for Detection of Physical and Digital Attacks against Face Recognition Systems](https://arxiv.org/abs/2507.15285)
*Lazaro Janier Gonzalez-Soler,Maciej Salwowski,Christoph Busch*

Main category: cs.CV

TL;DR: 论文探讨了生物识别系统中攻击检测的挑战，提出了一种基于视觉语言模型（VLM）的上下文学习框架，用于检测物理和数字攻击，并在实验中验证了其性能优于传统CNN。

- Motivation: 随着生物识别系统的发展，攻击技术也日益复杂，传统深度学习模型在适应新型攻击和环境变化方面表现不足，且需要大量训练数据。本研究旨在利用VLM解决这些问题。
- Method: 提出了一种基于VLM的上下文学习框架，用于检测物理呈现攻击和数字变形攻击，并通过开源模型进行系统评估。
- Result: 实验结果表明，该框架在物理和数字攻击检测中表现优异，优于传统CNN，且无需大量训练资源。
- Conclusion: 该框架为生物识别系统中的攻击检测提供了一种泛化能力强且高效的解决方案。


### [95] [Minutiae-Anchored Local Dense Representation for Fingerprint Matching](https://arxiv.org/abs/2507.15297)
*Zhiyu Pan,Xiongjun Guan,Yongjie Duan,Jianjiang Feng,Jie Zhou*

Main category: cs.CV

TL;DR: 提出了一种名为DMD的指纹匹配方法，通过局部密集表示结合细粒度纹理和细节特征，提升了多样捕获条件下的识别性能。

- Motivation: 解决指纹匹配在不同捕获条件下的鲁棒性和准确性挑战。
- Method: 基于细节特征的局部密集表示，提取三维张量描述符，结合空间结构和语义特征。
- Result: 在多种指纹数据集上表现优异，计算效率高，达到最先进水平。
- Conclusion: DMD方法在指纹识别中具有高效性和泛化能力，适用于大规模应用。


### [96] [Few-Shot Object Detection via Spatial-Channel State Space Model](https://arxiv.org/abs/2507.15308)
*Zhimeng Xin,Tianxu Wu,Yixiong Zou,Shiming Chen,Dingjie Fu,Xinge You*

Main category: cs.CV

TL;DR: 论文提出了一种基于空间-通道状态建模（SCSM）的模块，用于解决少样本目标检测（FSOD）中通道特征提取不准确的问题，通过Mamba建模通道相关性，显著提升了检测性能。

- Motivation: 当前少样本目标检测方法在有限训练样本下难以准确提取通道特征，高权重通道未必有效，低权重通道可能仍有价值。
- Method: 提出SCSM模块，包含空间特征建模（SFM）和基于Mamba的通道状态建模（CSM），以平衡空间与通道关系学习。
- Result: 在VOC和COCO数据集上实验表明，SCSM模块显著提升了特征表示质量，达到最先进性能。
- Conclusion: SCSM模块通过建模通道相关性，有效解决了FSOD中的特征提取问题，提升了检测性能。


### [97] [BenchDepth: Are We on the Right Way to Evaluate Depth Foundation Models?](https://arxiv.org/abs/2507.15321)
*Zhenyu Li,Haotong Lin,Jiashi Feng,Peter Wonka,Bingyi Kang*

Main category: cs.CV

TL;DR: 提出BenchDepth新基准，通过五个下游代理任务评估深度基础模型（DFMs），避免传统对齐指标的偏见。

- Motivation: 现有深度评估协议存在不一致性，传统基准依赖对齐指标导致偏见和不公平比较。
- Method: 设计BenchDepth基准，选择五个下游任务（如深度补全、立体匹配等）评估DFMs的实际应用效果。
- Result: 对八种先进DFMs进行评测，提供关键发现和分析。
- Conclusion: 希望推动深度模型评估的最佳实践，促进深度估计领域的研究进展。


### [98] [ExDD: Explicit Dual Distribution Learning for Surface Defect Detection via Diffusion Synthesis](https://arxiv.org/abs/2507.15335)
*Muhammad Aqeel,Federico Leonardi,Francesco Setti*

Main category: cs.CV

TL;DR: ExDD框架通过显式建模双特征分布和生成合成缺陷数据，解决了工业缺陷检测中的单类异常检测局限性和数据稀缺问题。

- Motivation: 工业缺陷检测系统受限于单类异常检测范式，假设异常分布均匀且难以应对真实制造环境中的数据稀缺问题。
- Method: ExDD框架利用并行记忆库建模正常和异常特征分布，结合潜在扩散模型生成合成缺陷数据，并通过邻域感知比率评分机制融合距离度量。
- Result: 在KSDD2数据集上，ExDD表现优异（I-AUROC 94.2%，P-AUROC 97.7%），最佳增强效果为100个合成样本。
- Conclusion: ExDD通过显式双分布建模和合成数据生成，显著提升了工业缺陷检测的性能和适用性。


### [99] [RoadFusion: Latent Diffusion Model for Pavement Defect Detection](https://arxiv.org/abs/2507.15346)
*Muhammad Aqeel,Kidus Dagnaw Bellete,Francesco Setti*

Main category: cs.CV

TL;DR: RoadFusion框架通过合成异常生成和双路径特征适应，解决了路面缺陷检测中的数据稀缺、领域偏移和缺陷多样性问题。

- Motivation: 路面缺陷检测面临标注数据稀缺、训练与部署环境间的领域偏移以及缺陷外观的高变异性等挑战。
- Method: 采用潜在扩散模型生成多样化的合成缺陷，结合双路径特征适应器分别处理正常和异常输入，并使用轻量级判别器进行细粒度缺陷分类。
- Result: 在六个基准数据集上评估，RoadFusion在分类和定位任务中均表现优异，多项指标达到最新技术水平。
- Conclusion: RoadFusion为实际道路检测提供了高效且鲁棒的解决方案。


### [100] [DAViD: Data-efficient and Accurate Vision Models from Synthetic Data](https://arxiv.org/abs/2507.15365)
*Fatemeh Saleh,Sadegh Aliakbarian,Charlie Hewitt,Lohit Petikam,Xiao-Xian,Antonio Criminisi,Thomas J. Cashman,Tadas Baltrušaitis*

Main category: cs.CV

TL;DR: 论文提出了一种使用高保真合成数据集训练模型的方法，无需牺牲准确性且效率更高。

- Motivation: 当前人类中心计算机视觉模型需要大量参数、数据和计算资源，合成数据集可以降低成本并提供更好的数据控制。
- Method: 利用合成训练数据，提供细节丰富的完美标签，并通过程序化数据合成控制数据多样性。
- Result: 在深度估计、表面法线估计和软前景分割任务中，模型表现出高准确性，且训练和推理成本显著降低。
- Conclusion: 合成数据集是高效且公平的训练替代方案，模型和数据集已公开。


### [101] [Rethinking Occlusion in FER: A Semantic-Aware Perspective and Go Beyond](https://arxiv.org/abs/2507.15401)
*Huiyu Zhai,Xingxing Yang,Yalan Ye,Chenyang Li,Bin Fan,Changze Li*

Main category: cs.CV

TL;DR: ORSANet通过多模态语义引导、多尺度交互模块和动态对抗排斥损失，显著提升了遮挡条件下的面部表情识别性能。

- Motivation: 现有FER模型在面部遮挡时难以提取有效特征，导致分类不准确。
- Method: 引入多模态语义引导（语义分割图和面部关键点）、多尺度交互模块（MCM）和动态对抗排斥损失（DARELoss）。
- Result: 在公开基准和自建Occlu-FER数据集上达到SOTA性能。
- Conclusion: ORSANet有效解决了遮挡和数据集偏差问题，提升了FER的鲁棒性。


### [102] [SurgX: Neuron-Concept Association for Explainable Surgical Phase Recognition](https://arxiv.org/abs/2507.15418)
*Ka Young Kim,Hyeon Bae Kim,Seong Tae Kim*

Main category: cs.CV

TL;DR: SurgX是一个新颖的概念解释框架，旨在提高手术阶段识别模型的可解释性，通过将神经元与相关概念关联。

- Motivation: 深度学习模型在手术阶段识别中取得了进展，但其不透明性导致难以理解决策过程，影响了信任和调试。
- Method: 提出SurgX框架，包括选择代表性神经元序列、构建手术视频数据集的概念集、关联神经元与概念，并识别关键神经元。
- Result: 在两个手术阶段识别模型上的实验验证了方法的有效性，并分析了预测的解释。
- Conclusion: SurgX展示了在解释手术阶段识别方面的潜力，代码已开源。


### [103] [EgoPrune: Efficient Token Pruning for Egomotion Video Reasoning in Embodied Agent](https://arxiv.org/abs/2507.15428)
*Jiaao Li,Kaiyuan Li,Chen Gao,Yong Li,Xinlei Chen*

Main category: cs.CV

TL;DR: EgoPrune是一种无需训练的令牌修剪方法，专为第一人称视频推理设计，通过关键帧选择、冗余过滤和多样性令牌选择提升效率。

- Motivation: 第一人称视频推理对嵌入式AI代理至关重要，但现有方法计算成本高且未充分利用时空连续性。
- Method: EgoPrune包含关键帧选择、视角感知冗余过滤和基于MMR的令牌选择。
- Result: 在多个基准测试中，EgoPrune优于现有方法，显著降低计算资源消耗。
- Conclusion: EgoPrune适用于边缘设备，展示了实际部署的高效性。


### [104] [One Last Attention for Your Vision-Language Model](https://arxiv.org/abs/2507.15480)
*Liang Chen,Ghazi Shazan Ahmad,Tianjun Yao,Lingqiao Liu,Zhiqiang Shen*

Main category: cs.CV

TL;DR: RAda是一种简单有效的视觉语言模型（VLM）微调方法，通过动态校准融合表示（理性矩阵）来优化跨模态交互，提升性能。

- Motivation: 现有方法多关注单模态表示优化，忽视了融合表示在决策中的关键作用。
- Method: RAda通过轻量级注意力层学习掩码，动态调整理性矩阵中各元素的贡献，无需修改中间特征。
- Result: 实验表明RAda在多种设置下均优于基线，性能与当前先进方法相当。
- Conclusion: RAda是一种通用且高效的微调技术，适用于不同场景。


### [105] [An aerial color image anomaly dataset for search missions in complex forested terrain](https://arxiv.org/abs/2507.15492)
*Rakesh John Amala Arokia Nathan,Matthias Gessner,Nurullah Özkan,Marius Bock,Mohamed Youssef,Maximilian Mews,Björn Piltz,Ralf Berger,Oliver Bimber*

Main category: cs.CV

TL;DR: 论文探讨了在复杂森林环境中通过众包搜索生成的数据集，用于改进异常检测方法，支持搜捕和救援行动。

- Motivation: 在德国农村发生一起家庭谋杀案后，传统搜索方法因植被遮挡无法有效定位嫌疑人，促使研究团队通过高分辨率航空影像和众包搜索生成数据集。
- Method: 研究团队利用高分辨率航空影像，结合众包搜索生成标注数据集，并开发了交互式网络界面支持动态标注。
- Result: 现有异常检测方法在复杂森林环境中表现不佳，凸显了上下文感知方法的必要性。
- Conclusion: 该数据集为改进复杂环境中的异常检测提供了基准，支持搜捕和救援行动，并开放供离线处理和在线动态标注。


### [106] [Dense-depth map guided deep Lidar-Visual Odometry with Sparse Point Clouds and Images](https://arxiv.org/abs/2507.15496)
*JunYing Huang,Ao Xu,DongSun Yong,KeRen Li,YuanFeng Wang,Qi Qin*

Main category: cs.CV

TL;DR: 提出了一种新颖的LiDAR-视觉里程计框架，结合LiDAR点云和图像，通过深度补全和多尺度特征提取网络实现高精度姿态估计。

- Motivation: 解决自主系统在自定位和导航中对精确且鲁棒的里程计的需求。
- Method: 利用深度补全生成稠密深度图，结合多尺度特征提取网络和注意力机制，并通过层次化姿态优化模块逐步优化运动估计。
- Result: 在KITTI里程计基准测试中表现出与或优于现有视觉和LiDAR里程计方法的精度和鲁棒性。
- Conclusion: 提出的LiDAR-视觉融合框架在动态环境和尺度模糊情况下表现出色，为自主系统提供了可靠的里程计解决方案。


### [107] [Quantifying and Narrowing the Unknown: Interactive Text-to-Video Retrieval via Uncertainty Minimization](https://arxiv.org/abs/2507.15504)
*Bingqing Zhang,Zhuo Cao,Heming Du,Yang Li,Xue Li,Jiajun Liu,Sen Wang*

Main category: cs.CV

TL;DR: UMIVR是一个基于不确定性最小化的交互式文本到视频检索框架，通过量化文本模糊性、映射不确定性和帧不确定性，生成针对性问题以减少检索模糊性。

- Motivation: 当前交互式文本到视频检索方法依赖启发式策略，未能显式量化不确定性，限制了其效果。
- Method: UMIVR使用语义熵（TAS）、Jensen-Shannon散度（MUS）和时间质量采样器（TQFS）量化不确定性，并生成针对性问题。
- Result: 在MSR-VTT-1k数据集上，UMIVR在10轮交互后Recall@1达到69.2%。
- Conclusion: UMIVR为交互式文本到视频检索建立了不确定性最小化的基础，显著提升了检索效果。


### [108] [SAIGFormer: A Spatially-Adaptive Illumination-Guided Network for Low-Light Image Enhancement](https://arxiv.org/abs/2507.15520)
*Hanting Li,Fei Zhou,Xin Sun,Yang Hua,Jungong Han,Liang-Jie Zhang*

Main category: cs.CV

TL;DR: SAIGFormer是一种基于Transformer的低光增强方法，通过动态积分图像表示和光照引导的多头自注意力机制，解决了非均匀光照场景下的过曝光和亮度恢复不足问题。

- Motivation: 现有Transformer方法在非均匀光照场景（如背光和阴影）中表现不佳，导致过曝光或亮度恢复不足。
- Method: 提出动态积分图像表示和SAI2E估计器，结合光照引导的多头自注意力机制（IG-MSA），实现精确的光照恢复。
- Result: 在五个标准低光数据集和跨域基准（LOL-Blur）上，SAIGFormer在定量和定性指标上均显著优于现有方法。
- Conclusion: SAIGFormer在非均匀光照增强中表现优异，并展现出强大的跨数据集泛化能力。


### [109] [Procedure Learning via Regularized Gromov-Wasserstein Optimal Transport](https://arxiv.org/abs/2507.15540)
*Syed Ahmed Mahmood,Ali Shah Ali,Umer Ahmed,Fawad Javed Fateh,M. Zeeshan Zia,Quoc-Huy Tran*

Main category: cs.CV

TL;DR: 本文提出了一种自监督程序学习框架，通过融合Gromov-Wasserstein最优传输和结构先验来解决视频中关键步骤发现和顺序确定的问题，并通过对比正则化避免退化解。

- Motivation: 现有方法在处理顺序变化、背景/冗余帧和重复动作时性能受限，需要更鲁棒的解决方案。
- Method: 采用融合Gromov-Wasserstein最优传输和结构先验的框架，结合对比正则化以避免退化解。
- Result: 在多个大规模基准测试（EgoProceL、ProceL、CrossTask）上表现优于现有方法，如OPEL。
- Conclusion: 提出的方法有效解决了自监督程序学习中的关键挑战，性能显著提升。


### [110] [Towards Holistic Surgical Scene Graph](https://arxiv.org/abs/2507.15541)
*Jongmin Shin,Enki Cho,Ka Yong Kim,Jung Yong Kim,Seong Tae Kim,Namkee Oh*

Main category: cs.CV

TL;DR: 论文提出了一种新的数据集Endoscapes-SG201和基于图的方法SSG-Com，用于改进手术场景理解，特别是工具-动作-目标组合和操作手身份的建模。

- Motivation: 手术场景理解需要全面建模工具、解剖结构及其交互，但现有图表示方法未充分探索工具-动作-目标组合和操作手身份的重要性。
- Method: 提出Endoscapes-SG201数据集和SSG-Com方法，通过图结构学习工具-动作-目标组合和操作手身份。
- Result: 实验证明，这些关键要素的整合显著提升了手术场景理解，特别是在关键安全视图评估和动作三元组识别任务中。
- Conclusion: 研究强调了工具-动作-目标组合和操作手身份在图表示中的重要性，为手术场景理解提供了新方向。


### [111] [HOLa: Zero-Shot HOI Detection with Low-Rank Decomposed VLM Feature Adaptation](https://arxiv.org/abs/2507.15542)
*Qinqian Lei,Bo Wang,Robby T. Tan*

Main category: cs.CV

TL;DR: HOLa提出了一种新的零样本人-物交互检测方法，通过低秩分解VLM特征适应，提升了对未见类别的泛化能力和动作区分能力。

- Motivation: 解决现有方法在区分相同对象的不同动作或泛化到未见类别时的局限性。
- Method: 使用低秩分解VLM文本特征，生成类共享基础特征和可调权重，并通过LLM引导权重适应和引入人-物标记丰富视觉表示。
- Result: 在HICO-DET上实现了零样本HOI检测的新SOTA，未见动词设置下的mAP为27.91。
- Conclusion: HOLa通过低秩分解和特征适应，显著提升了零样本HOI检测的性能。


### [112] [DynImg: Key Frames with Visual Prompts are Good Representation for Multi-Modal Video Understanding](https://arxiv.org/abs/2507.15569)
*Xiaoyi Bao,Chenwei Xie,Hao Tang,Tingyu Weng,Xiaofeng Wang,Yun Zheng,Xingang Wang*

Main category: cs.CV

TL;DR: 提出了一种名为Dynamic-Image (DynImg)的视频表示方法，通过引入非关键帧作为时间提示，增强快速移动物体的空间特征提取，并结合4D视频旋转位置嵌入保持时空顺序，显著提升了视频理解性能。

- Motivation: 传统方法将空间和时间信息分开处理，导致快速移动物体的空间信息难以准确表示，影响时空交互和视频理解。
- Method: 提出DynImg方法，利用非关键帧作为时间提示，突出快速移动物体的空间区域，并结合4D视频旋转位置嵌入保持时空顺序。
- Result: 实验表明，DynImg在多个视频理解基准上比现有方法提升了约2%。
- Conclusion: DynImg通过时间提示和时空顺序保持，有效提升了视频理解的准确性。


### [113] [GeMix: Conditional GAN-Based Mixup for Improved Medical Image Augmentation](https://arxiv.org/abs/2507.15577)
*Hugo Carlesso,Maria Eliza Patulea,Moncef Garouani,Radu Tudor Ionescu,Josiane Mothe*

Main category: cs.CV

TL;DR: GeMix是一种基于条件GAN的两阶段图像增强框架，用于改进传统Mixup在医学图像分类中的不足，通过生成更真实的图像提升分类性能。

- Motivation: 传统Mixup的像素级插值在医学图像中生成不真实图像，可能阻碍学习效果，尤其是在高风险的医疗应用中。
- Method: 使用StyleGAN2-ADA生成器，通过Dirichlet和Beta分布采样标签向量，生成连续类别流形上的视觉一致图像。
- Result: 在COVIDx-CT-3数据集上，GeMix结合真实数据提升了所有测试骨干网络的macro-F1，降低了COVID-19检测的假阴性率。
- Conclusion: GeMix是传统Mixup的有效替代方案，提供更强的正则化和语义保真度，且无需修改现有训练流程。


### [114] [Compress-Align-Detect: onboard change detection from unregistered images](https://arxiv.org/abs/2507.15578)
*Gabriele Inzerillo,Diego Valsesia,Aniello Fiengo,Enrico Magli*

Main category: cs.CV

TL;DR: 提出一种卫星上实时变化检测框架，通过端到端深度神经网络解决数据存储、图像配准和变化检测的挑战。

- Motivation: 传统卫星图像变化检测因数据传输和处理延迟无法满足实时需求，需将整个流程移至卫星上。
- Method: 采用三模块深度神经网络：图像压缩、轻量级配准和高效变化检测模型。
- Result: 在低功耗硬件上实现0.7 Mpixel/s吞吐量，F1分数表现优异。
- Conclusion: 该框架首次实现卫星端到端变化检测，性能优于现有方法。


### [115] [SegDT: A Diffusion Transformer-Based Segmentation Model for Medical Imaging](https://arxiv.org/abs/2507.15595)
*Salah Eddine Bekhouche,Gaby Maroun,Fadi Dornaika,Abdenour Hadid*

Main category: cs.CV

TL;DR: SegDT是一种基于扩散变换器（DiT）的新型皮肤病变分割模型，适用于低成本硬件，通过Rectified Flow提升生成质量并保持快速推理速度。

- Motivation: 皮肤病变分割对皮肤癌诊断和患者监测至关重要，但现有方法在性能和效率上仍有改进空间。
- Method: 提出SegDT模型，结合扩散变换器和Rectified Flow技术，优化生成质量和推理速度。
- Result: 在三个基准数据集上测试，SegDT达到最先进性能，同时保持快速推理。
- Conclusion: SegDT为医学图像分析提供了高效、准确的工具，适用于实际医疗应用。


### [116] [Being-H0: Vision-Language-Action Pretraining from Large-Scale Human Videos](https://arxiv.org/abs/2507.15597)
*Hao Luo,Yicheng Feng,Wanpeng Zhang,Sipeng Zheng,Ye Wang,Haoqi Yuan,Jiazheng Liu,Chaoyi Xu,Qin Jin,Zongqing Lu*

Main category: cs.CV

TL;DR: Being-H0是一种基于大规模人类视频训练的视觉-语言-动作模型（VLA），通过物理指令调优和部分级运动标记化方法，解决了现有模型在复杂操作任务中的泛化问题。

- Motivation: 现有VLA模型依赖合成数据或有限规模的遥控演示，难以处理高灵巧性任务和泛化到新场景。
- Method: 提出物理指令调优训练范式，结合大规模VLA预训练、物理空间对齐和机器人任务后适应，并引入毫米级重建精度的部分级运动标记化方法。
- Result: Being-H0在手部运动生成和指令跟随方面表现优异，且在模型和数据规模扩展时表现良好，实际机器人操作中也有显著提升。
- Conclusion: 通过人类视频数据和物理指令调优，Being-H0显著提升了复杂操作任务的性能和泛化能力。


### [117] [SurfaceSplat: Connecting Surface Reconstruction and Gaussian Splatting](https://arxiv.org/abs/2507.15602)
*Zihui Gao,Jia-Wang Bian,Guosheng Lin,Hao Chen,Chunhua Shen*

Main category: cs.CV

TL;DR: 提出了一种结合SDF和3DGS的混合方法，用于稀疏视图图像的表⾯重建和新视角渲染，效果优于现有方法。

- Motivation: 稀疏视图图像的表⾯重建和新视角渲染存在挑战，SDF⽅法难以捕捉细节，3DGS⽅法缺乏全局几何⼀致性。
- Method: 结合SDF和3DGS的优势：SDF捕捉粗粒度几何以增强3DGS渲染，3DGS⽣成的新图像细化SDF细节。
- Result: 在DTU和MobileBrick数据集上，⽅法在表�重建和新视角合成⽅⾯优于现有技术。
- Conclusion: 混合⽅法有效解决了稀疏视图重建的挑战，代码将开源。


### [118] [CylinderPlane: Nested Cylinder Representation for 3D-aware Image Generation](https://arxiv.org/abs/2507.15606)
*Ru Jia,Xiaozhuang Ma,Jianji Wang,Nanning Zheng*

Main category: cs.CV

TL;DR: 提出了一种基于圆柱坐标系的CylinderPlane表示法，解决了Tri-plane表示中的多视角一致性问题，实现了高质量、无伪影的360°图像生成。

- Motivation: Tri-plane表示在3D感知图像生成中存在多视角特征模糊和伪影问题，限制了360°视图生成能力。
- Method: 采用圆柱坐标系构建CylinderPlane表示，通过嵌套圆柱结构捕捉多尺度特征，提升复杂几何和分辨率适应性。
- Result: 实验表明，CylinderPlane在合成数据集和真实图像上均优于现有方法。
- Conclusion: CylinderPlane解决了Tri-plane的局限性，为360°图像生成提供了高效、灵活的新方法。


### [119] [A Survey on Efficiency Optimization Techniques for DNN-based Video Analytics: Process Systems, Algorithms, and Applications](https://arxiv.org/abs/2507.15628)
*Shanjiang Tang,Rui Huang,Hsinyu Luo,Chunjiang Wang,Ce Yu,Yusen Li,Hao Fu,Chao Sun,and Jian Xiao*

Main category: cs.CV

TL;DR: 本文综述了深度神经网络（DNN）在视频分析中效率优化的技术，从硬件支持、数据处理等多角度进行了全面回顾。

- Motivation: 视频数据的爆炸式增长对视频分析的准确性和效率提出了更高要求，而现有研究多关注准确性优化，本文则聚焦于DNN在视频分析中的效率提升。
- Method: 采用自底向上的方式组织现有方法，涵盖硬件支持、数据处理、操作部署等多个视角。
- Result: 提出了一个优化框架，并基于现有工作分析了DNN在视频分析中性能优化的问题与挑战。
- Conclusion: 本文为DNN在视频分析中的效率优化提供了系统性的综述，并指出了未来的研究方向与挑战。


### [120] [Experimenting active and sequential learning in a medieval music manuscript](https://arxiv.org/abs/2507.15633)
*Sachin Sharma,Federico Simonetta,Michele Flammini*

Main category: cs.CV

TL;DR: 该论文研究了主动学习（AL）和顺序学习（SL）在光学音乐识别（OMR）中的应用，以解决历史音乐手稿标注数据稀缺的问题。

- Motivation: 解决历史音乐手稿标注数据稀缺和复杂性对音乐数字化文化遗产的挑战。
- Method: 使用YOLOv8，通过选择预测置信度最低的样本进行迭代标注和重新训练，从单张标注图像开始逐步提升性能。
- Result: 实验表明，该方法在显著减少标注样本的情况下，可以达到与完全监督训练相当的准确性。
- Conclusion: 在特定手稿中，基于不确定性的AL效果不佳，建议在数据稀缺场景中采用更实用的方法。


### [121] [Uncovering Critical Features for Deepfake Detection through the Lottery Ticket Hypothesis](https://arxiv.org/abs/2507.15636)
*Lisan Al Amin,Md. Ismail Hossain,Thanh Thi Nguyen,Tasnim Jahan,Mahbubul Islam,Faisal Quader*

Main category: cs.CV

TL;DR: 研究探讨了彩票假设（LTH）在深度伪造检测中的应用，发现关键子网络（“中奖彩票”）在高稀疏度下仍能保持性能。

- Motivation: 深度伪造技术威胁信息完整性和社会信任，现有检测方法模型庞大且机制不明确，难以在资源有限环境中部署。
- Method: 采用彩票假设（LTH）进行网络剪枝，通过迭代幅度剪枝方法在MesoNet、CNN-5和ResNet-18架构上实验。
- Result: MesoNet在80%稀疏度下保持56.2%准确率（基线62.6%），参数仅3,000；LTH剪枝方法优于一次性剪枝。
- Conclusion: LTH剪枝方法高效且可转移，为资源有限的深度伪造检测系统提供了潜在解决方案。


### [122] [Extracting Visual Facts from Intermediate Layers for Mitigating Hallucinations in Multimodal Large Language Models](https://arxiv.org/abs/2507.15652)
*Haoran Zhou,Zihan Zhang,Hao Chen*

Main category: cs.CV

TL;DR: 论文提出了一种名为EVA的训练无关方法，通过动态选择中间层来提取视觉事实知识，显著减少多模态大语言模型中的幻觉现象。

- Motivation: 多模态大语言模型（MLLMs）在视觉识别和语言理解结合方面取得了进展，但仍存在对象幻觉问题，即生成看似合理但实际错误的内容。研究发现先验知识在深层抑制了视觉信息，但中间层的作用尚不明确。
- Method: 提出EVA方法，通过对比原始输入和纯文本输入的输出分布，动态选择视觉事实信息最显著的中间层，并将其知识融入最终层以修正输出。
- Result: 在广泛使用的基准测试中，EVA显著降低了幻觉率，优于基线方法。
- Conclusion: EVA是一种模型无关的方法，能有效减少MLLMs中的幻觉现象，且与多种经典解码策略兼容。


### [123] [HW-MLVQA: Elucidating Multilingual Handwritten Document Understanding with a Comprehensive VQA Benchmark](https://arxiv.org/abs/2507.15655)
*Aniket Pal,Ajoy Mondal,Minesh Mathew,C. V. Jawahar*

Main category: cs.CV

TL;DR: HW-MLVQA是一个新的多语言手写文档视觉问答基准，包含1600页手写文档和2400个问答对，旨在填补多语言手写文档理解的空白，并评估OCR模型的性能。

- Motivation: 当前的多语言视觉问答模型在处理多样化的手写文档时表现不足，因此需要一个新的基准来推动多语言手写文档理解的研究。
- Method: HW-MLVQA包含1600页手写文档和2400个问答对，提供文本、图像及图像与文本结合的三种模态评估框架，并测试OCR模型在无真实文本转录的情况下的表现。
- Result: HW-MLVQA为多语言手写文档理解提供了一个全面的评估工具，并展示了OCR模型在实际场景中的性能。
- Conclusion: HW-MLVQA有望推动多语言手写文档理解领域的创新和研究进展。


### [124] [Visual-Language Model Knowledge Distillation Method for Image Quality Assessment](https://arxiv.org/abs/2507.15680)
*Yongkang Hou,Jiarun Song*

Main category: cs.CV

TL;DR: 提出了一种基于视觉-语言模型知识蒸馏的方法，用于图像质量评估（IQA），显著降低了模型复杂度并提升了性能。

- Motivation: 解决CLIP在IQA任务中参数过多和局部失真特征识别能力不足的问题。
- Method: 设计质量分级提示模板，微调CLIP，并提出模态自适应知识蒸馏策略。
- Result: 在多个IQA数据集上表现优于现有方法，同时显著降低模型复杂度。
- Conclusion: 该方法展示了实际部署的潜力。


### [125] [Hi^2-GSLoc: Dual-Hierarchical Gaussian-Specific Visual Relocalization for Remote Sensing](https://arxiv.org/abs/2507.15683)
*Boni Hu,Zhenyu Xia,Lin Chen,Pengcheng Han,Shuhui Bu*

Main category: cs.CV

TL;DR: 论文提出了一种基于3D高斯泼溅（3DGS）的双层次视觉重定位框架Hi²-GSLoc，解决了现有方法在精度和计算复杂度上的权衡问题，适用于大规模遥感场景。

- Motivation: 现有视觉重定位方法在精度和计算效率之间存在固有矛盾，尤其是在大规模遥感场景中。3DGS作为一种紧凑的场景表示方法，能够同时编码几何和外观信息，为解决这一问题提供了新思路。
- Method: 提出Hi²-GSLoc框架，采用稀疏到密集、粗到细的双阶段策略：稀疏阶段通过高斯特定的采样策略和地标检测器估计初始位姿；密集阶段通过迭代的密集光栅化匹配和可靠性验证细化位姿。
- Result: 在仿真数据、公开数据集和实际飞行实验中，该方法在定位精度、召回率和计算效率方面表现出色，并能有效过滤不可靠位姿估计。
- Conclusion: Hi²-GSLoc框架为遥感应用提供了一种高效、准确的视觉重定位解决方案，验证了3DGS在复杂场景中的实用性。


### [126] [LINR-PCGC: Lossless Implicit Neural Representations for Point Cloud Geometry Compression](https://arxiv.org/abs/2507.15686)
*Wenjie Huang,Qi Yang,Shuting Xia,He Huang,Zhu Li,Yiling Xu*

Main category: cs.CV

TL;DR: 提出了一种基于隐式神经表示（INR）的无损点云几何压缩方法LINR-PCGC，解决了现有方法依赖特定训练数据分布的问题，并显著提升了编码速度和压缩效率。

- Motivation: 现有AI点云压缩方法依赖特定训练数据分布，限制了实际应用；INR方法虽解决了分布依赖问题，但仅支持有损压缩且编码时间和解码器体积受限。
- Method: 设计了点云级编码框架和高效网络初始化策略，减少60%编码时间；提出基于多尺度SparseConv的轻量级编码网络，实现快速推理和小解码器体积。
- Result: 在MVUB数据集上，比特流比G-PCC TMC13v23减少21.21%，比SparsePCGC减少21.95%。
- Conclusion: LINR-PCGC首次实现基于INR的无损点云几何压缩，显著提升了压缩效率和实用性。


### [127] [DWTGS: Rethinking Frequency Regularization for Sparse-view 3D Gaussian Splatting](https://arxiv.org/abs/2507.15690)
*Hung Nguyen,Runfa Li,An Le,Truong Nguyen*

Main category: cs.CV

TL;DR: DWTGS提出了一种基于小波变换的频率正则化方法，通过监督低频子带并自监督高频子带，显著提升了稀疏视图3D高斯泼溅的重建质量。

- Motivation: 稀疏视图3D高斯泼溅（3DGS）在重建高质量新视图时容易过拟合高频细节，传统傅里叶变换方法存在参数调优困难和对高频学习有害的问题。
- Method: DWTGS利用小波空间损失，通过监督低频LL子带并自监督高频HH子带，提供额外的空间监督。
- Result: 实验表明，DWTGS在多个基准测试中优于基于傅里叶变换的方法，低频策略提高了泛化能力并减少了高频幻觉。
- Conclusion: DWTGS通过小波变换的频率正则化方法，有效解决了稀疏视图3DGS的高频过拟合问题，提升了重建质量。


### [128] [Efficient Face Image Quality Assessment via Self-training and Knowledge Distillation](https://arxiv.org/abs/2507.15709)
*Wei Sun,Weixia Zhang,Linhan Cao,Jun Jia,Xiangyang Zhu,Dandan Zhu,Xiongkuo Min,Guangtao Zhai*

Main category: cs.CV

TL;DR: 提出了一种高效的人脸图像质量评估方法，通过教师-学生模型和自训练策略，实现低计算开销的高性能。

- Motivation: 解决现有FIQA方法计算复杂度高的问题，提升实际部署的可行性。
- Method: 采用两阶段方法：训练强大的教师模型，并通过自训练和知识蒸馏生成轻量级学生模型。
- Result: 学生模型性能接近教师模型，计算开销极低，并在ICCV 2025 VQualA FIQA挑战赛中夺冠。
- Conclusion: 该方法在保持高性能的同时显著降低了计算复杂度，适合实际应用部署。


### [129] [A Practical Investigation of Spatially-Controlled Image Generation with Transformers](https://arxiv.org/abs/2507.15724)
*Guoxuan Xia,Harleen Hanspal,Petru-Daniel Tudosiu,Shifeng Zhang,Sarah Parisot*

Main category: cs.CV

TL;DR: 论文探讨了空间控制图像生成模型的研究，通过实验比较了不同生成范式，提出了控制令牌预填充作为基线方法，并研究了采样时间增强技术。

- Motivation: 研究旨在解决现有模型在空间控制生成中缺乏科学比较的问题，澄清文献中的知识空白，为开发基于Transformer的系统提供清晰指导。
- Method: 在ImageNet上进行了扩散模型、流模型和自回归模型的对照实验，提出了控制令牌预填充方法，并研究了分类器自由引导和softmax截断等技术。
- Result: 控制令牌预填充是一种简单且高效的基线方法；采样时间增强技术（如分类器自由引导和softmax截断）显著提高了生成与控制的连贯性；适配器方法在有限数据下表现良好，但生成控制连贯性不及完整训练。
- Conclusion: 论文为空间控制图像生成提供了实用的技术见解，强调了采样时间增强的重要性，并指出了适配器方法的优缺点。


### [130] [TokensGen: Harnessing Condensed Tokens for Long Video Generation](https://arxiv.org/abs/2507.15728)
*Wenqi Ouyang,Zeqi Xiao,Danni Yang,Yifan Zhou,Shuai Yang,Lei Yang,Jianlou Si,Xingang Pan*

Main category: cs.CV

TL;DR: TokensGen提出了一种两阶段框架，利用压缩的token解决长视频生成中的内存瓶颈和长期一致性问题。

- Motivation: 扩散模型在生成短视频时表现良好，但扩展到长视频时面临内存和一致性问题。
- Method: 方法分为两阶段：1) 训练To2V模型生成短视频；2) 使用T2To模型生成全局一致的token，并通过FIFO-Diffusion策略平滑过渡。
- Result: 实验表明，该方法显著提升了长期时间和内容一致性，且计算开销可控。
- Conclusion: 通过压缩token和预训练短视频模型，TokensGen为长视频生成提供了可扩展的模块化解决方案。


### [131] [Appearance Harmonization via Bilateral Grid Prediction with Transformers for 3DGS](https://arxiv.org/abs/2507.15748)
*Jisu Shin,Richard Shaw,Seunghyun Shin,Anton Pelykh,Zhensong Zhang,Hae-Gon Jeon,Eduardo Perez-Pellitero*

Main category: cs.CV

TL;DR: 提出了一种基于Transformer的方法，通过预测空间自适应双边网格来校正多视角中的光度变化，无需场景特定重训练，提升了3D高斯溅射管线的重建质量。

- Motivation: 现代相机管线处理（如曝光调整、白平衡等）会导致多视角间的光度不一致，影响新视角合成的质量。现有方法通过联合优化场景表示和每张图像的外观嵌入来解决，但增加了计算复杂性和训练时间。
- Method: 采用Transformer预测空间自适应双边网格，校正光度变化，并将其集成到3D高斯溅射管线中，实现多视角一致性。
- Result: 实验表明，该方法在重建质量和收敛速度上优于或匹配现有的场景特定优化方法。
- Conclusion: 该方法无需场景特定重训练，实现了高效且高质量的多视角一致性校正。


### [132] [Learning from Heterogeneity: Generalizing Dynamic Facial Expression Recognition via Distributionally Robust Optimization](https://arxiv.org/abs/2507.15765)
*Feng-Qi Cui,Anyang Tong,Jinyang Huang,Jie Zhang,Dan Guo,Zhi Liu,Meng Wang*

Main category: cs.CV

TL;DR: 提出了一种名为HDF的新框架，通过两个模块增强动态面部表情识别的性能，解决了多源数据和个体差异带来的样本异质性问题。

- Motivation: 现有方法在多源数据和个体表达差异导致的样本异质性下性能下降，需要一种更鲁棒的解决方案。
- Method: 设计了Time-Frequency Distributional Attention Module (DAM)和Distribution-aware Scaling Module (DSM)，分别用于增强时间-频率建模和优化不平衡问题。
- Result: 在DFEW和FERV39k数据集上，HDF显著提高了识别准确性和鲁棒性，取得了更高的WAR和UAR。
- Conclusion: HDF框架通过双模块设计有效解决了样本异质性问题，提升了动态面部表情识别的性能。


### [133] [Label tree semantic losses for rich multi-class medical image segmentation](https://arxiv.org/abs/2507.15777)
*Junwen Wang,Oscar MacCormac,William Rochford,Aaron Kujawa,Jonathan Shapey,Tom Vercauteren*

Main category: cs.CV

TL;DR: 论文提出两种基于树结构的语义损失函数，利用标签的层次结构改进医学图像分割，并在稀疏标注下验证其性能。

- Motivation: 现有医学图像分割方法对所有错误同等惩罚，未能利用标签空间的语义关系，尤其在标签复杂时表现不佳。
- Method: 提出两种树状语义损失函数，结合稀疏标注训练方法，应用于全监督和稀疏标注场景。
- Result: 在脑部MRI和神经外科高光谱成像任务中达到最优性能。
- Conclusion: 树状语义损失函数能有效提升复杂标签下的分割精度。


### [134] [Regularized Low-Rank Adaptation for Few-Shot Organ Segmentation](https://arxiv.org/abs/2507.15793)
*Ghassen Baklouti,Julio Silva-Rodríguez,Jose Dolz,Houda Bahig,Ismail Ben Ayed*

Main category: cs.CV

TL;DR: 论文提出了一种动态调整低秩适应（LoRA）方法，用于医学图像分割，通过引入稀疏正则化自动选择任务适应的秩，显著提升了性能。

- Motivation: 传统LoRA方法需要固定秩，难以适应医学图像任务的复杂性和多样性，因此需要一种动态调整秩的方法。
- Method: 通过奇异值分解和l1稀疏正则化动态调整低秩表示的秩，并使用近端优化器求解。
- Result: 在少量样本微调场景中，该方法显著优于标准LoRA和其他PEFT方法，表现出高效性和鲁棒性。
- Conclusion: 动态调整秩的方法在医学图像分割中具有显著优势，代码已开源。


### [135] [Exploring Superposition and Interference in State-of-the-Art Low-Parameter Vision Models](https://arxiv.org/abs/2507.15798)
*Lilian Hollard,Lucas Mohimont,Nathalie Gaveau,Luiz-Angelo Steffenel*

Main category: cs.CV

TL;DR: 论文研究了低参数深度神经网络在计算机视觉中的性能，重点关注瓶颈架构及其使用超线性激活函数的行为，提出减少干扰可提升小规模网络的扩展性和准确性。

- Motivation: 研究低参数深度神经网络中特征图的干扰现象，以提升小规模网络的性能和效率。
- Method: 通过分析多种瓶颈架构，识别减少干扰的关键设计元素，并提出名为NoDepth Bottleneck的概念验证架构。
- Result: 实验证明，减少干扰可显著提升小规模网络（参数少于150万）在ImageNet数据集上的扩展性和准确性。
- Conclusion: 研究为低参数范围的神经网络提供了更高效和可扩展的设计方案，并深化了对瓶颈架构的理解。


### [136] [ConformalSAM: Unlocking the Potential of Foundational Segmentation Models in Semi-Supervised Semantic Segmentation with Conformal Prediction](https://arxiv.org/abs/2507.15803)
*Danhui Chen,Ziquan Liu,Chuxi Yang,Dan Wang,Yan Yan,Yi Xu,Xiangyang Ji*

Main category: cs.CV

TL;DR: ConformalSAM利用基础分割模型SEEM生成未标注数据的预测掩码，并通过不确定性校准和自依赖训练策略提升半监督语义分割性能。

- Motivation: 解决像素级视觉任务中标注数据稀缺的问题，利用基础分割模型的泛化能力。
- Method: 提出ConformalSAM框架，结合不确定性校准和自依赖训练策略，优化SEEM生成的掩码质量。
- Result: 在三个标准基准测试中，ConformalSAM性能优于现有半监督方法，并可作为插件提升其他方法。
- Conclusion: ConformalSAM有效利用基础模型，解决了标注稀缺问题，提升了半监督语义分割的性能。


### [137] [True Multimodal In-Context Learning Needs Attention to the Visual Context](https://arxiv.org/abs/2507.15807)
*Shuo Chen,Jianzhe Liu,Zhen Han,Yan Xia,Daniel Cremers,Philip Torr,Volker Tresp,Jindong Gu*

Main category: cs.CV

TL;DR: 当前的多模态大语言模型（MLLMs）在多模态上下文学习（MICL）中过度依赖文本模式，忽视视觉信息。论文提出动态注意力重分配（DARA）和专用数据集TrueMICL，以提升模型的真正多模态学习能力。

- Motivation: 现有MLLMs在MICL中未能有效利用视觉信息，导致学习结果偏向文本模仿而非多模态适应，限制了实际应用。
- Method: 提出动态注意力重分配（DARA）策略，通过调整视觉和文本令牌的注意力权重，鼓励模型关注视觉内容；同时构建TrueMICL数据集，明确要求整合多模态信息。
- Result: 实验表明，提出的解决方案显著提升了模型的多模态上下文学习能力。
- Conclusion: DARA和TrueMICL共同解决了MLLMs在MICL中的视觉信息利用不足问题，为多模态学习提供了可靠评估和改进方法。


### [138] [Diffusion models for multivariate subsurface generation and efficient probabilistic inversion](https://arxiv.org/abs/2507.15809)
*Roberto Miele,Niklas Linde*

Main category: cs.CV

TL;DR: 扩散模型在多变量地下建模和概率反演中表现优异，通过改进扩散后验采样方法，显著提升了统计稳健性和计算效率。

- Motivation: 研究扩散模型在多变量地下建模和概率反演中的应用，以提升建模能力和计算效率。
- Method: 提出对扩散后验采样方法的修正，包括引入噪声污染的似然近似，并评估其在多变量地质场景中的性能。
- Result: 相比原始方法，改进后的方法在统计稳健性、后验概率密度采样和计算成本方面均有显著提升。
- Conclusion: 该方法适用于硬数据和间接条件数据，且计算速度优于需要外循环的方法（如马尔可夫链蒙特卡洛）。


### [139] [Can Your Model Separate Yolks with a Water Bottle? Benchmarking Physical Commonsense Understanding in Video Generation Models](https://arxiv.org/abs/2507.15824)
*Enes Sanli,Baris Sarper Tezcan,Aykut Erdem,Erkut Erdem*

Main category: cs.CV

TL;DR: PhysVidBench是一个评估文本到视频（T2V）生成模型物理常识能力的基准，包含383个精心设计的提示，并通过三阶段评估流程间接衡量模型的物理合理性。

- Motivation: 当前T2V生成模型在物理常识方面表现不足，常违反因果关系、物体行为和工具使用等直觉期望，因此需要一种评估方法填补这一空白。
- Method: 提出PhysVidBench基准，包含383个提示，通过三阶段评估流程（问题生成、视频字幕生成、语言模型回答）间接评估物理合理性。
- Result: PhysVidBench提供了一个结构化、可解释的框架，用于评估生成视频模型的物理常识能力，特别关注工具使用和材料属性等领域。
- Conclusion: PhysVidBench填补了当前T2V评估的空白，为提升模型的物理常识能力提供了有效工具。


### [140] [SeC: Advancing Complex Video Object Segmentation via Progressive Concept Construction](https://arxiv.org/abs/2507.15852)
*Zhixiong Zhang,Shuangrui Ding,Xiaoyi Dong,Songxin He,Jianfan Lin,Junsong Tang,Yuhang Zang,Yuhang Cao,Dahua Lin,Jiaqi Wang*

Main category: cs.CV

TL;DR: 提出Segment Concept (SeC)框架，结合视觉语言模型提升视频目标分割性能，并在新基准SeCVOS上表现优异。

- Motivation: 现有视频目标分割方法依赖外观匹配，缺乏人类对物体的概念理解，导致在复杂场景下表现不佳。
- Method: SeC通过视觉语言模型构建高级概念表示，动态平衡语义推理与特征匹配。
- Result: SeC在SeCVOS基准上比SAM 2.1提升11.8分，达到新SOTA。
- Conclusion: SeC通过概念驱动的方法显著提升了视频目标分割的鲁棒性。


### [141] [Latent Denoising Makes Good Visual Tokenizers](https://arxiv.org/abs/2507.15856)
*Jiawei Yang,Tianhong Li,Lijie Fan,Yonglong Tian,Yue Wang*

Main category: cs.CV

TL;DR: 论文提出了一种新的视觉分词器（l-DeTok），通过直接与去噪目标对齐，提升生成模型的性能。

- Motivation: 现代生成模型的训练目标（如去噪）与分词器的有效性之间存在潜在联系，但尚未明确。
- Method: 提出Latent Denoising Tokenizer（l-DeTok），通过训练分词器从受噪声和掩码干扰的潜在嵌入中重建干净图像。
- Result: 在ImageNet 256x256上，l-DeTok在六种代表性生成模型中表现优于标准分词器。
- Conclusion: 去噪是分词器设计的基本原则，未来研究可基于此展开。
## cs.NE

### [142] [APTx Neuron: A Unified Trainable Neuron Architecture Integrating Activation and Computation](https://arxiv.org/abs/2507.14270)
*Ravin Kumar*

Main category: cs.NE

TL;DR: APTx Neuron是一种新型统一神经计算单元，将非线性激活和线性变换集成到单个可训练表达式中，提高了计算效率和架构简洁性。

- Motivation: 传统神经元设计需要分离的激活层，增加了计算复杂性和架构冗余，APTx Neuron旨在解决这一问题。
- Method: APTx Neuron基于APTx激活函数，形式为$y = \sum_{i=1}^{n} ((\alpha_i + \tanh(\beta_i x_i)) \cdot \gamma_i x_i) + \delta$，所有参数可训练。
- Result: 在MNIST数据集上验证，仅用20个周期和约332K可训练参数即达到96.69%测试准确率。
- Conclusion: APTx Neuron在表达能力和计算效率上优于传统神经元，为统一神经元设计提供了新范式。
## astro-ph.IM

### [143] [Hyper-spectral Unmixing algorithms for remote compositional surface mapping: a review of the state of the art](https://arxiv.org/abs/2507.14260)
*Alfredo Gimenez Zapiola,Andrea Boselli,Alessandra Menafoglio,Simone Vantini*

Main category: astro-ph.IM

TL;DR: 对遥感图像数据的高光谱解混方法进行了详细综述，包括材料推断、丰度估计及空间分布分析，并比较了最新方法，探讨了公开数据集和未来研究方向。

- Motivation: 研究目的是解决从高光谱图像中推断地表覆盖材料及其丰度和空间分布的问题，以支持地球和其他天体的大范围遥感数据分析。
- Method: 综述了最成功和相关的高光谱解混方法，并分析了最新技术，同时系统探讨了常用的公开数据集。
- Result: 总结了现有方法的优缺点，并提供了公开数据集的详细信息。
- Conclusion: 指出了当前研究的开放性问题，并提出了未来研究的具体建议。
## cs.CR

### [144] [Breaking the Illusion of Security via Interpretation: Interpretable Vision Transformer Systems under Attack](https://arxiv.org/abs/2507.14248)
*Eldor Abdukhamidov,Mohammed Abuhamad,Simon S. Woo,Hyoungshick Kim,Tamer Abuhmed*

Main category: cs.CR

TL;DR: 论文提出了一种名为AdViT的攻击方法，能够同时欺骗视觉Transformer模型及其解释模型，实验表明攻击成功率高且难以检测。

- Motivation: 研究视觉Transformer模型及其解释模型在对抗攻击下的脆弱性，填补了现有研究忽略解释模型影响的空白。
- Method: 提出AdViT攻击方法，生成能同时误导Transformer模型和解释模型的对抗样本，并在多种模型和解释器上进行实验验证。
- Result: AdViT在白盒和黑盒场景下攻击成功率达100%，白盒场景下误分类置信度达98%，黑盒场景下达76%，且生成的对抗样本解释准确。
- Conclusion: AdViT攻击揭示了视觉Transformer模型及其解释模型在对抗攻击下的严重漏洞，需进一步研究防御方法。
## eess.IV

### [145] [Exposing and Mitigating Calibration Biases and Demographic Unfairness in MLLM Few-Shot In-Context Learning for Medical Image Classification](https://arxiv.org/abs/2506.23298)
*Xing Shen,Justin Szeto,Mingyang Li,Hengguan Huang,Tal Arbel*

Main category: eess.IV

TL;DR: 论文研究了多模态大语言模型（MLLMs）在医学图像分类中的校准偏差和人口统计不公平性，提出了CALIN方法以在推理时校准预测置信度，提高公平性和准确性。

- Motivation: MLLMs在医学图像分析中具有巨大潜力，但其预测准确性和校准误差在不同人口统计子群中的表现需要深入分析，以确保临床实践中的安全部署。
- Method: 提出了CALIN方法，通过双层程序（从群体到子群）估计校准矩阵，并在推理时应用这些矩阵校准预测置信度。
- Result: 在三个医学影像数据集上的实验表明，CALIN能有效确保预测的公平性，同时提高整体准确性，且公平性与效用之间的权衡最小。
- Conclusion: CALIN是一种有效的推理时校准方法，可减少MLLMs在医学图像分类中的校准偏差和人口统计不公平性。


### [146] [MiDeSeC: A Dataset for Mitosis Detection and Segmentation in Breast Cancer Histopathology Images](https://arxiv.org/abs/2507.14271)
*Refik Samet,Nooshin Nemati,Emrah Hancer,Serpil Sak,Bilge Ayca Kirmizi,Zeynep Yildirim*

Main category: eess.IV

TL;DR: MiDeSeC数据集包含25名患者的H&E染色乳腺癌切片，用于训练和测试模型，覆盖多种有丝分裂形态。

- Motivation: 由于有丝分裂形态多样，需要大规模数据集以全面覆盖所有情况，从而提升模型识别能力。
- Method: 从25名患者的玻璃切片中选择50个1024*1024像素区域，包含500多个有丝分裂，2/3用于训练，1/3用于测试。
- Result: 数据集包含500多个有丝分裂，分布合理，适用于模型训练和评估。
- Conclusion: MiDeSeC数据集为乳腺癌有丝分裂研究提供了高质量资源，有助于提升识别准确性。


### [147] [NuSeC: A Dataset for Nuclei Segmentation in Breast Cancer Histopathology Images](https://arxiv.org/abs/2507.14272)
*Refik Samet,Nooshin Nemati,Emrah Hancer,Serpil Sak,Bilge Ayca Kirmizi*

Main category: eess.IV

TL;DR: NuSeC数据集包含100张图像，分为75%训练集和25%测试集，用于未来方法开发的比较分析。

- Motivation: 为研究人员提供一个标准化的数据集，以便未来开发的方法可以进行一致的比较分析。
- Method: 从25名患者的每张幻灯片中选取4张图像，随机选择每名患者的一张图像作为测试集，其余为训练集。
- Result: 训练集包含75张图像（约30000个核结构），测试集包含25张图像（约6000个核结构）。
- Conclusion: NuSeC数据集的设计支持未来研究方法的开发和比较。


### [148] [Self-Supervised Joint Reconstruction and Denoising of T2-Weighted PROPELLER MRI of the Lungs at 0.55T](https://arxiv.org/abs/2507.14308)
*Jingjia Chen,Haoyang Pei,Christoph Maier,Mary Bruno,Qiuting Wen,Seon-Hi Shin,William Moore,Hersh Chandarana,Li Feng*

Main category: eess.IV

TL;DR: 研究提出了一种自监督联合重建和去噪模型，用于改进0.55T T2加权PROPELLER肺部MRI图像质量。

- Motivation: 提高低场强（0.55T）T2加权PROPELLER肺部MRI的图像清晰度和结构完整性，同时减少扫描时间。
- Method: 使用44名COVID康复患者的MRI数据集，开发自监督学习框架，将PROPELLER采集的每个叶片分为两部分，分别用于训练重建网络和计算损失。与MPPCA去噪方法对比。
- Result: 模型显著提升了图像质量，与CT图像对齐良好，且扫描时间减半。读者评估显示优于MPPCA方法（p<0.001）。
- Conclusion: 自监督学习模型通过利用k空间子集的结构冗余性，有效重建图像并抑制噪声，适用于0.55T T2加权肺部MRI。


### [149] [Classification of Histopathology Slides with Persistence Homology Convolutions](https://arxiv.org/abs/2507.14378)
*Shrunal Pothagoni,Benjamin Schweinhart*

Main category: eess.IV

TL;DR: 论文提出了一种名为“Persistent Homology Convolutions”的新方法，通过改进卷积操作来生成局部持久同源性数据，以解决CNN在医学图像分析中丢失拓扑信息的问题。

- Motivation: 在医学图像分析（如组织病理学）中，拓扑信息是区分疾病指示组织的重要描述符，但传统CNN模型可能丢失此类信息。现有方法使用全局拓扑摘要，缺乏局部拓扑特征信息。
- Method: 提出了一种改进的卷积算子（Persistent Homology Convolutions），生成局部持久同源性数据，捕捉拓扑特征的局部性和平移不变性。
- Result: 实验表明，使用该方法训练的模型在组织病理学图像分类任务中优于传统模型，且对超参数更不敏感。
- Conclusion: Persistent Homology Convolutions能够有效提取组织病理学图像中的几何信息，提升诊断性能。


### [150] [QUTCC: Quantile Uncertainty Training and Conformal Calibration for Imaging Inverse Problems](https://arxiv.org/abs/2507.14760)
*Cassandra Tong Ye,Shamus Li,Tyler King,Kristina Monakhova*

Main category: eess.IV

TL;DR: QUTCC是一种非线性、非均匀的量化不确定性训练和校准技术，用于改进深度学习模型在医学成像任务中的可靠性，提供更紧密的不确定性区间。

- Motivation: 深度学习模型在医学成像任务中可能产生幻觉（虚假信息），准确性至关重要，现有方法的不确定性边界较大且信息量不足。
- Method: 提出QUTCC技术，通过U-Net架构和量化嵌入预测完整的条件分布，并通过迭代查询上下分位数逐步优化不确定性边界。
- Result: QUTCC能有效识别图像估计中的幻觉，并在多个去噪任务和MRI重建中提供比现有方法更紧密的不确定性区间。
- Conclusion: QUTCC显著提升了医学成像任务中不确定性量化的精度和可靠性。


### [151] [PET Image Reconstruction Using Deep Diffusion Image Prior](https://arxiv.org/abs/2507.15078)
*Fumio Hashimoto,Kuang Gong*

Main category: eess.IV

TL;DR: 提出了一种基于扩散模型的解剖先验引导PET图像重建方法，通过交替扩散采样和模型微调，实现跨示踪剂的高质量重建，并采用HQS算法提高计算效率。

- Motivation: 解决PET成像中示踪剂特异性对比度变化和高计算需求的问题，扩展扩散模型在医学图像重建中的应用。
- Method: 结合解剖先导和扩散模型，交替进行扩散采样与模型微调，利用HQS算法分离网络优化与迭代重建。
- Result: 在模拟和临床数据上验证了方法的有效性，能够跨示踪剂和扫描仪类型实现稳健重建。
- Conclusion: 该方法为低剂量PET成像提供了一种高效且通用的重建框架。


### [152] [Performance Analysis of Post-Training Quantization for CNN-based Conjunctival Pallor Anemia Detection](https://arxiv.org/abs/2507.15151)
*Sebastian A. Cruz Romero,Wilfredo E. Lugo Beauchamp*

Main category: eess.IV

TL;DR: 利用深度学习模型通过结膜苍白检测贫血，在CP-AnemiC数据集上取得高准确率，并探索量化技术以优化移动设备部署。

- Motivation: 解决传统贫血检测方法成本高、依赖专家的问题，提供一种低成本、高效的替代方案。
- Method: 使用MobileNet架构，结合数据增强和交叉验证策略，对模型进行端到端微调，并评估不同量化位宽的性能。
- Result: 模型准确率达0.9313，精度0.9374，F1分数0.9773；FP16量化后性能保持较高，但INT8和INT4量化导致性能显著下降。
- Conclusion: 支持进一步探索量化方案和硬件优化，以平衡模型大小、推理时间和诊断准确性。


### [153] [A Study of Anatomical Priors for Deep Learning-Based Segmentation of Pheochromocytoma in Abdominal CT](https://arxiv.org/abs/2507.15193)
*Tanjin Taher Toma,Tejas Sudharshan Mathai,Bikash Santra,Pritam Mukherjee,Jianfei Liu,Wesley Jong,Darwish Alabyad,Vivek Batheja,Abhishek Jha,Mayank Patel,Darko Pucar,Jayadira del Rivero,Karel Pacak,Ronald M. Summers*

Main category: eess.IV

TL;DR: 该研究通过引入基于器官特异性解剖先验的多类标注策略，显著提高了深度学习模型对腹部CT扫描中嗜铬细胞瘤（PCC）的分割准确性。

- Motivation: 准确的PCC分割对肿瘤负荷估计、预后和治疗规划至关重要，同时可减少对昂贵基因检测的依赖。
- Method: 使用nnU-Net框架评估了11种标注策略，包括基于相邻器官解剖先验的多类方案，并在105例CT扫描上进行了训练和测试。
- Result: Tumor + Kidney + Aorta (TKA)标注策略在DSC、NSD和F1分数上显著优于其他策略，并在肿瘤负荷量化和遗传亚型分割中表现优异。
- Conclusion: 研究表明，结合相关解剖背景可显著提升PCC分割精度，支持临床评估和长期监测。


### [154] [Personalized 3D Myocardial Infarct Geometry Reconstruction from Cine MRI with Explicit Cardiac Motion Modeling](https://arxiv.org/abs/2507.15194)
*Yilin Lyu,Fan Yang,Xiaoyue Liu,Zichen Jiang,Joshua Dillon,Debbie Zhao,Martyn Nash,Charlene Mauger,Alistair Young,Ching-Hui Sia,Mark YY Chan,Lei Li*

Main category: eess.IV

TL;DR: 提出了一种无需对比剂的高保真3D心肌梗死几何重建框架，基于2D标准cine MRI，利用动态几何运动模式定位梗死区域。

- Motivation: LGE MRI需要对比剂且依赖稀疏2D切片，限制了空间分辨率和准确性，因此需要一种无对比剂的高分辨率替代方法。
- Method: 通过自动深度形状拟合模型biv-me重建4D双心室网格，再设计CMotion2Infarct-Net模型利用动态几何运动模式定位梗死区域。
- Result: 在205例cine MRI扫描中，方法与手动描绘结果具有合理一致性。
- Conclusion: 证明了无对比剂、心脏运动驱动的3D梗死重建的可行性，为MI数字孪生提供了高效途径。


### [155] [Personalized 4D Whole Heart Geometry Reconstruction from Cine MRI for Cardiac Digital Twins](https://arxiv.org/abs/2507.15203)
*Xiaoyue Liu,Xicheng Sheng,Xiahai Zhuang,Vicente Grau,Mark YY Chan,Ching-Hui Sia,Lei Li*

Main category: eess.IV

TL;DR: 提出了一种弱监督学习模型，从多视角2D心脏电影MRI直接重建4D心脏网格，为精准医学提供个性化心脏数字孪生模型。

- Motivation: 心脏数字孪生（CDT）在精准医学中潜力巨大，但目前全心脏四腔室电机械模拟模型有限。
- Method: 通过自监督映射学习2D电影MRI与4D心脏网格的关系，生成个性化心脏模型。
- Result: 模型可自动提取关键心脏参数（如射血分数和动态腔室体积变化），验证了从MRI推断个性化4D心脏模型的可行性。
- Conclusion: 为高效CDT平台奠定了基础，代码将在论文接受后公开。


### [156] [EndoControlMag: Robust Endoscopic Vascular Motion Magnification with Periodic Reference Resetting and Hierarchical Tissue-aware Dual-Mask Contro](https://arxiv.org/abs/2507.15292)
*An Wanga,Rulin Zhou,Mengya Xu,Yiru Ye,Longfei Gou,Yiting Chang,Hao Chen,Chwee Ming Lim,Jiankun Wang,Hongliang Ren*

Main category: eess.IV

TL;DR: EndoControlMag是一种无需训练的、基于拉格朗日的方法，用于内窥镜手术中血管细微运动的放大，通过周期性参考重置和分层组织感知放大技术，显著提升了运动放大的准确性和视觉质量。

- Motivation: 内窥镜手术中血管细微运动的可视化对手术精度和决策至关重要，但由于手术场景的复杂性和动态性，这一任务极具挑战性。
- Method: 提出EndoControlMag框架，包含周期性参考重置（PRR）和分层组织感知放大（HTM）模块，采用双模式掩码膨胀策略，适应不同手术场景。
- Result: 在EndoVMM24数据集上的实验表明，EndoControlMag在放大准确性和视觉质量上显著优于现有方法，并在复杂手术条件下保持鲁棒性。
- Conclusion: EndoControlMag为内窥镜手术中的血管运动可视化提供了一种高效且鲁棒的解决方案，具有广泛的应用潜力。


### [157] [MedSR-Impact: Transformer-Based Super-Resolution for Lung CT Segmentation, Radiomics, Classification, and Prognosis](https://arxiv.org/abs/2507.15340)
*Marc Boubnovski Martell,Kristofer Linton-Reid,Mitchell Chen,Sumeet Hindocha,Benjamin Hunter,Marco A. Calzado,Richard Lee,Joram M. Posma,Eric O. Aboagye*

Main category: eess.IV

TL;DR: TVSRN-V2是一种基于Transformer的超分辨率框架，用于临床肺部CT分析，显著提升了分割准确性、放射组学特征可重复性和预测性能。

- Motivation: 高分辨率CT对胸部疾病诊断和治疗规划至关重要，但受限于辐射剂量和硬件成本。
- Method: 采用Transformer架构，包括Through-Plane Attention Blocks和Swin Transformer V2，结合伪低分辨率增强技术提升鲁棒性。
- Result: 在多个临床队列中，分割准确性提升4%（Dice），放射组学特征可重复性更高，预测性能提升（C-index和AUC+0.06）。
- Conclusion: TVSRN-V2是一种临床可行的系统，通过超分辨率恢复结构细节，显著提升临床决策支持能力。


### [158] [Latent Space Synergy: Text-Guided Data Augmentation for Direct Diffusion Biomedical Segmentation](https://arxiv.org/abs/2507.15361)
*Muhammad Aqeel,Maham Nazir,Zanxi Ruan,Francesco Setti*

Main category: eess.IV

TL;DR: SynDiff结合文本引导的合成数据生成和高效扩散分割，解决医学图像分割中的数据稀缺问题，提升分割性能。

- Motivation: 医学图像分割（如息肉检测）面临数据稀缺问题，标注需要专业知识。SynDiff旨在通过合成数据增强解决这一问题。
- Method: 使用潜在扩散模型生成临床真实的合成息肉，通过文本条件修复增强训练数据，并引入直接潜在估计实现单步推理。
- Result: 在CVC-ClinicDB上达到96.0% Dice和92.9% IoU，保持实时性能。
- Conclusion: SynDiff通过可控合成增强提升分割鲁棒性，适用于资源有限的医疗场景。


### [159] [A Steel Surface Defect Detection Method Based on Lightweight Convolution Optimization](https://arxiv.org/abs/2507.15476)
*Cong Chen,Ming Chen,Hoileong Lee,Yan Li,Jiyang Yu*

Main category: eess.IV

TL;DR: 提出了一种基于YOLOv9s的深度学习框架，结合C3Ghost、SCConv和CARAFE模块，提升钢表面多尺度缺陷检测的精度和性能。

- Motivation: 钢表面缺陷检测在工业制造中面临多尺度缺陷识别困难、传统方法精度不足和高漏检率的问题。
- Method: 采用SCConv模块优化特征表示，C3Ghost模块增强特征提取能力，CARAFE上采样算子精细化重组特征图。
- Result: 实验表明，该方法在钢表面缺陷检测中具有更高的精度和鲁棒性。
- Conclusion: 该框架有效解决了钢表面缺陷检测问题，优于其他方法。


### [160] [DeSamba: Decoupled Spectral Adaptive Framework for 3D Multi-Sequence MRI Lesion Classification](https://arxiv.org/abs/2507.15487)
*Dezhen Wang,Sheng Miao,Rongxin Chai,Jiufa Cui*

Main category: eess.IV

TL;DR: DeSamba框架通过解耦表示学习和动态频谱-空间特征融合，显著提升了多序列MRI数据的3D病灶分类性能。

- Motivation: 多序列MRI数据的有效整合对病灶分类至关重要，但现有方法难以实现稳健的3D分类。
- Method: 提出DeSamba框架，包含解耦表示学习模块（DRLM）和频谱自适应调制块（SAMB），动态融合频谱与空间特征。
- Result: 在脊柱转移和脊柱炎数据集上，DeSamba性能优于现有方法，AUC分别达87.71%和74.75%。
- Conclusion: DeSamba为多序列医学影像的3D病灶分类提供了通用且高效的解决方案。


### [161] [RARE-UNet: Resolution-Aligned Routing Entry for Adaptive Medical Image Segmentation](https://arxiv.org/abs/2507.15524)
*Simon Winther Albertsen,Hjalte Svaneborg Bjørnstrup,Mostafa Mehdipour Ghazi*

Main category: eess.IV

TL;DR: RARE-UNet是一种分辨率感知的多尺度分割架构，通过动态调整推理路径适应输入分辨率，显著提升低分辨率数据的分割性能。

- Motivation: 现有模型在高分辨率输入下表现良好，但在低分辨率数据中性能显著下降，限制了临床应用的准确性。
- Method: 提出RARE-UNet，采用多尺度块、分辨率感知路由机制和一致性驱动训练，动态适应输入分辨率。
- Result: 在脑部影像任务中，RARE-UNet的平均Dice分数最高（0.84和0.65），且推理时间显著减少。
- Conclusion: RARE-UNet在分辨率鲁棒性和效率上表现优异，适用于临床场景。
## cs.IR

### [162] [LOVO: Efficient Complex Object Query in Large-Scale Video Datasets](https://arxiv.org/abs/2507.14301)
*Yuxin Liu,Yuezhang Peng,Hefeng Zhou,Hongze Liu,Xinyu Lu,Jiong Lou,Chentao Wu,Wei Zhao,Jie Li*

Main category: cs.IR

TL;DR: LOVO是一个高效处理大规模视频数据中复杂对象查询的系统，通过预训练视觉编码器提取特征，构建高效索引，显著降低查询延迟并提高准确性。

- Motivation: 随着摄像头广泛部署，视频数据激增，现有方法难以高效处理大规模视频中的复杂对象查询，且查询延迟高。
- Method: LOVO使用预训练视觉编码器一次性提取特征，构建紧凑视觉嵌入和倒排多索引结构，支持快速近似最近邻搜索和跨模态重排序。
- Result: 在真实视频数据集上，LOVO在复杂查询处理中表现优异，查询准确率接近最优，搜索延迟降低85倍，索引构建成本显著减少。
- Conclusion: LOVO重新定义了视频分析中对象查询的最新技术，为动态环境中的复杂查询提供了可扩展且高效的解决方案。


### [163] [U-MARVEL: Unveiling Key Factors for Universal Multimodal Retrieval via Embedding Learning with MLLMs](https://arxiv.org/abs/2507.14902)
*Xiaojie Li,Chu Li,Shi-Zhe Chen,Xi Chen*

Main category: cs.IR

TL;DR: 论文提出了一种名为U-MARVEL的统一框架，通过系统分析多模态检索中的关键因素，显著提升了性能。

- Motivation: 现有基于MLLM的多模态检索方法虽有效，但其机制未充分探索，可能导致性能不佳和泛化能力有限。
- Method: 构建通用MLLM嵌入学习流程，分析关键因素，并探索嵌入生成和训练策略（如渐进过渡、困难负样本挖掘和重排序蒸馏）。
- Result: U-MARVEL框架在M-BEIR基准测试中大幅领先，并在零样本任务中表现优异。
- Conclusion: U-MARVEL展示了在多模态检索任务中的强大泛化能力，为未来研究提供了重要参考。
## cs.NI

### [164] [On Splitting Lightweight Semantic Image Segmentation for Wireless Communications](https://arxiv.org/abs/2507.14199)
*Ebrahim Abu-Helalah,Jordi Serra,Jordi Perez-Romero*

Main category: cs.NI

TL;DR: 本文提出了一种新颖的语义通信方法，通过在资源受限的发射器和接收器之间分割语义图像分割过程，以降低带宽需求和计算负担，同时保持分割精度。

- Motivation: 当前语义通信在图像分割中难以平衡计算效率、带宽需求和精度，尤其是在资源受限和信道条件变化的环境中。
- Method: 提出将语义图像分割过程分割到资源受限的发射器和接收器之间，以减少传输数据量和发射器的计算负担。
- Result: 实验表明，与全分割在发射器相比，传输比特率降低72%，发射器计算负载减少19%以上。
- Conclusion: 该方法适用于通信系统，尤其是未来的6G系统，具有显著的应用潜力。
## cs.ET

### [165] [Design of an Edge-based Portable EHR System for Anemia Screening in Remote Health Applications](https://arxiv.org/abs/2507.15146)
*Sebastian A. Cruz Romero,Misael J. Mercado Hernandez,Samir Y. Ali Rivera,Jorge A. Santiago Fernandez,Wilfredo E. Lugo Beauchamp*

Main category: cs.ET

TL;DR: 本文提出了一种便携式、边缘支持的电子健康记录平台，专为资源有限的环境设计，支持离线操作、安全数据管理和模块化诊断集成。通过贫血筛查模块验证，系统在性能和成本上表现优异。

- Motivation: 解决资源有限环境中医疗系统的互操作性差、缺乏离线支持和高成本基础设施依赖等问题。
- Method: 开发了一种便携式电子健康记录平台，支持AES-256加密本地存储和可选云同步，集成了基于随机森林的贫血筛查模块和优化的YOLOv8n指甲床检测器。
- Result: 贫血筛查模块测试RMSE为1.969 g/dL，MAE为1.490 g/dL，灵敏度达79.2%。YOLOv8n检测器延迟从46.96 ms降至21.50 ms，mAP@0.5保持0.995。
- Conclusion: 该系统为资源有限环境提供了一种低成本、模块化且合规的解决方案，支持便携式健康信息系统的发展。
## cs.LG

### [166] [Generative Distribution Distillation](https://arxiv.org/abs/2507.14503)
*Jiequan Cui,Beier Zhu,Qingshan Xu,Xiaogang Xu,Pengguang Chen,Xiaojuan Qi,Bei Yu,Hanwang Zhang,Richang Hong*

Main category: cs.LG

TL;DR: 论文提出了一种名为GenDD的条件生成框架，用于知识蒸馏（KD），解决了高维优化和标签语义监督不足的问题，通过Split Tokenization和Distribution Contraction技术实现了高效的无监督和有监督训练。

- Motivation: 知识蒸馏通常面临高维优化和缺乏标签语义监督的挑战，需要一种更高效的框架来解决这些问题。
- Method: 提出GenDD框架，采用Split Tokenization策略实现无监督KD，并通过Distribution Contraction技术整合标签监督。
- Result: 在无监督设置下，GenDD显著优于KL基线16.29%；在有监督设置下，ResNet-50在ImageNet上达到82.28%的top-1准确率。
- Conclusion: GenDD框架在无监督和有监督知识蒸馏中均表现出色，成为新的state-of-the-art方法。


### [167] [The Origin of Self-Attention: From Pairwise Affinity Matrices to Transformers](https://arxiv.org/abs/2507.14560)
*Giorgio Roffo*

Main category: cs.LG

TL;DR: 论文追溯了自注意力机制的概念起源，将其视为基于亲和矩阵的通用计算原则的特例，并与无限特征选择（Inf-FS）进行了对比。

- Motivation: 揭示自注意力机制与更广泛的基于亲和矩阵的计算方法之间的联系，统一不同领域的机器学习研究。
- Method: 通过分析自注意力与Inf-FS的亲和矩阵定义和应用方式，比较两者的异同。
- Result: 自注意力是Inf-FS的单跳特例，两者共享基于成对关系的计算结构。
- Conclusion: 将自注意力置于基于亲和矩阵的计算范式中，为不同模型和任务提供了统一的数学基础。


### [168] [CXR-TFT: Multi-Modal Temporal Fusion Transformer for Predicting Chest X-ray Trajectories](https://arxiv.org/abs/2507.14766)
*Mehak Arora,Ayman Ali,Kaiyuan Wu,Carolyn Davis,Takashi Shimazui,Mahmoud Alwakeel,Victor Moas,Philip Yang,Annette Esper,Rishikesan Kamaleswaran*

Main category: cs.LG

TL;DR: CXR-TFT是一种新型多模态框架，结合稀疏的胸部X光片和临床数据，预测重症患者的X光片结果变化。

- Motivation: 解决现有胸部X光片分析工具无法捕捉时间动态的问题，提升重症监护中的诊断效率。
- Method: 通过视觉编码器生成潜在嵌入，与高频临床数据对齐，利用Transformer模型预测未来X光片结果。
- Result: 在2万名ICU患者中，CXR-TFT能提前12小时高准确率预测异常X光片结果。
- Conclusion: CXR-TFT提供高时间分辨率的预测能力，有望改善急性呼吸窘迫综合征等时间敏感病症的管理。


### [169] [Flow Equivariant Recurrent Neural Networks](https://arxiv.org/abs/2507.14793)
*T. Anderson Keller*

Main category: cs.LG

TL;DR: 论文将等变性网络理论扩展到时间参数化的序列变换（如RNN），提出了流等变性模型，显著提升了训练速度和泛化能力。

- Motivation: 现有等变性网络仅适用于静态变换和前馈网络，无法处理时间参数化的序列变换（如视觉运动），限制了其在序列模型中的应用。
- Method: 扩展等变性网络理论到时间参数化的流变换，提出流等变性模型，并通过实验验证其有效性。
- Result: 流等变性模型在训练速度、长度泛化和速度泛化方面显著优于非等变性模型。
- Conclusion: 这是构建尊重时间参数化对称性的序列模型的第一步，为未来研究奠定了基础。


### [170] [To Label or Not to Label: PALM -- A Predictive Model for Evaluating Sample Efficiency in Active Learning Models](https://arxiv.org/abs/2507.15381)
*Julia Machnio,Mads Nielsen,Mostafa Mehdipour Ghazi*

Main category: cs.LG

TL;DR: PALM提出了一种统一的数学模型，用于分析主动学习（AL）的动态过程，通过四个关键参数预测性能，并在实验中验证了其有效性。

- Motivation: 传统AL评估方法仅关注最终准确性，无法全面捕捉学习过程的动态性，PALM旨在填补这一空白。
- Method: PALM通过四个参数（可达到的准确性、覆盖效率、早期表现和可扩展性）建模AL轨迹，并利用部分观测预测未来性能。
- Result: 实验表明，PALM能有效泛化到不同数据集、预算和策略，准确预测学习曲线，并揭示AL方法的关键效率。
- Conclusion: PALM为AL的系统化、可重复和数据高效评估奠定了基础，适用于研究和实际应用。


### [171] [GUI-G$^2$: Gaussian Reward Modeling for GUI Grounding](https://arxiv.org/abs/2507.15846)
*Fei Tang,Zhangxuan Gu,Zhengxi Lu,Xuyang Liu,Shuheng Shen,Changhua Meng,Wen Wang,Wenqi Zhang,Yongliang Shen,Weiming Lu,Jun Xiao,Yueting Zhuang*

Main category: cs.LG

TL;DR: 论文提出GUI-G²，一种基于高斯分布的奖励框架，用于改进GUI交互任务中的空间定位，显著优于现有方法。

- Motivation: 现有强化学习方法使用二元奖励，忽略了空间交互的连续性，而人类点击行为自然形成高斯分布。
- Method: GUI-G²通过高斯点奖励和覆盖奖励建模连续分布，并采用自适应方差机制处理不同元素尺寸。
- Result: 在多个基准测试中，GUI-G²显著优于UI-TARS-72B，最高提升24.7%。
- Conclusion: 连续建模提高了对界面变化的鲁棒性和泛化能力，为GUI交互任务建立了新范式。


### [172] [Diffusion Beats Autoregressive in Data-Constrained Settings](https://arxiv.org/abs/2507.15857)
*Mihir Prabhudesai,Menging Wu,Amir Zadeh,Katerina Fragkiadaki,Deepak Pathak*

Main category: cs.LG

TL;DR: 扩散模型在数据受限场景下优于自回归模型，尤其在计算资源充足时表现更佳。

- Motivation: 探索扩散模型在数据受限情况下相对于自回归模型的优势。
- Method: 系统研究掩码扩散模型在数据受限场景下的表现，分析其性能。
- Result: 扩散模型在数据稀缺时表现更好，验证损失更低，下游任务性能更优。
- Conclusion: 当数据成为瓶颈时，扩散模型是自回归模型的有力替代方案。
## cs.CL

### [173] [In-Depth and In-Breadth: Pre-training Multimodal Language Models Customized for Comprehensive Chart Understanding](https://arxiv.org/abs/2507.14298)
*Wan-Cyuan Fan,Yen-Chun Chen,Mengchen Liu,Alexander Jacobson,Lu Yuan,Leonid Sigal*

Main category: cs.CL

TL;DR: ChartScope是一种针对多样化图表类型优化的LVLM，通过高效数据生成管道和双路径训练策略提升图表理解能力。

- Motivation: 现有方法依赖有限图表类型的配对数据且缺乏针对性预训练，限制了模型的泛化能力和数据理解。
- Method: 提出高效数据生成管道和双路径训练策略，结合底层数据推理。
- Result: 实验表明ChartScope显著提升了对多种图表类型的理解能力。
- Conclusion: ChartScope通过创新方法和数据生成策略，解决了现有方法的局限性，并建立了新的评估基准。


### [174] [Smart Eyes for Silent Threats: VLMs and In-Context Learning for THz Imaging](https://arxiv.org/abs/2507.15576)
*Nicolas Poggi,Shashank Agnihotri,Margret Keuper*

Main category: cs.CL

TL;DR: 论文提出了一种基于上下文学习（ICL）和视觉语言模型（VLM）的太赫兹（THz）图像分类方法，无需微调即可在低数据条件下提升分类效果和可解释性。

- Motivation: 太赫兹成像在安全筛查和材料分类等应用中具有潜力，但由于标注数据有限、分辨率低和视觉模糊等问题，其图像分类仍具挑战性。
- Method: 采用模态对齐的提示框架，将两种开放权重的视觉语言模型（VLM）适配到太赫兹领域，并在零样本和单样本设置下评估其性能。
- Result: 实验结果表明，上下文学习（ICL）在低数据条件下显著提升了分类性能和模型的可解释性。
- Conclusion: 这是首次将ICL增强的VLM应用于太赫兹成像，为资源受限的科学领域提供了一种有前景的解决方案。
## cs.GR

### [175] [Real-Time Scene Reconstruction using Light Field Probes](https://arxiv.org/abs/2507.14624)
*Yaru Liu,Derek Nowrouzezahri,Morgan Mcguire*

Main category: cs.GR

TL;DR: 提出了一种基于探针数据结构的神经渲染方法，用于高效重建大规模复杂场景，无需显式依赖几何数据。

- Motivation: 解决现有神经渲染方法在大规模场景中效率低、显式几何数据维护成本高的问题。
- Method: 利用探针数据结构重建多尺度隐式几何表示，结合稀疏图像输入实现高效渲染。
- Result: 方法显著降低了计算成本，渲染效率与场景复杂度无关，适用于VR/AR应用。
- Conclusion: 探针数据结构为大规模场景的神经渲染提供了一种高效且可扩展的解决方案。


### [176] [Towards Geometric and Textural Consistency 3D Scene Generation via Single Image-guided Model Generation and Layout Optimization](https://arxiv.org/abs/2507.14841)
*Xiang Tang,Ruotong Li,Xiaopeng Fan*

Main category: cs.GR

TL;DR: 提出一种三阶段框架，通过单图像引导生成和空间布局优化，解决单RGB图像生成3D场景的挑战。

- Motivation: 当前方法在多对象场景中难以保证生成质量和场景一致性，需改进。
- Method: 三阶段框架：图像实例分割与修复、伪立体视角构建与模型选择、布局参数优化。
- Result: 在几何精度和纹理保真度上优于现有方法，且在场景布局合成中表现突出。
- Conclusion: 该方法有效提升了单图像生成3D场景的质量和一致性。


### [177] [Blended Point Cloud Diffusion for Localized Text-guided Shape Editing](https://arxiv.org/abs/2507.15399)
*Etai Sella,Noam Atia,Ron Mokady,Hadar Averbuch-Elor*

Main category: cs.GR

TL;DR: 提出了一种基于修复的框架，用于编辑点云表示的3D形状，结合3D扩散模型和坐标混合算法，实现局部编辑并保持全局一致性。

- Motivation: 自然语言为3D形状的局部精细编辑提供了直观接口，但现有方法难以在局部修改时保持全局一致性。
- Method: 利用基础3D扩散模型进行局部形状编辑，引入部分条件形状作为结构指导，并提出推理时坐标混合算法，平衡全形状重建与修复。
- Result: 实验表明，该方法在保真度和文本描述一致性方面优于其他技术。
- Conclusion: 该方法通过坐标混合算法实现了精细编辑，避免了计算成本高且不准确的逆过程。


### [178] [ObjectGS: Object-aware Scene Reconstruction and Scene Understanding via Gaussian Splatting](https://arxiv.org/abs/2507.15454)
*Ruijie Zhu,Mulin Yu,Linning Xu,Lihan Jiang,Yixuan Li,Tianzhu Zhang,Jiangmiao Pang,Bo Dai*

Main category: cs.GR

TL;DR: ObjectGS是一个结合3D场景重建与语义理解的对象感知框架，通过动态调整局部锚点实现精确的对象级重建。

- Motivation: 3D Gaussian Splatting缺乏语义理解，限制了对象级感知能力。
- Method: ObjectGS将场景中的对象建模为局部锚点，生成神经高斯并共享对象ID，通过动态调整锚点和优化特征实现重建。
- Result: 在开放词汇和全景分割任务中优于现有方法，并能无缝集成网格提取和场景编辑应用。
- Conclusion: ObjectGS成功实现了高保真重建与语义理解的结合，为对象级感知提供了新思路。


### [179] [Gaussian Splatting with Discretized SDF for Relightable Assets](https://arxiv.org/abs/2507.15629)
*Zuo-Liang Zhu,Jian Yang,Beibei Wang*

Main category: cs.GR

TL;DR: 3D高斯泼溅（3DGS）在逆渲染任务中通过离散化SDF表示，结合投影一致性损失，提高了重光照质量，同时避免了额外内存和复杂优化。

- Motivation: 解决3DGS在逆渲染中因离散性难以应用几何约束的问题，同时避免现有方法增加内存和训练复杂性的缺点。
- Method: 提出离散化SDF表示，通过SDF-to-opacity转换链接高斯不透明度，并引入投影一致性损失正则化离散样本。
- Result: 实验表明，该方法在重光照质量上优于现有基于高斯的逆渲染方法，且无需额外内存或复杂优化。
- Conclusion: 离散化SDF结合投影一致性损失是一种高效且高质量的逆渲染解决方案。
## cs.RO

### [180] [Uncertainty-aware Probabilistic 3D Human Motion Forecasting via Invertible Networks](https://arxiv.org/abs/2507.14694)
*Yue Ma,Kanglei Zhou,Fuyang Yu,Frederick W. B. Li,Xiaohui Liang*

Main category: cs.RO

TL;DR: ProbHMI提出了一种基于可逆网络的方法，用于3D人体运动预测中的不确定性量化，适用于安全关键场景。

- Motivation: 现有方法在不确定性量化方面存在不足，而安全关键场景（如人机协作）需要准确的风险评估。
- Method: 使用可逆网络将姿态参数化解耦到潜在空间，并显式预测未来潜在分布以实现不确定性量化。
- Result: 在基准测试中，ProbHMI在确定性和多样性预测方面表现优异，且不确定性校准有效。
- Conclusion: ProbHMI为风险感知决策提供了可靠的不确定性量化方法。


### [181] [Low-Latency Event-Based Velocimetry for Quadrotor Control in a Narrow Pipe](https://arxiv.org/abs/2507.15444)
*Leonard Bauersfeld,Davide Scaramuzza*

Main category: cs.RO

TL;DR: 提出了一种基于实时流场测量的四旋翼无人机闭环控制系统，用于在狭窄管道中悬停和横向移动。

- Motivation: 解决四旋翼在狭窄管道中因气流扰动导致的悬停不稳定问题。
- Method: 开发了低延迟的事件烟雾测速法，结合循环卷积神经网络估计扰动，并通过强化学习训练控制器。
- Result: 系统能有效抵消瞬态气动效应，防止与管道壁碰撞。
- Conclusion: 首次展示了基于实时流场测量的无人机闭环控制，为复杂气动环境中的飞行研究开辟了新方向。


### [182] [GR-3 Technical Report](https://arxiv.org/abs/2507.15493)
*Chilam Cheang,Sijin Chen,Zhongren Cui,Yingdong Hu,Liqun Huang,Tao Kong,Hang Li,Yifeng Li,Yuxiao Liu,Xiao Ma,Hao Niu,Wenxuan Ou,Wanli Peng,Zeyu Ren,Haixin Shi,Jiawen Tian,Hongtao Wu,Xin Xiao,Yuyang Xiao,Jiafeng Xu,Yichu Yang*

Main category: cs.RO

TL;DR: GR-3是一个大规模视觉-语言-动作模型，展示了在新对象、环境和抽象指令上的卓越泛化能力，并能高效微调。结合ByteMini机器人，GR-3在多种任务中超越现有方法。

- Motivation: 开发通用机器人策略，以辅助人类日常生活。
- Method: 通过多模态训练（网络规模视觉-语言数据、人类轨迹数据微调、机器人轨迹模仿学习）构建GR-3模型。
- Result: GR-3在多种挑战性任务中表现优于现有方法。
- Conclusion: GR-3是迈向通用机器人技术的重要一步。


### [183] [Look, Focus, Act: Efficient and Robust Robot Learning via Human Gaze and Foveated Vision Transformers](https://arxiv.org/abs/2507.15833)
*Ian Chuang,Andrew Lee,Dechen Gao,Jinyu Zou,Iman Soltani*

Main category: cs.RO

TL;DR: 论文探讨了将人类主动注视机制融入机器人视觉系统的方法，以提高效率和性能。通过模拟人类头部和眼球运动，结合注视数据和机器人演示，提出了一种新的框架，并在ViTs中引入注视信息以减少计算量。实验表明，该方法显著降低了计算开销，并提升了任务性能和鲁棒性。

- Motivation: 人类视觉通过主动注视任务相关区域显著减少视觉处理，而机器人系统通常被动处理图像。研究旨在探索如何通过模拟人类注视机制提升机器人视觉系统的效率和性能。
- Method: 提出了一种框架，结合人类注视数据和机器人演示，利用ViTs中的注视信息进行图像处理。采用两种方法：两阶段模型预测注视以指导动作，以及端到端联合预测注视和动作。
- Result: 实验结果显示，该方法显著减少了计算开销，同时提高了高精度任务的性能和对抗干扰的鲁棒性。
- Conclusion: 人类启发的视觉处理为机器人视觉系统提供了有益的归纳偏置，显著提升了效率和性能。
## cs.AI

### [184] [WebGuard: Building a Generalizable Guardrail for Web Agents](https://arxiv.org/abs/2507.14293)
*Boyuan Zheng,Zeyi Liao,Scott Salisbury,Zeyuan Liu,Michael Lin,Qinyuan Zheng,Zifan Wang,Xiang Deng,Dawn Song,Huan Sun,Yu Su*

Main category: cs.AI

TL;DR: WebGuard是一个用于评估网络代理行为风险的数据集，旨在为现实世界在线环境开发安全措施。研究发现，即使前沿的大型语言模型在预测高风险行为时表现不佳，但通过微调专用模型可以显著提升性能。

- Motivation: 随着基于大型语言模型的自主网络代理快速发展，其可能采取意外或有害行为的风险凸显，亟需有效的安全措施。
- Method: 引入WebGuard数据集，包含4,939个人工标注的行为，采用三级风险分类（SAFE、LOW、HIGH），并支持多种泛化场景的评估。通过微调专用模型（如Qwen2.5VL-7B）提升性能。
- Result: 前沿大型语言模型在预测行为结果和高风险行为召回率上表现不佳（均低于60%）。微调后模型性能显著提升（准确率从37%升至80%，高风险行为召回率从20%升至76%）。
- Conclusion: 尽管微调模型性能有所改善，但仍未达到高可靠性部署的要求，需进一步优化以实现近乎完美的准确率和召回率。


### [185] [InsightX Agent: An LMM-based Agentic Framework with Integrated Tools for Reliable X-ray NDT Analysis](https://arxiv.org/abs/2507.14899)
*Jiale Liu,Huan Wang,Yue Zhang,Xiaoyu Luo,Jiaxiang Hu,Zhiliang Liu,Min Xie*

Main category: cs.AI

TL;DR: 本文提出了一种基于大型多模态模型（LMM）的交互式框架InsightX Agent，用于提升X射线无损检测的可靠性和可解释性。

- Motivation: 现有基于深度学习的X射线检测方法缺乏交互性、可解释性和自我评估能力，限制了其可靠性和操作员信任。
- Method: InsightX Agent以LMM为核心，协调稀疏可变形多尺度检测器（SDMSD）和基于证据的反思工具（EGR），通过主动推理优化检测和分析过程。
- Result: 在GDXray+数据集上，InsightX Agent实现了96.35%的F1分数，显著提升了分析的可解释性和可信度。
- Conclusion: InsightX Agent展示了基于代理的LMM框架在工业检测任务中的变革潜力。


### [186] [Chart-R1: Chain-of-Thought Supervision and Reinforcement for Advanced Chart Reasoner](https://arxiv.org/abs/2507.15509)
*Lei Chen,Xuanle Zhao,Zhixiong Zeng,Jing Huang,Yufeng Zhong,Lin Ma*

Main category: cs.AI

TL;DR: Chart-R1是一种基于强化学习微调的图表领域视觉语言模型，用于复杂图表推理。通过程序化数据合成技术和两阶段训练策略（Chart-COT和Chart-RFT），在开源基准和自建数据集上表现优异。

- Motivation: 验证R1-Style方法在通用多模态数据（如图表）上的优势，解决图表领域推理数据不足的挑战。
- Method: 提出程序化数据合成技术生成高质量推理数据，并采用两阶段训练策略（Chart-COT和Chart-RFT）。
- Result: Chart-R1在图表领域方法中表现显著优于其他方法，甚至可与GPT-4o等大型模型媲美。
- Conclusion: Chart-R1为图表领域的复杂推理任务提供了有效解决方案，展示了强化学习在多模态数据中的潜力。
## cs.CE

### [187] [Self-Supervised Distillation of Legacy Rule-Based Methods for Enhanced EEG-Based Decision-Making](https://arxiv.org/abs/2507.14542)
*Yipeng Zhang,Yuanyi Ding,Chenda Duan,Atsuro Daida,Hiroki Nariai,Vwani Roychowdhury*

Main category: cs.CE

TL;DR: 论文提出了一种自监督学习框架SS2LD，用于改进传统HFO检测器的高假阳性问题，通过变分自编码器和聚类技术生成弱监督信号，最终提升病理HFO的检测精度。

- Motivation: 传统HFO检测器精度不足且依赖专家标注数据，而标注数据获取困难且一致性差，因此需要一种无需大量标注的高效检测方法。
- Method: 使用变分自编码器（VAE）进行形态学预训练，学习潜在表示；通过聚类生成弱监督信号；结合真实和增强数据训练分类器优化检测边界。
- Result: 在多机构间期iEEG数据集上，SS2LD优于现有方法，提供了一种可扩展且高效的病理HFO检测策略。
- Conclusion: SS2LD通过自监督学习和弱监督信号，显著提升了病理HFO的检测精度，为临床提供了更可靠的工具。
## cs.DC

### [188] [Towards a Proactive Autoscaling Framework for Data Stream Processing at the Edge using GRU and Transfer Learning](https://arxiv.org/abs/2507.14597)
*Eugene Armah,Linda Amoako Bannning*

Main category: cs.DC

TL;DR: 论文提出了一种三步骤解决方案，用于主动边缘流处理自动扩展问题，包括负载预测、迁移学习框架和动态并行度调整。

- Motivation: 随着数字经济的快速发展，高速数据处理变得至关重要。边缘流处理面临快速工作负载波动，现有方法难以满足资源分配的实时需求。
- Method: 1. 使用GRU神经网络预测上游负载；2. 通过迁移学习框架将预测模型集成到在线系统中；3. 基于预测负载动态调整操作并行度。
- Result: GRU模型在真实数据集上达到1.3%的SMAPE值，优于CNN、ARIMA和Prophet，且训练时间短于强化学习模型。
- Conclusion: 提出的方法有效解决了边缘流处理的资源分配问题，具有高预测精度和低计算开销。
## cs.MM

### [189] [Prompt-aware of Frame Sampling for Efficient Text-Video Retrieval](https://arxiv.org/abs/2507.15491)
*Deyu Zhang,Tingting Long,Jinrui Zhang,Ligeng Chen,Ju Ren,Yaoxue Zhang*

Main category: cs.MM

TL;DR: ProCLIP是一个用户中心的框架，通过动态帧采样和两阶段候选剪枝策略，在文本-视频检索中实现了高效和准确性。

- Motivation: 现有方法在平衡准确性和计算效率方面存在挑战，ProCLIP旨在解决这一问题。
- Method: 采用提示感知的帧采样策略和两阶段候选剪枝策略。
- Result: 在MSR-VTT数据集上实现75.3%的延迟减少，R@1=49.0。
- Conclusion: ProCLIP在保持高准确性的同时显著提升了效率。
